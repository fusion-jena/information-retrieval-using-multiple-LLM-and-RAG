@article{WU2024102519,
title = {Optimizing the ecological source area identification method and building ecological corridor using a genetic algorithm: A case study in Weihe River Basin, NW China},
journal = {Ecological Informatics},
volume = {80},
pages = {102519},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102519},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400061X},
author = {Xueting Wu and Jinghu Pan and Xiuwei Zhu},
keywords = {Ecological source areas, Ecological corridors, Genetic algorithm, Graph theory method, Ecological security},
abstract = {Abstract:
The extraction of ecological corridors is influenced by the accuracy of ecological source area identification, which is a crucial component of ecological security construction. The ecological source areas of the Weihe River Basin (WRB) were comprehensively identified by analyzing the supply, demand, and ecological sensitivity of ecosystem services. Different initial populations were set using a genetic algorithm to determine the optimal source areas for the WRB. The minimum cumulative resistance model (MCR) was used to extract the ecological corridors, and then a comparison was made before and after. The results showed that the ecological source areas within the WRB covered approximately 43.362 × 103 km2 in 2020, accounting for 32.38% of the entire area. This included mainly forest, grassland, and a small amount of farmland, of which 89.3% of the ecological source areas were forest. Fifty optimal ecological source areas were obtained using a genetic algorithm, generating 122 ecological corridors with an overall length of 40.245 × 105 km that could disperse the entire WRB. By comparing the ecological source areas before and after optimization, the IIC value of the ecological source areas before optimization was 0.006, the PC value was 0.007, and the FN value was 0.10. The IIC, PC, and FN values of the optimized ecological source area were 0.08, 0.079, and 0.042, respectively. The overall connectivity of the optimal source identified by the genetic algorithm increased by 13.3 times, with a possible connectivity increase of 11.2 times and a 42% reduction in fragmentation. The applicability and reliability in identifying optimal ecological source areas genetic algorithm was high, offering a reliable idea for constructing regional ecological security.}
}
@article{CHAWLA2024102548,
title = {MobileNet-GRU fusion for optimizing diagnosis of yellow vein mosaic virus},
journal = {Ecological Informatics},
volume = {81},
pages = {102548},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102548},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000906},
author = {Tisha Chawla and Shubh Mittal and Hiteshwar Kumar Azad},
keywords = {Yellow vein mosaic virus, MobileNet, Gated recurrent unit, Recurrent neural networks, Transfer learning, Deep learning},
abstract = {Yellow vein mosaic virus (YVMV) is a destructive plant virus that commonly affects crops, particularly okra, in India. The virus is transmitted by whiteflies and poses significant challenges to agricultural productivity. Infection with YVMV leads to distinct yellow vein patterns on leaves, stunted growth, reduced yield, and ultimately economic losses for farmers. Timely and accurate detection of YVMV is crucial for effective disease management. In this article, we present a novel method that employs advanced deep-learning models to identify YVMV-infected okra plants. The study leverages a dataset of over 2000 okra plant leaves that implements transfer learning models, including MobileNet, EfficientNet, InceptionV3, VGG19, InceptionResNetV2, and ResNet50 and recurrent neural networks (RNN) variants, including Long short-term memory (LSTM), Bidirectional long short-term memory (BiLSTM) and Gated recurrent unit (GRU). Additionally, three hybrid models, combining MobileNet with LSTM, BiLSTM, and GRU, are incorporated to capitalize on the characteristics of both MobileNet and RNNs through superior feature extraction and detection of temporal dependencies. The results demonstrate that the MobileNet model combined with all three RNNs achieves exceptional accuracy, surpassing 99.27%. Notably, the MobileNet model integrated with GRU exhibits the most optimized performance with the least loss and greatest accuracy, facilitating improved disease management strategies and aiding in the yield of crops by reducing the impact of YVMV.}
}
@article{VIZCARRA2021101268,
title = {The Peruvian Amazon forestry dataset: A leaf image classification corpus},
journal = {Ecological Informatics},
volume = {62},
pages = {101268},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101268},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000595},
author = {Gerson Vizcarra and Danitza Bermejo and Antoni Mauricio and Ricardo {Zarate Gomez} and Erwin Dianderas},
keywords = {Leaves dataset, Peruvian Amazon, Deep learning, Visual interpretation, Interpretation},
abstract = {Forest census allows getting precise data for logging planning and elaboration of the forest management plan. Species identification blunders carry inadequate forest management plans and high risks inside forest concessions. Hence, an identification protocol prevents the exploitation of non-commercial or endangered timber species. The current Peruvian legislation allows the incorporation of non-technical experts, called “materos”, during the identification. Materos use common names given by the folklore and traditions of their communities instead of formal ones, which generally lead to misclassifications. In the real world, logging companies hire materos instead of botanists due to cost/time limitations. Given such a motivation, we explore an end-to-end software solution to automatize the species identification. This paper introduces the Peruvian Amazon Forestry Dataset, which includes 59,441 leaves samples from ten of the most profitable and endangered timber-tree species. The proposal contemplates a background removal algorithm to feed a pre-trained CNN by the ImageNet dataset. We evaluate the quantitative (accuracy metric) and qualitative (visual interpretation) impacts of each stage by ablation experiments. The results show a 96.64% training accuracy and 96.52% testing accuracy on the VGG-19 model. Furthermore, the visual interpretation of the model evidences that leaf venations have the highest correlation in the plant recognition task.}
}
@article{PAGANO2023102133,
title = {Machine learning models to predict daily actual evapotranspiration of citrus orchards under regulated deficit irrigation},
journal = {Ecological Informatics},
volume = {76},
pages = {102133},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102133},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001620},
author = {Antonino Pagano and Federico Amato and Matteo Ippolito and Dario {De Caro} and Daniele Croce and Antonio Motisi and Giuseppe Provenzano and Ilenia Tinnirello},
keywords = {Actual evapotranspiration, Machine learning, Artificial Neural Network, Multi-Layer Perceptron, Random Forest, Citrus orchard, Regulated deficit irrigation},
abstract = {Precise estimations of actual evapotranspiration (ETa) are essential for various environmental issues, including those related to agricultural ecosystem sustainability and water management. Indeed, the increasing demands of agricultural production, coupled with increasingly frequent drought events in many parts of the world, necessitate a more careful evaluation of crop water requirements. Artificial Intelligence-based models represent a promising alternative to the most common measurement techniques, e.g. using expensive Eddy Covariance (EC) towers. In this context, the main challenges are choosing the best possible model and selecting the most representative features. The objective of this research is to evaluate two different machine learning algorithms, namely Multi-Layer Perceptron (MLP) and Random Forest (RF), to predict daily actual evapotranspiration (ETa) in a citrus orchard typical of the Mediterranean ecosystem using different feature combinations. With many features available coming from various infield sensors, a thorough analysis was performed to measure feature importance, scatter matrix observations, and Pearson’s correlation coefficient calculation, which resulted in the selection of 12 promising feature combinations. The models were calibrated under regulated deficit irrigation (RDI) conditions to estimate ETa and save irrigation water. On average up to 38.5% water savings were obtained, compared to full irrigation. Moreover, among the different input variables adopted, the soil water content (SWC) feature appears to have a prominent role in the prediction of ETa. Indeed, the presented results show that by choosing the appropriate input features, the accuracy of the proposed machine learning models remains acceptable even when the number of features is reduced to only 4. The best performance was achieved by the Random Forest method, with seven input features, obtaining a root mean square error (RMSE) and a coefficient of determination (R2) of 0.39 mm/day and 0.84, respectively. Finally, the results show that the joint use of SWC, weather and satellite data significantly improves the performance of evapotranspiration forecasts compared to models using only meteorological variables.}
}
@article{KRISNAWIJAYA2024102613,
title = {Reference architecture design for developing data management systems in smart farming},
journal = {Ecological Informatics},
volume = {81},
pages = {102613},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102613},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001559},
author = {Ngakan Nyoman Kutha Krisnawijaya and Bedir Tekinerdogan and Cagatay Catal and Rik {van der Tol}},
keywords = {Domain analysis, Feature model, Reference architecture, Data management, Smart farming},
abstract = {The traditional data management systems prove inadequate to handle the volume, velocity, and variety of the data within farm business processes. Smart farming technologies offer advanced data management systems as a practical solution to these challenges. However, data is complex and originates from many sources; hence many aspects of data must be considered during the data management design of smart farming systems. This study proposes a reference architecture for data management in smart farming, developed through domain analysis and architecture modeling approaches. The domain analysis provides insights into the common and variant features and modules of the smart farming system, resulting in a blueprint representing family features across various smart farming domains. The effectiveness of the proposed reference architecture has been evaluated through two case studies, demonstrating its efficacy in designing data management systems for smart farming. The study found that the percentage of reused modules in the case studies, compared to the provided reference architecture, was 82.6%. The outcomes of this research will pave the way for further exploration in smart farming, particularly addressing data management issues within smart farming systems.}
}
@article{VAN2024102601,
title = {Enhancing wildfire mapping accuracy using mono-temporal Sentinel-2 data: A novel approach through qualitative and quantitative feature selection with explainable AI},
journal = {Ecological Informatics},
volume = {81},
pages = {102601},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001432},
author = {Linh Nguyen Van and Vinh Ngoc Tran and Giang V. Nguyen and Minho Yeon and May Thi-Tuyet Do and Giha Lee},
keywords = {Wildfire severity mapping, Machine learning, Sentinel-2, SHAP, Forward stepwise selection},
abstract = {Accurate wildfire severity mapping (WSM) is crucial in environmental damage assessment and recovery strategies. Machine learning (ML) and remote sensing technologies are extensively integrated and employed as powerful tools for WSM. However, the intricate nature of ML algorithms often leads to ‘black box’ systems, obscuring the decision-making process and significantly limiting stakeholders' ability to comprehend the basis of predictions. This opacity hinders efforts to enhance performance and risks exacerbating overfitting. This present study proposes an innovative WSM approach that incorporates qualitative and quantitative feature selection techniques within the Explainable AI (XAI) framework. The methodology aims to enhance the precision of WSM and provide insights into the factors contributing to model decisions, thereby increasing the interpretability of predictions and streamlining models to improve performance. To achieve this objective, we employed the SHapley Additive exPlanations (SHAP)-Forward Stepwise Selection (FSS) method to demonstrate its efficacy in elucidating the qualitative and quantitative impacts of predictors on ML algorithm performance, accuracy, and interpretability designed for WSM. Utilizing post-fire imagery from Sentinel-2 (S2), we analyzed ten bands to generate 225 unique spectral indices utilizing five different calculations: normalized, algebraic sum, difference, ratio, and product forms. Combined with the original S2 bands, this resulted in 235 potential predictors for ML classifications. A random forest model was subsequently developed using these predictors and optimized through extensive hyperparameter tuning, achieving an overall accuracy (OA) of 0.917 and a Kappa statistic of 0.896. The most influential predictors were identified using SHAP values, with an FSS process narrowing them down to the 12 most critical for effective WSM, as evidenced by stabilized OA and Kappa values (0.904 and 0.881, respectively). Further validation using a ninefold spatial cross-validation technique demonstrated the method's consistent performance across different data partitions, with OA values ranging from 0.705 to 0.894 and Kappa values from 0.607 to 0.867. By providing a more accurate and comprehensible XAI-based method for WSM, this research contributes to the broader field of environmental monitoring and disaster response, underscoring the potential of integrated qualitative and quantitative analysis to enhance ML models' capabilities.}
}
@article{STEN2024102670,
title = {A ridge-based detection algorithm with filament overlap identification for 2D mycelium network analysis},
journal = {Ecological Informatics},
volume = {82},
pages = {102670},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102670},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002127},
author = {Oscar Sten and Emanuela {Del Dottore} and Nicola Pugno and Barbara Mazzolai},
keywords = {Mycelium, Network topology, Image analysis},
abstract = {Many terrestrial ecosystems engage mycorrhizal symbiotic associations, potentially to enhance nutrition, increase resistance to soil-borne pests and diseases, and improve resilience and soil structure. Mycorrhizal fungi create dynamic networked structures through branching and anastomosis that connect multiple plants and consent to transport resources underground from nutrient-rich patches to demanding plants. Controlled laboratory experiments are fundamental to improving our knowledge of mycelium network growth dynamics and further understanding its role in preserving ecological niches. We propose a method for highly automated analysis of the mycelium network structure and other morphological properties, such as hyphal length, hyphal density, and number of crossing and branches, in 2D microscopy images of fungal samples. Available tools for automated network analyses suffer from overestimating network connectivity since filament crossings are not considered. In particular, we propose a) a ridge-based mycelium detection algorithm and b) a geometrical-based approach to identify overlapping filaments crossing each other. The algorithmic solution is evaluated on a total of 135 real mycelium sample images over different validation steps, originating from different datasets and having different characteristics, including background, contrast, image acquisition system, fungal species, and clearness (e.g., level of transparency, homogeneity, dirtiness of the medium) of the sample. Results show that 1) the proposed detection method can be used to measure the length of mycelium in an image, replacing manual tracing and allowing for less laborious analysis ρ̂c=0.96, 2) the filament detection is on par with state-of-the-art techniques F1=0.88−0.94 with a more intuitive parameterization, and 3) the proposed algorithm correctly identifies filament crossings F1=0.89 in most common cases, yielding a reduction in the overestimation of network connectivity. The latter feature consents to applying the proposed fully automated solution to complex and irregular fungal structures, advancing mycelium detection and reconstruction performance accuracy with respect to the state-of-the-art.}
}
@article{CROCKER2024102698,
title = {Synthetic data for reef modelling},
journal = {Ecological Informatics},
volume = {82},
pages = {102698},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102698},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002401},
author = {Rose Crocker and Barbara J. Robson and Chinenye Ani and Ken Anthony and Takuya Iwanaga},
keywords = {Synthetic data, Reef modelling, Data pipeline, Model testing and validation, Decision support tools, Machine learning, Neural networks, Synthetic data vault},
abstract = {Synthetic data mimics the statistical properties of real-world datasets while removing reference to sensitive or confidential information in the original dataset (Quintana, 2020). Synthetic data is also useful for general model testing and development, with many methods available for generating data from machine learning models (Raghunathan, 2021). Although not widely used in the context of ecological and environmental modelling, synthetic data can support and accelerate model testing and analyses where rightsholders are sensitive to data disclosure for study areas, or data collection is expensive. In the context of reef modelling, synthetic data can be used to support model analyses that can be published without referring to specific sites, reefs, or study areas. This is desirable in the context of decision support for restoration of the Great Barrier Reef. The Reef has many stakeholders and release of early modelling results for intervention scenarios for specific areas would be premature until management or intervention strategy options have been discussed with stakeholders and/or rightsholders. Synthetic data allows a path to publish model and method demonstrations to share knowledge with the reef decision support community without prematurely suggesting policy recommendations for reefs which are sensitive to rightsholders or stakeholders. We showcase a synthetic data pipeline developed for the reef decision-support system ADRIA (Adaptive Dynamic Reef Intervention Algorithms), using methods from the Python package Synthetic Data Vault (Patki et al., 2016) and others. The synthetic data models are developed to emulate the statistics of case-study reefs for publishing decision-support tool demonstrations, testing and method validation without revealing sensitive reef site information. This pipeline includes developing models for tabular (benthic/compositional reef data), spatial-temporal (wave and heat stress data) and spatial network data (coral larval connectivity). Conditional sampling methods which connect spatial relationships across datasets are used to develop synthetic reef data packages which mimic the statistical properties of the original dataset. The utility of the synthetic data is demonstrated on a sample reef data package, and methods used for anonymizing the data are detailed. The results are discussed in the context of formalizing synthetic data for reef modelling. All synthetic data code is available at ADRIA-synthetic-data/README.md at v0.1.0 · open-AIMS/ADRIA-synthetic-data (github.com), DOI: https://doi.org/10.5281/zenodo.10158323.}
}
@article{LOPEZCOLLADO2024102444,
title = {Bioclimatic similarity between species locations and their environment revealed by dimensionality reduction analysis},
journal = {Ecological Informatics},
volume = {79},
pages = {102444},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102444},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004739},
author = {J. Lopez-Collado and J. Jacinto-Padilla and O. Rodríguez-Aguilar and J.V. Hidalgo-Contreras},
keywords = {Binary classifier, Data visualization, Latent distance, Species distribution modeling, UMAP},
abstract = {Species distribution modeling is an active research topic with applications in conservation management, pest risk assessment, and population ecology. Several machine-learning methods have been applied to estimate species distribution. Non-linear dimensionality reduction techniques aim to preserve the similarity among objects at a reduced dimension for visualization, clustering, and feature selection. We propose a framework that uses Uniform Manifold Approximation and Projection (UMAP) to analyze bioclimatic variables associated with environmental (background) and species samples. Our objective was to identify geographic areas similar to those inhabited by the species. We hypothesize that the similarity between species locations and their environment in the reduced dimension will reflect similarity in the multivariate bioclimatic space. We estimated the probability of background points near a species point utilizing the latent nearest neighbor distance distribution. We tested this procedure with ten insect pest species of global importance and found that UMAP was able to generate a gradient of similarity between geographic areas and species occurrence. We also found that background-species latent distance tends to have a convergent non-linear relationship with the mean value of bioclimatic variables, thus supporting our key assumption. The performance of UMAP as a binary classifier and comparison with MaxEnt supports its use in modeling of species distribution. Potential applications are discussed for multi-species and multi-scenario analysis, as well as projection to new regions.}
}
@article{DUAN2024102637,
title = {SIAlex: Species identification and monitoring based on bird sound features},
journal = {Ecological Informatics},
volume = {81},
pages = {102637},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102637},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001791},
author = {Lin Duan and Lidong Yang and Yong Guo},
keywords = {Lightweight, Cascading activation function, Bird sound recognition, Structural re-parameterization, Nonlinear performance},
abstract = {The combination of deep learning and bird sound recognition is widely employed in bird species conservation monitoring. A complex network structure is not conducive for deploying bird sound recognition devices, resulting in problems such as long inference time and low efficiency. Using AlexNet as the backbone model, we explore the potential of shallow and straightforward models without complex connection techniques or attention mechanisms, named SIAlex, to recognise and classify 20 bird sound datasets, which are simultaneously validated on a 10 class UrbanSound8k dataset. Using the structural re-parameterization method, the number of model layers is reduced, computational efficiency is improved, and the inference time is significantly reduced, achieving a decoupling of training and inference time in the structure. To increase the nonlinearity of the model, a cascaded approach is utilised to increase the number of activation functions, thereby significantly improving the generalisation performance of the model. Simultaneously, in the classifier section, convolutional layer replaces the original fully connected layer, thereby reducing the inference time and increasing the feature extraction ability of the model, improving accuracy, and effectively recognising bird speech. The experimental data show that the SIAlex network on the Birdsdata dataset improves the accuracy to 93.66%, and the inference time for a piece of data is only 2.466 ms. The accuracy of the UrbanSound8k dataset reaches 96.04%, and the inference time for a piece of data is 3.031 ms. A large number of experimental comparisons have shown that the method proposed in this paper achieves good results in reducing the inference time of the model, bringing breakthroughs in the application of shallow, simple models.}
}
@article{MENG2024102677,
title = {Association between multilevel landscape characteristics and rural sustainability: A case study of the water-net region in the Yangtze River Delta, China},
journal = {Ecological Informatics},
volume = {82},
pages = {102677},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102677},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400219X},
author = {Chengyu Meng and Yimei Chen and Jiexin Yang and Xinyi Su and Wei Guo and Kaili Zhang},
keywords = {Typo-morphology, Deep learning, Spatial heterogeneity, Automatic classification, Regression analysis},
abstract = {In the Yangtze River Delta in China, known for its intricate water network, achieving harmonious development between humans and nature in rural areas is imperative. However, the identification of the water-net landscape characteristics and the relationship between rural sustainability and these landscape characteristics remain unclear. The aim of this study was to bridge this gap by proposing a novel framework for investigating the relationship between landscape characteristics and rural sustainability from a typo-morphological perspective. Specifically, through regression analysis, the influence of multilevel spatial characteristics of rural landscape on sustainability was selected as the research focus. First, multilevel metrics were introduced to delineate the rural landscape characteristics, including single and multiple landscape elements and landscape types, using deep learning methods to achieve automatic classification. Subsequently, by employing an improved entropy method, we comprehensively quantified rural sustainability indicators from the economic, social, and ecological dimensions. Finally, the ordinary least squares (OLS) model and two spatial variation coefficient models, namely, geographically weighted regression (GWR) and multiscale geographically weighted regression (MGWR), were used to quantitatively analyze the relationship between the landscape characteristics and rural sustainability. Significant regression model performances were obtained with adjusted R2 values of 0.33, 0.35, and 0.4 at each landscape characteristic level. The adjusted R2 values for the GWR and MGWR, which incorporated all of the landscape characteristics metrics, were 0.84 and 0.88, respectively. The results demonstrate that rural sustainability highly depends on the proposed multilevel characteristics and exhibits spatial heterogeneity. The findings of this study improve our understanding of the typo-morphological characteristics of the landscape and provide important planning and decision-making references for sustainable development in rural areas.}
}
@article{GYAWALI2024102706,
title = {From simple linear regression to machine learning methods: Canopy cover modelling of a young forest using planet data},
journal = {Ecological Informatics},
volume = {82},
pages = {102706},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102706},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002486},
author = {Arun Gyawali and Hari Adhikari and Mika Aalto and Tapio Ranta},
keywords = {Young boreal forest, Forest canopy cover, Light detection and ranging, PlanetScope, Vegetation index, Machine learning},
abstract = {Accurate canopy cover estimation is essential for mature and early-stage young forests, as it guides forest management and silvicultural activities necessary for their growth and regeneration. However, obtaining precise measurements of canopy cover in the field is time-consuming and challenging, especially at the regional and landscape levels. Remote sensing techniques offer a promising alternative to traditional field-based measurements for estimating forest canopy cover. In this study, our objective is to estimate forest canopy cover using vegetation indices derived from the multispectral bands of PlanetScope (Planet Lab, Inc., San Francisco, CA, USA). To the best of our knowledge, this is the first study to utilise PlanetScope imagery data for estimating canopy cover in young boreal forests. Based on the analysis of four bands (green, blue, red, and near-infrared) from PlanetScope imagery, 43 vegetation indices, including four spectral bands and 13 salinity indices, were computed to select predictors in canopy cover modelling. Six regression models were employed to model canopy cover: linear, elastic net, support vector machine, random forest, extreme gradient boosting, and light gradient boosting machine. All the models demonstrated good performance for both the training dataset (R2 = 0.58–0.69) and the testing dataset (R2 = 0.59–0.64, RMSE = 0.16–0.18, rRMSE = 22%–23%, and MAE = 0.12–0.14). Based on the fit statistics in the training and testing datasets and the paired t-test, our study identified the light gradient boosting machine as the most suitable model for predicting canopy cover in young boreal forests. For the light gradient boosting machine, the R2 value was 0.69 (training), and for testing data, the R2 = 0.64, RMSE = 0.16, rRMSE = 22%, and MAE = 0.12. Therefore, we recommend that future researchers utilise Planet multispectral data and the light gradient boosting machine regression to estimate forest canopy cover at a higher spatial resolution. However, exploring additional machine learning algorithms and explicitly boosting methods when computing forest canopy cover using satellite remote sensing is strongly advised.}
}
@article{MCEWEN2024102734,
title = {Active few-shot learning for rare bioacoustic feature annotation},
journal = {Ecological Informatics},
volume = {82},
pages = {102734},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102734},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002760},
author = {Ben McEwen and Kaspar Soltero and Stefanie Gutschmidt and Andrew Bainbridge-Smith and James Atlas and Richard Green},
keywords = {Active learning, Audio classification, Bioacoustics, Few-shot learning, Machine learning},
abstract = {The collection and annotation of bioacoustic data present several challenges to researchers. Bioacoustic monitoring of rare (sparse) or cryptic species generally encounter two main issues. The cost of collecting and processing field data and a lack of labelled datasets for the target species. The detection of invasive species incursions and probability of absence testing is especially challenging due to these species having population densities at or close to zero. We present a methodology specifically designed to aid in the analysis of rare acoustic events within long-term field recordings. This approach combines a wavelet-based segmentation method that automatically extracts transient features from within-field recordings. A few-shot active learning recommender system in a human-in-the-loop process prioritises the annotation of low-certainty samples. This process combines the accuracy of human classification and the speed of computational tools to greatly reduce the presence of non-target features in field recordings. We evaluate this approach using an invasive species identification case study. This methodology achieves a test accuracy of 98.4% as well as 81.2% test accuracy using 2-shot, 2-way prototypical learning without fine-tuning, demonstrating high performance at varying data availability contexts. Active learning using low-certainty samples achieves >90% test accuracy using only 20 training samples compared to 80 samples without active learning. This approach allows users to train custom audio classification models for any application with rare features. The model can be easily exported for use in the field making real-time bioacoustic monitoring of less-vocal species a possibility. All code and data are available at https://github.com/Listening-Lab/Annotator.}
}
@article{PHAM2024102392,
title = {Classifying forest cover and mapping forest fire susceptibility in Dak Nong province, Vietnam utilizing remote sensing and machine learning},
journal = {Ecological Informatics},
volume = {79},
pages = {102392},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102392},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004211},
author = {Van The Pham and Tuyet Anh Thi Do and Hau Duc Tran and Anh Ngoc Thi Do},
keywords = {XGBoost, Forest fire, ABC-ANFIS, Unmanned aerial vehicle, Bamboo and dipterocarp forests},
abstract = {Forest fires can cause significant harm to the biodiversity, air quality, economy, and industries that depend on forests, which is particularly critical given the current climate change scenario. Therefore, it is crucial to predict potential fire risks, especially in Dak Nong, a province located in the highland region of Vietnam, where forest farming is prevalent. In this study, the utilization of remote sensing data from unmanned aerial vehicles (UAV) revealed a decline in forest areas while agricultural rubber and industrial crops witnessed an increase. Furthermore, the integration of SPOT satellite images with UAV and the eXtreme gradient boosting (XGBoost) classification algorithm proved highly efficient in mapping forest types in this province (OA = 81.446%, and Kappa = 0.803). To assess forest fire susceptibility in this study, a hybrid model known as Artificial bee colony-Adaptive neuro fuzzy inference system (ABC-ANFIS) was employed, which indicated that the majority of forests in the area face high to very high of fires, particularly in bamboo and dipterocarp forest areas. The present model is proposed to suggest better prevention and suppression strategies. These facts can help managers stop fires or deal with this disturbance more effectively that may occur in the future. Policymakers and researchers in different areas, such as the limestone forest in the north or the Dipterocarp forests in Vietnam, may consider replicating this study to evaluate specific wildfire risks and develop appropriate fire prevention strategies tailored to their local circumstances.}
}
@article{ZHANG2024102597,
title = {Tracking changes in chlorophyll-a concentration and turbidity in Nansi Lake using Sentinel-2 imagery: A novel machine learning approach},
journal = {Ecological Informatics},
volume = {81},
pages = {102597},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102597},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001390},
author = {Jiawei Zhang and Fei Meng and Pingjie Fu and Tingting Jing and Jie Xu and Xinyue Yang},
keywords = {Sentinel-2, Lake, Machine learning, Model fusion, Chlorophyll-a, Turbidity},
abstract = {This study represents the first application of Sentinel-2 remote sensing imagery and model fusion techniques to assess the chlorophyll-a (Chla) concentration and turbidity in Nansi Lake, Shandong Province, China, from 2016 to 2022. First, we innovatively employed the stacking method to fuse eight fundamentally different Machine Learning (ML) models, each utilising 20 and 17 feature bands, resulting in the development of a robust algorithm for estimating the Chla concentration and turbidity in Nansi Lake. The results demonstrate that the Stacking Model has achieved outstanding theoretical generalisation capability. Second, the sensitivity of the model to extreme value data in the sample was quantified, and we found that compared with extreme gradient boosting (XGBoost), the optimal performance of the Stacking Model improved by 12%, to some extent, it solved the problem of high-value underestimation and low-value overestimation. The SHapley Additive exPlanations (SHAP) results revealed that features such as Three Bands, Enhanced Three, Rrs492/Rrs560, Rrs705/Rrs665 play a crucial role in estimating Chla concentration. For the turbidity estimation, the Normalized Difference Turbidity Index (NDTI), Rrs705+Rrs560, Rrs865-Rrs740 made significant contributions. Finally, we utilised the Stacking Model to create spatiotemporal maps of the Chla concentration and turbidity in Nansi Lake from 2016 to 2022. We analysed the causes of the water quality changes and explored the driving factors. Compared with previous studies, this paper provides a new idea for the monitoring of lake water quality parameters by using the high resolution of Sentinel-2 image and the high precision of model fusion technology, these results can provide a reference for similar water area research and decision-making support for environment-related departments.}
}
@article{WANG2024102666,
title = {Evaluation of five atmospheric correction algorithms for multispectral remote sensing data over plateau lake},
journal = {Ecological Informatics},
volume = {82},
pages = {102666},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102666},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002085},
author = {Dong Wang and Bo-Hui Tang and Zhao-Liang Li},
keywords = {Atmospheric correction (AC), Remote sensing reflectance, Satellite, Plateau lake (PL)},
abstract = {The precise correction of atmospheric effects is essential for the accurate analysis of inland water color from remote sensing (RS) data. This study systematically evaluates the efficacy of five atmospheric correction (AC) algorithms—Acolite, C2RCC, FLAASH, iCOR, and L2gen—when applied to Sentinel-2 Multi Spectral Instrument (MSI) and Sentinel-3 Ocean and Land Color Instrument (OLCI) imagery. The performance of these algorithms is scrutinized across different spectral bands and spatial resolutions, with a focus on their suitability for water body AC. Our validation approach primarily focuses on the spatial arrangement of sampling points and the timeliness of the collected data. The results reveal that Acolite demonstrates superior performance in the red band of MSI data, whereas C2RCC exhibits inconsistencies in the blue and green bands. FLAASH stands out in its handling of OLCI data, although iCOR exhibits sensitivity to resolution, resulting in over-correction in lower resolution scenarios. L2gen is noted for its consistent provision of concentrated data amplitude across the board. The findings, graphically represented through a radar chart, are pivotal for guiding the selection of optimal AC algorithms for the visible spectrum, thereby enhancing the accuracy of RS applications in environmental monitoring and research. Additionally, our study highlights the impact of sampling time differences on the AC spectrum, with variations of approximately 3% observed for a single sensor. This underscores the critical need for temporal consistency in field measurements.}
}
@article{FU2023102250,
title = {Classification of birdsong spectrograms based on DR-ACGAN and dynamic convolution},
journal = {Ecological Informatics},
volume = {77},
pages = {102250},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102250},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002790},
author = {Yixing Fu and Chunjiang Yu and Yan Zhang and Danjv Lv and Yue Yin and Jing Lu and Dan Lv},
keywords = {Auxiliary classifier GAN, Data augmentation, Dynamic convolution, Attention mechanism, Birdsong recognition},
abstract = {Birdsongs are highly valuable for bird studies as they provide insights into various aspects such as species distribution, population structures, and habitat. Recognizing birdsongs plays a crucial role in bird conservation efforts. However, manually collecting a large number of birdsongs from the natural environment is expensive and time-consuming. Moreover, using limited birdsong data often results in low classification accuracy of the models. To better identification of birdsongs, we utilize wavelet transform(WT) to convert them into spectrograms, which contain abundant energy and frequency information. Effectively extracting these features is vital to improve the classification accuracy of the model. To address this problem, we proposed an improved ACGAN model based on residual structure and attention mechanism named DR-ACGAN, which achieved stable training of the model and high-quality generated birdsong spectrograms. The dynamic convolution kernel is then fused with MobileNetV2, ResNet18, and VGG16 models and trained on different datasets, which used different ways of mixing the generated and original spectrograms. The experimental results show that the classification accuracy after data augmentation improves by 6.66%, 4.35%, and 2.29% compared to the original dataset in the three base classifiers. After adding dynamic convolutional kernel structure, the accuracy is further improved by 1.68%, 0.67%, and 0.38% on average which the VGG16 model achieves the highest accuracy of 97.60%.}
}
@article{TURAB2024102639,
title = {Computational modeling of animal behavior in T-mazes: Insights from machine learning},
journal = {Ecological Informatics},
volume = {81},
pages = {102639},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102639},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400181X},
author = {Ali Turab and Wutiphol Sintunavarat and Farhan Ullah and Shujaat Ali Zaidi and Andrés Montoyo and Josué-Antonio Nescolarde-Selva},
keywords = {Animal behavior, Decision-making, T-mazes, Computational modeling, Solution, Machine learning methods},
abstract = {This study investigates the intricacies of animal decision-making in T-maze environments through a synergistic approach combining computational modeling and machine learning techniques. Focusing on the binary decision-making process in T-mazes, we examine how animals navigate choices between two paths. Our research employs a mathematical model tailored to the decision-making behavior of fish, offering analytical insights into their complex behavioral patterns. To complement this, we apply advanced machine learning algorithms, specifically Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and a hybrid approach involving Principal Component Analysis (PCA) for dimensionality reduction followed by SVM for classification to analyze behavioral data from zebrafish and rats. The above techniques result in high predictive accuracies, approximately 98.07% for zebrafish and 98.15% for rats, underscoring the efficacy of computational methods in decoding animal behavior in controlled experiments. This study not only deepens our understanding of animal cognitive processes but also showcases the pivotal role of computational modeling and machine learning in elucidating the dynamics of behavioral science.}
}
@article{CANOVI2024102733,
title = {Trajectory-based fish event classification through pre-training with diffusion models},
journal = {Ecological Informatics},
volume = {82},
pages = {102733},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102733},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002759},
author = {Noemi Canovi and Benjamin A. Ellis and Tonje K. Sørdalen and Vaneeda Allken and Kim T. Halvorsen and Ketil Malde and Cigdem Beyan},
keywords = {Fish behavior, Underwater videos, Event recognition, Trajectory, Generative models, Autoencoder, Diffusion model, Corkwing wrasse},
abstract = {This study contributes to advancing the field of automatic fish event recognition in natural underwater videos, addressing the current gap in studying fish interaction and competition, including predator-prey relationships and mating behaviors. We used the corkwing wrasse (Symphodus melops) as a model, a marine species of commercial importance that reproduces in sea-weed nests built and cared for by a single male. These nests attract a wide range of visitors and are the focal point for behavior such as spawning, chasing, and maintenance. We propose a deep learning methodology to analyze the movement trajectories of the nesting male and classify the associated events observed in their natural habitat. Our approach leverages unsupervised pre-training based on diffusion models, leading to improved feature learning. Additionally, we introduce a dataset comprising 16,937 trajectories across 12 event classes, making it the largest in terms of event class diversity. Our results demonstrate the superior performance of our method compared to several deep architectures. The code for the proposed method and the trajectories can be found at https://github.com/NoeCanovi/Fish_Behaviors_Generative_Models.}
}
@article{GONCALVES2024102628,
title = {Revealing forest structural "fingerprints": An integration of LiDAR and deep learning uncovers topographical influences on Central Amazon forests},
journal = {Ecological Informatics},
volume = {81},
pages = {102628},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102628},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001705},
author = {Nathan Borges Gonçalves and Diogo Martins Rosa and Dalton Freitas {do Valle} and Marielle N. Smith and Ricardo Dalagnol and Danilo Roberti Alves {de Almeida} and Bruce W. Nelson and Scott C. Stark},
keywords = {Structural "fingerprints", LiDAR, Deep learning, Amazon Forest, Terrain variation},
abstract = {Amazon forests are characterized by rich structural diversity. However, the influence of factors such as topography, soil attributes, and external disturbances on structural variability is not always well characterized, and traditional structural metrics may be inadequate to capture this type of complexity. While LiDAR offers expanded structural insights, traditional parameters used in LiDAR analysis, such as mean or maximum canopy height, are not always well directly linked to environmental variables like topography. Emerging approaches merge LiDAR with machine learning to uncover deeper structural complexities. However, work to date may fail to fully utilize the potential of fine-scale LiDAR information. Here we introduce a novel approach, leveraging 2D point cloud images derived from a profiling canopy LiDAR (PCL). The technique targets intricate details within LiDAR point clouds by using deep learning algorithms. With a dataset from the Central Amazon comprising 18 multitemporal transects of 450 m in length, our objective was to detect structural "fingerprints" of varied topographical types along a hillslope, comprising: Riparian, White-sand, and Plateau, and to detect any gradient of structural shifts based on terrain variations here represented by the height above the nearest drainage (HAND). The dataset was trained and tested using a leave-one-group-out approach (LOGO) in which, for each iteration, a complete 450 m multitemporal transect was excluded from training and tested after each iteration. The fast.ai platform and a ResNet-34 architecture, coupled with transfer learning, were used to perform a classification to distinguish between three topographical types. Furthermore, a hybrid model combining a Convolutional Autoencoder, and Partial Least Square (PLS) regression was designed to detect forest structural gradient correlations with HAND variation. Cross-validation achieved a promising high weighted F1 score of 0.83 to classify forests based on the topographical types. Additionally, a combined Convolutional Autoencoder and PLS regression revealed a strong correlation (R2 = 0.76) between actual and predicted HAND. Innovatively combining deep learning with ground-based PCL LiDAR, our study revealed unique Amazon Forest structures connected to topographic variation. Our findings underscore the transformative potential of such integrative approaches for investigating forest dynamics and promise a powerful new tool for understanding climate-related forest structure change.}
}
@article{ZHOU2024102680,
title = {Real-time underwater object detection technology for complex underwater environments based on deep learning},
journal = {Ecological Informatics},
volume = {82},
pages = {102680},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102680},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400222X},
author = {Hui Zhou and Meiwei Kong and Hexiang Yuan and Yanyan Pan and Xinru Wang and Rong Chen and Weiheng Lu and Ruizhi Wang and Qunhui Yang},
keywords = {Underwater object detection, You only look once, Cross stage multi-branch, Large kernel spatial pyramid},
abstract = {Underwater object detection technology is crucial in many marine-related fields, including marine environmental monitoring, marine resource development, and marine ecological protection. However, this technology faces great challenges due to the poor quality of underwater optical images and the varying sizes of underwater objects. Therefore, we proposed an underwater optical detection network (UODN) based on the you only look once version 8 (YOLOv8) framework, which addresses these issues through the cross stage multi-branch (CSMB) module and large kernel spatial pyramid (LKSP) module. The aim of the CSMB module is to extract more features from underwater optical images to address the issue of poor image quality, while the LKSP module is designed to enhance the ability of the network to detect underwater objects of various scales. Furthermore, CSMBDarknet built by CSMB and LKSP can be used as the backbone of other underwater object detection algorithms for underwater feature extraction. Extensive experimental results on the underwater robot professional contest 2020 dataset revealed that the average precision (AP) of UODN increased by 1.0%, the AP50 of UODN increased by 1.1%, and the AP75 of UODN increased by 2.1% compared with those of the original YOLOv8s. Furthermore, UODN outperforms 12 state-of-the-art models on multiple underwater optical datasets, paving the way for future real-time and high-precision underwater object detection.}
}
@article{MONTAGHI2024102433,
title = {An open-source cloud-based procedure for MODIS remote sensing products: The nasawebservicepython package},
journal = {Ecological Informatics},
volume = {79},
pages = {102433},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102433},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004624},
author = {Alessandro Montaghi and Simone Bregaglio and Sofia Bajocco},
keywords = {Smart farming, Open-source software, Python, MODIS, Cloud-application},
abstract = {Living in the era of “big data” demands an increase in the application and development of solutions for data ingestion in agroecological research, both in the private and public sectors. Among available data sources, satellite imagery is a viable solution to acquire large amounts of data at cheaper costs. Although cloud-based commercially distributed services are flourishing, open-source software able to assist practitioners and researchers in downloading and pre-processing satellite imagery is strongly demanded by the remote sensing community. This is especially true when looking at applications developed in Python, a programming language that quickly gained popularity in agroecological science. In this letter, we introduce nasawebservice version 1.0.0, a Python Package designed to automatically collect remotely sensed data from the NASA MODIS/VIIRS Land Products web service. The nasawebservice package contains a set of classes and methods to facilitate download operations for practitioners and researchers and to implement user-friendly data ingestion pipelines in local and cloud environments. The main advantage of nasawebservice is the reduction of pre-processing operations to use satellite images due to getting the data in JSON format, with consequent saving of computational time for large data download and analytic operational pipelines.}
}
@article{COMESANACEBRAL2024102612,
title = {Wildfire response of forest species from multispectral LiDAR data. A deep learning approach with synthetic data},
journal = {Ecological Informatics},
volume = {81},
pages = {102612},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102612},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001547},
author = {Lino Comesaña-Cebral and Joaquín Martínez-Sánchez and Gabriel Suárez-Fernández and Pedro Arias},
keywords = {Multispectral LiDAR, Deep learning, Fire response, Synthetic data, Wildfire},
abstract = {Forests play a crucial role as the lungs and life-support system of our planet, harbouring 80% of the Earth's biodiversity. However, we are witnessing an average loss of 480 ha of forest every hour because of destructive wildfires spreading across the globe. To effectively mitigate the threat of wildfires, it is crucial to devise precise and dependable approaches for forecasting fire dynamics and formulating efficient fire management strategies, such as the utilisation of fuel models. The objective of this study was to enhance forest fuel classification that considers only structural information, such as the Prometheus model, by integrating data on the fire responses of various tree species and other vegetation elements, such as ground litter and shrubs. This distinction can be achieved using multispectral (MS) Light Detection and Ranging (LiDAR) data in mixed forests. The methodology involves a novel approach in semantic classifications of forests by generating synthetic data with semantic labels regarding fire responses and reflectance information at different spectral bands, as a real MS scanner device would detect. Forests, which are highly intricate environments, present challenges in accurately classifying point clouds. To address this complexity, a deep learning (DL) model for semantic classification was trained on synthetic point clouds in different formats to achieve the best performance when leveraging MS data. Forest plots in the study region were scanned using different Terrestrial Laser Scanning sensors at wavelengths of 905 and 1550 nm. Subsequently, an interpolation process was applied to generate the MS point clouds of each plot, and the trained DL model was applied to classify them. These classifications surpassed the average thresholds of 90% and 75% for accuracy and intersection over union, respectively, resulting in a more precise categorisation of fuel models based on the distinct responses of forest elements to fire. The results of this study reveal the potential of MS LiDAR data and DL classification models for improving fuel model retrieval in forest ecosystems and enhancing wildfire management efforts.}
}
@article{LONG2024102681,
title = {From meteorological to agricultural drought: Propagation time and influencing factors over diverse underlying surfaces based on CNN-LSTM model},
journal = {Ecological Informatics},
volume = {82},
pages = {102681},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102681},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002231},
author = {Junchen Long and Changchun Xu and Yazhen Wang and Jing Zhang},
keywords = {Drought propagation, Seasonal variation, Hybrid deep learning model, Influencing factors, Land Use and Land Cover},
abstract = {As global warming intensifies and extreme weather events become more frequent, the severity of drought conditions in China's Xinjiang region has escalated. This exacerbates socio-economic pressures in the area and presents increasingly formidable challenges for the future. In response to these challenges, researching drought phenomena in Xinjiang is imperative. This study employs Bayesian methods and copula functions to estimate drought propagation time. It utilizes a hybrid deep learning model (CNN-LSTM) to analyze the process of drought propagation and its influencing factors across four land cover types: crops, forest land, grassland, and unused land. The findings indicate that Cropland experiences the longest average time of drought propagation (5.27 months), while forests have the shortest duration (4.2 months). Unused land and grassland exhibit similar average durations of propagation (4.8 months). On an annual scale, drought propagation time for each land type manifests in two phases: from January to May and from June to December. The former phase shows propagation time ranging from 6 to 9 months, while the latter ranges from 1 to 5 months; both demonstrate an increasing trend over time. Seasonally, all Land Cover Types exhibit a pattern of shorter propagation times in summer and autumn compared with winter and spring. Moreover, a longer time of drought propagation correlates with a greater disparity between meteorological and resultant agricultural drought severity. In analyzing the influence of factors on drought propagation, soil moisture content and El Niño-Southern Oscillation(ENSO) were found to significantly impact all Land Cover Types, progressively strengthening their influence over the years.}
}
@article{HOU2024102429,
title = {Exploring the optimal model for assessing SOC and TN in Zanthoxylum bungeanum forest on the Loess Plateau using VNIR spectroscopy},
journal = {Ecological Informatics},
volume = {79},
pages = {102429},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102429},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004582},
author = {Mengjia Hou and Zemin Ai and Xinghua Li and Xiaohu Dang and Yuyan Yao and Yi Deng and Tao Wang and Ting Li and Lie Xiao},
keywords = {Partial least squares regression, Support vector machine regression, Spectral pre-processing, Calibration models, Validation models},
abstract = {Zanthoxylum bungeanum forest is an important economic forest on the Loess Plateau. The rapid assessment of its soil organic carbon (SOC) and total nitrogen (TN) concentrations is critical for the evaluation of soil quality. Soil samples of different forest ages and soil depths were collected for laboratory analyses and spectral measurements, and the visible and near-infrared reflectance (VNIR) spectral data were processed by mathematical transformations, such as first-order derivative (FD) and second-order derivative, multiple scattering correction, and logarithm of the reciprocal. The importance bands of SOC and TN were screened on the basis of competitive adaptive reweighted sampling. In addition, partial least squares regression and support vector machine regression models were constructed, and the applicability of SOC and TN to the models were compared. Results showed that forest age and soil depth remarkably affect SOC and TN concentrations. Among the calibration and validation models, the combination of the SVMR model with Savitzky–Golay smoothing and FD estimated SOC and TN with the highest accuracy, and the validation accuracy of the surface SOC and TN was higher than that of the bottom depths. Meanwhile, the importance bands involved in the modeling were mainly distributed in 400–600 nm and 1000–2400 nm. The combination of the FD transformation and the SVMR model is suitable for determining SOC and TN concentrations in Z. bungeanum forests, and the model has great potential for the quantitative evaluation of soil quality in the Loess Plateau.}
}
@article{YANG2024102705,
title = {Adaptive image processing embedding to make the ecological tasks of deep learning more robust on camera traps images},
journal = {Ecological Informatics},
volume = {82},
pages = {102705},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102705},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002474},
author = {Zihe Yang and Ye Tian and Junguo Zhang},
keywords = {Adaptive image processing, Camera traps, Deep learning, Ecological tasks},
abstract = {Camera traps serve as a valuable tool for wildlife monitoring, generating a vast collection of images for ecologists to conduct ecological investigations, such as species identification and population estimation. However, the sheer volume of images poses a challenge, and the integration of deep learning into automated ecological investigation tasks remains complex, particularly when dealing with low-quality images in long-term monitoring programs. Existing approaches often struggle to strike a balance between image enhancement and deep learning for ecological tasks, thereby overlooking crucial information contained within low-quality images. This research introduces a pioneering adaptive image processing module (AIP) that seamlessly incorporates image processing into camera trap ecological tasks, elevating the performance of wildlife monitoring activities. Specifically, a differentiable image processing (DIP) module is presented to enhance low-quality images, with its parameters predicted by a Non-local based parameter predictor (NLPP). Additionally, an end-to-end approach based on hybrid data containing both original and synthetic data is proposed, encompassing adaptive image processing methods and downstream tasks for camera traps, adaptable to various scenarios. This approach effectively reduces the manual labor and time required for professional image processing. When applied to real-world camera trap images and synthetic image datasets, our method achieves an accuracy of 92.26% and 86.65% in classifying wildlife, respectively, demonstrating its robustness. By outperforming alternative methods under harsh conditions, the application of the adaptive image processing module instills greater confidence in deep learning applications within complex environments.}
}
@article{ARAUJO2024102388,
title = {Membership inference attack for beluga whales discrimination},
journal = {Ecological Informatics},
volume = {79},
pages = {102388},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102388},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300417X},
author = {Voncarlos M. Araújo and Sébastien Gambs and Robert Michaud and Hadrien Lautraite and Léo Schneider and Clément Chion},
keywords = {Membership inference attack, Animal ecology, -identification, Discrimination, Open-set problem},
abstract = {To efficiently monitor the growth and evolution of a particular wildlife population, one of the fundamental challenges to address in animal ecology is the re-identification of individuals that have been previously encountered but also the discrimination between known and unknown individuals (the so-called “open-set problem”), which is the first step to realize before re-identification. In particular, in this work, we are interested in the discrimination within digital photos of beluga whales, which are known to be among the most challenging marine species to discriminate due to their lack of distinctive features. To tackle this problem, we propose a novel approach based on the use of Membership Inference Attacks (MIAs), which are normally used to assess the privacy risks associated with releasing a particular machine learning model. More precisely, we demonstrate that the problem of discriminating between known and unknown individuals can be solved efficiently using state-of-the-art approaches for MIAs. Extensive experiments on three benchmark datasets related to whales, two different neural network architectures, and three MIA clearly demonstrate the performance of the approach. In addition, we have also designed a novel MIA strategy that we coined as ensemble MIA, which combines the outputs of different MIAs to increase the discrimination accuracy while diminishing the false positive rate. Overall, one of the main objectives of our work is to demonstrate that the study of privacy attacks can also be harnessed positively, assisting in the resolution of practical issues encountered in the field of animal ecology.}
}
@article{WEI2024102445,
title = {YOLO_MRC: A fast and lightweight model for real-time detection and individual counting of Tephritidae pests},
journal = {Ecological Informatics},
volume = {79},
pages = {102445},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102445},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004740},
author = {Min Wei and Wei Zhan},
keywords = {Real-time detection, Individual counting, YOLOv8, Lightweight, Attention mechanism, },
abstract = {Tephritidae pests severely affect the quality and safety of various melons, fruits and vegetable crops. However, many agricultural managers lack an adequate understanding of the level of pest occurrence, resulting in the misuse of pesticides, which ultimately leads to environmental pollution and economic loss. Therefore, real-time detection and counting of Tephritidae pests are important for timely pest spotting and control. This work helps quickly determine the distribution and abundance of pests in the current environment, thus providing data on pest conditions for agricultural management to optimize pesticide use. Nevertheless, the fast speed, high accuracy, and lightweight performance of real-time detection and counting are difficult to balance. To address this problem, based on the YOLOv8n model, this paper takes Bactrocera cucurbitae pests as the detection target and proposes a fast and lightweight real-time detection and individual counting model for Tephritidae pests, named YOLO_MRC. This paper introduces three key improvements: (1) Constructing a new module called Multicat into the neck network increases the focus on the detection target by incorporating an attention mechanism; (2) Reducing the original three detection heads to two and then adjusting their sizes to decrease the number of parameters in the network model; (3) Devising a novel module, C2flite, to enhance the deep feature extraction capability of the backbone network. According to the above points, this paper conducts ablation experiments to compare the performances of different models. Experiments showed that the Multicat module significantly offsets the large increase in GFLOPs and processing time caused by reducing the detection head and can further reduce the number of parameters and improve the accuracy when combined with the C2flite module. On our Bactrocera cucurbitae pest dataset, the mAP@0.5 of the YOLO_MRC model reached 99.3%. Simultaneously, as the number of parameters decreases by 63.68%, GFLOPs is reduced by 19.75%, and the processing time is shortened by 5%. To ensure the validity of the model, YOLO_MRC is compared with four excellent detection models by using manual counting results as the benchmark. YOLO_MRC achieves an average pest counting accuracy of 94%, demonstrating superior performance in terms of model size and processing time. To further explore the performance of YOLO_MRC in multiclass insect detection tasks, we choose the public dataset Pest_24_640 for comparison with four state-of-the-art models. YOLO_MRC achieves a 3.6 ms processing time and 70.4% accuracy with only a 2.4 MB model size, which demonstrates the potential of YOLO_MRC in multiclass pest detection.}
}
@article{PELE2024102463,
title = {A neural network encoder-decoder for time series prediction: Application on 137Cs particulate concentrations in nuclearized rivers},
journal = {Ecological Informatics},
volume = {80},
pages = {102463},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102463},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000050},
author = {Kathleen Pelé and Valérie Nicoulaud-Gouin and Hugo Lepage},
keywords = {Deep learning, Suspended particulate matter, Radioactivity, Micropollutant, Data-driven model},
abstract = {Monitoring the impact of human activities on the environment is a major challenge as many pollutants can be found in the different ecosystems. This is the case of the caesium-137 that has been present in the environment for many decades as a result of atmospheric tests, accidents such as Chernobyl and release from nuclear industries. With the recent advance in data-driven models, this study evaluate the relevance of a deep learning tool for reconstructing caesium-137 chronics particulate concentration in rivers. An encoder-decoder neural network, “Hierarchical Attention-Based Recurrent Highway Networks”(HRHN), is proposed notably for its ability to extract the most relevant temporal and spatial information from the databases. Three monitoring stations were studied, one on the Rhône River and two on the Loire River, all of them downstream nuclear industries in these catchments affected by the global fallout and the accident of Chernobyl. The objective is to predict the future concentration from a set of variables providing past information on water discharge, washout flux and industrial radioactive releases. Once optimised, the model generates first results in agreement with the real concentration curves by correctly following the main trends, with a NSE of 0.89, 0.53 and 0.35 respectively for the Rhone station and the two stations on the Loire. The main reason of inaccuracies is due to the quantity of data available. The originality of this model is its capacity to make predictions on different catchment areas. In fact the training was conducted on the Rhône station as the range of the concentration was higher (from 265.4 to 2700.0 Bq/kg) and the testing on the two Loire station. Another encoder-decoder model DA-RNN (Dual-Stage Attention-Based Recurrent Neural Network) was also evaluate in order to compare the performance of an alternative architecture, without convolution layer. The conclusion is that HRHN remains more powerful in the predictions on the 3 systems. With these first interesting results for HRHN, further investigations should be taken into account for other pollutants than caesium-137 to better understand the robustness of the model.}
}
@article{LI2023102215,
title = {Tree trunk detection in urban scenes using a multiscale attention-based deep learning method},
journal = {Ecological Informatics},
volume = {77},
pages = {102215},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102215},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002443},
author = {Rao Li and GuoDong Sun and Sheng Wang and TianZhuzi Tan and Fu Xu},
keywords = {Salient object detection, Tree trunk detection, Deep learning, Attention mechanism, Dataset construction},
abstract = {Precise identification of tree trunks contributes to the understanding of urban green dynamics. Previous attempts to develop tree trunk detection methods have faced limitations in respect of precision and generalization due to the use of hand-engineered features and the constraint of single-species detection. In this study, we construct a new tree trunk dataset considering the object’s strong diversity and propose a deep model to detect and segment the salient tree trunks or even branches in urban scenes. Comprehensive experiments are performed to evaluate our model. The presented method exhibits exceptional performance, evidenced by its outstanding scores across seven evaluation metrics, indicating its capability to segment tree trunks of different species, even if they exhibit significant variations in appearance. Specifically, our model demonstrates outstanding accuracy in detecting trunks with intricate furcations, as well as effectively identifying trunks that are partially occluded.}
}
@article{MASAGO2022101835,
title = {Estimating the first flowering and full blossom dates of Yoshino cherry (Cerasus × yedoensis ‘Somei-yoshino’) in Japan using machine learning algorithms},
journal = {Ecological Informatics},
volume = {71},
pages = {101835},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101835},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002850},
author = {Yoshifumi Masago and Maychee Lian},
keywords = {Phenology, Yoshino cherry, Machine learning, Gradient boosting decision tree, Random forest, Artificial neural network},
abstract = {Climate change alters the phenology of various plants. For example, increasing temperatures shift the first flowering and full blossom days of Yoshino cherry trees and affect cultural events related to cherry blossoms. We developed models to estimate the first flowering and full blossom dates of Yoshino cherry in Japan based on temperature and phenological data observed at 82 stations in Japan for 68 years (1953–2020). Three machine learning algorithms, namely, the random forest (RF), artificial neural network (ANN), and gradient boosting decision tree (GBDT) algorithms, were utilized, and the hyperparameters were optimized using Optuna. The GBDT models produced the best estimation accuracy, with an overall root mean square error (RMSE) = 1.53 and 1.48 days for the first flowering date and full blossom date, respectively. Furthermore, our analysis using Shapley Additive Explanations (SHAP) revealed that in the RF and GBDT models, the low temperature in winter and high temperature in spring would advance the estimated first flowering and full blossom dates.}
}
@article{XU2024102518,
title = {Mapping the potential distribution of Asian elephants: Implications for conservation and human–elephant conflict mitigation in South and Southeast Asia},
journal = {Ecological Informatics},
volume = {80},
pages = {102518},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102518},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000608},
author = {Haixia Xu and Luguang Jiang and Ye Liu},
keywords = {Asian elephant, Maximum entropy, Environmental features, Population characteristics},
abstract = {Asian elephants play a pivotal role in their ecosystem. Understanding the potential distribution area of this species is vital for effective conservation efforts and mitigation of human-elephant conflicts. In this study, we used the maximum entropy to simulate the potential distribution area of Asian elephants across South and Southeast Asia, leveraging Maximum Entropy (MaxEnt) and presence data sourced from the Global Biodiversity Information Facility (GBIF). The analysis revealed that the potential distribution area of Asian elephants spans 530,418 km2 (10.59% of the study area), with significant potential distribution areas observed in Indonesia (136,890 km2) and Malaysia (119,497 km2). Vegetation type emerged as the dominant environmental factor influencing model outcomes, encompassing aspects such as broadleaved evergreen tree coverage, broadleaved deciduous closed tree coverage and EVI. The potential distribution area of Asian elephants overlaps with regions inhabited by 55.25 million people, with 6.07 million people residing in highly suitable habitats. India and Malaysia have high potential for human-elephant conflict (HEC) due to the high number of people living in potential and highly suitable habitats for elephants. Bangladesh and Nepal, on the other hand, have fewer people living in these habitats suitable for elephants, but they face relatively high human population density in these areas.}
}
@article{AKINOSHO2022101609,
title = {A scalable deep learning system for monitoring and forecasting pollutant concentration levels on UK highways},
journal = {Ecological Informatics},
volume = {69},
pages = {101609},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101609},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122000589},
author = {Taofeek D. Akinosho and Lukumon O. Oyedele and Muhammad Bilal and Ari Y. Barrera-Animas and Abdul-Quayyum Gbadamosi and Oladimeji A. Olawale},
keywords = {Urban air pollution, Air quality prediction, Highway, Deep learning, Big data, Internet of things},
abstract = {The construction of intercity highways by the government has resulted in a progressive increase in vehicle emissions and pollution from noise, dust, and vibrations despite its recognition of the air pollution menace. Efforts that have targeted roadside pollution still do not accurately monitor deadly pollutants such as nitrogen oxides and particulate matter. Reports on regional highways across the country are based on a limited number of fixed monitoring stations that are sometimes located far from the highway. These periodic and coarse-grained measurements cause inefficient highway air quality reporting, leading to inaccurate air quality forecasts. This paper, therefore, proposes and validates a scalable deep learning framework for efficiently capturing fine-grained highway data and forecasting future concentration levels. Highways in four different UK regions - Newport, Lewisham, Southwark, and Chepstow were used as case studies to develop a REVIS system and validate the proposed framework. REVIS examined the framework's ability to capture granular pollution data, scale up its storage facility to rapid data growth and translate high-level user queries to structured query language (SQL) required for exploratory data analysis. Finally, the framework's suitability for predictive analytics was tested using fastai's library for tabular data, and automated hyperparameter tuning was implemented using bayesian optimisation. The results of our experiments demonstrate the suitability of the proposed framework in building end-to-end systems for extensive monitoring and forecasting of pollutant concentration levels on highways. The study serves as a background for future related research looking to improve the overall performance of roadside and highway air quality forecasting models.}
}
@article{FOTSOKAMGA2024102530,
title = {Expert knowledge-based modelling approach for mapping beekeeping suitability area},
journal = {Ecological Informatics},
volume = {80},
pages = {102530},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102530},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000724},
author = {Guy A. {Fotso Kamga} and Yacine Bouroubi and Mickaël Germain and A. Mengue Mbom and Madeleine Chagnon},
keywords = {Beekeeping activity, Ecosystem services, Suitability mapping, Fuzzy inference system, Geospatial data},
abstract = {It is becoming increasingly accepted that beekeeping is declining due to the damaging effect of global changes such as climate and land-use change that directly and indirectly impact Apis Melliferas. Despite numerous investigations, a comprehensive study that incorporates both global and local knowledge has yet to be conducted. For a long time, researchers have suggested that expert knowledge should be taken into account when creating decision support tools for managing activities related to natural resources, such as beekeeping. Unlike previous studies, this research seeks to tackle these questions while also introducing the concept of ecosystem service in modelling, offering a fresh perspective on sustainable land use. To achieve this goal, we combined several methods, including using literature knowledge, beekeeper knowledge, and multi-source geospatial data. These data are employed in a hierarchical fuzzy inference system in a unified way. The proposed approach was applied in the Québec region and the suggested technique appears to be both reliable and effective. The validation step revealed that the landscape variable, particularly the area used for agriculture or grassland, had the greatest impact on changes in hive weight throughout the season. In addition, we demonstrated that meteorological factors such as rainfall and relative humidity are strongly correlated to beekeeping. We showed that access to data and knowledge can be a critical factor in decision-making in the beekeeping industry, and thus we suggest that wild-bees conservationists, decision-makers, farmers, beekeepers, and other stakeholders adopt a collaborative approach.}
}
@article{PUSHPA2024102611,
title = {On the importance of integrating convolution features for Indian medicinal plant species classification using hierarchical machine learning approach},
journal = {Ecological Informatics},
volume = {81},
pages = {102611},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102611},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001535},
author = {B.R. Pushpa and N. Shobha Rani and M. Chandrajith and N. Manohar and Smitha Sunil Kumaran Nair},
keywords = {Medicinal plant classification, Fusion features, Convolution features, Smartphone images, Inter-class similarities},
abstract = {This work proposes a novel hierarchical classification framework designed to categorize hundred Indian medicinal plant species. The innovation lies in introducing a comprehensive feature representation by integrating convolutional features with geometric, texture, shape, and multispectral features for classification tasks. In this study, a two-level hierarchical plant classification model is proposed to address the challenges of inter-class similarity and intra-class variations. The first level classifies 100 medicinal plant species into 11 groups based on visual similarities among the plants. At level two, the specific plant species containing in each group are predicted using Random Forest classifier. The evaluation is performed at two levels to analyze the effectiveness of the proposed model. The performance analysis compares the effectiveness of individual feature types against the composite feature model. Performance is also evaluated based on specific groups that demonstrate high similarity between classes and intra-class variations among the plant species separately. Furthermore, the generality of the model is tested using two self-created datasets-RTL80 and RTP40, requiring more than 300 man-hours to collect. Experimental results demonstrate a promising accuracy of 94.54% on GSL100 leaf dataset and 75.46% on RTL80 and RTP40 real-time datasets reflecting the superiority of the proposed hierarchical model over state-of-the-art methods.}
}
@article{MORITAKE2024102462,
title = {Sub-alpine shrub classification using UAV images: Performance of human observers vs DL classifiers},
journal = {Ecological Informatics},
volume = {80},
pages = {102462},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102462},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000049},
author = {Koma Moritake and Mariano Cabezas and Tran Thi Cam Nhung and Maximo Larry {Lopez Caceres} and Yago Diez},
keywords = {Sub-alpine vegetation, Vegetation change monitoring, Deep learning, Observer study, ConvNeXt, Swin},
abstract = {In recent years, the automatic analysis of natural environment images acquired with unmanned aerial vehicles (UAV) has rapidly gained popularity. UAVs are specially important in mountainous forests where access is difficult and large areas need to be surveyed. In Zao mountains in northeastern Japan, regenerated fir saplings are competing with sub-alpine vegetation shrubs after a severe fir tree mortality caused by bark beetle infestation. A detailed survey of vegetation distribution is key to improve our understanding of species succession and the influence of climate change in that process. To that end, we evaluated the suitability of deep-learning-based automatic image classification of UAV images in order to map sub-alpine vegetation succession in large areas and the potential of fir regeneration. In order to assess the contribution of this technology in this research field, we first conducted an observer study to assess the difficulty for humans of the task of classifying vegetation from images. Afterwards, we compared the observers' accuracy to four state-of-the art deep learning networks for automatic image classification. The best observer accuracy of 55% demonstrates the limitations of species classification using only images. Furthermore, a detailed analysis of the sources of error showed that even though humans could differentiate between deciduous and evergreen species with an accuracy of 96%, identifying the correct species within each group proved much more challenging. In contrast, deep learning networks achieved accuracy values in the range of 70–80% for species classification, clearly demonstrating capabilities beyond human experts. Our experiments also indicated that the performance of these networks was significantly influenced by the similarity between the datasets used to fine-tune them and evaluate them. This fact highlights the importance of building publicly available images databases to further improve the results. Nevertheless, the results presented in this paper show that the analysis of UAV-acquired with deep learning networks can usher in a new type of large-scale study, spanning tenths or even hundreds of hectares with high spatial resolution (of a few cms per pixel), providing the ability to assess challenging vegetation dynamics problems that go beyond the ability of conventional fieldwork methodologies.}
}
@article{SAJIB2024102514,
title = {Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches},
journal = {Ecological Informatics},
volume = {80},
pages = {102514},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102514},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000566},
author = {Abdul Majed Sajib and Mir Talas Mahammad Diganta and Md. Moniruzzaman and Azizur Rahman and Tomasz Dabrowski and Md Galal Uddin and Agnieszka I. Olbert},
keywords = {Surface water quality, Machine learning, Water quality index, Model sensitivity, Model uncertainty, RMS-WQI Model},
abstract = {This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.}
}
@article{AREPALLI2024102405,
title = {Water contamination analysis in IoT enabled aquaculture using deep learning based AODEGRU},
journal = {Ecological Informatics},
volume = {79},
pages = {102405},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102405},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300434X},
author = {Peda Gopi Arepalli and K. Jairam Naik},
keywords = {Water quality, Water contamination, Water contamination index (WCI), Gated recurrent unit (GRU), Internet of things (IoT)},
abstract = {Water contamination presents a significant challenge in aquaculture, impacting the sustainability of ecosystems and the health of aquatic organisms. Precisely assessing water contamination levels is crucial for effective monitoring and safeguarding aquatic life within the aquaculture industry. Traditional methods for evaluating water contamination are characterized by their costliness, time-consuming nature, and susceptibility to errors. Integrating computer technologies such as Artificial Intelligence (AI), the Internet of Things (IoT), and Data Analytics offers promising potential in addressing this issue. Nevertheless, current deep learning solutions have limitations related to data variability, interpretability, and performance. To address these limitations, this study proposes a comprehensive framework that incorporates IoT-based data collection and data segregation techniques to enhance the accuracy of water contamination classification in aquaculture. Real-time data collected through IoT devices, encompassing parameters like temperature, pH levels, dissolved oxygen, nitrate concentration, and other water quality indicators, enables a holistic evaluation of water quality. By considering predefined acceptable ranges for aquatic life, this framework calculates a water contamination index, facilitating the classification of data into categories such as contaminated and non-contaminated. To ensure robust classification, the study introduces an innovative attention-based model known as the Ordinary Differential Equation Gated Recurrent Unit (AODEGRU). This attention mechanism directs the model's focus towards salient features associated with water contamination, while the AODEGRU architecture captures temporal patterns within the data. Experimental results underscore the effectiveness of the proposed model. It demonstrates its superiority with high performance, achieving an accuracy rate of approximately 98.69% on a publicly available dataset and an impressive 99.89% accuracy on a real-time dataset, clearly outperforming existing methodologies.}
}
@article{GALAZGARCIA2024102559,
title = {Mapping invasive iceplant extent in southern coastal California using high-resolution aerial imagery},
journal = {Ecological Informatics},
volume = {81},
pages = {102559},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102559},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001018},
author = {Carmen {Galaz García} and Julien Brun and Benjamin S. Halpern},
keywords = {Invasive species, Iceplant, , Remote sensing, NAIP, Machine learning, Random forest, Microsoft Planetary Computer, Texture},
abstract = {Invasive species threaten natural ecosystems globally, displacing native species and causing biodiversity loss. In coastal areas with Mediterranean climate around the world, iceplant (Carpobrotus edulis) has become highly invasive, forming large monospecific zones that compete for resources with native plant species, including threatened or endangered species. Despite the widespread impact of iceplant across coastal areas with a Mediterranean climate, there is no precise information on where it is and how much it has spread. This study focuses on mapping and quantifying iceplant extent along the coast of Santa Barbara County in California, USA, by leveraging machine learning methods to identify iceplant in images from the 2020 National Agriculture Imagery Program (NAIP) archive at 0.6 m/pixel resolution, creating the most extensive assessment to date of this invasive species. Results include a map showing iceplant locations in 2020 with overall accuracy of 87.11% ± 2.45% (95% confidence interval). The estimated iceplant coverage in our region of study is 2.2 ± 0.42 km2 (95% confidence interval). Additionally, this study's use of open data and reproducible data analysis and validation workflow opens the door for the methods presented to be adapted and applied across California and all other Mediterranean climatic regions. In addition, the developed approach will accelerate monitoring over time to comprehend the spread and mitigation of iceplant invasions.}
}
@article{ZBINDEN2024102623,
title = {On the selection and effectiveness of pseudo-absences for species distribution modeling with deep learning},
journal = {Ecological Informatics},
volume = {81},
pages = {102623},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102623},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001651},
author = {Robin Zbinden and Nina {van Tiel} and Benjamin Kellenberger and Lloyd Hughes and Devis Tuia},
keywords = {Species distribution modeling, Neural networks, Presence-only data, Pseudo-absences, Deep learning},
abstract = {Species distribution modeling is a highly versatile tool for understanding the intricate relationship between environmental conditions and species occurrences. However, the available data often lacks information on confirmed species absence and is limited to opportunistically sampled, presence-only observations. To overcome this limitation, a common approach is to employ pseudo-absences, which are specific geographic locations designated as negative samples. While pseudo-absences are well-established for single-species distribution models, their application in the context of multi-species neural networks remains underexplored. Notably, the significant class imbalance between species presences and pseudo-absences is often left unaddressed. Moreover, the existence of different types of pseudo-absences (e.g., random and target-group background points) adds complexity to the selection process. Determining the optimal combination of pseudo-absences types is difficult and depends on the characteristics of the data, particularly considering that certain types of pseudo-absences can be used to mitigate geographic biases. In this paper, we demonstrate that these challenges can be effectively tackled by integrating pseudo-absences in the training of multi-species neural networks through modifications to the loss function. This adjustment involves assigning different weights to the distinct terms of the loss function, thereby addressing both the class imbalance and the choice of pseudo-absence types. Additionally, we propose a strategy to set these loss weights using spatial block cross-validation with presence-only data. We evaluate our approach using a benchmark dataset containing independent presence-absence data from six different regions and report improved results when compared to competing approaches.}
}
@article{DURDEN2024102526,
title = {Defining the target population to make marine image-based biological data FAIR},
journal = {Ecological Informatics},
volume = {80},
pages = {102526},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102526},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000682},
author = {Jennifer M. Durden and Timm Schoening and Emma J. Curtis and Anna Downie and Andrew R. Gates and Daniel O.B. Jones and Alexandra Kokkinaki and Erik Simon-Lledó and Danielle Wright and Brian J. Bett},
keywords = {Data reuse, Underwater photography, Remote sensing, Environmental monitoring, Optical imaging, In-situ observation, Survey design, Quantitative ecology},
abstract = {Marine imaging studies have unique constraints on the data collected requiring a tool for defining the biological scope to facilitate data discovery, quality evaluation, sharing and reuse. Defining the ‘target population’ is way of scoping biological sampling or observations by setting the pool of organisms to be observed or sampled. It is used in survey design and planning, to determine statistical inference, and is critical for data interpretation and reuse (both images and derived data). We designed a set of attributes for defining and recording the target population in biological studies using marine photography, incorporating ecological and environmental delineation and marine imaging method constraints. We describe how this definition may be altered and recorded at different phases of a project. The set of attributes records the definition of the target population in a structured metadata format to enhance data FAIRness. It is designed as an extension to the image FAIR Digital Objects metadata standard, and we map terms to other biological data standards where possible. This set of attributes serves a need to update ecological metadata to align with new remotely-sensed data, and can be applied to other remotely-sensed ecological image data.}
}
@article{KISTNER2024102676,
title = {Enhancing endangered species monitoring by lowering data entry requirements with imputation techniques as a preprocessing step for the footprint identification technology (FIT)},
journal = {Ecological Informatics},
volume = {82},
pages = {102676},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102676},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002188},
author = {Frederick Kistner and Justus Tulowietzki and Larissa Slaney and Sky Alibhai and Zoe Jewell and Burim Ramosaj and Markus Pauly},
keywords = {Endangered species, Footprint identification technology, Non-invasive monitoring, Imputation, Missing values, Random Forest},
abstract = {Numerous species of Earth's biota are at risk of extinction and wildlife conservation is more important than ever. Reliable baseline data are essential for wildlife management to inform on the numbers and distribution of endangered species. A promising non-invasive and cost-effective method for monitoring endangered species is the Footprint Identification Technology (FIT). It lends itself to both conservation research as well as citizen science and can be combined with other data collection methods. FIT extracts and uses morphometrics from animal footprints to create geometric profiles that are analyzed in customized classification models. These can identify species, sex and individual. The ability to identify individuals can then be used to predict various population parameters including size, distribution, and growth rate. FIT has been developed and published for several species, but it requires high quality footprints. Perfect prints are not always easy to find in the field as various factors can influence their quality. In this paper, we demonstrate that geometrical profiles derived from poor quality footprints can be seen as datasets with missing values. Missing values are a common problem in various disciplines, and well-established strategies to impute missing values are widely available. We conducted two experiments to see whether such an approach could widen the application of the FIT method. The experiments were designed to test the hypothesis that population sizes can be underestimated when incomplete footprints are discarded from the data. We artificially introduced different proportions of missing values in datasets with geometric profiles of five different species for which FIT models have been published. We also analyzed a new dataset of geometric profiles of cheetah (Acinonyx jubatus) footprints not meeting the standard FIT requirements. We demonstrated that excluding incomplete footprints led to an underestimation of the known population. As an alternative to discarding footprints, we compared different imputation techniques as data pre-processing steps by comparing the performance of resulting FIT models. When imputation was chosen instead, we could show that FIT models with imputed geometric profiles were not significantly less accurate in predicting individual ID or population size even with high rates of missing values. We believe that our findings can be generalized, and the results indicate that imperfect footprints can contribute to the robustness of the FIT method and that this approach is particularly applicable when few good-quality footprints are available. We therefore highly recommend including imputation of imperfect footprints as a data pre-processing step.}
}
@article{KHADKE2024102446,
title = {Hydrometeorological Factors Affecting the Carbon Exchange of the Himalayan Pine-dominated Ecosystem},
journal = {Ecological Informatics},
volume = {79},
pages = {102446},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102446},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004752},
author = {Leena Khadke and Sandipan Mukherjee and Kireet Kumar and Subimal Ghosh},
keywords = {Himalayas, Process networks, Information theory, Ecology, Carbon sequestration},
abstract = {The net carbon uptake of the natural and dense Himalayan ecosystems is not well explored at a sub-daily scale due to limited data availability. Here, we present the first-ever analysis of the hydrometeorological controls of the sub-daily scale Net Ecosystem Exchange (NEE) in a Western Himalayan pine-dominated ecosystem (Pinus roxburghii). We used observed half-hourly flux tower data for 104 weeks from December 2014 to November 2016. We found that the sub-daily (6 h) scale variability of NEE contributes 20–40% to its within-week variability. We generated transfer entropy (TE)-based weekly process networks with a maximum memory of 6 h to understand sub-daily scale processes. Using weekly networks, we present consistent causal links on a seasonal scale. The hydrometeorological variables affecting the NEE and Ecosystem Respiration (RE) at a sub-daily scale are Net Solar Radiation (NSR), Relative Humidity (RH), Surface Air Temperature (TA), and Sensible Heat Flux (SH). These variables are consistently active in the networks with seasonally varying magnitudes of TE. We also found that for both monsoon and post-monsoon, NEE receives more incoming links from meteorological variables during dry weeks than wet weeks. Precipitation (P) did not send a direct causal link to NEE or RE within a sub-daily scale but strongly influenced the causal associations between hydrometeorological and carbon exchange variables. The network does not show any immediate (within 6 h) impact of P on NEE, which probably implies a delayed response of vegetation to P through soil moisture. At higher memory, P may act as an influential background variable.}
}
@article{AGBOOLA2024102583,
title = {Optimizing landslide susceptibility mapping using machine learning and geospatial techniques},
journal = {Ecological Informatics},
volume = {81},
pages = {102583},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102583},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001250},
author = {Gazali Agboola and Leila Hashemi Beni and Tamer Elbayoumi and Gary Thompson},
keywords = {Landslide susceptibility, Machine learning, Remote sensing, Natural disaster, Data driven},
abstract = {Landslides present a substantial risk to human lives, the environment, and infrastructure. Consequently, it is crucial to highlight the regions prone to future landslides by examining the correlation between past landslides and various geo-environmental factors. This study aims to investigate the optimal data selection and machine learning model, or ensemble technique, for evaluating the vulnerability of areas to landslides and determining the most accurate approach. To attain our objectives, we considered two different scenarios for selecting landslide-free random points (a slope threshold and a buffer-based approach) and performed a comparative analysis of five machine learning models for landslide susceptibility mapping, namely: Support Vector Machine (SVM), Logistic Regression (LR), Linear Discriminant Analysis (LDA), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The study area for this research is an area in Polk County in Western North Carolina that has experienced fatal landslides, leading to casualties and significant damage to infrastructure, properties, and road networks. The model construction process involves the utilization of a dataset comprising 1215 historical landslide occurrences and 1215 non-landslide points. We integrated a total of fourteen geospatial data layers, consisting of topographic variables, soil data, geological data, and land cover attributes. We use various metrics to assess the models' performance, including accuracy, F1-score, Kappa score, and AUC-ROC. In addition, we used the seeded-cell area index (SCAI) to evaluate map consistency. The ensemble of the five models using Weighted Average produces outstanding results, with an AUC-ROC of 99.4% for the slope threshold scenario and 91.8% for the buffer-based scenario. Our findings emphasize the significant impact of non-landslide random sampling on model performance in landslide susceptibility mapping. Furthermore, by optimally identifying landslide-prone regions and hotspots that need urgent risk management and land use planning, our study demonstrates the effectiveness of machine learning models in analyzing landslide susceptibility and providing valuable insights for informed decision-making and disaster risk reduction initiatives.}
}
@article{JIANG2024102650,
title = {Monitoring public perceptions of contaminated sites based on social media},
journal = {Ecological Informatics},
volume = {81},
pages = {102650},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102650},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001924},
author = {Yefeng Jiang and Yingcong Ye and Congkang Sun and Xi Guo and Zhou Shi},
keywords = {Spatiotemporal distribution, Contaminated site, Public perception, Social media, Risk management},
abstract = {Contaminated sites have a negative impact on human health and the ecological environment, which can potentially lead to major pollution incidents, and frequently receive complaints and reports from the public. Therefore, monitoring public perceptions of contaminated sites is crucial for risk management. However, methods based on traditional questionnaire surveys are limited in terms of time, cost, and target audience size. The purpose of this study was to establish a method using social media to monitor public perceptions of contaminated sites in the Yangtze River Delta urban agglomeration. Thus, 6802 public opinions were collected from social media (mainly microblogs in China) and topic modeling and pollution and spatial mining techniques were employed. The topic modeling results indicated that public perceptions of contaminated sites mainly focused on the construction of prevention and control systems, law enforcement work, developments and challenges applicable to the coal industry, environmental public interest litigation (pertaining to pollution), pollution inspection and rectification, and green development and ecological governance, with intensities of 7.9%, 7.8%, 7.1%, 6.1%, 5.9%, and 4.8%, respectively. Three communities resulting from public opinions in the study area included “environment and pollution,” “enterprises,” and “environmental protection,” with proportions of 37.68%, 34.78%, and 27.54%, respectively. The field investigation results indicated that approximately 90% of the tweets in three typical cities (i.e., Taizhou City in Zhejiang Province and Wuxi and Changzhou Cities in Jiangsu Province) involved key industrial enterprises or contaminated sites located within 1 km of the surrounding areas. The emotional analysis indicated that >3401 tweets dealt with a pollution probability (i.e., the possibility of potentially contaminated sites mentioned in social media becoming contaminated sites) exceeding 0.90 for the period 2011–2021. This finding suggests that the pollution probability for the sites involved in these tweets was high. Our study provides methodological references for monitoring public perceptions of contaminated sites for large-scale, long-term, and high-resolution studies.}
}
@article{FENG2024102501,
title = {An ensembled method for predicting dissolved oxygen level in aquaculture environment},
journal = {Ecological Informatics},
volume = {80},
pages = {102501},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102501},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000438},
author = {Dachun Feng and Qianyu Han and Longqin Xu and Ferdous Sohel and Shahbaz Gul Hassan and Shuangyin Liu},
keywords = {Aquaculture monitoring, Dissolved oxygen level estimation, Water quality assessment},
abstract = {Dissolved oxygen (DO) level is an important indicator aquaculture quality. This study proposes an ensembled method, WTD-GWO-SVR, combining wavelet threshold denoising (WTD), grey wolf optimization (GWO), and support vector regression (SVR) for accurately predicting DO levels. Addressing challenges such as high noise, poor data quality, and non-linearity and non-stationary properties of time series data, our method integrates SVR for regression-based estimation, WTD for data denoising, and GWO for optimizing the SVR parameters and the Gaussian kernel's radial basis function. We collected a dataset using a variety of low-cost sensors in a real aquaculture setting. Our comprehensive evaluation on the dataset demonstrates that WTD-GWO-SVR achieved mean squared error, mean absolute error, and R2 values of 0.38%, 3.81%, and 99.73%, respectively. It also consistently outperformed the back-propagation neural network and the long short-term memory model. It also achieved superior computational time performance compared to these methods. The high throughput and accuracy of WTD-GWO-SVR make it a potential choice for DO level prediction in water quality monitoring systems.}
}
@article{SARKAR2024102598,
title = {Ensembling machine learning models to identify forest fire-susceptible zones in Northeast India},
journal = {Ecological Informatics},
volume = {81},
pages = {102598},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102598},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001407},
author = {Mriganka Shekhar Sarkar and Bishal Kumar Majhi and Bhawna Pathak and Tridipa Biswas and Soumik Mahapatra and Devendra Kumar and Indra D. Bhatt and Jagadish C. Kuniyal and Sunil Nautiyal},
keywords = {Forest fire risk, Variable inflation factor analysis, Ensemble forecasting, Statistical modeling, Forest fire management},
abstract = {Forest fires pose significant challenges by disrupting ecological balance, impacting socio-economic harmony, and raising global concerns. North-East India (NEI) experiences high incidences of forest fires, making it crucial to implement suitable management measures considering the driving forces influencing fire likelihood. This study aims to identify forest fire susceptibility zones in NEI by using five machine-learning modeling approaches, Boosted Regression Tree (BRT), Random Forest (RF), Support Vector Machine (SVM), Classification and Regression Tree (CART), and Multivariate Adaptive Regression Splines (MARS), and an ensemble method. Forest fire data from the SNPP – VIIRS sensor (2018–2019) were rectified for spatial autocorrelation. Thirty-two responsive predictor variables related to topographic, climatic, biophysical, and anthropogenic factors were used as model inputs and multicollinearity analysis was performed to eliminate highly correlated predictors. Results indicate that the southern and southeastern regions of NEI, characterized by ample solar radiation, enhanced vegetation index, high human population density, and jhum cultivation, contribute significantly to higher susceptibility to forest fires. The Random Forest model performs best among the models employed, achieving an AUC value of 0.87. The ensemble susceptibility map, binarized based on AUC weighting, covers 29.54% of the total geographic area and 44.42% of the forested area of NEI. The vulnerability levels vary among states, with Mizoram showing the highest susceptibility at 89.27% and Sikkim exhibiting the lowest vulnerability at only 0.49% of their respective geographic areas. This map provides valuable insights for implementing effective forest fire management plans in the region. Moreover, the methodology utilized in this study, which incorporates satellite imagery, GIS techniques, and improved modeling techniques, can be replicated in any geographical region worldwide to facilitate effective forest fire management at a regional to large scale.}
}
@article{PARK2024102719,
title = {Generalizability evaluations of heterogeneous ensembles for river health predictions},
journal = {Ecological Informatics},
volume = {82},
pages = {102719},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102719},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002619},
author = {Taeseung Park and Jihoon Shin and Baekyung Park and Jeongsuk Moon and YoonKyung Cha},
keywords = {River health, Multimetric biological indices, Generalizability, Bias–variance decomposition, Heterogenous ensembles, SHapley additive exPlanations},
abstract = {Predictive models leverage the relationships between environmental factors and river health to predict the river health at unmonitored sites. Such models should be generalizable to unseen data. Among various machine learning models, heterogeneous ensembles are known to be generalizable owing to their structural diversity. The present study compares the generalizability of heterogeneous ensembles with those of homogeneous ensembles and single models. The models classified five grades (very good to very poor) of river health indices (RHIs) for three taxa (benthic macroinvertebrates, fish, and diatoms) given various environmental factors (water quality, hydrology, meteorological, land cover, and stream properties) as inputs. The data were monitored at 2915 sites in the four major river watersheds in South Korea during the 2016–2021 period. The results indicated better generalizability of the heterogeneous and homogeneous ensembles than single models. Moreover, heterogeneous ensembles tended to show higher generalizability than homogeneous ensembles, although the differences were marginal. Weighted soft voting was the most generalizable of the heterogeneous ensembles, with losses ranging from 0.49 to 0.59 across the three taxa. Weighted soft voting also delivered acceptable classification performance on the test set, with accuracies ranging from 0.42 to 0.52 across the taxa. The relative contributions of the environmental factors to RHI predictions and the directions of their effects agreed with established knowledge, confirming the reliability of the predictions. However, as heterogeneous ensembles have been rarely applied to RHI prediction, the extent to which heterogeneous ensembles improve the generalizability of prediction must be investigated in future studies.}
}
@article{MASSARELLI2023102342,
title = {Dynamics of pesticides in surface water bodies by applying data mining to spatiotemporal big data. A case study for the Puglia Region},
journal = {Ecological Informatics},
volume = {78},
pages = {102342},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102342},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003710},
author = {Carmine Massarelli and Claudia Campanale and Mariangela Triozzi and Vito Felice Uricchio},
keywords = {Plant protection products, Knowledge discovery in databases, Glyphosate, AMPA, Pesticides mixtures, Corine land cover, Geographic information system},
abstract = {Surface water pollution by pesticides is a primary concern in many parts of the world. Therefore, an effective monitoring program is essential to assess the environmental state of aquatic ecosystems and evaluate mitigation strategies. In the Puglia Region (southern Italy), a complex seasonal monitoring program for detecting pesticide residues in water was initiated in 2018 and is still underway (over four years). The program was based on site-specific assessments and identified 170 Plant Protection Products (PPPs) to identify residues in the surface water bodies of Puglia. In this context, the present work aims to analyse pesticide data obtained from the regional monitoring of rivers over four years using a multidisciplinary approach, which includes statistical methods, data mining, and mapping tools to extract as much information as possible.To this end, data mining was applied to identify the prevalent mixtures of pesticide residues found at the monitoring stations and correlate these results with possible causative factors. The results showed that surface water bodies are subject to different pressures derived from the massive use of PPPs, and several seasonal and territorial-related factors were identified to be strictly correlated with pesticide concentration results. Nine main PPPs mixtures have been identified in the Puglia River. Glyphosate, AMPA, imidacloprid, and azoxystrobin represent the main residues detected in the surface aquatic environments regarding the amount and frequency revealed. The methodological approach proposed in the present work can represent a good “model study” to be used by researchers to interpret water quality trends and data variability from long-term monitoring studies. Moreover, our results can significantly support the decision-making process and implementation of environmental mitigation measures by optimising the results of complex monitoring programs.}
}
@article{KAUKAB2024102691,
title = {Improving real-time apple fruit detection: Multi-modal data and depth fusion with non-targeted background removal},
journal = {Ecological Informatics},
volume = {82},
pages = {102691},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102691},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002334},
author = {Shaghaf Kaukab and  Komal and Bhupendra M Ghodki and Hena Ray and Yogesh B. Kalnar and Kairam Narsaiah and Jaskaran S. Brar},
keywords = {Apple, Fruit detection, 3D localization, YOLO network, RGB-D images, Depth sensor},
abstract = {In automated fruit detection, RGB-Depth (RGB-D) images aid the detection model with additional depth information to enhance detection accuracy. However, outdoor depth images are usually of low quality, which limits the quality of depth data. In this study, an approach/technique for real-time apple fruit detection in a high-density orchard environment by using multi-modal data is presented. Non-targeted background removal using the depth fusion (NBR-DF) method was developed to reduce the high noise condition of depth images. The noise occurred due to the uncontrolled lighting condition and holes with incomplete depth information in the depth images. NBR-DF technique follows three primary steps: pre-processing of depth images (point cloud generation), target object extraction, and background removal. The NBR-DF method serves as a pipeline to pre-process multi-modal data to enhance features of depth images by filling holes to eliminate noise generated by depth holes. Further, the NBR-DF implemented with the YOLOv5 enhances the detection accuracy in dense orchard conditions by using multi-modal information as input. An attention-based depth fusion module that adaptively fuses the multi-modal features was developed. The integration of the depth-attention matrix involved pooling operations and sigmoid normalization, both of which are efficient methods for summarizing and normalizing depth information. The fusion module improves the identification of multiscale objects and strengthens the network's resistance to noise. The network then detects the fruit position using multiscale information from the RGB-D images in highly complex orchard environments. The detection results were compared and validated with other methods using different input modals and fusion strategies. The results showed that the detection accuracy using the NBR-DF approach achieved an average precision rate of 0.964 in real time. The performance comparison with other state-of-the-art methods and the model generalization study also establish that the present advanced depth-fusion attention mechanism and effective preprocessing steps in NBR-DF-YOLOv5 significantly surpass those in performance. In conclusion, the developed NBR-DF technique showed the potential to improve real-time apple fruit detection using multi-modal information.}
}
@article{CHEN2024102594,
title = {Tradeoffs among multi-source remote sensing images, spatial resolution, and accuracy for the classification of wetland plant species and surface objects based on the MRS_DeepLabV3+ model},
journal = {Ecological Informatics},
volume = {81},
pages = {102594},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102594},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001365},
author = {Zizhen Chen and Jianjun Chen and Yuemin Yue and Yanping Lan and Ming Ling and Xinhong Li and Haotian You and Xiaowen Han and Guoqing Zhou},
keywords = {Wetland, UAV image, Satellite image, Spatial resolution, DeepLabV3 +, Multi-resolution segmentation},
abstract = {Classification of wetland plant species (PlatSpe) and surface objects (SurfObj) in remote sensing images faces significant challenges due to the high diversity of PlatSpe and the fragmented nature of SurfObj. Unmanned aerial vehicle (UAV) images and satellite images are the primary data sources for the classification of wetland PlatSpe and SurfObj. However, there is still insufficient research on the effect of various data sources and spatial resolutions on the classification results. This study essentially focuses on Huixian Wetland in Guilin, Guangxi, China through utilizing UAV images and satellite images with varying spatial resolutions as data sources. To this end, the MRS_DeepLabV3+ model is constructed based on multi-resolution segmentation and DeepLabV3+, and the wetland PlatSpe and SurfObj are appropriately classified based on this model. The obtained results reveal that: (1) MRS_DeepLabV3+ model with optimal scale parameter (SP) is capable of achieving higher classification accuracy compared to DeepLabV3+. The optimal SPs for both UAV images and satellite images gradually lessen with decreasing the spatial resolution, and satellite images require larger SPs compared to UAV images. (2) In both the UAV and satellite image models, both OA and kappa exhibit a decreasing trend with the reduction of the spatial resolution. (3) The overall classification accuracies of the satellite image models are superior to the UAV image models in the spatial resolution intervals of 2 to 16 m. This investigation can be regarded as a valuable reference for selecting data sources and spatial resolutions in the wetland PlatSpe and SurfObj classification.}
}
@article{ORIOL2024102606,
title = {Automatic identification of Collembola with deep learning techniques},
journal = {Ecological Informatics},
volume = {81},
pages = {102606},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102606},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001481},
author = {Théo Oriol and Jérôme Pasquet and Jérôme Cortet},
keywords = {Deep learning, Object detection, Collembola, Soil quality, Bioindication},
abstract = {Collembola are very abundant organisms in soils (several thousand individuals per square meter) and are considered to be good indicators of soil quality. These indicators are mainly based on the number of individuals observed (abundance per square meter of soil), but also the singularity and number of species present (species richness). A limitation that comes with the usage of collembola as an indicator is the complexity of the identification of the species under a microscope, how time-consuming it is, and the morphological similarity between some species. Deep learning approaches have been very successful in the resolution of image-based problems. Still, no work yet exists that uses deep learning in the recognition of collembola on a microscope slide. This could be a valuable tool for experts seeking to use Collembola as a metric on a larger scale. In this work, we explore and evaluate the performance of state-of-the-art deep learning techniques over the identification of Collembola on a new manually annotated dataset.}
}
@article{GRIJALVA2024102540,
title = {Detecting and counting sorghum aphid alates using smart computer vision models},
journal = {Ecological Informatics},
volume = {80},
pages = {102540},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102540},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000827},
author = {Ivan Grijalva and H. Braden Adams and Nicholas Clark and Brian McCornack},
keywords = {sorghum, sorghum aphid, alates, automation, detection},
abstract = {Sorghum aphid [Melanaphis sorghi (Theobald)] is considered an economic pest causing significant yield losses in susceptible sorghum in the southern U.S. Infestations start with the migration of alates (i.e., winged adults) to sorghum and establishing aphid colonies. In favorable conditions, sorghum aphid can exponentially reproduce via asexual reproduction. A suggested strategy is to monitor alates to determine initial infestations and take preventive strategies, which can result in more efficient pest monitoring and management. To reduce the time of monitoring and better understand of alate establishment under field conditions, we propose using computer vision models, specifically deep learning, to detect and count alates using field-collected images. During pest monitoring, we captured 2527 images and assessed the performance of five models within the YOLOv5 architecture family using two different image sizes, including input resolutions of 640 × 640, and 1280 × 1280 pixels. We trained models to detect and count individual alates, which ranged between 1 and 100 alates/leaf. Among models, the YOLOv5l Pytorch detection model had the best overall performance at 1280 × 1280 input pixel resolution. The YOLOv5l model is a candidate model for quantifying alates on sorghum leaves using deep learning with a precision of 83.80%, 85.60% recall, and 89% mAP@0.5 with a lower mean percent error of misdetection. To enable the use of our best deep learning model by the research community, we developed a web-based application that is freely available to the public. Using this application, users can upload images to detect and count alates with a low error of misdetection.}
}
@article{PEREZGRANADOS2022101861,
title = {Automated signal recognition as a useful tool for monitoring little-studied species: The case of the Band-tailed Nighthawk},
journal = {Ecological Informatics},
volume = {72},
pages = {101861},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101861},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003119},
author = {Cristian Pérez-Granados and Karl-L. Schuchmann},
keywords = {eBird, Nightjar, Pantanal, Passive acoustic monitoring, Vocal activity, Xeno-canto},
abstract = {Passive acoustic monitoring, when coupled with automated signal recognition software, is a useful technique for monitoring vocally active taxa. In this study, we evaluated the utility of automated signal recognition to gain insights into the ecology of little-studied species. For this purpose, we selected an avian family, Caprimulgidae (nightjars), composed of cryptic and nocturnal species, and focused the study on a Neotropical wetland, the Brazilian Pantanal. We reviewed the number of publications, observations, and recordings available for each nightjar inhabiting the Brazilian Pantanal and the Band-tailed Nighthawk (Nyctiprogne leucopyga) was identified as the species with the least information available. We employed automated signal recognition software to study the vocal behavior of this species over a complete annual cycle in the Pantanal. Previous knowledge about the ecology of this species is based on general descriptions and anecdotal observations. Our findings corroborate that the Nighthawk is a resident species of the Brazilian Pantanal, and according to seasonal changes in vocal activity, the breeding season extends from July to October. The breeding period starts at the end of the dry season (July–August), and the nesting period may occur at the beginning of the wet season and following the first rains, which is a period of maximum insect food availability. The vocal activity of the Nighthawk was restricted to the nocturnal period and was maximum at dusk. That preference for dusk is in disagreement with the pattern described for the other four nightjars in the study area, which highlights the importance of performing species-specific studies and avoiding drawing any conclusions about the activity pattern of a species based on the genus or family to which it belongs to. Automated signal recognition software was able to detect over three quarters of the songs annotated by a human on a subset of sound recordings, therefore proving its utility for monitoring the Band-tailed Nighthawk.}
}
@article{MAMUN2024102608,
title = {Advancing reservoirs water quality parameters estimation using Sentinel-2 and Landsat-8 satellite data with machine learning approaches},
journal = {Ecological Informatics},
volume = {81},
pages = {102608},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102608},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400150X},
author = {Md Mamun and Mahmudul Hasan and Kwang-Guk An},
keywords = {Landsat-8 OLI, Machine learning, Remote sensing, Sentinel-2 MSI, Water quality parameters},
abstract = {Reservoir eutrophication, caused by human activities and climate change, has emerged as a critical environmental concern that has attracted both governmental and public attention. However, accurate measurement of water quality parameters, such as chlorophyll a (CHL-a), water clarity (Secchi depth; SD), and total suspended solids (TSS), in inland waters is challenging due to the optical complexity of individual water bodies, which impedes the optimization of conventional bio-optical algorithms. The aim of this study was to demonstrate the viability of harmonizing Sentinel-2 Multi-Spectral Imager (MSI) and Landsat-8 Operational Land Imager (OLI) satellite imagery surface reflectance (SR) products to facilitate the monitoring of inland reservoir CHL-a, SD, and TSS using the Google Earth Engine (GEE) platform and machine learning algorithms. Machine learning models were trained using Landsat-8 OLI and Sentinel-2 MSI surface reflectance products to identify bands and combinations predicting CHL-a, SD, and TSS. Among the machine learning algorithms tested, random forest (RF) (S-2 MSI: R2 = 0.61, mean absolute error [MAE] = 6.56%, root-mean-square error [RMSE] = 12.51 μg/L, L-8 OLI: R2 = 0.56, MAE = 8.44%, RMSE = 16.01 μg/L) yielded the best results in the test set for CHL-a prediction from the Sentinel-2 MSI and Landsat-8 OLI, outperforming the k-nearest neighbor (KNN), AdaBoost, and artificial neural network (ANN) models. It also showed superior performance for SD and TSS prediction. The feature importance analysis revealed that specific band ratios, such as (red/red edge1)*red edge2 for Sentinel-2 MSI and red/blue for Landsat-8 OLI, were significant predictors of CHL-a and TSS. The red/blue band ratio and the green band were highly predictive for SD in Sentinel-2 MSI and Landsat-8 OLI, respectively. The results of fall CHL-a predictions revealed varying trophic levels in the reservoirs. Landsat-8 OLI indicated that 2% of the reservoirs were oligotrophic, while 46%, 43%, and 9% were mesotrophic, eutrophic, and hypertrophic, respectively. Meanwhile, the Sentinel-2 MSI results showed that 51% of the reservoirs were mesotrophic, while 6%, 35%, and 8% were oligotrophic, eutrophic, and hypertrophic, respectively. Overall, this study demonstrates the effectiveness of Landsat-8 OLI and Sentinel-2 MSI surface reflectance products in estimating and monitoring reservoir water quality parameters using machine learning algorithms. This approach has the potential to yield valuable insights aiding the assessment and management of water quality at the regional, national, and global levels.}
}
@article{STORY2024102657,
title = {DialectDecoder: Human/machine teaming for bird song classification and anomaly detection},
journal = {Ecological Informatics},
volume = {82},
pages = {102657},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102657},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001997},
author = {Brittany Story and Patrick Gillespie and Graham Derryberry and Elizabeth Derryberry and Nina Fefferman and Vasileios Maroulas},
keywords = {Human-machine teaming, Song classification, Anomaly detection},
abstract = {Classification tasks are some of the most widely known machine learning applications. Computers can classify images, sounds, and patterns with high accuracy, given enough training data, time, and computational resources. After training, computers can perform identification tasks faster than humans and often with less error. In contrast, humans are well equipped for anomaly identification and can adapt to new information quickly and effectively. Thus we introduce DialectDecoder, a tool that uses human intelligence and machine learning to classify different dialects of White-crowned Sparrow songs, relying on both the human and the computer for different parts of the classification process. DialectDecoder is an example of humans and computers working together to detect and classify anomalies. After preprocessing the data and training the classifiers with the built-in tools, each new song is fed to the network where the computer classifies the song as a specific dialect or gives the song conflicting labels which, with the song, are sent to the expert human for classification. The human expert can label all songs with conflicting labels and append them to the training set, which provides the computer with updated information to retrain on. We performed three different tests that illustrate the applicability of human-machine teaming and demonstrate the ability of DialectDecoder, paired with an expert human, to classify different dialects of White-crowned Sparrow songs. Then, we discuss extensions of DialectDecoder and its applicability to other human-machine teaming tasks that leverage the distinct strengths contributed by each half of the partnership to improve overall performance.}
}
@article{MORTIER2024102730,
title = {Inferring the relationship between soil temperature and the normalized difference vegetation index with machine learning},
journal = {Ecological Informatics},
volume = {82},
pages = {102730},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102730},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002723},
author = {Steven Mortier and Amir Hamedpour and Bart Bussmann and Ruth Phoebe Tchana Wandji and Steven Latré and Bjarni D. Sigurdsson and Tom {De Schepper} and Tim Verdonck},
keywords = {Soil temperature, Phenology, Machine learning, Climate change, SHAP values, Subarctic grassland},
abstract = {Changes in climate can greatly affect the phenology of plants, which can have important feedback effects, such as altering the carbon cycle. These phenological feedback effects are often induced by a shift in the start or end dates of the growing season of plants. The normalized difference vegetation index (NDVI) serves as a straightforward indicator for assessing the presence of green vegetation and can also provide an estimation of the plants' growing season. In this study, we investigated the effect of soil temperature on the timing of the start of the season (SOS), timing of the peak of the season (POS), and the maximum annual NDVI value (PEAK) in subarctic grassland ecosystems between 2014 and 2019. We also explored the impact of other meteorological variables, including air temperature, precipitation, and irradiance, on the inter-annual variation in vegetation phenology. Using machine learning (ML) techniques and SHapley Additive exPlanations (SHAP) values, we analyzed the relative importance and contribution of each variable to the phenological predictions. Our results reveal a significant relationship between soil temperature and SOS and POS, indicating that higher soil temperatures lead to an earlier start and peak of the growing season. However, the Peak NDVI values showed just a slight increase with higher soil temperatures. The analysis of other meteorological variables demonstrated their impacts on the inter-annual variation of the vegetation phenology. Ultimately, this study contributes to our knowledge of the relationships between soil temperature, meteorological variables, and vegetation phenology, providing valuable insights for predicting vegetation phenology characteristics and managing subarctic grasslands in the face of climate change. Additionally, this work provides a solid foundation for future ML-based vegetation phenology studies.}
}
@article{LAVNER2024102528,
title = {The bioacoustic soundscape of a pandemic: Continuous annual monitoring using a deep learning system in Agmon Hula Lake Park},
journal = {Ecological Informatics},
volume = {80},
pages = {102528},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102528},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000700},
author = {Yizhar Lavner and Ronen Melamed and Moshe Bashan and Yoni Vortman},
keywords = {Long-term bird monitoring, BirdNET, Deep learning, Bioacoustics, Passive acoustic monitoring, Avian influenza},
abstract = {Continuous bioacoustic monitoring is an emerging opportunity as well as a challenge, allowing detection of cryptic species' activity while producing high computational demands. In this paper, we present an automated framework that allows the monitoring of a large number of bird species by their vocalizations over extended periods. The framework relies on the BirdNET-Analyzer deep learning model. We applied the framework to >80 species; 20 species with the highest recall scores were selected for further analysis. We used the framework to analyze acoustic signals recorded continuously for over two years using autonomous recorders at various locations in Agmon Hula Lake Park, Israel. During this period there was an acute outbreak of avian influenza in the area. We analyzed differences in acoustic occupancy for various species between two consecutive years (November 2020 to October 2022). We examined between-year population trends for 17 species, both migratory and resident, and found a significant decline in vocal activity between the two years for 10 species. We assume that this decline is related to the avian influenza outbreak, suggesting that the impact of the pandemic may be more widespread and affected a greater number of local species than was previously realized. This further highlights the power and effectiveness of bioacoustic monitoring in detecting cryptic but dramatic dynamics.}
}
@article{BRAVOSANCHEZ2024102593,
title = {Improved analysis of deep bioacoustic embeddings through dimensionality reduction and interactive visualisation},
journal = {Ecological Informatics},
volume = {81},
pages = {102593},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102593},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001353},
author = {Francisco J. {Bravo Sanchez} and Nathan B. English and Md Rahat Hossain and Steven T. Moore},
keywords = {Bioacoustics, Deep neural networks, Embeddings, Dimensionality reduction},
abstract = {Deep neural networks (DNN) are a popular tool to process environmental sounds and identify sound-producing animals, but it can be difficult to understand the decision-making logic, particularly when it does not produce the expected results. Here we describe a new and enhanced visual interactive analysis of embeddings and explore its application in bioacoustics. Embeddings are the output of the penultimate layer of a DNN, an N-dimensional vector that, only one step removed from the final output, represent the inner-workings of a DNN model. Using existing dimensionality reduction techniques we converted the N-dimensional embeddings into 2 or 3-dimensional arrays displayed in scatterplots. By incorporating sound samples into the scatterplots we developed a visual and aural interactive interface and demonstrate its utility in assessing the performance of trained bioacoustic models, facilitating post-processing of results, error detection, input selection and the detection of rare events, which the reader can experience in online examples with publicly available code.}
}
@article{WEINSTEIN2020101061,
title = {Cross-site learning in deep learning RGB tree crown detection},
journal = {Ecological Informatics},
volume = {56},
pages = {101061},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101061},
url = {https://www.sciencedirect.com/science/article/pii/S157495412030011X},
author = {Ben G. Weinstein and Sergio Marconi and Stephanie A. Bohlman and Alina Zare and Ethan P. White},
keywords = {Tree crown detection, RGB deep learning, Object detection, Airborne LiDAR},
abstract = {Tree crown detection is a fundamental task in remote sensing for forestry and ecosystem ecology. While many individual tree segmentation algorithms have been proposed, the development and testing of these algorithms is typically site specific, with few methods evaluated against data from multiple forest types simultaneously. This makes it difficult to determine the generalization of proposed approaches, and limits tree detection at broad scales. Using data from the National Ecological Observatory Network, we extend a recently developed deep learning approach to include data from a range of forest types to determine whether information from one forest can be used for tree detection in other forests, and explore the potential for building a universal tree detection algorithm. We find that the deep learning approach works well for overstory tree detection across forest conditions. Performance was best in open oak woodlands and worst in alpine forests. When models were fit to one forest type and used to predict another, performance generally decreased, with better performance when forests were more similar in structure. However, when models were pretrained on data from other sites and then fine-tuned using a relatively small amount of hand-labeled data from the evaluation site, they performed similarly to local site models. Most importantly, a model fit to data from all sites performed as well or better than individual models trained for each local site.}
}
@article{SINGH2024102408,
title = {Optimising carbon fixation through agroforestry: Estimation of aboveground biomass using multi-sensor data synergy and machine learning},
journal = {Ecological Informatics},
volume = {79},
pages = {102408},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102408},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004375},
author = {R.K. Singh and C.M. Biradar and M.D. Behera and A.J. Prakash and P. Das and M.R. Mohanta and G. Krishna and A. Dogra and S.K. Dhyani and J. Rizvi},
keywords = {Machine learning, Aboveground biomass, Agroforestry, Vegetation indices, SAR backscatters},
abstract = {As agricultural land expansion is the primary driver of deforestation, agroforestry could be an optimal land use strategy for climate change mitigation and reducing pressure on forests. Agroforestry is a promising method for carbon sequestration. With recent advancements in geospatial and data science technology, the ability to predict aboveground biomass (AGB) and assess ecosystem services in agroforestry is rapidly expanding. This study was conducted in the Belpada Block of Balangir, Odisha, a forest-dominated region of eastern India. We recorded species occurrence and measured plant parameters, including Circumference at Breast Height (CBH), height, and geolocation, in 196 plots (0.09 ha) in agroforestry intervention sites and noted the tree species. This study used Sentinel-1 and Sentinel-2 multi sensor data to achieve data synergy in AGB estimation. Three machine learning models were used: Random Forest (RF), Support Vector Machine (SVM), and Artificial Neural Network (ANN). The RF model exhibited the highest level of prediction accuracy (R2 = 0.69 and RMSE = 17.07 Mg/ha), followed by the ANN model (R2 = 0.63 and RMSE = 19.35 Mg/ha), SVM model (R2 = 0.54, RMSE = 21.97 Mg/ha. The spectral vegetation indices that are (Normalized Difference Vegetation Index (NDVI), Soil-Adjusted Vegetation Index (SAVI), Enhanced Vegetation Index (EVI), Modified Simple Ratio (MSR), Modified Soil-Adjusted Vegetation Index (MSAVI), Difference Vegetation Index (DVI), and SAR backscatter values, were found important variables for AGB prediction. The findings revealed that agroforestry interventions and plantations resulted in an average carbon stock increase of 15 Mg/ha over five years in the study area. The Plant Value Index (PVI), which indicates the importance of species in the local economy and biomass carbon storage, showed that Tectona grandis was the dominant species with the highest PVI value (88.35), followed by Eucalyptus globulus (56.87), Mangifera indica (53.75), and Azadirachta indica (15.45). This approach enables the expansion of monitoring efforts to assess carbon stock in agroforestry systems, thereby promoting effective management strategies.}
}
@article{GOIKOETXEA2024102577,
title = {Machine-learning aiding sustainable Indian Ocean tuna purse seine fishery},
journal = {Ecological Informatics},
volume = {81},
pages = {102577},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102577},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001195},
author = {Nerea Goikoetxea and Izaro Goienetxea and Jose A. Fernandes-Salvador and Nicolas Goñi and Igor Granado and Iñaki Quincoces and Leire Ibaibarriaga and Jon Ruiz and Hilario Murua and Ainhoa Caballero},
keywords = {Sustainable fishing, Bycatch, Machine-learning, Tropical tuna, Fisheries oceanography, Species distribution models},
abstract = {Among the various challenges facing tropical tuna purse seine fleet are the need to reduce fuel consumption and carbon footprint, as well as minimising bycatch of vulnerable species. Tools designed for forecasting optimum tuna fishing grounds can contribute to adapting to changes in fish distribution due to climate change, by identifying the location of new suitable fishing grounds, and thus reducing the search time. While information about the high probability to find vulnerable species could result in a bycatch reduction. The present study aims at contributing to a more sustainable and cleaner fishing, i.e. catching the same amount of target tuna with less fuel consumption/emissions and lower bycatch. To achieve this, tropical tuna catches as target species, and silky shark accidental catches as bycatch species have been modelled by machine learning models in the Indian Ocean using as inputs historical catch data of these fleets and environmental data. The resulting models show an accuracy of 0.718 and 0.728 for the SKJ and YFT, being the absences (TPR = 0.996 for SKJ and 0.993 for YFT, respectively) better predicted than the high or low catches. In the case of the BET, which is not the main target species of this fleet, the accuracy is lower than that of the previous species. Regarding the silky shark, the presence/absence model provides an accuracy of 0.842. Even though the model's performance has room for improvement, the present work lays the foundations of a process for forecasting fishing grounds avoiding vulnerable species, by only using as input data forecast environmental data provided in near real time by earth observation programs. In the future these models can be improved as more input data and knowledge about the main environmental conditions influencing these species becomes available.}
}
@article{LI2024102686,
title = {Coupled zoning and spatial heterogeneity of human activities and natural endowments based on self-organizing map and random forest: A case study of the agro-pastoral ecotone in Gansu, China},
journal = {Ecological Informatics},
volume = {82},
pages = {102686},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102686},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002280},
author = {Jie Li and Ninghui Pan and Yao Yao and Guang Li and Zhiyuan Cheng and Yanhua Lu and Shuainan Liu and Wenming Liu},
keywords = {Human activity–natural endowment coupled zoning, Regional differentiation, Self-organizing map, Random forest, Agro-pastoral ecotone in Gansu, China},
abstract = {Regional zoning is an important way for humans to understand geographical space，but the existing research on regional zoning focuses on natural conditions, ignoring the interdependent characteristics of human and nature, and the driving mechanism of regional differentiation is not sufficiently explained. In this study, using algorithms such as self-organizing feature map, clustering quality index, structural similarity index measure (SSIM) and random forest, the human activity (HA)–natural endowment (NE) coupled zoning in the agro-pastoral ecotone in Gansu, China (AEGC), was conducted to explore the driving mechanism of regional differentiation. Results show the following: (1) The HA-NE coupled zoning has the best clustering effect when implementing the partitioning scheme with a classification number of 4. Accordingly, the AEGC can be divided into four regions with significant differences between HAs and NEs. (2) From the perspective of spatial distribution, HA–NE coupled zoning, climate zoning, geographic zoning, and vegetation zoning are similar, whereas HA zoning is different. The results of SSIM showed that HA–NE coupled zoning takes all types of factors into consideration (SSIM mean 0.708), and the zoning results are better than single type zonings. HAs have strong independence (SSIM mean 0.576), and geographic conditions are closely related to all other factors (SSIM mean 0.671). (3) Elevation is the most important driver of regional differentiation in the AEGC, with a contribution degree of 22.36%; other important drivers include land use intensity, precipitation, and normalized difference vegetation index, with contribution degree distributions of 17.38%, 16.34%, and 15.79%. Furthermore, the dominant factors of regional differentiation in each sub-region are different. This study emphasizes that regional characteristic factors and uneven spatial distribution factors are important drivers of regional differentiation, and land use intensity has become an important force influencing geographic space. Policy recommendations for zonal governance are made based on the inherent conditions of different regions. This study may provide a reference for scientific regional zoning and cognitive regional differentiation.}
}
@article{KUMAR2023102206,
title = {CO2 emission based GDP prediction using intuitionistic fuzzy transfer learning},
journal = {Ecological Informatics},
volume = {77},
pages = {102206},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102206},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002352},
author = {Sandeep Kumar and Amit K. Shukla and Pranab K. Muhuri and Q.M. Danish Lohani},
keywords = {Atanassov intuitionistic fuzzy sets, Hausdorff distance, Yager's generating function, GDP prediction, Fuzzy sets},
abstract = {The industrialization has been the primary cause of the economic boom in almost all countries. However, this happened at the cost of the environment, as industrialization also caused carbon emissions to increase exponentially. According to the established literature, Gross Domestic Product (GDP) is related to carbon emissions (CO2) which could be optimally employed to precisely estimate a country's GDP. However, the scarcity of data is a significant bottleneck that could be handled using transfer learning (TL) which uses previously learned information to resolve new tasks, more specifically, related tasks. Notably, TL is highly vulnerable to performance degradation due to the deficiency of suitable information and hesitancy in decision-making. Therefore, this paper proposes ‘Intuitionistic Fuzzy Transfer Learning (IFTL)’, which is trained to use CO2 emission data of developed nations and is tested for its prediction of GDP in a developing nation. IFTL exploits the concepts of intuitionistic fuzzy sets (IFSs) and a newly introduced function called the modified Hausdorff distance function. The proposed IFTL is investigated to demonstrate its actual capabilities for TL in modeling hesitancy. To further emphasize the role of hesitancy modelled with IFSs, we propose an ordinary fuzzy set (FS) based transfer learning. The prediction accuracy of the IFTL is further compared with widely used machine learning approaches, extreme learning machines, support vector regression, and generalized regression neural networks. It is observed that IFTL capably ensured significant improvements in the prediction accuracy over other existing approaches whenever training and testing data have huge data distribution differences. Moreover, the proposed IFTL is deterministic in nature and presents a novel way for mathematically computing the intuitionistic hesitation degree.}
}
@article{AGARWAL2021101251,
title = {Balancing the needs of consumers and producers for scientific data collections},
journal = {Ecological Informatics},
volume = {62},
pages = {101251},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101251},
url = {https://www.sciencedirect.com/science/article/pii/S157495412100042X},
author = {Deborah A. Agarwal and Joan Damerow and Charuleka Varadharajan and Danielle S. Christianson and Gilberto Z. Pastorello and You-Wei Cheah and Lavanya Ramakrishnan},
abstract = {Recent emphasis and requirements for open data publication have led to significant increases in data availability in the Earth sciences, which is critical to long-tail data integration. Currently, data are often published in a repository with an identifier and citation, similar to those for papers. Subsequent publications that use the data are expected to provide a citation in the reference section of the paper. However, the format of the data citation is still evolving, particularly with regards to citing dynamic data, subsets, and collections of data. Considering the motivations of both data producers and consumers, the most pressing need is to create user-friendly solutions that provide credit for data producers and enable accurate citation of data, particularly integrated data. Providing easy-to-use data citations is a critical foundation that is required to address the socio-technical challenges around data integration. Studies that integrate data from dozens or hundreds of datasets must often include data citations in supplementary material due to page limits. However, citations in the supplementary material are not indexed, making it difficult to track citations and thus giving credit to the data producer. In this paper, we discuss our experiences and the challenges we have encountered with current citation guidance. We also review the relative merits of the currently available mechanisms designed to enable compact citation of collections of data, such as data collections, data papers, and dynamic data citations. We consider these options for three data producer scenarios: a domain-specific data collection, a data repository, and a large-scale, multidisciplinary project. We posit that a new mechanism is also needed to enable citation of multiple datasets and credit to data producers.}
}
@article{BACHECHI2024102568,
title = {HypeAIR: A novel framework for real-time low-cost sensor calibration for air quality monitoring in smart cities},
journal = {Ecological Informatics},
volume = {81},
pages = {102568},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102568},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001109},
author = {Chiara Bachechi and Federica Rollo and Laura Po},
keywords = {Real-time, Sensor calibration, Air quality monitoring, Smart cities, Air pollution monitoring, Low cost sensors, Time series, Framework, Air quality, LSTM, Random forest},
abstract = {While less reliable than authorized air quality stations, low-cost sensors help monitor air quality in areas overlooked by traditional devices. A calibration process in the same environment as the sensor is crucial to enhance their accuracy. Furthermore, low-cost sensors deteriorate over time, necessitating repeated calibration for sustained performance. HypeAIR is a novel open-source framework for the management of sensor calibration in real-time. It incorporates two calibration methodologies: a combination of machine learning models (Voting Regressor and Support Vector Regression) and the Long Short-Term Memory deep learning model. To evaluate the framework, three extensive experiments were conducted over a 2-year period in the city of Modena, Italy, to monitor NO, NO2, and O3 gases. Both calibration methodologies outperform the manufacturer calibration and our baseline (i.e., a variation of the Random Forest algorithm) and maintain efficiency over time. The availability of the source code facilitates customization for monitoring additional pollutants, while shared air quality datasets ensure reproducibility.}
}
@article{PETROSYAN2023102126,
title = {FAIR degree assessment in agriculture datasets using the F-UJI tool},
journal = {Ecological Informatics},
volume = {76},
pages = {102126},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102126},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001553},
author = {Luiza Petrosyan and Rafael Aleixandre-Benavent and Fernanda Peset and Juan Carlos Valderrama-Zurián and Antonia Ferrer-Sapena and Andrea Sixto-Costoya},
keywords = {Agriculture, Data sharing, FAIR principles},
abstract = {For the agricultural scientific community, data sharing is crucial both for the advancement of the discipline and ability to meet global challenges, such as the target no. 2, i.e., “Zero Hunger,” of the Sustainable Development Goals (SDG 2030). In this context, FAIR (Findable, Accessible, Interoperable and Reusable) principles play an important role, as they guarantee the findability, accessibility, interoperability, and reusability of shared data. To improve the practice of data sharing, institutions, funders, and publishers are increasingly demanding data be shared as well as be of an acceptable level of quality, including compliance with FAIR principles. Therefore, the objective of this work is twofold: first, this research aims to determine the degree of compliance with the FAIR principles exhibited by a number of datasets; and second, it aims to explore useful and valid methodologies and procedures that can be used to perform this evaluation quickly, automatically, and effectively. For this purpose, the Data Citation Index (DCI) was used to obtain many datasets in the field of agriculture, which were further grouped by repositories and evaluated using the automated assessment tool F-UJI provided by the FAIRsFAIR project. The results indicated that the principle that exhibited the highest scores was “Findable”, while “Reusable” received the lowest scores, as none of the analysed repositories achieved a 50% compliance score in this respect. The datasets published in the Zenodo and Dryad repositories exhibited better overall results in terms of the FAIR principles, and the AG Commons repository was the third best rated repository, representing only one of the first three repositories belonging to the agricultural sector. Regarding the use of F-UJI as an automated assessment tool and DCI as a source for obtaining datasets, we conclude that this methodology is useful, and that although it can be improved, it is easy to use and implement by other scientific groups and agents of interest.}
}
@article{GIBB2024102449,
title = {Towards interpretable learned representations for ecoacoustics using variational auto-encoding},
journal = {Ecological Informatics},
volume = {80},
pages = {102449},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102449},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004788},
author = {K.A. Gibb and A. Eldridge and C.J. Sandom and I.J.A. Simpson},
keywords = {Representation learning, Variational auto-encoder, Biodiversity monitoring, Deep learning, Ecoacoustics, Passive acoustic monitoring},
abstract = {Ecoacoustics is an emerging science that seeks to understand the role of sound in ecological processes. Passive acoustic monitoring is being used to collect vast quantities of soundscape audio recordings to study variations in acoustic community and monitor biodiversity. However, extracting relevant information from soundscape recordings is non-trivial. Recent approaches to machine-learned acoustic features appear promising but are limited by at least three issues: inductive biases, lack of interpretability and crude temporal integration. In this paper we introduce a novel self-supervised representation learning algorithm for ecoacoustics - a convolutional Variational Auto-encoder (VAE) - and directly address these shortcomings. Firstly, we train the network on soundscape recordings from temperate and tropical field sites along a gradient of ecological degradation to provide a more relevant inductive bias than prior approaches. Secondly, we present a new method that allows interpretation of the latent space for the first time, giving insight into the basis of classification. Thirdly, we advance existing methods for temporal aggregation of learned embeddings by encoding latent features as a distribution over time. Under our approach to increase interpretability, we provide insight into how learned features drive habitat classification for the first time: inspection of latent space confirms that varying combinations of biophony, geophony and anthrophony are used to infer sites along a degradation gradient. Our novel temporal encoding method increases sensitivity to periodic signals and improves on previous research that uses time-averaged representations for site classification. This approach also reveals the contribution of hardware-specific frequency response that create a potential bias; we demonstrate how a simple linear transformation can be used to mitigate the effect of hardware variance on the learned representation under our approach. Our novel approach paves the way for development of a new class of deep neural networks that afford more interpretable learned ecoacoustic representations to advance both fundamental and applied science and support global conservation efforts.}
}
@article{SAIN2024102648,
title = {Cotton leaf curl disease (CLCuD) prediction modeling in upland cotton under different ecological conditions using machine learning tools},
journal = {Ecological Informatics},
volume = {81},
pages = {102648},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102648},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001900},
author = {Satish Kumar Sain and Debashis Paul and Pradeep Kumar and Ashok Kumar and Man Mohan and Dilip Monga and A.H. Prakash and Yenumula G. Prasad},
keywords = {Artificial neural network (ANN), Bootstrap forest, Boosted tree, Multiple linear regression (MLR), CLCuD, Upland cotton, Growing degree days},
abstract = {Cotton leaf curl disease (CLCuD) is a major threat to cotton production in Africa and South Asia. Due to the dearth of absolute CLCuD-resistant cultivars and effective Bemisia tabaci-vector management strategy, yield loss in cotton crops is witnessed regularly. To ensure the timely application of management practices there is a dire need for a reliable prediction model that can forecast the CLCuD with high speed and accuracy. To overcome this problem, we developed and compared the machine learning (ML) techniques- multiple linear regression (MLR), bootstrap forest (BSF), boosted tree (BST) and artificial neural network (ANN) to predict CLCuD under field conditions. We investigated disease and weather data collected from four locations (host spots) for a period of nine years (2011–12 to 2019–20). During each season/year, 10 ecological variables including CLCuD disease incidence, severity data from ∼8000 plants on four cultivars (2000 each), and ecological factors at each location were recorded. Temperature data were transformed to growing degree days (GDD) and used for modeling as one of the most dependent factors. All data sets for training and validation sets were divided into the ratio of 75:25 for machine learning models. Results indicated that the BSF model was the best ML model with the highest R-squared value in terms of CLCuD prediction accuracy (R2training = 0.81 and R2validation = 0.64) for CLCuD prediction. ANN model with 14 hidden nodes achieved a slightly low R-squared value (R2training = 0.80 and R2validation = 0.79) having an architecture of (9:14:1) whereas, the BST model achieved the lowest R-squared value (R2training = 0.71 and R2validation = 0.59). The testing and validation of activation functions and various training and validation sets indicated that the BSF model is the best ML model. This can provide technical support for CLCuD prediction under field conditions through the designed graphical user interface and further advocate the timely application of management interventions to boost cotton productivity in the region.}
}
@article{QI2024102436,
title = {Applying 3D spatial metrics for landscape planning: Creating and measuring landscape scenarios by a point cloud-based approach},
journal = {Ecological Informatics},
volume = {79},
pages = {102436},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102436},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300465X},
author = {Jinda Qi and Ervine Shengwei Lin and Puay Yok Tan and Xudong Zhang and Roger Ho and Angelia Sia and Agnieszka Olszewska-Guizzo and Radha Waykool},
keywords = {3D spatial metrics, Quantitative landscape assessment, Restorative potential, Digital planning},
abstract = {The current planning and design process predominantly relies on experts' experiences or preferences, which is beneficial and straightforward but can be subjective and time-consuming. Although there are some quantitative assessment tools available to aid decision-makers in understanding the perceived quality of landscape scenarios, how to integrate them into the design thinking process to improve landscape design is challenging. This study presents a 3D digital model integrating the quantitative representation of visual quality into the design thinking process to improve urban landscapes' restorative potential. The model consists of generating landscape scenarios in a 3D environment, converting them into point clouds and voxelising them, quantitatively assessing the restorative potential, and interactively modifying landscape designs. To demonstrate the feasibility and effectiveness of the model, we have applied it to improve the restorative potential of a park in Singapore. The results show that the model provides a clear assessment of landscape scenarios and identifies specific areas needing improvement. The significance of this study lies in an innovative approach to generating and assessing the landscape scenario, ultimately enhancing the overall quality of landscapes during the digital planning and design process.}
}
@article{XIE2024102661,
title = {Forecasting China's agricultural carbon emissions: A comparative study based on deep learning models},
journal = {Ecological Informatics},
volume = {82},
pages = {102661},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102661},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002036},
author = {Tiantian Xie and Zetao Huang and Tao Tan and Yong Chen},
keywords = {Forecast, Agricultural carbon emissions, Deep learning, Long short-term memory neural network, Tree-structured Parzen estimator Bayesian optimization},
abstract = {Given the critical urgency to combat the escalating climate crisis and the continuous rise in agricultural carbon emissions (ACE) in China, accurately forecasting their future trends is crucial. This research employs the emission factor method to assess ACE throughout mainland China from 1993 to 2021. To refine our forecasting approach, both statistical and neural network methodologies were utilized to pinpoint key factors influencing ACE. We crafted forecasting models incorporating both deep learning techniques and traditional methods. Notably, the Tree-structured Parzen Estimator Bayesian Optimization (TPEBO) algorithm was applied to optimize Long Short-Term Memory (LSTM) neural networks, culminating in the creation of a superior integrated TPEBO-LSTM model that demonstrated strong performance across various datasets. The forecasting outcomes suggest that ACE in 24 provinces are expected to reach their zenith before 2030, primarily driven by farm operations, as well as livestock and poultry manure management. The result provides a significant forecasting tool for assessing agricultural carbon emissions in different regions, offering insights crucial for targeted mitigation strategies.}
}
@article{FORRESI2024102713,
title = {A data platform for real-time monitoring and analysis of the brown marmorated stink bug in Northern Italy},
journal = {Ecological Informatics},
volume = {82},
pages = {102713},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102713},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002553},
author = {Chiara Forresi and Enrico Gallinucci and Matteo Golfarelli and Lara Maistrello and Michele Preti and Giacomo Vaccari},
keywords = {, Integrated pest management, Data platform, Sustainable agriculture, Precision agriculture, Decision support system},
abstract = {The brown marmorated stink bug (Halyomorpha halys) is one of the main insect pest species causing economic damage to several agricultural commodities worldwide and one of the worst threats to tree fruit crops in northern Italy, especially in the Emilia-Romagna region. Previous efforts in implementing H. halys surveillance at the regional level were mainly focused on studying the H. halys phenology, but they were not designed to provide a public service. In this paper, we propose a data-driven approach to support the application of Integrated Pest Management strategies against H. halys. The proposal is based on the experience of a three-year project in which a network of monitoring traps has been deployed throughout the whole Emilia-Romagna region and a data platform has been implemented to enable the real-time tracking of H. halys occurrence and distribution, integrating these information with multiple data sources, and analytical capabilities through a public website. Besides the real-time pest surveillance, the data platform allowed us to increase our understanding about H. halys seasonal invasion dynamics and the main factors contributing to its spread. The results will help individual growers in protecting their crops and the whole region in promoting more efficient usage of insecticides and more sustainable and healthy agricultural productions.}
}
@article{PEREZGRANADOS2023101981,
title = {The sound of the illegal: Applying bioacoustics for long-term monitoring of illegal cattle in protected areas},
journal = {Ecological Informatics},
volume = {74},
pages = {101981},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.101981},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000109},
author = {Cristian Pérez-Granados and Karl-L. Schuchmann},
keywords = {Automated signal recognition, Autonomous recording units, Human activity, Kaleidoscope Pro, Livestock, Pantanal},
abstract = {Passive acoustic monitoring coupled with automated signal recognition software has been widely used in recent years as an effective and affordable tool for wildlife monitoring and to combat illegal activities within protected areas. Here, we evaluate this technique to monitor the patterns of illegal cattle occurrence in the Brazilian Pantanal over a complete annual cycle. We aim to provide one of the first assessments of the performance of automated signal recognition software to detect ungulates. Cattle occurrences reached their maximum during the end of the dry season when lowland areas provide excellent pastures for cattle. In contrast, cattle occurrences were very low during the rainy season when the study area was seasonally inundated. Automated software was an efficient tool that was able to detect approximately three-quarters of cow calls within the recordings. Passive acoustic monitoring can be used to direct patrols to areas where illegal activities, such as cattle and poaching or logging, have been confirmed, which could be a method that would be especially well suited for remote areas, such as tropical forests. Future studies should evaluate whether there is a relationship between cattle grazing intensity and its associated impacts on wildlife and flora. Rapid advances in automated recognition and the recent development of low-cost recorders foresee a new era of acoustic ecology for improved conservation in the short term.}
}
@article{JAMES2024102580,
title = {Monitoring vegetation patterns and their drivers to infer resilience: Automated detection of vegetation and megaherbivores from drone imagery using deep learning},
journal = {Ecological Informatics},
volume = {81},
pages = {102580},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102580},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001225},
author = {Rebecca K. James and Freek Daniels and Aneesh Chauhan and Pramaditya Wicaksono and Muhammad Hafizt and Setiawan Djody Harahap and Marjolijn J.A. Christianen},
keywords = {Semantic segmentation, Object detection, Pytorch, Seagrass, Drone imagery, Turtle monitoring, Conservation},
abstract = {Ecological pattern theory has highlighted spatial vegetation patterns that can be used as indicators of ecosystem resilience. Combining this spatial pattern theory with aerial imagery from drones and automated image processing with deep learning methods, we show how monitoring of natural ecosystems can be enhanced through quantifying vegetation spatial patterns. We demonstrate this approach in a tropical seagrass ecosystem with a high abundance of turtles that generate vegetation patches when grazing. Past field observations suggest that patch size and density reflect the seagrass meadow resilience, but understanding the natural variation in vegetation patchiness is crucial. Employing the deep learning methods of semantic segmentation and object detection, we quantify vegetation patchiness metrics and turtle distribution across 12 ha of seagrass meadow in the years 2012 and 2022. The resulting output facilitates spatial and temporal comparisons, revealing areas of low resilience. In 2012, turtle grazing across the entire site yielded vegetation patch sizes averaging 2 ± 0.2 m2 (95% confidence interval). Reduced patch sizes of 0.24 ± 0.05 m2 and 0.67 ± 0.6 m2 at the reef edge and beach slope respectively, in conjunction with a reduced patch density, indicated lower resilience at the seagrass meadow edges. Analysis of the 2022 dataset indicates a general decrease in patch size over time, suggesting declining resilience. A retraining experiment of the semantic segmentation model was conducted where the initial model was retrained on the 2022 dataset and demonstrated the adaptability of the deep learning methods. Despite using different equipment, the model achieved high accuracy with only 5–10 additional training images. By providing the tools to conduct these analyses, we aim to stimulate the uptake of deep learning for enhancing the data obtained from aerial imagery to improve the monitoring and conservation of natural ecosystems.}
}
@article{ZHANG2024102467,
title = {Marine zoobenthos recognition algorithm based on improved lightweight YOLOv5},
journal = {Ecological Informatics},
volume = {80},
pages = {102467},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102467},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000098},
author = {Lijun Zhang and Jiawen Fan and Yi Qiu and Zhe Jiang and Qingsong Hu and Bowen Xing and Jingxiang Xu},
keywords = {Ecological monitoring, Marine zoobenthos, Model lightweight, YOLOv5, EfficientnetV2, Bottleneck transformer},
abstract = {Detecting the distribution and density of marine zoobenthos is crucial for monitoring healthy coastal ecosystems and for growth reference tracking in precision aquaculture. However, current detection algorithms for marine zoobenthos have high computational complexity and cannot guarantee a balance between accuracy and speed, limiting their deployment in fishery equipment. This study used a portion of the Augmented Underwater Detection Dataset, a large underwater biological dataset containing marine zoobenthos data. A marine zoobenthos recognition algorithm was proposed for sea cucumbers, sea urchins, and scallops based on an improved lightweight YOLOv5, which can recognize the three types of marine zoobenthos. In the image enhancement module, an underwater image enhancement algorithm based on color balance and multi-input fusion is used, which turns the blurred image into a natural appearance of the seabed image. The lightweight backbone network EfficientnetV2-S was chosen to replace the original YOLOv5 backbone network, reducing network parameter calculations and improving recognition speed. A Bottleneck Transformer was introduced into the backbone network, and an attention mechanism based on the convolution module was introduced to construct the embedded Convolutional Block Attention Module in the Neck structure of YOLOv5, thereby improving the recognition accuracy of the lightweight YOLOv5 model. The experimental results showed that the mAP of the proposed algorithm reached 0.941, which is an improvement of 0.002 compared with the original YOLOv5l algorithm. The computation of this algorithm is 37.0 FLOPs (G), the model size is 54 MB, and the inference time is 5.9 ms. Compared to the original YOLOv5l algorithm, the reductions are 66.1%, 40.5%, and 39.2%. The proposed algorithm efficiently identified and classified marine zoobenthos.}
}
@article{DEROT2024102437,
title = {Improved climate time series forecasts by machine learning and statistical models coupled with signature method: A case study with El Niño},
journal = {Ecological Informatics},
volume = {79},
pages = {102437},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102437},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004661},
author = {Jonathan Derot and Nozomi Sugiura and Sangyeob Kim and Shinya Kouketsu},
keywords = {Signature method, El Niño, Random Forest model, Long-short-term-memory model, Lasso model, Partial dependence plot, Climate time series},
abstract = {The different phases of ENSO (El Niño Southern Oscillation) directly influence the occurrence of natural disasters and global warming. To limit the socio-economic impact, it is essential to develop simple and fast numerical models that can predict these different cycles. Here, we aimed to improve the predictive performance and extracting relevant information from climatic events by applying the signature method to time series models. After transforming the data using this signature method, we performed a comparative analysis of the statistical and machine learning models. In addition, we used PDP (Partial Dependence Plot) and SPRC (Standard Partial Regression Coefficient) to better understand the interactions between different climate indices. Our results showed that the best predictive performance was obtained when we use the signature method with the LSTM (R2 = 0.74) and Lasso (R2 = 0.79) models. Two complementary methods were used to highlight the influence of the following climate indices on ENSO cycle changes: NINO3, NINO3.4 and NPI (North Pacific Index). These methodologies also enabled us to determine the switchover thresholds, and order temporal variations. With this first application of the signature method to this type of time series, we obtained accurate forecasts on a 6-month scale with reduced computation time. This suggests that our methodology can be applied to many other fields of research that use multivariate time-series analyses.}
}
@article{KIM2024102576,
title = {Application of the domain adaptation method using a phenological classification framework for the land-cover classification of North Korea},
journal = {Ecological Informatics},
volume = {81},
pages = {102576},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102576},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001183},
author = {Joon Kim and Hyun-Woo Jo and Whijin Kim and Yujeong Jeong and Eunbeen Park and Sujong Lee and Moonil Kim and Woo-Kyun Lee},
keywords = {Land-cover mapping, Phenological classification, Domain adaptation, North Korea, Deep learning},
abstract = {Efforts to achieve carbon neutrality are global, encompassing a wide range of factors. For the estimation of greenhouse gas emissions from the agriculture, forestry, and other land use (AFOLU) sector, the Intergovernmental Panel on Climate Change has proposed an advanced method that requires Approach 3, the highest level of suggested method, of activity data. Accordingly, we propose a phenological classification framework (PCF) that can perform land-cover classification by training the climatic repeatability of the annual cycle using a U-Net deep learning model. Additionally, the domain adaptation (DA) method can be applied to classify areas with insufficient data. We applied these methods to classify North Korea (i.e., using South Korean data), with an accuracy of 81.31%; overall this effort culminated in the simultaneous classification of the Korean Peninsula. Domain distribution comparison showed that the results for the two regions were similar. The PCF and DA methods proposed in this study allow for annual production of a land-cover map and change matrix, regardless of the presence or absence of data. The application of these methods is expected to provide a scientific basis for policy decisions that can facilitate the global attainment of carbon neutrality.}
}
@article{LIU2024102401,
title = {YWnet: A convolutional block attention-based fusion deep learning method for complex underwater small target detection},
journal = {Ecological Informatics},
volume = {79},
pages = {102401},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102401},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004302},
author = {Pingzhu Liu and Wenbin Qian and Yinglong Wang},
keywords = {Underwater target detection, Deep learning, Feature fusion, Attention mechanism},
abstract = {Underwater target detection holds a noteworthy role in the field of marine exploration. However, it is difficult to extract useful feature information from blurred images with complex backgrounds, resulting in suboptimal and unsatisfactory target detection in conventional models. Among them, YOLOv5 leverages the advantages of fast detection performs better in detecting underwater samples. Nevertheless, YOLOv5 still faces difficulties including missed and incorrect detections due to the underwater environment's small scale of objects, dense distribution of organisms, and occlusion. To address these challenges, we propose a novel YoLoWaternet (YWnet) model that builds upon the YOLOv5 framework for complex underwater species detection with three main innovations: 1) A convolutional block attention module (CBAM) is introduced to enhance feature extraction for blurry images in the initial stages of the network and a new feature fusion network called the CRFPN is created to transfer important information and detect underwater targets. 2) A novel feature extraction module is presented, namely, the skip residual C3 module (SRC3), by effectively merging information from various scales to minimize the loss of original data during transmission. 3) Regression and classification algorithms are separated using the decoupled head to improve the effectiveness of detection and the EIoU loss function is employed to accelerate the convergence speed. Finally, the experimental results demonstrate that YWnet achieves remarkable accuracies of 73.2% mAp and 39.3% mAp50–95 on the underwater dataset, surpassing YOLOv5 by 2.3% and 2.4%, respectively. Furthermore, the proposed fusion model outperforms nine state-of-the-art baseline models on the undersea dataset and has generalization capabilities in other datasets.}
}
@article{RIVERAMUNOZ2022101775,
title = {Deep matrix factorization models for estimation of missing data in a low-cost sensor network to measure air quality},
journal = {Ecological Informatics},
volume = {71},
pages = {101775},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101775},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002254},
author = {L.M. Rivera-Muñoz and A.F. Giraldo-Forero and J.D. Martinez-Vargas},
keywords = {Deep matrix factorization - DMF, Information retrieval, Low-cost sensors network, Missing data},
abstract = {According to the WHO, pollution is a worldwide public health problem. In Colombia, low-cost strategies for air quality monitoring have been implemented using wireless sensor networks (WSNs), which achieve a better spatial resolution than traditional sensor networks for a lower operating cost. Nevertheless, one of the recurrent issues of WSNs is the missing data due to environmental and location conditions, hindering data collection. Consequently, WSNs should have effective mechanisms to recover missing data, and matrix factorization (MF) has shown to be a solid alternative to solve this problem. This study proposes a novel MF technique with a neural network architecture (i.e., deep matrix factorization or DMF) to estimate missing particulate matter (PM) data in a WSN in Aburrá Valley, Colombia. We found that the model that included spatial-temporal features (using embedding layers) captured the behavior of the pollution measured at each node more efficiently, thus producing better estimations than standard matrix factorization and other variations of the model proposed here.}
}
@article{JUNG2023102127,
title = {An integrated species distribution modelling framework for heterogeneous biodiversity data},
journal = {Ecological Informatics},
volume = {76},
pages = {102127},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102127},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001565},
author = {Martin Jung},
keywords = {Species distribution model, Data integration, Environmental niche, Offset, Point-process-model, Bayesian, R-package},
abstract = {Most knowledge about species and habitats is in-homogeneously distributed, with biases existing in space, time and taxonomic and functional knowledge. Yet, controversially the total amount of biodiversity data has never been greater. A key challenge is thus how to make effective use of the various sources of biodiversity data in an integrated manner. Particularly for widely used modelling approaches, such as species distribution models (SDMs), the need for integration is urgent, if spatial and temporal predictions are to be accurate enough in addressing global challenges. Here, I present a modelling framework that brings together several ideas and methodological advances for creating integrated species distribution models (iSDM). The ibis.iSDM R-package is a set of modular convenience functions that allows the integration of different data sources, such as presence-only, community survey, expert ranges or species habitat preferences, in a single model or ensemble of models. Further it supports convenient parameter transformations and tuning, data preparation helpers and allows the creation of spatial-temporal projections and scenarios. Ecological constraints such as projection limits, dispersal, connectivity or adaptability can be added in a modular fashion thus helping to prevent unrealistic estimates of species distribution changes. The ibis.iSDM R-package makes use of a series of methodological advances and is aimed to be a vehicle for creating more realistic and constrained spatial predictions. Besides providing convenience functions for a range of different statistical models as well as an increasing number of wrappers for mechanistic modules, ibis.iSDM also introduces several innovative concepts such as sequential or weighted integration, or thresholding by prediction uncertainty. The overall framework will be continued to be improved and further functionalities be added.}
}
@article{ZHANG2024102454,
title = {Research on the fine-scale spatial-temporal evolution characteristics of carbon emissions based on nighttime light data: A case study of Xi'an city},
journal = {Ecological Informatics},
volume = {79},
pages = {102454},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102454},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004831},
author = {Yao Zhang and Jing Quan and Yaqian Kong and Qian Wang and Yongjian Zhang and Yuxin Zhang},
keywords = {Multiscale carbon emission, NPP-VIIRS-like NTL data, Street (township) level, Standard deviation ellipse method},
abstract = {Carbon emissions have resulted in severe ecological damage, jeopardizing the very existence of humanity. In China, carbon emissions from urban areas contribute to 80% of the total carbon emissions, this significant contribution underscores the importance of addressing urban emissions. To gain insights into the spatial patterns of carbon emissions in urban areas at the fine-scale regional level, this study utilizes Xi'an as a case study, constructs a fine-scale regional carbon emission estimation model based on energy consumption and NPP-VIIRS-like NTL data, and quantifies multiscale carbon emissions from 2000 to 2021. Furthermore, global spatial autocorrelation, cold and hot spot analysis, and standard deviation ellipse analysis were used to investigate the spatial characteristics of carbon emissions at the street (township) level in Xi'an. This study revealed a sixfold increase in carbon emissions in Xi'an, rising from 51.35 million tons in 2000 to 281.95 million tons in 2021.The area affected by carbon emissions has expanded, with the centre of gravity of emission consistently shifting towards the south. The average street-level carbon emission density fluctuated and doubled compared to that in 2000. The total number of streets with low-carbon-emission-density decreased by 23%, indicating a shift away from low-carbon-emission-density streets. Furthermore, the global Moran's I index consistently remained within the range of 0.85–0.95, indicating significant spatial clustering, with cold spots expanding into surrounding districts and counties. Additionally, this study accurately identified carbon emissions within the city, offering the potential for the development of more precise carbon reduction strategies. Moreover, this approach can provide valuable support for the dynamic monitoring of carbon emissions in developing cities worldwide.}
}
@article{BOSSO2024102402,
title = {Integrating citizen science and spatial ecology to inform management and conservation of the Italian seahorses},
journal = {Ecological Informatics},
volume = {79},
pages = {102402},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102402},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004314},
author = {Luciano Bosso and Raffaele Panzuto and Rosario Balestrieri and Sonia Smeraldo and Maria Luisa Chiusano and Francesca Raffini and Daniele Canestrelli and Luigi Musco and Claudia Gili},
keywords = {Conservation biology, Ecological corridor, GIS analysis, Marine citizen science, Risk map, Seahorse, Species distribution model, Wildlife management},
abstract = {Citizen science and spatial ecology analyses can inform species distributions, habitat preferences, and threats in elusive and endangered species such as seahorses. Through a dedicated citizen science survey submitted to the Italian diving centers, we collected 115 presence records of the two seahorses occurring along the Italian coasts: Hippocampus hippocampus and H. guttulatus. From this dataset, we used 85 seahorse valitaded records to identify the ecological features of these two poorly known species and quantify the effects of human activities on their habitat suitability through geographic information systems and species distribution modelling. Our results indicated a continuous suitable area for both seahorses along the Italian coasts, with a single major gap in the central Adriatic Sea (Emilia-Romagna and Marche regions). They co-occurred in most of their Italian range, particularly in the central and southern Tyrrhenian coasts, and their ecological niches resulted to be significantly similar, although not equivalent. The least-cost paths of both species were concentrated in southern Italy (Apulia, Calabria, and Sicily), suggesting that more data is needed to improve the spatial resolution of the available information, especially in the northern and central Italy. Human activities influenced 38% and 42% of the habitat suitability of H. hippocampus and H. guttulatus, respectively, while only 25% and 30% of their potential distributions, respectively, are protected by Italy's existing conservation area system, in accordance with the global average for seahorses. In particular, the central Adriatic Sea represents a critical area where the occurrence of these seahorses is lower and the anthropic impact is higher. Considering all the Italian regions, fishing effort is the main human activity impacting both species. These findings will support the implementation of more efficient conservation actions. We encourage the application and interaction of citizen science and spatial ecology analyses to facilitate the assessment and sustainable management of elusive organisms.}
}
@article{ESTOPINAN2024102627,
title = {Mapping global orchid assemblages with deep learning provides novel conservation insights},
journal = {Ecological Informatics},
volume = {81},
pages = {102627},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102627},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001699},
author = {Joaquim Estopinan and Maximilien Servajean and Pierre Bonnet and Alexis Joly and François Munoz},
keywords = {Spatial indicator, Species assemblage, Deep learning, Species distribution modelling, IUCN status, Orchids},
abstract = {Although increasing threats on biodiversity are now widely recognised, there are no accurate global maps showing whether and where species assemblages are at risk. We hereby assess and map at kilometre resolution the conservation status of the iconic orchid family, and discuss the insights conveyed at multiple scales. We introduce a new Deep Species Distribution Model trained on 1 M occurrences of 14 K orchid species to predict their assemblages at global scale and at kilometre resolution. We propose two main indicators of the conservation status of the assemblages: (i) the proportion of threatened species, and (ii) the status of the most threatened species in the assemblage. We show and analyze the variation of these indicators at World scale and in relation to currently protected areas in Sumatra island. Global and interactive maps available online show the indicators of conservation status of orchid assemblages, with sharp spatial variations at all scales. The highest level of threat is found at Madagascar and the neighbouring islands. In Sumatra, we found good correspondence of protected areas with our indicators, but supplementing current IUCN assessments with status predictions results in alarming levels of species threat across the island. Recent advances in deep learning enable reliable mapping of the conservation status of species assemblages on a global scale. As an umbrella taxon, orchid family provides a reference for identifying vulnerable ecosystems worldwide, and prioritising conservation actions both at international and local levels.}
}
@article{GANJIRAD2024102498,
title = {Google Earth Engine-based mapping of land use and land cover for weather forecast models using Landsat 8 imagery},
journal = {Ecological Informatics},
volume = {80},
pages = {102498},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102498},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000402},
author = {Mohammad Ganjirad and Hossein Bagheri},
keywords = {LULC, GEE, WRF model, Machine learning, Classification, Landsat 8, Weather forecast},
abstract = {Land Use and Land Cover (LULC) maps are vital prerequisites for weather prediction models. This study proposes a framework to generate LULC maps based on the U.S. Geological Survey (USGS) 24-category scheme using Google Earth Engine. To realize a precise LULC map, a fusion of pixel-based and object-based classification strategies was implemented using various machine learning techniques across different seasons. For this purpose, feature importance analysis was conducted on the top classifiers considering the dynamic (seasonal) behavior of LULC. The results showed that ensemble approaches such as Random Forest and Gradient Tree Boosting outperformed other algorithms. The results also demonstrated that the object-based approach had better performance due to the consideration of contextual features. Finally, the proposed fusion framework produced a LULC map with higher accuracy (overall accuracy = 94.92% and kappa coefficient = 94.19%). Furthermore, the performance of the generated LULC map was assessed by applying it to the Weather Research and Forecasting (WRF) model for downscaling wind speed and 2-m air temperature (T2). The assessment indicated that the generated LULC map effectively reflected real-world conditions, thereby impacting the estimation of wind speed and T2 fields by WRF. Statistical assessments demonstrated enhancements in RMSE by 0.02 °C, MAE by 1 °C, and Bias by 0.03 °C for T2. Additionally, there was an improvement of 0.06 m/s in MAE for wind speed. Consequently, the framework can be implemented to produce accurate and up-to-date high-resolution LULC maps in various geographical areas worldwide. The source codes corresponding to this research paper are available on GitHub via https://github.com/Mganjirad/GEE-LULC-WRF.}
}
@article{QUASH2024102442,
title = {Assessing the impact of gold mining on forest cover in the Surinamese Amazon from 1997 to 2019: A semi-automated satellite-based approach},
journal = {Ecological Informatics},
volume = {80},
pages = {102442},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102442},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004715},
author = {Yann Quash and Angela Kross and Jochen A.G. Jaeger},
keywords = {Google Earth Engine, Artisanal and small-scale gold mining (ASGM), Classification and regression tree (CART), Deforestation, Forest phenology and fragmentation, Land use and land cover (LULC) classification},
abstract = {The Amazon rainforest has faced extensive deforestation for decades due to urban growth, agricultural expansion, logging and mining. Mining however has been relatively understudied in the Amazon. The objectives of this study were: (1) to develop an effective cloud-based classification approach coupled with an innovative semi-automated reclassification method; (2) to quantify the mining extent and its impacts on forest cover in Suriname from 1997 to 2019; and (3) to evaluate the impact of mining on the structure and health of the forest. Landsat 5 and 8 images were used for the initial land-use/land-cover classification using the classification and regression trees algorithm in Google Earth Engine. The resulting classified maps were reclassified in a semi-automated model to correct misclassifications between mining and urban pixels. The final maps were used to analyse the expansion of mining and its impacts on forest cover, structure (using the fragmentation metric effective mesh size), and forest health (using the phenology metric peak greenness). The combined approach resulted in an improvement in mining detection accuracy from 72% (65% producer, 79% user) to 89.5% (84% producer accuracy, 95% user). The results showed that mining increased from 69.4 km2 in 1997 to 431.6 km2 in 2019, an increase by 522% over 22 years, which led to 421.3 km2 of forest loss, of which 85% was due to artisanal and small-scale mining (ASGM). The loss of forest for ASGM resulted in greater fragmentation, with a decrease in effective mesh size by 122.8 km2 compared to a decrease by 83 km2 caused by industrial mining. Mining also caused a decrease in the health of the surrounding forest, with a larger decrease in peak greenness due to ASGM compared to industrial mining. The results demonstrate the potential of this approach that leverages cloud-based machine learning with a semi-automated reclassification to allow for rapid, accurate, and potentially global mining detection.}
}
@article{KANG2024102482,
title = {A deep learning-based biomonitoring system for detecting water pollution using Caenorhabditis elegans swimming behaviors},
journal = {Ecological Informatics},
volume = {80},
pages = {102482},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102482},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000244},
author = {Seung-Ho Kang and In-Seon Jeong and Hyeong-Seok Lim},
keywords = {, Biomonitoring system, Water pollution, Water pollutant, Long short-term memory model, Branch length similarity entropy},
abstract = {Caenorhabditis elegans is a representative organism whose DNA structure has been fully elucidated. It has been used as a model organism for various analyses, including genetic functional analysis, individual behavioral analysis, and group behavioral analysis. Recently, it has also been studied as an important bioindicator of water pollution. In previous studies, traditional machine learning methods, such as the Hidden Markov Model (HMM), were used to determine water pollution and identify pollutants based on the differences in the swimming behavior of C. elegans before and after exposure to chemicals. However, these traditional machine learning models have low accuracy and a relatively high false-negative rate. This study proposes a method for detecting water pollution and identifying the types of pollutants using the Long Short-Term Memory (LSTM) model, a deep learning model suitable for time-series data analysis. The swimming activities of C. elegans in each of the image frames are characterized by the Branch Length Similarity (BLS) entropy profile. These BLS entropy profiles are converted into input vectors through additional preprocessing using two clustering methods. We conduct experiments using formaldehyde and benzene at 0.1 mg/L each, with observation time intervals varying from 30 to 180 s. The performance of the proposed method is compared with that of the previously proposed HMM approach and variants of LSTM models, such as Gated Recurrent Unit (GRU) and Bidirectional LSTM (BiLSTM).}
}
@article{DELCASTILLO2024102655,
title = {Improving river water quality prediction with hybrid machine learning and temporal analysis},
journal = {Ecological Informatics},
volume = {82},
pages = {102655},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102655},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001973},
author = {Alberto Fernández {del Castillo} and Marycarmen Verduzco Garibay and Diego Díaz-Vázquez and Carlos Yebra-Montes and Lee E. Brown and Andrew Johnson and Alejandro Garcia-Gonzalez and Misael Sebastián Gradilla-Hernández},
keywords = {Water Quality Index, Highly polluted river, Time series analysis, Cluster analysis, Monitoring network, Data Science},
abstract = {River systems provide multiple ecosystem services to society globally, but these are already degraded or threatened in many areas of the world due to water quality issues linked to diffuse and point-source pollutant inputs. Water quality evaluation is essential to develop remediation and management strategies. Computational tools such as machine learning based predictive models have been developed to improve monitoring network capabilities. The model's performance is reduced when datasets composed of reductant information are used for training, on the other hand, the selection of most representative and variable water quality scenarios could result in higher precision. This study analyzed historical water quality behavior in the Santiago River, Mexico, to identify the most variable and representative data available to train machine learning models (Adaptive Neuro Fuzzy Inference System – ANFIS, Artificial Neural Network – ANN, and Support Vector Machine - SVM). Thirteen monitoring sites were clustered according to their water quality variability from 2009 to 2022. Subsequently, a Time Series Analysis (TSA) was used to select the most representative monitoring station from each cluster. Data for 6/13 monitoring sites were retained for the Best Training Subset (BTS) used to train restricted models that performed with similar (ANN and SMV) or higher (ANFIS) prediction accuracy (in terms of RMSE, MAE, MSE and R2) for both training and testing. This study provides evidence of water quality data containing redundant information that is not useful to improve machine learning model performance, in turn leading to overtraining. Combined analytical approaches can maximize the representativeness and variability of data selected for machine learning applications, leading to improved prediction.}
}
@article{BAKHT2024102631,
title = {MuLA-GAN: Multi-Level Attention GAN for Enhanced Underwater Visibility 11⁎First two authors has equal contribution⋆github code link:https://github.com/AhsanBaidar/MuLAGAN.git ORCID (s): 0000–0002–9079-0960 (A.B. Bakht); 0000–0001–9789-8483 (Z. Jia); 0000–0001–6214-1077 (M.U. Din); 0000–0002–7401-5120 (W. Akram); 0000–0003–4445-3135 (L.S. Saoud); 0000–0001–6405-8402 (L. Seneviratne); 0000–0001–6432-5187 (S. He); 0000–0003–2759-0306 (I. Hussain)},
journal = {Ecological Informatics},
volume = {81},
pages = {102631},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102631},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001730},
author = {Ahsan B. Bakht and Zikai Jia and Muhayy Ud Din and Waseem Akram and Lyes Saad Saoud and Lakmal Seneviratne and Defu Lin and Shaoming He and Irfan Hussain},
keywords = {Underwater image enhancement, Generative adversarial networks (GANs), Spatio-channel attention, Computer vision, Real-time image processing},
abstract = {The underwater environment presents unique challenges (color distortions, reduced contrast, blurriness) hindering accurate analysis. This work introduces MuLA-GAN, a novel approach leveraging Generative Adversarial Networks (GANs) and specifically adapted Multi-Level Attention for comprehensive underwater image enhancement. MuLA-GAN integrates Multi-Level Attention within the GAN architecture to prioritize learning discriminative features crucial for precise image restoration. These relevant features encompass information on local details within image regions leveraged by spatial attention and features at various scales across the entire image captured by multi-level attention. This allows MuLA-GAN to identify and enhance objects, textures, and edges obscured by underwater distortions while also reconstructing a more accurate and visually clear representation of the underwater scene by analyzing low-level information like edges and textures, as well as high-level information like object shapes and global scene information. By selectively focusing on these relevant features, MuLA-GAN excels at capturing and preserving intricate details in underwater imagery, which is essential for various marine research, exploration, and resource management applications. Extensive evaluations on diverse datasets (UIEB test, UIEB challenge, U45, UCCS) demonstrate MuLA-GAN's superior performance compared to existing methods. Additionally, a specialized bio-fouling and aquaculture dataset confirms the model's robustness in challenging environments. On the UIEB test dataset, MuLA-GAN achieves exceptional Peak Signal-to-Noise Ratio (PSNR) (25.59) and Structural Similarity Index (SSIM) (0.893) scores, surpassing Water-Net (24.36 PSNR, 0.885 SSIM). This work addresses a significant research gap in underwater image enhancement by demonstrating the effectiveness of combining GANs with specifically adapted Multi-Level Attention mechanisms. This tailored approach offers a novel and comprehensive framework for restoring underwater image quality, providing valuable insights for accurate underwater scene analysis. The source code for MuLA-GAN is publicly available on GitHub at https://github.com/AhsanBaidar/MuLA_GAN.git}
}
@article{LARSEN2021101290,
title = {Online computational ethology based on modern IT infrastructure},
journal = {Ecological Informatics},
volume = {63},
pages = {101290},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101290},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000819},
author = {Leon B. Larsen and Mathias M. Neerup and John Hallam},
keywords = {Bioacoustics, Recording, Automated annotation},
abstract = {In the study of animal behaviour, annotation and analysis is largely done manually either directly in the field or from recordings. An emerging field, computational ethology, is challenging this approach by using machine learning to automate the process. However, the use of such methods in general is complicated by a lack of modularity, leading to high cost and long development times. At the same time, the benefits of implementing a fully automated pipeline are often minuscule. We propose online analysis as a way to gain more from automating the process, such as making it easier to ensure that equipment is properly configured and calibrated, enabling the recording equipment to follow the animals, and even enabling closed-loop experiments. In this work, we discuss the requirements and challenges for such a system and propose an implementation based on modern IT infrastructure. Finally, we demonstrate the system in case studies of bats and mongoose. As more and more methods and algorithms are developed we expect online systems to enable new experimental setups to study behaviour, leading to new insights in the field.}
}
@article{JOLLIFFE2024102410,
title = {Tracking pygmy blue whales in the Perth Canyon using passive acoustic observatories},
journal = {Ecological Informatics},
volume = {79},
pages = {102410},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102410},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004399},
author = {Capri D. Jolliffe and Robert D. McCauley and Alexander N. Gavrilov and Curt Jenner and Micheline N. Jenner},
keywords = {Blue whale, Bioacoustics, Acoustic localisation, Acoustic tracking},
abstract = {Eastern Indian Ocean pygmy blue (EIOPB) whales were localised and tracked through the Perth Canyon area utilising a passive acoustic tracking array. Vocalising animals were tracked using the Type II unit of the EIOPB whale song across recordings for an average of 109.3 min (95% CI ± 27 min), suggesting that animals move slowly through the array area. Comparisons of the distribution of animals between sample years revealed non-uniform distribution of animals suggesting that environmental variables may drive pygmy blue whale spatial distribution within foraging areas. Analysis of the movement patterns of acoustically tracked animals found that animals tracked between January and early March generally exhibited directional movement while singing animals tracked between March and May exhibited directional and milling movement patterns, indicating that they may be foraging, and thus that animals may sing between feeding bouts. Comparisons of visual and acoustic localisations found animals appeared to utilise similar areas around the passive acoustic receiver array on days where survey effort overlapped, though acoustic survey methods returned consistently higher numbers of detections. Further, acoustic and visual detections of animals within the same day were not within the same location highlighting the need for holistic studies of species habitat utilisation. The inclusion of in-situ environmental data collection in the design of future acoustic tracking studies would be valuable to understand whether there is a link between environmental factors at the local scale and the localised movement of whales around the listening area.}
}
@article{AZEDOU2023102333,
title = {Enhancing Land Cover/Land Use (LCLU) classification through a comparative analysis of hyperparameters optimization approaches for deep neural network (DNN)},
journal = {Ecological Informatics},
volume = {78},
pages = {102333},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102333},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300362X},
author = {Ali Azedou and Aouatif Amine and Isaya Kisekka and Said Lahssini and Youness Bouziani and Said Moukrim},
keywords = {Deep learning, Optimization algorithms, Image processing, Remote sensing, Land-use and land-cover classification, Google Earth Engine},
abstract = {Sustainable natural resources management relies on effective and timely assessment of conservation and land management practices. Using satellite imagery for Earth observation has become essential for monitoring land cover/land use (LCLU) changes and identifying critical areas for conserving biodiversity. Remote Sensing (RS) datasets are often quite large and require tremendous computing power to process. The emergence of cloud-based computing techniques presents a powerful avenue to overcome computing limitations by allowing machine-learning algorithms to process and analyze large RS datasets on the cloud. Our study aimed to classify LCLU for the Talassemtane National Park (TNP) using a Deep Neural Network (DNN) model incorporating five spectral indices to differentiate six land use classes using Sentinel-2 satellite imagery. Optimization of the DNN model was conducted using a comparative analysis of three optimization algorithms: Random Search, Hyperband, and Bayesian optimization. Results indicated that the spectral indices improved classification between classes with similar reflectance. The Hyperband method had the best performance, improving the classification accuracy by 12.5% and achieving an overall accuracy of 94.5% with a kappa coefficient of 93.4%. The dropout regularization method prevented overfitting and mitigated over-activation of hidden nodes. Our initial results show that machine learning (ML) applications can be effective tools for improving natural resources management.}
}
@article{YIN2024102450,
title = {Automatic detection of stereotypical behaviors of captive wild animals based on surveillance videos of zoos and animal reserves},
journal = {Ecological Informatics},
volume = {79},
pages = {102450},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102450},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300479X},
author = {Zixuan Yin and Yaqin Zhao and Zhihao Xu and Qiuping Yu},
keywords = {Stereotypical behavior, Captive animal, Animal welfare, Animal tracking, Siamese network, Motion trajectory},
abstract = {The timely detection of the depressive and stereotypical behaviors often observed in captive wild animals and the subsequent intervention can contribute to improving their living environment in enclosures, which is crucial for safeguarding animal welfare, enhancing animal husbandry practices, regulating human–animal relationships. Several studies have analyzed factors that influence animal stereotypical behaviors and identified preventive measures via regular animal observations. An automatic detection method based on video technology can yield long-term automatic recordings of motion trajectories of animals after a professionally trained automatic detection software is integrated into the human–machine interaction operation interface of animal management. As an initial exploration of this research paradigm, we propose a novel method for automatically tracking and recognizing the stereotypical behavior of animals in surveillance videos based on the periodic analysis of motion trajectories. First, we introduced a Siamese relation network to track the motion trajectories of animals. This network accurately tracked animals and distinguished different individuals in complex environments. Second, an autocorrelation function was used to analyze the periodicity of the motion trajectory, which was divided into several periodic curves. Finally, a cross-correlation function was introduced to determine the linear correlation between the two variables of the periodic curves. This function distinguished the three types of motion trajectories. The success rate and precision of the animal-tracking method adopted in this study were 67.4% and 90.4%, respectively, which were superior to those of common Siamese tracking networks. The average prediction error of the cycle time was 0.095 s. Therefore, the proposed method can accurately track the motion trajectories of animals and identify their stereotypical behaviors. Furthermore, this study provides data to facilitate the scientific management of animals and improve animal welfare. The codes and datasets used in the study are available at https://github.com/yinyinzixuan/animal-stereotypical-behavior.git.}
}
@article{FLORES2024102481,
title = {Applying machine learning to predict reproductive condition in fish},
journal = {Ecological Informatics},
volume = {80},
pages = {102481},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102481},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000232},
author = {Andrés Flores and Rodrigo Wiff and Carl R. Donovan and Patricio Gálvez},
keywords = {Histology, Gonadosomatic index, Maturity, Random forest,  gayi},
abstract = {Knowledge of reproductive traits in exploited marine populations is crucial for their management and conservation. The maturity status in fish is usually assigned by traditional methods such as macroscopy and histology. Macroscopic analysis is the assessing of maturity stages by naked eye and usually introduces large amount of error. In contrast, histology is the most accurate method for maturity staging but is expensive and unavailable for many stocks worldwide. Here, we use the Random Forest (RF) machine learning method for classification of reproductive condition in fish, using the extensive data from Chilean hake (Merluccius gayi gayi). Gonads randomly collected from commercial industrial and acoustic surveys were classified as immature, mature-active and mature-inactive. A classifier for these three maturity classes was fitted using RFs, with the continuous covariates total length (TL), gonadosomatic index (GSI), condition factor (Krel), latitude, longitude, and depth, along with month as a factor variable. The RF model showed high accuracy (>82%) and high proportion of agreement (>71%) compared to histology, with an OOB error rate lower than 15%. GSI and TL were the most important variables for predicting the reproductive condition in Chilean hake, and to lesser extent, depth when using survey data. The application of the RF shows a promising tool for assigning maturity stages in fishes when covariates are available, and also to improve the accuracy of maturity classification when only macroscopic staging is available.}
}
@article{CELIS2024102578,
title = {A versatile, semi-automated image analysis workflow for time-lapse camera trap image classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102578},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102578},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001201},
author = {Gerardo Celis and Peter Ungar and Aleksandr Sokolov and Natalia Sokolova and Hanna Böhner and Desheng Liu and Olivier Gilg and Ivan Fufachev and Olga Pokrovskaya and Rolf Anker Ims and Wenbo Zhou and Dan Morris and Dorothee Ehrich},
keywords = {Arctic wildlife monitoring, Deep learning, ResNet-50, MegaDetector, Time-lapse camera},
abstract = {Camera traps are a powerful, practical, and non-invasive method used widely to monitor animal communities and evaluate management actions. However, camera trap arrays can generate thousands to millions of images that require significant time and effort to review. Computer vision has emerged as a tool to accelerate this image review process. We propose a multi-step, semi-automated workflow which takes advantage of site-specific and generalizable models to improve detections and consists of (1) automatically identifying and removing low-quality images in parallel with classification into animals, humans, vehicles, and empty, (2) automatically cropping objects from images and classifying them (rock, bait, empty, and species), and (3) manually inspecting a subset of images. We trained and evaluated this approach using 548,627 images from 46 cameras in two regions of the Arctic: “Finnmark” (Finnmark County, Norway) and “Yamal” (Yamalo-Nenets Autonomous District, Russia). The automated steps yield image classification accuracies of 92% and 90% for the Finnmark and Yamal sets, respectively, reducing the number of images that required manual inspection to 9.2% of the Finnmark set and 3.9% of the Yamal set. The amount of time invested in developing models would be offset by the time saved from automation after 960 thousand images have been processed. Researchers can modify this multi-step process to develop their own site-specific models and meet other needs for monitoring and surveying wildlife, balancing the acceptable levels of false negatives and positives.}
}
@article{MORERA2024102557,
title = {Analysis of climate change impacts on the biogeographical patterns of species-specific productivity of socioeconomically important edible fungi in Mediterranean forest ecosystems},
journal = {Ecological Informatics},
volume = {81},
pages = {102557},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102557},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000992},
author = {Albert Morera and Hannah LeBlanc and Juan {Martínez de Aragón} and José Antonio Bonet and Sergio de-Miguel},
keywords = {Mushroom, , , Non-wood forest products, Global warming, Modeling},
abstract = {In Mediterranean forests, many species of fungi produce fruiting bodies every autumn, some of which are of great social and economic interest as NTFPs. In addition, these fungi are an essential part of the biodiversity network that ensures the proper functioning of natural ecosystems and that is currently in check due to global change. Therefore, understanding the biogeographic patterns of species-specific fungal productivity is fundamental to anticipate possible changes in the socioeconomic value of our forests and to understand the role they play in the functioning of ecosystems in terms of mitigation and adaptation to climate change. In this study we estimate the future impact of climate change (in Catalonia region, between 2023 and 2100) on five fungal species with high socioeconomic interest in a broad bioclimatic gradient representative of the Mediterranean basin using high resolution at the landscape scale. To achieve this, we use predictive models based on machine learning algorithms and a fungal database resulting from the sampling of more than 100 permanent sampling plots over 20 years. We estimate that current and future productivity patterns differ among species, under different climate change scenarios and bioclimatic regions. Our results suggest that optimal productivity areas may be shifted to higher elevations, making those species with higher productivity at higher elevations the most affected by climate change. This would mean that some species with high socioeconomic value, such as Lactarius deliciosus and Boletus edulis, could be negatively affected in their total productivity in the study area. This study highlights the need to anticipate the potential effects of climate change on fungal productivity and in particular on high socioeconomic value species and to develop management policies oriented to maintain the important role of fungi in natural ecosystems.}
}
@article{CHEN2024102465,
title = {Exploring the association between the built environment and positive sentiments of tourists in traditional villages in Fuzhou, China},
journal = {Ecological Informatics},
volume = {80},
pages = {102465},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102465},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000074},
author = {Zhengyan Chen and Honghui Yang and Yishan Lin and Jiahui Xie and Yuanqin Xie and Zheng Ding},
keywords = {Traditional village, Tourist sentiments, Built environment, Natural language processing, Machine learning},
abstract = {Promoting positive emotional experiences for tourists is crucial for sustaining development in rural areas. However, existing research has limited focus on the rural built environment, particularly in developing a framework to evaluate environmental sentiment on a small to medium scale with detailed indicators. This study addresses this gap by examining the impact of the rural built environment on tourists' emotions. Natural Language Processing (NLP) technologies are employed to analyze web text data and determine the average sentiment index for traditional villages in Fuzhou, China. Additionally, data on the built environment were acquired through the HRnet segmentation model and Matlab. To assess the association between environmental indicators and the sentiment index, we used eXtreme Gradient Boosting (XGBoost), the SHapley Additive exPlanation (SHAP) model, and ArcMap software. The study demonstrated that (1) the spatial distribution of the average sentiment index was significant. Houfu Village (9.91), Qianhu Village (9.88), and Ximen Village (9.75) had the highest scores, while Doukui Village (−0.85), Jiji Village (0.2), and Qiaodong Village (0.55) had the lowest. (2) The indicators that have the most significant impact on sentiment are Openness, Greenness, and Color Complexity, with a contribution value above 0.7—followed by Enclosure, Visual Entropy, and Ground Exposure, with a contribution between 0.5 and 0.7. Furthermore, analyzing the interaction mechanism of the indicators showed a non-linear relationship. The environmental characteristics associated with high emotional index scores are openness in the range of 0.2 to 0.5, greenness in the range of 0.4 to 0.6, and color complexity in the range of 0.3 to 0.5. This study provides observations pertinent to the sustainable development of traditional village environments. The findings contribute to an understanding of how these environmental elements might be effectively designed to improve tourists' sentiment in rural settings.}
}
@article{ZHANG2024102517,
title = {Automatic bioacoustics noise reduction method based on a deep feature loss network},
journal = {Ecological Informatics},
volume = {80},
pages = {102517},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102517},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000591},
author = {Chengyun Zhang and Kaiying He and Xinghui Gao and Yingying Guo},
keywords = {Bioacoustics, Noise reduction, Deep learning, Deep feature loss network},
abstract = {Acoustic sensors that collect acoustic data over extended periods and broad ranges are widely used in bioacoustics monitoring. However, in open environments, acoustic data collected using acoustic sensors can be subject to interference from various real-world noises, thereby influencing the subsequent analysis and processing of bioacoustic data. Existing bioacoustic noise reduction methods are limited in their application because of their low efficiency, unsuitability for non-stationary noise, generally unimproved signal-to-noise ratio (SNR) efficacy, and considerable amounts of residual noise. These limitations hinder the effective processing of recorded signals for which extraneous noise overlaps with bird vocalizations. In this study, we propose a bioacoustic noise reduction method based on a deep feature loss network for bird sounds. The method has a rapid denoising speed and can more effectively remove background noise from field recording signals without distorting the bird acoustic spectrum. The denoising effects of the proposed method were compared with those of a speech enhancement generative adversarial network, web real-time communications denoising, and other noise reduction methods. The denoising ability of these methods for different noises was evaluated using spectrograms and objective evaluation measures such as the SNR and perceptual evaluation of speech quality (PESQ). The experimental results revealed that our proposed noise reduction method can obtain higher SNRs and PESQ scores than other noise reduction methods, with the SNR increasing by up to 35.83 dB following denoising.}
}
@article{ZHANG2024102399,
title = {Fully automatic system for fish biomass estimation based on deep neural network},
journal = {Ecological Informatics},
volume = {79},
pages = {102399},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102399},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004284},
author = {Tianye Zhang and Yuqiao Yang and Yueyue Liu and Chenglei Liu and Ran Zhao and Daoliang Li and Chen Shi},
keywords = {Aquaculture, Mass estimation, Neural network, Sustainable production},
abstract = {The approach for estimating biomass in non-contact, free-swimming fish has encountered difficulties such as fish body occlusion, bending, non-orthogonal angles, and low efficiency. To address these issues, this study had combined fish posture recognition (using deep learning technology) with biomass estimation (utilizing stereo vision technology) for the first time, and developed a fast, precise, and fully automatic fish biomass estimation system. The improved single-stage target detection algorithm significantly improved the direct detection and extraction of high-quality images of moving fish in real-time, eliminating the need for manual processing of images that may have imperfect posture. Fish body length and height were measured in the real world using binocular stereo vision technology. Finally, the fish body weight can be estimated by considering the relationship among their body length, height, and weight. The experiment confirmed that the system had successfully avoided influencing factors that could affect fully automatic estimation. The results demonstrated a strong linear relationship between the estimated and measured fish body weights, with a mean relative error (MRE) of 2.87%. There were no significant differences between the estimated and measured weights (p = 0.94). The MRE of the multi-factor model was much lower than that of the single-factor model (length-weight of 8.86% and height-weight of 7.41%). The results indicate that the system developed is a highly effective approach to fully automated biomass estimation. This can be used to guide actual production and further study of the mechanism of fish growth.}
}
@article{YANG2024102477,
title = {Deep learning-based air pollution analysis on carbon monoxide in Taiwan},
journal = {Ecological Informatics},
volume = {80},
pages = {102477},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102477},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000190},
author = {Cheng-Hong Yang and Po-Hung Chen and Chih-Hsien Wu and Cheng-San Yang and Li-Yeh Chuang},
keywords = {Air pollution, Carbon Monoxide (CO), Deep learning, Seasonal gated recurrent unit (SGRU)},
abstract = {Global air pollution poses a threat to humanity. Specifically, CO directly affects cardiovascular and other organ tissues and leads to numerous chronic diseases and major public health problems. The effective implementation of a deep learning model for predicting variations in CO levels would enable the early formulation of policies for controlling air pollution. In this study, a seasonal gated recurrent unit (SGRU) model, which is a deep learning time-series prediction model, was developed to predict the levels of CO in Taiwan. Atmospheric CO measurements from 2005 to 2021 were collected from the Environmental Protection Administration of Taiwan and preprocessed using the Kalman filter to achieve accurate forecasting. The performance of the proposed SGRU model was compared with that of the autoregressive integrated moving average (ARIMA), seasonal ARIMA, exponential smoothing (ETS), Holt–Winters ETS, support vector regression, and seasonal long short-term memory models in terms of mean absolute percentage error (MAPE) and root mean square error. The SGRU model achieved the lowest MAPE value of 0.94, which demonstrated its superior performance. The construction of an accurate air pollution prediction model can assist government entities in formulating health and social care strategies and in planning future air pollution control measures.}
}
@article{RIECHMANN2022101657,
title = {Motion vectors and deep neural networks for video camera traps},
journal = {Ecological Informatics},
volume = {69},
pages = {101657},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101657},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122001066},
author = {Miklas Riechmann and Ross Gardiner and Kai Waddington and Ryan Rueger and Frederic Fol Leymarie and Stefan Rueger},
keywords = {AI, Computer vision, Machine learning, Motion vectors, Video camera trap, Video pipeline},
abstract = {Commercial camera traps are usually triggered by a Passive Infra-Red (PIR) motion sensor necessitating a delay between triggering and the image being captured. This often seriously limits the ability to record images of small and fast moving animals. It also results in many “empty” images, e.g., owing to moving foliage against a background of different temperature. In this paper we detail a new triggering mechanism based solely on the camera sensor. This is intended for use by citizen scientists and for deployment on an affordable, compact, low-power Raspberry Pi computer (RPi). Our system introduces a video frame filtering pipeline consisting of movement and image-based processing. This makes use of Machine Learning (ML) feasible on a live camera stream on an RPi. We describe our free and open-source software implementation of the system; introduce a suitable ecology efficiency measure that mediates between specificity and recall; provide ground-truth for a video clip collection from camera traps; and evaluate the effectiveness of our system thoroughly. Overall, our video camera trap turns out to be robust and effective.}
}