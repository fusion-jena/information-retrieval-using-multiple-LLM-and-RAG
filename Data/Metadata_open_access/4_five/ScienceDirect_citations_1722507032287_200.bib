@article{CORO2024102644,
title = {Climate change effects on animal presence in the Massaciuccoli Lake basin},
journal = {Ecological Informatics},
volume = {81},
pages = {102644},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102644},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001869},
author = {Gianpaolo Coro and Pasquale Bove and Ilaria Baneschi and Andrea Bertini and Lorenzo Calvisi and Antonello Provenzale},
keywords = {Ecological niche modelling, Species richness, Wetlands, Artificial intelligence, Open Science, Maximum entropy},
abstract = {Big-data mining approaches based on Artificial Intelligence models can help forecast biodiversity changes before they happen. These approaches can predict macroscopic species distribution patterns and trends that can inform preventive measures to avoid the loss of ecosystem functions and services. They can, therefore, help study and mitigate climate change implications on biodiversity conservation in fragile ecosystems. Wetlands are particularly fragile ecosystems where climate change poses severe risks and has dramatically reduced their size over the past century, with profound consequences on biodiversity and ecosystem services. Through big-data mining approaches, we can predict future wetland biodiversity trends in the context of climate change. This paper proposes such predictive analysis for a specific wetland: The Massaciuccoli Lake basin in Tuscany, Italy. This basin is a critical tourist attraction due to its rich biodiversity, making it an area of interest for citizens, tourists, and scientists. However, the region's suitability for native and non-native species is at risk due to climate and land-use change. Using machine-learning models, we predict the potential effects of climate change on animal spatial distribution in the basin under different greenhouse gas emission scenarios. The results suggest that habitat suitability has generally improved from 1950 to today, presumably owing to the targeted conservation strategies adopted in the area, but climate change will severely reduce bird biodiversity by 2050 while favouring several insect species' proliferation and other species' habitat change, even under a medium-emission scenario. This will lead to significant changes in the basin's biodiversity. Our methodology is adaptable to other wetland basins, being fully based on open data and models. The spatially explicit modelling used in this research provides valuable information for policymakers and spatial planners, complementing traditional biodiversity trend analyses.}
}
@article{AYUSHI2024102479,
title = {A comparative analysis of machine learning techniques for aboveground biomass estimation: A case study of the Western Ghats, India},
journal = {Ecological Informatics},
volume = {80},
pages = {102479},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102479},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000219},
author = {Kurian Ayushi and Kanda Naveen Babu and Narayanan Ayyappan and Jaishanker Raghunathan Nair and Athira Kakkara and C. Sudhakar Reddy},
keywords = {Climate, Remote sensing, Field data, Soil, Topography, Tropical forest, Uncertainty},
abstract = {Accurate assessment of aboveground biomass (AGB) in tropical forests, particularly within a biodiversity hotspot, is vital for sustainable resource management and the preservation of ecosystems. However, estimating AGB in tropical forests is complex due to the diverse and intricate nature of vegetation, necessitating the integration of data from multiple sources. To tackle this challenge, our study utilized seven machine learning algorithms to analyze various combination of multisource datasets. We developed seven models/scenarios that incorporated Sentinel-1, Sentinel-2 as well as environmental factors such as topography, soil and climate to identify key variables for accurate estimation of AGB. For optimal performance, hyperparameters of the algorithms were fine-tuned through 10-fold cross-validation and their accuracy were assessed using the testing dataset. We found that the integrated model of satellite datasets, topography, climate, and soil variables exhibited the highest accuracy, where ensemble stacking, that combined multiple MLAs, proved to be reliable and best suited for predicting AGB (mean absolute error-3.97 Mg 0.1 ha−1, root mean square error-5.67 Mg 0.1 ha−1, and coefficient of determination - 0.82). Notably, the top predictor variables included Sentinel-2 bands (near infrared and green), soil properties (pH and soil organic carbon), and topography (elevation). The study emphasizes the significance of incorporating environmental variables (specifically topography and soil properties) along with Sentinel datasets to improve the accuracy of AGB estimation. This approach has the potential for broader applications, specifically in regions where vegetation productivity is governed by diverse environmental conditions.}
}
@article{WANG2024102538,
title = {Hierarchical-taxonomy-aware and attentional convolutional neural networks for acoustic identification of bird species: A phylogenetic perspective},
journal = {Ecological Informatics},
volume = {80},
pages = {102538},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102538},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000803},
author = {Qingyu Wang and Yanzhi Song and Yeqian Du and Zhouwang Yang and Peng Cui and Binnan Luo},
keywords = {Bioacoustics, Bird sound recognition, Hierarchical architecture, Attention module, Path correction},
abstract = {The study of bird populations is crucial for biodiversity research and conservation. Deep artificial neural networks have revolutionized bird acoustic recognition; however, most methods overlook inherent relationships among bird populations, resulting in the loss of biological information. To address this limitation, we propose the Phylogenetic Perspective Neural Network (PPNN), which incorporates hierarchical multilevel labels for each bird. PPNN uses a hierarchical semantic embedding framework to capture feature information at different levels. Attention mechanisms are employed to extract and select common and distinguishing features, thereby improving classification accuracy. We also propose a path correction strategy to rectify inconsistent predictions. Experimental results on bird acoustic datasets demonstrate that PPNN outperforms current methods, achieving classification accuracies of 90.450%, 91.883%, and 89.950% on the Lishui-Zhejiang Birdsdata (100 species), BirdCLEF2018-Small (150 species), and BirdCLEF2018-Large (500 species) datasets respectively, with the lowest hierarchical distance of a mistake across all datasets. Our proposed method is applicable to any bird acoustic dataset and presents significant advantages as the number of categories increases.}
}
@article{MORITAKE2024102462,
title = {Sub-alpine shrub classification using UAV images: Performance of human observers vs DL classifiers},
journal = {Ecological Informatics},
volume = {80},
pages = {102462},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102462},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000049},
author = {Koma Moritake and Mariano Cabezas and Tran Thi Cam Nhung and Maximo Larry {Lopez Caceres} and Yago Diez},
keywords = {Sub-alpine vegetation, Vegetation change monitoring, Deep learning, Observer study, ConvNeXt, Swin},
abstract = {In recent years, the automatic analysis of natural environment images acquired with unmanned aerial vehicles (UAV) has rapidly gained popularity. UAVs are specially important in mountainous forests where access is difficult and large areas need to be surveyed. In Zao mountains in northeastern Japan, regenerated fir saplings are competing with sub-alpine vegetation shrubs after a severe fir tree mortality caused by bark beetle infestation. A detailed survey of vegetation distribution is key to improve our understanding of species succession and the influence of climate change in that process. To that end, we evaluated the suitability of deep-learning-based automatic image classification of UAV images in order to map sub-alpine vegetation succession in large areas and the potential of fir regeneration. In order to assess the contribution of this technology in this research field, we first conducted an observer study to assess the difficulty for humans of the task of classifying vegetation from images. Afterwards, we compared the observers' accuracy to four state-of-the art deep learning networks for automatic image classification. The best observer accuracy of 55% demonstrates the limitations of species classification using only images. Furthermore, a detailed analysis of the sources of error showed that even though humans could differentiate between deciduous and evergreen species with an accuracy of 96%, identifying the correct species within each group proved much more challenging. In contrast, deep learning networks achieved accuracy values in the range of 70–80% for species classification, clearly demonstrating capabilities beyond human experts. Our experiments also indicated that the performance of these networks was significantly influenced by the similarity between the datasets used to fine-tune them and evaluate them. This fact highlights the importance of building publicly available images databases to further improve the results. Nevertheless, the results presented in this paper show that the analysis of UAV-acquired with deep learning networks can usher in a new type of large-scale study, spanning tenths or even hundreds of hectares with high spatial resolution (of a few cms per pixel), providing the ability to assess challenging vegetation dynamics problems that go beyond the ability of conventional fieldwork methodologies.}
}
@article{CHRISTIANSON2017148,
title = {A metadata reporting framework (FRAMES) for synthesis of ecohydrological observations},
journal = {Ecological Informatics},
volume = {42},
pages = {148-158},
year = {2017},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2017.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1574954116302497},
author = {Danielle S. Christianson and Charuleka Varadharajan and Bradley Christoffersen and Matteo Detto and Boris Faybishenko and Bruno O. Gimenez and Val Hendrix and Kolby J. Jardine and Robinson Negron-Juarez and Gilberto Z. Pastorello and Thomas L. Powell and Megha Sandesh and Jeffrey M. Warren and Brett T. Wolfe and Jeffrey Q. Chambers and Lara M. Kueppers and Nathan G. McDowell and Deborah A. Agarwal},
keywords = {Metadata, Data management system, Model-data integration, Data synthesis, Data preservation, Informatics},
abstract = {Metadata describe the ancillary information needed for data preservation and independent interpretation, comparison across heterogeneous datasets, and quality assessment and quality control (QA/QC). Environmental observations are vastly diverse in type and structure, can be taken across a wide range of spatiotemporal scales in a variety of measurement settings and approaches, and saved in multiple formats. Thus, well-organized, consistent metadata are required to produce usable data products from diverse environmental observations collected across field sites. However, existing metadata reporting protocols do not support the complex data synthesis and model-data integration needs of interdisciplinary earth system research. We developed a metadata reporting framework (FRAMES) to enable management and synthesis of observational data that are essential in advancing a predictive understanding of earth systems. FRAMES utilizes best practices for data and metadata organization enabling consistent data reporting and compatibility with a variety of standardized data protocols. We used an iterative scientist-centered design process to develop FRAMES, resulting in a data reporting format that incorporates existing field practices to maximize data-entry efficiency. Thus, FRAMES has a modular organization that streamlines metadata reporting and can be expanded to incorporate additional data types. With FRAMES's multi-scale measurement position hierarchy, data can be reported at observed spatial resolutions and then easily aggregated and linked across measurement types to support model-data integration. FRAMES is in early use by both data originators (persons generating data) and consumers (persons using data and metadata). In this paper, we describe FRAMES, identify lessons learned, and discuss areas of future development.}
}
@article{PASANISI2024102700,
title = {A global systematic review of species distribution modelling approaches for cetaceans and sea turtles},
journal = {Ecological Informatics},
volume = {82},
pages = {102700},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102700},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002425},
author = {E. Pasanisi and D.S. Pace and A. Orasi and M. Vitale and A. Arcangeli},
keywords = {Cetacean, Habitat modelling, Predictive models, PPM, Sea turtles, Species distribution},
abstract = {In the last decades, interest in species distribution models (SDMs) has grown greatly. The descriptive and predictive power of correlative SDMs is highly valued to meet the high demand for filling gaps in the spatial ecology of wide-ranging and elusive species, such as cetaceans and sea turtles, living in habitats that are technically challenging to survey and where the availability of high quality, unbiased data at appropriate spatial and temporal resolution is not straightforward. This study endeavours to offer a comprehensive global overview of recent advancements in modelling techniques within the realm of SDMs applied to cetaceans and sea turtles. Through a rigorous systematic review of 295 research papers, we identified gaps in species and geographic coverage and highlighted the underrepresentation of biotic, anthropogenic, and water column variables. Our examination revealed a diverse array of modelling approaches, showcasing a notable preference for standard regression-based or machine-learning models, such as GAMs or Maxent, with Bayesian-based models emerging and experiencing growing development. Critical limitations and decisions in constructing and evaluating SDMs were discussed, proposing best practices for future studies. Emphasis was placed on the importance of validating models using fully independent datasets, particularly in the context of conservationist studies. This work not only sheds light on the state of the field but also serves as a valuable tool for those interested in modelling the distribution of these magnificent and enigmatic animals, as well as other cryptic species, offering insights that can guide researchers in making informed decisions in the realm of SDMs.}
}
@article{KANDE2024102547,
title = {Demonstrating the relevance of spatial-functional statistical analysis in marine ecological studies: The case of environmental variations in micronektonic layers},
journal = {Ecological Informatics},
volume = {81},
pages = {102547},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102547},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400089X},
author = {Yoba Kande and Ndague Diogoul and Patrice Brehmer and Sophie Dabo-Niang and Papa Ngom and Yannick Perrot},
keywords = {Clustering, Functional data analysis, Functional generalized spectral additive model, General additive model, Principal component analysis, Sound scattering layers, Spatial regression},
abstract = {In this study, we conducted an analysis of a multifrequency acoustics dataset acquired from scientific echosounders in the West African water. Our objective was to explore the spatial arrangement of marine organism aggregations. We investigated various attributes of these intricate biological entities, such as thickness, relative density, and depth, in relation to their surroundings. These environmental conditions were represented at a fine scale using a towed multiparameter system. This study is closely intertwined with two key domains: Fisheries acoustics techniques and functional data analysis. Fisheries acoustics techniques facilitate the collection of high-resolution spatial and temporal data concerning marine organisms at various depths and spatial scales, all without causing any disturbance. On the other hand, spatial-functional data analysis is a statistical approach for examining data characterised by functional attributes distributed across a spatial domain. This analysis encompasses dimension reduction techniques, as well as supervised and unsupervised methods, which take into consideration spatial dependencies within extensive datasets. We began by applying multivariate statistical techniques and subsequently employed Functional Data Analysis (FDA). In the modeling section, we introduced the spatial dimension with the spatial coordinates as covariates in the General Additive Model (GAM) and Functional Generalized Spectral Additive Model (FGSAM) models, aiming to underscore its relevance in those contexts. In an exploratory phase, Multivariate Functional Principal Component Analysis provided detailed insights into the variations of parameters at different depths, a capability not offered by traditional Principal Component Analysis. When it came to regression tasks, we explored the interactions between descriptors of Sound Scattering Layers and key environmental variables, both with and without considering spatial dimensions. Our findings revealed significant distinctions between northern and southern Sound Scattering Layers, as well as between coastal and high-sea regions. The use of the spatial locations enhanced the performance of GAM and FGSAM, particularly in the case of salinity, reflecting the influence of water mixing and seawater temperature. The multifaceted effects of environmental variations on Sound Scattering Layers underscore the importance of spatial-functional statistical analysis in ecological studies involving complex, spatially functional objects. Beyond the scope of this specific case study, the application of functional data analysis shows promise for a wide array of ecological studies dealing with extensive spatial datasets.}
}
@article{COMESANACEBRAL2024102612,
title = {Wildfire response of forest species from multispectral LiDAR data. A deep learning approach with synthetic data},
journal = {Ecological Informatics},
volume = {81},
pages = {102612},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102612},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001547},
author = {Lino Comesaña-Cebral and Joaquín Martínez-Sánchez and Gabriel Suárez-Fernández and Pedro Arias},
keywords = {Multispectral LiDAR, Deep learning, Fire response, Synthetic data, Wildfire},
abstract = {Forests play a crucial role as the lungs and life-support system of our planet, harbouring 80% of the Earth's biodiversity. However, we are witnessing an average loss of 480 ha of forest every hour because of destructive wildfires spreading across the globe. To effectively mitigate the threat of wildfires, it is crucial to devise precise and dependable approaches for forecasting fire dynamics and formulating efficient fire management strategies, such as the utilisation of fuel models. The objective of this study was to enhance forest fuel classification that considers only structural information, such as the Prometheus model, by integrating data on the fire responses of various tree species and other vegetation elements, such as ground litter and shrubs. This distinction can be achieved using multispectral (MS) Light Detection and Ranging (LiDAR) data in mixed forests. The methodology involves a novel approach in semantic classifications of forests by generating synthetic data with semantic labels regarding fire responses and reflectance information at different spectral bands, as a real MS scanner device would detect. Forests, which are highly intricate environments, present challenges in accurately classifying point clouds. To address this complexity, a deep learning (DL) model for semantic classification was trained on synthetic point clouds in different formats to achieve the best performance when leveraging MS data. Forest plots in the study region were scanned using different Terrestrial Laser Scanning sensors at wavelengths of 905 and 1550 nm. Subsequently, an interpolation process was applied to generate the MS point clouds of each plot, and the trained DL model was applied to classify them. These classifications surpassed the average thresholds of 90% and 75% for accuracy and intersection over union, respectively, resulting in a more precise categorisation of fuel models based on the distinct responses of forest elements to fire. The results of this study reveal the potential of MS LiDAR data and DL classification models for improving fuel model retrieval in forest ecosystems and enhancing wildfire management efforts.}
}
@article{CARRIGER2024102665,
title = {Exploring coral reef communities in Puerto Rico using Bayesian networks},
journal = {Ecological Informatics},
volume = {82},
pages = {102665},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102665},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002073},
author = {John F. Carriger and William S. Fisher},
keywords = {Coral reefs, Community ecology, Bayesian networks, Cluster analysis},
abstract = {Most coral reef studies focus on scleractinian (stony) corals to indicate reef condition, but there are other prominent assemblages that play a role in ecosystem structure and function. In Puerto Rico these include fish, gorgonians, and sponges. The U.S. Environmental Protection Agency conducted unique surveys of coral reef communities across the southern coast of Puerto Rico that included simultaneous measurement of all four assemblages. Evaluating the results from a community perspective demands endpoints for all four assemblages, so patterns of community structure were explored by probabilistic clustering of measured variables with Bayesian networks. Most variables were found to have stronger associations within than between taxa, but unsupervised structure learning identified three cross-taxa relationships with potential ecological significance. Clusters for each assemblage were constructed using an expectation-maximization algorithm that created a factor node jointly characterizing the density, size, and diversity of individuals in each taxon. The clusters were characterized by the measured variables, and relationships to variables for other taxa were examined, such as stony coral clusters with fish variables. Each of the factor nodes were then used to create a set of meta-factor clusters that further summarized the aggregate monitoring variables for the four taxa. Once identified, taxon-specific and meta-clusters represent patterns of community structure that can be examined on a regional or site-specific basis to better understand risk assessment, risk management and delivery of ecosystem services.}
}
@article{XIE2022101893,
title = {Multi-view features fusion for birdsong classification},
journal = {Ecological Informatics},
volume = {72},
pages = {101893},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101893},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003430},
author = {Shanshan Xie and Jing Lu and Jiang Liu and Yan Zhang and Danjv Lv and Xu Chen and Youjie Zhao},
keywords = {Birdsong recognition, Deep features, Handcrafted features, mRMR, Feature selection},
abstract = {As important members of the ecosystem, birds are good monitors of the ecological environment. Bird recognition, especially birdsong recognition, has attracted more and more attention in the field of artificial intelligence. At present, traditional machine learning and deep learning are widely used in birdsong recognition. Deep learning can not only classify and recognize the spectrums of birdsong, but also be used as a feature extractor. Machine learning is often used to classify and recognize the extracted birdsong handcrafted feature parameters. As the data samples of the classifier, the feature of birdsong directly determines the performance of the classifier. Multi-view features from different methods of feature extraction can obtain more perfect information of birdsong. Therefore, aiming at enriching the representational capacity of single feature and getting a better way to combine features, this paper proposes a birdsong classification model based multi-view features, which combines the deep features extracted by convolutional neural network (CNN) and handcrafted features. Firstly, four kinds of handcrafted features are extracted. Those are wavelet transform (WT) spectrum, Hilbert-Huang transform (HHT) spectrum, short-time Fourier transform (STFT) spectrum and Mel-frequency cepstral coefficients (MFCC). Then CNN is used to extract the deep features from WT, HHT and STFT spectrum, and the minimal-redundancy-maximal-relevance (mRMR) to select optimal features. Finally, three classification models (random forest, support vector machine and multi-layer perceptron) are built with the deep features and handcrafted features, and the probability of classification results of the two types of features are fused as the new features to recognize birdsong. Taking sixteen species of birds as research objects, the experimental results show that the three classifiers obtain the accuracy of 95.49%, 96.25% and 96.16% respectively for the features of the proposed method, which are better than the seven single features and three fused features involved in the experiment. This proposed method effectively combines the deep features and handcrafted features from the perspectives of signal. The fused features can more comprehensively express the information of the bird audio itself, and have higher classification accuracy and lower dimension, which can effectively improve the performance of bird audio classification.}
}
@article{BAYR2019220,
title = {Automatic detection of woody vegetation in repeat landscape photographs using a convolutional neural network},
journal = {Ecological Informatics},
volume = {50},
pages = {220-233},
year = {2019},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2019.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S1574954118303121},
author = {Ulrike Bayr and Oskar Puschmann},
keywords = {Repeat photography, Photo monitoring, Landscape monitoring, Landscape change, Vegetation succession, Machine learning},
abstract = {Repeat photography is an efficient method for documenting long-term landscape changes. So far, the usage of repeat photographs for quantitative analyses is limited to approaches based on manual classification. In this paper, we demonstrate the application of a convolutional neural network (CNN) for the automatic detection and classification of woody regrowth vegetation in repeat landscape photographs. We also tested if the classification results based on the automatic approach can be used for quantifying changes in woody vegetation cover between image pairs. The CNN was trained with 50 × 50 pixel tiles of woody vegetation and non-woody vegetation. We then tested the classifier on 17 pairs of repeat photographs to assess the model performance on unseen data. Results show that the CNN performed well in differentiating woody vegetation from non-woody vegetation (accuracy = 87.7%), but accuracy varied strongly between individual images. The very similar appearance of woody vegetation and herbaceous species in photographs made this a much more challenging task compared to the classification of vegetation as a single class (accuracy = 95.2%). In this regard, image quality was identified as one important factor influencing classification accuracy. Although the automatic classification provided good individual results on most of the 34 test photographs, change statistics based on the automatic approach deviated from actual changes. Nevertheless, the automatic approach was capable of identifying clear trends in increasing or decreasing woody vegetation in repeat photographs. Generally, the use of repeat photography in landscape monitoring represents a significant added value to other quantitative data retrieved from remote sensing and field measurements. Moreover, these photographs are able to raise awareness on landscape change among policy makers and public as well as they provide clear feedback on the effects of land management.}
}
@article{MORALES2022101909,
title = {Method for passive acoustic monitoring of bird communities using UMAP and a deep neural network},
journal = {Ecological Informatics},
volume = {72},
pages = {101909},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101909},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003594},
author = {Gabriel Morales and Víctor Vargas and Diego Espejo and Víctor Poblete and Jorge A. Tomasevic and Felipe Otondo and Juan G. Navedo},
keywords = {Passive acoustic monitoring, Bird community, Deep learning, Soundscape, Phenology},
abstract = {An effective practice for monitoring bird communities is the recognition and identification of their acoustic signals, whether simple, complex, fixed or variable. A method for the passive monitoring of diversity, activity and acoustic phenology of structural species of a bird community in an annual cycle is presented. The method includes the semi-automatic elaboration of a dataset of 22 vocal and instrumental forms of 16 species. To analyze bioacoustic richness, the UMAP algorithm was run on two parallel feature extraction channels. A convolutional neural network was trained using STFT-Mel spectrograms to perform the task of automatic identification of bird species. The predictive performance was evaluated by obtaining a minimum average precision of 0.79, a maximum equal to 1.0 and a mAP equal to 0.97. The model was applied to a huge set of passive recordings made in a network of urban wetlands for one year. The acoustic activity results were synchronized with climatological temperature data and sunlight hours. The results confirm that the proposed method allows for monitoring a taxonomically diverse group of birds that nourish the annual soundscape of an ecosystem, as well as detecting the presence of cryptic species that often go unnoticed.}
}
@article{GOITIAURDIAIN2024102397,
title = {Software-dependent biases in the recognition of di- and tri-syllabic bird songs can create false interpretations of bird abundance and singing activity},
journal = {Ecological Informatics},
volume = {79},
pages = {102397},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102397},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004260},
author = {Madalen Goitia-Urdiain and Teresa Sauras-Yera and Gustavo A. Llorente and Eudald Pujol-Buxó},
keywords = {Autonomous recording unit, Bioacoustics, Signal processing, Biodiversity monitoring, Passive acoustic monitoring},
abstract = {The use of autonomous recording units (ARUs) for passive acoustic monitoring has recently gained a lot of importance. It is now widely used for scientific purposes and has been increasingly applied in the field of conservation biology. However, while ARUs may greatly increase cost-effectiveness in monitoring, they are not exempt from possible biases. In this study, we compared the performances of three different software in recognizing bi- and tri-syllabic bird songs and tested if their results varied significantly in a real setting. We focused on the interpretation of the relative abundance among habitats and the time of vocal activity, also using different numbers of training records to assess if the results of the software improved. Even with the quality measures of the recognizer being consistent with those of previously published studies, in several cases the results produced significantly different interpretations depending on the software used. While increasing the number of training records slightly improved the overlap in the estimates of activity among the different software, differences in the relative abundance of each song were present even with a fairly solid number of training records. Our results suggest that reliable biological interpretations might only be attained with a large number of training records and very high values of precision, recall, and the F-score. In fact, even with very high precision and F-scores, lower values for recall led not only to statistically significant differences, but also to different interpretations of relative abundance and time of activity between the two best-performing software. Thus, great caution must be taken in interpreting the results of bioacoustics studies that use automated recognition, and standards of minimum quality should be created for recognizers in scientific and technical studies.}
}