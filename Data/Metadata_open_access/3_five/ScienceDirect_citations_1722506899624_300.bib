@article{WU2024102519,
title = {Optimizing the ecological source area identification method and building ecological corridor using a genetic algorithm: A case study in Weihe River Basin, NW China},
journal = {Ecological Informatics},
volume = {80},
pages = {102519},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102519},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400061X},
author = {Xueting Wu and Jinghu Pan and Xiuwei Zhu},
keywords = {Ecological source areas, Ecological corridors, Genetic algorithm, Graph theory method, Ecological security},
abstract = {Abstract:
The extraction of ecological corridors is influenced by the accuracy of ecological source area identification, which is a crucial component of ecological security construction. The ecological source areas of the Weihe River Basin (WRB) were comprehensively identified by analyzing the supply, demand, and ecological sensitivity of ecosystem services. Different initial populations were set using a genetic algorithm to determine the optimal source areas for the WRB. The minimum cumulative resistance model (MCR) was used to extract the ecological corridors, and then a comparison was made before and after. The results showed that the ecological source areas within the WRB covered approximately 43.362 × 103 km2 in 2020, accounting for 32.38% of the entire area. This included mainly forest, grassland, and a small amount of farmland, of which 89.3% of the ecological source areas were forest. Fifty optimal ecological source areas were obtained using a genetic algorithm, generating 122 ecological corridors with an overall length of 40.245 × 105 km that could disperse the entire WRB. By comparing the ecological source areas before and after optimization, the IIC value of the ecological source areas before optimization was 0.006, the PC value was 0.007, and the FN value was 0.10. The IIC, PC, and FN values of the optimized ecological source area were 0.08, 0.079, and 0.042, respectively. The overall connectivity of the optimal source identified by the genetic algorithm increased by 13.3 times, with a possible connectivity increase of 11.2 times and a 42% reduction in fragmentation. The applicability and reliability in identifying optimal ecological source areas genetic algorithm was high, offering a reliable idea for constructing regional ecological security.}
}
@article{VIZCARRA2021101268,
title = {The Peruvian Amazon forestry dataset: A leaf image classification corpus},
journal = {Ecological Informatics},
volume = {62},
pages = {101268},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101268},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000595},
author = {Gerson Vizcarra and Danitza Bermejo and Antoni Mauricio and Ricardo {Zarate Gomez} and Erwin Dianderas},
keywords = {Leaves dataset, Peruvian Amazon, Deep learning, Visual interpretation, Interpretation},
abstract = {Forest census allows getting precise data for logging planning and elaboration of the forest management plan. Species identification blunders carry inadequate forest management plans and high risks inside forest concessions. Hence, an identification protocol prevents the exploitation of non-commercial or endangered timber species. The current Peruvian legislation allows the incorporation of non-technical experts, called “materos”, during the identification. Materos use common names given by the folklore and traditions of their communities instead of formal ones, which generally lead to misclassifications. In the real world, logging companies hire materos instead of botanists due to cost/time limitations. Given such a motivation, we explore an end-to-end software solution to automatize the species identification. This paper introduces the Peruvian Amazon Forestry Dataset, which includes 59,441 leaves samples from ten of the most profitable and endangered timber-tree species. The proposal contemplates a background removal algorithm to feed a pre-trained CNN by the ImageNet dataset. We evaluate the quantitative (accuracy metric) and qualitative (visual interpretation) impacts of each stage by ablation experiments. The results show a 96.64% training accuracy and 96.52% testing accuracy on the VGG-19 model. Furthermore, the visual interpretation of the model evidences that leaf venations have the highest correlation in the plant recognition task.}
}
@article{TAMIMINIA2024102404,
title = {State-wide forest canopy height and aboveground biomass map for New York with 10 m resolution, integrating GEDI, Sentinel-1, and Sentinel-2 data},
journal = {Ecological Informatics},
volume = {79},
pages = {102404},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102404},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004338},
author = {Haifa Tamiminia and Bahram Salehi and Masoud Mahdianpari and Tristan Goulden},
keywords = {Canopy height model, Forest aboveground biomass, Machine learning, GEDI, Spaceborne LiDAR, Large-scale, Google earth engine},
abstract = {Investigating the quantity of forest aboveground biomass (AGB) is crucial for understanding the role forests play in the global carbon cycle. The canopy height model (CHM) is a critical component in estimating AGB, as it provides a three-dimensional representation of the tree canopy. Traditional CHM estimation methods are time-consuming, labor-intensive, and expensive, particularly at large-scales. Remote sensing is a cost-effective and efficient alternative approach, providing valuable information over large areas in a timely manner. The Global Ecosystem Dynamics Investigation (GEDI) onboard the International Space Station is a space-based light detection and ranging (LiDAR) system designed to collect information on vertical structures of vegetation. One major problem with the collection of GEDI data is that it provides limited information over discrete ground samples, also known as footprints, and thus do not provide wall-to-wall gridded height products. The objective of this study was twofold: a) to integrate the GEDI LiDAR footprint heights with Sentinel-2 multispectral imagery to generate a 10 m wall-to-wall CHM map of New York State (NYS), USA for the year 2019 and b) to improve our previously generated AGB map (both accuracy and resolution) of NYS for the year 2019 by fusing Sentinel-2 multispectral, Sentinel-1 synthetic aperture radar (SAR), and the produced CHM. To generate the 10 m CHM map, the GEDI footprints height measurements were extrapolated using Sentinel-2 imagery and a random forest model. The CHM that was produced was assessed by using GEDI footprints that were not part of the training phase and were therefore independent (extrapolated). Comparing our 10 m CHM with the available global 30 m CHM map provided by Potapov et al. (2021) over NYS shows significant improvement not only in terms of spatial resolution, but also in terms of accuracy. The root mean square error (RMSE) of our 10 m CHM is 4.4 m while this value is 7.49 m for the 30 m CHM over NYS. Similarly, the R2 value for the 10 m CHM map is 0.74, while that of the 30 m CHM is 0.46. Finally, the integration of produced 10 m CHM, Sentinel-1, and Sentinel-2 datasets were utilized to create a 10 m AGB map of NYS with the RMSE of 39.49 Mg/ha, and R2 of 0.65. The results demonstrate the potential of integrating GEDI, Sentinel-1, and Sentinel-2 data for providing a valuable tool for large-scale mapping of forest canopy structure and biomass, which can help to inform forest management and carbon accounting efforts.}
}
@article{KRISNAWIJAYA2024102613,
title = {Reference architecture design for developing data management systems in smart farming},
journal = {Ecological Informatics},
volume = {81},
pages = {102613},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102613},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001559},
author = {Ngakan Nyoman Kutha Krisnawijaya and Bedir Tekinerdogan and Cagatay Catal and Rik {van der Tol}},
keywords = {Domain analysis, Feature model, Reference architecture, Data management, Smart farming},
abstract = {The traditional data management systems prove inadequate to handle the volume, velocity, and variety of the data within farm business processes. Smart farming technologies offer advanced data management systems as a practical solution to these challenges. However, data is complex and originates from many sources; hence many aspects of data must be considered during the data management design of smart farming systems. This study proposes a reference architecture for data management in smart farming, developed through domain analysis and architecture modeling approaches. The domain analysis provides insights into the common and variant features and modules of the smart farming system, resulting in a blueprint representing family features across various smart farming domains. The effectiveness of the proposed reference architecture has been evaluated through two case studies, demonstrating its efficacy in designing data management systems for smart farming. The study found that the percentage of reused modules in the case studies, compared to the provided reference architecture, was 82.6%. The outcomes of this research will pave the way for further exploration in smart farming, particularly addressing data management issues within smart farming systems.}
}
@article{GOMEZFERNANDEZ2024102738,
title = {Landsat images and GIS techniques as key tools for historical analysis of landscape change and fragmentation},
journal = {Ecological Informatics},
volume = {82},
pages = {102738},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102738},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002802},
author = {Darwin Gómez-Fernández and Rolando Salas López and Jhon A. Zabaleta-Santisteban and Angel J. Medina-Medina and Malluri Goñas and Jhonsy O. Silva-López and Manuel Oliva-Cruz and Nilton B. Rojas-Briceño},
keywords = {Fragmentation, LULC, Changes, Classification, Random Forest, Amazon, Forest},
abstract = {Monitoring and evaluation of landscape fragmentation is important in numerous research areas, such as natural resource protection and management, sustainable development, and climate change. One of the main challenges in image classification is the intricate selection of parameters, as the optimal combination significantly affects the accuracy and reliability of the final results. This research aimed to analyze landscape change and fragmentation in northwestern Peru. We utilized accurate land cover and land use (LULC) maps derived from Landsat imagery using Google Earth Engine (GEE) and ArcGIS software. For this, we identified the best dataset based on its highest overall accuracy, and kappa index; then we performed an analysis of variance (ANOVA) to assess the differences in accuracies among the datasets, finally, we obtained the LULC and fragmentation maps and analyzed them. We generated 31 datasets resulting from the combination of spectral bands, indices of vegetation, water, soil and clusters. Our analysis revealed that dataset 19, incorporating spectral bands along with water and soil indices, emerged as the optimal choice. Regarding the number of trees utilized in classification, we determined that using between 10 and 400 decision trees in Random Forest classification doesn't significantly affect overall accuracy or the Kappa index, but we observed a slight cumulative increase in accuracy metrics when using 100 decision trees. Additionally, between 1989 and 2023, the categories Artificial surfaces, Agricultural areas, and Scrub/ Herbaceous vegetation exhibit a positive rate of change, while the categories Forest and Open spaces with little or no vegetation display a decreasing trend. Consequently, the areas of patches and perforated have expanded in terms of area units, contributing to a reduction in forested areas (Core 3) due to fragmentation. As a result, forested areas smaller than 500 acres (Core 1 and 2) have increased. Finally, our research provides a methodological framework for image classification and assessment of landscape change and fragmentation, crucial information for decision makers in a current agricultural zone of northwestern Peru.}
}
@article{NAKHJIRI2024102504,
title = {Air pollution in industrial clusters: A comprehensive analysis and prediction using multi-source data},
journal = {Ecological Informatics},
volume = {80},
pages = {102504},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102504},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000463},
author = {Armin Nakhjiri and Ata Abdollahi Kakroodi},
abstract = {Air pollution is a pressing concern, especially in developing countries, and its impact on the climate, physical health, and overall quality of life cannot be overstated. This study focuses on the Tehran province, Iran, aiming to clarify the role of different industrial activities in emitting air pollution. To achieve this objective, zonal areas spanning 3.2 km were designated for each industrial establishment within the province and subsequently categorized based on their respective activities forming industrial clusters. Five Copernicus Sentinel-5 Precursor vertical column density (VCD) data products, along with several other auxiliary datasets, were utilized to analyze the spatio-temporal patterns of major air pollutants, including formaldehyde (HCHO), carbon monoxide (CO), nitrogen dioxide (NO2), sulfur dioxide (SO2), and tropospheric ozone (O3), and to forecast their concentration trends within each cluster. The use of the Exponential Smoothing Model (ESM) for forecasting was necessitated by the limited temporal coverage of available datasets from Sentinel-5P. This model, utilizing weighted averages of past observations to predict future values, was deemed suitable for addressing the temporal constraints of the datasets. The spatial analysis revealed three dispersion patterns in the study area: HCHO, CO, and NO2 exhibited island-like patterns, SO2 exhibited spot-like patterns, and tropospheric O3 exhibited topography-influenced patterns. The temporal analysis revealed significant inter-annual patterns and variations in pollutant concentrations among industrial clusters. Average concentrations of CO, NO2, SO2, and O3 reached their peaks during the cooler months of the year, likely attributable to temperature inversions and heightened usage of heating components, leading to increased combustion of fossil fuels. In contrast, peak levels of HCHO were observed during warmer months, a trend that may be attributed to intensified photochemical processes resulting from the heightened intensity of solar radiation. According to the ESM results, the concentration of HCHO above lime/plaster factories, the concentration of CO above petroleum refineries, power plants, and asphalt/sand factories, and the concentration of SO2 and NO2 above all studied clusters are forecasted to increase until 2025. In contrast, the tropospheric O3 concentration is expected to decrease during the same period. The methodology utilized in this study can be applied to other regions to identify major sources of air pollution and predict future trends.}
}
@article{ZHANG2024102556,
title = {A reliable unmanned aerial vehicle multi-target tracking system with global motion compensation for monitoring Procapra przewalskii},
journal = {Ecological Informatics},
volume = {81},
pages = {102556},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102556},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000980},
author = {Guoqing Zhang and Yongxiang Zhao and Ping Fu and Wei Luo and Quanqin Shao and Tongzuo Zhang and Zhongde Yu},
keywords = { monitoring, UAV MOT, GMC, Deep SORT},
abstract = {Procapra przewalskii, which inhabits plateau areas, faces the constant threat of poaching and unpredictable risks that impede its survival. The implementation of a comprehensive, real-time monitoring and tracking system for Procapra przewalskii using artificial intelligence and unmanned aerial vehicle (UAV) technology is crucial to safeguard its existence. Therefore, a UAV multi-object-tracking (MOT) system with global motion compensation (GMC) was proposed in this study. YOLOv7 and Deep SORT were employed for object detection and tracking, respectively. Furthermore, the Kalman filter (KF) in Deep SORT is optimized to enhance the accuracy of object-tracking. Moreover, a novel appearance feature-extraction network (FEN) is introduced to enable more effective multi-scale feature (MSF) extraction. In addition, a GMC module was proposed to align neighboring frames through feature matching. This facilitates the correction of the position of the target in the subsequent frame, mitigating the impact of UAV camera motion on tracking. The results demonstrated the remarkable tracking accuracy of the system. Compared with the Deep SORT model, the proposed system exhibited an increase of 6.4% in MOTA, 2.7% in MOTP, and 7.9% in IDF1. Through a comprehensive evaluation and analysis of real-world tracking scenarios, the system proposed in this study exhibits reliability in complex scenes and holds the potential to significantly enhance the protection of Procapra przewalskii from threats.}
}
@article{STEN2024102670,
title = {A ridge-based detection algorithm with filament overlap identification for 2D mycelium network analysis},
journal = {Ecological Informatics},
volume = {82},
pages = {102670},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102670},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002127},
author = {Oscar Sten and Emanuela {Del Dottore} and Nicola Pugno and Barbara Mazzolai},
keywords = {Mycelium, Network topology, Image analysis},
abstract = {Many terrestrial ecosystems engage mycorrhizal symbiotic associations, potentially to enhance nutrition, increase resistance to soil-borne pests and diseases, and improve resilience and soil structure. Mycorrhizal fungi create dynamic networked structures through branching and anastomosis that connect multiple plants and consent to transport resources underground from nutrient-rich patches to demanding plants. Controlled laboratory experiments are fundamental to improving our knowledge of mycelium network growth dynamics and further understanding its role in preserving ecological niches. We propose a method for highly automated analysis of the mycelium network structure and other morphological properties, such as hyphal length, hyphal density, and number of crossing and branches, in 2D microscopy images of fungal samples. Available tools for automated network analyses suffer from overestimating network connectivity since filament crossings are not considered. In particular, we propose a) a ridge-based mycelium detection algorithm and b) a geometrical-based approach to identify overlapping filaments crossing each other. The algorithmic solution is evaluated on a total of 135 real mycelium sample images over different validation steps, originating from different datasets and having different characteristics, including background, contrast, image acquisition system, fungal species, and clearness (e.g., level of transparency, homogeneity, dirtiness of the medium) of the sample. Results show that 1) the proposed detection method can be used to measure the length of mycelium in an image, replacing manual tracing and allowing for less laborious analysis ρ̂c=0.96, 2) the filament detection is on par with state-of-the-art techniques F1=0.88−0.94 with a more intuitive parameterization, and 3) the proposed algorithm correctly identifies filament crossings F1=0.89 in most common cases, yielding a reduction in the overestimation of network connectivity. The latter feature consents to applying the proposed fully automated solution to complex and irregular fungal structures, advancing mycelium detection and reconstruction performance accuracy with respect to the state-of-the-art.}
}
@article{BOTERSPITARCH2023102266,
title = {Application of a stochastic compartmental model to approach the spread of environmental events with climatic bias},
journal = {Ecological Informatics},
volume = {77},
pages = {102266},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102266},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002959},
author = {Joan {Boters Pitarch} and María Teresa {Signes Pont} and Julian Szymański and Higinio {Mora Mora}},
keywords = {Epidemiological models, Climatic variables, SIR paradigm, Monte Carlo method},
abstract = {Wildfires have significant impacts on both environment and economy, so understanding their behaviour is crucial for the planning and allocation of firefighting resources. Since forest fire management is of great concern, there has been an increasing demand for computationally efficient and accurate prediction models. In order to address this challenge, this work proposes applying a parameterised stochastic model to study the propagation of environmental events, focusing on the bias introduced by climatic variables such as wind. This model’s propagation occurs in a grid where cells are classified into different compartments based on their state. Furthermore, this approach generalises previous non-stochastic models, which are now considered particular cases within this broader framework. The use of the Monte Carlo method is highlighted, which allows for obtaining probabilistic estimates of the state of the cells in each time step, considering a level of confidence. In this way, the model provides a tool to obtain a quantitative estimate of the probability associated with each state in the spread of forest fires.}
}
@article{ZHANG2023102242,
title = {Research on the identification of land types and tree species in the Engebei ecological demonstration area based on GF-1 remote sensing},
journal = {Ecological Informatics},
volume = {77},
pages = {102242},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102242},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002716},
author = {Jie Zhang and Yanyan Zhang and Tiantian Zhou and Yi Sun and Zhichao Yang and Shulin Zheng},
keywords = {Multi-scale segmentation, Tree species identification, Nearest neighbor classification, Random forest classification, Object-oriented classification, Change detection},
abstract = {Identifying forest types is crucial in satellite remote sensing monitoring. Research focusing on the identification of forest tree species using high-resolution remote sensing images is on the rise. Traditional pixel-based classification methods have not been successful in fully utilizing the rich spatial and texture feature information present in the image. Further, these methods are plagued by “classification noise”, which impedes the precise extraction of information regarding forest tree species. The object-oriented classification method, on the other hand, offers an extraction methodology rooted in image segmentation object features. It efficiently leverages the spectral, texture, and spatial geometry information of high-resolution remote sensing images. In this study, an initial application of the object-oriented, multi-level information extraction was conducted on ground objects within the Engebei ecological demonstration area. This was performed utilizing Gaofen (GF)-1 remote sensing images. Following this, a multi-scale segmentation algorithm was utilized to establish different segmentation scales relative to the features of the different objects. The optimal segmentation scale, shape factor, and compactness factor were determined to be 222/0.5/0.5, 167/0.5/0.6, and 81/0.4/0.6, respectively, for the three levels. Subsequently, training samples were used to select optimal features during the classification process. The nearest neighbor classification and random forest classification were performed respectively. The results indicate an overall classification accuracy of 88.58% and 87.26% for the nearest neighbor classification of remote sensing images in 2020 and 2021 respectively. Meanwhile, the overall classification accuracy for the random forest classification was 92.95% and 92.02% respectively. The Kappa coefficients for the nearest neighbor classification were 0.86 and 0.85, whereas those for the random forest classification were 0.92 and 0.90. These outcomes underscore the utility of the object-oriented classification method in enhancing the accuracy of forest type identification.}
}
@article{NODA2024102658,
title = {Predicting habitat suitability for Asian elephants in non-analog ecosystems with Bayesian models},
journal = {Ecological Informatics},
volume = {82},
pages = {102658},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102658},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002000},
author = {Ryoko Noda and Michael Francis Mechenich and Juha Saarinen and Aki Vehtari and Indrė Žliobaitė},
keywords = {Bayesian statistical models, Species distribution modeling, Rewilding, Non-analog ecosystems, },
abstract = {Rewilding is an ambitious approach to conservation aiming at restoring and protecting natural processes. As the world is rapidly transitioning into conditions that have not been observed before, we need to be able to extrapolate and predict how natural processes would act under new conditions. Species distribution models have a good potential to inform rewilding decisions by the predictive modeling of potential species presence under various habitat conditions. A critical requirement when utilizing these models is to be able to express the uncertainty in the environment or its predictions. This study demonstrates the use of Bayesian statistical models to address this challenge. As a case study, we explore Bayesian logistic regression and Bayesian generalized additive models in order to predict suitable habitats for Asian elephants (Elephas maximus) until the year 2070 under the worst case working scenario of climate change. In this comparative study predictions of habitat suitability are solely based on climatic conditions. The results of the two Bayesian models are compared to two benchmark models, maximum-likelihood estimated logistic regression and random forest. We analyze and discuss trade-offs, relative advantages, and limitations of these modeling choices. The results of our analysis suggest that one configuration of Bayesian logistic regression gives the most robust predictions in this setting, which tend to correspond with the distribution of woodland biomes broadly similar to those in the species' historical range.}
}
@article{WANG2024102666,
title = {Evaluation of five atmospheric correction algorithms for multispectral remote sensing data over plateau lake},
journal = {Ecological Informatics},
volume = {82},
pages = {102666},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102666},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002085},
author = {Dong Wang and Bo-Hui Tang and Zhao-Liang Li},
keywords = {Atmospheric correction (AC), Remote sensing reflectance, Satellite, Plateau lake (PL)},
abstract = {The precise correction of atmospheric effects is essential for the accurate analysis of inland water color from remote sensing (RS) data. This study systematically evaluates the efficacy of five atmospheric correction (AC) algorithms—Acolite, C2RCC, FLAASH, iCOR, and L2gen—when applied to Sentinel-2 Multi Spectral Instrument (MSI) and Sentinel-3 Ocean and Land Color Instrument (OLCI) imagery. The performance of these algorithms is scrutinized across different spectral bands and spatial resolutions, with a focus on their suitability for water body AC. Our validation approach primarily focuses on the spatial arrangement of sampling points and the timeliness of the collected data. The results reveal that Acolite demonstrates superior performance in the red band of MSI data, whereas C2RCC exhibits inconsistencies in the blue and green bands. FLAASH stands out in its handling of OLCI data, although iCOR exhibits sensitivity to resolution, resulting in over-correction in lower resolution scenarios. L2gen is noted for its consistent provision of concentrated data amplitude across the board. The findings, graphically represented through a radar chart, are pivotal for guiding the selection of optimal AC algorithms for the visible spectrum, thereby enhancing the accuracy of RS applications in environmental monitoring and research. Additionally, our study highlights the impact of sampling time differences on the AC spectrum, with variations of approximately 3% observed for a single sensor. This underscores the critical need for temporal consistency in field measurements.}
}
@article{KIM2024102464,
title = {Metapopulation models using landscape connectivity can better reflect landscape heterogeneity},
journal = {Ecological Informatics},
volume = {80},
pages = {102464},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102464},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000062},
author = {Eun Sub Kim and Dong Kun Lee and Jiyoung Choi and Jae Hyun Kim and Youngwon Mo and Yoonho Jeon and Ji Yeon Kim},
keywords = {Conservation area priorities, Endangered species, Forest fragmentation, Habitat loss, Incidence function model},
abstract = {Forest fragmentation due to urban development has a significant impact on species persistence, necessitating a metapopulation theory approach considering landscape structure and patch-based impact assessments. In this study, we propose a method that applies landscape connectivity and incidence function models (IFM) to a species distribution model to represent the persistence of metapopulations by considering landscape structure (IFM-LCONS). The proposed approach was used to understand changes in leopard cat (Prionailurus bengalensis) occupancy patterns resulting from urban development considering landscape and patch structure. The impact on changes in occupancy owing to urban development was better reflected by patch area (R2 = 0.5031, R2 = 0.1642) and quality (R2 = 0.5142, R2 = 0.1042). Notably, the IFM-LCONS showed an increasing occupancy at a connectivity value of 500, whereas the IFM indicated the opposite. These results highlight that the here proposed approach allows for a more thorough consideration of the impact of urban development on landscape and structural aspects with respect to endangered and rare species, which can be used for conservation planning.}
}
@article{NOLAN2023102330,
title = {Distance sampling and spatial capture-recapture for estimating density of Northern Bobwhite},
journal = {Ecological Informatics},
volume = {78},
pages = {102330},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102330},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300359X},
author = {Victoria Nolan and Nathan Wilhite and Paige E. Howell and Richard B. Chandler and Dallas Ingram and John M. Yeiser and Chris Scott and James A. Martin},
keywords = {Bias, Density, Di-Lane, Distance sampling, Northern bobwhite, Precision, Spatial capture-recapture, Telemetry},
abstract = {Obtaining accurate density estimates is critical for managers making decisions regarding wildlife populations. A variety of methods have been used to estimate population density, with two of the most common being distance sampling (DS) and spatial capture recapture (SCR). We evaluated precision and bias of density estimators through a simulation study of DS using data collected from either human observer point counts or automated recording units (ARUs), and SCR using trapping data or trapping data augmented with telemetry data. We then fit each of the four models to empirical data collected during autumn 2016–2018 for a population of northern bobwhite Colinus virginianus on Di-Lane Wildlife Management Area in Georgia. Density estimates in our simulation study were relatively unbiased using all four methods but were most accurate for the two SCR methods. Empirical density estimates were similar across methods and years, with annual averages of 0.41 birds per ha in 2016, 0.44 birds per ha in 2017 and 0.31 birds per ha in 2018. In general, both SCR methods were also the most precise using the empirical data, although ARU distance sampling did also produce comparable density estimates and precision values. Although SCR methods performed the best overall, cost and increased labor of these monitoring programs should be evaluated in relation to the relative ease of ARU deployment or point count surveys, which also provided adequate, and often similar, density estimates. Integrating these constraints into a structured decision-making framework will aid managers weighing decisions regarding how to monitor, and ultimately make management decisions.}
}
@article{KOWALSKI2021101284,
title = {Numerical analysis of factors, pace and intensity of the corona virus (COVID-19) epidemic in Poland},
journal = {Ecological Informatics},
volume = {63},
pages = {101284},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101284},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000753},
author = {Piotr Andrzej Kowalski and Marcin Szwagrzyk and Jolanta Kielpinska and Aleksander Konior and Maciej Kusy},
keywords = {Corona virus, COVID-19, Disease curve, Epidemiological model, Excess mortality, Pearson's correlation, Multivariate linear regression, Factor analysis, Least-squares estimation},
abstract = {This article focuses on a statistical analysis of the corona virus disease 2019 (COVID-19) data that appeared until November 31, 2020 in Poland. The studied database, expressed in terms of both population and air pollution (particulate) indicators, is provided mainly by the Airly company, the Central Statistical Office (GUS) and the Rogalski project. The particular measured factors, which underwent standardization, were assessed for mutual dependency by means of a Pearson correlation coefficient and analysed by a linear regression. Based on the presented models, our results indicate that air quality (air pollution level) is the most important factor in the context of enabling COVID-19 case load increase in Poland.}
}
@article{BERTOLINI2022101659,
title = {Using a clustering algorithm to identify patterns of valve-gaping behaviour in mussels reared under different environmental conditions},
journal = {Ecological Informatics},
volume = {69},
pages = {101659},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101659},
url = {https://www.sciencedirect.com/science/article/pii/S157495412200108X},
author = {C. Bertolini and J. Capelle and E. Royer and M. Milan and R. Witbaard and T.J. Bouma and R. Pastres},
keywords = {Bivalves, K-means, Precision shellfish aquaculture, Transitional ecosystem, Venice lagoon, Wadden Sea},
abstract = {Physiological adaptations for inhabiting transitional environments with strongly variable abiotic conditions can sometimes be displayed as behavioural shifts. A striking example might be found in bivalve species that inhabit estuaries characterised by fluctuations in environment. The opening and closing of their valves, so called gaping activity, represents behaviour that is required for two key physiological functions: food intake and respiration. Linking valve-gaping behaviour to environmental drivers can greatly improve our understanding and modelling of bivalve bioenergetics. Nowadays large data sets on gaping activity can be collected with automated sensors, but interpretation is difficult due to the large amount of environmental drivers and the intra-individual variability. This study aims to understand whether an unsupervised machine learning method (k-means clustering) can be used to identify patterns in gaping activity. Two commercially important congener mussels, Mytilus galloprovincialis and Mytilus edulis inhabiting two transitional coastal areas, the Venice Lagoon and the Wadden Sea, were fitted with sensors to monitor valve-gaping, while a comprehensive set of environmental parameters was also monitored. Data were analysed by applying three times a k-mean algorithm to the gaping time series. In the 1st analyses, the algorithm was applied to the overall gaping time series, including daily variations. We identified at both sites three clusters that were characterised by different average daily gaping aperture. The algorithm was subsequently reapplied to relate daily means of gaping to environmental conditions, being temperatures, oxygen saturation and chlorophyll levels. This 2nd analyses revealed that mean gaping aperture was mainly linked to food availability. A 3rd follow-up analysis aimed at exploring daily patterns. This third analysis again revealed consistent patterns amongst the two sites, where two clusters emerged that showed different degrees of oscillatory behaviour. There was however no obvious relationship between this fine scale oscillatory behaviours and environmental variables, but in the Venice Lagoon there was a site effect. Overall, we show that clustering algorithms can disentangle behavioural patterns within complex series of big data. The latter offers new opportunities to improve site-specific bioenergetic bivalve models by rephrasing the clearance and respiration terms based on the mean gaping aperture, provided that further laboratory experimentations are conducted to extrapolate parameters linking aperture with energy inputs and outputs.}
}
@article{FU2023102250,
title = {Classification of birdsong spectrograms based on DR-ACGAN and dynamic convolution},
journal = {Ecological Informatics},
volume = {77},
pages = {102250},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102250},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002790},
author = {Yixing Fu and Chunjiang Yu and Yan Zhang and Danjv Lv and Yue Yin and Jing Lu and Dan Lv},
keywords = {Auxiliary classifier GAN, Data augmentation, Dynamic convolution, Attention mechanism, Birdsong recognition},
abstract = {Birdsongs are highly valuable for bird studies as they provide insights into various aspects such as species distribution, population structures, and habitat. Recognizing birdsongs plays a crucial role in bird conservation efforts. However, manually collecting a large number of birdsongs from the natural environment is expensive and time-consuming. Moreover, using limited birdsong data often results in low classification accuracy of the models. To better identification of birdsongs, we utilize wavelet transform(WT) to convert them into spectrograms, which contain abundant energy and frequency information. Effectively extracting these features is vital to improve the classification accuracy of the model. To address this problem, we proposed an improved ACGAN model based on residual structure and attention mechanism named DR-ACGAN, which achieved stable training of the model and high-quality generated birdsong spectrograms. The dynamic convolution kernel is then fused with MobileNetV2, ResNet18, and VGG16 models and trained on different datasets, which used different ways of mixing the generated and original spectrograms. The experimental results show that the classification accuracy after data augmentation improves by 6.66%, 4.35%, and 2.29% compared to the original dataset in the three base classifiers. After adding dynamic convolutional kernel structure, the accuracy is further improved by 1.68%, 0.67%, and 0.38% on average which the VGG16 model achieves the highest accuracy of 97.60%.}
}
@article{GALBRUN2021101314,
title = {Redescription mining for analyzing local limiting conditions: A case study on the biogeography of large mammals in China and southern Asia},
journal = {Ecological Informatics},
volume = {63},
pages = {101314},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101314},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121001059},
author = {Esther Galbrun and Hui Tang and Anu Kaakinen and Indrė Žliobaitė},
keywords = {Limiting conditions, Climate, Large mammals, Machine learning, Redescription mining, Teeth},
abstract = {Identifying and understanding limiting conditions is at the centre of ecology and biogeography. Traditionally, associations between climate and occurrences of organisms are inferred from observational data using regression analysis, correlation analysis or clustering. Those methods extract patterns and relationships that hold throughout a dataset. We present a computational methodology called redescription mining, that emphasizes local patterns and associations that hold strongly on subsets of the dataset, instead. We aim to showcase the potential of this methodology for ecological and biogeographical studies, and encourage researchers to try it. Redescription mining can be used to identify associations between different descriptive views of the same system. It produces an ensemble of local models, that provide different perspectives over the system. Each model (redescription) consists of two sets of limiting conditions, over two different views, that hold locally. Limiting conditions, as well as the corresponding subregions, are identified automatically using data analysis algorithms. We explain how this methodology applies to a biogeographic case study focused on China and southern Asia. We consider dental traits of the large herbivorous mammals that occur there and climatic conditions as two aspects of this ecological system, and look for associations between them. Redescription mining can offer more refined inferences on the potential relation between variables describing different aspects of a system than classical methods. Thus, it permits different questions to be posed of the data, and can usefully complement classical methods in ecology and biogeography to uncover novel biogeographic patterns. A python package for carrying out redescription mining analysis is publicly available.}
}
@article{TUOKU2024102555,
title = {Impacts of climate factors and human activities on NDVI change in China},
journal = {Ecological Informatics},
volume = {81},
pages = {102555},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102555},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000979},
author = {Lina Tuoku and Zhijian Wu and Baohui Men},
keywords = {China, Climatic factors, Human activities, NDVI, Vegetation cover},
abstract = {Vegetation plays a crucial role in terrestrial ecosystems, and there has been a substantial shift in global vegetation cover in recent decades. China is recognized for its substantial impact on global vegetation cover changes, which are influenced by both climate change and human activities. Therefore, this research aims to assess the respective influences of climate modification and human activities on vegetation variations in China. First, the changes in vegetation cover are explored between 1982 and 2020 using satellite-image derived vegetation index, known as the Normalized Difference Vegetation Index (NDVI). Second, a multiple regression model based on time-lag analysis is used to simulate NDVI. In addition to common climatic factors such as temperature, precipitation, solar radiation intensity and relative humidity, the atmospheric CO2 concentration to directly reflect climate change is considered in this model. Finally, the relative influence of climate variation and human activities on the alteration of vegetation cover is determined based on reconstructed NDVI. Results: (1) Precipitation and solar radiation are the most important influences, while carbon dioxide concentration and relative humidity have the least influence. (2) The simulation error before 2000 was 0.875%, which was considerably lower than the error after 2000. (3) After 2000, human activities favorably affected vegetation recovery in most of the study area, with an average degree of influence of >30%.}
}
@article{ZHOU2024102680,
title = {Real-time underwater object detection technology for complex underwater environments based on deep learning},
journal = {Ecological Informatics},
volume = {82},
pages = {102680},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102680},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400222X},
author = {Hui Zhou and Meiwei Kong and Hexiang Yuan and Yanyan Pan and Xinru Wang and Rong Chen and Weiheng Lu and Ruizhi Wang and Qunhui Yang},
keywords = {Underwater object detection, You only look once, Cross stage multi-branch, Large kernel spatial pyramid},
abstract = {Underwater object detection technology is crucial in many marine-related fields, including marine environmental monitoring, marine resource development, and marine ecological protection. However, this technology faces great challenges due to the poor quality of underwater optical images and the varying sizes of underwater objects. Therefore, we proposed an underwater optical detection network (UODN) based on the you only look once version 8 (YOLOv8) framework, which addresses these issues through the cross stage multi-branch (CSMB) module and large kernel spatial pyramid (LKSP) module. The aim of the CSMB module is to extract more features from underwater optical images to address the issue of poor image quality, while the LKSP module is designed to enhance the ability of the network to detect underwater objects of various scales. Furthermore, CSMBDarknet built by CSMB and LKSP can be used as the backbone of other underwater object detection algorithms for underwater feature extraction. Extensive experimental results on the underwater robot professional contest 2020 dataset revealed that the average precision (AP) of UODN increased by 1.0%, the AP50 of UODN increased by 1.1%, and the AP75 of UODN increased by 2.1% compared with those of the original YOLOv8s. Furthermore, UODN outperforms 12 state-of-the-art models on multiple underwater optical datasets, paving the way for future real-time and high-precision underwater object detection.}
}
@article{HU2024102640,
title = {Capturing urban green view with mobile crowd sensing},
journal = {Ecological Informatics},
volume = {81},
pages = {102640},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102640},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001821},
author = {Yingqiang Hu and Yue Wu and Zhuzi Tantian and Guodong Sun},
keywords = {Urban green spaces, Green view index, Deep learning, Mobile crowd sensing},
abstract = {Urban green spaces are beneficial to ecosystems and the health of people. The Green View Index (GVI) is an essential metric for assessing urban green spaces from a human perspective. However, measuring GVI at an urban scale requires extensive collection and processing of sensing data, posing challenges in terms of high resource consumption, difficulty in implementation, and lack of user participation. Mobile crowd Sensing (MCS) is an emerging large-scale, low-cost solution for sensing data collection. To address the aforementioned issues, this study proposes an MCS system called GreenCam to measure the GVI with smartphone sensors. GreenCam guides users to capture photos of urban green spaces from human perspective. The system employs a Transformer-based model, which is trained on a customized dataset of 1200 carefully-labeled urban green images, to extract the greenery from the captured photos and calculate GVI. With widespread participation from urban users, the photos captured by users with GreenCam can cover various streets and areas of the city, enabling the measurement of GVI at an urban scale. Additionally, these photos reflect people's preferences towards specific urban landscapes, and analyzing the distribution and characteristics of popular landscapes contributes to the enhancement of urban ecosystems and landscapes.}
}
@article{OTERO2024102515,
title = {Surveillance of coastal biodiversity through social network monitoring},
journal = {Ecological Informatics},
volume = {80},
pages = {102515},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102515},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000578},
author = {P. Otero and E. Velasco and J. Valeiras},
keywords = {Coastal biodiversity, Passive citizen science, Twitter, Social media, Spain},
abstract = {Knowledge of marine biodiversity is vital for developing appropriate conservation policies. In the current Information Age, data shared by citizens in social networks are a cost-effective alternative to complement on-going marine biodiversity monitoring programs, as well as to understand human interactions with the natural environment from a current perspective. This information can be obtained in a transparent way to the citizen (passive citizen science approach) after sharing relevant content such as: rare catches of recreational fishermen, sightings of invasive species, stranding of cetaceans, sea turtle entanglements, episodes of massive arrival of jellyfish or interactions between organisms, among others. This study has analyzed the content posted on the social networking site X (formerly known as Twitter) from its launch in 2007 to 2022, focusing on those posts that apparently reported a biodiversity observation along the Spanish coast. To avoid an initial bias, generic messages asking “who knows” or if “anyone knows” what they have found were captured, as well as messages stating that they had found something interesting. After retrieving ∼11 K tweets with potential information, 597 tweets were finally identified after human validation. Most of the observations (21%) corresponded to gelatinous animals, with observations of fish (11%) and marine mammals (11%) also being frequent. 57% of these tweets were adequately located over the coast, drawing the first coastal biodiversity map in Spain based on this methodology. The results show this technique as a low-cost tool complementary to existing monitoring programs, which allows studying the occurrence as well as the temporal variability of non-indigenous and sensitive species, as well as to alert in case of massive coastal arrivals of jellyfish, or stranding of cetaceans or sea turtles, among others.}
}
@article{WAGNER2024102709,
title = {Automatic detection of color markings and numbers on trees in point clouds from Personal Laser Scanning (PLS) and Terrestrial Laser Scanning (TLS)},
journal = {Ecological Informatics},
volume = {82},
pages = {102709},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102709},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002516},
author = {Sarah Wagner and Alessa Angerschmid and Anna Saranti and Christoph Gollob and Tim Ritter and Ralf Krassnitzer and Andreas Tockner and Sarah Witzmann and Andreas Holzinger and Karl Stampfer and Arne Nothdurft},
keywords = {Automatic recognition of marked trees, Personal Laser Scanning (PLS), Terrestrial Laser Scanning (TLS), Spectral information from images, Machine learning},
abstract = {In forestry, colored spray paint is used for different purposes, such as marking trees that are chosen for the next harvest or that will be promoted by future silvicultural activities, or for the demarcation of skid/cable roads. Numerous studies have demonstrated the application of Terrestrial Laser Scanners (TLS) and Personal Laser Scanners (PLS) for the acquisition of tree parameters (diameters, heights, and tree positions) in a forest inventory context. However, no studies have included classification based on spectral information by applying colored markings to trees. When a laser scanner is combined with a camera, the color information can be mapped onto the laser point cloud, allowing for additional analysis of spectral information. In this study, we have tested the analysis of joint information from imagery and 3D point clouds in two different settings: (i) PLS point cloud data from a GeoSLAM ZEB Horizon were complemented with spectral information from images collected with a NCTech iSTAR Pulsar 360-degree camera, (ii) TLS point cloud data from a RIEGL VZ-400i were combined with imagery from a Nikon D850 digital single lens reflex (DSLR) camera with 14 mm fisheye lens. The major objective was to automatically classify trees that were marked with colored sprays automatically identify the numbers sprayed on the trees. The marked trees could be classified correctly with a balanced accuracy of 77.26% for PLS and 98.01% for the data collected with the TLS system using a support vector machine (SVM) model. The numbers written on the trees were classified from the TLS data using a YOLOv8 model. The accuracy of the digit classification reached up to 97.30%. In conclusion, it is possible to automatically detect marked trees and to automatically recognize the numbers spayed on these trees from colored point cloud data. However, accuracy strongly depends on the selected combination of scanner and camera. The findings of future research on this subject might differ with the ongoing development of PLS systems and could be enhanced by creating a large dataset of handwritten numbers collected using laser scanning systems.}
}
@article{MONTAGHI2024102433,
title = {An open-source cloud-based procedure for MODIS remote sensing products: The nasawebservicepython package},
journal = {Ecological Informatics},
volume = {79},
pages = {102433},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102433},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004624},
author = {Alessandro Montaghi and Simone Bregaglio and Sofia Bajocco},
keywords = {Smart farming, Open-source software, Python, MODIS, Cloud-application},
abstract = {Living in the era of “big data” demands an increase in the application and development of solutions for data ingestion in agroecological research, both in the private and public sectors. Among available data sources, satellite imagery is a viable solution to acquire large amounts of data at cheaper costs. Although cloud-based commercially distributed services are flourishing, open-source software able to assist practitioners and researchers in downloading and pre-processing satellite imagery is strongly demanded by the remote sensing community. This is especially true when looking at applications developed in Python, a programming language that quickly gained popularity in agroecological science. In this letter, we introduce nasawebservice version 1.0.0, a Python Package designed to automatically collect remotely sensed data from the NASA MODIS/VIIRS Land Products web service. The nasawebservice package contains a set of classes and methods to facilitate download operations for practitioners and researchers and to implement user-friendly data ingestion pipelines in local and cloud environments. The main advantage of nasawebservice is the reduction of pre-processing operations to use satellite images due to getting the data in JSON format, with consequent saving of computational time for large data download and analytic operational pipelines.}
}
@article{COMESANACEBRAL2024102612,
title = {Wildfire response of forest species from multispectral LiDAR data. A deep learning approach with synthetic data},
journal = {Ecological Informatics},
volume = {81},
pages = {102612},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102612},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001547},
author = {Lino Comesaña-Cebral and Joaquín Martínez-Sánchez and Gabriel Suárez-Fernández and Pedro Arias},
keywords = {Multispectral LiDAR, Deep learning, Fire response, Synthetic data, Wildfire},
abstract = {Forests play a crucial role as the lungs and life-support system of our planet, harbouring 80% of the Earth's biodiversity. However, we are witnessing an average loss of 480 ha of forest every hour because of destructive wildfires spreading across the globe. To effectively mitigate the threat of wildfires, it is crucial to devise precise and dependable approaches for forecasting fire dynamics and formulating efficient fire management strategies, such as the utilisation of fuel models. The objective of this study was to enhance forest fuel classification that considers only structural information, such as the Prometheus model, by integrating data on the fire responses of various tree species and other vegetation elements, such as ground litter and shrubs. This distinction can be achieved using multispectral (MS) Light Detection and Ranging (LiDAR) data in mixed forests. The methodology involves a novel approach in semantic classifications of forests by generating synthetic data with semantic labels regarding fire responses and reflectance information at different spectral bands, as a real MS scanner device would detect. Forests, which are highly intricate environments, present challenges in accurately classifying point clouds. To address this complexity, a deep learning (DL) model for semantic classification was trained on synthetic point clouds in different formats to achieve the best performance when leveraging MS data. Forest plots in the study region were scanned using different Terrestrial Laser Scanning sensors at wavelengths of 905 and 1550 nm. Subsequently, an interpolation process was applied to generate the MS point clouds of each plot, and the trained DL model was applied to classify them. These classifications surpassed the average thresholds of 90% and 75% for accuracy and intersection over union, respectively, resulting in a more precise categorisation of fuel models based on the distinct responses of forest elements to fire. The results of this study reveal the potential of MS LiDAR data and DL classification models for improving fuel model retrieval in forest ecosystems and enhancing wildfire management efforts.}
}
@article{SZABO2024102624,
title = {Aquatic vegetation mapping with UAS-cameras considering phenotypes},
journal = {Ecological Informatics},
volume = {81},
pages = {102624},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102624},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001663},
author = {Loránd Szabó and László Bertalan and Gergely Szabó and István Grigorszky and Imre Somlyai and György Dévai and Sándor Alex Nagy and Imre J. Holb and Szilárd Szabó},
keywords = {Image classification, Spectral index, Texture index, DSM, Data fusion, UAS, Recursive feature elimination, Aquatic vegetation},
abstract = {Aquatic vegetation species at the genus level in an oxbow lake were identified in Hungary based on a multispectral Uncrewed Aerial System (UAS) survey within an elongated oxbow lake area of the Tisza River under continental climate. Seven and 13 classes were discriminated using three different classification methods (Support Vector Machine [SVM], Random Forest [RF], and Multivariate Adaptive Regression Splines [MARS]) using different input data in ten combinations: original spectral bands, spectral indices, Digital Surface Model (DSM), and Haralick texture indices. We achieved a high (97.1%) overall accuracies (OAs) by applying the SVM classifier, but the RF performed only <1% worse, as it was represented in the first places of the classification rank before the MARS. The highest classification accuracies (>84% OA) were obtained using the most important variables derived by the Recursive Feature Elimination (RFE) method. The best classification required DSM as an input variable. The poorest classification performance belonged to the model that used only texture indices or spectral indices. On the class level, Stratiotes aloides exhibit the lowest degree of separability compared to the other classes. Accordingly, we recommend using supplementary input data for the classifications besides the original spectral bands, for example, DSM, spectral, and texture indices, as these variables significantly improve the classification accuracies in the proper combinations of the input variables.}
}
@article{WANG2024102721,
title = {Forecasting ecological water demand of an arid oasis under a drying climate scenario based on deep learning methods},
journal = {Ecological Informatics},
volume = {82},
pages = {102721},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102721},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002632},
author = {Xu-dong Wang and Hao-jie Xu and Yan-xia Pan and Xue-mei Yang},
keywords = {Environmental flow, Artificial oasis, Model simulation, Meteorological drought, Scenario analysis},
abstract = {Ecological water diversion projects (EWDP) are an effective management tool for restoring oasis ecosystems in arid regions. Given the potential for drier climatic conditions in arid regions in the future, it is essential to develop water diversion strategies that can adapt to climate change and reduce the risk of oasis ecosystem degradation. Here, this study used a Bayesian optimization-based long- and short-term memory (BO-LSTM) model to determine the optimal amount of water diversion needed to maintain healthy growth of oasis vegetation under future climate change scenarios in the Qingtu Oasis, which is a typical downstream oasis of inland rivers restored by EWDP in China. The results showed that the BO-LSTM model effectively captured the response of oasis vegetation to changes in water inundation areas and drought stress with low computational cost and high accuracy. The study revealed that regional vegetation became more vulnerable than previously thought when extreme drought and a drying trend were taken into account. It was found that if the amount of water entering the oasis ranges from 10 to 15 million m3, there will be a decline in the growth of oasis vegetation as indicated by the normalized difference vegetation index (NDVI). Even if current levels of water diversion (20 million m3) are maintained, oasis vegetation may still face growth decline due to meteorological drought. The optimal amount of water diversion was determined to be 25 million m3, resulting in a 21.7% increase in NDVI regardless of drought events. This study represents an innovative approach as it couples EWDP, climate change, and oasis vegetation dynamics based on deep learning models, which unveils divergent responses of oasis vegetation to climate change and EWDP and verifies a non-linear relationship between water diversion amounts and ecological benefits generated.}
}
@article{LONG2024102681,
title = {From meteorological to agricultural drought: Propagation time and influencing factors over diverse underlying surfaces based on CNN-LSTM model},
journal = {Ecological Informatics},
volume = {82},
pages = {102681},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102681},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002231},
author = {Junchen Long and Changchun Xu and Yazhen Wang and Jing Zhang},
keywords = {Drought propagation, Seasonal variation, Hybrid deep learning model, Influencing factors, Land Use and Land Cover},
abstract = {As global warming intensifies and extreme weather events become more frequent, the severity of drought conditions in China's Xinjiang region has escalated. This exacerbates socio-economic pressures in the area and presents increasingly formidable challenges for the future. In response to these challenges, researching drought phenomena in Xinjiang is imperative. This study employs Bayesian methods and copula functions to estimate drought propagation time. It utilizes a hybrid deep learning model (CNN-LSTM) to analyze the process of drought propagation and its influencing factors across four land cover types: crops, forest land, grassland, and unused land. The findings indicate that Cropland experiences the longest average time of drought propagation (5.27 months), while forests have the shortest duration (4.2 months). Unused land and grassland exhibit similar average durations of propagation (4.8 months). On an annual scale, drought propagation time for each land type manifests in two phases: from January to May and from June to December. The former phase shows propagation time ranging from 6 to 9 months, while the latter ranges from 1 to 5 months; both demonstrate an increasing trend over time. Seasonally, all Land Cover Types exhibit a pattern of shorter propagation times in summer and autumn compared with winter and spring. Moreover, a longer time of drought propagation correlates with a greater disparity between meteorological and resultant agricultural drought severity. In analyzing the influence of factors on drought propagation, soil moisture content and El Niño-Southern Oscillation(ENSO) were found to significantly impact all Land Cover Types, progressively strengthening their influence over the years.}
}
@article{HOU2024102429,
title = {Exploring the optimal model for assessing SOC and TN in Zanthoxylum bungeanum forest on the Loess Plateau using VNIR spectroscopy},
journal = {Ecological Informatics},
volume = {79},
pages = {102429},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102429},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004582},
author = {Mengjia Hou and Zemin Ai and Xinghua Li and Xiaohu Dang and Yuyan Yao and Yi Deng and Tao Wang and Ting Li and Lie Xiao},
keywords = {Partial least squares regression, Support vector machine regression, Spectral pre-processing, Calibration models, Validation models},
abstract = {Zanthoxylum bungeanum forest is an important economic forest on the Loess Plateau. The rapid assessment of its soil organic carbon (SOC) and total nitrogen (TN) concentrations is critical for the evaluation of soil quality. Soil samples of different forest ages and soil depths were collected for laboratory analyses and spectral measurements, and the visible and near-infrared reflectance (VNIR) spectral data were processed by mathematical transformations, such as first-order derivative (FD) and second-order derivative, multiple scattering correction, and logarithm of the reciprocal. The importance bands of SOC and TN were screened on the basis of competitive adaptive reweighted sampling. In addition, partial least squares regression and support vector machine regression models were constructed, and the applicability of SOC and TN to the models were compared. Results showed that forest age and soil depth remarkably affect SOC and TN concentrations. Among the calibration and validation models, the combination of the SVMR model with Savitzky–Golay smoothing and FD estimated SOC and TN with the highest accuracy, and the validation accuracy of the surface SOC and TN was higher than that of the bottom depths. Meanwhile, the importance bands involved in the modeling were mainly distributed in 400–600 nm and 1000–2400 nm. The combination of the FD transformation and the SVMR model is suitable for determining SOC and TN concentrations in Z. bungeanum forests, and the model has great potential for the quantitative evaluation of soil quality in the Loess Plateau.}
}
@article{CARRIGER2024102665,
title = {Exploring coral reef communities in Puerto Rico using Bayesian networks},
journal = {Ecological Informatics},
volume = {82},
pages = {102665},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102665},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002073},
author = {John F. Carriger and William S. Fisher},
keywords = {Coral reefs, Community ecology, Bayesian networks, Cluster analysis},
abstract = {Most coral reef studies focus on scleractinian (stony) corals to indicate reef condition, but there are other prominent assemblages that play a role in ecosystem structure and function. In Puerto Rico these include fish, gorgonians, and sponges. The U.S. Environmental Protection Agency conducted unique surveys of coral reef communities across the southern coast of Puerto Rico that included simultaneous measurement of all four assemblages. Evaluating the results from a community perspective demands endpoints for all four assemblages, so patterns of community structure were explored by probabilistic clustering of measured variables with Bayesian networks. Most variables were found to have stronger associations within than between taxa, but unsupervised structure learning identified three cross-taxa relationships with potential ecological significance. Clusters for each assemblage were constructed using an expectation-maximization algorithm that created a factor node jointly characterizing the density, size, and diversity of individuals in each taxon. The clusters were characterized by the measured variables, and relationships to variables for other taxa were examined, such as stony coral clusters with fish variables. Each of the factor nodes were then used to create a set of meta-factor clusters that further summarized the aggregate monitoring variables for the four taxa. Once identified, taxon-specific and meta-clusters represent patterns of community structure that can be examined on a regional or site-specific basis to better understand risk assessment, risk management and delivery of ecosystem services.}
}
@article{WEI2024102445,
title = {YOLO_MRC: A fast and lightweight model for real-time detection and individual counting of Tephritidae pests},
journal = {Ecological Informatics},
volume = {79},
pages = {102445},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102445},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004740},
author = {Min Wei and Wei Zhan},
keywords = {Real-time detection, Individual counting, YOLOv8, Lightweight, Attention mechanism, },
abstract = {Tephritidae pests severely affect the quality and safety of various melons, fruits and vegetable crops. However, many agricultural managers lack an adequate understanding of the level of pest occurrence, resulting in the misuse of pesticides, which ultimately leads to environmental pollution and economic loss. Therefore, real-time detection and counting of Tephritidae pests are important for timely pest spotting and control. This work helps quickly determine the distribution and abundance of pests in the current environment, thus providing data on pest conditions for agricultural management to optimize pesticide use. Nevertheless, the fast speed, high accuracy, and lightweight performance of real-time detection and counting are difficult to balance. To address this problem, based on the YOLOv8n model, this paper takes Bactrocera cucurbitae pests as the detection target and proposes a fast and lightweight real-time detection and individual counting model for Tephritidae pests, named YOLO_MRC. This paper introduces three key improvements: (1) Constructing a new module called Multicat into the neck network increases the focus on the detection target by incorporating an attention mechanism; (2) Reducing the original three detection heads to two and then adjusting their sizes to decrease the number of parameters in the network model; (3) Devising a novel module, C2flite, to enhance the deep feature extraction capability of the backbone network. According to the above points, this paper conducts ablation experiments to compare the performances of different models. Experiments showed that the Multicat module significantly offsets the large increase in GFLOPs and processing time caused by reducing the detection head and can further reduce the number of parameters and improve the accuracy when combined with the C2flite module. On our Bactrocera cucurbitae pest dataset, the mAP@0.5 of the YOLO_MRC model reached 99.3%. Simultaneously, as the number of parameters decreases by 63.68%, GFLOPs is reduced by 19.75%, and the processing time is shortened by 5%. To ensure the validity of the model, YOLO_MRC is compared with four excellent detection models by using manual counting results as the benchmark. YOLO_MRC achieves an average pest counting accuracy of 94%, demonstrating superior performance in terms of model size and processing time. To further explore the performance of YOLO_MRC in multiclass insect detection tasks, we choose the public dataset Pest_24_640 for comparison with four state-of-the-art models. YOLO_MRC achieves a 3.6 ms processing time and 70.4% accuracy with only a 2.4 MB model size, which demonstrates the potential of YOLO_MRC in multiclass pest detection.}
}
@article{KIKUCHI2022101767,
title = {Wild birds in YouTube videos: Presence of specific species contributes to increased views},
journal = {Ecological Informatics},
volume = {71},
pages = {101767},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101767},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002175},
author = {Yutaro Kikuchi and Issei Nishimura and Takehiro Sasaki},
keywords = {Bird watching, Cultural ecosystem services, Feature selection, Random forest, Songbirds, Social network service},
abstract = {Recent advances in understanding cultural ecosystem services (CES) using big data such as social media and other web archives have been primarily made to identify the relationships between the specific indicators for CES and large-scale features of ecosystems, such as vegetation covers and types, ecosystem types, naturalness, and the proportion of areas designated as protected areas. Yet, we know little about how biodiversity and specific species contribute to the enhancement of CES. Here, we examined the factors influencing the number of views in YouTube videos displaying wild birds in nature as a direct indicator of CES related to aesthetic enjoyment, environmental education, and nature experience. We found that the presence of specific wild bird species (i.e., Streptopelia orientalis and Larvivora cyane) increased the number of views while controlling for confounding factors such as the length of the video and the number of days since uploading. We suggest that these species are widely recognized, positively perceived presumably owing to their cultural significance, and preferred among viewers watching videos of wild birds, resulting in more views for videos including these species. Finally, we depicted the geographic distribution (on a national scale) of YouTube videos displaying wild birds in nature. Urban and agricultural land cover around the geotagged location of each video negatively affected the number of views, suggesting that over-exploitation of ecosystems may lead to the loss of important CES. Our study thus demonstrates the contributions of specific wild bird species to enhancing the CES related to aesthetic enjoyment, environmental education, and nature experience, provided through online shared videos.}
}
@article{MCEWEN2023102280,
title = {Automatic noise reduction of extremely sparse vocalisations for bioacoustic monitoring},
journal = {Ecological Informatics},
volume = {77},
pages = {102280},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102280},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003096},
author = {Ben McEwen and Kaspar Soltero and Stefanie Gutschmidt and Andrew Bainbridge-Smith and James Atlas and Richard Green},
keywords = {Audio enhancement, Bioacoustics, Noise reduction, Perceptual quality, Signal processing},
abstract = {Environmental noise and data sparsity present major challenges within the field of bioacoustics. The presence of noise degrades the analysis of audio and field recordings commonly containing large quantities of data with sparse vocalisation features. This work explores noise reduction (audio enhancement) techniques in the context of extremely sparse vocalisations (< 1% occurrence rates) of invasive mammalian and marsupial species, and the clear implications for other bioacoustics applications which face similar challenges. This work compares relevant noise reduction techniques and recommends a spectral subtraction approach. Spectral subtraction achieved a 42.1 dB improvement in signal to noise power (SnNR) and a 2.7 dB improvement in noise variance (SR). We also demonstrate reliable noise reduction at bandwidths up to 250 kHz and efficiency improvements compared to alternative methods. We explore the benefits of deep audio enhancement approaches demonstrating comparable noise reduction with improvements in transient noise reduction but also key limitations such as bandwidth, efficiency and data generation in bioacoustics applications. We identify how the contributions of this work can be applied within the broader context of bioacoustics. All data and code is publicly available at https://github.com/BenMcEwen1/Sparse-Noise-Reduction}
}
@article{PIECHAUD2022101786,
title = {Fast and accurate mapping of fine scale abundance of a VME in the deep sea with computer vision},
journal = {Ecological Informatics},
volume = {71},
pages = {101786},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101786},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002369},
author = {Nils Piechaud and Kerry L. Howell},
keywords = {Benthic ecology, Computer vision, Xenophyophores, Quantitative ecology, Mapping, Automated image analysis, Marine conservation},
abstract = {With growing anthropogenic pressure on deep-sea ecosystems, large quantities of data are needed to understand their ecology, monitor changes over time and inform conservation managers. Current methods of image analysis are too slow to meet these requirements. Recently, computer vision has become more accessible to biologists, and could help address this challenge. In this study we demonstrate a method by which non-specialists can train a YOLOV4 Convolutional Neural Network (CNN) able to count and measure a single class of objects. We apply CV to the extraction of quantitative data on the density and population size structure of the xenophyophore Syringammina fragilissima, from more than 58,000 images taken by an AUV 1200 m deep in the North-East Atlantic. The workflow developed used open-source tools, cloud-base hardware, and only required a level of experience with CV commonly found among ecologists. The CNN performed well, achieving a recall of 0.84 and precision of 0.91. Individual counts per image and size measurements resulting from model predictions were highly correlated (0.96 and 0.92, respectively) with manually collected data. The analysis could be completed in less than 10 days thus bringing novel insights into the population size structure and fine scale distribution of this Vulnerable Marine Ecosystem. It showed S. fragilissima distribution is patchy. The average density is 2.5 ind.m−2 but can vary from up to 45 ind.m−2 only a few tens of meter away from areas where it is almost absent. The average size is 5.5 cm and the largest individuals (>15 cm) tend to be in areas of low density. This study demonstrates how researchers could take advantage of CV to quickly and efficiently generate large quantitative datasets data on benthic ecosystems extent and distribution. This, coupled with the large sampling capacity of AUVs could bypass the bottleneck of image analysis and greatly facilitate future deep-ocean exploration and monitoring. It also illustrates the future potential of these new technologies to meet the goals set by the UN Ocean Decade.}
}
@article{XU2024102518,
title = {Mapping the potential distribution of Asian elephants: Implications for conservation and human–elephant conflict mitigation in South and Southeast Asia},
journal = {Ecological Informatics},
volume = {80},
pages = {102518},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102518},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000608},
author = {Haixia Xu and Luguang Jiang and Ye Liu},
keywords = {Asian elephant, Maximum entropy, Environmental features, Population characteristics},
abstract = {Asian elephants play a pivotal role in their ecosystem. Understanding the potential distribution area of this species is vital for effective conservation efforts and mitigation of human-elephant conflicts. In this study, we used the maximum entropy to simulate the potential distribution area of Asian elephants across South and Southeast Asia, leveraging Maximum Entropy (MaxEnt) and presence data sourced from the Global Biodiversity Information Facility (GBIF). The analysis revealed that the potential distribution area of Asian elephants spans 530,418 km2 (10.59% of the study area), with significant potential distribution areas observed in Indonesia (136,890 km2) and Malaysia (119,497 km2). Vegetation type emerged as the dominant environmental factor influencing model outcomes, encompassing aspects such as broadleaved evergreen tree coverage, broadleaved deciduous closed tree coverage and EVI. The potential distribution area of Asian elephants overlaps with regions inhabited by 55.25 million people, with 6.07 million people residing in highly suitable habitats. India and Malaysia have high potential for human-elephant conflict (HEC) due to the high number of people living in potential and highly suitable habitats for elephants. Bangladesh and Nepal, on the other hand, have fewer people living in these habitats suitable for elephants, but they face relatively high human population density in these areas.}
}
@article{AKINOSHO2022101609,
title = {A scalable deep learning system for monitoring and forecasting pollutant concentration levels on UK highways},
journal = {Ecological Informatics},
volume = {69},
pages = {101609},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101609},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122000589},
author = {Taofeek D. Akinosho and Lukumon O. Oyedele and Muhammad Bilal and Ari Y. Barrera-Animas and Abdul-Quayyum Gbadamosi and Oladimeji A. Olawale},
keywords = {Urban air pollution, Air quality prediction, Highway, Deep learning, Big data, Internet of things},
abstract = {The construction of intercity highways by the government has resulted in a progressive increase in vehicle emissions and pollution from noise, dust, and vibrations despite its recognition of the air pollution menace. Efforts that have targeted roadside pollution still do not accurately monitor deadly pollutants such as nitrogen oxides and particulate matter. Reports on regional highways across the country are based on a limited number of fixed monitoring stations that are sometimes located far from the highway. These periodic and coarse-grained measurements cause inefficient highway air quality reporting, leading to inaccurate air quality forecasts. This paper, therefore, proposes and validates a scalable deep learning framework for efficiently capturing fine-grained highway data and forecasting future concentration levels. Highways in four different UK regions - Newport, Lewisham, Southwark, and Chepstow were used as case studies to develop a REVIS system and validate the proposed framework. REVIS examined the framework's ability to capture granular pollution data, scale up its storage facility to rapid data growth and translate high-level user queries to structured query language (SQL) required for exploratory data analysis. Finally, the framework's suitability for predictive analytics was tested using fastai's library for tabular data, and automated hyperparameter tuning was implemented using bayesian optimisation. The results of our experiments demonstrate the suitability of the proposed framework in building end-to-end systems for extensive monitoring and forecasting of pollutant concentration levels on highways. The study serves as a background for future related research looking to improve the overall performance of roadside and highway air quality forecasting models.}
}
@article{TOOSI2022101733,
title = {Citrus orchard mapping in Juybar, Iran: Analysis of NDVI time series and feature fusion of multi-source satellite imageries},
journal = {Ecological Informatics},
volume = {70},
pages = {101733},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101733},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122001832},
author = {Ahmad Toosi and Farzaneh Dadrass Javan and Farhad Samadzadegan and Soroosh Mehravar and Alishir Kurban and Hossein Azadi},
keywords = {Precision agriculture, Crop mapping, Citrus orchard, Data fusion, Change detection, Google Earth Engine},
abstract = {Nowadays crop mapping as an interdisciplinary hot topic attracted both agriculture and remote sensing researchers' interests. This study proposed an automatic method to map citrus orchards in Juybar, Iran, where planting citrus trees is booming there. In this regard, 148 Sentinel-1, Sentinel-2, and ALOS Digital Surface Model (DSM) tiles are processed in Google Earth Engine to provide a hybrid feature set including initial satellite images, Gray Level Co-occurrence Matrix (GLCM) textural features, and spectral features such as vegetation, built-up, bare-soil indices, and the proposed Vegetation Dynamic Index (VDI). A semi-automatic sample selection paradigm is also developed based on a time-series analysis of 12 monthly Normalized Difference Vegetation Indices (NDVIs), Otsu thresholding, multi-level thresholding (MLT), and using two proposed indices called Evergreenness Index (EGI) and Water-covered or No-vegetation (WCNV) index, and finally human post-revision. The output of the Support Vector Machine (SVM) classification using 60,000 samples and the post-classification operation showed that the classified map has an average overall accuracy (OA) and an average kappa coefficient (KC) equal to 99.7% and 0.992, respectively. The results show that multispectral bands lonely extracted orchards with high accuracy (OA: 99.55%, KC: 0.986), and the rest of the features only made a slight improvement to that. For the year 2019, an area of about 4351 ha is estimated as citrus orchards, which is in accordance with the agriculture department's reports (~4700 ha). The results indicate that from 2016 to 2019, despite a “citrus to non-citrus” land-use conversion of about 754 ha, the citrus orchards area was totally expanded by about 17%. Comparing the results with the Google Earth images indicates the precise extraction of orchards with a 10 m spatial resolution. To use the proposed method for extensive cases or areas with other types of evergreen trees, it is recommended to use high-resolution normalized DSMs (nDSMs) and textural features.}
}
@article{RYDHMER2021101456,
title = {Dynamic β-VAEs for quantifying biodiversity by clustering optically recorded insect signals},
journal = {Ecological Informatics},
volume = {66},
pages = {101456},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101456},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002478},
author = {Klas Rydhmer and Raghavendra Selvan},
keywords = {Unsupervised clustering, VAE, Insect classification, Biodiversity},
abstract = {While insects are the largest and most diverse group of terrestrial animals, constituting ca. 80% of all known species, they are difficult to study due to their small size and similarity between species. Conventional monitoring techniques depend on time consuming trapping methods and tedious microscope-based work by skilled experts in order to identify the caught insect specimen at species, or even family level. Researchers and policy makers are in urgent need of a scalable monitoring tool in order to conserve biodiversity and secure human food production due to the rapid decline in insect numbers. Novel automated optical monitoring equipment can record tens of thousands of insect observations in a single day and the ability to identify key targets at species level can be a vital tool for entomologists, biologists and agronomists. Recent work has aimed for a broader analysis using unsupervised clustering as a proxy for conventional biodiversity measures, such as species richness and species evenness, without actually identifying the species of the detected target. In order to improve upon existing insect clustering methods, we propose an adaptive variant of the variational autoencoder (VAE) which is capable of clustering data by phylogenetic groups. The proposed dynamic β-VAE dynamically adapts the scaling of the reconstruction and regularization loss terms (β value) yielding useful latent representations of the input data. We demonstrate the usefulness of the dynamic β-VAE on optically recorded insect signals from regions of southern Scandinavia to cluster unlabelled targets into possible species. We also demonstrate improved clustering performance in a semi-supervised setting using a small subset of labelled data. These experimental results, in both unsupervised- and semi-supervised settings, with the dynamic β-VAE are promising and, in the near future, can be deployed to monitor insects and conserve the rapidly declining insect biodiversity.}
}
@article{LIU2024102622,
title = {Rice leaf chlorophyll content estimation with different crop coverages based on Sentinel-2},
journal = {Ecological Informatics},
volume = {81},
pages = {102622},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102622},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400164X},
author = {Lushi Liu and Yichen Xie and Bingxue Zhu and Kaishan Song},
keywords = {LCC estimation, Vegetation index, Crop coverage, Rice, Sentinel-2},
abstract = {Chlorophyll content is an important index for evaluating the health and productivity of crops, and environmental stress on them. The real-time, rapid, and accurate acquisition of chlorophyll content plays a key role in crop growth monitoring. Remote sensing can quickly obtain chlorophyll content in regional and global scale, but how to eliminate the interference of soil background in estimation is a major challenge. The statistical analysis method based on empirical/semi-empirical model is simpler, faster and easier to implement than that based on radiative transfer mechanism model. The statistical analysis method can eliminate the influence of environmental background by looking for a Vegetation index (VI) that is sensitive to the chlorophyll content but not to soil background to a certain extent. However, the accuracy of this method is low in fields with different degrees of crop coverage. Additionally, the special soil background characteristics of rice fields make the method a doubtful tool to estimate the Chlorophyll content in rice coverage. To improve the accuracy of the rice leaf chlorophyll content (LCC) estimation model, we here propose a new model based on crop coverage. We analyzed remote sensing images of the Sentinel-2 over rice-planting areas of Qian Gorlos County in Jilin Province of China. We divided the study area into three regions based on high-, medium-, and low-rice canopy coverage. Rice LCC in each region was estimated by identifying remote sensing vegetation indices that are sensitive to chlorophyll in different rice canopy coverages. Compared to the estimated results without considering the crop coverage, our model achieves a higher accuracy. In addition, we applied the model in the region of Northeast China in 2023 to verify its strong generalisability and robustness. Our study provides a reference for rapidly and non-destructively obtaining rice LCC based on Sentinel-2 images. However, the applicability of our model to other crops will be verified in the future.}
}
@article{MA2024102651,
title = {UAV equipped with infrared imaging for Cervidae monitoring: Improving detection accuracy by eliminating background information interference},
journal = {Ecological Informatics},
volume = {81},
pages = {102651},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102651},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001936},
author = {Guangkai Ma and Wenjiao Li and Heng Bao and Nathan James Roberts and Yang Li and Weihua Zhang and Kun Yang and Guangshun Jiang},
keywords = {YOLOv7, ViT, Wild Cervidae monitoring},
abstract = {Wild Cervidae(deer and their relatives) play a crucial role in maintaining ecological balance and are integral components of ecosystems. However, factors such as environmental changes and poaching behaviors have resulted in habitat degradation for Cervidae. The protection of wild Cervidae has become urgent, and Cervidae monitoring is one of the key means to ensure the effectiveness of wild Cervidae protection. Object detection algorithms based on deep learning offer promising potential for automatically detecting and identifying animals. However, when those algorithms are used for inference in unseen background environments, there will be a significant decrease in accuracy, especially in the situation that a certain type of Cervidae images are collected from single scene for algorithm training. In this paper, a two-stage localization and classification pipeline for Cervidae monitoring is proposed. The pipeline effectively reduces background interference in Cervidae monitoring and enhances monitoring accuracy. In the first stage, the YOLOv7 network is designed to automatically locate Cervidae in UAV infrared images, while implementing improved bounding box regression through the α-IoU loss function enables the network to locate Cervidae more accurately. Then, Cevdidae objects are extracted to eliminate the background information. In the second stage, a classification network named CA-Hybrid, based on Convolutional Neural Networks(CNN) and Vision Transformer(ViT), as well as Channel Attention Mechanism(CAM) enhances the expression of key features, is constructed to accurately identify Cervidae categories. Experimental results indicate that this method achieves an Average Precision (AP) of 95.9% for Cervidae location and a top-1 accuracy of 77.73% for Cervidae identification. This research contributes to a more comprehensive and accurate monitoring of wild Cervidae, and provides valuable references for subsequent UAV-based wildlife monitoring.}
}
@article{MORITAKE2024102462,
title = {Sub-alpine shrub classification using UAV images: Performance of human observers vs DL classifiers},
journal = {Ecological Informatics},
volume = {80},
pages = {102462},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102462},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000049},
author = {Koma Moritake and Mariano Cabezas and Tran Thi Cam Nhung and Maximo Larry {Lopez Caceres} and Yago Diez},
keywords = {Sub-alpine vegetation, Vegetation change monitoring, Deep learning, Observer study, ConvNeXt, Swin},
abstract = {In recent years, the automatic analysis of natural environment images acquired with unmanned aerial vehicles (UAV) has rapidly gained popularity. UAVs are specially important in mountainous forests where access is difficult and large areas need to be surveyed. In Zao mountains in northeastern Japan, regenerated fir saplings are competing with sub-alpine vegetation shrubs after a severe fir tree mortality caused by bark beetle infestation. A detailed survey of vegetation distribution is key to improve our understanding of species succession and the influence of climate change in that process. To that end, we evaluated the suitability of deep-learning-based automatic image classification of UAV images in order to map sub-alpine vegetation succession in large areas and the potential of fir regeneration. In order to assess the contribution of this technology in this research field, we first conducted an observer study to assess the difficulty for humans of the task of classifying vegetation from images. Afterwards, we compared the observers' accuracy to four state-of-the art deep learning networks for automatic image classification. The best observer accuracy of 55% demonstrates the limitations of species classification using only images. Furthermore, a detailed analysis of the sources of error showed that even though humans could differentiate between deciduous and evergreen species with an accuracy of 96%, identifying the correct species within each group proved much more challenging. In contrast, deep learning networks achieved accuracy values in the range of 70–80% for species classification, clearly demonstrating capabilities beyond human experts. Our experiments also indicated that the performance of these networks was significantly influenced by the similarity between the datasets used to fine-tune them and evaluate them. This fact highlights the importance of building publicly available images databases to further improve the results. Nevertheless, the results presented in this paper show that the analysis of UAV-acquired with deep learning networks can usher in a new type of large-scale study, spanning tenths or even hundreds of hectares with high spatial resolution (of a few cms per pixel), providing the ability to assess challenging vegetation dynamics problems that go beyond the ability of conventional fieldwork methodologies.}
}
@article{MICHAELSEN2022101721,
title = {Uncertainty and ignored information in the analysis of bat ultrasound: Bayesian approximation to the rescue},
journal = {Ecological Informatics},
volume = {70},
pages = {101721},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101721},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122001716},
author = {Tore Christian Michaelsen and Jens Rydell and Rasmus Bååth and Knut Helge Jensen},
keywords = {Bayesian statistics, Bat ultrasound analysis, Probability theory, GNU R},
abstract = {Bat ultrasound analysis has been around for several decades and it is one of the most important tools in studies of bat ecology. Discrimination between species is based on intra-specific features of echolocation calls. Identification of species and genera in audio files can be attempted either manually or through software which performs a fully automated discrimination between species. However, significant overlap in various features (e.g. frequencies of calls) exists between species and even genera. Species ID is therefore often not an absolute conclusion, but rather an opinion or best guess, as opposed to DNA tests or measurements on external characters of captured bats. To make things even worse, the probability of actually observing a bat of a given species in space and time is ignored when performing bat ultrasound analysis. This study introduces Bayesian approximation through a new method we have named Alternative Bayesian Bat Analysis (ABBA). We show, through a simple proof-of-concept example, the importance of adding information about the local composition of the bat community, hence making informed decisions regarding which species is most likely present in audio files. The superior performance of ABBA is also shown through an example using R code. Here, we use simulated data for three Pipistrellus spp., a genus with significant overlap in frequencies, but the code can easily be adapted to other bat species and genera worldwide. ABBA outperformed the non-Bayesian approach for all three species. The rare species in the simulated data set was super-inflated when using the non-Bayesian method. Further the results show, contrarily to common belief, that the frequency dominated by a given species in a data set, depends on the composition of the bat fauna and not just means and SDs reported in the literature. ABBA allows researchers to include all observations in statistical modeling, rather than excluding observations, an approach which can affect the reliability of studies. This study also, to a great extent, explains the poor performance of software attempting automated bat ID. Implementing Bayesian algorithms, and thereby allowing users to interact with the software, should significantly improve their performance.}
}
@article{AREPALLI2024102405,
title = {Water contamination analysis in IoT enabled aquaculture using deep learning based AODEGRU},
journal = {Ecological Informatics},
volume = {79},
pages = {102405},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102405},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300434X},
author = {Peda Gopi Arepalli and K. Jairam Naik},
keywords = {Water quality, Water contamination, Water contamination index (WCI), Gated recurrent unit (GRU), Internet of things (IoT)},
abstract = {Water contamination presents a significant challenge in aquaculture, impacting the sustainability of ecosystems and the health of aquatic organisms. Precisely assessing water contamination levels is crucial for effective monitoring and safeguarding aquatic life within the aquaculture industry. Traditional methods for evaluating water contamination are characterized by their costliness, time-consuming nature, and susceptibility to errors. Integrating computer technologies such as Artificial Intelligence (AI), the Internet of Things (IoT), and Data Analytics offers promising potential in addressing this issue. Nevertheless, current deep learning solutions have limitations related to data variability, interpretability, and performance. To address these limitations, this study proposes a comprehensive framework that incorporates IoT-based data collection and data segregation techniques to enhance the accuracy of water contamination classification in aquaculture. Real-time data collected through IoT devices, encompassing parameters like temperature, pH levels, dissolved oxygen, nitrate concentration, and other water quality indicators, enables a holistic evaluation of water quality. By considering predefined acceptable ranges for aquatic life, this framework calculates a water contamination index, facilitating the classification of data into categories such as contaminated and non-contaminated. To ensure robust classification, the study introduces an innovative attention-based model known as the Ordinary Differential Equation Gated Recurrent Unit (AODEGRU). This attention mechanism directs the model's focus towards salient features associated with water contamination, while the AODEGRU architecture captures temporal patterns within the data. Experimental results underscore the effectiveness of the proposed model. It demonstrates its superiority with high performance, achieving an accuracy rate of approximately 98.69% on a publicly available dataset and an impressive 99.89% accuracy on a real-time dataset, clearly outperforming existing methodologies.}
}
@article{LUNANARANJO2024102668,
title = {Quantifying and mitigating recorder-induced variability in ecological acoustic indices},
journal = {Ecological Informatics},
volume = {82},
pages = {102668},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102668},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002103},
author = {David Luna-Naranjo and Juan D. Martinez-Vargas and Camilo Sánchez-Giraldo and Juan M. Daza and José D. López},
keywords = {Audio recorders, Ecoacoustics, Ecological acoustic indices, Pre-processing},
abstract = {Due to the complexity of soundscapes, Ecological Acoustic Indices (EAI) are frequently used as metrics to summarize ecologically meaningful information from audio recordings. Recent technological advances have allowed the rapid development of many audio recording devices with significant hardware/firmware variations among brands, whose effects in calculating EAI have not yet been determined. In this work, we show how recordings of the same landscape with different devices effectively hinder reproducibility and produce contradictory results. To address these issues, we propose a preprocessing pipeline to reduce EAI variability resulting from different hardware without altering the target information in the audio. To this end, we tested eight EAI commonly used in soundscape analyses. We targeted three common cases of variability caused by recorder characteristics: sampling frequency, microphone gain variation, and frequency response. We quantified the difference in the probability density functions of each index among recorders according to the Kullback-Leibler divergence. As a result, our approach reduced up to 75% variations among recorders from different brands (AudioMoth and SongMeter) and identified the conditions in which these devices are comparable. In conclusion, we demonstrated that different devices effectively affect EAI and show how these variations can be mitigated.}
}
@article{WANG2024102571,
title = {Evaluation of the role of urban domestic wastewater treatment systems for greenhouse gases emissions in China},
journal = {Ecological Informatics},
volume = {81},
pages = {102571},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102571},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001134},
author = {Tianxiang Wang and Zixiong Wang and Tianzi Wang and Ma Shumin and Suduan Hu and Shanjun Gao and Li Ye and Cui Runfa and George Arhonditsis},
keywords = {Greenhouse gas emissions, Urban domestic wastewater treatment systems, Carbon neutrality, Climate change},
abstract = {Rapid urbanization has exacerbated the dual challenge of mitigating water pollution and reducing greenhouse gas (GHG) emissions. The present study offers insights into the actual role of urban domestic wastewater treatment systems by shedding light on their capacity to act as GHG emitters. We introduce a modelling framework to calculate GHG emissions from wastewater treatment systems in China over the past two decades. Our analysis showed that treated wastewater volume increased by over 4.5 times, but GHG emissions also increased by 2.9 times. The annual emissions from wastewater treatment were -on average- nearly 60 Tg CO2-eq over the past two decades, accounting for <1% of the total national emissions. We also found a significant spatial variability with thirteen developed areas contributing >70% of the GHG emissions. Constructions and operations of wastewater treatment systems approximately accounted for 17% and 83% of the GHG emissions, respectively. Our study also proposes a hierarchical governance framework based on ten major regions that could maximize the efficiency in mitigating water pollution and GHG emissions in China.}
}
@article{GUO2024102607,
title = {A novel space–spectrum array tile probability random-forest model enhances LULC mapping accuracy on Google Earth Engine: An experiment in Ordos, China},
journal = {Ecological Informatics},
volume = {81},
pages = {102607},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102607},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001493},
author = {Fuchen Guo and Liangxin Fan and Chengkang Zhang and Sha Xue},
keywords = {Arid zone, LULC, Tile, Multiple probabilistic classification, Space–spectrum array, Random forest, Google earth engine},
abstract = {The rapid renewal of land use and land cover (LULC) maps using remote-sensing technologies constitutes a sine qua non for judicious land resource management at both regional and national scales. Existing research conducted on the Google Earth Engine (GEE) platform has overwhelmingly focused on pixel-based LULC classification techniques, often neglecting the role of spatial context via neighbouring valuable pixel information. Remarkably, little attention has been paid to the amalgamation of 3 × 3 neighbouring pixels into a three-dimensional space–spectrum array that can emulate the functionalities of object-based image analysis. In this study, we developed a novel integrated model consisting of a space–spectrum array (SSA) model based on 3 × 3 neighbouring pixels, a tile model based on random forest, and a multiple probabilistic classification model (SSA-TPRF) on the GEE platform to generate a LULC map with high overall accuracy (OA) for Ordos in 2020. Three bimonthly median value images were synthesised and feature collections, including spectral bands and vegetation indices, were constructed. Five experimental groups (EXP1–EXP5) were used to assess the different model combinations. Subsequent validation procedures employed abundant reference samples and compared the results with those of the three extant LULC mapping products. The results showed that EXP2, which was grounded in the tile-based model, yielded an OA of 87.53%, surpassing that of EXP1 (84.99%), which employed a traditional overall model. Furthermore, EXP3, which integrated the multiple probabilistic classification model with the traditional overall model, exhibited an OA of 85.19%, exceeding that of EXP1. A comparison of the five experimental groups using the four regional spatial subtlety features revealed that the EXP5, employing the SSA-TPRF model, successfully decreased the salt and pepper noise. The OA of six tile sizes ranging from 10 km to 100 km were compared, and the highest OA (88.35%) was achieved at a tile size of 25 km. The resultant LULC map in Ordos, derived from the SSA-TPRF model, showed superior OA compared with the extant LULC products. This study thus contributes to a versatile and scalable model within the GEE framework, offering avenues for facile adaptation and recurrent application across disparate geographical locations and temporal settings. The adaptability of this model is particularly advantageous for developing nations and regions typified by diverse landscapes, thereby catalysing the iterative updating of LULC maps through advanced remote-sensing paradigms.}
}
@article{KISTNER2024102676,
title = {Enhancing endangered species monitoring by lowering data entry requirements with imputation techniques as a preprocessing step for the footprint identification technology (FIT)},
journal = {Ecological Informatics},
volume = {82},
pages = {102676},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102676},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002188},
author = {Frederick Kistner and Justus Tulowietzki and Larissa Slaney and Sky Alibhai and Zoe Jewell and Burim Ramosaj and Markus Pauly},
keywords = {Endangered species, Footprint identification technology, Non-invasive monitoring, Imputation, Missing values, Random Forest},
abstract = {Numerous species of Earth's biota are at risk of extinction and wildlife conservation is more important than ever. Reliable baseline data are essential for wildlife management to inform on the numbers and distribution of endangered species. A promising non-invasive and cost-effective method for monitoring endangered species is the Footprint Identification Technology (FIT). It lends itself to both conservation research as well as citizen science and can be combined with other data collection methods. FIT extracts and uses morphometrics from animal footprints to create geometric profiles that are analyzed in customized classification models. These can identify species, sex and individual. The ability to identify individuals can then be used to predict various population parameters including size, distribution, and growth rate. FIT has been developed and published for several species, but it requires high quality footprints. Perfect prints are not always easy to find in the field as various factors can influence their quality. In this paper, we demonstrate that geometrical profiles derived from poor quality footprints can be seen as datasets with missing values. Missing values are a common problem in various disciplines, and well-established strategies to impute missing values are widely available. We conducted two experiments to see whether such an approach could widen the application of the FIT method. The experiments were designed to test the hypothesis that population sizes can be underestimated when incomplete footprints are discarded from the data. We artificially introduced different proportions of missing values in datasets with geometric profiles of five different species for which FIT models have been published. We also analyzed a new dataset of geometric profiles of cheetah (Acinonyx jubatus) footprints not meeting the standard FIT requirements. We demonstrated that excluding incomplete footprints led to an underestimation of the known population. As an alternative to discarding footprints, we compared different imputation techniques as data pre-processing steps by comparing the performance of resulting FIT models. When imputation was chosen instead, we could show that FIT models with imputed geometric profiles were not significantly less accurate in predicting individual ID or population size even with high rates of missing values. We believe that our findings can be generalized, and the results indicate that imperfect footprints can contribute to the robustness of the FIT method and that this approach is particularly applicable when few good-quality footprints are available. We therefore highly recommend including imputation of imperfect footprints as a data pre-processing step.}
}
@article{FAGARDJENKIN2024102486,
title = {Faster inference from state space models via GPU computing},
journal = {Ecological Informatics},
volume = {80},
pages = {102486},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102486},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000281},
author = {Calliste Fagard-Jenkin and Len Thomas},
keywords = {Bayesian inference, CUDA, GPU, Grey seal, , Particle filter, Parallel processing, Particle Markov chain Monte Carlo, Population dynamics model},
abstract = {Inexpensive Graphics Processing Units (GPUs) offer the potential to greatly speed up computation by employing their massively parallel architecture to perform arithmetic operations more efficiently. Population dynamics models are important tools in ecology and conservation. Modern Bayesian approaches allow biologically realistic models to be constructed and fitted to multiple data sources in an integrated modelling framework based on a class of statistical models called state space models. However, model fitting is often slow, requiring hours to weeks of computation. We demonstrate the benefits of GPU computing using a model for the population dynamics of British grey seals, fitted with a particle Markov chain Monte Carlo algorithm. Speed-ups of two orders of magnitude were obtained for estimations of the log-likelihood, compared to a traditional ‘CPU-only’ implementation, allowing for an accurate method of inference to be used where this was previously too computationally expensive to be viable. GPU computing has enormous potential, but one barrier to further adoption is a steep learning curve, due to GPUs' unique hardware architecture. We provide a detailed description of hardware and software setup, and our case study provides a template for other similar applications. We also provide a detailed tutorial-style description of GPU hardware architectures, and examples of important GPU-specific programming practices.}
}
@article{ZHANG2024102394,
title = {Evaluation of digital soil mapping projection in soil organic carbon change modeling},
journal = {Ecological Informatics},
volume = {79},
pages = {102394},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102394},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004235},
author = {Tao Zhang and Lai-Ming Huang and Ren-Min Yang},
keywords = {Soil carbon change, Digital soil mapping, Model projections, Environmental change, Temporal transferability},
abstract = {There is increasing interest in the application of digital soil mapping (DSM) projections to infer changes in soil carbon across both space and time. This approach relies on the assumption that the spatially modeled soil carbon-environment relationship can be transferred over time. However, this assumption is rarely tested due to a lack of temporally independent validation data. This paper assesses this assumption by developing models of topsoil organic carbon stocks (SOCS) with a deep learning algorithm and data covering mainland China pertaining to the 1980s and 2010s. The temporal prediction performance of models capturing a specific period was assessed by evaluating their performance in the prediction of data during another period. The results revealed that the prediction accuracy of temporal modeling decreased, as indicated by the coefficient of determination, and was lower than that of spatial modeling. The lower prediction accuracy obtained with the DSM-projection approach may result from differences in the magnitudes of influential variables across periods. We found that different levels of environmental similarity and model projection sensitivity to dynamic variables may cause discrepancies in forecast and hindcast accuracy. Our results demonstrate that the prediction error in temporal modeling is related to the degree of environmental similarity between periods. Our findings generally support the implementation of the DSM-projection approach in soil carbon change modeling. However, caution should be exercised, as there exists much uncertainty regarding the projection of spatial models over time.}
}
@article{YOU2023102200,
title = {Segmentation of individual mangrove trees using UAV-based LiDAR data},
journal = {Ecological Informatics},
volume = {77},
pages = {102200},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102200},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002297},
author = {Haotian You and Yao Liu and Peng Lei and Zhigang Qin and Qixu You},
keywords = {LiDAR data, CHM, Segmentation algorithm, Stand density, Spatial resolution},
abstract = {Accurate assessment of structural parameters is essential to effectively monitor the mangrove resources. However, the extraction results of mangrove structural parameters are closely related to the segmentation results of individual trees. Although the results of individual tree segmentation are influenced by many factors, the specific factors affecting the segmentation results of individual mangrove trees, such as data source, image resolution, segmentation algorithm, and stand density, have not yet been elucidated. Therefore, in this study, canopy height models (CHMs) with different spatial resolutions were derived from unmanned aerial vehicle (UAV)-based light detection and ranging (LiDAR) data. Moreover, the watershed algorithm (WA), regional growth (RG), and improved K-nearest neighbour (KNN) and bird's eye view (BEV) faster region-based convolutional neural network (R-CNN) algorithms were used to segment the individual mangrove trees based on CHMs and LiDAR data at three sites with varying stand densities. Finally, different segmentation algorithms, image resolutions, and forest densities were comparatively assessed to determine their influence on the segmentation results of individual trees. Segmentation accuracy of the improved KNN algorithm was the highest among the CHM-based algorithms, such as the WA, RG, and improved KNN algorithms, with an optimal F of 0.893 and minimum F of 0.628. R-CNN algorithm based on LiDAR data had an optimal F value of 0.931 and minimum F value of 0.612. Based on the segmentation results, the overall accuracy ranking of the different segmentation algorithms was BEV Faster R-CNN > improved KNN > RG > WA. The ranking of the segmentation results for sites with different stand densities was low-density (LD) > medium-density (MD) > high-density (HD). For LD and MD sites, the BEV Faster R-CNN algorithm had the highest F values (0.931 and 0.712, respectively). For the HD site, all algorithms performed poorly, and the F values of all algorithms, except the RG algorithm, were higher than 0.6. Based on the segmentation results of different spatial resolutions, CHM result with 0.1 m was the best, being better than the CHM results with 0.25 and 0.5 m. Our results demonstrated that all segmentation algorithms, spatial resolutions, and stand densities affected the segmentation results for individual mangrove trees. Although the segmentation results of the deep learning algorithm were better than those of the other algorithms, the segmentation results at the HD site were limited. Therefore, further research is necessary to improve the accuracy of the segmentation results for individual mangrove trees at HD sites.}
}
@article{KRIZOVA2022101496,
title = {Using a single-board computer as a low-cost instrument for SPAD value estimation through colour images and chlorophyll-related spectral indices},
journal = {Ecological Informatics},
volume = {67},
pages = {101496},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101496},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002879},
author = {Kateřina Křížová and Jan Kadeřábek and Václav Novák and Rostislav Linda and Gabriela Kurešová and Petr Šařec},
keywords = {Contact imaging, Image analysis, SPAD-502Plus, Raspberry Pi, Pi Camera, Python},
abstract = {The leaf chlorophyll content is a major indicator of plant stress. Therefore, it is often used for the evaluation of crop status to adjust agricultural management to ensure high quality yield while concurrently applying water and agrochemicals in a sustainable manner. Since laboratory procedures for their assessment are time-consuming and destructive, nondestructive methods have been developed recently based on known vegetation spectral response characteristics. In addition to various vegetation indices derived from remotely sensed data, hand-held sensors such as SPAD-502 are currently widely used for in-field sampling to gain precise information for decision-making in terms of best-fitting agricultural management. However, the costs of such commercial devices can be limiting for farmers. The low-cost alternatives that have been developed recently exploit widely accessible digital cameras with sensors sensitive to the visible region of the electromagnetic spectrum. Digital numbers extracted from colour images in RGB channels serve as the input for broadband “chlorophyll index” calculations. Major constraints regarding digital cameras are, however, the natural light illuminance and the necessity of data postprocessing. In the framework of this study, a novel technological solution was developed to address these issues. A Raspberry Pi single-board computer together with a Pi Camera and a simple LED incorporated in a 3D print case created a prototype called Rasp2SPAD, which was programmed to acquire and analyse a colour image. The prototype and its setup were further tested on the experimental plant material of the winter rapeseed. A set of 22 chlorophyll-related parameters across various colour representation models were generated, from which an SPAD value was modelled using i) a simple linear model, ii) a generalized linear model, and iii) an artificial neural network. The blue (Cb) and red (Cr) chroma components of the YUV colour space were found to be most suitable for SPAD value modelling. Calibration equations were determined, and the results reached relatively high accuracy (mean absolute deviance 1.85 and R-squared 0.81 for simple linear model) while keeping the costs significantly low compared to the most commonly used commercial sensor. In this way, a simple and cheap methodology was introduced to bring the results of research closer to practice, which should help first spread the precision agriculture concept to a wider audience and second allow them to utilize with it.}
}
@article{BAKANA2024102541,
title = {WildARe-YOLO: A lightweight and efficient wild animal recognition model},
journal = {Ecological Informatics},
volume = {80},
pages = {102541},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102541},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000839},
author = {Sibusiso Reuben Bakana and Yongfei Zhang and Bhekisipho Twala},
keywords = {Wild animal recognition, Deep learning, Lightweight, Efficient, Loss function},
abstract = {For the protection of endangered species and successful wildlife population monitoring, wild animal recognition is essential. While deep learning models like YOLOv5 have shown promise in real-time object recognition, their practical applicability may be constrained by their high processing requirements. In this paper, we suggest a faster and lighter version of YOLOv5s for wild animal recognition. To lower computational costs for model parameters and floating-point operations (FLOPs) for the backbone, our suggested model includes Mobile Bottleneck Block modules and an improved StemBlock. We also use Focal-EIoU as a loss function to gauge the accuracy of the predicted bounding boxes during inference and employ a BiFPN-based neck. We tested our technique on three datasets, including Wild Animal Facing Extinction, Fishmarket, and MS COCO 2017. Additionally, our technique is compared with state-of-the-art deep learning models, and from the baseline model we recorded a 17.65% increase in FPS, 28.55% model parameters reduction, and 50.92% in FLOPs reduction. Furthermore, our model has a faster model loading time, which is critical for deployment in remote areas. This enables real-time species recognition on basic hardware, aiding conservation efforts through rapid analysis. The model advances deep learning in ecology by balancing efficiency with performance.}
}
@article{MASSARELLI2023102342,
title = {Dynamics of pesticides in surface water bodies by applying data mining to spatiotemporal big data. A case study for the Puglia Region},
journal = {Ecological Informatics},
volume = {78},
pages = {102342},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102342},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003710},
author = {Carmine Massarelli and Claudia Campanale and Mariangela Triozzi and Vito Felice Uricchio},
keywords = {Plant protection products, Knowledge discovery in databases, Glyphosate, AMPA, Pesticides mixtures, Corine land cover, Geographic information system},
abstract = {Surface water pollution by pesticides is a primary concern in many parts of the world. Therefore, an effective monitoring program is essential to assess the environmental state of aquatic ecosystems and evaluate mitigation strategies. In the Puglia Region (southern Italy), a complex seasonal monitoring program for detecting pesticide residues in water was initiated in 2018 and is still underway (over four years). The program was based on site-specific assessments and identified 170 Plant Protection Products (PPPs) to identify residues in the surface water bodies of Puglia. In this context, the present work aims to analyse pesticide data obtained from the regional monitoring of rivers over four years using a multidisciplinary approach, which includes statistical methods, data mining, and mapping tools to extract as much information as possible.To this end, data mining was applied to identify the prevalent mixtures of pesticide residues found at the monitoring stations and correlate these results with possible causative factors. The results showed that surface water bodies are subject to different pressures derived from the massive use of PPPs, and several seasonal and territorial-related factors were identified to be strictly correlated with pesticide concentration results. Nine main PPPs mixtures have been identified in the Puglia River. Glyphosate, AMPA, imidacloprid, and azoxystrobin represent the main residues detected in the surface aquatic environments regarding the amount and frequency revealed. The methodological approach proposed in the present work can represent a good “model study” to be used by researchers to interpret water quality trends and data variability from long-term monitoring studies. Moreover, our results can significantly support the decision-making process and implementation of environmental mitigation measures by optimising the results of complex monitoring programs.}
}
@article{NTALAMPIRAS2023102043,
title = {An integrated system for the acoustic monitoring of goat farms},
journal = {Ecological Informatics},
volume = {75},
pages = {102043},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102043},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000729},
author = {Stavros Ntalampiras and Luca A. Ludovico and Giorgio Presti and Mael Vittorio Vena and Davide Fantini and Tyfenn Ogel and Stefania Celozzi and Monica Battini and Silvana Mattiello},
keywords = {Precision livestock farming, Acoustic monitoring, Internet of things, Goat farms, Animal vocalizations bioacoustics},
abstract = {Effective precision livestock farming requires the availability of reliable and up-to-date data characterizing the animals and environment of interest. This work presents the design, architecture, and implementation of a wireless acoustic sensor network for monitoring goat farms on a 24/7 basis. In addition, we define a hierarchical organization of the involved sound classes exhaustively covering every aspect of the encountered goat vocalizations. Moreover, we developed an annotation tool tailored to the specifics of the problem at hand, i.e. a big, real-world data environment, able to meaningfully assist the annotation of goat vocalizations via a suitable sound classification module. On top of that, a mobile phone application was developed facilitating authorized users to remotely access information describing the situation on the farm site. Importantly, such a non-invasive monitoring framework was installed in 4 different sites located in Northern Italy while taking into account their diverse characteristics.}
}
@article{DELPLANQUE2024102679,
title = {Will artificial intelligence revolutionize aerial surveys? A first large-scale semi-automated survey of African wildlife using oblique imagery and deep learning},
journal = {Ecological Informatics},
volume = {82},
pages = {102679},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102679},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002218},
author = {Alexandre Delplanque and Julie Linchant and Xavier Vincke and Richard Lamprey and Jérôme Théau and Cédric Vermeulen and Samuel Foucher and Amara Ouattara and Roger Kouadio and Philippe Lejeune},
keywords = {Wildlife population estimation, Aerial surveys, Deep learning, Biodiversity monitoring, Conservation technology, African savanna},
abstract = {Large African mammal populations are traditionally estimated using the systematic reconnaissance flights (SRF) with rear-seat observers (RSOs). The oblique-camera-count (OCC) approach, utilizing digital cameras on aircraft sides, proved to provide more reliable population estimates but incurs high manual processing costs. Addressing the urgent need for efficiency, the research explores whether a semi-automated deep learning (SADL) model coupled with OCC improves wildlife population estimates compared to the SRF-RSO method. The study area was the Comoé National Park, in Ivory Coast, spanning 11,488 km2 of savannas and open forests. It was surveyed following both SRF-RSO standards and OCC method. Key species included the elephant, western hartebeest, roan antelope, buffalo, kob, waterbuck and warthog. The deep learning model HerdNet, priorly pre-trained on images from Uganda, was incorporated in the SADL pipeline to process the 190,686 images. It involved three human verification steps to ensure quality of detections and to avoid overestimating counts. The entire pipeline aims to balance efficiency and human effort in wildlife population estimation. RSO and SADL-OCC approaches were compared using the Jolly II analysis and a verification of 200 random RSO observations. Jolly II analysis revealed SADL-OCC estimates significantly higher for small-sized species (kob, warthog) and comparable for other key species. Counting differences were mainly attributed to vegetation obstruction, RSO observations not found in the images, and suspected RSO counting errors. Human effort in the SADL-OCC approach totaled 111 h, representing a significant time savings compared to a fully manual interpretation. Introducing the SADL approach for aerial surveys in Comoé National Park enabled us to address the OCC's time-intensive image interpretation. Achieving a significant reduction in human workload, our method provided population estimates comparable to or better than SRF-RSO counts. Vegetation obstruction was a key factor explaining differences, highlighting the OCC method's limitation in vegetated areas. Method comparisons emphasized SADL-OCC's advantages in spotting isolated, small and static animals, reducing count variance between sample units. Despite limitations, the SADL-OCC approach offers transformative potential, suggesting a shift towards DL-assisted aerial surveys for increased efficiency and affordability, especially using microlight aircraft and drones in future wildlife monitoring initiatives.}
}
@article{JATOESPINO2024102731,
title = {Spatiotemporal analysis of landscape dynamics and their use as input for the design of a habitat suitability index: A case study of Oryctolagus cuniculus in a Mediterranean region},
journal = {Ecological Informatics},
volume = {82},
pages = {102731},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102731},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002735},
author = {Daniel Jato-Espino and Sophie Lierow},
keywords = {Geographic information system, Habitat suitability index, Landscape dynamics, Land cover naturalness, Multi-criteria decision analysis},
abstract = {The connectivity of landscapes is increasingly threatened by urban sprawl, which leads to the fragmentation of habitats and thus endangers the species that live there. To address this situation, landscape dynamics in the literature have mostly been analyzed using predefined land cover classes, which were then not used to assess habitat suitability, but instead relied on physical variables. As a bridge between both aspects, this study aimed to model the spatiotemporal patterns of landscape fragmentation by analyzing the landscape metrics associated with four land cover groups classified according to their naturalness. Landscape metrics were then combined with a range of terrain, climate and proximity variables to develop a Habitat Suitability Index (HSI) for terrestrial animal species. The proposed methodology was tested using a case study in the Mediterranean region of the Valencian Community (Spain): landscape dynamics were assessed over the period 1992–2015, while the HSI was tested with the European rabbit (Oryctolagus cuniculus) as the target species. The results obtained in terms of landscape dynamics showed a growing presence of artificial surfaces at the expense of fewer transformed areas, which became progressively fragmented over time. Moreover, the results of the developed HSI were highly concordant with observations of rabbit abundance in the region, based in particular on variables related to the temperature in the area and the patch shape in the preferred habitats of this species. These outputs can be used to support the implementation of habitat restoration strategies aimed at increasing ecological connectivity through measures such as wildlife crossings.}
}
@article{KAUKAB2024102691,
title = {Improving real-time apple fruit detection: Multi-modal data and depth fusion with non-targeted background removal},
journal = {Ecological Informatics},
volume = {82},
pages = {102691},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102691},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002334},
author = {Shaghaf Kaukab and  Komal and Bhupendra M Ghodki and Hena Ray and Yogesh B. Kalnar and Kairam Narsaiah and Jaskaran S. Brar},
keywords = {Apple, Fruit detection, 3D localization, YOLO network, RGB-D images, Depth sensor},
abstract = {In automated fruit detection, RGB-Depth (RGB-D) images aid the detection model with additional depth information to enhance detection accuracy. However, outdoor depth images are usually of low quality, which limits the quality of depth data. In this study, an approach/technique for real-time apple fruit detection in a high-density orchard environment by using multi-modal data is presented. Non-targeted background removal using the depth fusion (NBR-DF) method was developed to reduce the high noise condition of depth images. The noise occurred due to the uncontrolled lighting condition and holes with incomplete depth information in the depth images. NBR-DF technique follows three primary steps: pre-processing of depth images (point cloud generation), target object extraction, and background removal. The NBR-DF method serves as a pipeline to pre-process multi-modal data to enhance features of depth images by filling holes to eliminate noise generated by depth holes. Further, the NBR-DF implemented with the YOLOv5 enhances the detection accuracy in dense orchard conditions by using multi-modal information as input. An attention-based depth fusion module that adaptively fuses the multi-modal features was developed. The integration of the depth-attention matrix involved pooling operations and sigmoid normalization, both of which are efficient methods for summarizing and normalizing depth information. The fusion module improves the identification of multiscale objects and strengthens the network's resistance to noise. The network then detects the fruit position using multiscale information from the RGB-D images in highly complex orchard environments. The detection results were compared and validated with other methods using different input modals and fusion strategies. The results showed that the detection accuracy using the NBR-DF approach achieved an average precision rate of 0.964 in real time. The performance comparison with other state-of-the-art methods and the model generalization study also establish that the present advanced depth-fusion attention mechanism and effective preprocessing steps in NBR-DF-YOLOv5 significantly surpass those in performance. In conclusion, the developed NBR-DF technique showed the potential to improve real-time apple fruit detection using multi-modal information.}
}
@article{CHEN2024102594,
title = {Tradeoffs among multi-source remote sensing images, spatial resolution, and accuracy for the classification of wetland plant species and surface objects based on the MRS_DeepLabV3+ model},
journal = {Ecological Informatics},
volume = {81},
pages = {102594},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102594},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001365},
author = {Zizhen Chen and Jianjun Chen and Yuemin Yue and Yanping Lan and Ming Ling and Xinhong Li and Haotian You and Xiaowen Han and Guoqing Zhou},
keywords = {Wetland, UAV image, Satellite image, Spatial resolution, DeepLabV3 +, Multi-resolution segmentation},
abstract = {Classification of wetland plant species (PlatSpe) and surface objects (SurfObj) in remote sensing images faces significant challenges due to the high diversity of PlatSpe and the fragmented nature of SurfObj. Unmanned aerial vehicle (UAV) images and satellite images are the primary data sources for the classification of wetland PlatSpe and SurfObj. However, there is still insufficient research on the effect of various data sources and spatial resolutions on the classification results. This study essentially focuses on Huixian Wetland in Guilin, Guangxi, China through utilizing UAV images and satellite images with varying spatial resolutions as data sources. To this end, the MRS_DeepLabV3+ model is constructed based on multi-resolution segmentation and DeepLabV3+, and the wetland PlatSpe and SurfObj are appropriately classified based on this model. The obtained results reveal that: (1) MRS_DeepLabV3+ model with optimal scale parameter (SP) is capable of achieving higher classification accuracy compared to DeepLabV3+. The optimal SPs for both UAV images and satellite images gradually lessen with decreasing the spatial resolution, and satellite images require larger SPs compared to UAV images. (2) In both the UAV and satellite image models, both OA and kappa exhibit a decreasing trend with the reduction of the spatial resolution. (3) The overall classification accuracies of the satellite image models are superior to the UAV image models in the spatial resolution intervals of 2 to 16 m. This investigation can be regarded as a valuable reference for selecting data sources and spatial resolutions in the wetland PlatSpe and SurfObj classification.}
}
@article{ZHANG2024102605,
title = {Response of spectral vegetation indices to Erannis jacobsoni Djak. damage in larch forests},
journal = {Ecological Informatics},
volume = {81},
pages = {102605},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102605},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400147X},
author = {Siyuan Zhang and Xiaojun Huang and Lei Ma and Ganbat Dashzevegd and Mungunkhuyag Ariunaa and Gang Bao and Siqin Tong and Yuhai Bao and Altanchimeg Dorjsuren and Davaadorj Enkhnasan},
keywords = {Erannis jacobsoni Djak., Spectral vegetation indices, Larch, Pest damage level, Variation characteristics},
abstract = {Erannis jacobsoni Djak. (EJD), a typical pest of coniferous forests in Mongolia, has severely threatened forest areas in recent years owing to its rapid development and spread. EJD feeds on needles and leaves, killing many trees and causing severe damage to forest ecosystems，which results in substantial local economic losses. The rapid and effective monitoring of forest pests is crucial for preventing or controlling infestations in a timely manner. To this end, in this study, we calculated spectral vegetation indices using UAV multispectral data, assessed ground survey data to determine the degree of pest damage, and conducted sensitivity analysis on the spectral vegetation indices. Nine sensitive spectral vegetation indices were selected to analyze the intramonthly and intermonthly variations in the spectral vegetation indices of forests during EJD infestation: the chlorophyll red-edge parameter index (CIreg), corrected NIR/IR simple ratio (GMSR), intensity index (Int and Int2), improved NIR/red-edge simple ratio (MSRreg), normalized difference NIR vegetation index (NDSI), soil adjusted vegetation index (SAVI), and salinity index (SI2reg and SI3). The results demonstrated that the variance F values of the sensitive spectral vegetation indices after screening using the successive projection algorithm were highly significant at the α=10−10 level, suggesting that these indices are highly sensitive to the level of pest damage. The intramonthly results were as follows: in June, CIreg, GMSR, Int, Int2, MSRreg, SAVI, SI2reg, and SI3 decreased with increasing pest damage, whereas NDSI increased; in August, the difference in index values between light, medium, and heavy damage and healthy stands was not significant; and in September, most of the index differences changed to mild > moderate > severe. Regarding the intermonthly results, the magnitude of the vegetation index values for each sensitive spectrum at different hazard levels was ranked as June > September > August, and the overall difference varied as δ3>δ2>δ1. The spectral vegetation indices apparently responded to different levels of pest damage, making them suitable for quickly and accurately monitoring the occurrence and development of forest pests. These results provide a reference for the monitoring of forest pests at spatial and temporal scales.}
}
@article{TAN2024102497,
title = {Mapping of nearshore bathymetry using Gaofen-6 images for the Yellow River Delta-Laizhou Bay, China},
journal = {Ecological Informatics},
volume = {80},
pages = {102497},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102497},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000396},
author = {Kun Tan and Minxuan Sun and Danfeng Sun and Xiaojie Liu and Xiaohuang Liu and Bin Wang and Wenjun Dou and Haiyan Zhang and Fei Lun},
keywords = {Nearshore bathymetry, Turbid waters, Band ratios, CART, RFR, NDTI, GF-6},
abstract = {Bathymetric mapping is integral to maintaining marine ecosystems, managing coastal zones, and safeguarding the environment. However, achieving accurate large-scale bathymetric maps remains a challenge in China, particularly in nearshore turbid waters. To address this gap, we leveraged seasonal Gaofen-6 (GF-6) data to conduct bathymetry mapping in the Yellow River Delta-Laizhou Bay area. In our study, we found that longer wavelengths, such as those in the red-edge2 and near-infrared (NIR) bands, exhibited superior performance in determining bathymetry. Moreover, specific band ratios derived from GF-6 data—such as Blue/NIR (BN), Violet/NIR (VN), Blue/Red-edge2 (BE), Violet/Red-edge2 (VE), Green/NIR (GN), and Green/Red-edge2 (GE)—showed promising outcomes, particularly in turbid nearshore waters. When comparing models, the random forest regression (RFR) model outperformed the classification and regression trees (CART) model in turbid nearshore areas, showing higher R2 values and lower RMSE. Notably, both models demonstrated higher accuracy in March compared to May and October. Incorporating the Normalized Difference Turbidity Index (NDTI) notably improved bathymetric results, especially in turbid sea regions. Furthermore, nearshore bathymetry proved highly susceptible to natural processes, seasonal variations, and human activities. The significant discrepancies in bathymetry among coastal areas emphasize the need for tailored management strategies to enhance coastal management and foster sustainable marine economic development.}
}
@article{ORIOL2024102606,
title = {Automatic identification of Collembola with deep learning techniques},
journal = {Ecological Informatics},
volume = {81},
pages = {102606},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102606},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001481},
author = {Théo Oriol and Jérôme Pasquet and Jérôme Cortet},
keywords = {Deep learning, Object detection, Collembola, Soil quality, Bioindication},
abstract = {Collembola are very abundant organisms in soils (several thousand individuals per square meter) and are considered to be good indicators of soil quality. These indicators are mainly based on the number of individuals observed (abundance per square meter of soil), but also the singularity and number of species present (species richness). A limitation that comes with the usage of collembola as an indicator is the complexity of the identification of the species under a microscope, how time-consuming it is, and the morphological similarity between some species. Deep learning approaches have been very successful in the resolution of image-based problems. Still, no work yet exists that uses deep learning in the recognition of collembola on a microscope slide. This could be a valuable tool for experts seeking to use Collembola as a metric on a larger scale. In this work, we explore and evaluate the performance of state-of-the-art deep learning techniques over the identification of Collembola on a new manually annotated dataset.}
}
@article{MARTINEZSANCHEZ2022101757,
title = {Skyline variations allow estimating distance to trees on landscape photos using semantic segmentation},
journal = {Ecological Informatics},
volume = {70},
pages = {101757},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101757},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002072},
author = {Laura Martinez-Sanchez and Daniele Borio and Raphaël d'Andrimont and Marijn {van der Velde}},
keywords = {Semantic segmentation, Conditional random fields, COCO, Landscape, Openness, Image depth},
abstract = {Approximate distance estimation can be used to determine fundamental landscape properties including complexity and openness. We show that variations in the skyline of landscape photos can be used to estimate distances to trees on the horizon. A methodology based on the variations of the skyline has been developed and used to investigate potential relationships with the distance to skyline objects. The skyline signal, defined by the skyline height expressed in pixels, was extracted for a set of 148 Land Use/Cover Area frame Survey (LUCAS) landscape photos. Photos were semantically segmented with DeepLabV3+ trained with the Common Objects in Context (COCO) dataset. This provided pixel-level classification of the objects forming the skyline. A Conditional Random Fields (CRF) algorithm was also applied to increase the details of the skyline signal. Three metrics, able to capture the skyline signal variations, were then considered for the analysis. These metrics shows a functional relationship with distance for the class of trees, whose contours have a fractal nature. In particular, regression analysis was performed against 475 ortho-photo based distance measurements, and, in the best case, a R2 score equal to 0.47 was achieved. This is an encouraging result which shows the potential of skyline variation metrics for inferring distance related information.}
}
@article{CHANG2024102566,
title = {Three decades of spatiotemporal dynamics in forest biomass density in the Qinba Mountains},
journal = {Ecological Informatics},
volume = {81},
pages = {102566},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102566},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001080},
author = {Jiahui Chang and Chang Huang},
keywords = {Forest biomass density, Forest inventories, Carbon storage, NDVI, Qinba Mountains},
abstract = {The forest ecosystem plays a pivotal role in the global carbon cycle and is crucial for investigating atmospheric carbon exchanges. Forest biomass, a fundamental quantitative measure of the forest ecosystem, serves as a critical indicator for forest carbon stocks and carbon sequestration capacity. This study utilizes the GIMMS NDVI3g dataset to downscale forest inventory data spanning from 1989 to 2018, creating a 1 km resolution map of forest biomass density in the Qinba Mountains. The density initially decreased but has been increasing since 2004. The northern region of the Qinba Mountains exhibits a high forest biomass density (>100 Mg/hm2), while the southern region has relatively lower biomass density. This study provides the longest-term estimation of forest biomass density in the Qinba Mountains to date. It serves as a foundation for regional-scale forest carbon sequestration management and carbonization decision-making. This research is of significant importance for enhancing understanding of regional carbon cycling and supporting sustainable ecological development.}
}
@article{DARIANE2024102452,
title = {Maximum energy entropy: A novel signal preprocessing approach for data-driven monthly streamflow forecasting},
journal = {Ecological Informatics},
volume = {79},
pages = {102452},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102452},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004818},
author = {Alireza B. Dariane and Mohammad Reza {M. Behbahani}},
keywords = {Signal preprocessing, Maximum-energy-entropy, Monthly streamflow forecasting, Input variable selection, Genetic programming, Wavelet-entropy},
abstract = {In recent years, the application of Data-Driven Models (DDMs) in ecological studies has garnered significant attention due to their capacity to accurately simulate complex hydrological processes. These models have proven invaluable in comprehending and predicting natural phenomena. However, to achieve improved outcomes, certain additive components such as signal analysis models (SAM) and input variable selections (IVS) are necessary. SAMs unveil hidden characteristics within time series data, while IVS prevents the utilization of inappropriate input data. In the realm of ecological research, understanding these patterns is pivotal for grasping the ecological implications of streamflow dynamics and guiding effective management decisions. Addressing the need for more precise streamflow forecasting, this study proposes a novel SAM called “Maximum Energy Entropy (MEE)” to forecast monthly streamflow in the Ajichai basin, located in northwestern Iran. A comparative analysis was conducted, pitting MEE against well-known methods such as Discreet Wavelet (DW) and Discreet Wavelet-Entropy (DWE), ultimately demonstrating the superiority of MEE. The results showcased the superior performance of our proposed method, with an NSE value of 0.72, compared to DW (NSE value of 0.68) and DWE (NSE value of 0.68). Furthermore, MEE exhibited greater reliability, boasting a lower Standard Deviation value of 0.13 compared to DW (0.26) and DWE (0.19). The utilization of MEE equips researchers and decision-makers with more accurate predictions, facilitating well-informed ecological management and water resource planning. To further evaluate MEE's accuracy using various DDMs, we integrated MEE with Artificial Neural Network (ANN) and Genetic Programming (GP). Additionally, GP served as an IVS method for selecting appropriate input variables. Ultimately, the combination of MEE and GP within the ANN forecasting model (MEE-GP-ANN) yielded the most favorable results.}
}
@article{PEREZGRANADOS2022101861,
title = {Automated signal recognition as a useful tool for monitoring little-studied species: The case of the Band-tailed Nighthawk},
journal = {Ecological Informatics},
volume = {72},
pages = {101861},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101861},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003119},
author = {Cristian Pérez-Granados and Karl-L. Schuchmann},
keywords = {eBird, Nightjar, Pantanal, Passive acoustic monitoring, Vocal activity, Xeno-canto},
abstract = {Passive acoustic monitoring, when coupled with automated signal recognition software, is a useful technique for monitoring vocally active taxa. In this study, we evaluated the utility of automated signal recognition to gain insights into the ecology of little-studied species. For this purpose, we selected an avian family, Caprimulgidae (nightjars), composed of cryptic and nocturnal species, and focused the study on a Neotropical wetland, the Brazilian Pantanal. We reviewed the number of publications, observations, and recordings available for each nightjar inhabiting the Brazilian Pantanal and the Band-tailed Nighthawk (Nyctiprogne leucopyga) was identified as the species with the least information available. We employed automated signal recognition software to study the vocal behavior of this species over a complete annual cycle in the Pantanal. Previous knowledge about the ecology of this species is based on general descriptions and anecdotal observations. Our findings corroborate that the Nighthawk is a resident species of the Brazilian Pantanal, and according to seasonal changes in vocal activity, the breeding season extends from July to October. The breeding period starts at the end of the dry season (July–August), and the nesting period may occur at the beginning of the wet season and following the first rains, which is a period of maximum insect food availability. The vocal activity of the Nighthawk was restricted to the nocturnal period and was maximum at dusk. That preference for dusk is in disagreement with the pattern described for the other four nightjars in the study area, which highlights the importance of performing species-specific studies and avoiding drawing any conclusions about the activity pattern of a species based on the genus or family to which it belongs to. Automated signal recognition software was able to detect over three quarters of the songs annotated by a human on a subset of sound recordings, therefore proving its utility for monitoring the Band-tailed Nighthawk.}
}
@article{ZHANG2024102725,
title = {Reconstruction of dense time series high spatial resolution NDVI data using a spatiotemporal optimal weighted combination estimation model based on Sentinel-2 and MODIS},
journal = {Ecological Informatics},
volume = {82},
pages = {102725},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102725},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400267X},
author = {Kun Zhang and Changming Zhu and Junli Li and Kuntao Shi and Xin Zhang},
keywords = {Dense time-series reconstruction, Regularized NDVI data, Spatiotemporal optimal weighted combination estimation model (SOWCEM), High-spatial remote sensing, Sentinel-2},
abstract = {A regular, dense time series of the normalized difference vegetation index (NDVI) is a crucial remote sensing parameter that provides insights into the growth status of plants across different temporal and spatial scales. However, the production of high-resolution, equal-interval, and dense-time-series NDVI products currently faces technical challenges, limiting their application in agriculture and forestry-related fields. This study proposes a new method for reconstructing a dense Sentinel-2 NDVI time series based on the spatiotemporal optimal weighted combination estimation model (SOWCEM). The SOWCEM is developed using state-of-the-art spatial and temporal reconstruction algorithms. This model considers the distribution characteristics of errors in spatiotemporal dimensions, allowing for adaptive determination of the optimal combination weight at the pixel level. Then, the reconstructed regular dense-time-series NDVI data covering the region for five days/time are evaluated through a comparative analysis. The experimental results demonstrate that the regional NDVI reconstruction image based on the SOWCEM algorithm has a determination coefficient (R2) of 0.9082, a root mean square error (RMSE) of 0.0403, and a comprehensive overall error (ERGAS) of 5.7726. Compared with single spatiotemporal dimension models, the SOWCEM algorithm shows an average improvement of 5.78% in R2, while the RMSE and ERGAS decrease by 6.5% and 6.86%, respectively. Moreover, the stability and robustness of the models are also enhanced. These results indicate that the SOWCEM algorithm can effectively achieve a high-quality fusion reconstruction of regional images, significantly enhancing the accuracy of high-spatial-resolution NDVI dense temporal spectral reconstruction. Furthermore, it exhibits clear superiority and good applicability. This algorithmic framework provides a feasible approach for the dense reconstruction of high-spatial-resolution regular time-series NDVI data, enabling more accurate and efficient high-resolution NDVI remote sensing monitoring services in related field applications. The core code of SOWCEM is available at https://github.com/GISerZkun/SOWCEM.}
}
@article{PUNALEKAR2024102714,
title = {Hierarchical-modular framework for habitat mapping through systematic and informed integration of remote sensing data with contextual information},
journal = {Ecological Informatics},
volume = {82},
pages = {102714},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102714},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002565},
author = {Suvarna M. Punalekar and Clive Hurford and Richard M. Lucas and Carole Planque and Sebastien Chognard},
keywords = {FAO LCCS, Machine learning, Knowledge-based decision rules, Contextual information, Sentinel-1 and 2},
abstract = {Accurate and up-to-date habitat maps at national or regional levels are critical for informing conservation and restoration actions. Land cover maps generated from Earth Observation (EO) data can, to varying degrees, indicate the extent of some habitat categories but these are often insufficient in terms of the level of detail required. This study introduces a hierarchical-modular framework based on the globally applicable Food and Agriculture Organization (FAO) Land Cover Classification System (LCCS) whereby the land cover classes can be systematically translated to habitat categories and further differentiated by referencing contextual information and expert knowledge. Application is showcased for Wales (United Kingdom) where 10 m spatial resolution land cover maps were first constructed nationally from time-series of Sentinel-1C-band radar and Sentinel-2 optical data (2018–2020). The contextual datasets derived from non-EO sources were utilised to associate dominant vegetation types to detailed habitat classes. The accuracy assessment done using field survey data highlights that habitat classes directly derived from EO, including cultivated/managed and forest types, demonstrated higher mapping accuracies (>70% User's and Producer's Accuracies) compared to those that were more heavily dependent on non-EO-derived contextual information. These included neutral grasslands and fen/marsh/swamp that demonstrated lower accuracies (<20%) but also other detailed wetland classes (user's and producer's accuracies ranging from 25 to 60%). These reduced accuracies were largely associated with discrepancies in the contextual datasets used for their differentiation and mapping, and those integrated within field validation datasets. Dependency on contextual datasets diminished as detailed habitat maps were generalized into broader categories. The study proposes that, for enhanced habitat mapping, efforts should focus not only on EO data but also on maximising the accuracy and minimizing inconsistencies in contextual datasets as well as taxonomical systems. The flexible structure of the FAO LCCS hierarchical framework is also highlighted, emphasizing its adaptability for future improvements in habitat mapping by incorporating contextual datasets and more advanced algorithms that can improve EO-derived land cover descriptions.}
}
@article{HOU2024102690,
title = {Construction of regional multi-scenario spatially balanced ecological security pattern based on self-organizing feature map: A case study of Guangzhou, China},
journal = {Ecological Informatics},
volume = {82},
pages = {102690},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102690},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002322},
author = {Yin Hou and Yiming Liu and Zijing Wu and Hui Zeng},
keywords = {Ecosystem service bundles, Self-organizing feature map, Ecological nodes, Multi-scenario, Ecological security pattern},
abstract = {Constructing ecological security patterns (ESPs) is the ecological basis for achieving sustainable regional development. This study explored a framework of spatially balanced ESPs suitable for rapidly urbanizing areas to address the issues of overreliance on ecological land and subjective parameter settings in traditional ESP construction methods. Three ecosystem service bundles (product supply, water conservation, and habitat maintenance) were identified in Guangzhou using the self-organizing feature map method. These bundles were then used to identify multifunctional sources. The minimum size of the ecological source was determined to be 10 km2 through the “structure-pattern-function” framework, and a total of 19 ecological sources from three ecological functions were extracted. In these three scenarios, the 102 ecological corridors were classified into five categories based on their connected sources. Ecological node parameters were set based on local planning and dominant species characteristics, enhancing the explanatory power of the circuit theory. The multi-scenario ESP framework proposed in this study achieved a spatially balanced distribution of the entire region at the point, line, and surface levels, as confirmed by the ecological network assessment results. Future planning in Guangzhou should value the ecological functions of non-conventional ecological land, such as cropland and urban green spaces, while considering the impact of human activities on the environment and promptly modifying crucial node areas.}
}
@article{XU2024102460,
title = {A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model},
journal = {Ecological Informatics},
volume = {80},
pages = {102460},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102460},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000025},
author = {Xianghui Xu and Weijiang Kong and Ligang Wang and Tengji Wang and Pingping Luo and Jianjun Cui},
keywords = {Land use/cover change, Uncertainty, Multiobjective planning, Multiscenario forecasting},
abstract = {Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.}
}
@article{CIAMPI2023102384,
title = {A deep learning-based pipeline for whitefly pest abundance estimation on chromotropic sticky traps},
journal = {Ecological Informatics},
volume = {78},
pages = {102384},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102384},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004132},
author = {Luca Ciampi and Valeria Zeni and Luca Incrocci and Angelo Canale and Giovanni Benelli and Fabrizio Falchi and Giuseppe Amato and Stefano Chessa},
keywords = {Smart agriculture, Smart farming, Integrated pest management, Computer vision, Object counting, Visual counting},
abstract = {Integrated Pest Management (IPM) is an essential approach used in smart agriculture to manage pest populations and sustainably optimize crop production. One of the cornerstones underlying IPM solutions is pest monitoring, a practice often performed by farm owners by using chromotropic sticky traps placed on insect hot spots to gauge pest population densities. In this paper, we propose a modular model-agnostic deep learning-based counting pipeline for estimating the number of insects present in pictures of chromotropic sticky traps, thus reducing the need for manual trap inspections and minimizing human effort. Additionally, our solution generates a set of raw positions of the counted insects and confidence scores expressing their reliability, allowing practitioners to filter out unreliable predictions. We train and assess our technique by exploiting PST - Pest Sticky Traps, a new collection of dot-annotated images we created on purpose and we publicly release, suitable for counting whiteflies. Experimental evaluation shows that our proposed counting strategy can be a valuable Artificial Intelligence-based tool to help farm owners to control pest outbreaks and prevent crop damages effectively. Specifically, our solution achieves an average counting error of approximately 9% compared to human capabilities requiring a matter of seconds, a large improvement respecting the time-intensive process of manual human inspections, which often take hours or even days.}
}
@article{WEINSTEIN2020101061,
title = {Cross-site learning in deep learning RGB tree crown detection},
journal = {Ecological Informatics},
volume = {56},
pages = {101061},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101061},
url = {https://www.sciencedirect.com/science/article/pii/S157495412030011X},
author = {Ben G. Weinstein and Sergio Marconi and Stephanie A. Bohlman and Alina Zare and Ethan P. White},
keywords = {Tree crown detection, RGB deep learning, Object detection, Airborne LiDAR},
abstract = {Tree crown detection is a fundamental task in remote sensing for forestry and ecosystem ecology. While many individual tree segmentation algorithms have been proposed, the development and testing of these algorithms is typically site specific, with few methods evaluated against data from multiple forest types simultaneously. This makes it difficult to determine the generalization of proposed approaches, and limits tree detection at broad scales. Using data from the National Ecological Observatory Network, we extend a recently developed deep learning approach to include data from a range of forest types to determine whether information from one forest can be used for tree detection in other forests, and explore the potential for building a universal tree detection algorithm. We find that the deep learning approach works well for overstory tree detection across forest conditions. Performance was best in open oak woodlands and worst in alpine forests. When models were fit to one forest type and used to predict another, performance generally decreased, with better performance when forests were more similar in structure. However, when models were pretrained on data from other sites and then fine-tuned using a relatively small amount of hand-labeled data from the evaluation site, they performed similarly to local site models. Most importantly, a model fit to data from all sites performed as well or better than individual models trained for each local site.}
}
@article{LI2024102686,
title = {Coupled zoning and spatial heterogeneity of human activities and natural endowments based on self-organizing map and random forest: A case study of the agro-pastoral ecotone in Gansu, China},
journal = {Ecological Informatics},
volume = {82},
pages = {102686},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102686},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002280},
author = {Jie Li and Ninghui Pan and Yao Yao and Guang Li and Zhiyuan Cheng and Yanhua Lu and Shuainan Liu and Wenming Liu},
keywords = {Human activity–natural endowment coupled zoning, Regional differentiation, Self-organizing map, Random forest, Agro-pastoral ecotone in Gansu, China},
abstract = {Regional zoning is an important way for humans to understand geographical space，but the existing research on regional zoning focuses on natural conditions, ignoring the interdependent characteristics of human and nature, and the driving mechanism of regional differentiation is not sufficiently explained. In this study, using algorithms such as self-organizing feature map, clustering quality index, structural similarity index measure (SSIM) and random forest, the human activity (HA)–natural endowment (NE) coupled zoning in the agro-pastoral ecotone in Gansu, China (AEGC), was conducted to explore the driving mechanism of regional differentiation. Results show the following: (1) The HA-NE coupled zoning has the best clustering effect when implementing the partitioning scheme with a classification number of 4. Accordingly, the AEGC can be divided into four regions with significant differences between HAs and NEs. (2) From the perspective of spatial distribution, HA–NE coupled zoning, climate zoning, geographic zoning, and vegetation zoning are similar, whereas HA zoning is different. The results of SSIM showed that HA–NE coupled zoning takes all types of factors into consideration (SSIM mean 0.708), and the zoning results are better than single type zonings. HAs have strong independence (SSIM mean 0.576), and geographic conditions are closely related to all other factors (SSIM mean 0.671). (3) Elevation is the most important driver of regional differentiation in the AEGC, with a contribution degree of 22.36%; other important drivers include land use intensity, precipitation, and normalized difference vegetation index, with contribution degree distributions of 17.38%, 16.34%, and 15.79%. Furthermore, the dominant factors of regional differentiation in each sub-region are different. This study emphasizes that regional characteristic factors and uneven spatial distribution factors are important drivers of regional differentiation, and land use intensity has become an important force influencing geographic space. Policy recommendations for zonal governance are made based on the inherent conditions of different regions. This study may provide a reference for scientific regional zoning and cognitive regional differentiation.}
}
@article{ZHANG2024102620,
title = {Spatiotemporal variation and prediction of NPP in Beijing-Tianjin-Hebei region by coupling PLUS and CASA models},
journal = {Ecological Informatics},
volume = {81},
pages = {102620},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102620},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001626},
author = {Junping Zhang and Jia Wang and Yuhan Chen and Shaodong Huang and Boyi Liang},
keywords = {NPP, CASA model, PLUS model, BTH region, Prediction under multi-scenarios},
abstract = {Vegetation productivity is crucial for human production and livelihoods. Understanding net primary productivity (NPP) in historical contexts and predicting its future fluctuations is imperative for assessing the environmental sustainability of a region. However, relatively few researches have been conducted on predicting NPP, requiring further development and refinement of NPP prediction methods and models. This study introduces a novel approach that discretely couples the PLUS and CASA models for NPP prediction, and it validates the applicability of this approach in the research area. The objective of our study is to analyze the spatiotemporal patterns of NPP change in the Beijing-Tianjin-Hebei (BTH) region from 2001 to 2020, predict NPP under three different climate scenarios (SSP 1-2.6, SSP 2-4.5, SSP 5-8.5) in 2030, and identify an appropriate path for the future development of this region. The results indicate:(1) From 2001 to 2020, NPP in the research area has shown a gradual improvement trend and maintained a certain spatial distribution pattern in general. (2) The study discovered a correlation coefficient of 0.83 and an RMSE of 102.86 between predicted and actual NPP for 2020. This suggests that the method introduced in our study is suitable for predicting NPP in the research area. (3) NPP in the study area is predicted to decline in 2030 compared with 2020 under all three scenarios. Moreover, the SSP 1-2.6 scenario, representing a low-emission scenario, is suitable for the BTH region compared with other climate scenarios. This research sheds light on NPP variations in the BTH region over the past 20 years and the next 10 years, offering a scientific basis for relevant departments to formulate future policies.}
}
@article{ALDOSSARI2022101803,
title = {Transferable species distribution modelling: Comparative performance of Generalised Functional Response models},
journal = {Ecological Informatics},
volume = {71},
pages = {101803},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101803},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002539},
author = {Shaykhah Aldossari and Dirk Husmeier and Jason Matthiopoulos},
keywords = {Generalised linear models, Habitat selection, Predictive species distribution models, Radial basis functions, Random forests, Transferability},
abstract = {Predictive species distribution models (SDMs) are becoming increasingly important in ecology, in the light of rapid environmental change. However, the predictions of most current SDMs are specific to the habitat composition of the environments in which they were fitted. This may limit SDM predictive power because species may respond differently to a given habitat depending on the availability of all habitats in their environment, a phenomenon known as a functional response in resource selection. The Generalised Functional Response (GFR) framework captures this dependence by formulating the SDM coefficients as functions of habitat availability. The original GFR implementation used global polynomial functions of habitat availability to describe the functional responses. In this study, we develop several refinements of this approach and compare their predictive performance using two simulated and two real datasets. We first use local radial basis functions (RBF), a more flexible approach than global polynomials, to represent the habitat selection coefficients, and balance bias with precision via regularization to prevent overfitting. Second, we use the RBF-GFR and GFR models in combination with the classification and regression tree CART, which has more flexibility and better predictive powers for non-linear modelling. As further extensions, we use random forests (RFs) and extreme gradient boosting (XGBoost), ensemble approaches that consistently lead to variance reduction in generalization error. We find that the different methods are ranked consistently across the datasets for out-of-data prediction. The traditional stationary approach to SDMs and the GFR model consistently perform at the bottom of the ranking (simple SDMs underfit, and polynomial GFRs overfit the data). The best methods in our list provide non-negligible improvements in predictive performance, in some cases taking the out-of-sample R2 from 0.3 up to 0.7 across datasets. At times of rapid environmental change and spatial non-stationarity ignoring the effects of functional responses on SDMs, results in two different types of prediction bias (under-prediction or mis-positioning of distribution hotspots). However, not all functional response models perform equally well. The more volatile polynomial GFR models can generate biases through over-prediction. Our results indicate that there are consistently robust GFR approaches that achieve impressive gains in transferability across very different datasets.}
}
@article{LIU2024102729,
title = {An ensemble modeling framework to elucidate the regulatory factors of chlorophyll-a concentrations in the Nanji wetland waters of Poyang Lake},
journal = {Ecological Informatics},
pages = {102729},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102729},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002711},
author = {Lizhen Liu and Qi Huang and Yongming Wu and George Arhonditsis and Tianxiang Wang and Yun Cao and Chaoyang Fang},
keywords = {Chlorophyll-, Random forest, Generalized additive modeling, Eutrophication, Poyang Lake},
abstract = {Chlorophyll-a (Chl a) is an important indicator of algal biomass that is frequently used to evaluate the severity of cultural eutrophication. Identifying the key covariates of Chl a concentrations is essential to understand the mechanisms that drive eutrophication and to develop forecasting tools that guide the restoration process. In this study, we present a novel ensemble modeling framework that is founded upon the complementary features of Random Forest (RF) and Generalized Additive modeling (GAMs). A series of RF models are first developed to forecast Chl a concentrations based on the antecedent values of a multitude of environmental predictors. GAMs are then used to explore the presence of non-linearities in the seasonal relationships between Chl a and the identified predictors. The optimal RF models using a 0–8 day time lag displayed high predictive skills with adjusted R2 values consistently above 0.80. Analyses of the RF models revealed that the modulating factors of Chl a display significant seasonality. Dissolved oxygen (DO) and turbidity were the key covariates of Chl a in the spring, while the water level fluctuations predominantly regulated phytoplankton biomass in the summer and winter. The occurrence and severity of algal blooms in the summer and autumn were associated with threshold levels of 0.06 and 1.50 mg/L for total phosphorus (TP) and total nitrogen (TN) concentrations, respectively. These results reveal the potential of the introduced modeling framework to shed light on the regulatory factors of algal biomass as well as to establish real-time predictions in the Nanji wetland waters of Poyang Lake.}
}
@article{TRAY2020101115,
title = {An open-source database model and collections management system for fish scale and otolith archives},
journal = {Ecological Informatics},
volume = {59},
pages = {101115},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101115},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120300650},
author = {Elizabeth Tray and Adam Leadbetter and Will Meaney and Andrew Conway and Caoimhín Kelly and Niall Ó Maoiléidigh and Elvira {de Eyto} and Siobhan Moran and Deirdre Brophy},
keywords = {Database, Fish scale, Otolith, Archive, FAIR data principles},
abstract = {Scales and otoliths (ear stones) from fish are routinely sampled for age estimation and fisheries management purposes. Growth records from scales and otoliths can be used to generate long-term time series data, and in combination with environmental data, can reveal species specific population responses to a changing climate. Additionally, scale and otolith microchemical data can be utilized to investigate fish habitat usage. A common problem associated with biological collections, is that while sample intake grows, long-term physical storage is rarely a priority, and much of the sampling took place before the advent of open-access digital infrastructure. Material is often collected to meet short-term objectives and resources are seldom committed to maintaining and archiving collections. As a consequence, precious samples are frequently stored in many different and unsuitable locations, and may become lost or separated from associated metadata. The Marine Institute's ecological research station in in Newport, Co. Mayo, Ireland, holds a multi-decadal (1928–2020) collection of scales and otoliths from various fish species, gathered from many geographic locations. Here we present an open-source database model and archiving system to consolidate and digitize this collection, and show how this case study infrastructure could be used for other biological sample collections. The system utilizes the FAIR (Findable Accessible Interoperable and Reusable) open-data principles, and includes a physical repository, sample metadata catalogue, and image library.}
}
@article{QI2024102436,
title = {Applying 3D spatial metrics for landscape planning: Creating and measuring landscape scenarios by a point cloud-based approach},
journal = {Ecological Informatics},
volume = {79},
pages = {102436},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102436},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300465X},
author = {Jinda Qi and Ervine Shengwei Lin and Puay Yok Tan and Xudong Zhang and Roger Ho and Angelia Sia and Agnieszka Olszewska-Guizzo and Radha Waykool},
keywords = {3D spatial metrics, Quantitative landscape assessment, Restorative potential, Digital planning},
abstract = {The current planning and design process predominantly relies on experts' experiences or preferences, which is beneficial and straightforward but can be subjective and time-consuming. Although there are some quantitative assessment tools available to aid decision-makers in understanding the perceived quality of landscape scenarios, how to integrate them into the design thinking process to improve landscape design is challenging. This study presents a 3D digital model integrating the quantitative representation of visual quality into the design thinking process to improve urban landscapes' restorative potential. The model consists of generating landscape scenarios in a 3D environment, converting them into point clouds and voxelising them, quantitatively assessing the restorative potential, and interactively modifying landscape designs. To demonstrate the feasibility and effectiveness of the model, we have applied it to improve the restorative potential of a park in Singapore. The results show that the model provides a clear assessment of landscape scenarios and identifies specific areas needing improvement. The significance of this study lies in an innovative approach to generating and assessing the landscape scenario, ultimately enhancing the overall quality of landscapes during the digital planning and design process.}
}
@article{PEREZGRANADOS2023101981,
title = {The sound of the illegal: Applying bioacoustics for long-term monitoring of illegal cattle in protected areas},
journal = {Ecological Informatics},
volume = {74},
pages = {101981},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.101981},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000109},
author = {Cristian Pérez-Granados and Karl-L. Schuchmann},
keywords = {Automated signal recognition, Autonomous recording units, Human activity, Kaleidoscope Pro, Livestock, Pantanal},
abstract = {Passive acoustic monitoring coupled with automated signal recognition software has been widely used in recent years as an effective and affordable tool for wildlife monitoring and to combat illegal activities within protected areas. Here, we evaluate this technique to monitor the patterns of illegal cattle occurrence in the Brazilian Pantanal over a complete annual cycle. We aim to provide one of the first assessments of the performance of automated signal recognition software to detect ungulates. Cattle occurrences reached their maximum during the end of the dry season when lowland areas provide excellent pastures for cattle. In contrast, cattle occurrences were very low during the rainy season when the study area was seasonally inundated. Automated software was an efficient tool that was able to detect approximately three-quarters of cow calls within the recordings. Passive acoustic monitoring can be used to direct patrols to areas where illegal activities, such as cattle and poaching or logging, have been confirmed, which could be a method that would be especially well suited for remote areas, such as tropical forests. Future studies should evaluate whether there is a relationship between cattle grazing intensity and its associated impacts on wildlife and flora. Rapid advances in automated recognition and the recent development of low-cost recorders foresee a new era of acoustic ecology for improved conservation in the short term.}
}
@article{LIN2024102507,
title = {A model for forest type identification and forest regeneration monitoring based on deep learning and hyperspectral imagery},
journal = {Ecological Informatics},
volume = {80},
pages = {102507},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102507},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000499},
author = {Feng-Cheng Lin and Yi-Shiang Shiu and Pei-Jung Wang and Uen-Hao Wang and Jhe-Syuan Lai and Yung-Chung Chuang},
keywords = {Remote sensing, Deep learning, VGG19, ResNet50, Hyperspectral images},
abstract = {Traditional ground-based forest survey methods involve high labor costs, and their inefficiency makes comprehensive forest resource surveys challenging. With the development of new sensors and vehicles in recent years, more diverse and novel remote sensing detection and survey techniques have emerged. This study aims to use hyperspectral imagery to classify forest types containing representative tree species. To verify the feasibility of the proposed methods, we used hyperspectral imagery from the Taiwan Forestry Experiment Institute's Liugui Research Forest in southern Taiwan, which has an area of 9882 ha and an altitude of 250–2600 m. Hyperspectral imagery offers several advantages compared to traditional multispectral imagery; it captures a broad spectrum of contiguous, narrow spectral bands, providing highly detailed spectral information, enabling differentiation of tree components that appear similar in multispectral imagery. Eight identifiable forest types were selected for the models considered, and three different deep learning algorithms, VGG19, ResNet50 and a proposed combination (VGG19 + ResNet50), were used to screen the best algorithms. Data formats and pre-processing methods that can effectively improve computational performance were explored. The research results found that: (1) Band filtering is a necessary means to improve calculation performance; (2) Flattening the original convolution kernel with cubic characteristics can significantly reduce the time required for calculation. In terms of simulation results, VGG19 + ResNet50 was identified as the best model. Its overall classification accuracy can generally reach 93% to 100%. According to the calculation process set in this study, the time required for model training can be shortened to less than 30 min. The results of this research will help process more detailed and complex information in forest resource management and more accurately quantify forest ecology and woodland conditions.}
}
@article{JAMES2024102580,
title = {Monitoring vegetation patterns and their drivers to infer resilience: Automated detection of vegetation and megaherbivores from drone imagery using deep learning},
journal = {Ecological Informatics},
volume = {81},
pages = {102580},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102580},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001225},
author = {Rebecca K. James and Freek Daniels and Aneesh Chauhan and Pramaditya Wicaksono and Muhammad Hafizt and Setiawan Djody Harahap and Marjolijn J.A. Christianen},
keywords = {Semantic segmentation, Object detection, Pytorch, Seagrass, Drone imagery, Turtle monitoring, Conservation},
abstract = {Ecological pattern theory has highlighted spatial vegetation patterns that can be used as indicators of ecosystem resilience. Combining this spatial pattern theory with aerial imagery from drones and automated image processing with deep learning methods, we show how monitoring of natural ecosystems can be enhanced through quantifying vegetation spatial patterns. We demonstrate this approach in a tropical seagrass ecosystem with a high abundance of turtles that generate vegetation patches when grazing. Past field observations suggest that patch size and density reflect the seagrass meadow resilience, but understanding the natural variation in vegetation patchiness is crucial. Employing the deep learning methods of semantic segmentation and object detection, we quantify vegetation patchiness metrics and turtle distribution across 12 ha of seagrass meadow in the years 2012 and 2022. The resulting output facilitates spatial and temporal comparisons, revealing areas of low resilience. In 2012, turtle grazing across the entire site yielded vegetation patch sizes averaging 2 ± 0.2 m2 (95% confidence interval). Reduced patch sizes of 0.24 ± 0.05 m2 and 0.67 ± 0.6 m2 at the reef edge and beach slope respectively, in conjunction with a reduced patch density, indicated lower resilience at the seagrass meadow edges. Analysis of the 2022 dataset indicates a general decrease in patch size over time, suggesting declining resilience. A retraining experiment of the semantic segmentation model was conducted where the initial model was retrained on the 2022 dataset and demonstrated the adaptability of the deep learning methods. Despite using different equipment, the model achieved high accuracy with only 5–10 additional training images. By providing the tools to conduct these analyses, we aim to stimulate the uptake of deep learning for enhancing the data obtained from aerial imagery to improve the monitoring and conservation of natural ecosystems.}
}
@article{ZHANG2024102467,
title = {Marine zoobenthos recognition algorithm based on improved lightweight YOLOv5},
journal = {Ecological Informatics},
volume = {80},
pages = {102467},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102467},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000098},
author = {Lijun Zhang and Jiawen Fan and Yi Qiu and Zhe Jiang and Qingsong Hu and Bowen Xing and Jingxiang Xu},
keywords = {Ecological monitoring, Marine zoobenthos, Model lightweight, YOLOv5, EfficientnetV2, Bottleneck transformer},
abstract = {Detecting the distribution and density of marine zoobenthos is crucial for monitoring healthy coastal ecosystems and for growth reference tracking in precision aquaculture. However, current detection algorithms for marine zoobenthos have high computational complexity and cannot guarantee a balance between accuracy and speed, limiting their deployment in fishery equipment. This study used a portion of the Augmented Underwater Detection Dataset, a large underwater biological dataset containing marine zoobenthos data. A marine zoobenthos recognition algorithm was proposed for sea cucumbers, sea urchins, and scallops based on an improved lightweight YOLOv5, which can recognize the three types of marine zoobenthos. In the image enhancement module, an underwater image enhancement algorithm based on color balance and multi-input fusion is used, which turns the blurred image into a natural appearance of the seabed image. The lightweight backbone network EfficientnetV2-S was chosen to replace the original YOLOv5 backbone network, reducing network parameter calculations and improving recognition speed. A Bottleneck Transformer was introduced into the backbone network, and an attention mechanism based on the convolution module was introduced to construct the embedded Convolutional Block Attention Module in the Neck structure of YOLOv5, thereby improving the recognition accuracy of the lightweight YOLOv5 model. The experimental results showed that the mAP of the proposed algorithm reached 0.941, which is an improvement of 0.002 compared with the original YOLOv5l algorithm. The computation of this algorithm is 37.0 FLOPs (G), the model size is 54 MB, and the inference time is 5.9 ms. Compared to the original YOLOv5l algorithm, the reductions are 66.1%, 40.5%, and 39.2%. The proposed algorithm efficiently identified and classified marine zoobenthos.}
}
@article{KIM2024102576,
title = {Application of the domain adaptation method using a phenological classification framework for the land-cover classification of North Korea},
journal = {Ecological Informatics},
volume = {81},
pages = {102576},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102576},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001183},
author = {Joon Kim and Hyun-Woo Jo and Whijin Kim and Yujeong Jeong and Eunbeen Park and Sujong Lee and Moonil Kim and Woo-Kyun Lee},
keywords = {Land-cover mapping, Phenological classification, Domain adaptation, North Korea, Deep learning},
abstract = {Efforts to achieve carbon neutrality are global, encompassing a wide range of factors. For the estimation of greenhouse gas emissions from the agriculture, forestry, and other land use (AFOLU) sector, the Intergovernmental Panel on Climate Change has proposed an advanced method that requires Approach 3, the highest level of suggested method, of activity data. Accordingly, we propose a phenological classification framework (PCF) that can perform land-cover classification by training the climatic repeatability of the annual cycle using a U-Net deep learning model. Additionally, the domain adaptation (DA) method can be applied to classify areas with insufficient data. We applied these methods to classify North Korea (i.e., using South Korean data), with an accuracy of 81.31%; overall this effort culminated in the simultaneous classification of the Korean Peninsula. Domain distribution comparison showed that the results for the two regions were similar. The PCF and DA methods proposed in this study allow for annual production of a land-cover map and change matrix, regardless of the presence or absence of data. The application of these methods is expected to provide a scientific basis for policy decisions that can facilitate the global attainment of carbon neutrality.}
}
@article{LIU2024102401,
title = {YWnet: A convolutional block attention-based fusion deep learning method for complex underwater small target detection},
journal = {Ecological Informatics},
volume = {79},
pages = {102401},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102401},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004302},
author = {Pingzhu Liu and Wenbin Qian and Yinglong Wang},
keywords = {Underwater target detection, Deep learning, Feature fusion, Attention mechanism},
abstract = {Underwater target detection holds a noteworthy role in the field of marine exploration. However, it is difficult to extract useful feature information from blurred images with complex backgrounds, resulting in suboptimal and unsatisfactory target detection in conventional models. Among them, YOLOv5 leverages the advantages of fast detection performs better in detecting underwater samples. Nevertheless, YOLOv5 still faces difficulties including missed and incorrect detections due to the underwater environment's small scale of objects, dense distribution of organisms, and occlusion. To address these challenges, we propose a novel YoLoWaternet (YWnet) model that builds upon the YOLOv5 framework for complex underwater species detection with three main innovations: 1) A convolutional block attention module (CBAM) is introduced to enhance feature extraction for blurry images in the initial stages of the network and a new feature fusion network called the CRFPN is created to transfer important information and detect underwater targets. 2) A novel feature extraction module is presented, namely, the skip residual C3 module (SRC3), by effectively merging information from various scales to minimize the loss of original data during transmission. 3) Regression and classification algorithms are separated using the decoupled head to improve the effectiveness of detection and the EIoU loss function is employed to accelerate the convergence speed. Finally, the experimental results demonstrate that YWnet achieves remarkable accuracies of 73.2% mAp and 39.3% mAp50–95 on the underwater dataset, surpassing YOLOv5 by 2.3% and 2.4%, respectively. Furthermore, the proposed fusion model outperforms nine state-of-the-art baseline models on the undersea dataset and has generalization capabilities in other datasets.}
}
@article{LIU2023102304,
title = {Remote sensing delineation of wildfire spatial extents and post-fire recovery along a semi-arid climate gradient},
journal = {Ecological Informatics},
volume = {78},
pages = {102304},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102304},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003333},
author = {Wenjie Liu and Huade Guan and Patrick A. Hesp and Okke Batelaan},
keywords = {Wildfire, Change detection, LandTrendr, Post-fire vegetation recovery},
abstract = {Understanding the wildfire extent and post-fire vegetation recovery is critical for fire and forest management. Remote sensing imagery is widely used in wildfire detection because it provides continuous and large-scale surface monitoring capability. In this study, we apply and evaluate the performance of the LandTrendr algorithm in wildfire detection across a semi-arid climate region with a marked precipitation gradient. The aims are to compare the performance of four spectral indices for the burned areas and post-fire recovery detection for different climate conditions and investigate the relationship between suitable model parameters and climate conditions. The results show that NDVI outperforms other indices, including NBR, in burned area detection for drier areas (annual precipitation <400 mm). Disturbance signal-to-noise ratio can serve as an indicator for suitable index selection for semi-arid areas. Although the performance in the detection of burned pixels varies among different indices, they are all suitable for delineating post-fire recovery except for the wet site (annual precipitation of 575 mm) where NBR displays the best performance. Parameter optimization results along the climate gradient show that climate conditions have a significant impact on suitable parameter selection. These findings provide guidance on vegetation wildfire detection in arid and semi-arid climates to support wildfire risk and forestry management.}
}
@article{GOITIAURDIAIN2024102397,
title = {Software-dependent biases in the recognition of di- and tri-syllabic bird songs can create false interpretations of bird abundance and singing activity},
journal = {Ecological Informatics},
volume = {79},
pages = {102397},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102397},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004260},
author = {Madalen Goitia-Urdiain and Teresa Sauras-Yera and Gustavo A. Llorente and Eudald Pujol-Buxó},
keywords = {Autonomous recording unit, Bioacoustics, Signal processing, Biodiversity monitoring, Passive acoustic monitoring},
abstract = {The use of autonomous recording units (ARUs) for passive acoustic monitoring has recently gained a lot of importance. It is now widely used for scientific purposes and has been increasingly applied in the field of conservation biology. However, while ARUs may greatly increase cost-effectiveness in monitoring, they are not exempt from possible biases. In this study, we compared the performances of three different software in recognizing bi- and tri-syllabic bird songs and tested if their results varied significantly in a real setting. We focused on the interpretation of the relative abundance among habitats and the time of vocal activity, also using different numbers of training records to assess if the results of the software improved. Even with the quality measures of the recognizer being consistent with those of previously published studies, in several cases the results produced significantly different interpretations depending on the software used. While increasing the number of training records slightly improved the overlap in the estimates of activity among the different software, differences in the relative abundance of each song were present even with a fairly solid number of training records. Our results suggest that reliable biological interpretations might only be attained with a large number of training records and very high values of precision, recall, and the F-score. In fact, even with very high precision and F-scores, lower values for recall led not only to statistically significant differences, but also to different interpretations of relative abundance and time of activity between the two best-performing software. Thus, great caution must be taken in interpreting the results of bioacoustics studies that use automated recognition, and standards of minimum quality should be created for recognizers in scientific and technical studies.}
}
@article{JUNG2023102127,
title = {An integrated species distribution modelling framework for heterogeneous biodiversity data},
journal = {Ecological Informatics},
volume = {76},
pages = {102127},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102127},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001565},
author = {Martin Jung},
keywords = {Species distribution model, Data integration, Environmental niche, Offset, Point-process-model, Bayesian, R-package},
abstract = {Most knowledge about species and habitats is in-homogeneously distributed, with biases existing in space, time and taxonomic and functional knowledge. Yet, controversially the total amount of biodiversity data has never been greater. A key challenge is thus how to make effective use of the various sources of biodiversity data in an integrated manner. Particularly for widely used modelling approaches, such as species distribution models (SDMs), the need for integration is urgent, if spatial and temporal predictions are to be accurate enough in addressing global challenges. Here, I present a modelling framework that brings together several ideas and methodological advances for creating integrated species distribution models (iSDM). The ibis.iSDM R-package is a set of modular convenience functions that allows the integration of different data sources, such as presence-only, community survey, expert ranges or species habitat preferences, in a single model or ensemble of models. Further it supports convenient parameter transformations and tuning, data preparation helpers and allows the creation of spatial-temporal projections and scenarios. Ecological constraints such as projection limits, dispersal, connectivity or adaptability can be added in a modular fashion thus helping to prevent unrealistic estimates of species distribution changes. The ibis.iSDM R-package makes use of a series of methodological advances and is aimed to be a vehicle for creating more realistic and constrained spatial predictions. Besides providing convenience functions for a range of different statistical models as well as an increasing number of wrappers for mechanistic modules, ibis.iSDM also introduces several innovative concepts such as sequential or weighted integration, or thresholding by prediction uncertainty. The overall framework will be continued to be improved and further functionalities be added.}
}
@article{DENG2024102546,
title = {Weed database development: An updated survey of public weed datasets and cross-season weed detection adaptation},
journal = {Ecological Informatics},
volume = {81},
pages = {102546},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102546},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000888},
author = {Boyang Deng and Yuzhen Lu and Jiajun Xu},
keywords = {Deep learning, Domain adaptation, Machine vision, Precision agriculture, Robustness, Weed detection},
abstract = {Weeds are a major threat to crop production. Automated innovations for reducing herbicides and labor needed for weeding have become a high priority for sustainable weed management. The current state-of-the-art weeding systems still cannot reliably recognize weeds in changing field conditions for precision weed control. Enhancing weed recognition accentuates the critical need to develop dedicated, labeled weed databases and whereby train advanced AI (artificial intelligence) models while ensuring the robustness of models across diverse field conditions. This study presents an up-to-date survey on publicly available image datasets for weed recognition. Among 36 datasets identified, limitations exist in terms of data variations and distribution shifts, and few of the datasets are suitable for examining the robustness of weed recognition models. A new two-season, eight-class weed dataset is described in this study, comprising two sub-datasets of images collected in the seasons of 2021 and 2022, respectively. Three state-of-the-art deep learning object detectors, i.e., YOLOX, YOLOv8, and DINO, were benchmarked and evaluated for their in-season and cross-season weed detection performance on the dataset. All three models attained in-season detection accuracies of 92% and higher in terms of mAP@50. However substantial accuracy drops of up to 14.5% were observed between in-season and cross-season testing, especially for YOLOX and YOLOv8. Unsupervised domain adaptation based on an implicit instance-invariant network (I3Net) was utilized for improved generalization of the YOLO models. The I3Net-based models resulted in accuracy improvements of 1.4% and 3.3% for YOLOX and YOLOv8, respectively, compared to modeling without domain adaptation, in the cross-season testing. Both the two-season detection dataset11https://doi.org/10.5281/zenodo.10762138 and software programs22https://github.com/vicdxxx/CrossSeasonWeedDetection for weed detection modeling in this study are made publicly available.}
}
@article{TENG2023102252,
title = {Development of a computationally efficient floodplain ecological response model for large-scale, data-sparse riparian environments},
journal = {Ecological Informatics},
volume = {77},
pages = {102252},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102252},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002819},
author = {J. Teng and B. Croke and D. Tan and T. Iwanaga and A.J. Jakeman and C. Pollino and D. Stratford and J. Vaze and W. Dawes and P. Bridgeman and A. Sengupta},
keywords = {Environmental flow, Riparian ecosystem, Wetland, Biodiversity maintenance},
abstract = {Quantitative assessment of floodplain ecological response to flow regimes is challenging but essential for setting targets and estimating impacts for environmental water management. This paper proposes a model that takes long-term (90 years) and large-scale (9 million grid cells) flood maps as input to estimate the response of floodplain vegetation using infinitely differentiable functions. The model, named Floodplain Ecological Response Model (FERM), is calibrated against 1-D temporal Leaf Area Index (LAI) data from the WAVES energy and water balance model at a daily timestep, and validated on the entire floodplain using condition data of the Icon Sites of the Murray River aggregated to a yearly timestep. Results show that FERM can adequately simulate the response of different types of vegetation on the floodplain, while reducing the data requirements and runtime drastically compared to other approaches. The FERM modeling approach is a first step towards a quantitative modeling of floodplain forest ecosystems at large scale with realistic data and computation requirements. It is intended to indicate the potential of such an approach in semi-arid systems where data availability is limited, and to encourage the further research needed to improve our understanding of floodplain forests and our capacity to model the impact of floods on their ecological response.}
}
@article{YUDAPUTRA2024102534,
title = {Vulnerability of lowland and upland orchids in their spatially response to climate change and land cover change},
journal = {Ecological Informatics},
volume = {80},
pages = {102534},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102534},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000761},
author = {Angga Yudaputra and Esti Munawaroh and Didi Usmadi and Danang Wahyu Purnomo and Inggit Puji Astuti and Dwi Murti Puspitaningtyas and Tri Handayani and R. Vitri Garvita and Popi Aprilianti and Hary Wawangningrum and Elga Renjana and Elizabeth Handini and Melisnawati H. Angio and Elok Rifqi Firdiana and Joko Ridho Witono and Lina Susanti Juswara and Izu Andry Fijridiyanto and Siti Roosita Ariati and  Yuzammi and Sudarmono Sudarmono and Irvan Fadli Wanda and Aninda Retno Utami Wibowo and Richa Kusuma Wati and Prima Wahyu Kusuma Hutabarat and Puguh Dwi Raharjo and Saniyatun {Mar'atus Solihah} and Reza Saputra and Wendell P. Cropper},
keywords = {Ensemble model, Climate change, Species distribution model, Orchids, Lowland, Upland, New Guinea},
abstract = {Climate change and land cover change often interactively affect plant species distributions. This study addresses the vulnerability of lowland and upland orchids to climate change and land cover change. Endemic orchids of New Guinea were grouped into four classes (lowland epiphyte, lowland terrestrial, upland epiphyte, upland terrestrial) based on their life form and elevation range. Forty occurrence records of endemic orchids were selected for each class, totaling 160 occurrence records. Ensemble modelling combining two machine learning algorithms was used to generate predictive current and future suitable areas for orchid classes. Model performance was evaluated using the AUC and TSS metrics. Suitable areas for both lowland and upland orchids (epiphyte and terrestrial) were predicted decrease in the future due to climate change and land cover change. The loss of suitable areas for upland terrestrial orchids was predicted to be most significant in the worst-case climate change scenario (SSP 5–8.5). Both lowland and upland orchids (epiphyte and terrestrial) tend to shift to higher elevation ranges from the present distributions. The predictive models have AUC values >0.90 and TSS value >0.80, indicating the models have excellent potential for predicting the impact of climate change and land cover change on orchid distributions.}
}
@article{HASAN2023102361,
title = {Image patch-based deep learning approach for crop and weed recognition},
journal = {Ecological Informatics},
volume = {78},
pages = {102361},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102361},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003904},
author = {A S M Mahmudul Hasan and Dean Diepeveen and Hamid Laga and Michael G.K. Jones and Ferdous Sohel},
keywords = {Weed classification, Deep learning, Patch-based technique, Digital agriculture},
abstract = {Accurate classification of weed species in crop plants plays a crucial role in precision agriculture by enabling targeted treatment. Recent studies show that artificial intelligence deep learning (DL) models achieve promising solutions. However, several challenging issues, such as lack of adequate training data, inter-class similarity between weed species and intra-class dissimilarity between the images of the same weed species at different growth stages or for other reasons (e.g., variations in lighting conditions, image capturing mechanism, agricultural field environments) limit their performance. In this research, we propose an image based weed classification pipeline where a patch of the image is considered at a time to improve the performance. We first enhance the images using generative adversarial networks. The enhanced images are divided into overlapping patches, a subset of which are used for training the DL models. For selecting the most informative patches, we use the variance of Laplacian and the mean frequency of Fast Fourier Transforms. At test time, the model's outputs are fused using a weighted majority voting technique to infer the class label of an image. The proposed pipeline was evaluated using 10 state-of-the-art DL models on four publicly available crop weed datasets: DeepWeeds, Cotton weed, Corn weed, and Cotton Tomato weed. Our pipeline achieved significant performance improvements on all four datasets. DenseNet201 achieved the top performance with F1 scores of 98.49%, 99.83% and 100% on Deepweeds, Corn weed and Cotton Tomato weed datasets, respectively. The highest F1 score on the Cotton weed dataset was 98.96%, obtained by InceptionResNetV2. Moreover, the proposed pipeline addressed the issues of intra-class dissimilarity and inter-class similarity in the DeepWeeds dataset and more accurately classified the minority weed classes in the Cotton weed dataset. This performance indicates that the proposed pipeline can be used in farming applications.}
}
@article{BAKHT2024102631,
title = {MuLA-GAN: Multi-Level Attention GAN for Enhanced Underwater Visibility 11⁎First two authors has equal contribution⋆github code link:https://github.com/AhsanBaidar/MuLAGAN.git ORCID (s): 0000–0002–9079-0960 (A.B. Bakht); 0000–0001–9789-8483 (Z. Jia); 0000–0001–6214-1077 (M.U. Din); 0000–0002–7401-5120 (W. Akram); 0000–0003–4445-3135 (L.S. Saoud); 0000–0001–6405-8402 (L. Seneviratne); 0000–0001–6432-5187 (S. He); 0000–0003–2759-0306 (I. Hussain)},
journal = {Ecological Informatics},
volume = {81},
pages = {102631},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102631},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001730},
author = {Ahsan B. Bakht and Zikai Jia and Muhayy Ud Din and Waseem Akram and Lyes Saad Saoud and Lakmal Seneviratne and Defu Lin and Shaoming He and Irfan Hussain},
keywords = {Underwater image enhancement, Generative adversarial networks (GANs), Spatio-channel attention, Computer vision, Real-time image processing},
abstract = {The underwater environment presents unique challenges (color distortions, reduced contrast, blurriness) hindering accurate analysis. This work introduces MuLA-GAN, a novel approach leveraging Generative Adversarial Networks (GANs) and specifically adapted Multi-Level Attention for comprehensive underwater image enhancement. MuLA-GAN integrates Multi-Level Attention within the GAN architecture to prioritize learning discriminative features crucial for precise image restoration. These relevant features encompass information on local details within image regions leveraged by spatial attention and features at various scales across the entire image captured by multi-level attention. This allows MuLA-GAN to identify and enhance objects, textures, and edges obscured by underwater distortions while also reconstructing a more accurate and visually clear representation of the underwater scene by analyzing low-level information like edges and textures, as well as high-level information like object shapes and global scene information. By selectively focusing on these relevant features, MuLA-GAN excels at capturing and preserving intricate details in underwater imagery, which is essential for various marine research, exploration, and resource management applications. Extensive evaluations on diverse datasets (UIEB test, UIEB challenge, U45, UCCS) demonstrate MuLA-GAN's superior performance compared to existing methods. Additionally, a specialized bio-fouling and aquaculture dataset confirms the model's robustness in challenging environments. On the UIEB test dataset, MuLA-GAN achieves exceptional Peak Signal-to-Noise Ratio (PSNR) (25.59) and Structural Similarity Index (SSIM) (0.893) scores, surpassing Water-Net (24.36 PSNR, 0.885 SSIM). This work addresses a significant research gap in underwater image enhancement by demonstrating the effectiveness of combining GANs with specifically adapted Multi-Level Attention mechanisms. This tailored approach offers a novel and comprehensive framework for restoring underwater image quality, providing valuable insights for accurate underwater scene analysis. The source code for MuLA-GAN is publicly available on GitHub at https://github.com/AhsanBaidar/MuLA_GAN.git}
}
@article{BHAGABATI2024102398,
title = {An automated approach for human-animal conflict minimisation in Assam and protection of wildlife around the Kaziranga National Park using YOLO and SENet Attention Framework},
journal = {Ecological Informatics},
volume = {79},
pages = {102398},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102398},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004272},
author = {Bijuphukan Bhagabati and Kandarpa Kumar Sarma and Kanak Chandra Bora},
keywords = {Computer vision, Object detection, Animal detection, Human-animal conflict, Kaziranga, Deep learning, Yolo},
abstract = {Human-animal conflict in Assam, India's north-eastern state, is rising continuously. Because it occurs year-round, it damages agricultural productivity and kills people and animals, including elephants. When a herd of wild elephants emerges from a deep forest and enters human-inhabited territory around the Kaziranga National Park (KNP) in Assam, an alert must be sounded for the neighbourhood residents and forest workers to prevent conflicts. Another concern is that many wild animals die near the KNP while crossing the national highway NH-37 which traverses the area. During floods, animals flee to the highlands for food and shelter. An automated animal identification and warning system near the KNP may reduce human-animal confrontations. This paper reports the design of a system that attempts to address the above concerns. Artificial Intelligence (AI)-based strategies are utilized to recognize wild animals from live video sequences, provide warnings to avoid encounters, and protect humans and animals. Deep learning models and YoloV5 with the SENet attention layer are used to recognize wild animals in real-time. This model is trained using a public and customized dataset of animal species. Cameras attached to the cloud-based AI system take photographs from several KNP locations to confirm the model. The model's 96% accuracy in animal photographs and videos taken day and night and in feed from contemporaneous location has shown its utility. The model also improves reliability by 1–13% over previous methods.}
}
@article{SOOM2022101817,
title = {Environmentally adaptive fish or no-fish classification for river video fish counters using high-performance desktop and embedded hardware},
journal = {Ecological Informatics},
volume = {72},
pages = {101817},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101817},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002679},
author = {Jürgen Soom and Vishwajeet Pattanaik and Mairo Leier and Jeffrey A. Tuhtan},
keywords = {Fish detection, Deep learning, Underwater video, Environmental classification, Embedded hardware},
abstract = {Automated fish counters featuring robust, real-time computer vision capabilities can provide a cost-effective means to count migrating freshwater fish. In this work, we propose a four-stage process for automatically sorting videos with and without fish. Underwater fish counter videos provide a challenging range of environmental conditions including clear water, biofilm growth, bubbles, turbidity, low light and overexposure. To address this, our method also includes the automated classification of these six environmental conditions. The proposed methods are computationally efficient and can be implemented on servers, high-performance desktop computers and low-cost, energy-efficient embedded hardware. The models were trained, tested, and validated using a collection of 3000 videos taken from underwater fish counter installations in several alpine and lowland European rivers provided by commercial and governmental collaborators. This work demonstrates a fast, accurate, and robust computer vision workflow for large-scale automated freshwater fish counting systems.}
}
@article{WU2022101534,
title = {SILIC: A cross database framework for automatically extracting robust biodiversity information from soundscape recordings based on object detection and a tiny training dataset},
journal = {Ecological Informatics},
volume = {68},
pages = {101534},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101534},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121003253},
author = {Shih-Hung Wu and Hsueh-Wen Chang and Ruey-Shing Lin and Mao-Ning Tuanmu},
keywords = {Sound Identification and Labeling Intelligence for Creatures, Automated wildlife sound identification, Passive acoustic monitoring, Autonomous recording unit, Object detection}
}
@article{YIN2024102450,
title = {Automatic detection of stereotypical behaviors of captive wild animals based on surveillance videos of zoos and animal reserves},
journal = {Ecological Informatics},
volume = {79},
pages = {102450},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102450},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300479X},
author = {Zixuan Yin and Yaqin Zhao and Zhihao Xu and Qiuping Yu},
keywords = {Stereotypical behavior, Captive animal, Animal welfare, Animal tracking, Siamese network, Motion trajectory},
abstract = {The timely detection of the depressive and stereotypical behaviors often observed in captive wild animals and the subsequent intervention can contribute to improving their living environment in enclosures, which is crucial for safeguarding animal welfare, enhancing animal husbandry practices, regulating human–animal relationships. Several studies have analyzed factors that influence animal stereotypical behaviors and identified preventive measures via regular animal observations. An automatic detection method based on video technology can yield long-term automatic recordings of motion trajectories of animals after a professionally trained automatic detection software is integrated into the human–machine interaction operation interface of animal management. As an initial exploration of this research paradigm, we propose a novel method for automatically tracking and recognizing the stereotypical behavior of animals in surveillance videos based on the periodic analysis of motion trajectories. First, we introduced a Siamese relation network to track the motion trajectories of animals. This network accurately tracked animals and distinguished different individuals in complex environments. Second, an autocorrelation function was used to analyze the periodicity of the motion trajectory, which was divided into several periodic curves. Finally, a cross-correlation function was introduced to determine the linear correlation between the two variables of the periodic curves. This function distinguished the three types of motion trajectories. The success rate and precision of the animal-tracking method adopted in this study were 67.4% and 90.4%, respectively, which were superior to those of common Siamese tracking networks. The average prediction error of the cycle time was 0.095 s. Therefore, the proposed method can accurately track the motion trajectories of animals and identify their stereotypical behaviors. Furthermore, this study provides data to facilitate the scientific management of animals and improve animal welfare. The codes and datasets used in the study are available at https://github.com/yinyinzixuan/animal-stereotypical-behavior.git.}
}
@article{ALI2024102618,
title = {An ensemble of deep learning architectures for accurate plant disease classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102618},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102618},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001602},
author = {Ali Hussein Ali and Ayman Youssef and Mahmoud Abdelal and Muhammad Adil Raja},
keywords = {Plant leaf disease, Agriculture, Ensemble deep learning models},
abstract = {A substantial fraction of agricultural produce loss can be attributed to plant diseases. Agricultural yield loss can have far-reaching consequences for a country's economy and contribute to global food insecurity. Early detection of plant diseases can be instrumental in maintaining global health and welfare. A pathologist's visual evaluation is typically used to make an early diagnosis of plant diseases. This technique involves experts or farmers examining plants with the naked eye and classifying the disease depending on their previous experience. This conventional approach includes drawbacks like low accuracy and the need for human expertise. This motivates researchers to investigate automated systems for the early diagnosis of plant diseases. To achieve this goal an ensemble of different deep learning architectures (DenseNet201, efficientNetB0, inceptionresnetV2, efficientNetB3) is introduced to increase the classification accuracy of plant leaf diseases. In this work, a novel image-processing technique is proposed to increase the efficiency of deep-learning models. Also, a data balancing technique is used to solve the problem of the imbalanced dataset. Five different deep-learning models are trained and tested using the largest plant disease dataset; PlantVillage. Ten different ensembles (chosen randomly) of the deep learning models are tested and compared to find the ensemble with the highest accuracy. The proposed ensemble model was able to achieve 99.89% accuracy on the New PlantVillage dataset. PlantVillage is a challenging dataset with 38 classes. Achieving high accuracies on such a dataset proves the ability of the system to generalize on unseen data or real-world scenarios. A comparison with the state-of-the-art is made with other available models from the literature. A section about this is added to show the superior performance of the proposed ensemble model in terms of accuracy and F1-score.}
}
@article{CELIS2024102578,
title = {A versatile, semi-automated image analysis workflow for time-lapse camera trap image classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102578},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102578},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001201},
author = {Gerardo Celis and Peter Ungar and Aleksandr Sokolov and Natalia Sokolova and Hanna Böhner and Desheng Liu and Olivier Gilg and Ivan Fufachev and Olga Pokrovskaya and Rolf Anker Ims and Wenbo Zhou and Dan Morris and Dorothee Ehrich},
keywords = {Arctic wildlife monitoring, Deep learning, ResNet-50, MegaDetector, Time-lapse camera},
abstract = {Camera traps are a powerful, practical, and non-invasive method used widely to monitor animal communities and evaluate management actions. However, camera trap arrays can generate thousands to millions of images that require significant time and effort to review. Computer vision has emerged as a tool to accelerate this image review process. We propose a multi-step, semi-automated workflow which takes advantage of site-specific and generalizable models to improve detections and consists of (1) automatically identifying and removing low-quality images in parallel with classification into animals, humans, vehicles, and empty, (2) automatically cropping objects from images and classifying them (rock, bait, empty, and species), and (3) manually inspecting a subset of images. We trained and evaluated this approach using 548,627 images from 46 cameras in two regions of the Arctic: “Finnmark” (Finnmark County, Norway) and “Yamal” (Yamalo-Nenets Autonomous District, Russia). The automated steps yield image classification accuracies of 92% and 90% for the Finnmark and Yamal sets, respectively, reducing the number of images that required manual inspection to 9.2% of the Finnmark set and 3.9% of the Yamal set. The amount of time invested in developing models would be offset by the time saved from automation after 960 thousand images have been processed. Researchers can modify this multi-step process to develop their own site-specific models and meet other needs for monitoring and surveying wildlife, balancing the acceptable levels of false negatives and positives.}
}
@article{ZHANG2024102517,
title = {Automatic bioacoustics noise reduction method based on a deep feature loss network},
journal = {Ecological Informatics},
volume = {80},
pages = {102517},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102517},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000591},
author = {Chengyun Zhang and Kaiying He and Xinghui Gao and Yingying Guo},
keywords = {Bioacoustics, Noise reduction, Deep learning, Deep feature loss network},
abstract = {Acoustic sensors that collect acoustic data over extended periods and broad ranges are widely used in bioacoustics monitoring. However, in open environments, acoustic data collected using acoustic sensors can be subject to interference from various real-world noises, thereby influencing the subsequent analysis and processing of bioacoustic data. Existing bioacoustic noise reduction methods are limited in their application because of their low efficiency, unsuitability for non-stationary noise, generally unimproved signal-to-noise ratio (SNR) efficacy, and considerable amounts of residual noise. These limitations hinder the effective processing of recorded signals for which extraneous noise overlaps with bird vocalizations. In this study, we propose a bioacoustic noise reduction method based on a deep feature loss network for bird sounds. The method has a rapid denoising speed and can more effectively remove background noise from field recording signals without distorting the bird acoustic spectrum. The denoising effects of the proposed method were compared with those of a speech enhancement generative adversarial network, web real-time communications denoising, and other noise reduction methods. The denoising ability of these methods for different noises was evaluated using spectrograms and objective evaluation measures such as the SNR and perceptual evaluation of speech quality (PESQ). The experimental results revealed that our proposed noise reduction method can obtain higher SNRs and PESQ scores than other noise reduction methods, with the SNR increasing by up to 35.83 dB following denoising.}
}
@article{ZOU2024102562,
title = {Bacterial community characterization by deep learning aided image analysis in soil chips},
journal = {Ecological Informatics},
volume = {81},
pages = {102562},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102562},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001043},
author = {Hanbang Zou and Alexandros Sopasakis and François Maillard and Erik Karlsson and Julia Duljas and Simon Silwer and Pelle Ohlsson and Edith C. Hammer},
keywords = {Soil bacterial cell counting, Segmentation, Microfluidics, Microbial image recognition, Morphological biodiversity, Bacterial traits},
abstract = {Soil microbes play an important role in governing global processes such as carbon cycling, but it is challenging to study them embedded in their natural environment and at the single cell level due to the opaque nature of the soil. Nonetheless, progress has been achieved in recent years towards visualizing microbial activities and organo-mineral interaction at the pore scale, especially thanks to the development of microfluidic ‘soil chips’ creating transparent soil model habitats. Image-based analyses come with new challenges as manual counting of bacteria in thousands of digital images taken from the soil chips is excessively time-consuming, while simple thresholding cannot be applied due to the background of soil minerals and debris. Here, we adopt the well-developed deep learning algorithm Mask-RCNN to quantitatively analyze the bacterial communities in soil samples from different locations in the world. This work demonstrates analysis of bacterial abundance from three contrasting locations (Greenland, Sweden and Kenya) using deep learning in microfluidic soil chips in order to characterize population and community dynamics. We additionally quantified cell- and colony morphology including cell size, shape and the cell aggregation level via calculation of the distance to the nearest neighbor. This approach allows for the first time an automated visual investigation of soil bacterial communities, and a crude biodiversity measure based on phenotypic cell morphology, which could become a valuable complement to molecular studies.}
}
@article{CORO2021101384,
title = {An Open Science approach to infer fishing activity pressure on stocks and biodiversity from vessel tracking data},
journal = {Ecological Informatics},
volume = {64},
pages = {101384},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101384},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121001758},
author = {Gianpaolo Coro and Anton Ellenbroek and Pasquale Pagano},
keywords = {Vessel transmitted information, Vessel tracking data, Automatic Identification System, Statistical analysis, e-Infrastructures, Open Science, Biodiversity, Integrated Environmental Assessment},
abstract = {Vessel tracking data help study the potential impact of fisheries on biodiversity and produce risk assessments. Existing workflows process vessel tracks to identify fishing activity and integrate information on species vulnerability. However, there are significant data integration challenges across the data sources needed for an integrated impact assessment due to heterogeneous nomenclatures, data accessibility issues, geographical and computational scalability of the processes, and confidentiality and transparency towards decision making authorities. This paper presents an Open Science data integration approach to use vessel tracking data in integrated impact assessments. Our approach combines heterogeneous knowledge sources from fisheries, biodiversity, and environmental observations to infer fishing activity and risks to potentially impacted species. An Open Science e-Infrastructure facilitates access to data sources and maximises the reproducibility of the results and the method's reusability across several application domains. Our method's quality is assessed through three case studies: The first demonstrates cross-dataset consistency by comparing the results obtained from two different vessel data sources. The second performs a temporal pattern analysis of fishing activity and potentially impacted species over time. The third assesses the potential impact of reduced fishing pressure on marine biodiversity and threatened species due to the 2020 COVID-19 lockdown in Italy. The method is meant to be integrated with other systems through its Open Science-oriented features and can rapidly use new sources of findable, accessible, interoperable, and reusable (FAIR) data. Other systems can use it to (i) classify vessel activity in data-limited scenarios, (ii) identify bycatch species (when catchability data are available), and (iii) study the effects of fisheries on habitats and populations’ growth.}
}