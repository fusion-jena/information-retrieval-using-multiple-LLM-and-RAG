@article{MEERDINK2024102432,
title = {Dealing with imperfect data for invasive species detection using multispectral imagery},
journal = {Ecological Informatics},
volume = {79},
pages = {102432},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102432},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004612},
author = {Susan Meerdink and Drew Hiatt and S. Luke Flory and Alina Zare},
keywords = {Multiple-instance learning, Random forest, Machine learning, Vegetation classification, RapidEye, Landsat 8, NAIP, , Everglades National Park},
abstract = {Detection and monitoring invasive species can provide valuable ecological information to guide management decisions. Multispectral imagery remote sensing may be an ideal tool to address this problem by providing accurate and affordable repeat imagery. However, developing training datasets for remote sensing imagery can be riddled with issues such as matching a training site to a single pixel in target imagery or mixed pixels caused by low invader densities. The multitarget multiple-instance spectral match filter (MTMI-SMF) algorithm accounts for such errors and has low computation costs. Here, we evaluated MTMI-SMF for invasive species detection with National Agriculture Imagery Program (NAIP), RapidEye, and Landsat imagery using Brazilian peppertree (Schinus terebinthifolia) in the Everglades National Park as a case study. MTMI-SMF detected Brazilian peppertree with an area under the curve (AUC) of 0.85 for Landsat, 0.82 for RapidEye, and 0.71 NAIP imagery. Invader classification was developed using a threshold calculated from MTMI-SMF image detection confidence values and compared to a random forest classification. MTMI-SMF and random forest classifications had similar overall accuracies with NAIP imagery performing the lowest (an average of 73.6% and 88.9%, respectively) and Landsat performing the highest (an average of 90.9% and 91.4%, respectively). However, due to the relatively rare nature of Brazilian peppertree across this landscape, the overall classification accuracy was not fully representative of detection capabilities. MTMI-SMF outperformed random forest for user accuracy and had comparable producer accuarcy across all three image sources. Classifications primarily relied on the brighter signature of Brazilian peppertree due to the limited number of spectral bands in the multispectral imagery. As a result, confusion was caused by heterogeneous vegetation communities or shrub habitats, which most likely could be resolved with the increased availability of satellite hyperspectral datasets. Our study indicates that MTMI-SMF, a machine-learning approach that allows flexibility in training data, can detect highly problematic invaders using multispectral imagery. This pipeline could be readily adapted to other invaders and ecosystems, as well as different remote sensing image sources, and has low computational requirements. Our study demonstrates that remote sensing technologies and multiple-instance learning algorithms can provide managers with critical tools for tackling the ever-growing, costly, and challenging problem of tracking invasive species' plant spread.}
}
@article{BOTERSPITARCH2024102456,
title = {An intelligent cellular automaton scheme for modelling forest fires},
journal = {Ecological Informatics},
volume = {80},
pages = {102456},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102456},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004855},
author = {Joan Boters-Pitarch and María Teresa Signes-Pont and Julian Szymański and Higinio Mora-Mora},
keywords = {Forest fires, Spread models, Intelligent architecture, Neighbourhood relationship},
abstract = {Forest fires have devastating consequences for the environment, the economy and human lives. Understanding their dynamics is therefore crucial for planning the resources allocated to combat them effectively. In a world where the incidence of such phenomena is increasing every year, the demand for efficient and accurate computational models is becoming increasingly necessary. In this study, we perform a revision of an initial proposal which consists of a two-dimensional propagation model based on cellular automata (2D-CA), which aims to understand the dynamics of these phenomena. We identify the key theoretical weaknesses and propose improvements to address these limitations. We also assess the effectiveness and accuracy of the model by evaluating improvements using real forest fire data (Beneixama, Alicante 2019). Moreover, as a result of the theoretical modifications performed, we introduce a novel intelligent architecture that seeks to capture relationships between system cells from the data. This new architecture has the ability to advance our understanding of forest fire dynamics, contributing to both the evaluation of existing protocols and more efficient firefighting resource management.}
}
@article{VAN2024102601,
title = {Enhancing wildfire mapping accuracy using mono-temporal Sentinel-2 data: A novel approach through qualitative and quantitative feature selection with explainable AI},
journal = {Ecological Informatics},
volume = {81},
pages = {102601},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001432},
author = {Linh Nguyen Van and Vinh Ngoc Tran and Giang V. Nguyen and Minho Yeon and May Thi-Tuyet Do and Giha Lee},
keywords = {Wildfire severity mapping, Machine learning, Sentinel-2, SHAP, Forward stepwise selection},
abstract = {Accurate wildfire severity mapping (WSM) is crucial in environmental damage assessment and recovery strategies. Machine learning (ML) and remote sensing technologies are extensively integrated and employed as powerful tools for WSM. However, the intricate nature of ML algorithms often leads to ‘black box’ systems, obscuring the decision-making process and significantly limiting stakeholders' ability to comprehend the basis of predictions. This opacity hinders efforts to enhance performance and risks exacerbating overfitting. This present study proposes an innovative WSM approach that incorporates qualitative and quantitative feature selection techniques within the Explainable AI (XAI) framework. The methodology aims to enhance the precision of WSM and provide insights into the factors contributing to model decisions, thereby increasing the interpretability of predictions and streamlining models to improve performance. To achieve this objective, we employed the SHapley Additive exPlanations (SHAP)-Forward Stepwise Selection (FSS) method to demonstrate its efficacy in elucidating the qualitative and quantitative impacts of predictors on ML algorithm performance, accuracy, and interpretability designed for WSM. Utilizing post-fire imagery from Sentinel-2 (S2), we analyzed ten bands to generate 225 unique spectral indices utilizing five different calculations: normalized, algebraic sum, difference, ratio, and product forms. Combined with the original S2 bands, this resulted in 235 potential predictors for ML classifications. A random forest model was subsequently developed using these predictors and optimized through extensive hyperparameter tuning, achieving an overall accuracy (OA) of 0.917 and a Kappa statistic of 0.896. The most influential predictors were identified using SHAP values, with an FSS process narrowing them down to the 12 most critical for effective WSM, as evidenced by stabilized OA and Kappa values (0.904 and 0.881, respectively). Further validation using a ninefold spatial cross-validation technique demonstrated the method's consistent performance across different data partitions, with OA values ranging from 0.705 to 0.894 and Kappa values from 0.607 to 0.867. By providing a more accurate and comprehensible XAI-based method for WSM, this research contributes to the broader field of environmental monitoring and disaster response, underscoring the potential of integrated qualitative and quantitative analysis to enhance ML models' capabilities.}
}
@article{WHITE2023102363,
title = {One size fits all? Adaptation of trained CNNs to new marine acoustic environments},
journal = {Ecological Informatics},
volume = {78},
pages = {102363},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102363},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003928},
author = {Ellen L. White and Holger Klinck and Jonathan M. Bull and Paul R. White and Denise Risch},
keywords = {Bioacoustics, Deep learning, Domain adaptation, Marine acoustics, Marine mammal detection, Soundscapes},
abstract = {Convolutional neural networks (CNNs) have the potential to enable a revolution in bioacoustics, allowing robust detection and classification of marine sound sources. As global Passive Acoustic Monitoring (PAM) datasets continue to expand it is critical we improve our confidence in the performance of models across different marine environments, if we are to exploit the full ecological value of information within the data. This work demonstrates the transferability of developed CNN models to new acoustic environments by using a pre-trained model developed for one location (West of Scotland, UK) and deploying it in a distinctly different soundscape (Gulf of Mexico, USA). In this work transfer learning is used to fine-tune an existing open-source ‘small-scale’ CNN, which detects odontocete tonal and broadband call types and vessel noise (operating between 0 and 48 kHz). The CNN is fine-tuned on training sets of differing sizes, from the unseen site, to understand the adaptability of a network to new marine acoustic environments. Fine-tuning with a small sample of site-specific data significantly improves the performance of the CNN in the new environment, across all classes. We demonstrate an improved performance in area-under-curve (AUC) score of 0.30, across four classes by fine-training with only 50 spectrograms per class, with a 5% improvement in accuracy between 50 frames and 500 frames. This work shows that only a small amount of site-specific data is needed to retrain a CNN, enabling researchers to harness the power of existing pre-trained models for their own datasets. The marine bioacoustic domain will benefit from a larger pool of global data for training large deep learning models, but we illustrate in this work that domain adaptation can be improved with limited site-specific exemplars.}
}
@article{GHAFFARI2024102573,
title = {On the role of audio frontends in bird species recognition},
journal = {Ecological Informatics},
volume = {81},
pages = {102573},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102573},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001158},
author = {Houtan Ghaffari and Paul Devos},
keywords = {Bioacoustics, Audio frontend, Bird sound recognition, Deep learning},
abstract = {Automatic acoustic monitoring of bird populations and their diversity is in demand for conservation planning. This requirement and recent advances in deep learning have inspired sophisticated species recognizers. However, there are still open challenges in creating reliable monitoring systems of natural habitats. One of many open questions is whether predominantly used audio features like mel-filterbanks are appropriate for such analysis since their design follows human's perception of the sound, making them susceptible to discarding fine details from other animals' vocalization. Although research shows that different audio features work better for particular tasks and datasets, it is hard to attribute all advantages to input features since the experimental setups vary. A general solution is to design a learnable audio frontend to extract task-relevant features from raw waveform since it contains all the information in other audio features. The current paper thoroughly analyzes the role of such frontends in bird species recognition, which helped to evaluate the adequacy of traditional time-frequency representations (static frontends) in capturing the relevant information from bird vocalization. In particular, this work shows that the main performance gain in learnable audio frontends comes from the normalization and compression operations rather than the data-driven frequency selectivity and functional form of filters. We observed no significant discrepancy between the frequency bands of the learned and static frontends for bird vocalization. Although the performance of learnable frontends was much higher, we will show that adequate normalization and compression enhance the accuracy of traditional frontends by more than 16% to achieve comparable results for bird species recognition. Ablation studies of the frontends under different configurations and detailed analysis of noise robustness provide evidence for the conclusions, validate the use of mel-filterbanks and similar features in prior works, and provide guidelines for designing future species recognizers. The code is available at https://github.com/houtan-ghaffari/bird-frontends.}
}
@article{LOPEZCOLLADO2024102444,
title = {Bioclimatic similarity between species locations and their environment revealed by dimensionality reduction analysis},
journal = {Ecological Informatics},
volume = {79},
pages = {102444},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102444},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004739},
author = {J. Lopez-Collado and J. Jacinto-Padilla and O. Rodríguez-Aguilar and J.V. Hidalgo-Contreras},
keywords = {Binary classifier, Data visualization, Latent distance, Species distribution modeling, UMAP},
abstract = {Species distribution modeling is an active research topic with applications in conservation management, pest risk assessment, and population ecology. Several machine-learning methods have been applied to estimate species distribution. Non-linear dimensionality reduction techniques aim to preserve the similarity among objects at a reduced dimension for visualization, clustering, and feature selection. We propose a framework that uses Uniform Manifold Approximation and Projection (UMAP) to analyze bioclimatic variables associated with environmental (background) and species samples. Our objective was to identify geographic areas similar to those inhabited by the species. We hypothesize that the similarity between species locations and their environment in the reduced dimension will reflect similarity in the multivariate bioclimatic space. We estimated the probability of background points near a species point utilizing the latent nearest neighbor distance distribution. We tested this procedure with ten insect pest species of global importance and found that UMAP was able to generate a gradient of similarity between geographic areas and species occurrence. We also found that background-species latent distance tends to have a convergent non-linear relationship with the mean value of bioclimatic variables, thus supporting our key assumption. The performance of UMAP as a binary classifier and comparison with MaxEnt supports its use in modeling of species distribution. Potential applications are discussed for multi-species and multi-scenario analysis, as well as projection to new regions.}
}
@article{DUAN2024102637,
title = {SIAlex: Species identification and monitoring based on bird sound features},
journal = {Ecological Informatics},
volume = {81},
pages = {102637},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102637},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001791},
author = {Lin Duan and Lidong Yang and Yong Guo},
keywords = {Lightweight, Cascading activation function, Bird sound recognition, Structural re-parameterization, Nonlinear performance},
abstract = {The combination of deep learning and bird sound recognition is widely employed in bird species conservation monitoring. A complex network structure is not conducive for deploying bird sound recognition devices, resulting in problems such as long inference time and low efficiency. Using AlexNet as the backbone model, we explore the potential of shallow and straightforward models without complex connection techniques or attention mechanisms, named SIAlex, to recognise and classify 20 bird sound datasets, which are simultaneously validated on a 10 class UrbanSound8k dataset. Using the structural re-parameterization method, the number of model layers is reduced, computational efficiency is improved, and the inference time is significantly reduced, achieving a decoupling of training and inference time in the structure. To increase the nonlinearity of the model, a cascaded approach is utilised to increase the number of activation functions, thereby significantly improving the generalisation performance of the model. Simultaneously, in the classifier section, convolutional layer replaces the original fully connected layer, thereby reducing the inference time and increasing the feature extraction ability of the model, improving accuracy, and effectively recognising bird speech. The experimental data show that the SIAlex network on the Birdsdata dataset improves the accuracy to 93.66%, and the inference time for a piece of data is only 2.466 ms. The accuracy of the UrbanSound8k dataset reaches 96.04%, and the inference time for a piece of data is 3.031 ms. A large number of experimental comparisons have shown that the method proposed in this paper achieves good results in reducing the inference time of the model, bringing breakthroughs in the application of shallow, simple models.}
}
@article{MCEWEN2024102734,
title = {Active few-shot learning for rare bioacoustic feature annotation},
journal = {Ecological Informatics},
volume = {82},
pages = {102734},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102734},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002760},
author = {Ben McEwen and Kaspar Soltero and Stefanie Gutschmidt and Andrew Bainbridge-Smith and James Atlas and Richard Green},
keywords = {Active learning, Audio classification, Bioacoustics, Few-shot learning, Machine learning},
abstract = {The collection and annotation of bioacoustic data present several challenges to researchers. Bioacoustic monitoring of rare (sparse) or cryptic species generally encounter two main issues. The cost of collecting and processing field data and a lack of labelled datasets for the target species. The detection of invasive species incursions and probability of absence testing is especially challenging due to these species having population densities at or close to zero. We present a methodology specifically designed to aid in the analysis of rare acoustic events within long-term field recordings. This approach combines a wavelet-based segmentation method that automatically extracts transient features from within-field recordings. A few-shot active learning recommender system in a human-in-the-loop process prioritises the annotation of low-certainty samples. This process combines the accuracy of human classification and the speed of computational tools to greatly reduce the presence of non-target features in field recordings. We evaluate this approach using an invasive species identification case study. This methodology achieves a test accuracy of 98.4% as well as 81.2% test accuracy using 2-shot, 2-way prototypical learning without fine-tuning, demonstrating high performance at varying data availability contexts. Active learning using low-certainty samples achieves >90% test accuracy using only 20 training samples compared to 80 samples without active learning. This approach allows users to train custom audio classification models for any application with rare features. The model can be easily exported for use in the field making real-time bioacoustic monitoring of less-vocal species a possibility. All code and data are available at https://github.com/Listening-Lab/Annotator.}
}
@article{XIE2022101893,
title = {Multi-view features fusion for birdsong classification},
journal = {Ecological Informatics},
volume = {72},
pages = {101893},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101893},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003430},
author = {Shanshan Xie and Jing Lu and Jiang Liu and Yan Zhang and Danjv Lv and Xu Chen and Youjie Zhao},
keywords = {Birdsong recognition, Deep features, Handcrafted features, mRMR, Feature selection},
abstract = {As important members of the ecosystem, birds are good monitors of the ecological environment. Bird recognition, especially birdsong recognition, has attracted more and more attention in the field of artificial intelligence. At present, traditional machine learning and deep learning are widely used in birdsong recognition. Deep learning can not only classify and recognize the spectrums of birdsong, but also be used as a feature extractor. Machine learning is often used to classify and recognize the extracted birdsong handcrafted feature parameters. As the data samples of the classifier, the feature of birdsong directly determines the performance of the classifier. Multi-view features from different methods of feature extraction can obtain more perfect information of birdsong. Therefore, aiming at enriching the representational capacity of single feature and getting a better way to combine features, this paper proposes a birdsong classification model based multi-view features, which combines the deep features extracted by convolutional neural network (CNN) and handcrafted features. Firstly, four kinds of handcrafted features are extracted. Those are wavelet transform (WT) spectrum, Hilbert-Huang transform (HHT) spectrum, short-time Fourier transform (STFT) spectrum and Mel-frequency cepstral coefficients (MFCC). Then CNN is used to extract the deep features from WT, HHT and STFT spectrum, and the minimal-redundancy-maximal-relevance (mRMR) to select optimal features. Finally, three classification models (random forest, support vector machine and multi-layer perceptron) are built with the deep features and handcrafted features, and the probability of classification results of the two types of features are fused as the new features to recognize birdsong. Taking sixteen species of birds as research objects, the experimental results show that the three classifiers obtain the accuracy of 95.49%, 96.25% and 96.16% respectively for the features of the proposed method, which are better than the seven single features and three fused features involved in the experiment. This proposed method effectively combines the deep features and handcrafted features from the perspectives of signal. The fused features can more comprehensively express the information of the bird audio itself, and have higher classification accuracy and lower dimension, which can effectively improve the performance of bird audio classification.}
}
@article{TORRESANI2023102082,
title = {LiDAR GEDI derived tree canopy height heterogeneity reveals patterns of biodiversity in forest ecosystems},
journal = {Ecological Informatics},
volume = {76},
pages = {102082},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102082},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001115},
author = {Michele Torresani and Duccio Rocchini and Alessandro Alberti and Vítězslav Moudrý and Michael Heym and Elisa Thouverai and Patrick Kacic and Enrico Tomelleri},
keywords = {GEDI, Height heterogeneity, Remote sensing, Canopy height model, Rao’s Q index, Species diversity},
abstract = {The “Height Variation Hypothesis” is an indirect approach used to estimate forest biodiversity through remote sensing data, stating that greater tree height heterogeneity (HH) measured by CHM LiDAR data indicates higher forest structure complexity and tree species diversity. This approach has traditionally been analyzed using only airborne LiDAR data, which limits its application to the availability of the dedicated flight campaigns. In this study we analyzed the relationship between tree species diversity and HH, calculated with four different heterogeneity indices using two freely available CHMs derived from the new space-borne GEDI LiDAR data. The first, with a spatial resolution of 30 m, was produced through a regression tree machine learning algorithm integrating GEDI LiDAR data and Landsat optical information. The second, with a spatial resolution of 10 m, was created using Sentinel-2 images and a deep learning convolutional neural network. We tested this approach separately in 30 forest plots situated in the northern Italian Alps, in 100 plots in the forested area of Traunstein (Germany) and successively in all the 130 plots through a cross-validation analysis. Forest density information was also included as influencing factor in a multiple regression analysis. Our results show that the GEDI CHMs can be used to assess biodiversity patterns in forest ecosystems through the estimation of the HH that is correlated to the tree species diversity. However, the results also indicate that this method is influenced by different factors including the GEDI CHMs dataset of choice and their related spatial resolution, the heterogeneity indices used to calculate the HH and the forest density. Our finding suggest that GEDI LIDAR data can be a valuable tool in the estimation of forest tree heterogeneity and related tree species diversity in forest ecosystems, which can aid in global biodiversity estimation.}
}
@article{CANOVI2024102733,
title = {Trajectory-based fish event classification through pre-training with diffusion models},
journal = {Ecological Informatics},
volume = {82},
pages = {102733},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102733},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002759},
author = {Noemi Canovi and Benjamin A. Ellis and Tonje K. Sørdalen and Vaneeda Allken and Kim T. Halvorsen and Ketil Malde and Cigdem Beyan},
keywords = {Fish behavior, Underwater videos, Event recognition, Trajectory, Generative models, Autoencoder, Diffusion model, Corkwing wrasse},
abstract = {This study contributes to advancing the field of automatic fish event recognition in natural underwater videos, addressing the current gap in studying fish interaction and competition, including predator-prey relationships and mating behaviors. We used the corkwing wrasse (Symphodus melops) as a model, a marine species of commercial importance that reproduces in sea-weed nests built and cared for by a single male. These nests attract a wide range of visitors and are the focal point for behavior such as spawning, chasing, and maintenance. We propose a deep learning methodology to analyze the movement trajectories of the nesting male and classify the associated events observed in their natural habitat. Our approach leverages unsupervised pre-training based on diffusion models, leading to improved feature learning. Additionally, we introduce a dataset comprising 16,937 trajectories across 12 event classes, making it the largest in terms of event class diversity. Our results demonstrate the superior performance of our method compared to several deep architectures. The code for the proposed method and the trajectories can be found at https://github.com/NoeCanovi/Fish_Behaviors_Generative_Models.}
}
@article{GONCALVES2024102628,
title = {Revealing forest structural "fingerprints": An integration of LiDAR and deep learning uncovers topographical influences on Central Amazon forests},
journal = {Ecological Informatics},
volume = {81},
pages = {102628},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102628},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001705},
author = {Nathan Borges Gonçalves and Diogo Martins Rosa and Dalton Freitas {do Valle} and Marielle N. Smith and Ricardo Dalagnol and Danilo Roberti Alves {de Almeida} and Bruce W. Nelson and Scott C. Stark},
keywords = {Structural "fingerprints", LiDAR, Deep learning, Amazon Forest, Terrain variation},
abstract = {Amazon forests are characterized by rich structural diversity. However, the influence of factors such as topography, soil attributes, and external disturbances on structural variability is not always well characterized, and traditional structural metrics may be inadequate to capture this type of complexity. While LiDAR offers expanded structural insights, traditional parameters used in LiDAR analysis, such as mean or maximum canopy height, are not always well directly linked to environmental variables like topography. Emerging approaches merge LiDAR with machine learning to uncover deeper structural complexities. However, work to date may fail to fully utilize the potential of fine-scale LiDAR information. Here we introduce a novel approach, leveraging 2D point cloud images derived from a profiling canopy LiDAR (PCL). The technique targets intricate details within LiDAR point clouds by using deep learning algorithms. With a dataset from the Central Amazon comprising 18 multitemporal transects of 450 m in length, our objective was to detect structural "fingerprints" of varied topographical types along a hillslope, comprising: Riparian, White-sand, and Plateau, and to detect any gradient of structural shifts based on terrain variations here represented by the height above the nearest drainage (HAND). The dataset was trained and tested using a leave-one-group-out approach (LOGO) in which, for each iteration, a complete 450 m multitemporal transect was excluded from training and tested after each iteration. The fast.ai platform and a ResNet-34 architecture, coupled with transfer learning, were used to perform a classification to distinguish between three topographical types. Furthermore, a hybrid model combining a Convolutional Autoencoder, and Partial Least Square (PLS) regression was designed to detect forest structural gradient correlations with HAND variation. Cross-validation achieved a promising high weighted F1 score of 0.83 to classify forests based on the topographical types. Additionally, a combined Convolutional Autoencoder and PLS regression revealed a strong correlation (R2 = 0.76) between actual and predicted HAND. Innovatively combining deep learning with ground-based PCL LiDAR, our study revealed unique Amazon Forest structures connected to topographic variation. Our findings underscore the transformative potential of such integrative approaches for investigating forest dynamics and promise a powerful new tool for understanding climate-related forest structure change.}
}
@article{KALFAS2023102037,
title = {Towards automatic insect monitoring on witloof chicory fields using sticky plate image analysis},
journal = {Ecological Informatics},
volume = {75},
pages = {102037},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102037},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000663},
author = {Ioannis Kalfas and Bart {De Ketelaere} and Klaartje Bunkens and Wouter Saeys},
keywords = {Insect recognition, Convolutional neural networks, Pest management, Automatic monitoring},
abstract = {Context
Sticky trap catches of agricultural pests can be employed for early hotspot detection, identification, and estimation of pest presence in greenhouses or in the field. However, manual procedures to produce and analyze catch results require substantial time and effort. As a result, much research has gone into creating efficient techniques for remotely monitoring possible infestations. A considerable number of these studies use Artificial Intelligence (AI) to analyze the acquired data and focus on performance metrics for various model architectures. Less emphasis, however, was devoted to the testing of the trained models to investigate how well they would perform under practical, in-field conditions.
Objective
In this study, we showcase an automatic and reliable computational method for monitoring insects in witloof chicory fields, while shifting the focus to the challenges of compiling and using a realistic insect image dataset that contains insects with common taxonomy levels.
Methods
To achieve this, we collected, imaged, and annotated 731 sticky plates - containing 74,616 bounding boxes - to train a YOLOv5 object detection model, concentrating on two pest insects (chicory leaf-miners and wooly aphids) and their two predatory counterparts (ichneumon wasps and grass flies). To better understand the object detection model's actual field performance, it was validated in a practical manner by splitting our image data on the sticky plate level.
Results and conclusions
According to experimental findings, the average mAP score for all dataset classes was 0.76. For both pest species and their corresponding predators, high mAP values of 0.73 and 0.86 were obtained. Additionally, the model accurately forecasted the presence of pests when presented with unseen sticky plate images from the test set.
Significance
The findings of this research clarify the feasibility of AI-powered pest monitoring in the field for real-world applications and provide opportunities for implementing pest monitoring in witloof chicory fields with minimal human intervention.}
}
@article{DEMELOLIMA2024102543,
title = {A lightweight and enhanced model for detecting the Neotropical brown stink bug, Euschistus heros (Hemiptera: Pentatomidae) based on YOLOv8 for soybean fields},
journal = {Ecological Informatics},
volume = {80},
pages = {102543},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102543},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000852},
author = {Bruno Pinheiro {de Melo Lima} and Lurdineide {de Araújo Barbosa Borges} and Edson Hirose and Díbio Leandro Borges},
keywords = {Heteroptera, Insect pest detection, Improved YOLO model, Image-based detection and counting, Deep learning, Soybean field images},
abstract = {Insect pest detection and monitoring are vital in an agricultural crop to help prevent losses and be more precise and sustainable regarding the consequent actions to be taken. Deep learning (DL) approaches have attracted attention, showing triumphant performance in many image-based applications. In the adult stage, this research considers detecting a vital insect pest in soybean crops, the Neotropical brown stink bug (Euschistus heros), from field images acquired by drones and cellphones. We develop and test an improved YOLO-model convolutional neural network (CNN) with fewer parameters than other state-of-the-art models and demonstrate its superior generalization and average precision on public image datasets and the new field data provided here. Considering the proposal's precision and time of response, the possibility of deploying this technology for automatic monitoring and pest management in the near future is promising. We provide open code and data for all the experiments performed.}
}
@article{CLARK2023102065,
title = {The effect of soundscape composition on bird vocalization classification in a citizen science biodiversity monitoring project},
journal = {Ecological Informatics},
volume = {75},
pages = {102065},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102065},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000948},
author = {Matthew L. Clark and Leonardo Salas and Shrishail Baligar and Colin A. Quinn and Rose L. Snyder and David Leland and Wendy Schackwitz and Scott J. Goetz and Shawn Newsam},
keywords = {Convolutional neural networks, CNN, Ecoacoustics, Avian diversity, Bird species classification, Mixture of experts (MoE), Citizen science, Automated recording units, ARU, Soundscapes to landscapes, BirdNET, Soundscape components},
abstract = {There is a need for monitoring biodiversity at multiple spatial and temporal scales to aid conservation efforts. Autonomous recording units (ARUs) can provide cost-effective, long-term and systematic species monitoring data for sound-producing wildlife, including birds, amphibians, insects and mammals over large areas. Modern deep learning can efficiently automate the detection of species occurrences in these sound data with high accuracy. Further, citizen science can be leveraged to scale up the deployment of ARUs and collect reference vocalizations needed for training and validating deep learning models. In this study we develop a convolutional neural network (CNN) acoustic classification pipeline for detecting 54 bird species in Sonoma County, California USA, with sound and reference vocalization data collected by citizen scientists within the Soundscapes to Landscapes project (www.soundscapes2landscapes.org). We trained three ImageNet-based CNN architectures (MobileNetv2, ResNet50v2, ResNet100v2), which function as a Mixture of Experts (MoE), to evaluate the usefulness of several methods to enhance model accuracy. Specifically, we: 1) quantify accuracy with fully-labeled 1-min soundscapes for an assessment of real-world conditions; 2) assess the effect on precision and recall of additional pre-training with an external sound archive (xeno-canto) prior to fine-tuning with vocalization data from our study domain; and, 3) assess how detections and errors are influenced by the presence of coincident biotic and non-biotic sounds (i.e., soundscape components). In evaluating accuracy with soundscape data (n = 37 species) across CNN probability thresholds and models, we found acoustic pre-training followed by fine-tuning improved average precision by 10.3% relative to no pre-training, although there was a small average 0.8% reduction in recall. In selecting an optimal CNN architecture for each species based on maximum F(β = 0.5), we found our MoE approach had total precision of 84.5% and average species precision of 85.1%. Our data exhibit multiple issues arising from applying citizen science and acoustic monitoring at the county scale, including deployment of ARUs with relatively low fidelity and recordings with background noise and overlapping vocalizations. In particular, human noise was significantly associated with more incorrect species detections (false positives, decreased precision), while physical interference (e.g., recorder hit by a branch) and geophony (e.g., wind) was associated with the classifier missing detections (false negatives, decreased recall). Our process surmounted these obstacles, and our final predictions allowed us to demonstrate how deep learning applied to acoustic data from low-cost ARUs paired with citizen science can provide valuable bird diversity data for monitoring and conservation efforts.}
}
@article{CHEN2024102693,
title = {Weight-based ensemble method for crop pest identification},
journal = {Ecological Informatics},
volume = {82},
pages = {102693},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102693},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002358},
author = {Miao Chen and Jianji Wang and Yanan Chen and Minghui Guo and Nanning Zheng},
keywords = {Crop pest identification, Deep learning, Ensemble method, Convex optimization},
abstract = {Crop pests cause significant losses to agricultural production. Pests can be detected and controlled over time using accurate and effective methods, thereby reducing potential losses. However, there are challenges in realistic agricultural scenarios, such as diverse pest species and complicated environments, which render manual recognition and conventional machine learning methods insufficient. To address this issue, deep learning methods that can automatically extract features have recently been widely used for pest identification. However, accurately recognizing images that resemble complex real-world scenarios remains a challenging task for a single deep learning model. The ensemble method, which combines multiple basic models, provides a solution for improving recognition performance. In this study, we proposed two weight-based ensemble methods, VecEnsemble and MatEnsemble, constructed from vector- and matrix-based weights, respectively. The weights that combine basic models significantly influence the performance of the ensemble methods. Therefore, to effectively combine the basic models, we formulated the weight design problem as a quadratic convex optimization problem whose solution has a closed-form expression and can be computed efficiently. Our method achieved the highest accuracy of 77.39% on the large-scale complex-scene IP102 dataset, which was competitive with those of other state-of-the-art methods. Furthermore, we conducted comprehensive ablation experiments to compare our proposed methods with voting-based approaches and illustrate the scenarios in which they are applicable. These results highlight the practical significance of our method for agricultural production and provide a foundation for further research on crop pest identification. The source code is available at https://github.com/shiguangqianmo/WBEnsemble.}
}
@article{YANG2024102705,
title = {Adaptive image processing embedding to make the ecological tasks of deep learning more robust on camera traps images},
journal = {Ecological Informatics},
volume = {82},
pages = {102705},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102705},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002474},
author = {Zihe Yang and Ye Tian and Junguo Zhang},
keywords = {Adaptive image processing, Camera traps, Deep learning, Ecological tasks},
abstract = {Camera traps serve as a valuable tool for wildlife monitoring, generating a vast collection of images for ecologists to conduct ecological investigations, such as species identification and population estimation. However, the sheer volume of images poses a challenge, and the integration of deep learning into automated ecological investigation tasks remains complex, particularly when dealing with low-quality images in long-term monitoring programs. Existing approaches often struggle to strike a balance between image enhancement and deep learning for ecological tasks, thereby overlooking crucial information contained within low-quality images. This research introduces a pioneering adaptive image processing module (AIP) that seamlessly incorporates image processing into camera trap ecological tasks, elevating the performance of wildlife monitoring activities. Specifically, a differentiable image processing (DIP) module is presented to enhance low-quality images, with its parameters predicted by a Non-local based parameter predictor (NLPP). Additionally, an end-to-end approach based on hybrid data containing both original and synthetic data is proposed, encompassing adaptive image processing methods and downstream tasks for camera traps, adaptable to various scenarios. This approach effectively reduces the manual labor and time required for professional image processing. When applied to real-world camera trap images and synthetic image datasets, our method achieves an accuracy of 92.26% and 86.65% in classifying wildlife, respectively, demonstrating its robustness. By outperforming alternative methods under harsh conditions, the application of the adaptive image processing module instills greater confidence in deep learning applications within complex environments.}
}
@article{HERDY2024102417,
title = {Utilization of deep learning tools to map and monitor biological soil crusts},
journal = {Ecological Informatics},
volume = {79},
pages = {102417},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102417},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004466},
author = {Stefan Herdy and Emilio Rodríguez-Caballero and Thomas Pock and Bettina Weber},
keywords = {Semantic segmentation, Joint energy-based modelling, Deep learning, Biological soil crust, Domain adaption, Neural network, Long-term monitoring},
abstract = {Biological soil crusts (biocrusts) form a layer of only one to few centimeters depth on the soil surface and occur mostly in hot and cold deserts. Biocrusts have a major impact on different processes in these ecosystems, like carbon and nitrogen cycling, biodiversity preservation, erosion protection and soil dust emission reduction, but also react highly sensitive upon climate alterations and land use intensification. Therefore, monitoring tools are required to keep track of the changes of these specialized communities in an altering environment. In the current study, we applied a semantic image segmentation approach, using neural networks. One main problem to be solved was, that the training data and target data, on which the model is applied, are often recorded with different camera devices. This leads to different statistical properties of the image data, like different scale, resolution, brightness etc., which could significantly affect the model's performance. To solve this problem, we propose a new domain adaption method using a joint energy-based approach. To test a semantic segmentation approach in general, we utilized biocrust imagery taken in Utah (United States of America) and two sub datasets from the National Park Gesäuse (Austria). Here, we achieved highly reliable results with an overall classification accuracy of 85.9% for the USA data and 88.6% and 91.4%, respectively, for the two sub datasets of the National Park Gesäuse. To test our joint energy-based domain adaption approach, we used the two sub datasets from the National Park Gesäuse, which were recorded with different camera devices. With this newly established approach, we improved the accuracy of our segmentation on the unlabeled sub dataset from 70.4% to 75.3%. The results suggest that joint energy-based modelling is a well-suited domain adaption method for semantic segmentation that could be applied to face various deep learning and image-based biomonitoring challenges.}
}
@article{LEORNA2022101876,
title = {Human vs. machine: Detecting wildlife in camera trap images},
journal = {Ecological Informatics},
volume = {72},
pages = {101876},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101876},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003260},
author = {Scott Leorna and Todd Brinkman},
keywords = {Confusion matrix, Deep learning, Image analysis, Software, Trail camera},
abstract = {As the capacity to collect and store large amounts of data expands, identifying and evaluating strategies to efficiently convert raw data into meaningful information is increasingly necessary. Across disciplines, this data processing task has become a significant challenge, delaying progress and actionable insights. In ecology, the growing use of camera traps (i.e., remotely triggered cameras) to collect information on wildlife has led to an enormous volume of raw data (i.e., images) in need of review and annotation. To expedite camera trap image processing, many have turned to the field of artificial intelligence (AI) and use machine learning models to automate tasks such as detecting and classifying wildlife in images. To contribute understanding of the utility of AI tools for processing wildlife camera trap images, we evaluated the performance of a state-of-the-art computer vision model developed by Microsoft AI for Earth named MegaDetector using data from an ongoing camera trap study in Arctic Alaska, USA. Compared to image labels determined by manual human review, we found MegaDetector reliably determined the presence or absence of wildlife in images generated by motion detection camera settings (≥94.6% accuracy), however, performance was substantially poorer for images collected with time-lapse camera settings (≤61.6% accuracy). By examining time-lapse images where MegaDetector failed to detect wildlife, we gained practical insights into animal size and distance detection limits and discuss how those may impact the performance of MegaDetector in other systems. We anticipate our findings will stimulate critical thinking about the tradeoffs of using automated AI tools or manual human review to process camera trap images and help to inform effective implementation of study designs.}
}
@article{CHIAVERINI2023102026,
title = {Not seeing the forest for the trees: Generalised linear model out-performs random forest in species distribution modelling for Southeast Asian felids},
journal = {Ecological Informatics},
volume = {75},
pages = {102026},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102026},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000559},
author = {Luca Chiaverini and David W. Macdonald and Andrew J. Hearn and Żaneta Kaszta and Eric Ash and Helen M. Bothwell and Özgün Emre Can and Phan Channa and Gopalasamy Reuben Clements and Iding Achmad Haidir and Pyae Phyoe Kyaw and Jonathan H. Moore and Akchousanh Rasphone and Cedric Kai Wei Tan and Samuel A. Cushman},
keywords = {Bootstrapping, Generalised linear model, Machine learning, Multi-scale, Random forest, Species distribution modelling},
abstract = {Species Distribution Models (SDMs) are a powerful tool to derive habitat suitability predictions relating species occurrence data with habitat features. Two of the most frequently applied algorithms to model species-habitat relationships are Generalised Linear Models (GLM) and Random Forest (RF). The former is a parametric regression model providing functional models with direct interpretability. The latter is a machine learning non-parametric algorithm, more tolerant than other approaches in its assumptions, which has often been shown to outperform parametric algorithms. Other approaches have been developed to produce robust SDMs, like training data bootstrapping and spatial scale optimisation. Using felid presence-absence data from three study regions in Southeast Asia (mainland, Borneo and Sumatra), we tested the performances of SDMs by implementing four modelling frameworks: GLM and RF with bootstrapped and non-bootstrapped training data. With Mantel and ANOVA tests we explored how the four combinations of algorithms and bootstrapping influenced SDMs and their predictive performances. Additionally, we tested how scale-optimisation responded to species' size, taxonomic associations (species and genus), study area and algorithm. We found that choice of algorithm had strong effect in determining the differences between SDMs' spatial predictions, while bootstrapping had no effect. Additionally, algorithm followed by study area and species, were the main factors driving differences in the spatial scales identified. SDMs trained with GLM showed higher predictive performance, however, ANOVA tests revealed that algorithm had significant effect only in explaining the variance observed in sensitivity and specificity and, when interacting with bootstrapping, in Percent Correctly Classified (PCC). Bootstrapping significantly explained the variance in specificity, PCC and True Skills Statistics (TSS). Our results suggest that there are systematic differences in the scales identified and in the predictions produced by GLM vs. RF, but that neither approach was consistently better than the other. The divergent predictions and inconsistent predictive abilities suggest that analysts should not assume machine learning is inherently superior and should test multiple methods. Our results have strong implications for SDM development, revealing the inconsistencies introduced by the choice of algorithm on scale optimisation, with GLM selecting broader scales than RF.}
}
@article{GIMENEZ2024102554,
title = {Assessment of oceanographic services for the monitoring of highly anthropised coastal lagoons: The Mar Menor case study},
journal = {Ecological Informatics},
volume = {81},
pages = {102554},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102554},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000967},
author = {José G. Giménez and Alberto Granero and Javier Senent-Aparicio and Francisco Gómez-Jakobsen and Jesús M. Mercado and Pablo Blanco-Gómez and Juan M. Ruiz and José M. Cecilia},
keywords = {Coastal lagoons, Chlorophyll-a, Satellite remote sensing, Data coverage, Quantitative validation},
abstract = {Ocean monitoring systems are designed for continuous monitoring of the seas and oceans to track their evolution and thus anticipate environmental issues. However, they are often based on Internet of Things (IoT) systems that are expensive, hard to maintain, and offer little spatial coverage. An emerging alternative is Satellite Remote Sensing (SRS) systems that offer good geographical coverage but, as a reliable and real-time monitoring system, they also face several challenges such as environmental conditions, spatio-temporal granularity, terrain oleography, etc. This paper introduces an easy-to-use software tool to crawl water-quality data from up to 6 satellite instruments (i.e. Sentinel 3A, Sentinel-3B, NOAA VIIRS, SNPP VIIRS, Aqua MODIS, Terra MODIS) of the European Space Agency's (ESA) Coopernicus system and NASA's Marine Environmental Monitoring Service. We also provide an in-depth analysis in terms of reliability and data coverage for the chlorophyll-a (Chl-a) in a highly anthropised local/regional context like the Mar Menor lagoon (Murcia, Spain), where serious socio-environmental issues are arising due to the eutrophication process. Our results show a good linear correlation between in situ data, obtained by several Spanish public institutions since 2016, and data generated by the IRTM-NN (Inverse Radiative Transfer Model-Neural Network) algorithm of Sentinel 3 in general, reaching coefficient correlation values close to 0.9. They also show that organic matter inputs from ephemeral streams are relevant in determining Chl-a concentrations. Moreover, the temporal coverage using a single instrument is rather limited, as no data were recorded for 80% of the days studied. This figure decreases to 30% when data from the 6 satellite instruments are combined, increasing the temporal granularity of the measurements from approximately 5 to 1.5 days, suggesting the need for a combination of these systems for a robust SRS system.}
}
@article{GALAZGARCIA2024102559,
title = {Mapping invasive iceplant extent in southern coastal California using high-resolution aerial imagery},
journal = {Ecological Informatics},
volume = {81},
pages = {102559},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102559},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001018},
author = {Carmen {Galaz García} and Julien Brun and Benjamin S. Halpern},
keywords = {Invasive species, Iceplant, , Remote sensing, NAIP, Machine learning, Random forest, Microsoft Planetary Computer, Texture},
abstract = {Invasive species threaten natural ecosystems globally, displacing native species and causing biodiversity loss. In coastal areas with Mediterranean climate around the world, iceplant (Carpobrotus edulis) has become highly invasive, forming large monospecific zones that compete for resources with native plant species, including threatened or endangered species. Despite the widespread impact of iceplant across coastal areas with a Mediterranean climate, there is no precise information on where it is and how much it has spread. This study focuses on mapping and quantifying iceplant extent along the coast of Santa Barbara County in California, USA, by leveraging machine learning methods to identify iceplant in images from the 2020 National Agriculture Imagery Program (NAIP) archive at 0.6 m/pixel resolution, creating the most extensive assessment to date of this invasive species. Results include a map showing iceplant locations in 2020 with overall accuracy of 87.11% ± 2.45% (95% confidence interval). The estimated iceplant coverage in our region of study is 2.2 ± 0.42 km2 (95% confidence interval). Additionally, this study's use of open data and reproducible data analysis and validation workflow opens the door for the methods presented to be adapted and applied across California and all other Mediterranean climatic regions. In addition, the developed approach will accelerate monitoring over time to comprehend the spread and mitigation of iceplant invasions.}
}
@article{MATA2024102708,
title = {Drone imagery and deep learning for mapping the density of wild Pacific oysters to manage their expansion into protected areas},
journal = {Ecological Informatics},
volume = {82},
pages = {102708},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102708},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002504},
author = {Aser Mata and David Moffat and Sílvia Almeida and Marko Radeta and William Jay and Nigel Mortimer and Katie Awty-Carroll and Oliver R. Thomas and Vanda Brotas and Steve Groom},
keywords = {Pacific oysters, Invasive species, Convolutional neural networks, Deep learning, Drone, Remote sensing, Ecological management},
abstract = {The recent expansion of wild Pacific oysters already had negative repercussions on sites in Europe and has raised further concerns over their potential harmful impact on the balance of biomes within protected areas. Monitoring their colonisation, especially at early stages, has become an urgent ecological issue. Current efforts to monitor wild Pacific oysters rely on “walk-over” surveys that are highly laborious and often limited to specific areas of easy access. Remotely Piloted Aircraft Systems (RPAS), commonly known as drones, can provide an effective tool for surveying complex terrains and detect Pacific oysters. This study provides a novel workflow for automated detection, counting and mapping of individual Pacific oysters to estimate their density per square meter by using Convolutional Neural Networks (CNNs) applied to drone imagery. Drone photos were collected at low tides and altitudes of approximately 10 m across a variety of cases of rocky shore and mudflats scenarios. Using object detection, we compared how different Convolutional Neural Networks (CNNs) architectures including YOLOv5s, YOLOv5m, TPH-YOLOv5 and FR-CNN performed in the detection of Pacific oysters over the surveyed areas. We report the precision of our model at 88% with a difference in performance of 1% across the two sites. The workflow presented in this work proposes the use of grid maps to visualize the density of Pacific oysters per square meter towards ecological management and the creation of time series to identify trends.}
}
@article{GHARECHAEE2024102647,
title = {Introducing a novel approach for assessment of groundwater salinity hazard, vulnerability, and risk in a semiarid region},
journal = {Ecological Informatics},
volume = {81},
pages = {102647},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102647},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001894},
author = {Hamidreza Gharechaee and Aliakbar {Nazari Samani} and Shahram {Khalighi Sigaroodi} and Seyed Mohammad Moein Sadeghi and Sanam Sharifitabesh and Maryam Sadat Mousavi and Marina Viorela Marcu and Jason A. Hubbart},
keywords = {Ecohydrology, Groundwater, Iran, Salinity, Semiarid region, Water resources},
abstract = {The application of machine learning approaches to improve groundwater salinity risk mapping is limited despite all potential advantages. Therefore, there is an ongoing need for investigations that present new techniques, like machine learning, validated against conventional methods. These advances are particularly important for arid and semiarid regions, such as the Bakhtegan Basin (southern Iran), where groundwater use may far outweigh recharge, but groundwater management improvements are essential. To address these needs, groundwater salinity hazard, vulnerability, and risk maps were investigated using an integrated application of statistical (i.e., frequency ratio and statistical index models), machine learning (i.e., random forest and classification and regression trees algorithms), and decision-making models (fuzzy analytic hierarchy process (FAHP)). Results showed that the risk of groundwater salinity was high in the central areas of the region as well as at the margins of Bakhtegan Lake and irrigated farming lands. Based on the modeling results in the testing phase, it was found that the frequency ratio and random forest models exhibited better performance, with Nash–Sutcliffe efficiency metrics of 0.73 and 0.70, respectively, compared to the classification and regression trees and statistical index models, which had Nash–Sutcliffe efficiency metrics of 0.65 and 0.63, respectively. The innovative techniques developed in the current work accurately identified variables such as normalized difference salinity index, distance from mines, and land use associated with the highest weight values (0.59, 0.14, and 0.11, respectively) compared to other variables to identify groundwater salinity areas of vulnerability. The application of the fuzzy analytic hierarchy process method in developing vulnerability maps, integrating them with hazard maps, and developing groundwater salinity risk maps was innovative in this study. The innovative approach is transferrable for groundwater salinity susceptibility, vulnerability, and risk assessments globally in the study area and similar settings.}
}
@article{JANSIRANI2024102663,
title = {A novel automated approach for fish biomass estimation in turbid environments through deep learning, object detection, and regression},
journal = {Ecological Informatics},
volume = {81},
pages = {102663},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102663},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400205X},
author = {S.V. {Jansi Rani} and Iacovos Ioannou and R. Swetha and R.M. {Dhivya Lakshmi} and Vasos Vassiliou},
keywords = {Fish biomass, Object detection, Regression, YOLOv8, mYOLOv8},
abstract = {Estimating fish biomass is crucial in the fisheries sector, where traditional methods often harm fish through manual sampling and anesthetics. A non-invasive approach is introduced using underwater films to estimate fish biomass in turbid conditions. This study presents the “Aquatic WeightNet” dataset, targeting the Genetically Improved Formed Tilapia (GIFT) Tilapia species, and addresses the challenge of unclear images with preprocessing techniques like dehazing and Contrast Limited Adaptive Histogram Equalization (CLAHE). YOLOv8, a leading object detection model modified to accommodate the custom Aquatic WeightNet dataset's varied image sizes with five detection heads, P2 to P6, is employed, achieving a recall of 0.997 and a mean Average Precision (mAP) of 0.899 within the 50–95% Intersection over Union (IoU) range. Fish biomass estimation assesses depth, length, and width using regression models for calculation. A three-phase grid search identifies the most effective models, with the Extra Trees Regressor outperforming depth estimation with mean absolute error (MAE) of 0.63 and coefficient of determination (R2) of 0.87 and the Random Forest Regressor for length and width (MAE of 0.01 and R2 of 0.99). For biomass estimation, the Extra Trees Regressor again performs well (MAE of 0.004 and R2 of 0.99), which is critical for determining optimal feed quantities to enhance aquaculture efficiency. This study emphasizes a non-invasive method to estimate fish biomass, optimizing the effectiveness and ecological sustainability of fish farming in murky waters through advanced detection algorithms and robust regression models.}
}
@article{HUETTMANN2023102364,
title = {Model-based prediction of a vacant summer niche in a subarctic urbanscape: A multi-year open access data analysis of a ‘niche swap’ by short-billed Gulls},
journal = {Ecological Informatics},
volume = {78},
pages = {102364},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102364},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300393X},
author = {Falk Huettmann and László Kövér and Richard Robold and Mark Spangler and Moriz Steiner},
keywords = {Short-billed (common/mew) Gull , Geographic information system (GIS), Open access data, Big data, Socio-economics, Multi-year field work, Machine learning ensemble predictions (RandomForest Treenet CART MARS)},
abstract = {Gulls belong to the seabird group, and are widely considered to be useful ecological indicators. Increasing urbanization throughout the Anthropocene has led to the rise of the urban landscape (‘urbanscape’) as a globally dominant habitat. Though historically less developed, similar urbanization patterns are emerging in the boreal forest, the world's largest forest ecoregion. Here we evaluate the ecological position of migratory Short-billed Gulls (Larus canus) in a subarctic urbanscape. We attempt to investigate a summer niche swap theory, in which gulls annually fill a vacant niche otherwise occupied by common ravens in winter. For that investigation we conducted seasonal plot surveys for Short-billed Gull presence from 2013 to 2016 in the Fairbanks, AK municipality. All data were made publicly available. We compiled them in a open source and ESRI geographic information system (GIS) platform and then added 68 open-access predictor layers, including socio-economic U.S. Census data. We trained, tested, and evaluated the performance of an ensemble of machine learning models, resulting in predictions of gull-abundance hotspots and coldspots, at 100-m resolution for inference. We find that Short-billed Gulls prefer the synergy of industrial areas near man-made water bodies, impervious surfaces, gravel pits, strip malls, transfer sites (garbage dumps) and some young forest vegetation. This study is a first-known attempt to utilize a blended ‘Big Data’ approach, in combination with traditional multi-year field-based data collection and alternative model assessments, in order to characterize an urban seabird niche. Our findings, and the digital infrastructure herein, provide an interdisciplinary baseline for potential applications in urban planning and monitoring the spread of disease reservoirs.}
}
@article{NGUYEN2024102744,
title = {Improving pollen-bearing honey bee detection from videos captured at hive entrance by combining deep learning and handling imbalance techniques},
journal = {Ecological Informatics},
pages = {102744},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102744},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002863},
author = {Dinh-Tu Nguyen and Thi-Nhung Le and Thi-Huong Phung and Duc-Manh Nguyen and Hong-Quan Nguyen and Hong-Thai Pham and Thi-Thu-Hong Phan and  Vu-Hai and Thi-Lan Le},
keywords = {Pollen foraging behavior, Pollen-bearing honey bee detection},
abstract = {The number of pollen-bearing honey bees serves as a vital indicator for assessing colony balance and health. Despite its significance, prevailing detection techniques still rely heavily on manual observation and annotation, leading to time-consuming processes that cannot sustain long-term, continuous monitoring efforts. To facilitate automatic beehive monitoring, this study introduces an efficient method for pollen-bearing bee detection. Initially, we furnish a comprehensive dataset, dubbed VnPollenBee, meticulously annotated for pollen-bearing honey bee detection and classification. The dataset comprises 60,826 annotated boxes that delineate both pollen-bearing and non-pollen-bearing bees in 2051 images captured at the entrances of beehives under various environmental conditions. To the best of our knowledge, this represents the first dedicated dataset for pollen-bearing bee detection. The VnPollenBee dataset is publicly accessible to the research community at https://comvis-hust.github.io/datasets/pollenbee.html. Subsequently, we propose the incorporation of diverse techniques into two baseline models, namely YOLOv5 and Faster RCNN, to effectively address the imbalance that arises during the detection of pollen-bearing bees due to their number being typically much lower than the total number of bees present at hive entrances. The experimental results demonstrate that our proposed method outperforms the baseline models on the VnPollenBee dataset, yielding Precision, Recall, and F1 score of 99%, 93%, and 95%, respectively. Specifically, the improvements obtained are 3% and 2% in Recall and F1 score when using YOLOv5, and 3%, 2%, and 2% in Precision, Recall, and F1 score when using Faster RCNN. These findings confirm the potential of our approach to facilitate bee foraging behavior analysis and automated bee monitoring.}
}
@article{KLADNY2024102474,
title = {Enhanced prediction of vegetation responses to extreme drought using deep learning and Earth observation data},
journal = {Ecological Informatics},
volume = {80},
pages = {102474},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102474},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000165},
author = {Klaus-Rudolf Kladny and Marco Milanta and Oto Mraz and Koen Hufkens and Benjamin D. Stocker},
keywords = {Drought impact forecasting, Sentinel-2, EarthNet2021, ConvLSTM, NDVI},
abstract = {The advent of abundant Earth observation data enables the development of novel predictive methods for forecasting climate impacts on the state and health of terrestrial ecosystems. Here, we predict the spatial and temporal variations of land surface reflectance and vegetation greenness, measuring the density of green vegetation and active foliage area, conditioned on current and past weather and the local topography. We train two alternative recurrent deep learning models that combine Long Short-Term Memory cells with convolutional layers (ConvLSTM) for forecasting the spatially resolved deviation of surface reflectance across a heterogeneous landscape from a specified initial state. Using data from diverse ecosystems and land cover types across Europe and following a standardized model evaluation framework (EarthNet2021 Challenge), our results indicate increased performance in predicting surface greenness during extreme drought events of the models presented here, compared to currently published benchmarks. This demonstrates how deep learning methods for optical Earth observation time series enable an early-warning of vegetation responses to the impacts of climatic extreme events, such as the drought-related loss of green foliage.}
}
@article{DING2024102664,
title = {Algal blooms forecasting with hybrid deep learning models from satellite data in the Zhoushan fishery},
journal = {Ecological Informatics},
volume = {82},
pages = {102664},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102664},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002061},
author = {Wenxiang Ding and Changlin Li},
keywords = {Hybrid deep learning model, Algal bloom, Chlorophyll, Forecast, Zhoushan fishery},
abstract = {Algal blooms are increasingly frequent in coastal areas, posing a significant threat to coastal ecosystems. The Zhoushan fishery, one of the most affected regions along the Chinese coast, faces severe challenges from algal blooms. In this study, Convolutional Neural Network (CNN), Long Short-term Memory (LSTM) and hybrid CNN-LSTM deep learning models were constructed to forecast chlorophyll (Chl) concentrations and algal blooms from satellite data. The hybrid CNN-LSTM model outperformed the individual models, achieving the highest determination coefficient and the lowest root mean square error for Chl concentration forecasts. It also excelled in predicting algal blooms, with the highest probability of detection and Heidke skill score, effectively capturing the trends in algal bloom development. In areas with high Chl concentration, the Chl parameter significantly influences model forecasts, while meridional wind and current are the main influence factors in the regions with medium and low Chl concentration. The powerful algal bloom forecast provided by the hybrid CNN-LSTM model offers valuable support for the efficient management and sustainable development of the Zhoushan fishery.}
}
@article{DWIVEDI2024102451,
title = {EMViT-Net: A novel transformer-based network utilizing CNN and multilayer perceptron for the classification of environmental microorganisms using microscopic images},
journal = {Ecological Informatics},
volume = {79},
pages = {102451},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102451},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004806},
author = {Karnika Dwivedi and Malay Kishore Dutta and Jay Prakash Pandey},
keywords = {Environmental microorganisms classification, Microscopic images, Computer-aided system, Deep learning, Vision transformer},
abstract = {Environmental microbes are certainly present in our surroundings since they are essential to the growth and survival of human advancement. The detailed analysis of environmental microorganisms (EMs) is very important to recognize, understand and make use of microbes as well and prevent damage. Extracting the discriminatory features from a limited-size dataset is very challenging for a deep learning model and a pure transformer-based network cannot achieve good classification results on a limited-size dataset due to the lack of muti-scale features. In this study, a novel vision transformer-based deep neural network is proposed by integrating the transformer with CNN for the classification of EM using microscopic images. The proposed network EMViT-Net has three main modules: a transformer module, a CNN module and a multilayer perceptron module. The transformer model extracted multiscale features to generate more discriminatory information from the images. A new separable convolutional parameter-sharing attention (SCPSA) block is integrated with the CNN module in the core of EMViT-Net, which makes the model robust to capture the local and global features, and simultaneously reduces the computational complexity of the model. The data augmentation is performed to introduce the variability in the dataset and counter the problem of overfitting and data imbalance. After extensive experiments and detailed analysis, it has been determined that the proposed model EMViT-Net outperforms the other existing methods and achieves state-of-the-art results with an accuracy of 71.17% which proves the effectiveness of the model for the classification of environmental microbes.}
}
@article{CLARFELD2023102257,
title = {Evaluating a tandem human-machine approach to labelling of wildlife in remote camera monitoring},
journal = {Ecological Informatics},
volume = {77},
pages = {102257},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102257},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002868},
author = {Laurence A. Clarfeld and Alexej P.K. Sirén and Brendan M. Mulhall and Tammy L. Wilson and Elena Bernier and John Farrell and Gus Lunde and Nicole Hardy and Katherina D. Gieder and Robert Abrams and Sue Staats and Scott McLellan and Therese M. Donovan},
keywords = {Artificial intelligence, Camera trap, Data labeling, Machine learning, Trail camera, Wildlife monitoring, Bounding box},
abstract = {Remote cameras (“trail cameras”) are a popular tool for non-invasive, continuous wildlife monitoring, and as they become more prevalent in wildlife research, machine learning (ML) is increasingly used to automate or accelerate the labor-intensive process of labelling (i.e., tagging) photos. Human-machine hybrid tagging approaches have been shown to greatly increase tagging efficiency (i.e., time to tag a single image). However, those potential increases hinge on the extent to which an ML model makes correct vs. incorrect predictions. We performed an experiment using a ML model that produces bounding boxes around animals, people, and vehicles in remote camera imagery (MegaDetector) to consider the impact of a ML model's performance on its ability to accelerate human labeling. Six participants tagged trail camera images collected from 12 sites in Vermont and Maine, USA (January–September 2022) using three tagging methods (one with ML bounding box assistance and two without assistance). We used a generalized linear mixed model to examine the influence of ML model performance and tagging method on tagging efficiency. We found that ML bounding boxes offer significant improvement in tagging efficiency when labelling data compared to unassisted tagging. Additionally, the time taken to label with bounding boxes was not statistically different from an unassisted tagging approach. However, we found that gains in efficiency are contingent on the ML algorithm's performance and that incorrect ML predictions, particularly the 4.2% false positive and 3.6% false negative predictions, can slow the tagging process compared to a non-hybrid approach. These findings indicate that although practitioners usually forgo the production of bounding boxes when selecting a data labelling process due to the increased effort, ML bounding box-assisted tagging can offer an efficient method for labeling. More broadly, ML-assisted data labelling offers an opportunity to accelerate the analysis of trail camera imagery, but an assessment of the ML model's performance can illuminate whether the hybrid-tagging approach is ultimately a help or hinderance.}
}
@article{MISIUK2023102181,
title = {Improved environmental mapping and validation using bagging models with spatially clustered data},
journal = {Ecological Informatics},
volume = {77},
pages = {102181},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102181},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002108},
author = {Benjamin Misiuk and Craig J. Brown},
keywords = {Spatial autocorrelation, Ecological modelling, Random Forest, Bagging, Cross-validation, Species distribution modelling},
abstract = {Spatially clustered sampling may result in non-independent data that pose challenges for environmental mapping applications. Two outstanding challenges resulting from the use of spatially clustered data for predictive geospatial modelling with machine learning approaches are biased model training and validation. These issues can be severe for popular bagging models such as Random Forest, yet one or both are often ignored or are handled using sub-optimal approaches. We propose to address these challenges using information on both the spatial autocorrelation of map errors and the spatial sampling intensity. This is achieved by applying the residual spatial covariance as a weighting function for the bagging procedure and for the calculation of weighted validation statistics. Using this approach, the full feature space of the sample data is retained during model training and validation. The utility of covariance weighting for these purposes is investigated through extensive simulation with a range of sample clustering configurations. Results are benchmarked against existing approaches. Covariance weighting improved model performance across a range of clustering scenarios but appeared to produce the greatest improvements for highly clustered data. Covariance-weighted validation demonstrated low bias across a broad range of clustering scenarios compared to existing spatial methods. Findings also suggest, though, that conditional Gaussian simulation approaches may perform well when the proportion of clustered data is very high. Covariance weighting is straightforward to implement, computationally efficient, and scales to different sample sizes and spatial extents.}
}
@article{FENG2024102501,
title = {An ensembled method for predicting dissolved oxygen level in aquaculture environment},
journal = {Ecological Informatics},
volume = {80},
pages = {102501},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102501},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000438},
author = {Dachun Feng and Qianyu Han and Longqin Xu and Ferdous Sohel and Shahbaz Gul Hassan and Shuangyin Liu},
keywords = {Aquaculture monitoring, Dissolved oxygen level estimation, Water quality assessment},
abstract = {Dissolved oxygen (DO) level is an important indicator aquaculture quality. This study proposes an ensembled method, WTD-GWO-SVR, combining wavelet threshold denoising (WTD), grey wolf optimization (GWO), and support vector regression (SVR) for accurately predicting DO levels. Addressing challenges such as high noise, poor data quality, and non-linearity and non-stationary properties of time series data, our method integrates SVR for regression-based estimation, WTD for data denoising, and GWO for optimizing the SVR parameters and the Gaussian kernel's radial basis function. We collected a dataset using a variety of low-cost sensors in a real aquaculture setting. Our comprehensive evaluation on the dataset demonstrates that WTD-GWO-SVR achieved mean squared error, mean absolute error, and R2 values of 0.38%, 3.81%, and 99.73%, respectively. It also consistently outperformed the back-propagation neural network and the long short-term memory model. It also achieved superior computational time performance compared to these methods. The high throughput and accuracy of WTD-GWO-SVR make it a potential choice for DO level prediction in water quality monitoring systems.}
}
@article{JIANG2024102650,
title = {Monitoring public perceptions of contaminated sites based on social media},
journal = {Ecological Informatics},
volume = {81},
pages = {102650},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102650},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001924},
author = {Yefeng Jiang and Yingcong Ye and Congkang Sun and Xi Guo and Zhou Shi},
keywords = {Spatiotemporal distribution, Contaminated site, Public perception, Social media, Risk management},
abstract = {Contaminated sites have a negative impact on human health and the ecological environment, which can potentially lead to major pollution incidents, and frequently receive complaints and reports from the public. Therefore, monitoring public perceptions of contaminated sites is crucial for risk management. However, methods based on traditional questionnaire surveys are limited in terms of time, cost, and target audience size. The purpose of this study was to establish a method using social media to monitor public perceptions of contaminated sites in the Yangtze River Delta urban agglomeration. Thus, 6802 public opinions were collected from social media (mainly microblogs in China) and topic modeling and pollution and spatial mining techniques were employed. The topic modeling results indicated that public perceptions of contaminated sites mainly focused on the construction of prevention and control systems, law enforcement work, developments and challenges applicable to the coal industry, environmental public interest litigation (pertaining to pollution), pollution inspection and rectification, and green development and ecological governance, with intensities of 7.9%, 7.8%, 7.1%, 6.1%, 5.9%, and 4.8%, respectively. Three communities resulting from public opinions in the study area included “environment and pollution,” “enterprises,” and “environmental protection,” with proportions of 37.68%, 34.78%, and 27.54%, respectively. The field investigation results indicated that approximately 90% of the tweets in three typical cities (i.e., Taizhou City in Zhejiang Province and Wuxi and Changzhou Cities in Jiangsu Province) involved key industrial enterprises or contaminated sites located within 1 km of the surrounding areas. The emotional analysis indicated that >3401 tweets dealt with a pollution probability (i.e., the possibility of potentially contaminated sites mentioned in social media becoming contaminated sites) exceeding 0.90 for the period 2011–2021. This finding suggests that the pollution probability for the sites involved in these tweets was high. Our study provides methodological references for monitoring public perceptions of contaminated sites for large-scale, long-term, and high-resolution studies.}
}
@article{LYASHEVSKA2020101154,
title = {Long-term trends in herring growth primarily linked to temperature by gradient boosting regression trees},
journal = {Ecological Informatics},
volume = {60},
pages = {101154},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101154},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120301047},
author = {Olga Lyashevska and Clementine Harma and Cóilín Minto and Maurice Clarke and Deirdre Brophy},
keywords = {Herring, , Growth, Time-series, Supervised machine learning, Gradient boosting regression trees, Multiple drivers, Interactions},
abstract = {Environmental change and fishing activity can produce directional trends in exploited fish populations with consequences for stock productivity. For herring in the Celtic Sea, size at age has been in steady decline since the mid 1980's. In the neighbouring herring stock off the Northwest coast of Ireland, reductions in size at age are noted after 1990. Here, gradient boosting regression trees were used to investigate trends in extended time series (1959–2012) of length-at-age across both populations and to identify important variables associated with the observed declines in size. The predominant signal detected was a non-linear negative relationship between adult size and mean Sea Surface Temperature during the first growing season. Herring length was negatively correlated with the Atlantic Multidecadal Oscillation. Weaker associations with indicators of food availability and population size were also detected. Across both populations a marked decline in length was observed at the upper end of the temperature range (~14∘C in the Celtic Sea and ~13∘C in the Northwest). Declines in length and associations with temperature were more pronounced in the Celtic Sea population which may be vulnerable to increasing sea temperatures due to its position at the southern limit of the species distribution.}
}
@article{GACHOKI2024102610,
title = {Towards accurate spatial prediction of Glossina pallidipes relative densities at country-scale in Kenya},
journal = {Ecological Informatics},
volume = {81},
pages = {102610},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102610},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001523},
author = {Stella Gachoki and Thomas A. Groen and Anton Vrieling and Andrew Skidmore and Daniel Masiga},
keywords = {Tsetse abundance, Machine learning, Vector borne diseases, Spatial extrapolations, Satellite data, Random forest},
abstract = {Vector-borne diseases, like those transmitted by tsetse flies, pose a significant global public health threat. Reducing vector populations is a promising strategy for disease control, especially in the case of tsetse-transmitted African trypanosomiasis. However, the cost-effective implementation of large-scale vector surveillance and control measures face challenges due to the lack of spatially explicit and reliable maps identifying vector hotspots. In this study, we assessed the accuracy of predicting Glossina pallidipes relative densities across Kenya by linking constrained in-situ tsetse catch data from 660 traps across three Kenyan regions with readily available gridded satellite information (human population, land cover, soil properties, elevation, precipitation, and land surface temperature) using a classical random forest algorithm. To enhance predictive performance, we employed two feature elimination techniques specifically designed for machine learning algorithms, i.e., Recursive Feature Elimination (RFE) and Variable Selection Using Random Forests (VSURF). For each set of retained variables, we trained a Random Forest model using a spatial cross-validation technique. Our findings showed that tsetse fly relative densities decreased with mean annual precipitation, and soil moisture, and conversely increased with higher tree cover. Based on the cross-validated R2, 41% of the spatial variability in relative densities of tsetse flies could be explained. For spatial extrapolation, only the set of predictors retained by VSURF closely matched known tsetse fly distributions in Kenya. This more accurate performance of VSURF may be attributed to its approach of assessing variables for both importance and their contribution to reducing prediction error. Our study demonstrates the potential of using a random forest method to upscale tsetse relative abundance predictions to the national level. However, the reliability of the current extrapolated map remains uncertain. We recommend: 1) increasing tsetse fly sampling efforts, particularly in the data-limited northern and eastern regions of Kenya, and 2) developing a more precise and accurate land cover map with classes that directly associate with known habitat characteristics of the target tsetse species.}
}
@article{HAN2024102489,
title = {Multi-sensor high spatial resolution leaf area index estimation by combining surface reflectance with vegetation indices for highly heterogeneous regions: A case study of the Chishui River Basin in southwest China},
journal = {Ecological Informatics},
volume = {80},
pages = {102489},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102489},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000311},
author = {Duo Han and Hong Cai and Lei Zhang and Yiting Wen},
keywords = {Leaf area index, Moderate-resolution imaging spectroradiometer (MODIS), Chishui River Basin, Vegetation index, Random Forest (RF)},
abstract = {The leaf area index (LAI) is an indispensable parameter in vegetation canopy research. In highly heterogeneous regions, a low spatial resolution LAI often fails to reveal dynamic changes in vegetation accurately. Most studies estimating high-resolution LAI from global products have focused on flat regions and have only established the relationship between training samples and band reflectance. The estimation result is easily affected by differences in the sensor bandwidth and has low universality among different sensors. This study selected high-quality LAI samples from moderate resolution imaging spectroradiometer (MODIS) products, combined band reflectance and vegetation indices (VIs), and used Random Forest to estimate the 30-m resolution LAI in the upper reaches of the Chishui River Basin in China. After adding VIs, the consistency between the LAI estimation results and the synchronous LAI estimated by the Sentinel-2 Land bio-physical processor (SL2P) improved compared with using only band reflectance. The coefficient of determination (R2) values of Landsat-8 and GF-1 increased by 0.04 and 0.18, and the root mean square deviation (RMSE) values decreased by 0.07 and 0.13; the Sentinel-2A R2 values increased by 0.09 and 0.24 in two phases, while the RMSE values decreased by 0.07 and 0.22. After terrain correction, the R2 value between the Landsat-8 estimation and SL2P LAI increased by 0.06, whereas the RMSE value decreased by 0.07. The results provide high-resolution LAI data and estimation methods for vegetation research in highly heterogeneous regions and improve the versatility of using MODIS products to estimate high-resolution LAI using different sensors.}
}
@article{SIVRIKAYA2024102461,
title = {Forest fire risk mapping with Landsat 8 OLI images: Evaluation of the potential use of vegetation indices},
journal = {Ecological Informatics},
volume = {79},
pages = {102461},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102461},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000037},
author = {Fatih Sivrikaya and Alkan Günlü and Ömer Küçük and Okan Ürker},
keywords = {Remote sensing, Normalized band indices, Fire risk map, NBR},
abstract = {Fire is one of the most important natural catastrophes threatening the forest ecosystem. The severity and frequency of forest fires are increasing daily due to the increase in population in vulnerable areas and the effects of global climate change. Creating fire risk maps and using them to take the required protective actions to prevent fires will decrease the adverse effects of forest fires. This study focused on producing and comparing fire risk maps based on four vegetation indices, the Normalized Burn Ratio (NBR) index, Normalized Burn Ratio Thermal (NBRT) index, Normalized Difference Vegetation Index (NDVI), and Normalized Difference Water Index (NDWI) and data gathered with the use of remote sensing devices. The Muğla Regional Directorate of Forestry, which is in the Mediterranean climate zone and has experienced mega-fires, was selected as the case study area. Fire risk maps were prepared for the four vegetation indices from Landsat 8 OLI satellite images. Receiver operating characteristic curves and 195 fire ignition points that occurred in 2021 from July 5 to the end of the year were used to assess the accuracy of fire risk maps. Most fire ignition locations (>90%) were in high- and extremely high-risk fire areas on the maps prepared according to the NBR, NDWI, and NDVI. The fact that almost all of the fires occurred in high-risk areas revealed that the study area was sensitive to fire and that the vegetation indices used to draw up the risk maps were highly accurate in predicting where fires might occur. The accuracy results showed that the area under the curve was 0.842 for the NBR, 0.835 for the NDWI, 0.812 for the NBRT, and 0.810 for the NDVI. The NBR approach was more precise than the other models in providing information for fire risk maps. Risk maps created with the NBR could help decision-makers to take precautions and minimize fire damage.}
}
@article{GUAN2024102703,
title = {Spectral characteristics of dissolved organic matter in Plateau Lakes: Identifying eutrophication indicators in Southwest China},
journal = {Ecological Informatics},
volume = {82},
pages = {102703},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102703},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002450},
author = {Yuying Guan and Gongliang Yu and Nannan Jia and Ruiming Han and Da Huo},
keywords = {Dissolved organic matter, Trophic state index, Excitation-emission matrix, LASSO},
abstract = {Dissolved organic matter (DOM) acts as a chemical intermediary between terrestrial and lacustrine ecosystems and significantly affects the structure and function of lakes. The trophic state of lakes, driven by terrestrial input and phytoplankton biomass, alters the optical properties of DOM. From November 2018 to July 2019, we collected 119 water samples from the Erhai watershed and analyzed them using UV–Vis and EEM-PARAFAC to study the optical properties of DOM in relation to the trophic conditions. Our result indicated that the tyrosine-like protein (C1), tryptophan-like protein (C2), and humic-like compounds (C3) were among the mostly autochthonous components of the DOM. The percentage of the C3 was higher in eutrophic lakes than in mesotrophic and light-eutrophic lakes. The ultraviolet absorption coefficients at 254 nm (aCDOM(254)) and fluorescence intensity at 355 nm (Fn(355)) increased significantly (p < 0.01) with an increased trophic state. Our findings indicate that the influence of nutrients and environmental factors (such as pH and water temperature) on DOM varies with the trophic state. The development of novel predictive models for trophic state assessment was largely based on the significant correlations between TSI and aCDOM(254) (R2 = 0.762, p < 0.01) and Fn(355) (R2 = 0.705, p < 0.01). This neural network model facilitates the creation of a novel fast assessment tool by highlighting the connection between DOM features and the trophic state index. By enabling swift experimental measurements, this model offers a high-resolution monitoring solution for tracking the eutrophication of plateau lakes and rivers.}
}
@article{LYU2024102383,
title = {Deer survey from drone thermal imagery using enhanced faster R-CNN based on ResNets and FPN},
journal = {Ecological Informatics},
volume = {79},
pages = {102383},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102383},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004120},
author = {Haitao Lyu and Fang Qiu and Li An and Douglas Stow and Rebecca Lewison and Eve Bohnett},
keywords = {UAV, Faster R-CNN, ResNet, FPN, Thermal image, Small object detection},
abstract = {Deer surveys play an important role in the estimation of local ecological balance. In the Chitwan National Park of Nepal, the dense tree canopies and tall vegetation often obscure the presence of wild deer, which has a negative effect on the accurate population surveys of wild deer. UAVs equipped with infrared sensors have been increasingly used to monitor wild deer by capturing a lot of images. How to automatically recognize and obtain the number of deer objects from thermal images is becoming an important research topic. Due to the difference between thermal images and true-color images, as well as the variations in deer object sizes in these two types of images, current ready-to-use object detection models, designed for true-color imagery, are ill-suited for the task of detecting small deer objects within thermal imagery. In this paper, an enhanced Faster R-CNN was constructed to detect small deer objects from thermal images, in which a Feature Pyramid Network (FPN) based on a residual network is used to improve feature extraction for small deer objects and multi-scale feature map constrution for the subsequent region proposals searching, bounding box regression, and regions of interest (RoIs) classification. In addition, small-scaled anchor boxes and a multi-scale feature map selection criterion are devised to improve the detection accuracy of small objects. Finally, based on Faster R-CNN, FPN, and different residual networks including ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152, we constructed five object detection models, and evaluated their detection performance by using COCO evaluation matrix. Under the condition of IoU≥0.5, the integration of Faster R-CNN, FPN, and ResNet18 demonstrated to perform better than others. Specifically, The COCO evaluation results revealed an Average Precision (AP) score of 91.6% for all deer objects. Small deer objects (area ≤ 200 pixels) achieved an AP score of 73.6%, medium deer objects (200 < area ≤ 400 pixels) demonstrated an AP score of 93.4%, and large deer objects (area > 400 pixels) achieved the highest AP score of 94.3%. Our research is helpful for effective wild deer monitoring and conservation and can be a valuable reference for the exploration of small object detection from low-resolution thermal images.}
}
@article{KIM2024102407,
title = {Predicting invasive species distributions using incremental ensemble-based pseudo-labeling},
journal = {Ecological Informatics},
volume = {79},
pages = {102407},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102407},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004363},
author = {Eunbeen Kim and Jaeuk Moon and Jonghwa Shim and Eenjun Hwang},
keywords = {Species distribution model, Semi-supervised learning, Pseudo-labeling, Ensemble model},
abstract = {Control strategies for preventing the spread of invasive species require their accurate geographical distribution. Species distribution models (SDMs) that can predict potential habitats of invasive species and thereby derive habitat suitability maps have become a valuable tool for supporting regulatory strategies. To date, machine learning (ML)-based approaches have outperformed profile and statistical-based approaches in terms of species distribution prediction accuracy. However, ML-based approaches often suffer from poor predictive performance when there is insufficient labeled data. Recently, pseudo-labeling (PL), a semi-supervised learning method, has been proposed to alleviate this problem, but pseudo-labels generated using a single-teacher model with very few labeled data points are generally biased and not suitable for training SDMs. In this paper, we propose a novel prediction scheme for invasive species distributions using incremental ensemble-based PL (SDP-EPL). We first build an ensemble-based teacher using multiple conventional SDMs and then incrementally construct a training set, starting with very few labeled data points, by repeating the following process: (i) generating pseudo-labels for unlabeled data using the teacher model, (ii) appending the pseudo-labeled data representing high or low habitat suitability to the training set, and (iii) training the teacher model using the updated training set. We then train a student SDM using the training set. Based on extensive experiments using citizen science datasets for three species, we show that the proposed scheme outperforms other commonly used SDMs in terms of diverse evaluation metrics and achieves performance improvements of up to 14.61% and 5.45% compared to the baseline and state-of-the-art models, respectively. We also demonstrate the effectiveness of the ensemble teacher model and incremental labeling in terms of predictive accuracy.}
}
@article{BEIGAITE2022101849,
title = {Multi-output regression with structurally incomplete target labels: A case study of modelling global vegetation cover},
journal = {Ecological Informatics},
volume = {72},
pages = {101849},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101849},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002990},
author = {Rita Beigaitė and Jesse Read and Indrė Žliobaitė},
keywords = {Multi-output regression, Compositional data, Incomplete targets, Weakly supervised learning, Vegetation cover modelling},
abstract = {Weakly-supervised learning has recently emerged in the classification context where true labels are often scarce or unreliable. However, this learning setting has not yet been extensively analyzed for regression problems, which are typical in macroecology. We further define a novel computational setting of structurally noisy and incomplete target labels, which arises, for example, when the multi-output regression task defines a distribution such that outputs must sum up to unity. We propose an algorithmic approach to reduce noise in the target labels and improve predictions. We evaluate this setting with a case study in global vegetation modelling, which involves building a model to predict the distribution of vegetation cover from climatic conditions based on global remote sensing data. We compare the performance of the proposed approach to several incomplete target baselines. The results indicate that the error in the targets can be reduced by our proposed partial-imputation algorithm. We conclude that handling structural incompleteness in the target labels instead of using only complete observations for training helps to better capture global associations between vegetation and climate.}
}
@article{DEBRUIN2022101665,
title = {Dealing with clustered samples for assessing map accuracy by cross-validation},
journal = {Ecological Informatics},
volume = {69},
pages = {101665},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101665},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122001145},
author = {Sytze {de Bruin} and Dick J. Brus and Gerard B.M. Heuvelink and Tom {van Ebbenhorst Tengbergen} and Alexandre M.J-C. Wadoux},
keywords = {Machine learning, Spatial cross-validation, Spatial autocorrelation, Soil organic carbon, Above-ground biomass},
abstract = {Mapping of environmental variables often relies on map accuracy assessment through cross-validation with the data used for calibrating the underlying mapping model. When the data points are spatially clustered, conventional cross-validation leads to optimistically biased estimates of map accuracy. Several papers have promoted spatial cross-validation as a means to tackle this over-optimism. Many of these papers blame spatial autocorrelation as the cause of the bias and propagate the widespread misconception that spatial proximity of calibration points to validation points invalidates classical statistical validation of maps. We present and evaluate alternative cross-validation approaches for assessing map accuracy from clustered sample data. The first method uses inverse sampling-intensity weighting to correct for selection bias. Sampling-intensity is estimated by a two-dimensional kernel approach. The two other approaches are model-based methods rooted in geostatistics, where the first assumes homogeneity of residual variance over the study area whilst the second accounts for heteroscedasticity as a function of the sampling intensity. The methods were tested and compared against conventional k-fold cross-validation and blocked spatial cross-validation to estimate map accuracy metrics of above-ground biomass and soil organic carbon stock maps covering western Europe. Results acquired over 100 realizations of five sampling designs ranging from non-clustered to strongly clustered confirmed that inverse sampling-intensity weighting and the heteroscedastic model-based method had smaller bias than conventional and spatial cross-validation for all but the most strongly clustered design. For the strongly clustered design where large portions of the maps were predicted by extrapolation, blocked spatial cross-validation was closest to the reference map accuracy metrics, but still biased. For such cases, extrapolation is best avoided by additional sampling or limitation of the prediction area. Weighted cross-validation is recommended for moderately clustered samples, while conventional random cross-validation suits fairly regularly spread samples.}
}
@article{GRIJALVA2024102540,
title = {Detecting and counting sorghum aphid alates using smart computer vision models},
journal = {Ecological Informatics},
volume = {80},
pages = {102540},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102540},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000827},
author = {Ivan Grijalva and H. Braden Adams and Nicholas Clark and Brian McCornack},
keywords = {sorghum, sorghum aphid, alates, automation, detection},
abstract = {Sorghum aphid [Melanaphis sorghi (Theobald)] is considered an economic pest causing significant yield losses in susceptible sorghum in the southern U.S. Infestations start with the migration of alates (i.e., winged adults) to sorghum and establishing aphid colonies. In favorable conditions, sorghum aphid can exponentially reproduce via asexual reproduction. A suggested strategy is to monitor alates to determine initial infestations and take preventive strategies, which can result in more efficient pest monitoring and management. To reduce the time of monitoring and better understand of alate establishment under field conditions, we propose using computer vision models, specifically deep learning, to detect and count alates using field-collected images. During pest monitoring, we captured 2527 images and assessed the performance of five models within the YOLOv5 architecture family using two different image sizes, including input resolutions of 640 × 640, and 1280 × 1280 pixels. We trained models to detect and count individual alates, which ranged between 1 and 100 alates/leaf. Among models, the YOLOv5l Pytorch detection model had the best overall performance at 1280 × 1280 input pixel resolution. The YOLOv5l model is a candidate model for quantifying alates on sorghum leaves using deep learning with a precision of 83.80%, 85.60% recall, and 89% mAP@0.5 with a lower mean percent error of misdetection. To enable the use of our best deep learning model by the research community, we developed a web-based application that is freely available to the public. Using this application, users can upload images to detect and count alates with a low error of misdetection.}
}
@article{KAHL2021101236,
title = {BirdNET: A deep learning solution for avian diversity monitoring},
journal = {Ecological Informatics},
volume = {61},
pages = {101236},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101236},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000273},
author = {Stefan Kahl and Connor M. Wood and Maximilian Eibl and Holger Klinck},
keywords = {Bioacoustics, Deep learning, Convolutional neural networks, Bird sound recognition, Avian diversity, Passive acoustic monitoring, Conservation},
abstract = {Variation in avian diversity in space and time is commonly used as a metric to assess environmental changes. Conventionally, such data were collected by expert observers, but passively collected acoustic data is rapidly emerging as an alternative survey technique. However, efficiently extracting accurate species richness data from large audio datasets has proven challenging. Recent advances in deep artificial neural networks (DNNs) have transformed the field of machine learning, frequently outperforming traditional signal processing techniques in the domain of acoustic event detection and classification. We developed a DNN, called BirdNET, capable of identifying 984 North American and European bird species by sound. Our task-specific model architecture was derived from the family of residual networks (ResNets), consisted of 157 layers with more than 27 million parameters, and was trained using extensive data pre-processing, augmentation, and mixup. We tested the model against three independent datasets: (a) 22,960 single-species recordings; (b) 286 h of fully annotated soundscape data collected by an array of autonomous recording units in a design analogous to what researchers might use to measure avian diversity in a field setting; and (c) 33,670 h of soundscape data from a single high-quality omnidirectional microphone deployed near four eBird hotspots frequented by expert birders. We found that domain-specific data augmentation is key to build models that are robust against high ambient noise levels and can cope with overlapping vocalizations. Task-specific model designs and training regimes for audio event recognition perform on-par with very complex architectures used in other domains (e.g., object detection in images). We also found that high temporal resolution of input spectrograms (short FFT window length) improves the classification performance for bird sounds. In summary, BirdNET achieved a mean average precision of 0.791 for single-species recordings, a F0.5 score of 0.414 for annotated soundscapes, and an average correlation of 0.251 with hotspot observation across 121 species and 4 years of audio data. By enabling the efficient extraction of the vocalizations of many hundreds of bird species from potentially vast amounts of audio data, BirdNET and similar tools have the potential to add tremendous value to existing and future passively collected audio datasets and may transform the field of avian ecology and conservation.}
}
@article{CAPINHA2021101252,
title = {Deep learning for supervised classification of temporal data in ecology},
journal = {Ecological Informatics},
volume = {61},
pages = {101252},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101252},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000431},
author = {César Capinha and Ana Ceia-Hasse and Andrew M. Kramer and Christiaan Meijer},
keywords = {Deep learning, Ecological prediction, Scalability, Sequential data, Temporal ecology, Time series},
abstract = {Temporal data is ubiquitous in ecology and ecologists often face the challenge of accurately differentiating these data into predefined classes, such as biological entities or ecological states. The usual approach consists of transforming the time series into user-defined features and then using these features as predictors in conventional statistical or machine learning models. Here we suggest the use of deep learning models as an alternative to this approach. Recent deep learning techniques can perform the classification directly from the time series, eliminating subjective and resource-consuming data transformation steps, and potentially improving classification results. We describe some of the deep learning architectures relevant for time series classification and show how these architectures and their hyper-parameters can be tested and used for the classification problems at hand. We illustrate the approach using three case studies from distinct ecological subdisciplines: i) insect species identification from wingbeat spectrograms; ii) species distribution modelling from climate time series and iii) the classification of phenological phases from continuous meteorological data. The deep learning approach delivered ecologically sensible and accurate classifications demonstrating its potential for wide applicability across subfields of ecology.}
}
@article{WANG2024102396,
title = {Feature-based and shape-match classifications of animal population time series},
journal = {Ecological Informatics},
volume = {79},
pages = {102396},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102396},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004259},
author = {Guiming Wang and Xueyan Shan},
keywords = {Dynamic time warming, Hierarchical clustering, Machine learning, State space model, Trend analysis},
abstract = {Estimation of long-term population trends can help population ecologists and conservation biologists assess the status and conditions of wildlife populations to inform the decision making of wildlife management and conservation. Machine learning methods such as time series clustering classify population time series into different clusters that have different trends and dynamic patterns as an alternative to statistical models. We used dynamic time warping (DTW) clustering and feature-based clustering to classify 15 rabbit population times in Mississippi, the United States from 1985 to 2005. Our feature-based method used the parameters of the order-2 Gompertz population models (or autoregressive time series models) as the features of population dynamics. We also estimated the long-term trends of the rabbit populations with the Theil-Sen analysis (TSA). The DTW clustering identified two clusters as optimal classification having the highest Silhouette score. Dynamic time warping clustering had 80% consistency in time series memberships with the TSA, whereas feature-based clustering had 87% consistency. Shape-match DTW clustering not only matches the shapes of trajectories, but also trends between time series. The features based on the Gompertz models capture trend, linear, and nonlinear dynamics. Our shape-match and feature-based time series clustering can cluster time series of different lengths and missing data. The Theil-Sen analysis generates an explicit estimate of linear trends and accounts for temporal autocorrelation. Since the true trends or patterns are often unknown, we recommend using two or all three methods of this study to assess the trends of wildlife populations.}
}
@article{GHOSH2024102581,
title = {HPB3C-3PG algorithm: A new hybrid global optimization algorithm and its application to plant classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102581},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102581},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001237},
author = {Sukanta Ghosh and Amar Singh and Shakti Kumar},
keywords = {Optimization problem, HPB3C-3PGA, Hybrid algorithm, CEC’21 benchmark function, PB3C, 3PGA, Exploration, Exploitation, Image classification},
abstract = {This paper proposes a hybrid bio-inspired search and optimization algorithm that combines the strengths of the PB3C (Parallel Big Bang Big Crunch) and 3PGA (3 Parent Genetic Algorithm) algorithms. The hybrid algorithm employs a single population-based evolutionary search coupled with multi-population parallel processing techniques to address optimization problems. The proposed algorithm is implemented in MATLAB software. We evaluate the performance of the proposed algorithm on the CEC2021 standard test bench suite. The performance of the proposed approach is compared with that of the other nine algorithms. The comparative analysis shows that the proposed hybrid PB3C and 3PGA algorithms performed better than the other nine optimization algorithms. Furthermore, this chapter proposes an HPB3C-3PGA-based approach to evolve the near-optimal architecture of CNN. The proposed plant image classification approach is implemented in Python and compared with 12 other approaches. The proposed approach achieved an accuracy of 98.96% on the Mendeley dataset and 98.97% on the CVIP100 dataset. The proposed approach outperforms all other approaches for the plant leaf classification problem. This research significantly contributes to overcoming limitations in existing approaches, providing a robust solution for optimization problems and image classification tasks.}
}
@article{SWAMINATHAN2024102471,
title = {Multi-label classification for acoustic bird species detection using transfer learning approach},
journal = {Ecological Informatics},
volume = {80},
pages = {102471},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102471},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400013X},
author = {Bhuvaneswari Swaminathan and M. Jagadeesh and Subramaniyaswamy Vairavasundaram},
keywords = {Wav2vec, Transformers, Transfer learning, Multi-label, Bird species classification, Audio classification},
abstract = {As part of ornithology, bird species classification is vital to understanding species distribution, habitat requirements and environmental changes that affect bird populations. It is possible for ornithologists to assess the health of a certain habitat by tracking changes in bird species distributions. This work has extended an efficient transfer learning technique for labelling and classifying multiple bird species from real-time audio recordings. For this purpose, Wav2vec is fine-tuned using the back propagation technique, which makes the feature extractor more effective in learning each bird's pitch and other sound characteristics. To perform the task, each audio recording has been clipped as chunks from the overlapping audio to determine multi-labels from it. Through the application of transfer learning, the features of audio recordings have been automatically extracted for classification and fed to a feed-forward network. Subsequently, probabilities associated with each audio segment is aggregated through the clipping approach to represent multiple species of bird call. These probability scores are then used to determine the presence of predominant bird species in the audio recording for multi-labelling. The proposed Wav2vec demonstrates remarkable performance, achieving an F1-score of 0.89 using the Xeno-Canto dataset in which outperforming other multi-label classifiers.}
}
@article{EITZEL2024102552,
title = {Using mixed-method analytical historical ecology to map land use and land cover change for ecocultural restoration in the Klamath River Basin (Northern California)},
journal = {Ecological Informatics},
volume = {81},
pages = {102552},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102552},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000943},
author = {M.V. Eitzel and Daniel Sarna-Wojcicki and Sean Hogan and Jennifer Sowerwine and Megan Mucioki and Kathy McCovey and Shawn Bourque and Leaf Hillman and Lisa Morehead-Hillman and Frank Lake and Vikki Preston and Chook-Chook Hillman and Andy Lyons and Bill Tripp},
keywords = {Analytical historical ecology, Manual photo interpretation, Mixed methods, Ethnographic research, Archival research, Historical aerial imagery, Ecocultural restoration, Change detection, Land use change, Land cover change},
abstract = {Ecocultural restoration involves the reciprocal repair of ecosystems and revitalization of cultural practices to enhance their mutual resilience to natural and anthropogenic disturbances and climate change stressors. Resilient ecocultural systems are adapted to retain structure and function in the face of disturbances that remain within historical ranges of severity. To assist in ecocultural restoration and management, understanding how a system has historically responded to different types of disturbances is therefore invaluable in understanding how social-ecological resilience can be maintained in the face of future stressors and disturbances. However, records of disturbances and ecocultural responses can be limited for certain landscapes and human communities. In this methods paper, we demonstrate a mixed-method process for integrating oral history, field-based knowledge, archival information, and historical and contemporary aerial images to gain insight into the changes on the Klamath River in Northern California from the 1940s through 2020. We georegistered historical imagery, quantified changes between land cover classes, and contextualized these classifications with qualitative assessments of changes in larger surrounding areas. By synthesizing these data sources with field measurements, mining and other land survey maps, timber management plans, fire and flood histories, and interviews with members of the Karuk Tribe, we were able to reconstruct the land use and land cover change histories at five sites. We noted that recovery of canopy cover from fire and logging practices was faster than for flood, which was faster than recovery from mining, consistent with the relative severity of likely soil disturbance. By combining different sources of information with complementary strengths, we were able to provide managers with site-specific information on recovery from different types of disturbance. Though this approach was labor-intensive, with emerging tools for supervised classification of high-resolution imagery, mixed-method analytical historical ecology could be applied more broadly, supporting ecocultural restoration on a larger scale.}
}
@article{MATIZA2024102472,
title = {The utility of Planetscope spectral data in quantifying above-ground carbon stock in an urban reforested landscape},
journal = {Ecological Informatics},
volume = {80},
pages = {102472},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102472},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000141},
author = {Collins Matiza and Onisimo Mutanga and John Odindi and Mthembeni Mngadi},
keywords = {Ecosystem services, Climate change, Spectral indices, Planetscope, Extreme gradient boosting},
abstract = {Urbanization, deforestation, and forest degradation significantly contribute to atmospheric carbon emissions and heightened climate change risks. Reforestation, a sustainable long-term land use strategy, offers mitigation by sequestering carbon dioxide. To assess reforestation efficacy within urban contexts, continuous carbon stock evaluation in reforested areas is essential for informed management and monitoring. Remote sensing techniques have gained traction in landscape analysis, driven by improved spatial-spectral data characteristics and novel indices. Notably, the Planetscope multispectral imagery, characterized by enhanced spatial and spectral attributes, has potential in enhancing carbon stock estimation. This study examines Planetscope's spectral, derived spectral features and terrain variables' effectiveness in estimating reforested urban landscape carbon stock. Employing extreme gradient boosting algorithm in Buffelsdraai, South Africa, the study's results are compared with an artificial neural network model to test the robustness of the model. Encouragingly, Planetscope spectral data accurately estimated reforested carbon stock with high R2 (0.78 and 0.81) and low RMSE (27.33 and 29.75 t. ha-1) from calibration and validation datasets. Notably, the green normalized vegetation index (GNDVI), red-edge normalized difference vegetation index (NDVIRED), and red-edge simple ratio index (SRRED) are optimal predictors. These findings underscore the value of Planetscope spectral data and extreme gradient boosting for precise carbon stock predictions in reforested urban environments. This study's insights are pivotal for designing effective reforestation ecosystem management and monitoring strategies, with implications for larger-scale carbon sequestration projects and resilient urban landscapes.}
}
@article{NOLASCO2023102258,
title = {Learning to detect an animal sound from five examples},
journal = {Ecological Informatics},
volume = {77},
pages = {102258},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102258},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300287X},
author = {Ines Nolasco and Shubhr Singh and Veronica Morfi and Vincent Lostanlen and Ariana Strandburg-Peshkin and Ester Vidaña-Vila and Lisa Gill and Hanna Pamuła and Helen Whitehead and Ivan Kiskin and Frants H. Jensen and Joe Morford and Michael G. Emmerson and Elisabetta Versace and Emily Grout and Haohe Liu and Burooj Ghani and Dan Stowell},
keywords = {Bioacoustics, Deep learning, Event detection, Few-shot learning},
abstract = {Automatic detection and classification of animal sounds has many applications in biodiversity monitoring and animal behavior. In the past twenty years, the volume of digitised wildlife sound available has massively increased, and automatic classification through deep learning now shows strong results. However, bioacoustics is not a single task but a vast range of small-scale tasks (such as individual ID, call type, emotional indication) with wide variety in data characteristics, and most bioacoustic tasks do not come with strongly-labelled training data. The standard paradigm of supervised learning, focussed on a single large-scale dataset and/or a generic pre-trained algorithm, is insufficient. In this work we recast bioacoustic sound event detection within the AI framework of few-shot learning. We adapt this framework to sound event detection, such that a system can be given the annotated start/end times of as few as 5 events, and can then detect events in long-duration audio—even when the sound category was not known at the time of algorithm training. We introduce a collection of open datasets designed to strongly test a system's ability to perform few-shot sound event detections, and we present the results of a public contest to address the task. Our analysis shows that prototypical networks are a very common used strategy and they perform well when enhanced with adaptations for general characteristics of animal sounds. However, systems with high time resolution capabilities perform the best in this challenge. We demonstrate that widely-varying sound event durations are an important factor in performance, as well as non-stationarity, i.e. gradual changes in conditions throughout the duration of a recording. For fine-grained bioacoustic recognition tasks without massive annotated training data, our analysis demonstrate that few-shot sound event detection is a powerful new method, strongly outperforming traditional signal-processing detection methods in the fully automated scenario.}
}
@article{BACHECHI2024102568,
title = {HypeAIR: A novel framework for real-time low-cost sensor calibration for air quality monitoring in smart cities},
journal = {Ecological Informatics},
volume = {81},
pages = {102568},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102568},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001109},
author = {Chiara Bachechi and Federica Rollo and Laura Po},
keywords = {Real-time, Sensor calibration, Air quality monitoring, Smart cities, Air pollution monitoring, Low cost sensors, Time series, Framework, Air quality, LSTM, Random forest},
abstract = {While less reliable than authorized air quality stations, low-cost sensors help monitor air quality in areas overlooked by traditional devices. A calibration process in the same environment as the sensor is crucial to enhance their accuracy. Furthermore, low-cost sensors deteriorate over time, necessitating repeated calibration for sustained performance. HypeAIR is a novel open-source framework for the management of sensor calibration in real-time. It incorporates two calibration methodologies: a combination of machine learning models (Voting Regressor and Support Vector Regression) and the Long Short-Term Memory deep learning model. To evaluate the framework, three extensive experiments were conducted over a 2-year period in the city of Modena, Italy, to monitor NO, NO2, and O3 gases. Both calibration methodologies outperform the manufacturer calibration and our baseline (i.e., a variation of the Random Forest algorithm) and maintain efficiency over time. The availability of the source code facilitates customization for monitoring additional pollutants, while shared air quality datasets ensure reproducibility.}
}
@article{CORO2024102644,
title = {Climate change effects on animal presence in the Massaciuccoli Lake basin},
journal = {Ecological Informatics},
volume = {81},
pages = {102644},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102644},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001869},
author = {Gianpaolo Coro and Pasquale Bove and Ilaria Baneschi and Andrea Bertini and Lorenzo Calvisi and Antonello Provenzale},
keywords = {Ecological niche modelling, Species richness, Wetlands, Artificial intelligence, Open Science, Maximum entropy},
abstract = {Big-data mining approaches based on Artificial Intelligence models can help forecast biodiversity changes before they happen. These approaches can predict macroscopic species distribution patterns and trends that can inform preventive measures to avoid the loss of ecosystem functions and services. They can, therefore, help study and mitigate climate change implications on biodiversity conservation in fragile ecosystems. Wetlands are particularly fragile ecosystems where climate change poses severe risks and has dramatically reduced their size over the past century, with profound consequences on biodiversity and ecosystem services. Through big-data mining approaches, we can predict future wetland biodiversity trends in the context of climate change. This paper proposes such predictive analysis for a specific wetland: The Massaciuccoli Lake basin in Tuscany, Italy. This basin is a critical tourist attraction due to its rich biodiversity, making it an area of interest for citizens, tourists, and scientists. However, the region's suitability for native and non-native species is at risk due to climate and land-use change. Using machine-learning models, we predict the potential effects of climate change on animal spatial distribution in the basin under different greenhouse gas emission scenarios. The results suggest that habitat suitability has generally improved from 1950 to today, presumably owing to the targeted conservation strategies adopted in the area, but climate change will severely reduce bird biodiversity by 2050 while favouring several insect species' proliferation and other species' habitat change, even under a medium-emission scenario. This will lead to significant changes in the basin's biodiversity. Our methodology is adaptable to other wetland basins, being fully based on open data and models. The spatially explicit modelling used in this research provides valuable information for policymakers and spatial planners, complementing traditional biodiversity trend analyses.}
}
@article{BOHNER2023102150,
title = {A semi-automatic workflow to process images from small mammal camera traps},
journal = {Ecological Informatics},
volume = {76},
pages = {102150},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102150},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001796},
author = {Hanna Böhner and Eivind Flittie Kleiven and Rolf Anker Ims and Eeva M. Soininen},
keywords = {Camera trap, Rodent, Automatic image classification, Adaptive monitoring, Data processing, Deep learning},
abstract = {Camera traps have become popular for monitoring biodiversity, but the huge amounts of image data that arise from camera trap monitoring represent a challenge and artificial intelligence is increasingly used to automatically classify large image data sets. However, it is still challenging to combine automatic classification with other steps and tools needed for efficient, quality-assured and adaptive processing of camera trap images in long-term monitoring programs. Here we propose a semi-automatic workflow to process images from small mammal cameras that combines all necessary steps from downloading camera trap images in the field to a quality checked data set ready to be used in ecological analyses. The workflow is implemented in R and includes (1) managing raw images, (2) automatic image classification, (3) quality check of automatic image labels, as well as the possibilities to (4) retrain the model with new images and to (5) manually review subsets of images to correct image labels. We illustrate the application of this workflow for the development of a new monitoring program of an Arctic small mammal community. We first trained a classification model for the specific small mammal community based on images from an initial set of camera traps. As the monitoring program evolved, the classification model was retrained with a small subset of images from new camera traps. This case study highlights the importance of model retraining in adaptive monitoring programs based on camera traps as this step in the workflow increases model performance and substantially decreases the total time needed for manually reviewing images and correcting image labels. We provide all R scripts to make the workflow accessible to other ecologists.}
}
@article{GIBB2024102449,
title = {Towards interpretable learned representations for ecoacoustics using variational auto-encoding},
journal = {Ecological Informatics},
volume = {80},
pages = {102449},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102449},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004788},
author = {K.A. Gibb and A. Eldridge and C.J. Sandom and I.J.A. Simpson},
keywords = {Representation learning, Variational auto-encoder, Biodiversity monitoring, Deep learning, Ecoacoustics, Passive acoustic monitoring},
abstract = {Ecoacoustics is an emerging science that seeks to understand the role of sound in ecological processes. Passive acoustic monitoring is being used to collect vast quantities of soundscape audio recordings to study variations in acoustic community and monitor biodiversity. However, extracting relevant information from soundscape recordings is non-trivial. Recent approaches to machine-learned acoustic features appear promising but are limited by at least three issues: inductive biases, lack of interpretability and crude temporal integration. In this paper we introduce a novel self-supervised representation learning algorithm for ecoacoustics - a convolutional Variational Auto-encoder (VAE) - and directly address these shortcomings. Firstly, we train the network on soundscape recordings from temperate and tropical field sites along a gradient of ecological degradation to provide a more relevant inductive bias than prior approaches. Secondly, we present a new method that allows interpretation of the latent space for the first time, giving insight into the basis of classification. Thirdly, we advance existing methods for temporal aggregation of learned embeddings by encoding latent features as a distribution over time. Under our approach to increase interpretability, we provide insight into how learned features drive habitat classification for the first time: inspection of latent space confirms that varying combinations of biophony, geophony and anthrophony are used to infer sites along a degradation gradient. Our novel temporal encoding method increases sensitivity to periodic signals and improves on previous research that uses time-averaged representations for site classification. This approach also reveals the contribution of hardware-specific frequency response that create a potential bias; we demonstrate how a simple linear transformation can be used to mitigate the effect of hardware variance on the learned representation under our approach. Our novel approach paves the way for development of a new class of deep neural networks that afford more interpretable learned ecoacoustic representations to advance both fundamental and applied science and support global conservation efforts.}
}
@article{VILLON2024102499,
title = {Toward an artificial intelligence-assisted counting of sharks on baited video},
journal = {Ecological Informatics},
volume = {80},
pages = {102499},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102499},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000414},
author = {Sébastien Villon and Corina Iovan and Morgan Mangeas and Laurent Vigliola},
keywords = {Deep learning, Neural network, Coral reef, Marine ecology, Shark conservation},
abstract = {Given the global biodiversity crisis, there is an urgent need for new tools to monitor populations of endangered marine megafauna, like sharks. To this end, Baited Remote Underwater Video Stations (BRUVS) stand as the most effective tools for estimating shark abundance, measured using the MaxN metric. However, a bottleneck exists in manually computing MaxN from extensive BRUVS video data. Although artificial intelligence methods are capable of solving this problem, their effectiveness is tested using AI metrics such as the F-measure, rather than ecologically informative metrics employed by ecologists, such as MaxN. In this study, we present both an automated and a semi-automated deep learning approach designed to produce the MaxN abundance metric for three distinct reef shark species: the grey reef shark (Carcharhinus amblyrhynchos), the blacktip reef shark (C. melanopterus), and the whitetip reef shark (Triaenodon obesus). Our approach was applied to one-hour baited underwater videos recorded in New Caledonia (South Pacific). Our fully automated model achieved F-measures of 0.85, 0.43, and 0.72 for the respective three species. It also generated MaxN abundance values that showed a high correlation with manually derived data for C. amblyrhynchos (R = 0.88). For the two other species, correlations were significant but weak (R = 0.35–0.44). Our semi-automated method significantly enhanced F-measures to 0.97, 0.86, and 0.82, resulting in high-quality MaxN abundance estimations while drastically reducing the video processing time. To our knowledge, we are the first to estimate MaxN with a deep-learning approach. In our discussion, we explore the implications of this novel tool and underscore its potential to produce innovative metrics for estimating fish abundance in videos, thereby addressing current limitations and paving the way for comprehensive ecological assessments.}
}
@article{FERNANDEZGUISURAGA2024102591,
title = {FIREMAP: Cloud-based software to automate the estimation of wildfire-induced ecological impacts and recovery processes using remote sensing techniques},
journal = {Ecological Informatics},
volume = {81},
pages = {102591},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102591},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400133X},
author = {José Manuel Fernández-Guisuraga and Alfonso Fernández-Manso and Carmen Quintano and Víctor Fernández-García and Alberto Cerrillo and Guillermo Marqués and Gaspar Cascallana and Leonor Calvo},
keywords = {Burned area, Fire severity, Google earth engine, Graphical user interface, Vegetation recovery},
abstract = {The formulation and planning of integrated fire management strategies must be strengthened by decision support systems about fire-induced ecological impacts and ecosystem recovery processes, particularly in the context of extreme wildfire events that challenge land management initiatives. Wildfire data collection and analysis through remote sensing earth observations is of utmost importance for this purpose. However, the needs of land managers are not always met because the exploitation of the full potential of remote sensing techniques requires a high level of technical expertise. In addition, data acquisition and storage, database management, networking, and computing requirements may present technical difficulties. Here, we present FIREMAP software, which leverages the potential of Google Earth Engine (GEE) cloud-based platform, an intuitive graphical user interface (GUI), and the European Forest Fire Information System (EFFIS) wildfire database for wildfire analyses through remote sensing techniques and data collections. FIREMAP software allows automatic computing of (i) machine learning-based burned area (BA) detection algorithms to facilitate the mapping of (historical) fire perimeters, (ii) fire severity spectral indices, and (iii) post-fire recovery trajectories through the inversion of physically-based radiative transfer models. We introduce (i) the FIREMAP platform architecture and the GUI, (ii) the implementation of well-established algorithms for wildfire science and management in GEE, (iii) the validation of the algorithm implementation in fifteen case-study wildfires across the western Mediterranean Basin, and (iv) the near-future and long-term planned expansion of FIREMAP features.}
}
@article{CINGANO2024102685,
title = {Seagrasses on the move: Tracing the multi-decadal species distribution trends in lagoon meadows using Landsat imagery},
journal = {Ecological Informatics},
volume = {82},
pages = {102685},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102685},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002279},
author = {Paolo Cingano and Marco Vuerich and Francesco Petruzzellis and Lorenzo Orzan and Giacomo Trotta and Valentino Casolo and Edoardo Asquini and Giovanni Bacaro and Francesco Boscutti},
keywords = {Biodiversity, Lagoon, Landsat, Long-term monitoring, Machine learning, Seagrass},
abstract = {Seagrass meadows play a vital role for lagoon ecosystems and their biota, sustaining multiple ecosystem services. Their distribution and functioning are closely tied to the environmental pressures induced by global changes. Long-term monitoring of seagrass species and communities is, hence, important to depict their response to past and future scenarios. The availability of long term open-access satellite data offers a new remote sensing perspective for monitoring seagrass communities dynamics in shallow waters, especially when combined with machine learning algorithms. In this study, seasonal multispectral images (from 1999 to 2019) were collected from Landsat 5 Thematic Mapper and 8 Operational Land Imager satellites to map the seagrass meadows, at the community and species levels, within the vast Grado and Marano lagoon (Northeast Italy) using a Random Forest (RF) algorithm. RF models were calculated using an extensive field training dataset collected in 2010 (n = 426) and reached an overall accuracy of 0.92 and 0.76 for the classification at the community and species levels, respectively. The change detection analysis revealed an increase of 14.16 km2 (+ 39%) of the whole seagrass community cover over the period, at a rate of 1.59 km2year−1. Despite the coarse spatial resolution (30 m) of the Landsat's images, the classification of seagrasses at species level achieved a good overall accuracy (0.76), evidencing Nanozostera noltei as the species with the highest cover increase (+13.87 km2 over the time period). The observed expansion is likely caused by an increase of the sea water influence that is radically modifying Adriatic brackish water bodies, emphasizing the connection between the ongoing environmental changes and the rapid responses of seagrass meadows.}
}
@article{LEVY2024102737,
title = {Improving deep learning based bluespotted ribbontail ray (Taeniura Lymma) recognition},
journal = {Ecological Informatics},
volume = {82},
pages = {102737},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102737},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002796},
author = {Avivit Levy and Adi Barash and Chen Zaguri and Ariel Hadad and Polina Polsky},
keywords = {Computer vision, Citizen science, Ecological study, Marine animal recognition, Pose handling},
abstract = {This paper presents the novel task of bluespotted ribbontail (BR) ray (Taeniura lymma) recognition using deep learning based computer vision methods to enable the identification of specific individuals of this species. Mapping the specific individuals in relation to location and time will allow marine researchers to understand their movement patterns, habitat choice, life span, size of the population and more – data which could allow monitoring and establishing a tailor-made conservation plan for this species. Our work is pioneer on this recognition problem. We give a detailed description of the three basic steps of detection, feature extraction and recognition in this vision problem and perform experiments to explore the system configuration and what improves the performance. A feature extraction enhancement as well as a crucial effect of a split into different main poses are demonstrated. Though the precision results achieved in this paper are still moderate and should be further improved, they are nevertheless promising and reasonable for practical use if the six best matches are chosen. For this scenario, almost 85% precision for upper-pose model, and almost 80% precision for left- and right-pose models, are achieved demonstrating the feasibility of the pipeline suggested as well as opportunities for improvement.}
}
@article{CHAIALLAH2023102332,
title = {Mining crowdsourced text to capture hikers' perceptions associated with landscape features and outdoor physical activities},
journal = {Ecological Informatics},
volume = {78},
pages = {102332},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102332},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003618},
author = {Abdesslam Chai-allah and Nathan Fox and Fritz Günther and Fadila Bentayeb and Gilles Brunschwig and Sandro Bimonte and Frédéric Joly},
keywords = {Cultural ecosystem services, Hiking, Natural language processing, Text analysis, Wikiloc},
abstract = {Outdoor recreation provides vital interactions between humans and ecological systems with a range of mental and physical benefits for people. Despite the increased number of studies using crowdsourced online data to assess how people interact with the landscape during recreational activities, the focus remains largely on mapping the spatial distribution of visitors or analyzing the content of shared images and little work has been done to quantify the perceptions and emotions people assign to the landscape. In this study, we used crowdsourced textual data from an outdoor activity-sharing platform (Wikiloc), and applied Natural Language Processing (NLP) methods and correlation analysis to capture hikers' perceptions associated with landscape features and physical outdoor activities. Our results indicate eight clusters based on the semantic similarity between words ranging from four clusters describing landscape features (“ecosystems, animals & plants”, “geodiversity”, “climate & weather”, and “built cultural heritage”), to one cluster describing the range of physical outdoor activities and three clusters indicating hikers' perceptions and emotions (“aesthetics”, “joy & restoration” and “physical effort sensation”). The association analysis revealed that the cluster “ecosystems, animals & plants” is likely to stimulate all three identified perceptions, suggesting that these natural features are important for hikers during their outdoor experience. Moreover, hikers strongly associate the cluster “outdoor physical activities” with both “joy & restoration” and “physical effort sensation” perceptions, highlighting the health and well-being benefits of physical activities in natural landscapes. Our study shows the potential of Wikiloc as a valuable data source to assess human-nature interactions and how textual data can provide significant advances in understanding peoples' preferences and perceptions while recreating. These findings can help inform outdoor recreation planners in the study region by focusing on the elements of the landscape that peoples perceive to be important (i.e. “ecosystems, animals & plants”).}
}
@article{ZHENG2024102689,
title = {A video object segmentation-based fish individual recognition method for underwater complex environments},
journal = {Ecological Informatics},
volume = {82},
pages = {102689},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102689},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002310},
author = {Tao Zheng and Junfeng Wu and Han Kong and Haiyan Zhao and Boyu Qu and Liang Liu and Hong Yu and Chunyu Zhou},
keywords = {Individual fish recognition, Video object segmentation, Underwater complex environments, Deep learning, Intelligent aquaculture},
abstract = {Currently, aquaculture methods tend to combine scale and intelligence, which saves manpower and improves the survival rate of seafood at the same time. High-precision and high-efficiency fish individual recognition can provide key technical support for fish disease detection, feeding habits, body condition, etc. In the realm of intelligent aquaculture, it provides robust data support for precision fish farming. However, the current research methods for individual fish recognition struggle to maintain the network model's focus on the fish body in real marine underwater complex environments (e.g., environmental background interference such as coral reefs, overlap between fish bodies, light noise, etc.), leading to unsatisfactory recognition results. To this end, this paper proposes a method for fish individual recognition in underwater complex environments based on video object segmentation, which consists of three parts, including a fish individual segmentation detection module, a fish individual recognition module, and an all-in-one visualization module. The work adopts a combination of deep learning methods and video object segmentation algorithms to solve the problem of low attention and poor detection accuracy of fish individuals in real underwater complex environments, which effectively improves the accuracy and efficiency of fish individual recognition, and analyzes and discusses the comparison of recognition effects using different weights. The results of the simulation experiments show that the key metric Rank1 value of the method achieves more than 96% accuracy on the public datasets DlouFish, WideFish, and the Fish-seg dataset produced in this paper, and improves over the state-of-the-art methods for fish individual recognition by 2.23%, 1.33%, and 1.25%, respectively.}
}
@article{WANG2024102409,
title = {Vegetation coverage precisely extracting and driving factors analysis in drylands},
journal = {Ecological Informatics},
volume = {79},
pages = {102409},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102409},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004387},
author = {Haolin Wang and Dongwei Gui and Qi Liu and Xinlong Feng and Jia Qu and Jianping Zhao and Guangyan Wang and Guanghui Wei},
keywords = {Image segmentation, Fractional vegetation coverage, Arid region, Ecological restoration, Deep learning},
abstract = {Fractional Vegetation Coverage (FVC) is an essential indicator that captures variations in vegetation and documents the impacts of climate change and human activity for environmental assessment. However, conventional methods encounter challenges in accurately extracting fine-scale FVC in drylands due to the vegetation distribution being very heterogeneous in space with patches and inter-patches. Using the lower Tarim River Basin as a typical study case, we investigated three deep convolutional neural networks—Unet, Pspnet, and Deeplabv3 + —to generate high-precision FVC in drylands with high-resolution (0.8 m) remote sensing images. Among these models, the Unet model performed better, with an accuracy of 93.38%, while the accuracy of Pspnet and Deeplabv3+ was 88.14% and 88.91%, respectively. Comparison with the FVC derived from normalized difference vegetation index (NDVI), and land use/land cover data from ESRI and ESA indicated that the FVC map produced by Unet was more consistent with on-site field observations. Delving into drivers influencing dryland FVC, we found that groundwater depth plays a pivotal role compared to topographical and climatic variables. Specifically, when the groundwater depth exceeds −3 m, the probability of occurring high FVC is reduced to 50%. This study innovatively extracted the FVC of drylands with high vegetation spatial heterogeneity, which better solves the insufficient accuracy of the existing dataset, serves as a valuable reference for monitoring vegetation change, and facilitates more precise quantification of carbon storage.}
}
@article{LEKUNBERRI2022101495,
title = {Identification and measurement of tropical tuna species in purse seiner catches using computer vision and deep learning},
journal = {Ecological Informatics},
volume = {67},
pages = {101495},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101495},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002867},
author = {Xabier Lekunberri and Jon Ruiz and Iñaki Quincoces and Fadi Dornaika and Ignacio Arganda-Carreras and Jose A. Fernandes},
keywords = {Computer vision, Deep learning, Fisheries, Electronic monitoring, Tropical tuna species identification},
abstract = {Fishery monitoring programs are essential for effective management of marine resources, as they provide scientists and managers with the necessary data for both the preparation of scientific advice and fisheries control and surveillance. The monitoring is generally done by human observers, both in port and onboard, with a high cost involved. Consequently, some Regional Fisheries Management Organizations (RFMO) are opting for electronic monitoring (EM) as an alternative or complement to human observers in certain fisheries. This is the case of the tropical tuna purse seine fishery operating in the Indian and Atlantic oceans, which started an EM program on a voluntary basis in 2017. However, even when the monitoring is conducted though EM, the image analysis is a tedious task manually performed by experts. In this paper, we propose a cost-effective methodology for the automatic processing of the images already being collected by cameras onboard tropical tuna purse seiners. Firstly, the images are preprocessed to homogenize them across all vessels and facilitate subsequent steps. Secondly, the fish are individually segmented using a deep neural network (Mask R-CNN). Then, all segments are passed through other deep neural network (ResNet50V2) to classify them by species and estimate their size distribution. For the classification of fish, we achieved an accuracy for all species of over 70%, i.e., about 3 out of 4 individuals are correctly classified to their corresponding species. The size distribution estimates are aligned with official port measurements but calculated using a larger number of individuals. Finally, we also propose improvements to the current image capture systems which can facilitate the work of the proposed automation methodology.}
}
@article{VABO2021101322,
title = {Automatic interpretation of salmon scales using deep learning},
journal = {Ecological Informatics},
volume = {63},
pages = {101322},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101322},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121001138},
author = {Rune Vabø and Endre Moen and Szymon Smoliński and Åse Husebø and Nils Olav Handegard and Ketil Malde},
keywords = {Fish scales, Deep learning, EfficientNet, Transfer learning, Age reading, Maturity staging},
abstract = {For several fish species, age and other important biological information is manually inferred from visual scrutinization of scales, and reliable automatic methods are not widely available. Here, we apply Convolutional Neural Networks (CNN) with transfer learning on a novel dataset of 9056 images of Atlantic salmon scales for four different prediction tasks. We predicted fish origin (wild/farmed), spawning history (previous spawner/non-spawner), river age, and sea age. We obtained high prediction accuracy for fish origin (96.70%), spawning history (96.40%), and sea age (86.99%), but lower accuracy for river age (63.20%). Against six human expert readers with an additional dataset of 150 scales, the CNN showed the second-highest percentage agreement for sea age (94.00%, range 87.25±97.30%), but the lowest agreement for river age (66.00%, range 66.00– 84.68%). Estimates of river age by expert readers exhibited higher variance and lower levels of agreement compared to sea age and may indicate why this task is also more difficult for the CNN. Automatic interpretation of scales may provide a cost- and time-efficient method of predicting fish age and life-history traits.}
}
@article{RIVERAMUNOZ2022101775,
title = {Deep matrix factorization models for estimation of missing data in a low-cost sensor network to measure air quality},
journal = {Ecological Informatics},
volume = {71},
pages = {101775},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101775},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002254},
author = {L.M. Rivera-Muñoz and A.F. Giraldo-Forero and J.D. Martinez-Vargas},
keywords = {Deep matrix factorization - DMF, Information retrieval, Low-cost sensors network, Missing data},
abstract = {According to the WHO, pollution is a worldwide public health problem. In Colombia, low-cost strategies for air quality monitoring have been implemented using wireless sensor networks (WSNs), which achieve a better spatial resolution than traditional sensor networks for a lower operating cost. Nevertheless, one of the recurrent issues of WSNs is the missing data due to environmental and location conditions, hindering data collection. Consequently, WSNs should have effective mechanisms to recover missing data, and matrix factorization (MF) has shown to be a solid alternative to solve this problem. This study proposes a novel MF technique with a neural network architecture (i.e., deep matrix factorization or DMF) to estimate missing particulate matter (PM) data in a WSN in Aburrá Valley, Colombia. We found that the model that included spatial-temporal features (using embedding layers) captured the behavior of the pollution measured at each node more efficiently, thus producing better estimations than standard matrix factorization and other variations of the model proposed here.}
}
@article{LIU201833,
title = {An accurate ecological footprint analysis and prediction for Beijing based on SVM model},
journal = {Ecological Informatics},
volume = {44},
pages = {33-42},
year = {2018},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2018.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574954117302972},
author = {Lingna Liu and Yalin Lei},
keywords = {Ecological footprint (EF), Back propagation neural network (BPNN), Support vector machine (SVM), Beijing},
abstract = {Accurate prediction of the ecological footprint (EF), an effective indicator for measuring urban sustainable development, enables better protection of urban ecosystems and alleviates discrepancies in urban development, resource utilization, and environmental protection. In contrast to previous research using general methods, we introduce the support vector machine (SVM) method. A novel model with improved prediction accuracy based on SVM is proposed, and we deploy this method to predict the EF of Beijing between 2016 and 2020. First, we calculate the EF of Beijing between 1996 and 2015 and screen out the 6 dominant indicators of EF changes using partial least squares (PLS). Second, based on 2014 and 2015 EF data, we compare the prediction accuracy of the back propagation neural network (BPNN) with the SVM using the 6 indicators as inputs and EF as the output, which then allows us to predict the year 2020 EF in Beijing. The results demonstrate that (1) the relative error rates between the prediction value and the actual value using the two models are 2% and 1% in 2014 and 3% and 0.53% in 2015, respectively, and the fact that the standard deviation of the SVM approaches zero demonstrates its higher prediction accuracy and stability compared to the BPNN; and (2) the EF of Beijing almost doubled to 8984 ten thousand acres from 1996 to 2015 and is predicted to increase to up to 14,206 ten thousand acres by 2020. Based on our prediction model, we provide science-based suggestions for the future development of Beijing.}
}
@article{NAZIR2024102453,
title = {Object classification and visualization with edge artificial intelligence for a customized camera trap platform},
journal = {Ecological Informatics},
volume = {79},
pages = {102453},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102453},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300482X},
author = {Sajid Nazir and Mohammad Kaleem},
keywords = {Data science, Computer vision, Deep learning, Model generalization, Fine tuning, Explainable AI, Hyperparameter tuning, Vision transformers},
abstract = {The camera traps have revolutionized the image and video capture in ecology and are often used to monitor and record animal presence. With miniaturization of low power electronic devices, better battery technologies, and software advancements, it has become possible to use the edge devices, such as Raspberry Pi as camera traps that can not only capture images and videos, but can also enable sophisticated image processing, and off-site communications. These developments can help to provide near real-time insights and reduce the manual processing of images. The on-board image classification and visualization is facilitated by the advancements in the Deep Neural Networks (DNN), transfer learning approaches, and software libraries. This paper provides an investigation of image classification with transfer learning approaches using pre-trained DNN models, and visualizations with Explainable Artificial Intelligence (XAI) techniques on Raspberry Pi Zero (RPi-Z) edge device. The MobileNetV2 model was used for image classification on the Florida-Part1 dataset obtaining the results for precision, recall, and F1-score as 0.95, 0.96, and 0.95 respectively. We also compared the model performance of MobileNetV2, EfficientNetV2B0, and MobileViT models for classification on the Extinction dataset with the best results for precision, recall, and F1-score as 0.97, 0.96, and 0.96 respectively, obtained with the EfficientNetV2B0 model. Two XAI techniques, Gradient-weighted-Class Activation Mapping (Grad-CAM) and Occlusion Sensitivity were used for visualization through heatmaps, to highlight the relative importance of the image areas contributing to the DNN model's prediction, that can also help to understand the model's performance and bias. The results provide practical use case scenarios for utilizing the transfer learning approaches, model optimization and deployment to edge devices, and model visualizations in ecological research.}
}
@article{SIGURDARDOTTIR2023102046,
title = {Otolith age determination with a simple computer vision based few-shot learning method},
journal = {Ecological Informatics},
volume = {76},
pages = {102046},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102046},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000754},
author = {Andrea Rakel Sigurðardóttir and Þór Sverrisson and Aðalbjörg Jónsdóttir and María Gudjónsdóttir and Bjarki Þór Elvarsson and Hafsteinn Einarsson},
keywords = {Otoliths, Fish age estimation, Few-shot learning, Deep-learning, Image analysis},
abstract = {In this study, we propose a computer vision-based few-shot learning method for otolith age determination in European plaice, Atlantic cod, Greenland halibut, and haddock. Our method outperforms prior state-of-the-art approaches, and is based on a vision encoder from CLIP as a feature extractor, which is used to train shallow models. The method is computationally efficient, as it does not require fine-tuning of deep networks, and is also data efficient, as it performs better than fine-tuning on the same data. Our results suggest that in some cases, our method can achieve the same performance as state-of-the-art finetuning approaches with up to three times less training data.}
}
@article{KUMAR2024102510,
title = {Bird species recognition using transfer learning with a hybrid hyperparameter optimization scheme (HHOS)},
journal = {Ecological Informatics},
volume = {80},
pages = {102510},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102510},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000529},
author = {Samparthi V.S. Kumar and Hari Kishan Kondaveeti},
keywords = {Automatic bird species recognition, Convolutional neural network, Deep learning, Hyperparameter tuning, Transfer learning},
abstract = {The use of automatic bird species recognition methods reduces the burden on scientists, ornithologists, and bird watchers as these methods help identify birds with minimal human effort and intervention. The current study employs a transfer learning approach combined with a Hybrid hyperparameter Optimization Scheme (HHOS) to enhance the efficiency and accuracy of automatic bird species recognition. First, the weights of selected pre-trained deep learning models are downloaded from ImageNet, and a few new trainable layers are added at the top. Thereafter, the selected models are trained using HHOS, which strategically integrates both manual and random searches to achieve favorable results. The manual search relies on domain knowledge and experience to identify the best hyperparameter settings, thereby making the search space smaller and more focused. Random search tests various combinations of the hyperparameters identified in manual search and trains the selected models to achieve the maximum possible accuracy through multiple iterations. Experimental analysis revealed that the Fine-tuned EfficientNetB0 model exhibited superior performance, achieving an accuracy of 99.12%. In contrast, the performance of the ResNet18 model was disappointing with an accuracy of 93.24%, while other models outperformed it.}
}
@article{GANJIRAD2024102498,
title = {Google Earth Engine-based mapping of land use and land cover for weather forecast models using Landsat 8 imagery},
journal = {Ecological Informatics},
volume = {80},
pages = {102498},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102498},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000402},
author = {Mohammad Ganjirad and Hossein Bagheri},
keywords = {LULC, GEE, WRF model, Machine learning, Classification, Landsat 8, Weather forecast},
abstract = {Land Use and Land Cover (LULC) maps are vital prerequisites for weather prediction models. This study proposes a framework to generate LULC maps based on the U.S. Geological Survey (USGS) 24-category scheme using Google Earth Engine. To realize a precise LULC map, a fusion of pixel-based and object-based classification strategies was implemented using various machine learning techniques across different seasons. For this purpose, feature importance analysis was conducted on the top classifiers considering the dynamic (seasonal) behavior of LULC. The results showed that ensemble approaches such as Random Forest and Gradient Tree Boosting outperformed other algorithms. The results also demonstrated that the object-based approach had better performance due to the consideration of contextual features. Finally, the proposed fusion framework produced a LULC map with higher accuracy (overall accuracy = 94.92% and kappa coefficient = 94.19%). Furthermore, the performance of the generated LULC map was assessed by applying it to the Weather Research and Forecasting (WRF) model for downscaling wind speed and 2-m air temperature (T2). The assessment indicated that the generated LULC map effectively reflected real-world conditions, thereby impacting the estimation of wind speed and T2 fields by WRF. Statistical assessments demonstrated enhancements in RMSE by 0.02 °C, MAE by 1 °C, and Bias by 0.03 °C for T2. Additionally, there was an improvement of 0.06 m/s in MAE for wind speed. Consequently, the framework can be implemented to produce accurate and up-to-date high-resolution LULC maps in various geographical areas worldwide. The source codes corresponding to this research paper are available on GitHub via https://github.com/Mganjirad/GEE-LULC-WRF.}
}
@article{ESTOPINAN2024102627,
title = {Mapping global orchid assemblages with deep learning provides novel conservation insights},
journal = {Ecological Informatics},
volume = {81},
pages = {102627},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102627},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001699},
author = {Joaquim Estopinan and Maximilien Servajean and Pierre Bonnet and Alexis Joly and François Munoz},
keywords = {Spatial indicator, Species assemblage, Deep learning, Species distribution modelling, IUCN status, Orchids},
abstract = {Although increasing threats on biodiversity are now widely recognised, there are no accurate global maps showing whether and where species assemblages are at risk. We hereby assess and map at kilometre resolution the conservation status of the iconic orchid family, and discuss the insights conveyed at multiple scales. We introduce a new Deep Species Distribution Model trained on 1 M occurrences of 14 K orchid species to predict their assemblages at global scale and at kilometre resolution. We propose two main indicators of the conservation status of the assemblages: (i) the proportion of threatened species, and (ii) the status of the most threatened species in the assemblage. We show and analyze the variation of these indicators at World scale and in relation to currently protected areas in Sumatra island. Global and interactive maps available online show the indicators of conservation status of orchid assemblages, with sharp spatial variations at all scales. The highest level of threat is found at Madagascar and the neighbouring islands. In Sumatra, we found good correspondence of protected areas with our indicators, but supplementing current IUCN assessments with status predictions results in alarming levels of species threat across the island. Recent advances in deep learning enable reliable mapping of the conservation status of species assemblages on a global scale. As an umbrella taxon, orchid family provides a reference for identifying vulnerable ecosystems worldwide, and prioritising conservation actions both at international and local levels.}
}
@article{QUASH2024102442,
title = {Assessing the impact of gold mining on forest cover in the Surinamese Amazon from 1997 to 2019: A semi-automated satellite-based approach},
journal = {Ecological Informatics},
volume = {80},
pages = {102442},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102442},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004715},
author = {Yann Quash and Angela Kross and Jochen A.G. Jaeger},
keywords = {Google Earth Engine, Artisanal and small-scale gold mining (ASGM), Classification and regression tree (CART), Deforestation, Forest phenology and fragmentation, Land use and land cover (LULC) classification},
abstract = {The Amazon rainforest has faced extensive deforestation for decades due to urban growth, agricultural expansion, logging and mining. Mining however has been relatively understudied in the Amazon. The objectives of this study were: (1) to develop an effective cloud-based classification approach coupled with an innovative semi-automated reclassification method; (2) to quantify the mining extent and its impacts on forest cover in Suriname from 1997 to 2019; and (3) to evaluate the impact of mining on the structure and health of the forest. Landsat 5 and 8 images were used for the initial land-use/land-cover classification using the classification and regression trees algorithm in Google Earth Engine. The resulting classified maps were reclassified in a semi-automated model to correct misclassifications between mining and urban pixels. The final maps were used to analyse the expansion of mining and its impacts on forest cover, structure (using the fragmentation metric effective mesh size), and forest health (using the phenology metric peak greenness). The combined approach resulted in an improvement in mining detection accuracy from 72% (65% producer, 79% user) to 89.5% (84% producer accuracy, 95% user). The results showed that mining increased from 69.4 km2 in 1997 to 431.6 km2 in 2019, an increase by 522% over 22 years, which led to 421.3 km2 of forest loss, of which 85% was due to artisanal and small-scale mining (ASGM). The loss of forest for ASGM resulted in greater fragmentation, with a decrease in effective mesh size by 122.8 km2 compared to a decrease by 83 km2 caused by industrial mining. Mining also caused a decrease in the health of the surrounding forest, with a larger decrease in peak greenness due to ASGM compared to industrial mining. The results demonstrate the potential of this approach that leverages cloud-based machine learning with a semi-automated reclassification to allow for rapid, accurate, and potentially global mining detection.}
}
@article{JIN2024102574,
title = {UAV-RGB-image-based aboveground biomass equation for planted forest in semi-arid Inner Mongolia, China},
journal = {Ecological Informatics},
volume = {81},
pages = {102574},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102574},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400116X},
author = {Xiao-Liang Jin and Yu Liu and Xiu-Bo Yu},
keywords = {Above ground biomass, Allometric growth equation, Unmanned aerial vehicles, Canopy height model (CHM), },
abstract = {The acquisition of high-resolution aboveground biomass (AGB) data cost-effectively and expeditiously represents a formidable challenge within the domain of current ecosystem surveillance. Plot-based inventory, the conventional approach for estimating and validating remote sensing data, is nonetheless costly and constrained in terms of spatial coverage. The expeditious advancements in unmanned-aerial-vehicle (UAV) technology furnish the potential to devise AGB equations that transcend traditional diameter-height-based equations alongside techniques for quantifying forest structural parameters through standard RGB aerial imagery. Since the canopy diameter (CD) and tree height (H) can be directly ascertained from UAV-derived datasets, biomass equations parameterized by CD and H may be more valuable. In the present investigation, we established AGB equations predicated on data procured from a UAV outfitted with a high-resolution RGB camera, specifically for planted sparsely Pinus sylvestris forest in central Inner Mongolia, China. Utilizing the aerial imagery, we generated the digital terrain model (DTM), digital surface model (DSM) and the digital orthophoto image (DOM). Then, the canopy height model (CHM) was obtained by subtracting DSM from DTM to extract the H and CD of individual trees. This methodology's CD (R2 = 0.85, RMSE = 0.203 m) and H (R2 = 0.77 and RMSE = 0.671 m) obtained closely mirrored the in-situ measurements. Six prospective AGB equations were constructed for the Pinus sylvestris forest, taking H and CD extracted from UAV aerial survey datasets as the dependent variables. The accuracy of the AGB estimation was appraised by employing extant allometric growth equations, which were parameterized using the ground-measured tree diameter at breast height (DBH) and H. The most efficacious biomass equation, predicated on H and CD data extracted from UAV aerial surveys, was delineated as W=2.3442CD∗H0.9057(R2 = 0.731, RMSE = 2.46 kg), thus presenting a convenient tool for estimating the AGB of sparse Pinus sylvestris forests in semi-arid locales.}
}
@article{BARTOLD2024102603,
title = {Estimating of chlorophyll fluorescence parameter Fv/Fm for plant stress detection at peatlands under Ramsar Convention with Sentinel-2 satellite imagery},
journal = {Ecological Informatics},
volume = {81},
pages = {102603},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102603},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001456},
author = {Maciej Bartold and Marcin Kluczek},
keywords = {Ecosystem dynamics, Fv/Fm, Machine learning, Plant stress, Peatlands, Ramsar sites},
abstract = {Monitoring vegetation is essential in Earth Observation (EO) due to its link with the global carbon cycle, playing a crucial role in ecosystem management. The fluorescence of chlorophyll (ChF) is a reliable indicator of plants' photosynthetic activity and growth, especially when they are experiencing unfavourable conditions, particularly in terrestrial wetlands. These wetlands are integral components of the landscape, contributing significantly to climate mitigation, adaptation, biodiversity, and the well-being of both the environment and humanity. We conducted a research study using the XGBoost machine learning algorithm to map the chlorophyll fluorescence parameter Fv/Fm in the Biebrza River Valley, which is known for its marshes, peatlands, and diverse flora and fauna. Our study highlights the benefits of using ensemble classifiers derived from EO Sentinel-2 satellite imagery for accurately mapping Fv/Fm across terrestrial landscapes under the Ramsar Convention at Narew River Valley (Poland) and Čepkeliai Marsh (Lithuania). The XGBoost algorithm provides an accurate estimate of ChF with a robust determination coefficient of 0.747 and minimal bias at 0.013, as validated using in situ data. The precision of Fv/Fm chlorophyll fluorescence parameter estimation from remote sensing sensors depends on the growth stage, emphasizing the importance of identifying the optimal overpass time for S-2 observations. Our study found that biophysical factors, as denoted by spectral indices related to greenness and leaf pigments, were highly impactful variables among the top classifiers. However, incorporating soil, vegetation and meteorological indicators from remote sensing data could further increase the accuracy of chlorophyll fluorescence mapping.}
}
@article{SONG2024102466,
title = {Benchmarking wild bird detection in complex forest scenes},
journal = {Ecological Informatics},
volume = {80},
pages = {102466},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102466},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000086},
author = {Qi Song and Yu Guan and Xi Guo and Xinhui Guo and Yufeng Chen and Hongfang Wang and Jianping Ge and Tianming Wang and Lei Bao},
keywords = {Object detection, Bird detection, Deep learning, Camera trap},
abstract = {Camera traps are widely used for wildlife monitoring and making informed conservation and land-management decisions, but the resulting ‘big data’ are laborious to process. Deep learning-based methods have been adopted for wildlife detection in camera traps. However, these methods detect large mammals in uncomplicated scenes, where powerful deep-learning models work effectively. Few studies have been conducted to develop artificial intelligence for recognizing wild birds that live in complicated field scenes with protective colors and small sizes. Here we used a dataset of 9717 images from 15 bird species based on camera traps to test 8 object detection algorithms (Faster RCNN, Cascade RCNN, RetinaNet, FCOS, RepPoints, ATSS, Deformable-DETR, and Sparse RCNN) and assess their performance. We also explored the effect of different backbones on model accuracy. Among them, the Cascade RCNN model performs best, with a mAP of 0.693 in model capabilities. Models perform differently in certain species, and backbones significantly affect the accuracy of the model. Cascade RCNN utilizing the Swin-T backbone is the best-performing combination, with a mAP of 0.704. This study could help researchers identify birds efficiently and inspires research on wildlife recognition in complex ecological settings.}
}
@article{CHEN2024102660,
title = {Detecting sun glint in UAV RGB images at different times using a deep learning algorithm},
journal = {Ecological Informatics},
volume = {81},
pages = {102660},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102660},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002024},
author = {Jiahao Chen and Yi Xiao and Yahui Guo and Mingwei Li and Xiran Li and Xuan Zhang and Fanghua Hao and Xiao Pu and Yongshuo Fu},
keywords = {Unmanned aerial vehicle, Water quality monitoring, Sun glint, Convolutional neural network, Res_AUNet network, WSGD dataset},
abstract = {Unmanned aerial vehicle (UAV) remote sensing has played a crucial role in water quality monitoring. However, the presence of water sun glint, resulting from specular reflection on the water surface, poses an inevitable challenge in UAV-acquired images. These excessively bright pixels disrupt the original images' spectral and textural characteristics, significantly diminishing their usability. This disruption has repercussions on subsequent tasks, such as target object classification and water quality parameter inversion. Precise detection of sun glint is a prerequisite for removing them, but current methods suffer from missed and false detections. In this study, we collected images by UAV to construct a specialized dataset for water surface sun glint, namely water sun glint detection (WSGD) dataset, laying the groundwork for further research endeavors. We proposed the Res_AUNet network by enhancing the UNet convolutional neural network. The Convolutional Block Attention Module was integrated into the encoding-decoding skip connections of the network, we also refined the convolutional blocks to better capture the distinctive semantic features associated with water sun glint. To mitigate overfitting, the residual structures were incorporated and the number of convolutional kernels within each block was reduced. The Res_AUNet network was trained and evaluated using the WSGD dataset, achieving metrics with an Accuracy of 98.02%, an F1-score of 83.67%, and an IOU of 74.73%. These results underscore the precision of our proposed method for water sun glint detection in UAV water images, offering valuable insights for effectively eliminating water sun glint and determining the optimal timing for UAV water image acquisition.}
}
@article{DUAN2024102563,
title = {Identifying soil groups and selecting a high-accuracy classification method based on multi-textural features with optimal window sizes using remote sensing images},
journal = {Ecological Informatics},
volume = {81},
pages = {102563},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102563},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001055},
author = {Mengqi Duan and Xiangyun Song and Zengqiang Li and Xiaoguang Zhang and Xiaodong Ding and Dejie Cui},
keywords = {Mean, Entropy, Multi-textural features, Soil groups, SVM, Textural feature windows},
abstract = {Determining the spatial distribution of soil groups accurately is crucial for managing soil resources. However, limitations persist in the mapping of soil groups using multi-textural features derived from remote sensing images. Identification of the optimal window size for multi-textural feature extraction and the most effective classification method for soil group recognition using remote sensing multi-textural features remains unresolved. In this study, we investigated soil groups in a representative area of the Jiaodong Peninsula. We extracted the mean and entropy texture parameters for various window sizes (3 × 3 to 25 × 25 in odd increments) from Landsat 8 images to determine the optimal sizes for multi-textural feature extraction. The efficacy of identifying soil groups via textural features was analyzed using maximum likelihood classification (MLC), support vector machine (SVM), artificial neural network (ANN), and random forest (RF) methods to ascertain the most suitable classification approach. The results indicate that the optimal window sizes were 19 × 19 for the mean parameter and 23 × 23 for the entropy parameter. The SVM method outperformed the MLC, ANN, and RF methods in terms of the classification accuracy. Notably, the SVM classification method reached a peak accuracy of 71.61% when combining multi-textural features with the optimal windows. This demonstrates the feasibility of different soil groups using multi-textural information from remote sensing images. These findings have notable implications in guiding digital soil mapping using multi-textural features.}
}
@article{LARSEN2021101290,
title = {Online computational ethology based on modern IT infrastructure},
journal = {Ecological Informatics},
volume = {63},
pages = {101290},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101290},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000819},
author = {Leon B. Larsen and Mathias M. Neerup and John Hallam},
keywords = {Bioacoustics, Recording, Automated annotation},
abstract = {In the study of animal behaviour, annotation and analysis is largely done manually either directly in the field or from recordings. An emerging field, computational ethology, is challenging this approach by using machine learning to automate the process. However, the use of such methods in general is complicated by a lack of modularity, leading to high cost and long development times. At the same time, the benefits of implementing a fully automated pipeline are often minuscule. We propose online analysis as a way to gain more from automating the process, such as making it easier to ensure that equipment is properly configured and calibrated, enabling the recording equipment to follow the animals, and even enabling closed-loop experiments. In this work, we discuss the requirements and challenges for such a system and propose an implementation based on modern IT infrastructure. Finally, we demonstrate the system in case studies of bats and mongoose. As more and more methods and algorithms are developed we expect online systems to enable new experimental setups to study behaviour, leading to new insights in the field.}
}
@article{SABERIOON2023102058,
title = {Examining the sensitivity of simulated EnMAP data for estimating chlorophyll-a and total suspended solids in inland waters},
journal = {Ecological Informatics},
volume = {75},
pages = {102058},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102058},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000870},
author = {Mohammadmehdi Saberioon and Vahid Khosravi and Jakub Brom and Asa Gholizadeh and Karl Segl},
keywords = {Biophysical properties, Hyperspectral imagery, Machine learning, Remote sensing, Satellite imagery, Water quality},
abstract = {Our study investigates the capability of the environmental mapping and analysis program (EnMAP) scenes simulated using the EnMAP end-to-end simulator software (EeteS) based on the AISA Eagle airborne data to predict chlorophyll-a (Chl-a) and total suspended solids (TSS) as two of the most crucial water quality indicators. Three machine learning (ML) approaches (principal component regression(PCR), partial least square regression (PLSR) and random forest (RF)) were employed to establish links between the simulated image spectra and the above-mentioned water attributes of the samples collected from several inland water reservoirs within the southern part of the Czech Republic. Airborne hyperspectral images were also used to develop a model to compare its performance with models developed based on the simulated EnMAP data. Adequate prediction accuracy was obtained for both Chl-a (R2 = 0.89, RMSE = 43.06 μg/L, and Lin’s concordance correlation coefficient (LCCC) = 0.91) and TSS (R2 = 0.91, RMSE = 17.53 mg/L, and LCCC = 0.94), which were close enough to those obtained from the airborne hyperspectral images. Chl-a and TSS correlated with the wavelengths around 550 nm and 700 to 750 nm of the red and near-infrared (NIR) regions. In addition, the spatial distribution maps derived from the simulated EnMAP were comparable to those obtained from the AISA Eagle airborne data. Overall, it can be concluded that the simulated EnMAP image successfully and reliably predicted and spatially mapped the selected biophysical properties of the small inland water bodies.}
}
@article{SHI2021101464,
title = {Modeling the response of negative air ions to environmental factors using multiple linear regression and random forest},
journal = {Ecological Informatics},
volume = {66},
pages = {101464},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101464},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002557},
author = {Guang-Yao Shi and Yu Zhou and Yu-Qiang Sang and Hui Huang and Jin-Song Zhang and Ping Meng and Lu-Lu Cai},
keywords = {Negative air ion, Environment factor, Machine learning, Random forest model, Multiple linear regression},
abstract = {Negative air ion (NAI) plays a vital role in promoting the psychological and physiological functions of the human body and is an essential indicator for measuring the air cleanliness of a given area. In this paper, we presented and compared the results of two methods for identifying the main environmental factors affecting changes of NAI in a warm-temperate region of China. NAI concentration was estimated based on measured data during the main growing season in a warm-temperate forest and was used as the dependent variable in the traditional multiple linear regression and random forest models. Air pollutants and certain weather, radiation, and soil factors were selected as predictors based on their potential influence on NAI. Two methods were applied for the analysis, and the latter was a non-parametric alternative based on an ensemble of classification and regression trees. We compared the precision of the two models, and the variables of each method on the basis of their levels of importance; Independent samples was used in model validation, then we discussed the important environmental factors affecting changes of NAI concentration for both linear and nonlinear perspectives, along with the potential implications of environmental factors on NAI. The random forest model showed a higher accuracy comparison with the multiple linear regression model. Furthermore, the analysis also indicated its better performance by using independent test data for 10-fold cross-validation of the random forest model, and showing that this method has potential for broad-scale application in the assessment of environmental-factor influence on NAI. Certain selected variables that were common to both models (particulate matter 2.5, soil moisture, and relative humidity) appeared to influence NAI to a relatively large extent, demonstrating the decidedly influential role of these parameters on NAI concentration.}
}
@article{EFFROSYNIDIS2018158,
title = {Seagrass detection in the mediterranean: A supervised learning approach},
journal = {Ecological Informatics},
volume = {48},
pages = {158-170},
year = {2018},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2018.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1574954118301560},
author = {Dimitrios Effrosynidis and Avi Arampatzis and Georgios Sylaios},
keywords = {Seagrass classification, Dataset integration and fusion, Machine learning, Data mining, Mediterranean Sea},
abstract = {We deal with the problem of detecting seagrass presence/absence and distinguishing seagrass families in the Mediterranean via supervised learning methods. By merging datasets about seagrass presence and other external environmental variables, we develop suitable training data, enhanced by seagrass absence data algorithmically produced based on certain hypotheses. Experiments comparing several popular classification algorithms yield up to 93.4% accuracy in detecting seagrass presence. In a feature strength analysis, the most important variables determining presence–absence are found to be Chlorophyll-α levels and Distance-to-Coast. For determining family, variables cannot be easily singled out; several different variables seem to be of importance, with Chlorophyll-α surpassing all others. In both problems, tree-based classification algorithms perform better than others, with Random Forest being the most effective. Hidden preferences reveal that Cymodocea and Posidonia favor the low, limited-range chlorophyll-α levels (<0.5 mg/m3), Halophila tolerates higher salinities (>39), while Ruppia prefers euryhaline conditions (37.5–39).}
}
@article{HARTMANN2022101782,
title = {A text and image analysis workflow using citizen science data to extract relevant social media records: Combining red kite observations from Flickr, eBird and iNaturalist},
journal = {Ecological Informatics},
volume = {71},
pages = {101782},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101782},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002321},
author = {Maximilian C. Hartmann and Moritz Schott and Alishiba Dsouza and Yannick Metz and Michele Volpi and Ross S. Purves},
keywords = {User-generated content, Volunteered geographic information, Data integration, Image content analysis, Convolutional neural networks},
abstract = {There is an urgent need to develop new methods to monitor the state of the environment. One potential approach is to use new data sources, such as User-Generated Content, to augment existing approaches. However, to date, studies typically focus on a single date source and modality. We take a new approach, using citizen science records recording sightings of red kites (Milvus milvus) to train and validate a Convolutional Neural Network (CNN) capable of identifying images containing red kites. This CNN is integrated in a sequential workflow which also uses an off-the-shelf bird classifier and text metadata to retrieve observations of red kites in the Chilterns, England. Our workflow reduces an initial set of more than 600,000 images to just 3065 candidate images. Manual inspection of these images shows that our approach has a precision of 0.658. A workflow using only text identifies 14% less images than that including image content analysis, and by combining image and text classifiers we achieve almost perfect precision of 0.992. Images retrieved from social media records complement those recorded by citizen scientists spatially and temporally, and our workflow is sufficiently generic that it can easily be transferred to other species.}
}
@article{ABDELGADIR2023102346,
title = {Distribution of denitrifiers predicted by correlative niche modeling of changing environmental conditions and future climatic scenarios across the Baltic Sea},
journal = {Ecological Informatics},
volume = {78},
pages = {102346},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102346},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003758},
author = {Mohanad Abdelgadir and Randa Alharbi and Monif AlRashidi and Abdulaziz S. Alatawi and Sara Sjöling and Patrik Dinnétz},
keywords = {Climate change, Benthic conditions, Ensemble modeling, Habitat suitability, Machine-learning, Multi-collated variables},
abstract = {Denitrifying microbial communities provide an important ecosystem function in aquatic systems. Yet, knowledge on predictive and modeling of these complex and changing communities is limited. The emergently challenging question of how the geographical distribution of denitrifiers responds to ongoing and future environmental change is not yet fully understood. In our study we use metadata-based correlative niche modeling to analyze the geographical distribution of selected putative denitrifiers in the genus Sphingomonas, Mycoplana, Shewanella, and Alteromonas at different predicted environmental conditions and future climatic scenarios across the Baltic Sea. Using the predictive power of an ensemble modeling approach and eight different machine-learning algorithms, habitat suitability and the distribution of the selected denitrifiers were evaluated using geophysical and bioclimatic variables, benthic conditions, and four Representative Concentration Pathway (RCP) trajectories of future global warming scenarios. All algorithms provided successful prediction capabilities both for variable importance, and for habitat suitability with Area Under the Curve (AUC) values between 0.89 and 1.00. Model findings revealed that salinity and nitrate concentrations significantly explained the variation in distribution of the selected denitrifiers. Rising temperatures of 0.8 to 1.8 °C at future RCP60–2050 trajectories are predicted to diminish or eliminate the bioclimatic suitable habitats for denitrifier distributions across the Baltic Sea. Multi-collated terrestrial and marine environmental variables contributed to the successful prediction of denitrifier distributions within the study area. The correlative niche modeling approach with high AUC values presented in the study allowed for accurate projections of the future distributions of the selected denitrifiers. The modeling approach can be used to improve our understanding of how ongoing and predicted future environmental changes may affect habitat suitability for organisms with denitrification capacity across the Baltic Sea.}
}
@article{NOMAN2023102047,
title = {Improving accuracy and efficiency in seagrass detection using state-of-the-art AI techniques},
journal = {Ecological Informatics},
volume = {76},
pages = {102047},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102047},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000766},
author = {Md Kislu Noman and Syed Mohammed Shamsul Islam and Jumana Abu-Khalaf and Seyed Mohammad Jafar Jalali and Paul Lavery},
keywords = {Deep learning, EfficientDet, Faster R-CNN, , NASNet, Seagrass, YOLOv5},
abstract = {Seagrasses provide a wide range of ecosystem services in coastal marine environments. Despite their ecological and economic importance, these species are declining because of human impact. This decline has driven the need for monitoring and mapping to estimate the overall health and dynamics of seagrasses in coastal environments, often based on underwater images. However, seagrass detection from underwater digital images is not a trivial task; it requires taxonomic expertise and is time-consuming and expensive. Recently automatic approaches based on deep learning have revolutionised object detection performance in many computer vision applications, and there has been interest in applying this to automated seagrass detection from imagery. Deep learning–based techniques reduce the need for hardcore feature extraction by domain experts which is required in machine learning-based techniques. This study presents a YOLOv5-based one-stage detector and an EfficientDetD7–based two-stage detector for detecting seagrass, in this case, Halophila ovalis, one of the most widely distributed seagrass species. The EfficientDet-D7–based seagrass detector achieves the highest mAP of 0.484 on the ECUHO-2 dataset and mAP of 0.354 on the ECUHO-1 dataset, which are about 7% and 5% better than the state-of-the-art Halophila ovalis detection performance on those datasets, respectively. The proposed YOLOv5-based detector achieves an average inference time of 0.077 s and 0.043 s respectively which are much lower than the state-of-the-art approach on the same datasets.}
}
@article{HYSEN2022101914,
title = {Background sampling for multi-scale ensemble habitat selection modeling: Does the number of points matter?},
journal = {Ecological Informatics},
volume = {72},
pages = {101914},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101914},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003648},
author = {Logan Hysen and Danial Nayeri and Samuel Cushman and Ho Yi Wan},
keywords = {Biomod, Ecological niche, Habitat suitability, Presence-absence, Species distribution model, Presence-only},
abstract = {Ensemble habitat selection modeling is becoming a popular approach among ecologists to answer different questions. Since we are still in the early stages of development and application of ensemble modeling, there remain many questions regarding performance and parameterization. One important gap, which this paper addresses, is how the number of background points used to train models influences the performance of the ensemble model. We used an empirical presence-only dataset and three different selections of background points to train scale-optimized habitat selection models using six modeling algorithms (GLM, GAM, MARS, ANN, Random Forest, and MaxEnt). We tested four ensemble models using different combinations of the component models: (a) equal numbers of background points and presences, (b) background points equaled ten times the number of presences, (c) 10,000 background points, and (d) optimized background points for each component model. Among regression-based approaches, MARS performed best when built with 10,000 background points. Among machine learning models, RF performed the best when built with equal presences and background points. Among the four ensemble models, AUC indicated that the best performing model was the ensemble with each component model including the optimized number of background points, while TSS increased as the number of background points models increased. We found that an ensemble of models, each trained with an optimal number of background points, outperformed ensembles of models trained with the same number of background points, although differences in performance were slight. When using a single modeling method, RF with equal number of presences and background points can perform better than an ensemble model, but the performance fluctuates when the number of background points is not properly selected. On the other hand, ensemble modeling provides consistently high accuracy regardless of background point sampling approach. Further, optimizing the number of background points for each component model within an ensemble model can provide the best model improvement. We suggest evaluating more models across multiple species to investigate how background point selection might affect ensemble models in different scenarios.}
}
@article{DATTA2024102509,
title = {Development of a spatially explicit model of blue carbon storages in tropical mudflat environment through integrated radar-optical approach and ground-based measurements},
journal = {Ecological Informatics},
volume = {80},
pages = {102509},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102509},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000517},
author = {Debajit Datta and Mansa Dey and Proshanta Kumar Ghosh and Argha Pratim Pal},
keywords = {Blue C pool, BP-ANN algorithm, Land use/ land cover, NDVI, SAR backscatter, Wetland influence zone},
abstract = {Tropical coastal wetlands have been well recognized for their role in mitigating climate change apart from possessing high biodiversity values as well as providing important habitats for fisheries and other ecosystem services. Although these wetlands play key roles in sequestering carbon (C) in the lithosphere and hydrosphere, there is a notable dearth of comprehensive yet spatially explicit accounts of their total blue carbon (TBC) stocks. The anthropogenic factors including development stressors have fundamentally altered the global C dynamics. In this respect, holistic accounting of the total C stocks of the coastal wetlands becomes the foremost task in emphasizing their recognition as integral components of climate change mitigation strategies. This study modeled TBC stocks of an intertidal mudflat of eastern India across different land use/ land covers (LULCs) by quantifying the above ground biomass (AGB), below ground biomass (BGB), and soil organic C (SOC). The distribution of SOC was modeled through spatial interpolation of point-specific C densities (R2 = 0.77; RMSE = 22.91 Mg ha−1). AGB was estimated by establishing allometric relationships between geospatial data, both of active (PALSAR-2) and passive (Pleiades-1B) nature and in-situ dendrometric variables using the artificial neural network (R2 = 0.85; RMSE = 48.91 Mg ha−1). BGB was estimated from the modeled AGB. Spatial integration of these datasets estimated the TBC stock of mudflat as 27,469.30 Mg. Overall, open mangrove represented highest mean TBC density (163.29 Mg ha−1) while herbaceous vegetation recorded largest TBC stock (9818.94 Mg). Mean TBC densities across LULCs were significantly different (p < 0.05) from each other except for the herbaceous vegetation and built-up categories, indicating the inertial effects of paleo-land covers. Accordingly, this study could be inferred as a pioneering one in developing a comprehensive geospatial model of TBC accounting in India towards strengthening the regional and national C inventories.}
}
@article{OLIVARESPINTO2024102653,
title = {Using honey bee flight activity data and a deep learning model as a toxicovigilance tool},
journal = {Ecological Informatics},
volume = {81},
pages = {102653},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102653},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400195X},
author = {Ulises Olivares-Pinto and Cédric Alaux and Yves {Le Conte} and Didier Crauser and Alberto Prado},
keywords = {Honeybee flight activity, Toxicovigilance, Neurotoxic pesticides, Recurrent neural network},
abstract = {Automatic monitoring devices placed at the entrances of honey bee hives have facilitated the detection of various sublethal effects related to pesticide exposure, such as homing failure and reduced flight activity. These devices have further demonstrated that different neurotoxic pesticide molecules produce similar sublethal impacts on flight activity. The detection of these effects was conducted a posteriori, following the recording of flight activity data. This study introduces a method using an artificial intelligence model, specifically a recurrent neural network, to detect the sublethal effects of pesticides in real-time based on honey bee flight activity. This model was trained on a flight activity dataset comprising 42,092 flight records from 1107 control and 1689 pesticide-exposed bees. The model was able to classify honey bees as healthy or pesticide-exposed based on the number of flights and minutes spent foraging per day. The model was the least accurate (68.46%) when only five days of records per bee were used for training. However, the highest classification accuracy of 99%, a Cohen Kappa of 0.9766, a precision of 0.99, a recall of 0.99, and an F1-score of 0.99 was achieved with the model trained on 25 days of activity data, signifying near-perfect classification ability. These results underscore the highly predictive performance of AI models for toxicovigilance and highlight the potential of our approach for real-time and cost-effective monitoring of risks due to exposure to neurotoxic pesticide in honey bee populations.}
}
@article{JAMEI2024102455,
title = {Quantitative improvement of streamflow forecasting accuracy in the Atlantic zones of Canada based on hydro-meteorological signals: A multi-level advanced intelligent expert framework},
journal = {Ecological Informatics},
volume = {80},
pages = {102455},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102455},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004843},
author = {Mozhdeh Jamei and Mehdi Jamei and Mumtaz Ali and Masoud Karbasi and Aitazaz A. Farooque and Anurag Malik and Saad Javed Cheema and Travis J. Esau and Zaher Mundher Yaseen},
keywords = {Streamflow forecasting, Hydro-meteorological drivers, Multivariate variational mode decomposition, CNN-BiGRU, Boruta-CART, Multi-temporal},
abstract = {Developing reliable streamflow forecasting models is critical for hydrological tasks such as improving water resource management, analyzing river patterns, and flood forecasting. In this research, for the first time, an emerging multi-level TOPSIS (technique for order preference by similarity to the ideal solution) -based hybridization comprised of the Boruta classification and regression tree (Boruta-CART) feature selection, multivariate variational mode decomposition (MVMD), and a hybrid Convolutional Neural Network (CNN) Bidirectional Gated Recurrent Unit (CNN-BiGRU) deep learning was adopted to multi-temporal (one and three days ahead) forecast the daily streamflow in the Rivers of Prince Edward Island, Canada. For this aim, in the first step, the Boruta-CART feature selection technique determines the most effective lagged components among all the antecedent two-day information (i.e., t-1 and t-2) of hydro-meteorological features (from 2015 to 2020), including the water level, mean air temperature, heat degree days, total precipitation, dew point temperature, and relative humidity in the Bear and Winter Rivers of Prince Edward Island, Canada. Afterwards, a multivariate variational mode decomposition (MVMD) decomposes the input time series to decrease the complexity and non-linearity of the non-stationary ones before feeding the deep learning (DL) models. Here, the CNN-GRU was employed as the primary DL model, along with the kernel extreme machine method (KELM), random variational function link (RVFL), and hybrid CNN bidirectional recurrent neural network (CNN-BiRNN) as the comparative models. A TOPSIS scheme applying several performance measures like the correlation coefficient (R), root mean square error (RMSE), and reliability was designed for the robustness assessment of the hybrid (MVM-CNN-BiGRU, MVM-CNN-BiRNN, MVM-RVFL, and MVM-KELM) and standalone models. The computational outcomes revealed that in the Bear River, the MVM-CNN-BiGRU, owing to its best forecasting performance (one day ahead: TOPSIS score 1, R = 0.960, RMSE = 0.098, and reliability = 65.082; three days ahead: TOPSIS score = 0.999, R = 0.924, and RMSE = 0.33) outperformed the other hybrid models, followed by the MVM-CNN-BiRNN, MVM-RVFL, and MVM-KELM, respectively. Moreover, in the Winter River, the MVM-CNN-BiGRU in terms of (one-day ahead: TOPSIS score = 0.890, R = 0.955, RMSE = 0.274, and reliability = 34.004; three-days ahead: TOPSIS score = 0.686, R = 0.924, and RMSE = 0.330) was superior to the other models. The provided expert system could be vital in the local flood decision-making process, in the absence of streamflow information as input modeling, during the flood seasons to reduce flood damage in residential areas.}
}
@article{KEASAR2024102521,
title = {STARdbi: A pipeline and database for insect monitoring based on automated image analysis},
journal = {Ecological Informatics},
volume = {80},
pages = {102521},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102521},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000633},
author = {Tamar Keasar and Michael Yair and Daphna Gottlieb and Liraz Cabra-Leykin and Chen Keasar},
keywords = {Classification, High-throughput screening, Insect monitoring, Machine learning, Object detection, Sticky trap},
abstract = {Insects are highly abundant and diverse, and play major roles in ecosystem functions. Monitoring of insect populations is key to their sustainable management. However, the labor and expertise needed to identify insects, and the challenges of archiving the wealth of data collected in monitoring programs, often limit these efforts. We describe a pipeline to reduce the barriers associated with curating and mining big data of insect biodiversity. The pipeline, STARdbi, includes capturing flying insects with sticky traps, scanning the traps, storing the trap-images in a public database with a web-based interface, and applying machine learning models to extract information from the images. To illustrate the insights that can be gained from STARdbi, we describe two case studies. One of them involves monitoring of circadian activity patterns of grain pests and of their natural enemies, and the other compares insect abundance, biomass and size distributions between agricultural and semi-natural habitats. We invite the community of insect ecologists to contribute to the STARdbi database, and to use its image analysis tools to address diverse ecological and evolutionary questions.}
}
@article{DUBUS2024102642,
title = {From citizen science to AI models: Advancing cetacean vocalization automatic detection through multi-annotator campaigns},
journal = {Ecological Informatics},
volume = {81},
pages = {102642},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102642},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001845},
author = {Gabriel Dubus and Dorian Cazau and Maëlle Torterotot and Anatole Gros-Martial and Paul {Nguyen Hong Duc} and Olivier Adam},
keywords = {Marine bioacoustics, Passive acoustic monitoring, Citizen science, Multi-annotation, Deep learning for automatic detection, Convolutional neural networks, Soft labeling},
abstract = {Continuous underwater Passive Acoustic Monitoring (PAM) has emerged as a strong tool for cetacean research. To handle the vast volume of collected data, it is essential to employ automated detection and classification methods. The recent advancement of deep learning, involving model training and testing, requires a large amount of labeled data. These labels are derived through the manual annotation of audio files often reliant on human experts. Based on an annotation campaign focusing on blue whale calls in the Indian Ocean involving 19 novice annotators and one expert in bioacoustics, this study explores the integration of novice annotators in marine bioacoustics research, through citizen science programs, which could drastically increase the size of labeled datasets and enhance the performance of detection and classification models. The analysis reveals distinctive annotation profiles influenced by the complexity of vocalizations and the annotators' strategies, ranging from conservative to permissive. To address the challenges of annotation discrepancies, Convolutional Neural Networks (CNNs) are trained on annotations from both novices and the expert. The results show variations in model performance. Our work highlights the importance of annotation guidelines encouraging a more conservative approach to improve overall annotation quality. In an effort to optimize the potential of multi-annotation and mitigate the presence of noisy labels, two annotation aggregation methods (majority voting and soft labeling) are proposed and tested. The results demonstrate that both methods, particularly when a sufficient number of annotators are involved, significantly improve model performance and reduce variability: the standard deviation of the area under PR and ROC curves fall under 0.02 for both vocalizations with 13 aggregated annotators, while it was at 0.17 and 0.21 for the Blue Whale Dcalls and 0.05 and 0.04 for the SEIO PBW vocalizations with all annotators separately. Moreover, these aggregation methods enable the training of models using non-expert annotations that achieve performance of models trained with expert annotations. These findings suggest that crowdsourced annotations from novice annotators can be a viable alternative to expert annotations.}
}
@article{MORERA2024102557,
title = {Analysis of climate change impacts on the biogeographical patterns of species-specific productivity of socioeconomically important edible fungi in Mediterranean forest ecosystems},
journal = {Ecological Informatics},
volume = {81},
pages = {102557},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102557},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000992},
author = {Albert Morera and Hannah LeBlanc and Juan {Martínez de Aragón} and José Antonio Bonet and Sergio de-Miguel},
keywords = {Mushroom, , , Non-wood forest products, Global warming, Modeling},
abstract = {In Mediterranean forests, many species of fungi produce fruiting bodies every autumn, some of which are of great social and economic interest as NTFPs. In addition, these fungi are an essential part of the biodiversity network that ensures the proper functioning of natural ecosystems and that is currently in check due to global change. Therefore, understanding the biogeographic patterns of species-specific fungal productivity is fundamental to anticipate possible changes in the socioeconomic value of our forests and to understand the role they play in the functioning of ecosystems in terms of mitigation and adaptation to climate change. In this study we estimate the future impact of climate change (in Catalonia region, between 2023 and 2100) on five fungal species with high socioeconomic interest in a broad bioclimatic gradient representative of the Mediterranean basin using high resolution at the landscape scale. To achieve this, we use predictive models based on machine learning algorithms and a fungal database resulting from the sampling of more than 100 permanent sampling plots over 20 years. We estimate that current and future productivity patterns differ among species, under different climate change scenarios and bioclimatic regions. Our results suggest that optimal productivity areas may be shifted to higher elevations, making those species with higher productivity at higher elevations the most affected by climate change. This would mean that some species with high socioeconomic value, such as Lactarius deliciosus and Boletus edulis, could be negatively affected in their total productivity in the study area. This study highlights the need to anticipate the potential effects of climate change on fungal productivity and in particular on high socioeconomic value species and to develop management policies oriented to maintain the important role of fungi in natural ecosystems.}
}
@article{SINGH2024102751,
title = {Spatial modeling for detection of water retention capacity in technosols developed on carboniferous spoil heap after hard coal mining},
journal = {Ecological Informatics},
volume = {82},
pages = {102751},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102751},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002930},
author = {Pranav Dev Singh and Paweł Hawryło and Anna Klamerus-Iwan and Marcin Pietrzykowski},
keywords = {Anthropocene pressure, Topographic indices, Volumetric water content, PlanetScope satellite imagery, Spatial modeling},
abstract = {Post-industrial areas, such as heaps, are an Anthropocene pressure on the environment but show natural potential for new ecosystem services, i.e., water retention, biodiversity, and C-sequestration. All these ecosystem functions of such sites can be developed only in the case of appropriate reclamation treatments, which are especially difficult under the conditions of carboniferous spoil heaps after coal deep mining. The study of reclamation effects has been increasingly supported in recent years by modern remote sensing techniques. This paper presents the possibilities of using selected remote sensing data and topographic indices and their effect on volumetric water content, which is crucial for habitat development. PlanetScope satellite imagery and airborne laser scanning point clouds were used to estimate the volumetric water content (VWC) of soil. This integrated analysis allows for more accurate spatial modeling of soil moisture, a key indicator of ecological restoration in degraded land. The method of generalized additive models was used to develop a predictive model. The developed predictive model was characterized by the following values of model accuracy evaluation parameters: MAE – 4.1%; RMSE – 5.6%; and R2–0.49. As a result of the analysis, topographic and spectral variables with significant influence on VWC were identified, and a map of the retention capacity of the Sosnica heap was developed.}
}
@article{CARDOSO2024102602,
title = {Can citizen science and social media images support the detection of new invasion sites? A deep learning test case with Cortaderia selloana},
journal = {Ecological Informatics},
volume = {81},
pages = {102602},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102602},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001444},
author = {Ana Sofia Cardoso and Eva Malta-Pinto and Siham Tabik and Tom August and Helen E. Roy and Ricardo Correia and Joana R. Vicente and Ana Sofia Vaz},
keywords = {Artificial intelligence, Convolutional neural networks, Computer vision, Pampas grass},
abstract = {Deep learning has advanced the content analysis of digital data, unlocking opportunities for detecting, mapping, and monitoring invasive species. Here, we tested the ability of open source classification and object detection models (i.e., convolutional neural networks: CNNs) to identify and map the invasive plant Cortaderia selloana (pampas grass) in mainland Portugal. CNNs were trained over citizen science images and then applied to social media content (from Flickr, Twitter, Instagram, and Facebook), allowing to classify or detect the species in over 77% of situations. Images where the species was identified were mapped, using their georeferenced coordinates and time stamp, showing previously unreported occurrences of C. selloana, and a tendency for the species expansion from 2019 to 2021. Our study shows great potential from deep learning, citizen science and social media data for the detection, mapping, and monitoring of invasive plants, and, by extension, for supporting follow-up management options.}
}
@article{GUILBAULT2023102155,
title = {A practical approach to making use of uncertain species presence-only data in ecology: Reclassification, regularization methods and observer bias},
journal = {Ecological Informatics},
volume = {77},
pages = {102155},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102155},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300184X},
author = {Emy Guilbault and Ian Renner and Eric J. Beh and Michael Mahony},
keywords = {Poisson point pattern, Misidentification, Mixture modelling, Machine learning, Observer bias, Lasso penalty},
abstract = {Various statistical models and software platforms aim to produce species distribution models to better predict where species occur as a function of the environment. However, there are many practical challenges that arise with observations coming from opportunistic surveys. Such data may be of low quality with respect to accuracy and may also exhibit sampling bias. Here, we explore three main challenges. First, species identification can be misleading with the changes in taxonomy where the identification of species has changed for some genus, rendering older records confounded with respect to species identity. Second, the observers' sampled pattern may not reflect the true species distribution as some observers may favor some areas where the species is found. Furthermore, ecological knowledge of environmental drivers of a species distribution may be limited, which presents challenges in selecting appropriate covariates to include in species distribution models. In this paper, we extend two algorithms we recently developed which make use of misidentified observations in order to predict species distributions using spatial point processes. In particular, these algorithms incorporate sampling bias correction and address potential overfitting of the model via lasso-type penalties. We compare the performance of these algorithms to models which do not make use of the confounded species data, and explore the effects of the lasso penalty and bias correction on model performance. We apply the best performing methods to a real dataset of eastern Australian frogs for which taxonomy recently changed. Including confounded observations in the models is particularly relevant for informing management decisions regarding endangered species and species in remote areas.}
}
@article{BJERGE2023102278,
title = {Hierarchical classification of insects with multitask learning and anomaly detection},
journal = {Ecological Informatics},
volume = {77},
pages = {102278},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102278},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003072},
author = {Kim Bjerge and Quentin Geissmann and Jamie Alison and Hjalte M.R. Mann and Toke T. Høye and Mads Dyrmann and Henrik Karstoft},
keywords = {nomaly detection, Computer vision, Deep learning, Hierarchical classification, Insects, Taxonomy},
abstract = {Cameras and computer vision are revolutionising the study of insects, creating new research opportunities within agriculture, epidemiology, evolution, ecology and monitoring of biodiversity. However, the diversity of insects and close resemblances of many species are a major challenge for image-based species-level classification. Here, we present an algorithm to hierarchically classify insects from images, leveraging a simple taxonomy to (1) classify specimens across multiple taxonomic ranks simultaneously, and (2) identify the lowest rank at which a reliable classification can be reached. Specifically, we propose multitask learning, a loss function incorporating class dependency at each taxonomic rank, and anomaly detection based on outlier analysis to quantify the uncertainty. First, we compile a dataset of 41,731 images of insects, combining images from time-lapse monitoring of floral scenes with images from the Global Biodiversity Information Facility (GBIF). Second, we adapt state-of-the-art convolutional neural networks, ResNet and EfficientNet, for the hierarchical classification of insects belonging to three orders, five families and nine species. Third, we assess model generalization for 11 species unseen by the trained models. Here, anomaly detection is used to predict the higher rank of the species which were not present in the training set. We found that incorporating a simple taxonomy into our model increased the accuracy at higher taxonomic ranks. As expected, our algorithm correctly classified new insect species at higher taxonomic ranks, while classification was uncertain at lower taxonomic ranks. Anomaly detection can effectively flag novel taxa that are visually distinct from species in the training data. However, five novel taxa were consistently mistaken for visually similar species in the training data. Above all, we have demonstrated a practical approach to hierarchical classification based on species taxonomy and uncertainty during automated in situ monitoring of live insects. Our method is simple and versatile, forming a valuable step towards high-level classification of species not found in training data.}
}
@article{ISLER2024102439,
title = {Hybrid model-based prediction of biomass density in case studies in Turkiye},
journal = {Ecological Informatics},
volume = {79},
pages = {102439},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102439},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004685},
author = {B. İşler and Z. Aslan and F. Sunar and A. Güneş and E. Feoli and D. Gabriels},
keywords = {ANN/W-ANN modelling, Atmospheric data, EVI, LST, NDBI},
abstract = {Growing global concern over natural resource degradation due to urbanisation and population growth emphasizes the critical need for innovative solutions. Addressing this imperative, our study pioneers the integration of cutting-edge artificial intelligence (AI) methods to investigate crucial changes in vegetation density. In this context, a hybrid model, which harmoniously integrates conventional artificial neural network (ANN) models with the innovative Wavelet-ANN (W-ANN) approach, was employed in two case pilot areas, namely on Alanya in Antalya and Iznik in Bursa, Turkiye, renowned for their distinct ecosystems and land cover patterns. By employing diverse data sources, encompassing satellite-derived metrics such as the Enhanced Vegetation Index (EVI) and Land Surface Temperature (LST) from the MODIS/Terra satellite, alongside atmospheric data, our investigation intricately models temporal vegetation dynamics extending to the year 2030. Remarkably, the W-ANN model demonstrates better predictive performance compared to conventional methodologies. It anticipates a substantial 21.4% reduction in vegetation biomass density for Iznik, achieving a minimal 5.4% error probability. Similarly, for Alanya, the model forecasts a notable 6.6% decrease with a remarkably low 2% error probability, both projections extending to the year 2030. Our study reveals a significant reduction in vegetation biomass density by comparing the projected values of the W-ANN model for 2030 with the observed data from 2018. These findings gain further support from an analysis of the Normalised Difference Built-up Index (NDBI) derived from Landsat satellites, affirming the exceptional efficacy of our innovative AI-driven approach in advancing the understanding of urbanisation's impact on ecosystems.}
}
@article{HU2024102695,
title = {A long-term multivariate time series prediction model for dissolved oxygen},
journal = {Ecological Informatics},
volume = {82},
pages = {102695},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102695},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002371},
author = {Jingzhe Hu and Peixuan Wang and Dashe Li and Shue Liu},
keywords = {Dissolved oxygen, Multivariate, Time series, Long-term prediction, Transformer},
abstract = {Accurate and efficient long-term prediction of marine dissolved oxygen (DO) is crucial for the sustainable development of aquaculture. However, the multidimensional time dependency and lag effects of marine chemical variables present significant challenges when handling multiple inputs in univariate long-term prediction tasks. To address these issues, we designed a multivariate time-series long-term prediction model (LMFormer) based on the Transformer architecture. The proposed multivariate time-series decomposition strategy effectively leverages the feature information of prediction variables at different scales, thereby reducing the loss of critical information. Additionally, a dynamic variable selection strategy based on a gating mechanism was designed to optimize the collinearity problem in the multivariate data feature extraction process. Finally, an efficient two-stage attention architecture is proposed to effectively capture the long-range dependencies between dynamic features. This study conducted high-precision 7-day advance DO long-term predictions in two case studies, the environmentally stable Shandong Peninsula in China and the San Juan Islands in the United States, which are affected by extreme conditions such as ocean currents. The experimental results demonstrate the superior prediction performance and generalizability of the designed model. In the Shandong Peninsula case, the mean absolute error (MAE), root mean square error (RMSE), coefficient of determination (R2), and Kling–Gupta efficiency (KGE) reached 0.0159, 0.126, 0.9743, and 0.9625, respectively. In the San Juan Islands case, the MAE was reduced by an average of 42.34% compared to that of the baseline model, the RMSE was reduced by an average of 24.57%, the R2 increased by 22.54%, and the KGE improved by an average of 12.04%. Overall, the proposed prediction model effectively achieves long-term prediction of multivariate marine chemical data, providing valuable references for sustainable management and decision-making in aquaculture.}
}
@article{GONG2023102334,
title = {Research on facial recognition of sika deer based on vision transformer},
journal = {Ecological Informatics},
volume = {78},
pages = {102334},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102334},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003631},
author = {He Gong and Tianye Luo and Lingyun Ni and Ji Li and Jie Guo and Tonghe Liu and Ruilong Feng and Ye Mu and Tianli Hu and Yu Sun and Ying Guo and Shijun Li},
keywords = {Sika deer, Vision transformer, DenseNet, Face recognition, Patch flattening},
abstract = {In the face of global concerns about endangered ecosystems, it is vital to identify individual animals. Along these lines, in this work, a Vision Transformer (ViT) based model for sika deer individual recognition using facial data was designed. To get the satisfactory results, both low-level aspects like texture and color must also be considered, in addition to the high-level semantic information. Consequently, it was difficult to get good results by only applying advanced retrieval features. The standard ViT or ViT with ResNet (Residual neural network) as the backbone network may not be the best solution, as the direct patch flattening method of feature embedded in the conventional ViT is not applicable for performing deer face recognition. Therefore, DenseNet (Densely connected convolutional networks) block as Module 1 was used for extracting low-level features. DenseNet layers enable feature reuse through dense connections, and any layer can communicate directly. Thus maximum exchange of information flow between layers in the network is enabled. In Module 2, the mask approach was also used to eliminate extraneous information from the images and reduce interference from complicated backgrounds on the identification accuracy. In addition, the pixel multiplication of the feature map output from the two modules enabled the fusion of the local features with global features, enriching hence the expressiveness of the feature map. Finally, the ViT structure was run through pre-trained. The experimental results showed that the proposed model can reach an accuracy of 97.68% for identifying sika deer individuals and exhibited excellent generalization capabilities. A valid database for the individual identification of sika deer is provided by our work, significantly contributing to the conservation and promotion of the ecosystem.}
}
@article{YANG2024102477,
title = {Deep learning-based air pollution analysis on carbon monoxide in Taiwan},
journal = {Ecological Informatics},
volume = {80},
pages = {102477},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102477},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000190},
author = {Cheng-Hong Yang and Po-Hung Chen and Chih-Hsien Wu and Cheng-San Yang and Li-Yeh Chuang},
keywords = {Air pollution, Carbon Monoxide (CO), Deep learning, Seasonal gated recurrent unit (SGRU)},
abstract = {Global air pollution poses a threat to humanity. Specifically, CO directly affects cardiovascular and other organ tissues and leads to numerous chronic diseases and major public health problems. The effective implementation of a deep learning model for predicting variations in CO levels would enable the early formulation of policies for controlling air pollution. In this study, a seasonal gated recurrent unit (SGRU) model, which is a deep learning time-series prediction model, was developed to predict the levels of CO in Taiwan. Atmospheric CO measurements from 2005 to 2021 were collected from the Environmental Protection Administration of Taiwan and preprocessed using the Kalman filter to achieve accurate forecasting. The performance of the proposed SGRU model was compared with that of the autoregressive integrated moving average (ARIMA), seasonal ARIMA, exponential smoothing (ETS), Holt–Winters ETS, support vector regression, and seasonal long short-term memory models in terms of mean absolute percentage error (MAPE) and root mean square error. The SGRU model achieved the lowest MAPE value of 0.94, which demonstrated its superior performance. The construction of an accurate air pollution prediction model can assist government entities in formulating health and social care strategies and in planning future air pollution control measures.}
}