@article{WU2024102519,
title = {Optimizing the ecological source area identification method and building ecological corridor using a genetic algorithm: A case study in Weihe River Basin, NW China},
journal = {Ecological Informatics},
volume = {80},
pages = {102519},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102519},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400061X},
author = {Xueting Wu and Jinghu Pan and Xiuwei Zhu},
keywords = {Ecological source areas, Ecological corridors, Genetic algorithm, Graph theory method, Ecological security},
abstract = {Abstract:
The extraction of ecological corridors is influenced by the accuracy of ecological source area identification, which is a crucial component of ecological security construction. The ecological source areas of the Weihe River Basin (WRB) were comprehensively identified by analyzing the supply, demand, and ecological sensitivity of ecosystem services. Different initial populations were set using a genetic algorithm to determine the optimal source areas for the WRB. The minimum cumulative resistance model (MCR) was used to extract the ecological corridors, and then a comparison was made before and after. The results showed that the ecological source areas within the WRB covered approximately 43.362 × 103 km2 in 2020, accounting for 32.38% of the entire area. This included mainly forest, grassland, and a small amount of farmland, of which 89.3% of the ecological source areas were forest. Fifty optimal ecological source areas were obtained using a genetic algorithm, generating 122 ecological corridors with an overall length of 40.245 × 105 km that could disperse the entire WRB. By comparing the ecological source areas before and after optimization, the IIC value of the ecological source areas before optimization was 0.006, the PC value was 0.007, and the FN value was 0.10. The IIC, PC, and FN values of the optimized ecological source area were 0.08, 0.079, and 0.042, respectively. The overall connectivity of the optimal source identified by the genetic algorithm increased by 13.3 times, with a possible connectivity increase of 11.2 times and a 42% reduction in fragmentation. The applicability and reliability in identifying optimal ecological source areas genetic algorithm was high, offering a reliable idea for constructing regional ecological security.}
}
@article{VIZCARRA2021101268,
title = {The Peruvian Amazon forestry dataset: A leaf image classification corpus},
journal = {Ecological Informatics},
volume = {62},
pages = {101268},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101268},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000595},
author = {Gerson Vizcarra and Danitza Bermejo and Antoni Mauricio and Ricardo {Zarate Gomez} and Erwin Dianderas},
keywords = {Leaves dataset, Peruvian Amazon, Deep learning, Visual interpretation, Interpretation},
abstract = {Forest census allows getting precise data for logging planning and elaboration of the forest management plan. Species identification blunders carry inadequate forest management plans and high risks inside forest concessions. Hence, an identification protocol prevents the exploitation of non-commercial or endangered timber species. The current Peruvian legislation allows the incorporation of non-technical experts, called “materos”, during the identification. Materos use common names given by the folklore and traditions of their communities instead of formal ones, which generally lead to misclassifications. In the real world, logging companies hire materos instead of botanists due to cost/time limitations. Given such a motivation, we explore an end-to-end software solution to automatize the species identification. This paper introduces the Peruvian Amazon Forestry Dataset, which includes 59,441 leaves samples from ten of the most profitable and endangered timber-tree species. The proposal contemplates a background removal algorithm to feed a pre-trained CNN by the ImageNet dataset. We evaluate the quantitative (accuracy metric) and qualitative (visual interpretation) impacts of each stage by ablation experiments. The results show a 96.64% training accuracy and 96.52% testing accuracy on the VGG-19 model. Furthermore, the visual interpretation of the model evidences that leaf venations have the highest correlation in the plant recognition task.}
}
@article{KATH2024102710,
title = {Leveraging transfer learning and active learning for data annotation in passive acoustic monitoring of wildlife},
journal = {Ecological Informatics},
volume = {82},
pages = {102710},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102710},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002528},
author = {Hannes Kath and Patricia P. Serafini and Ivan B. Campos and Thiago S. Gouvêa and Daniel Sonntag},
keywords = {Active learning, Transfer learning, Passive acoustic monitoring, BirdNet},
abstract = {Passive Acoustic Monitoring (PAM) has emerged as a pivotal technology for wildlife monitoring, generating vast amounts of acoustic data. However, the successful application of machine learning methods for sound event detection in PAM datasets heavily relies on the availability of annotated data, which can be laborious to acquire. In this study, we investigate the effectiveness of transfer learning and active learning techniques to address the data annotation challenge in PAM. Transfer learning allows us to use pre-trained models from related tasks or datasets to bootstrap the learning process for sound event detection. Furthermore, active learning promises strategic selection of the most informative samples for annotation, effectively reducing the annotation cost and improving model performance. We evaluate an approach that combines transfer learning and active learning to efficiently exploit existing annotated data and optimize the annotation process for PAM datasets. Our transfer learning observations show that embeddings produced by BirdNet, a model trained on high signal-to-noise recordings of bird vocalisations, can be effectively used for predicting anurans in PAM data: a linear classifier constructed using these embeddings outperforms the benchmark by 21.7%. Our results indicate that active learning is superior to random sampling, although no clear winner emerges among the strategies employed. The proposed method holds promise for facilitating broader adoption of machine learning techniques in PAM and advancing our understanding of biodiversity dynamics through acoustic data analysis.}
}
@article{HUNTER2023102076,
title = {Using hierarchical text classification to investigate the utility of machine learning in automating online analyses of wildlife exploitation},
journal = {Ecological Informatics},
volume = {75},
pages = {102076},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102076},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300105X},
author = {Sara Bronwen Hunter and Fiona Mathews and Julie Weeds},
keywords = {Machine learning, Natural language processing, iEcology, Wildlife exploitation, Digital conservation, Social media},
abstract = {Expanding digital data sources, including social media, online news articles and blogs, provide an opportunity to understand better the context and intensity of human-nature interactions, such as wildlife exploitation. However, online searches encompassing large taxonomic groups can generate vast datasets, which can be overwhelming to filter for relevant content without the use of automated tools. The variety of machine learning models available to researchers, and the need for manually labelled training data with an even balance of labels, can make applying these tools challenging. Here, we implement and evaluate a hierarchical text classification pipeline which brings together three binary classification tasks with increasingly specific relevancy criteria. Crucially, the hierarchical approach facilitates the filtering and structuring of a large dataset, of which relevant sources make up a small proportion. Using this pipeline, we also investigate how the accuracy with which text classifiers identify relevant and irrelevant texts is influenced by the use of different models, training datasets, and the classification task. To evaluate our methods, we collected data from Facebook, Twitter, Google and Bing search engines, with the aim of identifying sources documenting the hunting and persecution of bats (Chiroptera). Overall, the ‘state-of-the-art’ transformer-based models were able to identify relevant texts with an average accuracy of 90%, with some classifiers achieving accuracy of >95%. Whilst this demonstrates that application of more advanced models can lead to improved accuracy, comparable performance was achieved by simpler models when applied to longer documents and less ambiguous classification tasks. Hence, the benefits from using more computationally expensive models are dependent on the classification context. We also found that stratification of training data, according to the presence of key search terms, improved classification accuracy for less frequent topics within datasets, and therefore improves the applicability of classifiers to future data collection. Overall, whilst our findings reinforce the usefulness of automated tools for facilitating online analyses in conservation and ecology, they also highlight that the effectiveness and appropriateness of such tools is determined by the nature and volume of data collected, the complexity of the classification task, and the computational resources available to researchers.}
}
@article{GHASEMPOUR2024102560,
title = {Analysis of spatiotemporal variations of drought and soil salinity via integrated multiscale and remote sensing-based techniques (Case study: Urmia Lake basin)},
journal = {Ecological Informatics},
volume = {81},
pages = {102560},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102560},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400102X},
author = {Roghayeh Ghasempour and Mohammad Taghi Aalami and Seyed Mahdi Saghebian and V.S. Ozgur Kirca},
keywords = {Drought, EWT-DSE, Lake shrinkage, Remote sensing, Soil salinity, Urmia basin},
abstract = {In this study, the spatiotemporal variations of drought and salinity were assessed for the Urmia Lake basin, which is a very critical and challenging ecosystem problem. The lowering of water level in the Urmia Lake and the associated risk of becoming a completely saline land has become an important issue in Iran. In the first step of the study, using the ground- and satellite-based datasets, a new multiscale technique based on Empirical Wavelet Transform (EWT) and Differential Symbolic Entropy (DSE) was proposed to monitor the variations of drought in the selected region. In the next step, variations in the water level and salinity of Urmia Lake and its impacts on the environment were investigated using satellite datasets. Results showed that the Southern parts of the basin were more prone to severe droughts, and there was a direct relationship between entropy and drought intensity. Based on the results, it was concluded that climate change had an impact on the shrinkage of the lake; however, these changes were not solely responsible of causing the dramatic water loss of the Lake. Variations of the Salinity Index (SI) showed that saline lands were mostly seen in the Eastern and Southern parts of the lake, causing negative impacts on air quality and agricultural activities in these parts. It was found that the proper management of water resources would play an effective role in the restoration of the lake.}
}
@article{GOMEZFERNANDEZ2024102738,
title = {Landsat images and GIS techniques as key tools for historical analysis of landscape change and fragmentation},
journal = {Ecological Informatics},
volume = {82},
pages = {102738},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102738},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002802},
author = {Darwin Gómez-Fernández and Rolando Salas López and Jhon A. Zabaleta-Santisteban and Angel J. Medina-Medina and Malluri Goñas and Jhonsy O. Silva-López and Manuel Oliva-Cruz and Nilton B. Rojas-Briceño},
keywords = {Fragmentation, LULC, Changes, Classification, Random Forest, Amazon, Forest},
abstract = {Monitoring and evaluation of landscape fragmentation is important in numerous research areas, such as natural resource protection and management, sustainable development, and climate change. One of the main challenges in image classification is the intricate selection of parameters, as the optimal combination significantly affects the accuracy and reliability of the final results. This research aimed to analyze landscape change and fragmentation in northwestern Peru. We utilized accurate land cover and land use (LULC) maps derived from Landsat imagery using Google Earth Engine (GEE) and ArcGIS software. For this, we identified the best dataset based on its highest overall accuracy, and kappa index; then we performed an analysis of variance (ANOVA) to assess the differences in accuracies among the datasets, finally, we obtained the LULC and fragmentation maps and analyzed them. We generated 31 datasets resulting from the combination of spectral bands, indices of vegetation, water, soil and clusters. Our analysis revealed that dataset 19, incorporating spectral bands along with water and soil indices, emerged as the optimal choice. Regarding the number of trees utilized in classification, we determined that using between 10 and 400 decision trees in Random Forest classification doesn't significantly affect overall accuracy or the Kappa index, but we observed a slight cumulative increase in accuracy metrics when using 100 decision trees. Additionally, between 1989 and 2023, the categories Artificial surfaces, Agricultural areas, and Scrub/ Herbaceous vegetation exhibit a positive rate of change, while the categories Forest and Open spaces with little or no vegetation display a decreasing trend. Consequently, the areas of patches and perforated have expanded in terms of area units, contributing to a reduction in forested areas (Core 3) due to fragmentation. As a result, forested areas smaller than 500 acres (Core 1 and 2) have increased. Finally, our research provides a methodological framework for image classification and assessment of landscape change and fragmentation, crucial information for decision makers in a current agricultural zone of northwestern Peru.}
}
@article{KRISNAWIJAYA2024102613,
title = {Reference architecture design for developing data management systems in smart farming},
journal = {Ecological Informatics},
volume = {81},
pages = {102613},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102613},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001559},
author = {Ngakan Nyoman Kutha Krisnawijaya and Bedir Tekinerdogan and Cagatay Catal and Rik {van der Tol}},
keywords = {Domain analysis, Feature model, Reference architecture, Data management, Smart farming},
abstract = {The traditional data management systems prove inadequate to handle the volume, velocity, and variety of the data within farm business processes. Smart farming technologies offer advanced data management systems as a practical solution to these challenges. However, data is complex and originates from many sources; hence many aspects of data must be considered during the data management design of smart farming systems. This study proposes a reference architecture for data management in smart farming, developed through domain analysis and architecture modeling approaches. The domain analysis provides insights into the common and variant features and modules of the smart farming system, resulting in a blueprint representing family features across various smart farming domains. The effectiveness of the proposed reference architecture has been evaluated through two case studies, demonstrating its efficacy in designing data management systems for smart farming. The study found that the percentage of reused modules in the case studies, compared to the provided reference architecture, was 82.6%. The outcomes of this research will pave the way for further exploration in smart farming, particularly addressing data management issues within smart farming systems.}
}
@article{ZHANG2024102556,
title = {A reliable unmanned aerial vehicle multi-target tracking system with global motion compensation for monitoring Procapra przewalskii},
journal = {Ecological Informatics},
volume = {81},
pages = {102556},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102556},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000980},
author = {Guoqing Zhang and Yongxiang Zhao and Ping Fu and Wei Luo and Quanqin Shao and Tongzuo Zhang and Zhongde Yu},
keywords = { monitoring, UAV MOT, GMC, Deep SORT},
abstract = {Procapra przewalskii, which inhabits plateau areas, faces the constant threat of poaching and unpredictable risks that impede its survival. The implementation of a comprehensive, real-time monitoring and tracking system for Procapra przewalskii using artificial intelligence and unmanned aerial vehicle (UAV) technology is crucial to safeguard its existence. Therefore, a UAV multi-object-tracking (MOT) system with global motion compensation (GMC) was proposed in this study. YOLOv7 and Deep SORT were employed for object detection and tracking, respectively. Furthermore, the Kalman filter (KF) in Deep SORT is optimized to enhance the accuracy of object-tracking. Moreover, a novel appearance feature-extraction network (FEN) is introduced to enable more effective multi-scale feature (MSF) extraction. In addition, a GMC module was proposed to align neighboring frames through feature matching. This facilitates the correction of the position of the target in the subsequent frame, mitigating the impact of UAV camera motion on tracking. The results demonstrated the remarkable tracking accuracy of the system. Compared with the Deep SORT model, the proposed system exhibited an increase of 6.4% in MOTA, 2.7% in MOTP, and 7.9% in IDF1. Through a comprehensive evaluation and analysis of real-world tracking scenarios, the system proposed in this study exhibits reliability in complex scenes and holds the potential to significantly enhance the protection of Procapra przewalskii from threats.}
}
@article{VAN2024102601,
title = {Enhancing wildfire mapping accuracy using mono-temporal Sentinel-2 data: A novel approach through qualitative and quantitative feature selection with explainable AI},
journal = {Ecological Informatics},
volume = {81},
pages = {102601},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001432},
author = {Linh Nguyen Van and Vinh Ngoc Tran and Giang V. Nguyen and Minho Yeon and May Thi-Tuyet Do and Giha Lee},
keywords = {Wildfire severity mapping, Machine learning, Sentinel-2, SHAP, Forward stepwise selection},
abstract = {Accurate wildfire severity mapping (WSM) is crucial in environmental damage assessment and recovery strategies. Machine learning (ML) and remote sensing technologies are extensively integrated and employed as powerful tools for WSM. However, the intricate nature of ML algorithms often leads to ‘black box’ systems, obscuring the decision-making process and significantly limiting stakeholders' ability to comprehend the basis of predictions. This opacity hinders efforts to enhance performance and risks exacerbating overfitting. This present study proposes an innovative WSM approach that incorporates qualitative and quantitative feature selection techniques within the Explainable AI (XAI) framework. The methodology aims to enhance the precision of WSM and provide insights into the factors contributing to model decisions, thereby increasing the interpretability of predictions and streamlining models to improve performance. To achieve this objective, we employed the SHapley Additive exPlanations (SHAP)-Forward Stepwise Selection (FSS) method to demonstrate its efficacy in elucidating the qualitative and quantitative impacts of predictors on ML algorithm performance, accuracy, and interpretability designed for WSM. Utilizing post-fire imagery from Sentinel-2 (S2), we analyzed ten bands to generate 225 unique spectral indices utilizing five different calculations: normalized, algebraic sum, difference, ratio, and product forms. Combined with the original S2 bands, this resulted in 235 potential predictors for ML classifications. A random forest model was subsequently developed using these predictors and optimized through extensive hyperparameter tuning, achieving an overall accuracy (OA) of 0.917 and a Kappa statistic of 0.896. The most influential predictors were identified using SHAP values, with an FSS process narrowing them down to the 12 most critical for effective WSM, as evidenced by stabilized OA and Kappa values (0.904 and 0.881, respectively). Further validation using a ninefold spatial cross-validation technique demonstrated the method's consistent performance across different data partitions, with OA values ranging from 0.705 to 0.894 and Kappa values from 0.607 to 0.867. By providing a more accurate and comprehensible XAI-based method for WSM, this research contributes to the broader field of environmental monitoring and disaster response, underscoring the potential of integrated qualitative and quantitative analysis to enhance ML models' capabilities.}
}
@article{STEN2024102670,
title = {A ridge-based detection algorithm with filament overlap identification for 2D mycelium network analysis},
journal = {Ecological Informatics},
volume = {82},
pages = {102670},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102670},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002127},
author = {Oscar Sten and Emanuela {Del Dottore} and Nicola Pugno and Barbara Mazzolai},
keywords = {Mycelium, Network topology, Image analysis},
abstract = {Many terrestrial ecosystems engage mycorrhizal symbiotic associations, potentially to enhance nutrition, increase resistance to soil-borne pests and diseases, and improve resilience and soil structure. Mycorrhizal fungi create dynamic networked structures through branching and anastomosis that connect multiple plants and consent to transport resources underground from nutrient-rich patches to demanding plants. Controlled laboratory experiments are fundamental to improving our knowledge of mycelium network growth dynamics and further understanding its role in preserving ecological niches. We propose a method for highly automated analysis of the mycelium network structure and other morphological properties, such as hyphal length, hyphal density, and number of crossing and branches, in 2D microscopy images of fungal samples. Available tools for automated network analyses suffer from overestimating network connectivity since filament crossings are not considered. In particular, we propose a) a ridge-based mycelium detection algorithm and b) a geometrical-based approach to identify overlapping filaments crossing each other. The algorithmic solution is evaluated on a total of 135 real mycelium sample images over different validation steps, originating from different datasets and having different characteristics, including background, contrast, image acquisition system, fungal species, and clearness (e.g., level of transparency, homogeneity, dirtiness of the medium) of the sample. Results show that 1) the proposed detection method can be used to measure the length of mycelium in an image, replacing manual tracing and allowing for less laborious analysis ρ̂c=0.96, 2) the filament detection is on par with state-of-the-art techniques F1=0.88−0.94 with a more intuitive parameterization, and 3) the proposed algorithm correctly identifies filament crossings F1=0.89 in most common cases, yielding a reduction in the overestimation of network connectivity. The latter feature consents to applying the proposed fully automated solution to complex and irregular fungal structures, advancing mycelium detection and reconstruction performance accuracy with respect to the state-of-the-art.}
}
@article{CROCKER2024102698,
title = {Synthetic data for reef modelling},
journal = {Ecological Informatics},
volume = {82},
pages = {102698},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102698},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002401},
author = {Rose Crocker and Barbara J. Robson and Chinenye Ani and Ken Anthony and Takuya Iwanaga},
keywords = {Synthetic data, Reef modelling, Data pipeline, Model testing and validation, Decision support tools, Machine learning, Neural networks, Synthetic data vault},
abstract = {Synthetic data mimics the statistical properties of real-world datasets while removing reference to sensitive or confidential information in the original dataset (Quintana, 2020). Synthetic data is also useful for general model testing and development, with many methods available for generating data from machine learning models (Raghunathan, 2021). Although not widely used in the context of ecological and environmental modelling, synthetic data can support and accelerate model testing and analyses where rightsholders are sensitive to data disclosure for study areas, or data collection is expensive. In the context of reef modelling, synthetic data can be used to support model analyses that can be published without referring to specific sites, reefs, or study areas. This is desirable in the context of decision support for restoration of the Great Barrier Reef. The Reef has many stakeholders and release of early modelling results for intervention scenarios for specific areas would be premature until management or intervention strategy options have been discussed with stakeholders and/or rightsholders. Synthetic data allows a path to publish model and method demonstrations to share knowledge with the reef decision support community without prematurely suggesting policy recommendations for reefs which are sensitive to rightsholders or stakeholders. We showcase a synthetic data pipeline developed for the reef decision-support system ADRIA (Adaptive Dynamic Reef Intervention Algorithms), using methods from the Python package Synthetic Data Vault (Patki et al., 2016) and others. The synthetic data models are developed to emulate the statistics of case-study reefs for publishing decision-support tool demonstrations, testing and method validation without revealing sensitive reef site information. This pipeline includes developing models for tabular (benthic/compositional reef data), spatial-temporal (wave and heat stress data) and spatial network data (coral larval connectivity). Conditional sampling methods which connect spatial relationships across datasets are used to develop synthetic reef data packages which mimic the statistical properties of the original dataset. The utility of the synthetic data is demonstrated on a sample reef data package, and methods used for anonymizing the data are detailed. The results are discussed in the context of formalizing synthetic data for reef modelling. All synthetic data code is available at ADRIA-synthetic-data/README.md at v0.1.0 · open-AIMS/ADRIA-synthetic-data (github.com), DOI: https://doi.org/10.5281/zenodo.10158323.}
}
@article{LOPEZCOLLADO2024102444,
title = {Bioclimatic similarity between species locations and their environment revealed by dimensionality reduction analysis},
journal = {Ecological Informatics},
volume = {79},
pages = {102444},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102444},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004739},
author = {J. Lopez-Collado and J. Jacinto-Padilla and O. Rodríguez-Aguilar and J.V. Hidalgo-Contreras},
keywords = {Binary classifier, Data visualization, Latent distance, Species distribution modeling, UMAP},
abstract = {Species distribution modeling is an active research topic with applications in conservation management, pest risk assessment, and population ecology. Several machine-learning methods have been applied to estimate species distribution. Non-linear dimensionality reduction techniques aim to preserve the similarity among objects at a reduced dimension for visualization, clustering, and feature selection. We propose a framework that uses Uniform Manifold Approximation and Projection (UMAP) to analyze bioclimatic variables associated with environmental (background) and species samples. Our objective was to identify geographic areas similar to those inhabited by the species. We hypothesize that the similarity between species locations and their environment in the reduced dimension will reflect similarity in the multivariate bioclimatic space. We estimated the probability of background points near a species point utilizing the latent nearest neighbor distance distribution. We tested this procedure with ten insect pest species of global importance and found that UMAP was able to generate a gradient of similarity between geographic areas and species occurrence. We also found that background-species latent distance tends to have a convergent non-linear relationship with the mean value of bioclimatic variables, thus supporting our key assumption. The performance of UMAP as a binary classifier and comparison with MaxEnt supports its use in modeling of species distribution. Potential applications are discussed for multi-species and multi-scenario analysis, as well as projection to new regions.}
}
@article{NODA2024102658,
title = {Predicting habitat suitability for Asian elephants in non-analog ecosystems with Bayesian models},
journal = {Ecological Informatics},
volume = {82},
pages = {102658},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102658},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002000},
author = {Ryoko Noda and Michael Francis Mechenich and Juha Saarinen and Aki Vehtari and Indrė Žliobaitė},
keywords = {Bayesian statistical models, Species distribution modeling, Rewilding, Non-analog ecosystems, },
abstract = {Rewilding is an ambitious approach to conservation aiming at restoring and protecting natural processes. As the world is rapidly transitioning into conditions that have not been observed before, we need to be able to extrapolate and predict how natural processes would act under new conditions. Species distribution models have a good potential to inform rewilding decisions by the predictive modeling of potential species presence under various habitat conditions. A critical requirement when utilizing these models is to be able to express the uncertainty in the environment or its predictions. This study demonstrates the use of Bayesian statistical models to address this challenge. As a case study, we explore Bayesian logistic regression and Bayesian generalized additive models in order to predict suitable habitats for Asian elephants (Elephas maximus) until the year 2070 under the worst case working scenario of climate change. In this comparative study predictions of habitat suitability are solely based on climatic conditions. The results of the two Bayesian models are compared to two benchmark models, maximum-likelihood estimated logistic regression and random forest. We analyze and discuss trade-offs, relative advantages, and limitations of these modeling choices. The results of our analysis suggest that one configuration of Bayesian logistic regression gives the most robust predictions in this setting, which tend to correspond with the distribution of woodland biomes broadly similar to those in the species' historical range.}
}
@article{MCEWEN2024102734,
title = {Active few-shot learning for rare bioacoustic feature annotation},
journal = {Ecological Informatics},
volume = {82},
pages = {102734},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102734},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002760},
author = {Ben McEwen and Kaspar Soltero and Stefanie Gutschmidt and Andrew Bainbridge-Smith and James Atlas and Richard Green},
keywords = {Active learning, Audio classification, Bioacoustics, Few-shot learning, Machine learning},
abstract = {The collection and annotation of bioacoustic data present several challenges to researchers. Bioacoustic monitoring of rare (sparse) or cryptic species generally encounter two main issues. The cost of collecting and processing field data and a lack of labelled datasets for the target species. The detection of invasive species incursions and probability of absence testing is especially challenging due to these species having population densities at or close to zero. We present a methodology specifically designed to aid in the analysis of rare acoustic events within long-term field recordings. This approach combines a wavelet-based segmentation method that automatically extracts transient features from within-field recordings. A few-shot active learning recommender system in a human-in-the-loop process prioritises the annotation of low-certainty samples. This process combines the accuracy of human classification and the speed of computational tools to greatly reduce the presence of non-target features in field recordings. We evaluate this approach using an invasive species identification case study. This methodology achieves a test accuracy of 98.4% as well as 81.2% test accuracy using 2-shot, 2-way prototypical learning without fine-tuning, demonstrating high performance at varying data availability contexts. Active learning using low-certainty samples achieves >90% test accuracy using only 20 training samples compared to 80 samples without active learning. This approach allows users to train custom audio classification models for any application with rare features. The model can be easily exported for use in the field making real-time bioacoustic monitoring of less-vocal species a possibility. All code and data are available at https://github.com/Listening-Lab/Annotator.}
}
@article{PHAM2024102392,
title = {Classifying forest cover and mapping forest fire susceptibility in Dak Nong province, Vietnam utilizing remote sensing and machine learning},
journal = {Ecological Informatics},
volume = {79},
pages = {102392},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102392},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004211},
author = {Van The Pham and Tuyet Anh Thi Do and Hau Duc Tran and Anh Ngoc Thi Do},
keywords = {XGBoost, Forest fire, ABC-ANFIS, Unmanned aerial vehicle, Bamboo and dipterocarp forests},
abstract = {Forest fires can cause significant harm to the biodiversity, air quality, economy, and industries that depend on forests, which is particularly critical given the current climate change scenario. Therefore, it is crucial to predict potential fire risks, especially in Dak Nong, a province located in the highland region of Vietnam, where forest farming is prevalent. In this study, the utilization of remote sensing data from unmanned aerial vehicles (UAV) revealed a decline in forest areas while agricultural rubber and industrial crops witnessed an increase. Furthermore, the integration of SPOT satellite images with UAV and the eXtreme gradient boosting (XGBoost) classification algorithm proved highly efficient in mapping forest types in this province (OA = 81.446%, and Kappa = 0.803). To assess forest fire susceptibility in this study, a hybrid model known as Artificial bee colony-Adaptive neuro fuzzy inference system (ABC-ANFIS) was employed, which indicated that the majority of forests in the area face high to very high of fires, particularly in bamboo and dipterocarp forest areas. The present model is proposed to suggest better prevention and suppression strategies. These facts can help managers stop fires or deal with this disturbance more effectively that may occur in the future. Policymakers and researchers in different areas, such as the limestone forest in the north or the Dipterocarp forests in Vietnam, may consider replicating this study to evaluate specific wildfire risks and develop appropriate fire prevention strategies tailored to their local circumstances.}
}
@article{ZHANG2024102597,
title = {Tracking changes in chlorophyll-a concentration and turbidity in Nansi Lake using Sentinel-2 imagery: A novel machine learning approach},
journal = {Ecological Informatics},
volume = {81},
pages = {102597},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102597},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001390},
author = {Jiawei Zhang and Fei Meng and Pingjie Fu and Tingting Jing and Jie Xu and Xinyue Yang},
keywords = {Sentinel-2, Lake, Machine learning, Model fusion, Chlorophyll-a, Turbidity},
abstract = {This study represents the first application of Sentinel-2 remote sensing imagery and model fusion techniques to assess the chlorophyll-a (Chla) concentration and turbidity in Nansi Lake, Shandong Province, China, from 2016 to 2022. First, we innovatively employed the stacking method to fuse eight fundamentally different Machine Learning (ML) models, each utilising 20 and 17 feature bands, resulting in the development of a robust algorithm for estimating the Chla concentration and turbidity in Nansi Lake. The results demonstrate that the Stacking Model has achieved outstanding theoretical generalisation capability. Second, the sensitivity of the model to extreme value data in the sample was quantified, and we found that compared with extreme gradient boosting (XGBoost), the optimal performance of the Stacking Model improved by 12%, to some extent, it solved the problem of high-value underestimation and low-value overestimation. The SHapley Additive exPlanations (SHAP) results revealed that features such as Three Bands, Enhanced Three, Rrs492/Rrs560, Rrs705/Rrs665 play a crucial role in estimating Chla concentration. For the turbidity estimation, the Normalized Difference Turbidity Index (NDTI), Rrs705+Rrs560, Rrs865-Rrs740 made significant contributions. Finally, we utilised the Stacking Model to create spatiotemporal maps of the Chla concentration and turbidity in Nansi Lake from 2016 to 2022. We analysed the causes of the water quality changes and explored the driving factors. Compared with previous studies, this paper provides a new idea for the monitoring of lake water quality parameters by using the high resolution of Sentinel-2 image and the high precision of model fusion technology, these results can provide a reference for similar water area research and decision-making support for environment-related departments.}
}
@article{TURAB2024102639,
title = {Computational modeling of animal behavior in T-mazes: Insights from machine learning},
journal = {Ecological Informatics},
volume = {81},
pages = {102639},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102639},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400181X},
author = {Ali Turab and Wutiphol Sintunavarat and Farhan Ullah and Shujaat Ali Zaidi and Andrés Montoyo and Josué-Antonio Nescolarde-Selva},
keywords = {Animal behavior, Decision-making, T-mazes, Computational modeling, Solution, Machine learning methods},
abstract = {This study investigates the intricacies of animal decision-making in T-maze environments through a synergistic approach combining computational modeling and machine learning techniques. Focusing on the binary decision-making process in T-mazes, we examine how animals navigate choices between two paths. Our research employs a mathematical model tailored to the decision-making behavior of fish, offering analytical insights into their complex behavioral patterns. To complement this, we apply advanced machine learning algorithms, specifically Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and a hybrid approach involving Principal Component Analysis (PCA) for dimensionality reduction followed by SVM for classification to analyze behavioral data from zebrafish and rats. The above techniques result in high predictive accuracies, approximately 98.07% for zebrafish and 98.15% for rats, underscoring the efficacy of computational methods in decoding animal behavior in controlled experiments. This study not only deepens our understanding of animal cognitive processes but also showcases the pivotal role of computational modeling and machine learning in elucidating the dynamics of behavioral science.}
}
@article{TORRESANI2023102082,
title = {LiDAR GEDI derived tree canopy height heterogeneity reveals patterns of biodiversity in forest ecosystems},
journal = {Ecological Informatics},
volume = {76},
pages = {102082},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102082},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001115},
author = {Michele Torresani and Duccio Rocchini and Alessandro Alberti and Vítězslav Moudrý and Michael Heym and Elisa Thouverai and Patrick Kacic and Enrico Tomelleri},
keywords = {GEDI, Height heterogeneity, Remote sensing, Canopy height model, Rao’s Q index, Species diversity},
abstract = {The “Height Variation Hypothesis” is an indirect approach used to estimate forest biodiversity through remote sensing data, stating that greater tree height heterogeneity (HH) measured by CHM LiDAR data indicates higher forest structure complexity and tree species diversity. This approach has traditionally been analyzed using only airborne LiDAR data, which limits its application to the availability of the dedicated flight campaigns. In this study we analyzed the relationship between tree species diversity and HH, calculated with four different heterogeneity indices using two freely available CHMs derived from the new space-borne GEDI LiDAR data. The first, with a spatial resolution of 30 m, was produced through a regression tree machine learning algorithm integrating GEDI LiDAR data and Landsat optical information. The second, with a spatial resolution of 10 m, was created using Sentinel-2 images and a deep learning convolutional neural network. We tested this approach separately in 30 forest plots situated in the northern Italian Alps, in 100 plots in the forested area of Traunstein (Germany) and successively in all the 130 plots through a cross-validation analysis. Forest density information was also included as influencing factor in a multiple regression analysis. Our results show that the GEDI CHMs can be used to assess biodiversity patterns in forest ecosystems through the estimation of the HH that is correlated to the tree species diversity. However, the results also indicate that this method is influenced by different factors including the GEDI CHMs dataset of choice and their related spatial resolution, the heterogeneity indices used to calculate the HH and the forest density. Our finding suggest that GEDI LIDAR data can be a valuable tool in the estimation of forest tree heterogeneity and related tree species diversity in forest ecosystems, which can aid in global biodiversity estimation.}
}
@article{KALFAS2023102037,
title = {Towards automatic insect monitoring on witloof chicory fields using sticky plate image analysis},
journal = {Ecological Informatics},
volume = {75},
pages = {102037},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102037},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000663},
author = {Ioannis Kalfas and Bart {De Ketelaere} and Klaartje Bunkens and Wouter Saeys},
keywords = {Insect recognition, Convolutional neural networks, Pest management, Automatic monitoring},
abstract = {Context
Sticky trap catches of agricultural pests can be employed for early hotspot detection, identification, and estimation of pest presence in greenhouses or in the field. However, manual procedures to produce and analyze catch results require substantial time and effort. As a result, much research has gone into creating efficient techniques for remotely monitoring possible infestations. A considerable number of these studies use Artificial Intelligence (AI) to analyze the acquired data and focus on performance metrics for various model architectures. Less emphasis, however, was devoted to the testing of the trained models to investigate how well they would perform under practical, in-field conditions.
Objective
In this study, we showcase an automatic and reliable computational method for monitoring insects in witloof chicory fields, while shifting the focus to the challenges of compiling and using a realistic insect image dataset that contains insects with common taxonomy levels.
Methods
To achieve this, we collected, imaged, and annotated 731 sticky plates - containing 74,616 bounding boxes - to train a YOLOv5 object detection model, concentrating on two pest insects (chicory leaf-miners and wooly aphids) and their two predatory counterparts (ichneumon wasps and grass flies). To better understand the object detection model's actual field performance, it was validated in a practical manner by splitting our image data on the sticky plate level.
Results and conclusions
According to experimental findings, the average mAP score for all dataset classes was 0.76. For both pest species and their corresponding predators, high mAP values of 0.73 and 0.86 were obtained. Additionally, the model accurately forecasted the presence of pests when presented with unseen sticky plate images from the test set.
Significance
The findings of this research clarify the feasibility of AI-powered pest monitoring in the field for real-world applications and provide opportunities for implementing pest monitoring in witloof chicory fields with minimal human intervention.}
}
@article{OTERO2024102515,
title = {Surveillance of coastal biodiversity through social network monitoring},
journal = {Ecological Informatics},
volume = {80},
pages = {102515},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102515},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000578},
author = {P. Otero and E. Velasco and J. Valeiras},
keywords = {Coastal biodiversity, Passive citizen science, Twitter, Social media, Spain},
abstract = {Knowledge of marine biodiversity is vital for developing appropriate conservation policies. In the current Information Age, data shared by citizens in social networks are a cost-effective alternative to complement on-going marine biodiversity monitoring programs, as well as to understand human interactions with the natural environment from a current perspective. This information can be obtained in a transparent way to the citizen (passive citizen science approach) after sharing relevant content such as: rare catches of recreational fishermen, sightings of invasive species, stranding of cetaceans, sea turtle entanglements, episodes of massive arrival of jellyfish or interactions between organisms, among others. This study has analyzed the content posted on the social networking site X (formerly known as Twitter) from its launch in 2007 to 2022, focusing on those posts that apparently reported a biodiversity observation along the Spanish coast. To avoid an initial bias, generic messages asking “who knows” or if “anyone knows” what they have found were captured, as well as messages stating that they had found something interesting. After retrieving ∼11 K tweets with potential information, 597 tweets were finally identified after human validation. Most of the observations (21%) corresponded to gelatinous animals, with observations of fish (11%) and marine mammals (11%) also being frequent. 57% of these tweets were adequately located over the coast, drawing the first coastal biodiversity map in Spain based on this methodology. The results show this technique as a low-cost tool complementary to existing monitoring programs, which allows studying the occurrence as well as the temporal variability of non-indigenous and sensitive species, as well as to alert in case of massive coastal arrivals of jellyfish, or stranding of cetaceans or sea turtles, among others.}
}
@article{MONTAGHI2024102433,
title = {An open-source cloud-based procedure for MODIS remote sensing products: The nasawebservicepython package},
journal = {Ecological Informatics},
volume = {79},
pages = {102433},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102433},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004624},
author = {Alessandro Montaghi and Simone Bregaglio and Sofia Bajocco},
keywords = {Smart farming, Open-source software, Python, MODIS, Cloud-application},
abstract = {Living in the era of “big data” demands an increase in the application and development of solutions for data ingestion in agroecological research, both in the private and public sectors. Among available data sources, satellite imagery is a viable solution to acquire large amounts of data at cheaper costs. Although cloud-based commercially distributed services are flourishing, open-source software able to assist practitioners and researchers in downloading and pre-processing satellite imagery is strongly demanded by the remote sensing community. This is especially true when looking at applications developed in Python, a programming language that quickly gained popularity in agroecological science. In this letter, we introduce nasawebservice version 1.0.0, a Python Package designed to automatically collect remotely sensed data from the NASA MODIS/VIIRS Land Products web service. The nasawebservice package contains a set of classes and methods to facilitate download operations for practitioners and researchers and to implement user-friendly data ingestion pipelines in local and cloud environments. The main advantage of nasawebservice is the reduction of pre-processing operations to use satellite images due to getting the data in JSON format, with consequent saving of computational time for large data download and analytic operational pipelines.}
}
@article{LAKDARI2024102457,
title = {Mel-frequency cepstral coefficients outperform embeddings from pre-trained convolutional neural networks under noisy conditions for discrimination tasks of individual gibbons},
journal = {Ecological Informatics},
volume = {80},
pages = {102457},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102457},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004867},
author = {Mohamed Walid Lakdari and Abdul Hamid Ahmad and Sarab Sethi and Gabriel A. Bohn and Dena J. Clink},
keywords = {Vocal individuality, Sound feature extraction, Mel-frequency cepstral coefficients, Convolutional neural networks, Acoustic indices, },
abstract = {Passive acoustic monitoring – an approach that utilizes autonomous acoustic recording units – allows for non-invasive monitoring of individuals, assuming that it is possible to acoustically distinguish individuals. However, identifying effective analytical approaches for individual identification remains a challenge. Our study investigates how the use of different feature representations impacts our ability to distinguish between individual female Northern grey gibbons (Hylobates funereus). We broadcast pre-recorded calls from twelve gibbon females and re-recorded the calls at varying distances (directly under the tree to ∼400 m away) using autonomous recording units. We evaluated the effectiveness of using different automated feature extraction approaches to classify gibbon calls: Mel-frequency cepstral coefficients (MFCCs), embeddings from three pre-trained neural networks (BirdNET, VGGish, and Wav2Vec2), and four commonly used acoustic indices. We used a supervised classification approach (random forest) to classify calls to the respective female and compared two unsupervised clustering approaches (affinity propagation clustering and hierarchical density-based spatial clustering) to evaluate which features were most effective for distinguishing female calls without using class labels. We used MFCCs as a baseline as previous work has shown they can be used to distinguish high-quality calls of individual gibbon females. Human annotators could only identify calls in spectrograms from recordings <350 m from the playback speaker with signal-to-noise ratio ∼ 0 dB, so our results focus on these recordings. Using supervised classification, our results confirmed the efficiency of MFCCs and the use of embeddings from one neural network (BirdNET) for effective acoustic classification of gibbon individuals at closer recording distances (signal-to-noise ratio > 10 dB), while the remaining features did not perform well. Contrary to our expectations, we found that MFCCs outperformed all other features for the unsupervised clustering tasks at closer distances and none of the features performed well at farther distances. The ability to acoustically discriminate animals under noisy conditions and from low signal-to-noise ratio calls has important implications for monitoring populations of endangered animals, such as gibbons. Focusing only on high signal-to-noise ratio calls for individual discrimination may not be possible for rare sounds, and future work should focus on developing effective approaches of feature extraction that can perform well across noisy, real-world conditions with a limited number of training samples.}
}
@article{YANG2024102527,
title = {A systematic study on transfer learning: Automatically identifying empty camera trap images using deep convolutional neural networks},
journal = {Ecological Informatics},
volume = {80},
pages = {102527},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102527},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000694},
author = {Deng-Qi Yang and De-Yao Meng and Hao-Xuan Li and Meng-Tao Li and Han-Lin Jiang and Kun Tan and Zhi-Pang Huang and Na Li and Rong-Hai Wu and Xiao-Wei Li and Ben-Hui Chen and Mei Zhang and Guo-Peng Ren and Wen Xiao},
keywords = {Transfer learning, Camera trap images, ResNext-101, Updating layer selection, Image recognition},
abstract = {Transfer learning is extensively utilized for automatically recognizing and filtering out empty camera trap images that lack animal presence. Current research that uses transfer learning for identifying empty images typically solely updates the fully connected layer of models, and they usually select a pre-trained source model only based on its relevance to the target task. However, they do not consider the optimization of update layer selection, nor do they investigate the effect of sample size and class number of source domain data set used to construct the source model on the performance of the transfer model. Both of these are issues worth exploring. We answered these two issues using three different datasets and the ResNext-101 model. Our experimental results showed that when using 20,000 training samples to transfer the model from the ImageNet dataset to the Snapshot Serengeti dataset, our proposed optimal update layers improved the accuracy of the transfer model from 92.9% to 95.5% (z = −7.087, p < 0.001, N = 8118) compared to the existing method of updating only the fully connected layer. A similar improvement was observed when transferring the model from ImageNet to the Lasha Mountain dataset. Additionally, our results indicated that when using 20,000 training samples to update the pre-trained model and increasing the sample size of the binary-class training dataset used to build the source model from 100,000 to 1 million, the accuracy of the transfer model improved from 90.4% to 93.5% (z = −3.869, p < 0.001, N = 8948). Similar results were obtained when constructing the source domain dataset using ten classifications. Based on these results, we drew the following conclusions: (1) using our proposed optimal update layers instead of the commonly used method of updating only the fully connected layers can significantly improve the model's performance. (2) The optimal update layers varied when the model transferred from different source domain datasets to the same target dataset. (3) The number of classes in the source domain dataset did not significantly impact the transfer model performance. However, the sample size of the source domain dataset positively correlated with the transfer model performance, and there might be a threshold effect.}
}
@article{SZABO2024102624,
title = {Aquatic vegetation mapping with UAS-cameras considering phenotypes},
journal = {Ecological Informatics},
volume = {81},
pages = {102624},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102624},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001663},
author = {Loránd Szabó and László Bertalan and Gergely Szabó and István Grigorszky and Imre Somlyai and György Dévai and Sándor Alex Nagy and Imre J. Holb and Szilárd Szabó},
keywords = {Image classification, Spectral index, Texture index, DSM, Data fusion, UAS, Recursive feature elimination, Aquatic vegetation},
abstract = {Aquatic vegetation species at the genus level in an oxbow lake were identified in Hungary based on a multispectral Uncrewed Aerial System (UAS) survey within an elongated oxbow lake area of the Tisza River under continental climate. Seven and 13 classes were discriminated using three different classification methods (Support Vector Machine [SVM], Random Forest [RF], and Multivariate Adaptive Regression Splines [MARS]) using different input data in ten combinations: original spectral bands, spectral indices, Digital Surface Model (DSM), and Haralick texture indices. We achieved a high (97.1%) overall accuracies (OAs) by applying the SVM classifier, but the RF performed only <1% worse, as it was represented in the first places of the classification rank before the MARS. The highest classification accuracies (>84% OA) were obtained using the most important variables derived by the Recursive Feature Elimination (RFE) method. The best classification required DSM as an input variable. The poorest classification performance belonged to the model that used only texture indices or spectral indices. On the class level, Stratiotes aloides exhibit the lowest degree of separability compared to the other classes. Accordingly, we recommend using supplementary input data for the classifications besides the original spectral bands, for example, DSM, spectral, and texture indices, as these variables significantly improve the classification accuracies in the proper combinations of the input variables.}
}
@article{LONG2024102681,
title = {From meteorological to agricultural drought: Propagation time and influencing factors over diverse underlying surfaces based on CNN-LSTM model},
journal = {Ecological Informatics},
volume = {82},
pages = {102681},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102681},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002231},
author = {Junchen Long and Changchun Xu and Yazhen Wang and Jing Zhang},
keywords = {Drought propagation, Seasonal variation, Hybrid deep learning model, Influencing factors, Land Use and Land Cover},
abstract = {As global warming intensifies and extreme weather events become more frequent, the severity of drought conditions in China's Xinjiang region has escalated. This exacerbates socio-economic pressures in the area and presents increasingly formidable challenges for the future. In response to these challenges, researching drought phenomena in Xinjiang is imperative. This study employs Bayesian methods and copula functions to estimate drought propagation time. It utilizes a hybrid deep learning model (CNN-LSTM) to analyze the process of drought propagation and its influencing factors across four land cover types: crops, forest land, grassland, and unused land. The findings indicate that Cropland experiences the longest average time of drought propagation (5.27 months), while forests have the shortest duration (4.2 months). Unused land and grassland exhibit similar average durations of propagation (4.8 months). On an annual scale, drought propagation time for each land type manifests in two phases: from January to May and from June to December. The former phase shows propagation time ranging from 6 to 9 months, while the latter ranges from 1 to 5 months; both demonstrate an increasing trend over time. Seasonally, all Land Cover Types exhibit a pattern of shorter propagation times in summer and autumn compared with winter and spring. Moreover, a longer time of drought propagation correlates with a greater disparity between meteorological and resultant agricultural drought severity. In analyzing the influence of factors on drought propagation, soil moisture content and El Niño-Southern Oscillation(ENSO) were found to significantly impact all Land Cover Types, progressively strengthening their influence over the years.}
}
@article{ARAUJO2024102388,
title = {Membership inference attack for beluga whales discrimination},
journal = {Ecological Informatics},
volume = {79},
pages = {102388},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102388},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300417X},
author = {Voncarlos M. Araújo and Sébastien Gambs and Robert Michaud and Hadrien Lautraite and Léo Schneider and Clément Chion},
keywords = {Membership inference attack, Animal ecology, -identification, Discrimination, Open-set problem},
abstract = {To efficiently monitor the growth and evolution of a particular wildlife population, one of the fundamental challenges to address in animal ecology is the re-identification of individuals that have been previously encountered but also the discrimination between known and unknown individuals (the so-called “open-set problem”), which is the first step to realize before re-identification. In particular, in this work, we are interested in the discrimination within digital photos of beluga whales, which are known to be among the most challenging marine species to discriminate due to their lack of distinctive features. To tackle this problem, we propose a novel approach based on the use of Membership Inference Attacks (MIAs), which are normally used to assess the privacy risks associated with releasing a particular machine learning model. More precisely, we demonstrate that the problem of discriminating between known and unknown individuals can be solved efficiently using state-of-the-art approaches for MIAs. Extensive experiments on three benchmark datasets related to whales, two different neural network architectures, and three MIA clearly demonstrate the performance of the approach. In addition, we have also designed a novel MIA strategy that we coined as ensemble MIA, which combines the outputs of different MIAs to increase the discrimination accuracy while diminishing the false positive rate. Overall, one of the main objectives of our work is to demonstrate that the study of privacy attacks can also be harnessed positively, assisting in the resolution of practical issues encountered in the field of animal ecology.}
}
@article{LEORNA2022101876,
title = {Human vs. machine: Detecting wildlife in camera trap images},
journal = {Ecological Informatics},
volume = {72},
pages = {101876},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101876},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003260},
author = {Scott Leorna and Todd Brinkman},
keywords = {Confusion matrix, Deep learning, Image analysis, Software, Trail camera},
abstract = {As the capacity to collect and store large amounts of data expands, identifying and evaluating strategies to efficiently convert raw data into meaningful information is increasingly necessary. Across disciplines, this data processing task has become a significant challenge, delaying progress and actionable insights. In ecology, the growing use of camera traps (i.e., remotely triggered cameras) to collect information on wildlife has led to an enormous volume of raw data (i.e., images) in need of review and annotation. To expedite camera trap image processing, many have turned to the field of artificial intelligence (AI) and use machine learning models to automate tasks such as detecting and classifying wildlife in images. To contribute understanding of the utility of AI tools for processing wildlife camera trap images, we evaluated the performance of a state-of-the-art computer vision model developed by Microsoft AI for Earth named MegaDetector using data from an ongoing camera trap study in Arctic Alaska, USA. Compared to image labels determined by manual human review, we found MegaDetector reliably determined the presence or absence of wildlife in images generated by motion detection camera settings (≥94.6% accuracy), however, performance was substantially poorer for images collected with time-lapse camera settings (≤61.6% accuracy). By examining time-lapse images where MegaDetector failed to detect wildlife, we gained practical insights into animal size and distance detection limits and discuss how those may impact the performance of MegaDetector in other systems. We anticipate our findings will stimulate critical thinking about the tradeoffs of using automated AI tools or manual human review to process camera trap images and help to inform effective implementation of study designs.}
}
@article{XU2024102518,
title = {Mapping the potential distribution of Asian elephants: Implications for conservation and human–elephant conflict mitigation in South and Southeast Asia},
journal = {Ecological Informatics},
volume = {80},
pages = {102518},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102518},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000608},
author = {Haixia Xu and Luguang Jiang and Ye Liu},
keywords = {Asian elephant, Maximum entropy, Environmental features, Population characteristics},
abstract = {Asian elephants play a pivotal role in their ecosystem. Understanding the potential distribution area of this species is vital for effective conservation efforts and mitigation of human-elephant conflicts. In this study, we used the maximum entropy to simulate the potential distribution area of Asian elephants across South and Southeast Asia, leveraging Maximum Entropy (MaxEnt) and presence data sourced from the Global Biodiversity Information Facility (GBIF). The analysis revealed that the potential distribution area of Asian elephants spans 530,418 km2 (10.59% of the study area), with significant potential distribution areas observed in Indonesia (136,890 km2) and Malaysia (119,497 km2). Vegetation type emerged as the dominant environmental factor influencing model outcomes, encompassing aspects such as broadleaved evergreen tree coverage, broadleaved deciduous closed tree coverage and EVI. The potential distribution area of Asian elephants overlaps with regions inhabited by 55.25 million people, with 6.07 million people residing in highly suitable habitats. India and Malaysia have high potential for human-elephant conflict (HEC) due to the high number of people living in potential and highly suitable habitats for elephants. Bangladesh and Nepal, on the other hand, have fewer people living in these habitats suitable for elephants, but they face relatively high human population density in these areas.}
}
@article{PIECHAUD2022101786,
title = {Fast and accurate mapping of fine scale abundance of a VME in the deep sea with computer vision},
journal = {Ecological Informatics},
volume = {71},
pages = {101786},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101786},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002369},
author = {Nils Piechaud and Kerry L. Howell},
keywords = {Benthic ecology, Computer vision, Xenophyophores, Quantitative ecology, Mapping, Automated image analysis, Marine conservation},
abstract = {With growing anthropogenic pressure on deep-sea ecosystems, large quantities of data are needed to understand their ecology, monitor changes over time and inform conservation managers. Current methods of image analysis are too slow to meet these requirements. Recently, computer vision has become more accessible to biologists, and could help address this challenge. In this study we demonstrate a method by which non-specialists can train a YOLOV4 Convolutional Neural Network (CNN) able to count and measure a single class of objects. We apply CV to the extraction of quantitative data on the density and population size structure of the xenophyophore Syringammina fragilissima, from more than 58,000 images taken by an AUV 1200 m deep in the North-East Atlantic. The workflow developed used open-source tools, cloud-base hardware, and only required a level of experience with CV commonly found among ecologists. The CNN performed well, achieving a recall of 0.84 and precision of 0.91. Individual counts per image and size measurements resulting from model predictions were highly correlated (0.96 and 0.92, respectively) with manually collected data. The analysis could be completed in less than 10 days thus bringing novel insights into the population size structure and fine scale distribution of this Vulnerable Marine Ecosystem. It showed S. fragilissima distribution is patchy. The average density is 2.5 ind.m−2 but can vary from up to 45 ind.m−2 only a few tens of meter away from areas where it is almost absent. The average size is 5.5 cm and the largest individuals (>15 cm) tend to be in areas of low density. This study demonstrates how researchers could take advantage of CV to quickly and efficiently generate large quantitative datasets data on benthic ecosystems extent and distribution. This, coupled with the large sampling capacity of AUVs could bypass the bottleneck of image analysis and greatly facilitate future deep-ocean exploration and monitoring. It also illustrates the future potential of these new technologies to meet the goals set by the UN Ocean Decade.}
}
@article{PUSHPA2024102611,
title = {On the importance of integrating convolution features for Indian medicinal plant species classification using hierarchical machine learning approach},
journal = {Ecological Informatics},
volume = {81},
pages = {102611},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102611},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001535},
author = {B.R. Pushpa and N. Shobha Rani and M. Chandrajith and N. Manohar and Smitha Sunil Kumaran Nair},
keywords = {Medicinal plant classification, Fusion features, Convolution features, Smartphone images, Inter-class similarities},
abstract = {This work proposes a novel hierarchical classification framework designed to categorize hundred Indian medicinal plant species. The innovation lies in introducing a comprehensive feature representation by integrating convolutional features with geometric, texture, shape, and multispectral features for classification tasks. In this study, a two-level hierarchical plant classification model is proposed to address the challenges of inter-class similarity and intra-class variations. The first level classifies 100 medicinal plant species into 11 groups based on visual similarities among the plants. At level two, the specific plant species containing in each group are predicted using Random Forest classifier. The evaluation is performed at two levels to analyze the effectiveness of the proposed model. The performance analysis compares the effectiveness of individual feature types against the composite feature model. Performance is also evaluated based on specific groups that demonstrate high similarity between classes and intra-class variations among the plant species separately. Furthermore, the generality of the model is tested using two self-created datasets-RTL80 and RTP40, requiring more than 300 man-hours to collect. Experimental results demonstrate a promising accuracy of 94.54% on GSL100 leaf dataset and 75.46% on RTL80 and RTP40 real-time datasets reflecting the superiority of the proposed hierarchical model over state-of-the-art methods.}
}
@article{LUNANARANJO2024102668,
title = {Quantifying and mitigating recorder-induced variability in ecological acoustic indices},
journal = {Ecological Informatics},
volume = {82},
pages = {102668},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102668},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002103},
author = {David Luna-Naranjo and Juan D. Martinez-Vargas and Camilo Sánchez-Giraldo and Juan M. Daza and José D. López},
keywords = {Audio recorders, Ecoacoustics, Ecological acoustic indices, Pre-processing},
abstract = {Due to the complexity of soundscapes, Ecological Acoustic Indices (EAI) are frequently used as metrics to summarize ecologically meaningful information from audio recordings. Recent technological advances have allowed the rapid development of many audio recording devices with significant hardware/firmware variations among brands, whose effects in calculating EAI have not yet been determined. In this work, we show how recordings of the same landscape with different devices effectively hinder reproducibility and produce contradictory results. To address these issues, we propose a preprocessing pipeline to reduce EAI variability resulting from different hardware without altering the target information in the audio. To this end, we tested eight EAI commonly used in soundscape analyses. We targeted three common cases of variability caused by recorder characteristics: sampling frequency, microphone gain variation, and frequency response. We quantified the difference in the probability density functions of each index among recorders according to the Kullback-Leibler divergence. As a result, our approach reduced up to 75% variations among recorders from different brands (AudioMoth and SongMeter) and identified the conditions in which these devices are comparable. In conclusion, we demonstrated that different devices effectively affect EAI and show how these variations can be mitigated.}
}
@article{LI2024102704,
title = {Multi-species identification and number counting of fish passing through fishway at hydropower stations with LigTraNet},
journal = {Ecological Informatics},
volume = {82},
pages = {102704},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102704},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002462},
author = {Jianyuan Li and Chunna Liu and Luhai Wang and Yi Liu and Rui Li and Xiaochun Lu and Jia Lu and Jian Shen},
keywords = {LigTraNet, Fishway monitoring, Artificial intelligence, Lightweight model, Computer vision, Revolutionizes},
abstract = {Fishway monitoring can verify the effectiveness of the fishway, optimise the operation mode, and achieve scientific management of fishway operations. Traditional fishway monitoring approaches, hindered by their inefficiency and substantial disruption of fish, are ill-suited for long-term surveillance; thus, employing video monitoring coupled with object detection technology presents an alternative or complementary solution. However, challenges such as the constrained computational capacity of onsite equipment in fishways, complexities involved in model deployment, and sluggish pace of detection are significant hurdles. In this study, by utilising the YOLOv8n model as a benchmark, we engineered a cross-stage partial module with a single convolution (C1) module to replace the existing C2f module with the aim of enhancing performance. We replaced the conventional 2D convolutions in the bottleneck configuration with depthwise separable convolutions and integrated the SimAM module to extract the detailed characteristics of the fish species. By amalgamating LigObNet detection with the DeepSORT algorithm, we established LigTraNet, which is designed to enable precise tracking, identification, and counting of individual fish. The results showed that LigObNet exhibited the lowest complexity and fastest detection speed for underwater fish among similar object recognition and detection models. Compared with the benchmark YOLOv8n model, there were reductions of 8.9% in the network layers, 40.5% in the parameter count, 39.3% in the memory footprint, and 35.8% in the giga floating-point operations and a 38.1% improvement in the inference speed. LigTraNet achieved a total count accuracy rate of 91.8%, demonstrating superior species quantification capabilities over other models with minimal resource usage and rapid inference capabilities, thus offering enhanced practicality for deployment on devices in real-world engineering contexts. This represents a departure from traditional manual monitoring methods for assessing fishway effectiveness, revolutionising aquatic ecological monitoring tools and methodologies and fostering the collaborative advancement of water resource project operations and ecological conservation.}
}
@article{GUO2024102607,
title = {A novel space–spectrum array tile probability random-forest model enhances LULC mapping accuracy on Google Earth Engine: An experiment in Ordos, China},
journal = {Ecological Informatics},
volume = {81},
pages = {102607},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102607},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001493},
author = {Fuchen Guo and Liangxin Fan and Chengkang Zhang and Sha Xue},
keywords = {Arid zone, LULC, Tile, Multiple probabilistic classification, Space–spectrum array, Random forest, Google earth engine},
abstract = {The rapid renewal of land use and land cover (LULC) maps using remote-sensing technologies constitutes a sine qua non for judicious land resource management at both regional and national scales. Existing research conducted on the Google Earth Engine (GEE) platform has overwhelmingly focused on pixel-based LULC classification techniques, often neglecting the role of spatial context via neighbouring valuable pixel information. Remarkably, little attention has been paid to the amalgamation of 3 × 3 neighbouring pixels into a three-dimensional space–spectrum array that can emulate the functionalities of object-based image analysis. In this study, we developed a novel integrated model consisting of a space–spectrum array (SSA) model based on 3 × 3 neighbouring pixels, a tile model based on random forest, and a multiple probabilistic classification model (SSA-TPRF) on the GEE platform to generate a LULC map with high overall accuracy (OA) for Ordos in 2020. Three bimonthly median value images were synthesised and feature collections, including spectral bands and vegetation indices, were constructed. Five experimental groups (EXP1–EXP5) were used to assess the different model combinations. Subsequent validation procedures employed abundant reference samples and compared the results with those of the three extant LULC mapping products. The results showed that EXP2, which was grounded in the tile-based model, yielded an OA of 87.53%, surpassing that of EXP1 (84.99%), which employed a traditional overall model. Furthermore, EXP3, which integrated the multiple probabilistic classification model with the traditional overall model, exhibited an OA of 85.19%, exceeding that of EXP1. A comparison of the five experimental groups using the four regional spatial subtlety features revealed that the EXP5, employing the SSA-TPRF model, successfully decreased the salt and pepper noise. The OA of six tile sizes ranging from 10 km to 100 km were compared, and the highest OA (88.35%) was achieved at a tile size of 25 km. The resultant LULC map in Ordos, derived from the SSA-TPRF model, showed superior OA compared with the extant LULC products. This study thus contributes to a versatile and scalable model within the GEE framework, offering avenues for facile adaptation and recurrent application across disparate geographical locations and temporal settings. The adaptability of this model is particularly advantageous for developing nations and regions typified by diverse landscapes, thereby catalysing the iterative updating of LULC maps through advanced remote-sensing paradigms.}
}
@article{DEMIRANDA2024102430,
title = {Cellphone picture-based, genus-level automated identification of Chagas disease vectors: Effects of picture orientation on the performance of five machine-learning algorithms},
journal = {Ecological Informatics},
volume = {79},
pages = {102430},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102430},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004594},
author = {Vinícius Lima {de Miranda} and Ewerton Pacheco {de Souza} and Deborah Bambil and Ali Khalighifar and A. Townsend Peterson and Francisco Assis {de Oliveira Nascimento} and Rodrigo Gurgel-Gonçalves and Fernando Abad-Franch},
keywords = {Automated identification, Machine learning, Accuracy, Specificity, Low-resolution pictures, Triatominae},
abstract = {Chagas disease (CD) is a public-health concern across Latin America. It is caused by Trypanosoma cruzi, a parasite transmitted by blood-sucking triatomine bugs. Automated identification of triatomine bugs is a potential means to strengthen CD vector surveillance. To be broadly useful, however, automated systems must draw on algorithms capable of correctly identifying bugs from images taken with ordinary cellphone cameras at varying angles or positions. Here, we assess the performance of five machine-learning algorithms at identifying the main CD vector genera (Triatoma, Panstrongylus, and Rhodnius) based on bugs photographed at different angles/positions with a 72-dpi cellphone camera. Each bug (N = 730; 13 species) was photographed at nine angles representing three positions: dorsal-flat, dorsal-oblique, and front/back-oblique. We randomly split the 6570-picture database into training (80%) and testing sets (20%), and then trained and tested a convolutional neural network (AlexNet, AN); three boosting-based classifiers (AdaBoost, AB; Gradient Boosting, GB; and Histogram-based Gradient Boosting, HB); and a linear discriminant model (LD). We assessed identification accuracy and specificity with logit-binomial generalized linear mixed models fit in a Bayesian framework. Differences in performance across algorithms were mainly driven by AN's essentially perfect accuracy and specificity, irrespective of picture angle or bug position. HB predicted accuracies ranged from ∼0.987 (Panstrongylus, dorsal-oblique) to >0.999 (Triatoma, dorsal-flat). AB accuracy was poor for Rhodnius (∼0.224–0.282) and Panstrongylus (∼0.664–0.729), but high for Triatoma (∼0.988–0.991). For Panstrongylus, LD and GB had predicted accuracies in the ∼0.970–0.984 range. AB misclassified ∼57% of Rhodnius and Panstrongylus as Triatoma, whereas specificity ranged from ∼0.92 to ∼1.0 for the remaining algorithm-genus combinations. Dorsal-flat pictures appeared to improve algorithm performance slightly, but angle/position effects were overall weak-to-negligible. We conclude that, when high-performance algorithms such as AN are used, the angles or positions at which bugs are photographed seem unlikely to hinder cellphone picture-based automated identification of CD vectors, at least at the genus level. Future research should focus on combining mixed-quality pictures and state-of-the-art algorithms to (i) identify triatomine adults to the species level and (ii) distinguish triatomine nymphs (i.e., immature stages) from adults and from other insects.}
}
@article{KISTNER2024102676,
title = {Enhancing endangered species monitoring by lowering data entry requirements with imputation techniques as a preprocessing step for the footprint identification technology (FIT)},
journal = {Ecological Informatics},
volume = {82},
pages = {102676},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102676},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002188},
author = {Frederick Kistner and Justus Tulowietzki and Larissa Slaney and Sky Alibhai and Zoe Jewell and Burim Ramosaj and Markus Pauly},
keywords = {Endangered species, Footprint identification technology, Non-invasive monitoring, Imputation, Missing values, Random Forest},
abstract = {Numerous species of Earth's biota are at risk of extinction and wildlife conservation is more important than ever. Reliable baseline data are essential for wildlife management to inform on the numbers and distribution of endangered species. A promising non-invasive and cost-effective method for monitoring endangered species is the Footprint Identification Technology (FIT). It lends itself to both conservation research as well as citizen science and can be combined with other data collection methods. FIT extracts and uses morphometrics from animal footprints to create geometric profiles that are analyzed in customized classification models. These can identify species, sex and individual. The ability to identify individuals can then be used to predict various population parameters including size, distribution, and growth rate. FIT has been developed and published for several species, but it requires high quality footprints. Perfect prints are not always easy to find in the field as various factors can influence their quality. In this paper, we demonstrate that geometrical profiles derived from poor quality footprints can be seen as datasets with missing values. Missing values are a common problem in various disciplines, and well-established strategies to impute missing values are widely available. We conducted two experiments to see whether such an approach could widen the application of the FIT method. The experiments were designed to test the hypothesis that population sizes can be underestimated when incomplete footprints are discarded from the data. We artificially introduced different proportions of missing values in datasets with geometric profiles of five different species for which FIT models have been published. We also analyzed a new dataset of geometric profiles of cheetah (Acinonyx jubatus) footprints not meeting the standard FIT requirements. We demonstrated that excluding incomplete footprints led to an underestimation of the known population. As an alternative to discarding footprints, we compared different imputation techniques as data pre-processing steps by comparing the performance of resulting FIT models. When imputation was chosen instead, we could show that FIT models with imputed geometric profiles were not significantly less accurate in predicting individual ID or population size even with high rates of missing values. We believe that our findings can be generalized, and the results indicate that imperfect footprints can contribute to the robustness of the FIT method and that this approach is particularly applicable when few good-quality footprints are available. We therefore highly recommend including imputation of imperfect footprints as a data pre-processing step.}
}
@article{AGBOOLA2024102583,
title = {Optimizing landslide susceptibility mapping using machine learning and geospatial techniques},
journal = {Ecological Informatics},
volume = {81},
pages = {102583},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102583},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001250},
author = {Gazali Agboola and Leila Hashemi Beni and Tamer Elbayoumi and Gary Thompson},
keywords = {Landslide susceptibility, Machine learning, Remote sensing, Natural disaster, Data driven},
abstract = {Landslides present a substantial risk to human lives, the environment, and infrastructure. Consequently, it is crucial to highlight the regions prone to future landslides by examining the correlation between past landslides and various geo-environmental factors. This study aims to investigate the optimal data selection and machine learning model, or ensemble technique, for evaluating the vulnerability of areas to landslides and determining the most accurate approach. To attain our objectives, we considered two different scenarios for selecting landslide-free random points (a slope threshold and a buffer-based approach) and performed a comparative analysis of five machine learning models for landslide susceptibility mapping, namely: Support Vector Machine (SVM), Logistic Regression (LR), Linear Discriminant Analysis (LDA), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The study area for this research is an area in Polk County in Western North Carolina that has experienced fatal landslides, leading to casualties and significant damage to infrastructure, properties, and road networks. The model construction process involves the utilization of a dataset comprising 1215 historical landslide occurrences and 1215 non-landslide points. We integrated a total of fourteen geospatial data layers, consisting of topographic variables, soil data, geological data, and land cover attributes. We use various metrics to assess the models' performance, including accuracy, F1-score, Kappa score, and AUC-ROC. In addition, we used the seeded-cell area index (SCAI) to evaluate map consistency. The ensemble of the five models using Weighted Average produces outstanding results, with an AUC-ROC of 99.4% for the slope threshold scenario and 91.8% for the buffer-based scenario. Our findings emphasize the significant impact of non-landslide random sampling on model performance in landslide susceptibility mapping. Furthermore, by optimally identifying landslide-prone regions and hotspots that need urgent risk management and land use planning, our study demonstrates the effectiveness of machine learning models in analyzing landslide susceptibility and providing valuable insights for informed decision-making and disaster risk reduction initiatives.}
}
@article{STAHL2022101557,
title = {Identifying wetland areas in historical maps using deep convolutional neural networks},
journal = {Ecological Informatics},
volume = {68},
pages = {101557},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101557},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122000061},
author = {Niclas Ståhl and Lisa Weimann},
keywords = {Analysis of historical maps, Convolutional neural networks, Wetland management, Wetland restoration},
abstract = {The local environment and land usages have changed a lot during the past one hundred years. Historical documents and materials are crucial in understanding and following these changes. Historical documents are, therefore, an important piece in the understanding of the impact and consequences of land usage change. This, in turn, is important in the search of restoration projects that can be conducted to turn and reduce harmful and unsustainable effects originating from changes in the land-usage. This work extracts information on the historical location and geographical distribution of wetlands, from hand-drawn maps. This is achieved by using deep learning (DL), and more specifically a convolutional neural network (CNN). The CNN model is trained on a manually pre-labelled dataset on historical wetlands in the area of Jönköping county in Sweden. These are all extracted from the historical map called “Generalstabskartan”. The presented CNN performs well and achieves a F1-score of 0.886 when evaluated using a 10-fold cross validation over the data. The trained models are additionally used to generate a GIS layer of the presumable historical geographical distribution of wetlands for the area that is depicted in the southern collection in Generalstabskartan, which covers the southern half of Sweden. This GIS layer is released as an open resource and can be freely used. To summarise, the presented results show that CNNs can be a useful tool in the extraction and digitalisation of non-textual information in historical documents, such as historical maps. A modern GIS material that can be used to further understand the past land-usage change is produced within this research. Previously, no material of this detail and extent have been available, due to the large effort needed to manually create such. However, with the presented resource better quantifications and estimations of historical wetlands that have been lost can be made.}
}
@article{YOU2023102200,
title = {Segmentation of individual mangrove trees using UAV-based LiDAR data},
journal = {Ecological Informatics},
volume = {77},
pages = {102200},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102200},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002297},
author = {Haotian You and Yao Liu and Peng Lei and Zhigang Qin and Qixu You},
keywords = {LiDAR data, CHM, Segmentation algorithm, Stand density, Spatial resolution},
abstract = {Accurate assessment of structural parameters is essential to effectively monitor the mangrove resources. However, the extraction results of mangrove structural parameters are closely related to the segmentation results of individual trees. Although the results of individual tree segmentation are influenced by many factors, the specific factors affecting the segmentation results of individual mangrove trees, such as data source, image resolution, segmentation algorithm, and stand density, have not yet been elucidated. Therefore, in this study, canopy height models (CHMs) with different spatial resolutions were derived from unmanned aerial vehicle (UAV)-based light detection and ranging (LiDAR) data. Moreover, the watershed algorithm (WA), regional growth (RG), and improved K-nearest neighbour (KNN) and bird's eye view (BEV) faster region-based convolutional neural network (R-CNN) algorithms were used to segment the individual mangrove trees based on CHMs and LiDAR data at three sites with varying stand densities. Finally, different segmentation algorithms, image resolutions, and forest densities were comparatively assessed to determine their influence on the segmentation results of individual trees. Segmentation accuracy of the improved KNN algorithm was the highest among the CHM-based algorithms, such as the WA, RG, and improved KNN algorithms, with an optimal F of 0.893 and minimum F of 0.628. R-CNN algorithm based on LiDAR data had an optimal F value of 0.931 and minimum F value of 0.612. Based on the segmentation results, the overall accuracy ranking of the different segmentation algorithms was BEV Faster R-CNN > improved KNN > RG > WA. The ranking of the segmentation results for sites with different stand densities was low-density (LD) > medium-density (MD) > high-density (HD). For LD and MD sites, the BEV Faster R-CNN algorithm had the highest F values (0.931 and 0.712, respectively). For the HD site, all algorithms performed poorly, and the F values of all algorithms, except the RG algorithm, were higher than 0.6. Based on the segmentation results of different spatial resolutions, CHM result with 0.1 m was the best, being better than the CHM results with 0.25 and 0.5 m. Our results demonstrated that all segmentation algorithms, spatial resolutions, and stand densities affected the segmentation results for individual mangrove trees. Although the segmentation results of the deep learning algorithm were better than those of the other algorithms, the segmentation results at the HD site were limited. Therefore, further research is necessary to improve the accuracy of the segmentation results for individual mangrove trees at HD sites.}
}
@article{MANZANORUBIO2022101910,
title = {Low-cost open-source recorders and ready-to-use machine learning approaches provide effective monitoring of threatened species},
journal = {Ecological Informatics},
volume = {72},
pages = {101910},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101910},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003600},
author = {Robert Manzano-Rubio and Gerard Bota and Lluís Brotons and Eduardo Soto-Largo and Cristian Pérez-Granados},
keywords = {Autonomous recording unit, BirdNET, , Eurasian bittern, Kaleidoscope Pro, Passive acoustic monitoring, Wildlife monitoring},
abstract = {Passive acoustic monitoring is a powerful tool for monitoring vocally active taxa. Automated signal recognition software reduces the expert time needed for recording analyses and allows researchers and managers to manage large acoustic datasets. The application of state-of-the-art techniques for automated identification, such as Convolutional Neural Networks, may be challenging for ecologists and managers without informatics or engineering expertise. Here, we evaluated the use of AudioMoth — a low-cost and open-source sound recorder — to monitor a threatened and patchily distributed species, the Eurasian bittern (Botaurus stellaris). Passive acoustic monitoring was carried out across 17 potential wetlands in north Spain. We also assessed the performance of BirdNET — an automated and freely available classifier able to identify over 3000 bird species — and Kaleidoscope Pro — a user-friendly recognition software — to detect the vocalizations and the presence of the target species. The percentage of presences and vocalizations of the Eurasian bittern automatically detected by BirdNET and Kaleidoscope Pro software was compared to manual annotations of 205 recordings. The species was effectively recorded up to distances of 801–900 m, with at least 50% of the vocalizations uttered within that distance being manually detected; this distance was reduced to 601–700 m when considering the analyses carried out using Kaleidoscope Pro. BirdNET detected the species in 59 of the 63 (93.7%) recordings with known presence of the species, while Kaleidoscope detected the bittern in 62 recordings (98.4%). At the vocalization level, BirdNet and Kaleidoscope Pro were able to detect between 76 and 78%, respectively, of the vocalizations detected by a human observer. Our study highlights the ability of AudioMoth for detecting the bittern at large distances, which increases the potential of that technique for monitoring the species at large spatial scales. According to our results, a single AudioMoth could be useful for monitoring the species' presence in wetlands of up to 150 ha. Our study proves the utility of passive acoustic monitoring, coupled with BirdNET or Kaleidoscope Pro, as an accurate, repeatable, and cost-efficient method for monitoring the Eurasian bittern at large spatial and temporal scales. Nonetheless, further research should evaluate the performance of BirdNET on a larger number of species, and under different recording conditions (e.g., more closed habitats), to improve our knowledge about BirdNET's ability to perform bird monitoring. Future studies should also aim to develop an adequate protocol to perform effective passive acoustic monitoring of the Eurasian bittern.}
}
@article{VANOSTA2023102233,
title = {An active learning framework and assessment of inter-annotator agreement facilitate automated recogniser development for vocalisations of a rare species, the southern black-throated finch (Poephila cincta cincta)},
journal = {Ecological Informatics},
volume = {77},
pages = {102233},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102233},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002625},
author = {John M. {van Osta} and Brad Dreis and Ed Meyer and Laura F. Grogan and J. Guy Castley},
keywords = {Bioacoustics, Machine learning, Annotator agreement, Call recognition, Active learning},
abstract = {The application of machine learning methods has led to major advances in the development of automated recognisers used to analyse bioacoustics data. To further improve the performance of automated call recognisers, we investigated the development of efficient data annotation strategies and how best to address uncertainty around ambiguous vocalisations. These challenges present a particular problem for species whose vocalisations are rare in field recordings, where collecting enough training data can be problematic and a species' vocalisations may be poorly documented. We provide an open access solution to address these challenges using two strategies. First, we applied an active learning framework to iteratively improve a convolutional neural network (CNN) model able to automate call identification for a target rare bird species, the southern black-throated finch (Poephila cincta cincta). We collected 9098 h of unlabelled audio recordings from a field study in the Desert Uplands Bioregion of Queensland, Australia, and used active learning to prioritise human annotation effort towards data that would best improve model fit. Second, we progressed methods for managing ambiguous vocalisations by applying machine learning methods more commonly used in medical image analysis and natural language processing. Specifically, we assessed agreement among human annotators and the CNN model (i.e. inter-annotator agreement) and used this to determine realistic performance outcomes for the CNN model and to identify areas where inter-annotator agreement may be improved. We also applied a classification approach that allowed the CNN model to classify sounds into an ‘uncertain’ category, which replicated a requirement of human-annotation and facilitated the comparison of human-model annotation performance. We found that active learning was an efficient strategy to build a CNN model where there was limited labelled training data available, and target calls were extremely rare in the unlabelled data. As few as five active learning iterations, generating a final labelled dataset of 1073 target calls and 5786 non-target sounds, were required to train a model to identify the target species with comparable performance to experts in the field. Assessment of inter-annotator agreement identified a bias in our model to align predictions most closely with those of the primary annotator and identified significant differences in inter-annotator agreement among subsets of our acoustic data. Our results highlight the use of inter-annotator agreement to understand model performance and identify areas for improvement in data annotation. We also show that excluding ambiguous vocalisations during data annotation results in an overestimation of model performance, an important consideration for datasets with inter-annotator disagreement.}
}
@article{GARCIARODRIGUEZ2024102638,
title = {Predicting the fundamental fluxes of an eddy-covariance station using machine learning methods},
journal = {Ecological Informatics},
volume = {81},
pages = {102638},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102638},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001808},
author = {David Garcia-Rodriguez and Pablo Catret Ruber and Domingo J. {Iglesias Fuente} and Juan José Martínez Durá and Ernesto López Baeza and Antonio Garcia Celda},
keywords = {Eddy covariance fluxes, Machine learning, Deep learning, Agricultural crops, Surface energy balance},
abstract = {Monitoring tools are needed to maximise living systems' ability to mitigate emissions and adapt to changing environmental conditions. Therefore, it is important to be able to predict the fundamental fluxes in crops, in this case vineyards, such as sensible heat flux (H), latent heat flux (LE) and carbon dioxide flux (CO2), in order to know their capacity to adapt to the environmental effects of climate change. In this study, Linear Regression (LR), Elastic Net (EN) regression, K-Nearest Neighbours (KNN), Gaussian-Process (GP), Decision Tree (TREE) Regression, Random Forest (RF) Regression, XGBoost (XGB) Regression, Support Vector Regression (SVR) and Multi-layer Perceptron (MLP) models have been applied to predict fundamental fluxes of an eddy-covariance station from conventional meteorological parameters. These models reproduced well the estimations of three output parameters from the eddy-covariance station. The performance of each predictive model was evaluated using Root-Mean-Squared Error (RMSE), Mean Absolute Error (MAE), Mean Square Error (MSE), Mean Absolute Percentage Error (MAPE), Mean Absolute Scaled Error (MASE) and the coefficient of determination (R2). The findings indicate that for the variable H, the GP model outperformed the SVR and all other models, achieving an R2 value of 0.99. Conversely, the SVR demonstrated superior performance for the variables LE and CO2, with R2 values of 0.96 for both. In summary, these findings suggest that the three models proposed show a robust performance in the prediction of the studied fluxes, underlining their versatility and adaptability to the various environmental conditions of the vineyard.}
}
@article{FENG2024102501,
title = {An ensembled method for predicting dissolved oxygen level in aquaculture environment},
journal = {Ecological Informatics},
volume = {80},
pages = {102501},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102501},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000438},
author = {Dachun Feng and Qianyu Han and Longqin Xu and Ferdous Sohel and Shahbaz Gul Hassan and Shuangyin Liu},
keywords = {Aquaculture monitoring, Dissolved oxygen level estimation, Water quality assessment},
abstract = {Dissolved oxygen (DO) level is an important indicator aquaculture quality. This study proposes an ensembled method, WTD-GWO-SVR, combining wavelet threshold denoising (WTD), grey wolf optimization (GWO), and support vector regression (SVR) for accurately predicting DO levels. Addressing challenges such as high noise, poor data quality, and non-linearity and non-stationary properties of time series data, our method integrates SVR for regression-based estimation, WTD for data denoising, and GWO for optimizing the SVR parameters and the Gaussian kernel's radial basis function. We collected a dataset using a variety of low-cost sensors in a real aquaculture setting. Our comprehensive evaluation on the dataset demonstrates that WTD-GWO-SVR achieved mean squared error, mean absolute error, and R2 values of 0.38%, 3.81%, and 99.73%, respectively. It also consistently outperformed the back-propagation neural network and the long short-term memory model. It also achieved superior computational time performance compared to these methods. The high throughput and accuracy of WTD-GWO-SVR make it a potential choice for DO level prediction in water quality monitoring systems.}
}
@article{SARKAR2024102598,
title = {Ensembling machine learning models to identify forest fire-susceptible zones in Northeast India},
journal = {Ecological Informatics},
volume = {81},
pages = {102598},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102598},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001407},
author = {Mriganka Shekhar Sarkar and Bishal Kumar Majhi and Bhawna Pathak and Tridipa Biswas and Soumik Mahapatra and Devendra Kumar and Indra D. Bhatt and Jagadish C. Kuniyal and Sunil Nautiyal},
keywords = {Forest fire risk, Variable inflation factor analysis, Ensemble forecasting, Statistical modeling, Forest fire management},
abstract = {Forest fires pose significant challenges by disrupting ecological balance, impacting socio-economic harmony, and raising global concerns. North-East India (NEI) experiences high incidences of forest fires, making it crucial to implement suitable management measures considering the driving forces influencing fire likelihood. This study aims to identify forest fire susceptibility zones in NEI by using five machine-learning modeling approaches, Boosted Regression Tree (BRT), Random Forest (RF), Support Vector Machine (SVM), Classification and Regression Tree (CART), and Multivariate Adaptive Regression Splines (MARS), and an ensemble method. Forest fire data from the SNPP – VIIRS sensor (2018–2019) were rectified for spatial autocorrelation. Thirty-two responsive predictor variables related to topographic, climatic, biophysical, and anthropogenic factors were used as model inputs and multicollinearity analysis was performed to eliminate highly correlated predictors. Results indicate that the southern and southeastern regions of NEI, characterized by ample solar radiation, enhanced vegetation index, high human population density, and jhum cultivation, contribute significantly to higher susceptibility to forest fires. The Random Forest model performs best among the models employed, achieving an AUC value of 0.87. The ensemble susceptibility map, binarized based on AUC weighting, covers 29.54% of the total geographic area and 44.42% of the forested area of NEI. The vulnerability levels vary among states, with Mizoram showing the highest susceptibility at 89.27% and Sikkim exhibiting the lowest vulnerability at only 0.49% of their respective geographic areas. This map provides valuable insights for implementing effective forest fire management plans in the region. Moreover, the methodology utilized in this study, which incorporates satellite imagery, GIS techniques, and improved modeling techniques, can be replicated in any geographical region worldwide to facilitate effective forest fire management at a regional to large scale.}
}
@article{PARK2024102719,
title = {Generalizability evaluations of heterogeneous ensembles for river health predictions},
journal = {Ecological Informatics},
volume = {82},
pages = {102719},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102719},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002619},
author = {Taeseung Park and Jihoon Shin and Baekyung Park and Jeongsuk Moon and YoonKyung Cha},
keywords = {River health, Multimetric biological indices, Generalizability, Bias–variance decomposition, Heterogenous ensembles, SHapley additive exPlanations},
abstract = {Predictive models leverage the relationships between environmental factors and river health to predict the river health at unmonitored sites. Such models should be generalizable to unseen data. Among various machine learning models, heterogeneous ensembles are known to be generalizable owing to their structural diversity. The present study compares the generalizability of heterogeneous ensembles with those of homogeneous ensembles and single models. The models classified five grades (very good to very poor) of river health indices (RHIs) for three taxa (benthic macroinvertebrates, fish, and diatoms) given various environmental factors (water quality, hydrology, meteorological, land cover, and stream properties) as inputs. The data were monitored at 2915 sites in the four major river watersheds in South Korea during the 2016–2021 period. The results indicated better generalizability of the heterogeneous and homogeneous ensembles than single models. Moreover, heterogeneous ensembles tended to show higher generalizability than homogeneous ensembles, although the differences were marginal. Weighted soft voting was the most generalizable of the heterogeneous ensembles, with losses ranging from 0.49 to 0.59 across the three taxa. Weighted soft voting also delivered acceptable classification performance on the test set, with accuracies ranging from 0.42 to 0.52 across the taxa. The relative contributions of the environmental factors to RHI predictions and the directions of their effects agreed with established knowledge, confirming the reliability of the predictions. However, as heterogeneous ensembles have been rarely applied to RHI prediction, the extent to which heterogeneous ensembles improve the generalizability of prediction must be investigated in future studies.}
}
@article{KURU2023102285,
title = {Intelligent airborne monitoring of irregularly shaped man-made marine objects using statistical Machine Learning techniques},
journal = {Ecological Informatics},
volume = {78},
pages = {102285},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102285},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300314X},
author = {Kaya Kuru and Stuart Clough and Darren Ansell and John McCarthy and Stephanie McGovern},
keywords = {Marine ecosystems, Marine man-made objects, Statistical ML, HSV colour space, Object detection, ROC curve, Aerial surveys},
abstract = {The marine economy has historically been highly diversified and prolific due to the fact that the Earth's oceans comprise two-thirds of its total surface area. As technology advances, leading enterprises and ecological organisations are building and mobilising new devices supported by cutting-edge marine mechatronics solutions to explore and harness this challenging environment. Automated tracking of these types of industries and the marine life around them can help us figure out what's causing the current changes in species numbers, predict what could happen in the future, and create the right policies to help reduce the environmental impact and make the planet more sustainable. The objective of this study is to create a new platform for the automated detection of irregularly shaped man-made marine objects (ISMMMOs) in large datasets derived from marine aerial survey imagery. In this context, a novel nonparametric methodology, which harbours several hybrid statistical Machine Learning (ML) methods, was developed to automatically segment ISMMMOs on the sea surface in large surveys. This methodology was validated on a wide range of marine domains, providing robust empirical proof of concept. This approach enables the detection of ISMMMOs automatically, without any prior training, with accuracy (ACC), Matthews correlation coefficient (MCC), negative predictive value (NPV), positive predictive value (PPV), specificity (Sp) and sensitivity(Se) over 0.95. The outlined methodology can be utilised for a variety of purposes, but it's especially useful for researchers and policymakers who want to keep an eye on how the maritime industry is deploying and make sure the right policies are in place to meet regulatory and legal requirements to promote maritime tech innovation and shape what the future looks like for the marine ecosystem. For the first time in the literature, a method, the so-called ISMMMOD, has been developed to automate the detection of all types of ISMMMOs by statistical ML techniques that require no prior training, which will pioneer the monitoring of human footprint in the marine ecosystem.}
}
@article{GACHOKI2024102610,
title = {Towards accurate spatial prediction of Glossina pallidipes relative densities at country-scale in Kenya},
journal = {Ecological Informatics},
volume = {81},
pages = {102610},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102610},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001523},
author = {Stella Gachoki and Thomas A. Groen and Anton Vrieling and Andrew Skidmore and Daniel Masiga},
keywords = {Tsetse abundance, Machine learning, Vector borne diseases, Spatial extrapolations, Satellite data, Random forest},
abstract = {Vector-borne diseases, like those transmitted by tsetse flies, pose a significant global public health threat. Reducing vector populations is a promising strategy for disease control, especially in the case of tsetse-transmitted African trypanosomiasis. However, the cost-effective implementation of large-scale vector surveillance and control measures face challenges due to the lack of spatially explicit and reliable maps identifying vector hotspots. In this study, we assessed the accuracy of predicting Glossina pallidipes relative densities across Kenya by linking constrained in-situ tsetse catch data from 660 traps across three Kenyan regions with readily available gridded satellite information (human population, land cover, soil properties, elevation, precipitation, and land surface temperature) using a classical random forest algorithm. To enhance predictive performance, we employed two feature elimination techniques specifically designed for machine learning algorithms, i.e., Recursive Feature Elimination (RFE) and Variable Selection Using Random Forests (VSURF). For each set of retained variables, we trained a Random Forest model using a spatial cross-validation technique. Our findings showed that tsetse fly relative densities decreased with mean annual precipitation, and soil moisture, and conversely increased with higher tree cover. Based on the cross-validated R2, 41% of the spatial variability in relative densities of tsetse flies could be explained. For spatial extrapolation, only the set of predictors retained by VSURF closely matched known tsetse fly distributions in Kenya. This more accurate performance of VSURF may be attributed to its approach of assessing variables for both importance and their contribution to reducing prediction error. Our study demonstrates the potential of using a random forest method to upscale tsetse relative abundance predictions to the national level. However, the reliability of the current extrapolated map remains uncertain. We recommend: 1) increasing tsetse fly sampling efforts, particularly in the data-limited northern and eastern regions of Kenya, and 2) developing a more precise and accurate land cover map with classes that directly associate with known habitat characteristics of the target tsetse species.}
}
@article{KAUKAB2024102691,
title = {Improving real-time apple fruit detection: Multi-modal data and depth fusion with non-targeted background removal},
journal = {Ecological Informatics},
volume = {82},
pages = {102691},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102691},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002334},
author = {Shaghaf Kaukab and  Komal and Bhupendra M Ghodki and Hena Ray and Yogesh B. Kalnar and Kairam Narsaiah and Jaskaran S. Brar},
keywords = {Apple, Fruit detection, 3D localization, YOLO network, RGB-D images, Depth sensor},
abstract = {In automated fruit detection, RGB-Depth (RGB-D) images aid the detection model with additional depth information to enhance detection accuracy. However, outdoor depth images are usually of low quality, which limits the quality of depth data. In this study, an approach/technique for real-time apple fruit detection in a high-density orchard environment by using multi-modal data is presented. Non-targeted background removal using the depth fusion (NBR-DF) method was developed to reduce the high noise condition of depth images. The noise occurred due to the uncontrolled lighting condition and holes with incomplete depth information in the depth images. NBR-DF technique follows three primary steps: pre-processing of depth images (point cloud generation), target object extraction, and background removal. The NBR-DF method serves as a pipeline to pre-process multi-modal data to enhance features of depth images by filling holes to eliminate noise generated by depth holes. Further, the NBR-DF implemented with the YOLOv5 enhances the detection accuracy in dense orchard conditions by using multi-modal information as input. An attention-based depth fusion module that adaptively fuses the multi-modal features was developed. The integration of the depth-attention matrix involved pooling operations and sigmoid normalization, both of which are efficient methods for summarizing and normalizing depth information. The fusion module improves the identification of multiscale objects and strengthens the network's resistance to noise. The network then detects the fruit position using multiscale information from the RGB-D images in highly complex orchard environments. The detection results were compared and validated with other methods using different input modals and fusion strategies. The results showed that the detection accuracy using the NBR-DF approach achieved an average precision rate of 0.964 in real time. The performance comparison with other state-of-the-art methods and the model generalization study also establish that the present advanced depth-fusion attention mechanism and effective preprocessing steps in NBR-DF-YOLOv5 significantly surpass those in performance. In conclusion, the developed NBR-DF technique showed the potential to improve real-time apple fruit detection using multi-modal information.}
}
@article{CHEN2024102594,
title = {Tradeoffs among multi-source remote sensing images, spatial resolution, and accuracy for the classification of wetland plant species and surface objects based on the MRS_DeepLabV3+ model},
journal = {Ecological Informatics},
volume = {81},
pages = {102594},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102594},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001365},
author = {Zizhen Chen and Jianjun Chen and Yuemin Yue and Yanping Lan and Ming Ling and Xinhong Li and Haotian You and Xiaowen Han and Guoqing Zhou},
keywords = {Wetland, UAV image, Satellite image, Spatial resolution, DeepLabV3 +, Multi-resolution segmentation},
abstract = {Classification of wetland plant species (PlatSpe) and surface objects (SurfObj) in remote sensing images faces significant challenges due to the high diversity of PlatSpe and the fragmented nature of SurfObj. Unmanned aerial vehicle (UAV) images and satellite images are the primary data sources for the classification of wetland PlatSpe and SurfObj. However, there is still insufficient research on the effect of various data sources and spatial resolutions on the classification results. This study essentially focuses on Huixian Wetland in Guilin, Guangxi, China through utilizing UAV images and satellite images with varying spatial resolutions as data sources. To this end, the MRS_DeepLabV3+ model is constructed based on multi-resolution segmentation and DeepLabV3+, and the wetland PlatSpe and SurfObj are appropriately classified based on this model. The obtained results reveal that: (1) MRS_DeepLabV3+ model with optimal scale parameter (SP) is capable of achieving higher classification accuracy compared to DeepLabV3+. The optimal SPs for both UAV images and satellite images gradually lessen with decreasing the spatial resolution, and satellite images require larger SPs compared to UAV images. (2) In both the UAV and satellite image models, both OA and kappa exhibit a decreasing trend with the reduction of the spatial resolution. (3) The overall classification accuracies of the satellite image models are superior to the UAV image models in the spatial resolution intervals of 2 to 16 m. This investigation can be regarded as a valuable reference for selecting data sources and spatial resolutions in the wetland PlatSpe and SurfObj classification.}
}
@article{KRIVOGUZ2024102513,
title = {Geo-spatial analysis of urbanization and environmental changes with deep neural networks: Insights from a three-decade study in Kerch peninsula},
journal = {Ecological Informatics},
volume = {80},
pages = {102513},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102513},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000554},
author = {Denis Krivoguz},
keywords = {Urbanization dynamics, Kerch Peninsula, Land cover change, Environmental implications, Sustainable development, Remote sensing, GIS analysis, Natural ecosystems, Climate change},
abstract = {This study presents a comprehensive analysis of land use and land cover (LULC) changes on the Kerch Peninsula over the last thirty years, utilizing advanced satellite data and spatial modeling techniques. The research used Landsat 5, 7 and 8 satellite images to capture the intricate dynamics of LULC changes from 1990 to 2020. A quantitative approach was adopted, involving the use of convolutional neural networks (CNN) for enhanced classification accuracy. This methodology allowed for a detailed and precise identification of various LULC classes, revealing significant trends and transformations in the region's landscape. The spatial modeling incorporated in this study allowed exploration of both large-scale patterns and localized changes, providing insights into the drivers and consequences of LULC dynamics. The statistical analysis revealed a notable increase in urbanized areas, coupled with a decline in natural ecosystems such as forests and wetlands. These changes reflect the impact of sustained urban growth and agricultural expansion, underscoring the need for informed land management and conservation strategies. The study findings contribute to understanding urbanization processes and their ecological implications, providing valuable guidance for sustainable regional planning and environmental protection.}
}
@article{SIVRIKAYA2024102461,
title = {Forest fire risk mapping with Landsat 8 OLI images: Evaluation of the potential use of vegetation indices},
journal = {Ecological Informatics},
volume = {79},
pages = {102461},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102461},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000037},
author = {Fatih Sivrikaya and Alkan Günlü and Ömer Küçük and Okan Ürker},
keywords = {Remote sensing, Normalized band indices, Fire risk map, NBR},
abstract = {Fire is one of the most important natural catastrophes threatening the forest ecosystem. The severity and frequency of forest fires are increasing daily due to the increase in population in vulnerable areas and the effects of global climate change. Creating fire risk maps and using them to take the required protective actions to prevent fires will decrease the adverse effects of forest fires. This study focused on producing and comparing fire risk maps based on four vegetation indices, the Normalized Burn Ratio (NBR) index, Normalized Burn Ratio Thermal (NBRT) index, Normalized Difference Vegetation Index (NDVI), and Normalized Difference Water Index (NDWI) and data gathered with the use of remote sensing devices. The Muğla Regional Directorate of Forestry, which is in the Mediterranean climate zone and has experienced mega-fires, was selected as the case study area. Fire risk maps were prepared for the four vegetation indices from Landsat 8 OLI satellite images. Receiver operating characteristic curves and 195 fire ignition points that occurred in 2021 from July 5 to the end of the year were used to assess the accuracy of fire risk maps. Most fire ignition locations (>90%) were in high- and extremely high-risk fire areas on the maps prepared according to the NBR, NDWI, and NDVI. The fact that almost all of the fires occurred in high-risk areas revealed that the study area was sensitive to fire and that the vegetation indices used to draw up the risk maps were highly accurate in predicting where fires might occur. The accuracy results showed that the area under the curve was 0.842 for the NBR, 0.835 for the NDWI, 0.812 for the NBRT, and 0.810 for the NDVI. The NBR approach was more precise than the other models in providing information for fire risk maps. Risk maps created with the NBR could help decision-makers to take precautions and minimize fire damage.}
}
@article{LEBIEN2020101113,
title = {A pipeline for identification of bird and frog species in tropical soundscape recordings using a convolutional neural network},
journal = {Ecological Informatics},
volume = {59},
pages = {101113},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101113},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120300637},
author = {Jack LeBien and Ming Zhong and Marconi Campos-Cerqueira and Julian P. Velev and Rahul Dodhia and Juan Lavista Ferres and T. Mitchell Aide},
keywords = {Acoustic monitoring, Bioacoustics, Sound classification, Convolutional neural network, Deep learning},
abstract = {Automated acoustic recorders can collect long-term soundscape data containing species-specific signals in remote environments. Ecologists have increasingly used them for studying diverse fauna around the globe. Deep learning methods have gained recent attention for automating the process of species identification in soundscape recordings. We present an end-to-end pipeline for training a convolutional neural network (CNN) for multi-species multi-label classification of soundscape recordings, starting from raw, unlabeled audio. Training data for species-specific signals are collected using a semi-automated procedure consisting of an efficient template-based signal detection algorithm and a graphical user interface for rapid detection validation. A CNN is then trained based on mel-spectrograms of sound to predict the set of species present in a recording. Transfer learning of a pre-trained model is employed to reduce the necessary training data and time. Furthermore, we define a loss function that allows for using true and false template-based detections to train a multi-class multi-label audio classifier. This approach leverages relevant absence (negative) information in training, and reduces the effort in creating multi-label training data by allowing weak labels. We evaluated the pipeline using a set of soundscape recordings collected across 749 sites in Puerto Rico. A CNN model was trained to identify 24 regional species of birds and frogs. The semi-automated training data collection process greatly reduced the manual effort required for training. The model was evaluated on an excluded set of 1000 randomly sampled 1-min soundscapes from 17 sites in the El Yunque National Forest. The test recordings contained an average of ~3 present target species per recording, and a maximum of 8. The test set also showed a large class imbalance with most species being present in less than 5% of recordings, and others present in >25%. The model achieved a mean-average-precision of 0.893 across the 24 species. Across all predictions, the total average-precision was 0.975.}
}
@article{LYU2024102383,
title = {Deer survey from drone thermal imagery using enhanced faster R-CNN based on ResNets and FPN},
journal = {Ecological Informatics},
volume = {79},
pages = {102383},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102383},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004120},
author = {Haitao Lyu and Fang Qiu and Li An and Douglas Stow and Rebecca Lewison and Eve Bohnett},
keywords = {UAV, Faster R-CNN, ResNet, FPN, Thermal image, Small object detection},
abstract = {Deer surveys play an important role in the estimation of local ecological balance. In the Chitwan National Park of Nepal, the dense tree canopies and tall vegetation often obscure the presence of wild deer, which has a negative effect on the accurate population surveys of wild deer. UAVs equipped with infrared sensors have been increasingly used to monitor wild deer by capturing a lot of images. How to automatically recognize and obtain the number of deer objects from thermal images is becoming an important research topic. Due to the difference between thermal images and true-color images, as well as the variations in deer object sizes in these two types of images, current ready-to-use object detection models, designed for true-color imagery, are ill-suited for the task of detecting small deer objects within thermal imagery. In this paper, an enhanced Faster R-CNN was constructed to detect small deer objects from thermal images, in which a Feature Pyramid Network (FPN) based on a residual network is used to improve feature extraction for small deer objects and multi-scale feature map constrution for the subsequent region proposals searching, bounding box regression, and regions of interest (RoIs) classification. In addition, small-scaled anchor boxes and a multi-scale feature map selection criterion are devised to improve the detection accuracy of small objects. Finally, based on Faster R-CNN, FPN, and different residual networks including ResNet18, ResNet34, ResNet50, ResNet101, and ResNet152, we constructed five object detection models, and evaluated their detection performance by using COCO evaluation matrix. Under the condition of IoU≥0.5, the integration of Faster R-CNN, FPN, and ResNet18 demonstrated to perform better than others. Specifically, The COCO evaluation results revealed an Average Precision (AP) score of 91.6% for all deer objects. Small deer objects (area ≤ 200 pixels) achieved an AP score of 73.6%, medium deer objects (200 < area ≤ 400 pixels) demonstrated an AP score of 93.4%, and large deer objects (area > 400 pixels) achieved the highest AP score of 94.3%. Our research is helpful for effective wild deer monitoring and conservation and can be a valuable reference for the exploration of small object detection from low-resolution thermal images.}
}
@article{POUTARAUD2024102687,
title = {Meta-Embedded Clustering (MEC): A new method for improving clustering quality in unlabeled bird sound datasets},
journal = {Ecological Informatics},
volume = {82},
pages = {102687},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102687},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002292},
author = {Joachim Poutaraud and Jérôme Sueur and Christophe Thébaud and Sylvain Haupert},
keywords = {Bird sounds, Ecoacoustics, meta-learning, Unsupervised learning, Dimensionality reduction, Spectrogram},
abstract = {In recent years, ecoacoustics has offered an alternative to traditional biodiversity monitoring techniques with the development of passive acoustic monitoring (PAM) systems allowing, among others, to detect and identify species that are difficult to detect by human observers, automatically. PAM systems typically generate large audio datasets, but using these monitoring techniques to infer ecologically meaningful information remains challenging. In most cases, several thousand hours of recordings need to be manually labeled by experts limiting the operability of the systems. Based on recent developments of meta-learning algorithms and unsupervised learning techniques, we propose here Meta-Embedded Clustering (MEC), a new method with high potential for improving clustering quality in unlabeled bird sound datasets. MEC method is organized in two main steps, with: (a) fine-tuning of a pretrained convolutional neural network (CNN) backbone with different meta-learning algorithms using pseudo-labeled data, and (b) clustering of manually-labeled bird sounds in the latent space based on vector embeddings extracted from the fine-tuned CNN. The MEC method significantly enhanced average clustering performance from less than 1% to more than 80%, greatly outperforming the traditional approach of relying solely on CNN features extracted from a general neotropical audio database. However, this enhanced performance came with the cost of excluding a portion of the data categorized as noise. By improving the quality of clustering in unlabeled bird sound datasets, the MEC method should facilitate the work of ecoacousticians in managing acoustic units of bird song/call clustered according to their similarities, and in identifying potential clusters of species undetected using traditional approaches.}
}
@article{MARTINEZSANCHEZ2022101757,
title = {Skyline variations allow estimating distance to trees on landscape photos using semantic segmentation},
journal = {Ecological Informatics},
volume = {70},
pages = {101757},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101757},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002072},
author = {Laura Martinez-Sanchez and Daniele Borio and Raphaël d'Andrimont and Marijn {van der Velde}},
keywords = {Semantic segmentation, Conditional random fields, COCO, Landscape, Openness, Image depth},
abstract = {Approximate distance estimation can be used to determine fundamental landscape properties including complexity and openness. We show that variations in the skyline of landscape photos can be used to estimate distances to trees on the horizon. A methodology based on the variations of the skyline has been developed and used to investigate potential relationships with the distance to skyline objects. The skyline signal, defined by the skyline height expressed in pixels, was extracted for a set of 148 Land Use/Cover Area frame Survey (LUCAS) landscape photos. Photos were semantically segmented with DeepLabV3+ trained with the Common Objects in Context (COCO) dataset. This provided pixel-level classification of the objects forming the skyline. A Conditional Random Fields (CRF) algorithm was also applied to increase the details of the skyline signal. Three metrics, able to capture the skyline signal variations, were then considered for the analysis. These metrics shows a functional relationship with distance for the class of trees, whose contours have a fractal nature. In particular, regression analysis was performed against 475 ortho-photo based distance measurements, and, in the best case, a R2 score equal to 0.47 was achieved. This is an encouraging result which shows the potential of skyline variation metrics for inferring distance related information.}
}
@article{DARIANE2024102452,
title = {Maximum energy entropy: A novel signal preprocessing approach for data-driven monthly streamflow forecasting},
journal = {Ecological Informatics},
volume = {79},
pages = {102452},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102452},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004818},
author = {Alireza B. Dariane and Mohammad Reza {M. Behbahani}},
keywords = {Signal preprocessing, Maximum-energy-entropy, Monthly streamflow forecasting, Input variable selection, Genetic programming, Wavelet-entropy},
abstract = {In recent years, the application of Data-Driven Models (DDMs) in ecological studies has garnered significant attention due to their capacity to accurately simulate complex hydrological processes. These models have proven invaluable in comprehending and predicting natural phenomena. However, to achieve improved outcomes, certain additive components such as signal analysis models (SAM) and input variable selections (IVS) are necessary. SAMs unveil hidden characteristics within time series data, while IVS prevents the utilization of inappropriate input data. In the realm of ecological research, understanding these patterns is pivotal for grasping the ecological implications of streamflow dynamics and guiding effective management decisions. Addressing the need for more precise streamflow forecasting, this study proposes a novel SAM called “Maximum Energy Entropy (MEE)” to forecast monthly streamflow in the Ajichai basin, located in northwestern Iran. A comparative analysis was conducted, pitting MEE against well-known methods such as Discreet Wavelet (DW) and Discreet Wavelet-Entropy (DWE), ultimately demonstrating the superiority of MEE. The results showcased the superior performance of our proposed method, with an NSE value of 0.72, compared to DW (NSE value of 0.68) and DWE (NSE value of 0.68). Furthermore, MEE exhibited greater reliability, boasting a lower Standard Deviation value of 0.13 compared to DW (0.26) and DWE (0.19). The utilization of MEE equips researchers and decision-makers with more accurate predictions, facilitating well-informed ecological management and water resource planning. To further evaluate MEE's accuracy using various DDMs, we integrated MEE with Artificial Neural Network (ANN) and Genetic Programming (GP). Additionally, GP served as an IVS method for selecting appropriate input variables. Ultimately, the combination of MEE and GP within the ANN forecasting model (MEE-GP-ANN) yielded the most favorable results.}
}
@article{TAKIMOTO2021101466,
title = {Using a two-stage convolutional neural network to rapidly identify tiny herbivorous beetles in the field},
journal = {Ecological Informatics},
volume = {66},
pages = {101466},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101466},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002570},
author = {Hironori Takimoto and Yasuhiro Sato and Atsushi J. Nagano and Kentaro K. Shimizu and Akihiro Kanagawa},
keywords = {Entomology, Fine-grained image classification, Deep learning, Herbivory, Small object detection},
abstract = {Recently, deep convolutional neural networks (CNN) have been adopted to help non-experts identify insect species from field images. However, the application of these methods on the rapid identification of tiny congeneric species moving across heterogeneous background remains difficult. To improve rapid and automatic identification in the field, we customized an existing CNN-based method for a field video involving two Phyllotreta beetles. We first performed data augmentation using transformations, syntheses, and random erasing of the original images. We then proposed a two-stage method for the detection and identification of small insects based on CNN, where YOLOv4 and EfficientNet were used as a detector and a classifier, respectively. Evaluation of the model revealed that one-step object detection by YOLOv4 alone was not precise (Precision=0.55) when classifying two species of flea beetles and background objects. In contrast, the two-step CNNs improved the precision (Precision=0.89) with moderate accuracy (F-measure=0.55) and acceptable speed (ca. 5 frames per second for full HD images) of detection and identification of insect species in the field. Although real-time identification of tiny insects remains a challenge in the field, our method aids in improving small object detection on a heterogeneous background.}
}
@article{GHOSH2024102581,
title = {HPB3C-3PG algorithm: A new hybrid global optimization algorithm and its application to plant classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102581},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102581},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001237},
author = {Sukanta Ghosh and Amar Singh and Shakti Kumar},
keywords = {Optimization problem, HPB3C-3PGA, Hybrid algorithm, CEC’21 benchmark function, PB3C, 3PGA, Exploration, Exploitation, Image classification},
abstract = {This paper proposes a hybrid bio-inspired search and optimization algorithm that combines the strengths of the PB3C (Parallel Big Bang Big Crunch) and 3PGA (3 Parent Genetic Algorithm) algorithms. The hybrid algorithm employs a single population-based evolutionary search coupled with multi-population parallel processing techniques to address optimization problems. The proposed algorithm is implemented in MATLAB software. We evaluate the performance of the proposed algorithm on the CEC2021 standard test bench suite. The performance of the proposed approach is compared with that of the other nine algorithms. The comparative analysis shows that the proposed hybrid PB3C and 3PGA algorithms performed better than the other nine optimization algorithms. Furthermore, this chapter proposes an HPB3C-3PGA-based approach to evolve the near-optimal architecture of CNN. The proposed plant image classification approach is implemented in Python and compared with 12 other approaches. The proposed approach achieved an accuracy of 98.96% on the Mendeley dataset and 98.97% on the CVIP100 dataset. The proposed approach outperforms all other approaches for the plant leaf classification problem. This research significantly contributes to overcoming limitations in existing approaches, providing a robust solution for optimization problems and image classification tasks.}
}
@article{SWAMINATHAN2024102471,
title = {Multi-label classification for acoustic bird species detection using transfer learning approach},
journal = {Ecological Informatics},
volume = {80},
pages = {102471},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102471},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400013X},
author = {Bhuvaneswari Swaminathan and M. Jagadeesh and Subramaniyaswamy Vairavasundaram},
keywords = {Wav2vec, Transformers, Transfer learning, Multi-label, Bird species classification, Audio classification},
abstract = {As part of ornithology, bird species classification is vital to understanding species distribution, habitat requirements and environmental changes that affect bird populations. It is possible for ornithologists to assess the health of a certain habitat by tracking changes in bird species distributions. This work has extended an efficient transfer learning technique for labelling and classifying multiple bird species from real-time audio recordings. For this purpose, Wav2vec is fine-tuned using the back propagation technique, which makes the feature extractor more effective in learning each bird's pitch and other sound characteristics. To perform the task, each audio recording has been clipped as chunks from the overlapping audio to determine multi-labels from it. Through the application of transfer learning, the features of audio recordings have been automatically extracted for classification and fed to a feed-forward network. Subsequently, probabilities associated with each audio segment is aggregated through the clipping approach to represent multiple species of bird call. These probability scores are then used to determine the presence of predominant bird species in the audio recording for multi-labelling. The proposed Wav2vec demonstrates remarkable performance, achieving an F1-score of 0.89 using the Xeno-Canto dataset in which outperforming other multi-label classifiers.}
}
@article{NOORI2024102565,
title = {Lake total suspended matter retrieval by wind speed: A machine learning model trained by time-series satellite imagery},
journal = {Ecological Informatics},
volume = {81},
pages = {102565},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102565},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001079},
author = {Ashkan Noori and Seyed Hossein Mohajeri and Mojtaba Mehraein and Ahmad Sharafati},
keywords = {Chah-Nimeh reservoirs, Lake water quality, Neural network, Satellite images, Total suspended matter, Wind speed},
abstract = {This study aims to develop an affordable and continuous method for monitoring water quality in arid, remote areas with high erosion rates. It presents a hypothesis that establishes a link between the concentration of Total Suspended Matter (TSM) and wind speed, emphasizing its ecological importance in lakes with dry conditions and high erosion rates. Building upon this hypothesis, the study introduces Wind2TSM-Net, a machine learning model that effectively bridges between different regression and neural network algorithms. This model connects on-site wind speed measurements with TSM data obtained through a physically remote sensing approach. It accurately predicts TSM concentration values, overcoming challenges such as cloud interference and reducing reliance on satellite imagery. The model was applied to Iran's Chah-Nimeh Reservoirs (CNRs) as a case study in an arid and remote area. The results revealed a significant correlation between TSM concentration and wind speed measurements, with impressive performance metrics (coefficient of determination (R2) = 0.88, root mean square error (RMSE) = 1.97 g/m3, mean absolute error (MAE) = 1.33). These findings highlight the effectiveness of Wind2TSM-Net in monitoring TSM values in remote and dry regions, particularly during extreme weather conditions when on-site measurements are impractical or cloud cover obstructs satellite observations.}
}
@article{BRAVOSANCHEZ2024102593,
title = {Improved analysis of deep bioacoustic embeddings through dimensionality reduction and interactive visualisation},
journal = {Ecological Informatics},
volume = {81},
pages = {102593},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102593},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001353},
author = {Francisco J. {Bravo Sanchez} and Nathan B. English and Md Rahat Hossain and Steven T. Moore},
keywords = {Bioacoustics, Deep neural networks, Embeddings, Dimensionality reduction},
abstract = {Deep neural networks (DNN) are a popular tool to process environmental sounds and identify sound-producing animals, but it can be difficult to understand the decision-making logic, particularly when it does not produce the expected results. Here we describe a new and enhanced visual interactive analysis of embeddings and explore its application in bioacoustics. Embeddings are the output of the penultimate layer of a DNN, an N-dimensional vector that, only one step removed from the final output, represent the inner-workings of a DNN model. Using existing dimensionality reduction techniques we converted the N-dimensional embeddings into 2 or 3-dimensional arrays displayed in scatterplots. By incorporating sound samples into the scatterplots we developed a visual and aural interactive interface and demonstrate its utility in assessing the performance of trained bioacoustic models, facilitating post-processing of results, error detection, input selection and the detection of rare events, which the reader can experience in online examples with publicly available code.}
}
@article{JAHANBAKHT2023102303,
title = {Semi-supervised and weakly-supervised deep neural networks and dataset for fish detection in turbid underwater videos},
journal = {Ecological Informatics},
volume = {78},
pages = {102303},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102303},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003321},
author = {Mohammad Jahanbakht and Mostafa {Rahimi Azghadi} and Nathan J. Waltham},
keywords = {Weakly-supervised classifier, Self-supervised learning, Deep neural networks, Contrastive learning, Transfer learning, XGBoost ensemble, Fish detection, Highly turbid waters},
abstract = {Fish are key members of marine ecosystems, and they have a significant share in the healthy human diet. Besides, fish abundance is an excellent indicator of water quality, as they have adapted to various levels of oxygen, turbidity, nutrients, and pH. To detect various fish in underwater videos, Deep Neural Networks (DNNs) can be of great assistance. However, training DNNs is highly dependent on large, labeled datasets, while labeling fish in turbid underwater video frames is a laborious and time-consuming task, hindering the development of accurate and efficient models for fish detection. To address this problem, firstly, we have collected a dataset called FishInTurbidWater, which consists of a collection of video footage gathered from turbid waters, and quickly and weakly (i.e., giving higher priority to speed over accuracy) labeled them in a 4-times fast-forwarding software. Next, we designed and implemented a semi-supervised contrastive learning fish detection model that is self-supervised using unlabeled data, and then fine-tuned with a small fraction (20%) of our weakly labeled FishInTurbidWater data. At the next step, we trained, using our weakly labeled data, a novel weakly-supervised ensemble DNN with transfer learning from ImageNet. The results show that our semi-supervised contrastive model leads to more than 20 times faster turnaround time between dataset collection and result generation, with reasonably high accuracy (89%). At the same time, the proposed weakly-supervised ensemble model can detect fish in turbid waters with high (94%) accuracy, while still cutting the development time by a factor of four, compared to fully-supervised models trained on carefully labeled datasets. Our dataset and code are publicly available at the hyperlink FishInTurbidWater.}
}
@article{BAYR2019220,
title = {Automatic detection of woody vegetation in repeat landscape photographs using a convolutional neural network},
journal = {Ecological Informatics},
volume = {50},
pages = {220-233},
year = {2019},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2019.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S1574954118303121},
author = {Ulrike Bayr and Oskar Puschmann},
keywords = {Repeat photography, Photo monitoring, Landscape monitoring, Landscape change, Vegetation succession, Machine learning},
abstract = {Repeat photography is an efficient method for documenting long-term landscape changes. So far, the usage of repeat photographs for quantitative analyses is limited to approaches based on manual classification. In this paper, we demonstrate the application of a convolutional neural network (CNN) for the automatic detection and classification of woody regrowth vegetation in repeat landscape photographs. We also tested if the classification results based on the automatic approach can be used for quantifying changes in woody vegetation cover between image pairs. The CNN was trained with 50 × 50 pixel tiles of woody vegetation and non-woody vegetation. We then tested the classifier on 17 pairs of repeat photographs to assess the model performance on unseen data. Results show that the CNN performed well in differentiating woody vegetation from non-woody vegetation (accuracy = 87.7%), but accuracy varied strongly between individual images. The very similar appearance of woody vegetation and herbaceous species in photographs made this a much more challenging task compared to the classification of vegetation as a single class (accuracy = 95.2%). In this regard, image quality was identified as one important factor influencing classification accuracy. Although the automatic classification provided good individual results on most of the 34 test photographs, change statistics based on the automatic approach deviated from actual changes. Nevertheless, the automatic approach was capable of identifying clear trends in increasing or decreasing woody vegetation in repeat photographs. Generally, the use of repeat photography in landscape monitoring represents a significant added value to other quantitative data retrieved from remote sensing and field measurements. Moreover, these photographs are able to raise awareness on landscape change among policy makers and public as well as they provide clear feedback on the effects of land management.}
}
@article{MANSPEIZER2024102728,
title = {Disentangling disturbances with nested hierarchy classification of Mediterranean garrigue/maquis shrub community compositions through remote sensing and GIS},
journal = {Ecological Informatics},
volume = {82},
pages = {102728},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102728},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400270X},
author = {N. Manspeizer and A. Karnieli},
keywords = {UAV mapping, Shrub community patterns, Geoarchaeology, Disturbance ecology, Mediterranean},
abstract = {The paper presents an innovative nested hierarchical classification (NHC) method to disentangle landscape patterns between anthropogenic and natural drivers. This approach is motivated by the research need to differentiate between phytogeographic climate signals in vegetation communities based on these drivers. The method utilizes the non-conformity between spatial structures and granularity in remote sensing imagery with a twofold objective: (1) differentiate features within vegetation community compositions; and (2) aggregate these features with structural causal explanations. A sub-regional study in the southern Levant (Israel) is presented in which long-term ancient land use (LTA-LU) over 2300 years is juxtaposed with variable landscape patterns in modern semi-arid shrub communities. The modern land-cover is classified into three nestable classification levels using spaceborne, airborne, and unmanned aerial vehicle (UAV) imagery. NHC uses aggregation between the classification levels and the LTA-LU through a “bin sorting” technique based on the granularity and data type of the spatial structure. This technique enables the statistical feature extraction of vegetation community parts for association with their structural cause. The features identified indicate that areas of more intense LTA-LU are affected by plagioclimax attributed to industrial monoculture during the Hellenistic, Byzantine, and Ottoman periods. That form of land degradation, caused by long-term disturbance, results in substrates and vegetation compositions that cannot develop and recover to a climax state.}
}
@article{BOHNER2023102150,
title = {A semi-automatic workflow to process images from small mammal camera traps},
journal = {Ecological Informatics},
volume = {76},
pages = {102150},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102150},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123001796},
author = {Hanna Böhner and Eivind Flittie Kleiven and Rolf Anker Ims and Eeva M. Soininen},
keywords = {Camera trap, Rodent, Automatic image classification, Adaptive monitoring, Data processing, Deep learning},
abstract = {Camera traps have become popular for monitoring biodiversity, but the huge amounts of image data that arise from camera trap monitoring represent a challenge and artificial intelligence is increasingly used to automatically classify large image data sets. However, it is still challenging to combine automatic classification with other steps and tools needed for efficient, quality-assured and adaptive processing of camera trap images in long-term monitoring programs. Here we propose a semi-automatic workflow to process images from small mammal cameras that combines all necessary steps from downloading camera trap images in the field to a quality checked data set ready to be used in ecological analyses. The workflow is implemented in R and includes (1) managing raw images, (2) automatic image classification, (3) quality check of automatic image labels, as well as the possibilities to (4) retrain the model with new images and to (5) manually review subsets of images to correct image labels. We illustrate the application of this workflow for the development of a new monitoring program of an Arctic small mammal community. We first trained a classification model for the specific small mammal community based on images from an initial set of camera traps. As the monitoring program evolved, the classification model was retrained with a small subset of images from new camera traps. This case study highlights the importance of model retraining in adaptive monitoring programs based on camera traps as this step in the workflow increases model performance and substantially decreases the total time needed for manually reviewing images and correcting image labels. We provide all R scripts to make the workflow accessible to other ecologists.}
}
@article{GIBB2024102449,
title = {Towards interpretable learned representations for ecoacoustics using variational auto-encoding},
journal = {Ecological Informatics},
volume = {80},
pages = {102449},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102449},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004788},
author = {K.A. Gibb and A. Eldridge and C.J. Sandom and I.J.A. Simpson},
keywords = {Representation learning, Variational auto-encoder, Biodiversity monitoring, Deep learning, Ecoacoustics, Passive acoustic monitoring},
abstract = {Ecoacoustics is an emerging science that seeks to understand the role of sound in ecological processes. Passive acoustic monitoring is being used to collect vast quantities of soundscape audio recordings to study variations in acoustic community and monitor biodiversity. However, extracting relevant information from soundscape recordings is non-trivial. Recent approaches to machine-learned acoustic features appear promising but are limited by at least three issues: inductive biases, lack of interpretability and crude temporal integration. In this paper we introduce a novel self-supervised representation learning algorithm for ecoacoustics - a convolutional Variational Auto-encoder (VAE) - and directly address these shortcomings. Firstly, we train the network on soundscape recordings from temperate and tropical field sites along a gradient of ecological degradation to provide a more relevant inductive bias than prior approaches. Secondly, we present a new method that allows interpretation of the latent space for the first time, giving insight into the basis of classification. Thirdly, we advance existing methods for temporal aggregation of learned embeddings by encoding latent features as a distribution over time. Under our approach to increase interpretability, we provide insight into how learned features drive habitat classification for the first time: inspection of latent space confirms that varying combinations of biophony, geophony and anthrophony are used to infer sites along a degradation gradient. Our novel temporal encoding method increases sensitivity to periodic signals and improves on previous research that uses time-averaged representations for site classification. This approach also reveals the contribution of hardware-specific frequency response that create a potential bias; we demonstrate how a simple linear transformation can be used to mitigate the effect of hardware variance on the learned representation under our approach. Our novel approach paves the way for development of a new class of deep neural networks that afford more interpretable learned ecoacoustic representations to advance both fundamental and applied science and support global conservation efforts.}
}
@article{SAIN2024102648,
title = {Cotton leaf curl disease (CLCuD) prediction modeling in upland cotton under different ecological conditions using machine learning tools},
journal = {Ecological Informatics},
volume = {81},
pages = {102648},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102648},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001900},
author = {Satish Kumar Sain and Debashis Paul and Pradeep Kumar and Ashok Kumar and Man Mohan and Dilip Monga and A.H. Prakash and Yenumula G. Prasad},
keywords = {Artificial neural network (ANN), Bootstrap forest, Boosted tree, Multiple linear regression (MLR), CLCuD, Upland cotton, Growing degree days},
abstract = {Cotton leaf curl disease (CLCuD) is a major threat to cotton production in Africa and South Asia. Due to the dearth of absolute CLCuD-resistant cultivars and effective Bemisia tabaci-vector management strategy, yield loss in cotton crops is witnessed regularly. To ensure the timely application of management practices there is a dire need for a reliable prediction model that can forecast the CLCuD with high speed and accuracy. To overcome this problem, we developed and compared the machine learning (ML) techniques- multiple linear regression (MLR), bootstrap forest (BSF), boosted tree (BST) and artificial neural network (ANN) to predict CLCuD under field conditions. We investigated disease and weather data collected from four locations (host spots) for a period of nine years (2011–12 to 2019–20). During each season/year, 10 ecological variables including CLCuD disease incidence, severity data from ∼8000 plants on four cultivars (2000 each), and ecological factors at each location were recorded. Temperature data were transformed to growing degree days (GDD) and used for modeling as one of the most dependent factors. All data sets for training and validation sets were divided into the ratio of 75:25 for machine learning models. Results indicated that the BSF model was the best ML model with the highest R-squared value in terms of CLCuD prediction accuracy (R2training = 0.81 and R2validation = 0.64) for CLCuD prediction. ANN model with 14 hidden nodes achieved a slightly low R-squared value (R2training = 0.80 and R2validation = 0.79) having an architecture of (9:14:1) whereas, the BST model achieved the lowest R-squared value (R2training = 0.71 and R2validation = 0.59). The testing and validation of activation functions and various training and validation sets indicated that the BSF model is the best ML model. This can provide technical support for CLCuD prediction under field conditions through the designed graphical user interface and further advocate the timely application of management interventions to boost cotton productivity in the region.}
}
@article{RANKIN2024102511,
title = {Open-source machine learning BANTER acoustic classification of beaked whale echolocation pulses},
journal = {Ecological Informatics},
volume = {80},
pages = {102511},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102511},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000530},
author = {Shannon Rankin and Taiki Sakai and Frederick I. Archer and Jay Barlow and Danielle Cholewiak and Annamaria I. DeAngelis and Jennifer L.K. McCullough and Erin M. Oleson and Anne E. Simonis and Melissa S. Soldevilla and Jennifer S. Trickey},
keywords = {Bioacoustics, Machine learning, Random forest, Species classification, Passive acoustic monitoring, Beaked whale},
abstract = {Passive acoustic monitoring is increasingly used for assessing populations of marine mammals; however, analysis of large datasets is limited by our ability to easily classify sounds detected. Classification of beaked whale acoustic events, in particular, requires evaluation of multiple lines of evidence by expert analysts. Here we present a highly automated approach to acoustic detection and classification using supervised machine learning and open source software methods. Data from four large scale surveys of beaked whales (northwestern North Atlantic, southwestern North Atlantic, Hawaii, and eastern North Pacific) were analyzed using PAMGuard (acoustic detection), PAMpal (acoustic analysis) and BANTER (hierarchical random forest classifier). Overall classification accuracy ranged from 88% for the southwestern North Atlantic data to 97% for the northwestern North Atlantic. Results for many species could likely be improved with increased sample sizes, consideration of alternative automated detectors, and addition of relevant environmental features. These methods provide a highly automated approach to acoustic detection and classification using open source methods that can be readily adopted for other species and geographic regions.}
}
@article{PEREZGRANADOS2023101981,
title = {The sound of the illegal: Applying bioacoustics for long-term monitoring of illegal cattle in protected areas},
journal = {Ecological Informatics},
volume = {74},
pages = {101981},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.101981},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000109},
author = {Cristian Pérez-Granados and Karl-L. Schuchmann},
keywords = {Automated signal recognition, Autonomous recording units, Human activity, Kaleidoscope Pro, Livestock, Pantanal},
abstract = {Passive acoustic monitoring coupled with automated signal recognition software has been widely used in recent years as an effective and affordable tool for wildlife monitoring and to combat illegal activities within protected areas. Here, we evaluate this technique to monitor the patterns of illegal cattle occurrence in the Brazilian Pantanal over a complete annual cycle. We aim to provide one of the first assessments of the performance of automated signal recognition software to detect ungulates. Cattle occurrences reached their maximum during the end of the dry season when lowland areas provide excellent pastures for cattle. In contrast, cattle occurrences were very low during the rainy season when the study area was seasonally inundated. Automated software was an efficient tool that was able to detect approximately three-quarters of cow calls within the recordings. Passive acoustic monitoring can be used to direct patrols to areas where illegal activities, such as cattle and poaching or logging, have been confirmed, which could be a method that would be especially well suited for remote areas, such as tropical forests. Future studies should evaluate whether there is a relationship between cattle grazing intensity and its associated impacts on wildlife and flora. Rapid advances in automated recognition and the recent development of low-cost recorders foresee a new era of acoustic ecology for improved conservation in the short term.}
}
@article{ZHANG2024102467,
title = {Marine zoobenthos recognition algorithm based on improved lightweight YOLOv5},
journal = {Ecological Informatics},
volume = {80},
pages = {102467},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102467},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000098},
author = {Lijun Zhang and Jiawen Fan and Yi Qiu and Zhe Jiang and Qingsong Hu and Bowen Xing and Jingxiang Xu},
keywords = {Ecological monitoring, Marine zoobenthos, Model lightweight, YOLOv5, EfficientnetV2, Bottleneck transformer},
abstract = {Detecting the distribution and density of marine zoobenthos is crucial for monitoring healthy coastal ecosystems and for growth reference tracking in precision aquaculture. However, current detection algorithms for marine zoobenthos have high computational complexity and cannot guarantee a balance between accuracy and speed, limiting their deployment in fishery equipment. This study used a portion of the Augmented Underwater Detection Dataset, a large underwater biological dataset containing marine zoobenthos data. A marine zoobenthos recognition algorithm was proposed for sea cucumbers, sea urchins, and scallops based on an improved lightweight YOLOv5, which can recognize the three types of marine zoobenthos. In the image enhancement module, an underwater image enhancement algorithm based on color balance and multi-input fusion is used, which turns the blurred image into a natural appearance of the seabed image. The lightweight backbone network EfficientnetV2-S was chosen to replace the original YOLOv5 backbone network, reducing network parameter calculations and improving recognition speed. A Bottleneck Transformer was introduced into the backbone network, and an attention mechanism based on the convolution module was introduced to construct the embedded Convolutional Block Attention Module in the Neck structure of YOLOv5, thereby improving the recognition accuracy of the lightweight YOLOv5 model. The experimental results showed that the mAP of the proposed algorithm reached 0.941, which is an improvement of 0.002 compared with the original YOLOv5l algorithm. The computation of this algorithm is 37.0 FLOPs (G), the model size is 54 MB, and the inference time is 5.9 ms. Compared to the original YOLOv5l algorithm, the reductions are 66.1%, 40.5%, and 39.2%. The proposed algorithm efficiently identified and classified marine zoobenthos.}
}
@article{RIVERAMUNOZ2022101775,
title = {Deep matrix factorization models for estimation of missing data in a low-cost sensor network to measure air quality},
journal = {Ecological Informatics},
volume = {71},
pages = {101775},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101775},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002254},
author = {L.M. Rivera-Muñoz and A.F. Giraldo-Forero and J.D. Martinez-Vargas},
keywords = {Deep matrix factorization - DMF, Information retrieval, Low-cost sensors network, Missing data},
abstract = {According to the WHO, pollution is a worldwide public health problem. In Colombia, low-cost strategies for air quality monitoring have been implemented using wireless sensor networks (WSNs), which achieve a better spatial resolution than traditional sensor networks for a lower operating cost. Nevertheless, one of the recurrent issues of WSNs is the missing data due to environmental and location conditions, hindering data collection. Consequently, WSNs should have effective mechanisms to recover missing data, and matrix factorization (MF) has shown to be a solid alternative to solve this problem. This study proposes a novel MF technique with a neural network architecture (i.e., deep matrix factorization or DMF) to estimate missing particulate matter (PM) data in a WSN in Aburrá Valley, Colombia. We found that the model that included spatial-temporal features (using embedding layers) captured the behavior of the pollution measured at each node more efficiently, thus producing better estimations than standard matrix factorization and other variations of the model proposed here.}
}
@article{LIU201833,
title = {An accurate ecological footprint analysis and prediction for Beijing based on SVM model},
journal = {Ecological Informatics},
volume = {44},
pages = {33-42},
year = {2018},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2018.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574954117302972},
author = {Lingna Liu and Yalin Lei},
keywords = {Ecological footprint (EF), Back propagation neural network (BPNN), Support vector machine (SVM), Beijing},
abstract = {Accurate prediction of the ecological footprint (EF), an effective indicator for measuring urban sustainable development, enables better protection of urban ecosystems and alleviates discrepancies in urban development, resource utilization, and environmental protection. In contrast to previous research using general methods, we introduce the support vector machine (SVM) method. A novel model with improved prediction accuracy based on SVM is proposed, and we deploy this method to predict the EF of Beijing between 2016 and 2020. First, we calculate the EF of Beijing between 1996 and 2015 and screen out the 6 dominant indicators of EF changes using partial least squares (PLS). Second, based on 2014 and 2015 EF data, we compare the prediction accuracy of the back propagation neural network (BPNN) with the SVM using the 6 indicators as inputs and EF as the output, which then allows us to predict the year 2020 EF in Beijing. The results demonstrate that (1) the relative error rates between the prediction value and the actual value using the two models are 2% and 1% in 2014 and 3% and 0.53% in 2015, respectively, and the fact that the standard deviation of the SVM approaches zero demonstrates its higher prediction accuracy and stability compared to the BPNN; and (2) the EF of Beijing almost doubled to 8984 ten thousand acres from 1996 to 2015 and is predicted to increase to up to 14,206 ten thousand acres by 2020. Based on our prediction model, we provide science-based suggestions for the future development of Beijing.}
}
@article{PRASETYO2024102533,
title = {Standardizing the fish freshness class during ice storage using clustering approach},
journal = {Ecological Informatics},
volume = {80},
pages = {102533},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102533},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400075X},
author = {Eko Prasetyo and Nanik Suciati and Chastine Fatichah and  Aminin and Eric Pardede},
keywords = {Freshness class standardization, Fish, Clustering, Elbow method, Organoleptic inspection},
abstract = {The freshness of fish before consumption affects the taste of the food and human health, so many parties should consider it carefully. Fish is usually stored on ice to maintain its freshness. However, there has yet to be a standard for the fish freshness class during ice storage. On the other hand, each fish species has a different vigor in retaining freshness. In this research, we propose (1) a dataset of fish freshness inspection generated from daily inspection during ice storage for 11 days, (2) a standard of the freshness class of seven fish species using clustering, and (3) a framework for automatically determining the freshness class of fish with internal validation. The dataset is generated from daily inspection during ice storage for 11 days. Experts conduct the organoleptic inspection using six parameters according to the SNI 2729–2013 standards: eyes, gills, body surface mucus, meat, smell, and body textures. We experimented with six clustering methods on the dataset to obtain freshness clusters automatically. Our experimental results indicate that most species fall into two freshness categories, but Upeneus Moluccensis stands out by being classified into three distinct classes. Each species achieves a different number of days for each freshness class. K-Means and K-Means++ obtained the best freshness group with mean scores of 0.538 and 21.92 for Silhouette and Calinski-Harabasz, respectively. Therefore, the standardization of fish freshness class during ice storage for 11 days achieved satisfactory results and was acceptable as guidance and standard in freshness examination.}
}
@article{WANG2024102538,
title = {Hierarchical-taxonomy-aware and attentional convolutional neural networks for acoustic identification of bird species: A phylogenetic perspective},
journal = {Ecological Informatics},
volume = {80},
pages = {102538},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102538},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000803},
author = {Qingyu Wang and Yanzhi Song and Yeqian Du and Zhouwang Yang and Peng Cui and Binnan Luo},
keywords = {Bioacoustics, Bird sound recognition, Hierarchical architecture, Attention module, Path correction},
abstract = {The study of bird populations is crucial for biodiversity research and conservation. Deep artificial neural networks have revolutionized bird acoustic recognition; however, most methods overlook inherent relationships among bird populations, resulting in the loss of biological information. To address this limitation, we propose the Phylogenetic Perspective Neural Network (PPNN), which incorporates hierarchical multilevel labels for each bird. PPNN uses a hierarchical semantic embedding framework to capture feature information at different levels. Attention mechanisms are employed to extract and select common and distinguishing features, thereby improving classification accuracy. We also propose a path correction strategy to rectify inconsistent predictions. Experimental results on bird acoustic datasets demonstrate that PPNN outperforms current methods, achieving classification accuracies of 90.450%, 91.883%, and 89.950% on the Lishui-Zhejiang Birdsdata (100 species), BirdCLEF2018-Small (150 species), and BirdCLEF2018-Large (500 species) datasets respectively, with the lowest hierarchical distance of a mistake across all datasets. Our proposed method is applicable to any bird acoustic dataset and presents significant advantages as the number of categories increases.}
}
@article{BOSSO2024102402,
title = {Integrating citizen science and spatial ecology to inform management and conservation of the Italian seahorses},
journal = {Ecological Informatics},
volume = {79},
pages = {102402},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102402},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123004314},
author = {Luciano Bosso and Raffaele Panzuto and Rosario Balestrieri and Sonia Smeraldo and Maria Luisa Chiusano and Francesca Raffini and Daniele Canestrelli and Luigi Musco and Claudia Gili},
keywords = {Conservation biology, Ecological corridor, GIS analysis, Marine citizen science, Risk map, Seahorse, Species distribution model, Wildlife management},
abstract = {Citizen science and spatial ecology analyses can inform species distributions, habitat preferences, and threats in elusive and endangered species such as seahorses. Through a dedicated citizen science survey submitted to the Italian diving centers, we collected 115 presence records of the two seahorses occurring along the Italian coasts: Hippocampus hippocampus and H. guttulatus. From this dataset, we used 85 seahorse valitaded records to identify the ecological features of these two poorly known species and quantify the effects of human activities on their habitat suitability through geographic information systems and species distribution modelling. Our results indicated a continuous suitable area for both seahorses along the Italian coasts, with a single major gap in the central Adriatic Sea (Emilia-Romagna and Marche regions). They co-occurred in most of their Italian range, particularly in the central and southern Tyrrhenian coasts, and their ecological niches resulted to be significantly similar, although not equivalent. The least-cost paths of both species were concentrated in southern Italy (Apulia, Calabria, and Sicily), suggesting that more data is needed to improve the spatial resolution of the available information, especially in the northern and central Italy. Human activities influenced 38% and 42% of the habitat suitability of H. hippocampus and H. guttulatus, respectively, while only 25% and 30% of their potential distributions, respectively, are protected by Italy's existing conservation area system, in accordance with the global average for seahorses. In particular, the central Adriatic Sea represents a critical area where the occurrence of these seahorses is lower and the anthropic impact is higher. Considering all the Italian regions, fishing effort is the main human activity impacting both species. These findings will support the implementation of more efficient conservation actions. We encourage the application and interaction of citizen science and spatial ecology analyses to facilitate the assessment and sustainable management of elusive organisms.}
}
@article{GANJIRAD2024102498,
title = {Google Earth Engine-based mapping of land use and land cover for weather forecast models using Landsat 8 imagery},
journal = {Ecological Informatics},
volume = {80},
pages = {102498},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102498},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000402},
author = {Mohammad Ganjirad and Hossein Bagheri},
keywords = {LULC, GEE, WRF model, Machine learning, Classification, Landsat 8, Weather forecast},
abstract = {Land Use and Land Cover (LULC) maps are vital prerequisites for weather prediction models. This study proposes a framework to generate LULC maps based on the U.S. Geological Survey (USGS) 24-category scheme using Google Earth Engine. To realize a precise LULC map, a fusion of pixel-based and object-based classification strategies was implemented using various machine learning techniques across different seasons. For this purpose, feature importance analysis was conducted on the top classifiers considering the dynamic (seasonal) behavior of LULC. The results showed that ensemble approaches such as Random Forest and Gradient Tree Boosting outperformed other algorithms. The results also demonstrated that the object-based approach had better performance due to the consideration of contextual features. Finally, the proposed fusion framework produced a LULC map with higher accuracy (overall accuracy = 94.92% and kappa coefficient = 94.19%). Furthermore, the performance of the generated LULC map was assessed by applying it to the Weather Research and Forecasting (WRF) model for downscaling wind speed and 2-m air temperature (T2). The assessment indicated that the generated LULC map effectively reflected real-world conditions, thereby impacting the estimation of wind speed and T2 fields by WRF. Statistical assessments demonstrated enhancements in RMSE by 0.02 °C, MAE by 1 °C, and Bias by 0.03 °C for T2. Additionally, there was an improvement of 0.06 m/s in MAE for wind speed. Consequently, the framework can be implemented to produce accurate and up-to-date high-resolution LULC maps in various geographical areas worldwide. The source codes corresponding to this research paper are available on GitHub via https://github.com/Mganjirad/GEE-LULC-WRF.}
}
@article{GAME2024102619,
title = {Machine learning for non-experts: A more accessible and simpler approach to automatic benthic habitat classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102619},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102619},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001614},
author = {Chloe A. Game and Michael B. Thompson and Graham D. Finlayson},
keywords = {Machine learning, Computer vision, Convolutional neural network, Support vector machine, User-friendly, Benthic habitats},
abstract = {Automating identification of benthic habitats from imagery, with Machine Learning (ML), is necessary to contribute efficiently and effectively to marine spatial planning. A promising method is to adapt pre-trained general convolutional neural networks (CNNs) to a new classification task (transfer learning). However, this is often inaccessible to a non-specialist, requiring large investments in computational resources and time (for user comprehension and model training). In this paper, we demonstrate a simpler transfer learning framework for classifying broad deep-sea benthic habitats. Specifically, we take an ‘off-the-shelf’ CNN (VGG16) and use it to extract features (pixel patterns) from benthic images (without further training). The default outputs of VGG16 are then fed in to a Support Vector Machine (SVM), a classical and simpler method than deep networks. For comparison, we also train the remaining classification layers of VGG16 using stochastic gradient descent. The discriminative power of these approaches is demonstrated on three benthic datasets (574–8353 images) from Norwegian waters; each using a unique imaging platform. Benthic habitats are broadly classified as Soft Substrate (sands, muds), Hard Substrate (gravels, cobbles and boulders) and Reef (Desmophyllum pertusum). We found that the relatively simplicity of the SVM classifier did not compromise performance. Results were competitive with the CNN classifier and consistently high, with test accuracy ranging from 0.87 to 0.95 (average = 0.9 (±0.04)) across datasets, somewhat increasing with dataset size. Impressively, these results were achieved 2.4–5× faster than CNN training and had significantly less dependency on high-specification hardware. Our suggested approach maximises conceptual and practical simplicity, representing a realistic baseline for novice users when approaching benthic habitat classification. This method has wide potential. It allows automated image grouping to aid annotation or further model selection, as well as screening of old-datasets. It is especially suited to offshore scenarios as it can provide quick, albeit crude, insights into habitat presence, allowing adaptation of sampling protocols in near real-time.}
}
@article{BRAVODIAZ2024102684,
title = {Evaluating the ability of convolutional neural networks for transfer learning in Pinus radiata cover predictions},
journal = {Ecological Informatics},
volume = {82},
pages = {102684},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102684},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002267},
author = {A. Bravo-Diaz and S. Moreno and J. Lopatin},
keywords = {Invasive species, Unpiloted aerial vehicles (UAV), Spatial variability, Regression, Transfer domain},
abstract = {The species Pinus radiata is highly invasive in native forests in Chile, drastically affecting the functioning and structure of ecosystems. Hence, it is imperative to develop robust approaches to detect P. radiata invasions at different scales. Models based on convolutional neural networks (CNN) have proven to be a promising alternative to detect plant invasions in high-resolution remote sensing data, such as those obtained by drones. However, studies have been limited in their spatial variability and their assessments of transferability or transfer learning to new sectors, hindering the ability to use these models in a real-world setting. We train models based on CNN architectures using unpiloted aerial vehicle data and evaluate their ability to transfer learning outside the training domain using regression approaches. We compared models trained with low spatial variability (mono-site) with those with high spatial variability (multi-site). We further sought to maximize the transference of learning outside the training domain by searching among different architectures and models, maximizing the evaluation in an independent data set. The results showed that transfer learning is better when multi-site models with higher spatial variability are used for training, obtaining a coefficient of determination R2 between 60% and 87%. On the contrary, mono-site models present a wide variability of performance attributed to the dissimilarity of information between sites, limiting the possibilities of using these models for extrapolations or model generalizations. We also obtained a significant difference between within-domain generalization using test data versus transfer learning outside the training domain, showing that testing data alone cannot depict such discrepancy without further data. Finally, the best models for transfer learning on new data domains often do not agree with those selected by the standard training/validation/testing scheme. Our findings pave the way for deeper discussions and further investigations into the limitations of CNN models when applied to high-resolution imagery.}
}
@article{BARTOLD2024102603,
title = {Estimating of chlorophyll fluorescence parameter Fv/Fm for plant stress detection at peatlands under Ramsar Convention with Sentinel-2 satellite imagery},
journal = {Ecological Informatics},
volume = {81},
pages = {102603},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102603},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001456},
author = {Maciej Bartold and Marcin Kluczek},
keywords = {Ecosystem dynamics, Fv/Fm, Machine learning, Plant stress, Peatlands, Ramsar sites},
abstract = {Monitoring vegetation is essential in Earth Observation (EO) due to its link with the global carbon cycle, playing a crucial role in ecosystem management. The fluorescence of chlorophyll (ChF) is a reliable indicator of plants' photosynthetic activity and growth, especially when they are experiencing unfavourable conditions, particularly in terrestrial wetlands. These wetlands are integral components of the landscape, contributing significantly to climate mitigation, adaptation, biodiversity, and the well-being of both the environment and humanity. We conducted a research study using the XGBoost machine learning algorithm to map the chlorophyll fluorescence parameter Fv/Fm in the Biebrza River Valley, which is known for its marshes, peatlands, and diverse flora and fauna. Our study highlights the benefits of using ensemble classifiers derived from EO Sentinel-2 satellite imagery for accurately mapping Fv/Fm across terrestrial landscapes under the Ramsar Convention at Narew River Valley (Poland) and Čepkeliai Marsh (Lithuania). The XGBoost algorithm provides an accurate estimate of ChF with a robust determination coefficient of 0.747 and minimal bias at 0.013, as validated using in situ data. The precision of Fv/Fm chlorophyll fluorescence parameter estimation from remote sensing sensors depends on the growth stage, emphasizing the importance of identifying the optimal overpass time for S-2 observations. Our study found that biophysical factors, as denoted by spectral indices related to greenness and leaf pigments, were highly impactful variables among the top classifiers. However, incorporating soil, vegetation and meteorological indicators from remote sensing data could further increase the accuracy of chlorophyll fluorescence mapping.}
}
@article{POMMERENING2024102579,
title = {Monitoring spatial tree diversity indices using relascope sampling: Estimators, interactions and limitations},
journal = {Ecological Informatics},
volume = {81},
pages = {102579},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102579},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001213},
author = {Arne Pommerening and Hubert Sterba},
keywords = {Climate change, Biodiversity, Resilience, Edge effects, Forest inventory, Sampling simulation, Continuous cover forestry},
abstract = {With ongoing climate change the monitoring of tree diversity has become very important for avoiding or at least decelerating the loss of biodiversity and for maintaining forest ecosystem resilience. As part of such monitoring, spatial indices of tree diversity which are calculated for individual trees often serve as surrogates for more direct measures of biodiversity. Mainly for its efficiency and ease of application, relascope sampling is a widespread method applied in forest inventory of many countries and thus has often been suggested as a data source for the monitoring of tree diversity. Since the interaction between sampling design and spatial diversity indices is not always clear to data analysts, we reviewed existing estimators and experimentally examined a new one, conducted extensive sampling simulations using different indices and estimators and additionally analysed the data from a large-scale forest inventory in Austria. We found that both forest structure and index algorithm greatly influence the sampling error. The largest source of sampling error was the index variance and contrary to our expectation not so much the bias due to spatial effects. For diversity indices related to distances, it has turned out to be best to apply estimators that include spatial edge correction methods. For all other indices an estimator performed better that included information on both the sample trees and their nearest neighbours, as it much reduced overall index variance. However, if possible the plus-sampling edge correction method should be applied.}
}
@article{BAKHT2024102631,
title = {MuLA-GAN: Multi-Level Attention GAN for Enhanced Underwater Visibility 11⁎First two authors has equal contribution⋆github code link:https://github.com/AhsanBaidar/MuLAGAN.git ORCID (s): 0000–0002–9079-0960 (A.B. Bakht); 0000–0001–9789-8483 (Z. Jia); 0000–0001–6214-1077 (M.U. Din); 0000–0002–7401-5120 (W. Akram); 0000–0003–4445-3135 (L.S. Saoud); 0000–0001–6405-8402 (L. Seneviratne); 0000–0001–6432-5187 (S. He); 0000–0003–2759-0306 (I. Hussain)},
journal = {Ecological Informatics},
volume = {81},
pages = {102631},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102631},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001730},
author = {Ahsan B. Bakht and Zikai Jia and Muhayy Ud Din and Waseem Akram and Lyes Saad Saoud and Lakmal Seneviratne and Defu Lin and Shaoming He and Irfan Hussain},
keywords = {Underwater image enhancement, Generative adversarial networks (GANs), Spatio-channel attention, Computer vision, Real-time image processing},
abstract = {The underwater environment presents unique challenges (color distortions, reduced contrast, blurriness) hindering accurate analysis. This work introduces MuLA-GAN, a novel approach leveraging Generative Adversarial Networks (GANs) and specifically adapted Multi-Level Attention for comprehensive underwater image enhancement. MuLA-GAN integrates Multi-Level Attention within the GAN architecture to prioritize learning discriminative features crucial for precise image restoration. These relevant features encompass information on local details within image regions leveraged by spatial attention and features at various scales across the entire image captured by multi-level attention. This allows MuLA-GAN to identify and enhance objects, textures, and edges obscured by underwater distortions while also reconstructing a more accurate and visually clear representation of the underwater scene by analyzing low-level information like edges and textures, as well as high-level information like object shapes and global scene information. By selectively focusing on these relevant features, MuLA-GAN excels at capturing and preserving intricate details in underwater imagery, which is essential for various marine research, exploration, and resource management applications. Extensive evaluations on diverse datasets (UIEB test, UIEB challenge, U45, UCCS) demonstrate MuLA-GAN's superior performance compared to existing methods. Additionally, a specialized bio-fouling and aquaculture dataset confirms the model's robustness in challenging environments. On the UIEB test dataset, MuLA-GAN achieves exceptional Peak Signal-to-Noise Ratio (PSNR) (25.59) and Structural Similarity Index (SSIM) (0.893) scores, surpassing Water-Net (24.36 PSNR, 0.885 SSIM). This work addresses a significant research gap in underwater image enhancement by demonstrating the effectiveness of combining GANs with specifically adapted Multi-Level Attention mechanisms. This tailored approach offers a novel and comprehensive framework for restoring underwater image quality, providing valuable insights for accurate underwater scene analysis. The source code for MuLA-GAN is publicly available on GitHub at https://github.com/AhsanBaidar/MuLA_GAN.git}
}
@article{DUAN2024102563,
title = {Identifying soil groups and selecting a high-accuracy classification method based on multi-textural features with optimal window sizes using remote sensing images},
journal = {Ecological Informatics},
volume = {81},
pages = {102563},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102563},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001055},
author = {Mengqi Duan and Xiangyun Song and Zengqiang Li and Xiaoguang Zhang and Xiaodong Ding and Dejie Cui},
keywords = {Mean, Entropy, Multi-textural features, Soil groups, SVM, Textural feature windows},
abstract = {Determining the spatial distribution of soil groups accurately is crucial for managing soil resources. However, limitations persist in the mapping of soil groups using multi-textural features derived from remote sensing images. Identification of the optimal window size for multi-textural feature extraction and the most effective classification method for soil group recognition using remote sensing multi-textural features remains unresolved. In this study, we investigated soil groups in a representative area of the Jiaodong Peninsula. We extracted the mean and entropy texture parameters for various window sizes (3 × 3 to 25 × 25 in odd increments) from Landsat 8 images to determine the optimal sizes for multi-textural feature extraction. The efficacy of identifying soil groups via textural features was analyzed using maximum likelihood classification (MLC), support vector machine (SVM), artificial neural network (ANN), and random forest (RF) methods to ascertain the most suitable classification approach. The results indicate that the optimal window sizes were 19 × 19 for the mean parameter and 23 × 23 for the entropy parameter. The SVM method outperformed the MLC, ANN, and RF methods in terms of the classification accuracy. Notably, the SVM classification method reached a peak accuracy of 71.61% when combining multi-textural features with the optimal windows. This demonstrates the feasibility of different soil groups using multi-textural information from remote sensing images. These findings have notable implications in guiding digital soil mapping using multi-textural features.}
}
@article{LARSEN2021101290,
title = {Online computational ethology based on modern IT infrastructure},
journal = {Ecological Informatics},
volume = {63},
pages = {101290},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101290},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000819},
author = {Leon B. Larsen and Mathias M. Neerup and John Hallam},
keywords = {Bioacoustics, Recording, Automated annotation},
abstract = {In the study of animal behaviour, annotation and analysis is largely done manually either directly in the field or from recordings. An emerging field, computational ethology, is challenging this approach by using machine learning to automate the process. However, the use of such methods in general is complicated by a lack of modularity, leading to high cost and long development times. At the same time, the benefits of implementing a fully automated pipeline are often minuscule. We propose online analysis as a way to gain more from automating the process, such as making it easier to ensure that equipment is properly configured and calibrated, enabling the recording equipment to follow the animals, and even enabling closed-loop experiments. In this work, we discuss the requirements and challenges for such a system and propose an implementation based on modern IT infrastructure. Finally, we demonstrate the system in case studies of bats and mongoose. As more and more methods and algorithms are developed we expect online systems to enable new experimental setups to study behaviour, leading to new insights in the field.}
}
@article{CHARIZANOS2023101899,
title = {Bayesian prediction of wildfire event probability using normalized difference vegetation index data from an Australian forest},
journal = {Ecological Informatics},
volume = {73},
pages = {101899},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101899},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122003491},
author = {Georgios Charizanos and Haydar Demirhan},
keywords = {Bayesian model averaging, Bushfires, Forest fires, Multivariate prior, NDVI},
abstract = {Wildfires are impactful natural disasters, creating a significant impact across many rural communities. Predicting wildfire probability provides authorities with invaluable information to take preventive measures at the early stages. This study establishes Bayesian modelling for predicting the wildfire event probability based on a set of environmental predictors and forest vulnerability, represented by the normalized difference vegetation index. Prior information about the impact of these predictors on the likelihood of wildfire is available in the reports on the past major wildfire events. In that sense, the use of prior information in the Bayesian models has the potential to provide accurate predictions for the wildfire probability. Moreover, the relationship between the predictors creates mediating effects on the likelihood of a wildfire event. A multivariate prior distribution in the Bayesian modelling can capture the mediating effects. In this study, Bayesian models with informative and noninformative priors are considered with independent and multivariate prior distributions to utilize the available prior information and handle the mediating effects between the predictors using the normalized difference vegetation index data provided by Google Earth Engine. Nine years of data were gathered across 9841 sampled areas in a forested land of Australia. Modelling results concluded that forest vulnerability is found to be the dominant predictor of wildfire probability. This modelling can help create a Wildfire Warning Index based on climate data and forest vulnerability measurements, enabling preventative actions in high-risk and targeted areas.}
}
@article{CASTRILLO2024102672,
title = {A data-driven approach for the assessment of the thermal stratification of reservoirs based on readily available data},
journal = {Ecological Informatics},
volume = {82},
pages = {102672},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102672},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002140},
author = {María Castrillo and Fernando Aguilar and Daniel García-Díaz},
keywords = {Data-driven, Machine learning, Reservoir, Thermal stratification, Thermocline},
abstract = {A data-driven approach to assess the occurrence of thermal stratification and the depth of the thermocline in water masses has been developed and tested in the Spanish reservoir of El Val. The novelty of this approach is that it relies only on readily available data that can be collected for almost any reservoir, providing water managers with a transferable tool that can be easily adapted for any other reservoirs or lakes. The input variables were meteorological data, the water level and the output flow. A non-supervised clustering technique, k-means, was used to identify the stratification period with unlabelled data, that is to say inferring patterns when data from the target variable is not available. As a supervised method, Artificial Neural Networks were used to classify a given day as having or not having stratification and, in the positive case, to infer the depth of the thermocline. The classification showed a very high accuracy (96%) and the estimation of the thermocline depth showed a mean absolute error (MAE) of 1.94 m and 1.99 m in the training and test fractions, respectively. Shapley Additive Explanations (SHAP) values were used to improve the explainability and they revealed that the most important features to infer the depth of the thermocline were the water level, the daily average solar irradiance and the air temperature.}
}
@article{SABERIOON2023102058,
title = {Examining the sensitivity of simulated EnMAP data for estimating chlorophyll-a and total suspended solids in inland waters},
journal = {Ecological Informatics},
volume = {75},
pages = {102058},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102058},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123000870},
author = {Mohammadmehdi Saberioon and Vahid Khosravi and Jakub Brom and Asa Gholizadeh and Karl Segl},
keywords = {Biophysical properties, Hyperspectral imagery, Machine learning, Remote sensing, Satellite imagery, Water quality},
abstract = {Our study investigates the capability of the environmental mapping and analysis program (EnMAP) scenes simulated using the EnMAP end-to-end simulator software (EeteS) based on the AISA Eagle airborne data to predict chlorophyll-a (Chl-a) and total suspended solids (TSS) as two of the most crucial water quality indicators. Three machine learning (ML) approaches (principal component regression(PCR), partial least square regression (PLSR) and random forest (RF)) were employed to establish links between the simulated image spectra and the above-mentioned water attributes of the samples collected from several inland water reservoirs within the southern part of the Czech Republic. Airborne hyperspectral images were also used to develop a model to compare its performance with models developed based on the simulated EnMAP data. Adequate prediction accuracy was obtained for both Chl-a (R2 = 0.89, RMSE = 43.06 μg/L, and Lin’s concordance correlation coefficient (LCCC) = 0.91) and TSS (R2 = 0.91, RMSE = 17.53 mg/L, and LCCC = 0.94), which were close enough to those obtained from the airborne hyperspectral images. Chl-a and TSS correlated with the wavelengths around 550 nm and 700 to 750 nm of the red and near-infrared (NIR) regions. In addition, the spatial distribution maps derived from the simulated EnMAP were comparable to those obtained from the AISA Eagle airborne data. Overall, it can be concluded that the simulated EnMAP image successfully and reliably predicted and spatially mapped the selected biophysical properties of the small inland water bodies.}
}
@article{HO2023102289,
title = {LaDeco: A tool to analyze visual landscape elements},
journal = {Ecological Informatics},
volume = {78},
pages = {102289},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102289},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003187},
author = {Li-Chih Ho},
keywords = {Landscape assessment, Deep learning, Natural feature index, Semantic segmentation, Visual landscape elements},
abstract = {The assessment of visual landscape elements plays a crucial role in landscape change studies, aesthetic evaluation, and visual impact assessment. The proportions and statistical distributions of these elements are key factors that significantly influence these domains. Historically, the analysis has been performed manually, a process that is both labor intensive and time consuming, particularly when dealing with large assessment regions. To address this limitation, this study employs cutting-edge artificial intelligence technology to introduce an automated tool called LaDeco (Landscape Decoder). This tool enables researchers, planners, and evaluators to rapidly and objectively calculate the proportions of visual elements in images, thereby streamlining the assessment process.}
}
@article{CAMERON2022101658,
title = {Estimating boreal forest ground cover vegetation composition from nadir photographs using deep convolutional neural networks},
journal = {Ecological Informatics},
volume = {69},
pages = {101658},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101658},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122001078},
author = {Hilary A. Cameron and Pranoy Panda and Martin Barczyk and Jennifer L. Beverly},
abstract = {Ground cover and surface vegetation information are key inputs to wildfire propagation models and are important indicators of ecosystem health. Often these variables are approximated using visual estimation by trained professionals but the results are prone to bias and error. This study analyzed the viability of using nadir or downward photos from smartphones (iPhone 7) to provide quantitative ground cover and biomass loading estimates. Good correlations were found between field measured values and pixel counts from manually segmented photos delineating a pre-defined set of 10 discrete cover types. Although promising, segmenting photos manually was labor intensive and therefore costly. We explored the viability of using a trained deep convolutional neural network (DCNN) to perform image segmentation automatically. The DCNN was able to segment nadir images with 95% accuracy when compared with manually delineated photos. To validate the flexibility and robustness of the automated image segmentation algorithm, we applied it to an independent dataset of nadir photographs captured at a different study site with similar surface vegetation characteristics to the training site with promising results.}
}
@article{PALMA2023102220,
title = {Pattern-based prediction of population outbreaks},
journal = {Ecological Informatics},
volume = {77},
pages = {102220},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102220},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002492},
author = {Gabriel R. Palma and Wesley A.C. Godoy and Eduardo Engel and Douglas Lau and Edgar Galvan and Oliver Mason and Charles Markham and Rafael A. Moral},
keywords = {Alert zone procedure, Deep learning, Machine learning, Population dynamics, Time series},
abstract = {The complexity and practical importance of insect outbreaks have made the problem of predicting outbreaks a focus of recent research. We propose the Pattern-Based Prediction (PBP) method for predicting population outbreaks. It uses information on previous time series values that precede an outbreak event as predictors of future outbreaks, which can be helpful when monitoring pest species. We illustrate the methodology using simulated datasets and an aphid time series obtained in wheat crops in Southern Brazil. We obtained an average test accuracy of 84.6% in the simulation studies implemented with stochastic models and 95.0% for predicting outbreaks using a time series of aphids in wheat crops in Southern Brazil. Our results show the PBP method's feasibility in predicting population outbreaks. We benchmarked our results against established state-of-the-art machine learning methods: Support Vector Machines, Deep Neural Networks, Long Short Term Memory and Random Forests. The PBP method yielded a competitive performance associated with higher true-positive rates in most comparisons while providing interpretability rather than being a black-box method. It is an improvement over current state-of-the-art machine learning tools, especially by non-specialists, such as ecologists aiming to use a quantitative approach for pest monitoring. We provide the implemented PBP method in Python through the pypbp package.}
}
@article{LI2024102630,
title = {Spatio-temporal dynamics of vegetation over cloudy areas in Southwest China retrieved from four NDVI products},
journal = {Ecological Informatics},
volume = {81},
pages = {102630},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102630},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001729},
author = {Xin Li and Jingwen Xu and Yiyang Jia and Shuang Liu and Yudie Jiang and Zelin Yuan and Huiyu Du and Rui Han and Yang Ye},
keywords = {Vegetation dynamic, NDVI, Multi-source datasets, Satellite-based remote sensing, Complex landform},
abstract = {The Normalized Difference Vegetation Index (NDVI) is the most commonly used index for assessing vegetation. However, significant differences among various satellite datasets, complex terrain, and the impact of clouds on optical sensors limit vegetation change assessment based on NDVI. To address these issues, this study utilizes multi-source satellite data (GIMMS3g NDVI, CDR AVHRR NDVI, SPOT NDVI, and MODIS NDVI) to monitor vegetation dynamics at different time scales from 1990 to 2020 in Sichuan Province, China. The results indicate that over time, NDVI values from the four NDVI products in Sichuan Province have shown an upward trend. There are certain differences in the spatial distribution and spatial heterogeneity of the change rate of NDVI values among the four NDVI products at different time scales, and the differences are mainly concentrated in the Sichuan Basin (SB) and the Western Sichuan alpine plateau region (WS). Compared with the other three NDVI products, GIMMS NDVI has the highest value but the smallest increase during the study period. The SPOT NDVI value is the smallest, but the increase is relatively large. However, within the overlapping period of the four NDVI datasets, only the annual average of CDR AVHRR NDVI showed a downward trend (slope2000–2013 = −0.0001·a−1). The annual fluctuation of CDR AVHRR NDVI is the smallest, and compared to other NDVI datasets, its correlation with climate factors shows significantly weaker spatial variability. Moreover, the ability of CDR AVHRR NDVI to distinguish different vegetation land cover types is significantly poor (STD = 0.045). The findings of this study will provide a reference for further research on vegetation changes in Sichuan Province and NDVI reconstruction in cloudy areas.}
}
@article{SOOM2022101817,
title = {Environmentally adaptive fish or no-fish classification for river video fish counters using high-performance desktop and embedded hardware},
journal = {Ecological Informatics},
volume = {72},
pages = {101817},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101817},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002679},
author = {Jürgen Soom and Vishwajeet Pattanaik and Mairo Leier and Jeffrey A. Tuhtan},
keywords = {Fish detection, Deep learning, Underwater video, Environmental classification, Embedded hardware},
abstract = {Automated fish counters featuring robust, real-time computer vision capabilities can provide a cost-effective means to count migrating freshwater fish. In this work, we propose a four-stage process for automatically sorting videos with and without fish. Underwater fish counter videos provide a challenging range of environmental conditions including clear water, biofilm growth, bubbles, turbidity, low light and overexposure. To address this, our method also includes the automated classification of these six environmental conditions. The proposed methods are computationally efficient and can be implemented on servers, high-performance desktop computers and low-cost, energy-efficient embedded hardware. The models were trained, tested, and validated using a collection of 3000 videos taken from underwater fish counter installations in several alpine and lowland European rivers provided by commercial and governmental collaborators. This work demonstrates a fast, accurate, and robust computer vision workflow for large-scale automated freshwater fish counting systems.}
}
@article{MENG2024102549,
title = {Classification of inland lake water quality levels based on Sentinel-2 images using convolutional neural networks and spatiotemporal variation and driving factors of algal bloom},
journal = {Ecological Informatics},
volume = {80},
pages = {102549},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102549},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000918},
author = {Haobin Meng and Jing Zhang and Zhen Zheng and Yongyu Song and Yuequn Lai},
keywords = {Convolutional neural networks, Sentinel-2, Water quality level classification, Algal blooms, Driving factor},
abstract = {Water quality monitoring in inland lakes is crucial to ensuring the health and stability of aquatic ecosystems. For regional water environment agencies and researchers, remote sensing offers a cost-effective alternative to traditional in-situ water sampling methods. In this study, we designed a convolutional neural network (CNN) based on AlexNet to represent the relationship between Sentinel-2 images and in situ water quality levels of Lake Dianchi from November 2020 to April 2023. The model incorporated an algal bloom extraction algorithm and utilized correlation analysis, redundancy analysis (RDA), and random forest (RF) method to establish connections between two environmental factors: water quality and meteorology, to the area of algal bloom (AAB). The findings revealed an improvement in Lake Dianchi's water quality, with Levels A (good water quality) and B (mildly polluted water quality) averaging 1.24% and 84.28%, respectively. Starting in October 2022, water quality stabilized at Level B, averaging at 98.17%. Seasonal variations demonstrated the best water quality in spring and the worst in summer (Level C, severely polluted water quality, accounting for 5.19% and 21.68%, respectively). Algal bloom presence was minimally observed, with an average AAB value of 1.75%, peaking in autumn (4.05%) and hitting a low in winter (0.38%). A significant correlation was identified between water quality levels and AAB, with a notable spatial trend of decreasing Level C water quality and AAB from north to south, featuring lower AAB in the Southern Waihai compared to the Central Waihai. Statistical analysis pinpointed total phosphorus (TP) as the dominant factor influencing AAB, while meteorological factors such as wind speed (WS), relative humidity (RH), and precipitation (PP) playing secondary roles. Despite fluctuations in TP concentration, a recent stabilization at 0.05 mg/L suggests a positive trajectory for future algal bloom management in Lake Dianchi.}
}
@article{YIN2024102450,
title = {Automatic detection of stereotypical behaviors of captive wild animals based on surveillance videos of zoos and animal reserves},
journal = {Ecological Informatics},
volume = {79},
pages = {102450},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102450},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300479X},
author = {Zixuan Yin and Yaqin Zhao and Zhihao Xu and Qiuping Yu},
keywords = {Stereotypical behavior, Captive animal, Animal welfare, Animal tracking, Siamese network, Motion trajectory},
abstract = {The timely detection of the depressive and stereotypical behaviors often observed in captive wild animals and the subsequent intervention can contribute to improving their living environment in enclosures, which is crucial for safeguarding animal welfare, enhancing animal husbandry practices, regulating human–animal relationships. Several studies have analyzed factors that influence animal stereotypical behaviors and identified preventive measures via regular animal observations. An automatic detection method based on video technology can yield long-term automatic recordings of motion trajectories of animals after a professionally trained automatic detection software is integrated into the human–machine interaction operation interface of animal management. As an initial exploration of this research paradigm, we propose a novel method for automatically tracking and recognizing the stereotypical behavior of animals in surveillance videos based on the periodic analysis of motion trajectories. First, we introduced a Siamese relation network to track the motion trajectories of animals. This network accurately tracked animals and distinguished different individuals in complex environments. Second, an autocorrelation function was used to analyze the periodicity of the motion trajectory, which was divided into several periodic curves. Finally, a cross-correlation function was introduced to determine the linear correlation between the two variables of the periodic curves. This function distinguished the three types of motion trajectories. The success rate and precision of the animal-tracking method adopted in this study were 67.4% and 90.4%, respectively, which were superior to those of common Siamese tracking networks. The average prediction error of the cycle time was 0.095 s. Therefore, the proposed method can accurately track the motion trajectories of animals and identify their stereotypical behaviors. Furthermore, this study provides data to facilitate the scientific management of animals and improve animal welfare. The codes and datasets used in the study are available at https://github.com/yinyinzixuan/animal-stereotypical-behavior.git.}
}
@article{KEASAR2024102521,
title = {STARdbi: A pipeline and database for insect monitoring based on automated image analysis},
journal = {Ecological Informatics},
volume = {80},
pages = {102521},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102521},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000633},
author = {Tamar Keasar and Michael Yair and Daphna Gottlieb and Liraz Cabra-Leykin and Chen Keasar},
keywords = {Classification, High-throughput screening, Insect monitoring, Machine learning, Object detection, Sticky trap},
abstract = {Insects are highly abundant and diverse, and play major roles in ecosystem functions. Monitoring of insect populations is key to their sustainable management. However, the labor and expertise needed to identify insects, and the challenges of archiving the wealth of data collected in monitoring programs, often limit these efforts. We describe a pipeline to reduce the barriers associated with curating and mining big data of insect biodiversity. The pipeline, STARdbi, includes capturing flying insects with sticky traps, scanning the traps, storing the trap-images in a public database with a web-based interface, and applying machine learning models to extract information from the images. To illustrate the insights that can be gained from STARdbi, we describe two case studies. One of them involves monitoring of circadian activity patterns of grain pests and of their natural enemies, and the other compares insect abundance, biomass and size distributions between agricultural and semi-natural habitats. We invite the community of insect ecologists to contribute to the STARdbi database, and to use its image analysis tools to address diverse ecological and evolutionary questions.}
}
@article{GU2024102493,
title = {Quantifying the direct and indirect effects of terrain, climate and human activity on the spatial pattern of kNDVI-based vegetation growth: A case study from the Minjiang River Basin, Southeast China},
journal = {Ecological Informatics},
volume = {80},
pages = {102493},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102493},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124000359},
author = {Zipeng Gu and Xingwei Chen and Weifang Ruan and Meiling Zheng and Kaili Gen and Xiaochen Li and Haijun Deng and Ying Chen and Meibing Liu},
keywords = {kNDVI, Spatial pattern, Drivers, OPGD, PLS-SEM, GEE, Minjiang River basin},
abstract = {In the context of global change, it is vital to comprehensively understand the spatial pattern and driving mechanism of vegetation growth to maintain the stability of watershed ecosystems. Previous research has focused mainly on identifying the main drivers of vegetation growth, while the direct and indirect effects of climate, terrain, and human activity on vegetation growth have rarely been explored. This study used the Minjiang River Basin (MRB), an important ecological barrier and the largest watershed in southeastern China, as an example. The kernel normalized difference vegetation index (kNDVI) was calculated on the Google Earth Engine (GEE) platform to examine the spatial pattern and evolution characteristics of vegetation growth. The optimal parameter-based geographical detector (OPGD) and partial least squares structural equation modeling (PLS-SEM) were used to analyze how terrain, climate, and human activity influenced the spatial pattern of the kNDVI. (1) From 2001 to 2020, vegetation growth in the MRB was predominantly rated as excellent or good, and 88.93% of the area showed an increasing trend of vegetation growth. (2) The OPGD revealed that the primary drivers influencing the spatial distribution of the kNDVI in the MRB included population density, nighttime light, elevation and temperature, which explained >40% of the variation in the kNDVI. The interaction of all paired drivers enhanced the explanatory power of the kNDVI, among which the strongest interaction was between population density and elevation, and the second interaction was between population density and temperature. (3) PLS-SEM revealed that human activity had a direct negative effect on the kNDVI, while terrain and climate had direct and indirect positive effects on the kNDVI. Overall, the total effects of terrain, climate and human activity on the kNDVI were 0.594, 0.233 and − 0.495, respectively, indicating that the positive effect of terrain outweighed the negative effect of human activity on vegetation growth in the MRB. These findings not only provide scientific evidence for ecological conservation and management in the MRB but also offer a useful reference for other regions exploring the complex causes of spatial patterns of vegetation growth.}
}
@article{RICCARDI2024102590,
title = {First woody cover vegetation map of Kruger National Park in 1939–1944: Evidence from historical black and white aerial photography},
journal = {Ecological Informatics},
volume = {81},
pages = {102590},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102590},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001328},
author = {Tullia Riccardi and Benjamin J. Wigley and Linda Kleyn and Corli Coetsee and Sandra MacFadyen and Fabio Attorre and Luca Malatesta},
keywords = {Savanna ecosystem, Vegetation mapping, Object-based image analysis (OBIA), Google earth engine (GEE), Random forest, Historical baseline},
abstract = {Long-term spatial studies are crucial for understanding how the Earth's surface has changed. Before satellite imagery, landscapes were monitored using black and white (B&W) aerial photographs. However, surveys were infrequent and image analysis was a manual process that was both time-consuming and costly. In this study, we created a composite of high spatial resolution (0.5–0.75 m) B&W aerial images from 1939–1944, covering about 91% of Kruger National Park (KNP)’s nearly 2 million ha. We used this to produce the first historical woody cover (tall trees and shrubs) map of KNP, which until now was only partially understood through fragmented descriptions in period literature and small-area case studies. We established a supervised learning workflow using Google Earth Engine (GEE) which included performing an Object-based Image Analysis (OBIA) with a Random Forest classifier. This approach, enhanced by integrating texture, shape, neighboring features, and spectral variables into the training/validation dataset, enabled the identification of woody vegetation from B&W landscape objects. To enhance accuracy, we guided our sampling method using vegetation types with comparable woody cover and species composition. Initially, we tested our method on a smaller set of images (25 km2), and after confirming its effectiveness, we then expanded the approach to cover all available historical aerial imagery. Our results show that in 1939–1944, 26% of KNP was covered in woody vegetation (overall accuracy of 89%, producer's accuracy (non-woody = 88%, woody = 90%), and user's accuracy (non-woody = 90%, woody = 87%)). The importance of geological substrate in driving vegetation pattern is reflected in a higher woody cover percentage on granite (28%) than on basalt (21%) soils, with the lowest woody cover on northern basalts (11%) and the highest on north-central granites (32%). This study highlights the potential of GEE and OBIA for analyzing large-area, high spatial resolution B&W aerial photographs in a systematic and efficient manner and the importance of creating large-scale historical land cover baselines to support environmental planning and landscape management.}
}
@article{CELIS2024102578,
title = {A versatile, semi-automated image analysis workflow for time-lapse camera trap image classification},
journal = {Ecological Informatics},
volume = {81},
pages = {102578},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102578},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124001201},
author = {Gerardo Celis and Peter Ungar and Aleksandr Sokolov and Natalia Sokolova and Hanna Böhner and Desheng Liu and Olivier Gilg and Ivan Fufachev and Olga Pokrovskaya and Rolf Anker Ims and Wenbo Zhou and Dan Morris and Dorothee Ehrich},
keywords = {Arctic wildlife monitoring, Deep learning, ResNet-50, MegaDetector, Time-lapse camera},
abstract = {Camera traps are a powerful, practical, and non-invasive method used widely to monitor animal communities and evaluate management actions. However, camera trap arrays can generate thousands to millions of images that require significant time and effort to review. Computer vision has emerged as a tool to accelerate this image review process. We propose a multi-step, semi-automated workflow which takes advantage of site-specific and generalizable models to improve detections and consists of (1) automatically identifying and removing low-quality images in parallel with classification into animals, humans, vehicles, and empty, (2) automatically cropping objects from images and classifying them (rock, bait, empty, and species), and (3) manually inspecting a subset of images. We trained and evaluated this approach using 548,627 images from 46 cameras in two regions of the Arctic: “Finnmark” (Finnmark County, Norway) and “Yamal” (Yamalo-Nenets Autonomous District, Russia). The automated steps yield image classification accuracies of 92% and 90% for the Finnmark and Yamal sets, respectively, reducing the number of images that required manual inspection to 9.2% of the Finnmark set and 3.9% of the Yamal set. The amount of time invested in developing models would be offset by the time saved from automation after 960 thousand images have been processed. Researchers can modify this multi-step process to develop their own site-specific models and meet other needs for monitoring and surveying wildlife, balancing the acceptable levels of false negatives and positives.}
}
@article{SINGHAROY2023102265,
title = {Image background assessment as a novel technique for insect microhabitat identification},
journal = {Ecological Informatics},
volume = {77},
pages = {102265},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102265},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123002947},
author = {Sesa {Singha Roy} and Reid Tingley and Alan Dorin},
keywords = {Microhabitat, Insects, Image analysis, Computer vision, Machine learning},
abstract = {Habitat fragmentation under increased urbanisation, industrial agriculture and land clearing, are changing the way insects occupy habitat. Some species are highly adaptable and may occupy urbanised areas, utilising anthropogenic microhabitat-scale features. Other species are dependent on natural elements of their habitats, having to locate small regions of natural microhabitat within increasingly hostile landscapes. Consequently, humans are encountering insects in new settings. Identifying and analysing insects’ use of natural and anthropogenic microhabitats is therefore important to assess their responses to a changing environment, for instance to improve pollination or manage invasive pests. But such studies are labour-intensive. Traditional studies of insect microhabitat use can now be supplemented by machine learning-based insect image analysis. Typically, research has focused on automatic insect classification, but valuable data appearing in image backgrounds has been ignored. In this research, we analysed the backgrounds of insect images available in the Atlas of Living Australia database to determine the microhabitats in which they were commonly photographed. We analysed the image backgrounds of three globally distributed insect species that are common across Australia: Drone flies (Eristalis tenax), European honey bees (Apis mellifera), and European wasps (Vespula germanica). Image backgrounds were classified broadly as either natural or anthropogenic using computer vision and machine learning tools benchmarked against a manual classification algorithm. Our automated image background classification achieved 97.4% accuracy when compared against manual classification. Mis-classifications were scarce, usually less than 1%, and primarily for backgrounds of wood and soil or bare ground. Our results indicate that drone flies and European honey bees were predominantly photographed against natural backgrounds (flies manual classifier 95±3%, automated classifier 94%, bees 89±2%,87%), implying frequent observations by humans in natural microhabitat. European wasps were less frequently photographed against natural backgrounds (70±6%,63%). Within this data set, observations of the wasps in anthropogenic microhabitats were more common than for flies and bees. Our results are aligned with the expectation that the wasps are relatively well-suited to urban environments, and that European honey bees and drone flies utilise natural features of their environment. In general, although biases in data collected without formal protocols limits their application, our new automated approach for image background analysis can provide valuable data about insects’ interactions with humans, our artefacts, and natural features of their environments.}
}
@article{CHEN2024102667,
title = {Quantitatively analyzing the driving factors of vegetation change in China: Climate change and human activities},
journal = {Ecological Informatics},
volume = {82},
pages = {102667},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102667},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002097},
author = {Yang Chen and Tingbin Zhang and Xuan Zhu and Guihua Yi and Jingji Li and Xiaojuan Bie and Jiao Hu and Xian Liu},
keywords = {Growing season NDVI, Vegetation change, Human activities, Climate change, CHFA, China},
abstract = {Understanding the impact of climate change and human activities on vegetation dynamics is crucial for ecosystem management. Employing the Residual Trend method and integrating Normalized Difference Vegetation Index (NDVI) data with land use/cover, this study assesses the impacts of climate change and human activities on vegetation dynamics across China from 2000 to 2018. The findings indicate a consistent upward trend of China's Growing Season NDVI (GSN), averaging a change rate of 0.0032/yr. Human activities are the primary drivers of this change, contributing 82.47% to GSN in China, while climate change accounts for 17.53%. The effect of human activities on vegetation dynamics showed considerable variation across different river basins, with the Huaihe River Basin experiencing the highest human impact (93.53%) and the Continental Basin the lowest (76.27%). Conversely, the Continental Basin experienced the greatest impact from climate change (23.73%), compared to the minimal influence in the Huaihe River Basin (6.47%). The study results offer contribution rates for each type of changed and unchanged land use, with persistent forestland, persistent grassland, persistent cropland, and grassland to forest conversion contributing 28.65%, 22.09%, 13.76%, and 4.61%, respectively. Persistent forestland emerges as the most efficacious land use type for facilitating vegetation restoration. Within the persistent forestlands of the Yangtze, Pearl, and Southeast River Basins, human activities accounted for 26.99%, 42.18%, and 43.50% of the vegetation alterations, respectively. These findings provide a scientific basis for formulating effective ecosystem management and protection strategies.}
}
@article{HU2024102695,
title = {A long-term multivariate time series prediction model for dissolved oxygen},
journal = {Ecological Informatics},
volume = {82},
pages = {102695},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102695},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124002371},
author = {Jingzhe Hu and Peixuan Wang and Dashe Li and Shue Liu},
keywords = {Dissolved oxygen, Multivariate, Time series, Long-term prediction, Transformer},
abstract = {Accurate and efficient long-term prediction of marine dissolved oxygen (DO) is crucial for the sustainable development of aquaculture. However, the multidimensional time dependency and lag effects of marine chemical variables present significant challenges when handling multiple inputs in univariate long-term prediction tasks. To address these issues, we designed a multivariate time-series long-term prediction model (LMFormer) based on the Transformer architecture. The proposed multivariate time-series decomposition strategy effectively leverages the feature information of prediction variables at different scales, thereby reducing the loss of critical information. Additionally, a dynamic variable selection strategy based on a gating mechanism was designed to optimize the collinearity problem in the multivariate data feature extraction process. Finally, an efficient two-stage attention architecture is proposed to effectively capture the long-range dependencies between dynamic features. This study conducted high-precision 7-day advance DO long-term predictions in two case studies, the environmentally stable Shandong Peninsula in China and the San Juan Islands in the United States, which are affected by extreme conditions such as ocean currents. The experimental results demonstrate the superior prediction performance and generalizability of the designed model. In the Shandong Peninsula case, the mean absolute error (MAE), root mean square error (RMSE), coefficient of determination (R2), and Kling–Gupta efficiency (KGE) reached 0.0159, 0.126, 0.9743, and 0.9625, respectively. In the San Juan Islands case, the MAE was reduced by an average of 42.34% compared to that of the baseline model, the RMSE was reduced by an average of 24.57%, the R2 increased by 22.54%, and the KGE improved by an average of 12.04%. Overall, the proposed prediction model effectively achieves long-term prediction of multivariate marine chemical data, providing valuable references for sustainable management and decision-making in aquaculture.}
}
@article{GONG2023102334,
title = {Research on facial recognition of sika deer based on vision transformer},
journal = {Ecological Informatics},
volume = {78},
pages = {102334},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102334},
url = {https://www.sciencedirect.com/science/article/pii/S1574954123003631},
author = {He Gong and Tianye Luo and Lingyun Ni and Ji Li and Jie Guo and Tonghe Liu and Ruilong Feng and Ye Mu and Tianli Hu and Yu Sun and Ying Guo and Shijun Li},
keywords = {Sika deer, Vision transformer, DenseNet, Face recognition, Patch flattening},
abstract = {In the face of global concerns about endangered ecosystems, it is vital to identify individual animals. Along these lines, in this work, a Vision Transformer (ViT) based model for sika deer individual recognition using facial data was designed. To get the satisfactory results, both low-level aspects like texture and color must also be considered, in addition to the high-level semantic information. Consequently, it was difficult to get good results by only applying advanced retrieval features. The standard ViT or ViT with ResNet (Residual neural network) as the backbone network may not be the best solution, as the direct patch flattening method of feature embedded in the conventional ViT is not applicable for performing deer face recognition. Therefore, DenseNet (Densely connected convolutional networks) block as Module 1 was used for extracting low-level features. DenseNet layers enable feature reuse through dense connections, and any layer can communicate directly. Thus maximum exchange of information flow between layers in the network is enabled. In Module 2, the mask approach was also used to eliminate extraneous information from the images and reduce interference from complicated backgrounds on the identification accuracy. In addition, the pixel multiplication of the feature map output from the two modules enabled the fusion of the local features with global features, enriching hence the expressiveness of the feature map. Finally, the ViT structure was run through pre-trained. The experimental results showed that the proposed model can reach an accuracy of 97.68% for identifying sika deer individuals and exhibited excellent generalization capabilities. A valid database for the individual identification of sika deer is provided by our work, significantly contributing to the conservation and promotion of the ecosystem.}
}