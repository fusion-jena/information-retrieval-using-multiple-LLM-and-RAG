Answer: The provided context does not specifically mention the criteria used to split the data for deep learning model training. However, it does mention that for the modeling approach described, the testing data were 25% of samples, which is a randomly sampled split that is standard modeling practice. This is performed through the createDataPartition function in the caret package. 

It does not provide information on the specific criteria used to split the data into training, testing, and validation sets for deep learning models. The context primarily focuses on random forests and does not delve into deep learning models. Therefore, I do not have enough information to provide a specific answer to the query.