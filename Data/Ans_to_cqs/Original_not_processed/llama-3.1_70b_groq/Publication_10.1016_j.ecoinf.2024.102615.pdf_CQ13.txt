According to the provided context, the hyperparameters used in the deep learning model (MLP model) are:

1. Number of neural network layers: 1-5
2. Number of neurons per layer: 64, 128, 256, 512, 1024, 2048 (nth power of 2)
3. Dropout: 0.1, 0.25, 0.35, 0.5
4. Learning rate: 0.001, 0.0001, 0.00001
5. Batch size: 32, 64, 128, 256

These hyperparameters were tuned using the grid search method to optimize the model's performance. The optimal combination of these hyperparameters is shown in Table 2, but the specific values are not specified in the query.