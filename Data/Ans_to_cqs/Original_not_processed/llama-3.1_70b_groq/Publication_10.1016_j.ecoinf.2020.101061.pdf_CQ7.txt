Answer:

Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context discusses the use of different proportions of training data (5%, 25%, 50%, and 75% of the total hand-annotations) to assess the sensitivity of the model to the number of hand-annotations, but it does not provide information on how the data was split for training, testing, and validation.

However, it can be inferred that the data was split into training and evaluation sets, as the context mentions "evaluation data" and "evaluation plots". Additionally, the context mentions that the experiment was rerun five times to account for the random subsampling of annotations, suggesting that some form of random splitting was used.

But without more information, it is not possible to determine the exact criteria used to split the data for deep learning model training.