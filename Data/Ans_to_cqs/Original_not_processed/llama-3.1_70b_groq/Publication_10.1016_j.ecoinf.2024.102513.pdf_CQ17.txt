Unfortunately, the provided context does not mention specific regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily focuses on the architecture of a neural network, the pooling layer, and the training process, but it does not delve into regularization techniques.

However, it does mention that the neural network was trained using a loss function, such as categorical cross-entropy, and that backpropagation was used to update weights using gradient descent or its variants. But it does not provide information on specific regularization methods used to prevent overfitting.

Therefore, I do not know the specific regularization methods used to prevent overfitting in the deep learning pipeline based on the provided context.