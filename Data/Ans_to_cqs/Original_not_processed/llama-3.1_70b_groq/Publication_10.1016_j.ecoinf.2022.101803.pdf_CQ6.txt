Answer:::

Unfortunately, the provided context does not mention specific preprocessing steps involved before training a deep learning model. The context appears to be focused on a specific algorithm (XGBoost) and its optimization using a nested k-fold cross-validation scheme, as well as the evaluation of different models using metrics such as R2. It does not provide information on preprocessing steps such as normalization, scaling, or cleaning.

However, it does mention that the dataset is split into subsets (tuning set, validation set, and test set) for the purpose of training and evaluating the model. But it does not provide details on any preprocessing steps that may have been applied to the data before splitting.

Therefore, I do not have enough information to provide a specific answer to the query.