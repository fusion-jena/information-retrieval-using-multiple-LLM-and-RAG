Answer:::
The provided context does not specifically mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that the "nnet" package used for the MLP ANN model provides possibilities for adjusting weighted decay and size, which can be used to counter the effects of model overfitting. 

Weighted decay is a form of L1 regularization, which adds a penalty term to the loss function for large weights. This can help prevent overfitting by reducing the magnitude of the weights. However, it is not explicitly stated whether L2 regularization or dropout is used in the pipeline.

Therefore, based on the provided context, the only regularization method mentioned is weighted decay (L1 regularization), but it is not clear if other methods like dropout or L2 regularization are used.