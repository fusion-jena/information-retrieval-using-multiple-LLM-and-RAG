Answer:

Unfortunately, the provided context does not explicitly mention the criteria used to determine when training is complete, such as validation loss plateau. The context primarily focuses on the experimental setup, data preprocessing, and the use of BERT models for classification tasks. It mentions that development sets were used to evaluate classification performance during experiments, but it does not provide details on the specific criteria used to determine when training is complete.

However, it does mention that the best performing classifier was used to classify the whole dataset after experiments had been conducted, suggesting that some form of evaluation or validation was used to determine the best performing model. Additionally, Figure 4 shows the relationship between the number of texts in training data and the median F1 achieved by classifiers over five runs, which could be used to determine when training is complete, but the specific criteria used is not specified.

Therefore, based on the provided context, I do not know the specific criteria used to determine when training is complete.