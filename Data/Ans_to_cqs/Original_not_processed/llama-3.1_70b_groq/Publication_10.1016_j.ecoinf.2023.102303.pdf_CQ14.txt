Answer: 
The provided context does not explicitly mention how the hyperparameters of the model are optimized. It only mentions that XGBoost was originally introduced as an efficient and distributed gradient boosting algorithm with "rapidly optimized hyper-parameters", but it does not provide further details on the optimization method used. Therefore, I don't know the specific method used for hyperparameter optimization in this case.