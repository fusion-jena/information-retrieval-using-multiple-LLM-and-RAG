Answer:::

Unfortunately, the provided pieces of context do not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The texts primarily focus on data augmentation techniques, transfer learning, and fine-tuning pre-trained models to improve performance and prevent overfitting. 

However, it is mentioned that the convolutional neural networks experienced overfitting, and data augmentation techniques were employed to address this issue. Data augmentation helps maintain dataset balance, reduce overfitting, and improve the generalization of deep learning models. 

While the texts do not specifically mention dropout or L2 regularization, they do discuss the importance of fine-tuning the top layers of the convolutional base using the dataset, which can help prevent overfitting. Additionally, the use of pre-trained models and fine-tuning them on the specific dataset can also help reduce overfitting.

In summary, the provided texts do not explicitly mention the regularization methods used to prevent overfitting, but they do discuss the importance of data augmentation and fine-tuning pre-trained models to improve performance and prevent overfitting.