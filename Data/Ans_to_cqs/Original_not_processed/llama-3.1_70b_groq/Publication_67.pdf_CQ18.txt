Answer:::
The provided context does not explicitly mention the strategy implemented to monitor the model performance during training. However, it does mention that the model parameters were configured by training the last two fully connected network layers in the dataset using a learning rate of 0.001 and a decay factor of 16 every 30 epochs. Additionally, it mentions the use of RMSProp as an optimization algorithm with a momentum of 0.9 and epsilon of 0.1. 

It also mentions that a five-fold cross-validation strategy was used to evaluate the approach and the baseline on the test dataset, but this seems to be more related to the validation phase rather than monitoring the model performance during training.