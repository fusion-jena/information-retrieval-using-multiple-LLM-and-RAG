According to the provided context, the data used for model training and selection were randomly partitioned into four parts:

1. Data for training candidate models (25% of the data; At)
2. Data for validating candidate models (50%; Av)
3. Data for training the selected candidate model (75%; Bt = At + Av)
4. Validation data to determine the optimal number of epochs to train the selected candidate model (25%; Bv)

Additionally, a fifth partition is used to assess the predictive performance of the fully trained ('final') model, which is the data of each year (i.e., 2013 to 2019) used separately for model testing (partition 'T'), and the data for the remaining years for model training.

Therefore, the criteria used to split the data for deep learning model training are:

* 25% for training candidate models
* 50% for validating candidate models
* 75% for training the selected candidate model (which includes the initial 25% used for training candidate models)
* 25% for validation to determine the optimal number of epochs
* A separate partition for testing the fully trained model, which is the data of each year used separately.