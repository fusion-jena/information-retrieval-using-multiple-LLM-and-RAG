Answer: Unfortunately, the provided context does not mention the specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context focuses on the architecture of the model, including the use of residual networks, batch normalization, and ReLU activation, but does not provide information on the optimization techniques employed. Therefore, I do not know the answer to this question based on the provided context.