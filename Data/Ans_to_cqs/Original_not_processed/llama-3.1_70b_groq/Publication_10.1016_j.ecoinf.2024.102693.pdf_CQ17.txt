Answer:::

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention a few techniques that can be related to regularization.

One of the papers mentioned, "Cutmix: regularization strategy to train strong classifiers with localizable features" by Yun et al. (2019), suggests that Cutmix is a regularization strategy used to train strong classifiers. Cutmix is a technique that combines two images and their labels to create a new training example, which can help to prevent overfitting.

Another paper mentioned, "mixup: Beyond Empirical Risk Minimization" by Zhang et al. (2017), proposes Mixup as a technique to prevent overfitting. Mixup is a method that creates new training examples by interpolating between two images and their labels.

While these papers mention techniques that can be used to prevent overfitting, they do not explicitly mention dropout or L2 regularization. Therefore, I do not know if these specific regularization methods are used in the deep learning pipeline mentioned in the context.