Answer:::

According to the provided context, the optimization function used in the deep learning pipeline is Stochastic Gradient Descent (SGD) (Bottou, 2012). This is mentioned in the section 4.1, "Performance metrics used to evaluate the model", under the subheading "(ii) Optimization Function". There is no mention of other optimization techniques such as Adam being used in the pipeline.