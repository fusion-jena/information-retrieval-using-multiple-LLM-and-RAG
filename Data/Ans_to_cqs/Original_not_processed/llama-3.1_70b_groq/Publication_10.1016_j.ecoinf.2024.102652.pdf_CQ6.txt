Answer: According to the provided context, before training a deep learning model, the training set must have its data normalized and standardized. This is mentioned in the section 2.6.3. Training process, which states that "To fit into the network, the training set must have its data normalized and standardized." However, the context does not provide further details on the specific normalization or scaling techniques used. It only mentions that the batch size was set to 32, and the optimizer used Adam processing, but it does not elaborate on the preprocessing steps involved in normalizing and standardizing the data.