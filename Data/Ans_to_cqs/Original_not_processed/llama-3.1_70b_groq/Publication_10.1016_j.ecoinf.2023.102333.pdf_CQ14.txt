Answer: The hyperparameters of the model are optimized using three popular hyperparameter optimization approaches: Random Search, Hyperband, and Bayesian Optimization. 

Random Search (RS) is a simple and effective optimization approach that involves selecting and evaluating a set of hyperparameters randomly to find the set with the best accuracy. This method is often used as a baseline for comparing other optimization methods and can outperform grid search and compete with Bayesian optimization for classification problems.

Hyperband is another optimization approach that was used in the study. Although it improved the classification accuracy, it involved making several assumptions about resource allocation that may only hold in some scenarios.

Bayesian Optimization is a systematic approach towards hyperparameter tuning, but it can be computationally expensive and may not always converge to the global optimum.

The study found that each method produced its unique architecture for the MLP model, with Random Search providing the largest architecture with 34 hidden layers, but requiring additional time to randomly identify the best hyperparameter combination. Hyperband was found to be the most efficient method, with the lowest computation time compared to the other methods.