Answer:::

Unfortunately, the provided context does not explicitly mention the optimization techniques used in the deep learning pipeline. However, it does mention the use of the XGBoost algorithm, which is a popular machine learning algorithm that can be optimized using various techniques.

In one of the references, "Improving audit opinion prediction accuracy using metaheuristics-tuned XGBoost algorithm with interpretable results through SHAP value analysis," the authors use metaheuristics to tune the XGBoost algorithm. Metaheuristics are high-level optimization techniques that can be used to optimize the hyperparameters of machine learning algorithms.

While the context does not explicitly mention the use of SGD (Stochastic Gradient Descent) or Adam, it is possible that these optimization techniques may have been used in the deep learning pipeline. However, without further information, it is impossible to confirm this.

Therefore, the answer to the query is that the context does not provide enough information to determine the optimization techniques used in the deep learning pipeline.