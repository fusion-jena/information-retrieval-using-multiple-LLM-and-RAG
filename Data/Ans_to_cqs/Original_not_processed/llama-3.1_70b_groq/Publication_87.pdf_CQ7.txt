Answer:::
The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does mention that the validation dataset is created by filtering the data to include only rows between a certain range, specifically `floor(n()*80/100) + 1` and `n()`. This suggests that the data is split into training and validation sets based on a percentage, with 80% of the data used for training and 20% used for validation.

There is no mention of a test set in the provided context. It is possible that the validation set is used as a test set, or that a separate test set is not used in this particular case study.

It is also worth noting that the context mentions that the model is trained for 2 epochs, but that the full results presented in the main text were obtained by training the model for 20 epochs. This suggests that the model training process may involve multiple iterations or experiments, but the exact criteria used to split the data for each iteration is not specified.