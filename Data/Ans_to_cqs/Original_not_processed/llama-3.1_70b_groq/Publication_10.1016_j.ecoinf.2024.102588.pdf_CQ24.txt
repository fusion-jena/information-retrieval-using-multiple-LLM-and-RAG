Answer:::

The provided context does not explicitly discuss strategies for handling randomness in the deep learning pipeline. However, it does mention the use of random state and random subsets in some machine learning models.

For instance, in the Random Forest (RF) model, the hyper-parameters were set to the number of estimators at 100 and the random state at 0. This suggests that the random state is used to ensure reproducibility of the results.

Additionally, the context mentions the use of "randomly selected input subsets" in the Random Forest regression model. This implies that the model uses random sampling to select subsets of the input data, which can help to reduce overfitting and improve generalization.

However, the context does not provide information on how randomness is handled in the deep learning pipeline, such as the use of random seed values. Therefore, I do not know the specific strategies employed to handle randomness in the deep learning pipeline.