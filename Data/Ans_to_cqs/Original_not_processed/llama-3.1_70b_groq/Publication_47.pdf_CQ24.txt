Answer:::
To handle randomness in the deep learning pipeline, the employed strategy is to perform cross-validation by shifting the validation set 5 times. This approach is used to quantify the average validation cross-entropy loss and accuracy. Additionally, the data set is randomly split into a training set (90% of the entries) and a test set (10%), and 20% of the training set is used for validation. This random splitting and cross-validation help to reduce the impact of randomness in the deep learning pipeline. However, the specific random seed value used is not mentioned in the provided context.