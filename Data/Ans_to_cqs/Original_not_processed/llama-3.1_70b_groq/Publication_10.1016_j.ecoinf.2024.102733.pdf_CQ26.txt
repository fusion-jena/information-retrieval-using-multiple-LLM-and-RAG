Answer:

According to the provided context, several techniques are used to address data bias during preprocessing of the deep learning pipeline. These techniques aim to handle imbalanced datasets where the dominant classes heavily influence training, while minority classes have minimal impact.

The techniques mentioned in the context include:

1. **Undersampling**: This involves randomly removing samples from the majority classes to reduce their influence on the model.
2. **Oversampling**: This involves duplicating samples from the minority classes to increase their representation in the dataset.
3. **Synthetic Minority Over-sampling Technique (SMOTE)**: This is a more sophisticated approach that generates synthetic samples based on the feature space and combines features from neighboring samples. SMOTE has been widely used and has demonstrated its effectiveness in handling imbalanced datasets.

While the context does not explicitly mention Stratified splitting or Diverse data collection, it does highlight the importance of addressing data bias during preprocessing to ensure that the model is not biased towards the majority class. By using techniques like undersampling, oversampling, and SMOTE, it is possible to mitigate the effects of data bias and improve the performance of the model on minority classes.