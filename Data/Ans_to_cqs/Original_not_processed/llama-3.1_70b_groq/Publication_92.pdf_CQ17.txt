Answer:::
Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The text discusses the architecture of the network, which follows the GoogLeNet's with 27 layers, 9 inception layers, and a soft-max classifier, but it does not provide information on the specific regularization techniques used.

However, it is worth noting that the text mentions that the network was adapted to the size of the thumbnails, which allowed for better results than a classic architecture. This suggests that some modifications were made to the network to improve its performance, but the specific details of these modifications are not provided.

In general, common regularization methods used to prevent overfitting in deep learning pipelines include dropout, L2 regularization, and batch normalization, among others. However, without further information, it is not possible to determine which specific methods were used in this particular pipeline.