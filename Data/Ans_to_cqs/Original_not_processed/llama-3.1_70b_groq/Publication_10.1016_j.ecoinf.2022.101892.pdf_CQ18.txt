Answer:::
The provided context does not explicitly mention the strategy implemented to monitor the model performance during training. However, it does mention the evaluation metrics used to compare the performance of different models, such as Mean Absolute Error (MAE) and Classification Success (CS). 

Additionally, the context mentions that the models were tested under the same experiment setting and the same GPU to make comparisons between them fair. This suggests that the performance of the models was evaluated and compared after training, but it does not provide information on how the performance was monitored during training.

Therefore, based on the provided context, I do not know the specific strategy implemented to monitor the model performance during training.