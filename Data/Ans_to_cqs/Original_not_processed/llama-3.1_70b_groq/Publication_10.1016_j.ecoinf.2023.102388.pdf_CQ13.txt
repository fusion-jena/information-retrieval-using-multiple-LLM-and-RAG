Answer:

The hyperparameters used in the deep learning model are as follows:

* Optimizer: Stochastic Gradient Descent (SGD)
* Learning rate: 
  - 0.0001 (in the no-overfitting setting)
  - 0.001 (in the setting described in the last paragraph, possibly for the Siamese Neural Network)
* Weight decay: 
  - 0.5 (in the no-overfitting setting)
  - 0.5 (applied every 512 iterations in the setting described in the last paragraph)
* Batch size: 32
* Momentum: 0.9 (in the setting described in the last paragraph)
* Number of training epochs: 200 (in the no-overfitting setting)
* Dropout: 0.5 (in the no-overfitting setting)
* Batch-norm: used in the no-overfitting setting, but not in the overfitting setting.