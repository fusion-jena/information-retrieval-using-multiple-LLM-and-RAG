Answer:::

The provided context does not explicitly mention the preprocessing steps involved before training the DeepLabV3+ model, such as normalization, scaling, or cleaning. However, it does mention that the images were enhanced by flipping, exchanging channels, rotating, and adding noise to augment the training set. 

Additionally, the context mentions that the images were cut into regular image blocks of size 32 × 32 pixels with a redundancy rate of 0.5 to prevent memory overflow. This can be considered a preprocessing step, but it is more related to data preparation than traditional preprocessing techniques like normalization or scaling.

Therefore, based on the provided context, the only preprocessing steps mentioned are:

* Cutting images into regular blocks of size 32 × 32 pixels with a redundancy rate of 0.5
* Data augmentation techniques:
	+ Flipping images and labels along the X or Y axis
	+ Exchanging between multiple image channels while keeping labels unchanged
	+ Randomly rotating images and labels by 90°
	+ Randomly adding noise to images while keeping labels unchanged

No information is provided about normalization, scaling, or cleaning.