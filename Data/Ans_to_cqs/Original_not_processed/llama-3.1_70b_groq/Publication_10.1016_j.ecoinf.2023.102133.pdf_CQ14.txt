Answer: The hyperparameters of the model are optimized using the grid search technique. This involves testing different combinations of hyperparameters and comparing their performance to select the best model. Specifically, for the Multilayer Perceptron (MLP) predictor, the grid search technique was applied to test different hyperparameters such as solvers, number of neurons in the hidden layers, regularization factor, activation function, and learning rate. The best combination of hyperparameters that optimized the performance of the model was selected and adopted for analysis. Similarly, for the Random Forest (RF) predictor, the grid search technique was used to test different hyperparameters such as the number of decision trees, maximum depth of the decision tree, and number of features to consider at every split.