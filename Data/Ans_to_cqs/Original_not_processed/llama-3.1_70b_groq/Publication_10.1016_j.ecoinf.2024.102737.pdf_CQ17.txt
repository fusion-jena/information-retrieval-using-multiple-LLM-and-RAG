Answer:::

Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context primarily focuses on the use of contrastive loss as a loss function, Siamese networks, and the performance of Convolutional Neural Networks (CNNs) in various classification tasks.

However, it does mention "regularized cross entropy" as a loss function used in the original architecture of Koch et al., (2015). This suggests that some form of regularization is being used, but the specific methods (e.g., dropout, L2 regularization) are not mentioned.

Therefore, I do not have enough information to provide a definitive answer to the query.