Answer:::
The hyperparameters used in the deep learning model are not explicitly stated in the provided context. However, it is mentioned that the algorithms were trained using Adam as the optimizer. Additionally, the batch size is mentioned as 64 samples, and the number of epochs is 100. The context also mentions that a min-max scaler was used, but it is not clear if this is a hyperparameter or a preprocessing step. There is no mention of the learning rate.