Answer: 

To ensure the generalizability of the deep learning model, the researchers used a diverse dataset and cross-validation techniques. Specifically, they used three source-target pairs (GH!LH, GH!LL, and LL!LH) to simulate two alternative scenarios: (i) a global image database is used to predict local samples, and (ii) conventional images are used to predict images from a different dataset. This approach allowed them to evaluate the model's performance on different datasets and assess its ability to generalize to new, unseen data.

Additionally, the researchers used a technique called "between-datasets classification," where the CNN model was trained on a source dataset and then used to predict images from a different target dataset. This approach helped to evaluate the model's ability to generalize to new datasets and assess its robustness to variations in image quality and complexity.

However, there is no mention of stratified splitting in the provided context. It is also worth noting that the researchers used a random selection of images from the source dataset for training, which may not be the same as cross-validation. While the researchers did evaluate the model's performance on different datasets, it is not clear if they used a formal cross-validation approach, such as k-fold cross-validation.