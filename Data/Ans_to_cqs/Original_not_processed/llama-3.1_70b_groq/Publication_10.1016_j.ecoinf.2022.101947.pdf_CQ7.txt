Answer:

The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does describe a holdback trial partitioning test used to determine the optimal number of footprint trails required for the algorithm training set and test sets.

According to the text, the test set size was plotted against itself, against the predicted value for the test size, and against the mean predicted value for each test size. The results showed that the predicted mean for each test:training set size was close to the actual test size up to a certain ratio (32:12), but the variation in sequential trials increased after a certain point (20:24), potentially resulting in reduced algorithm accuracy.

It can be inferred that the data was split into training and test sets using a ratio-based approach, where the ratio of test set size to training set size was varied to evaluate the performance of the algorithm. However, the exact criteria used to split the data (e.g., random sampling, stratified sampling, etc.) are not specified in the provided context.

Therefore, the answer to the query is that the context does not provide explicit information on the criteria used to split the data for deep learning model training, but it does describe a ratio-based approach used to evaluate the performance of the algorithm.