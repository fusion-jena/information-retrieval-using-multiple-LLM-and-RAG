Unfortunately, the provided context does not mention the specific criteria used to split the data for deep learning model training. The context appears to be focused on the application of big-data mining approaches and Artificial Intelligence models to predict biodiversity changes and study the implications of climate change on ecosystem conservation, particularly in fragile ecosystems like wetlands.

However, I can provide some general information on common practices for splitting data in machine learning and deep learning. Typically, the data is split into three parts: training, validation, and testing sets. The training set is used to train the model, the validation set is used to tune the model's hyperparameters and evaluate its performance during training, and the testing set is used to evaluate the final performance of the trained model.

Common ratios for splitting the data include 80% for training, 10% for validation, and 10% for testing. However, these ratios can vary depending on the specific problem, the size of the dataset, and the specific requirements of the project.

In the context of the provided text, it is likely that the authors would have split their data into training, validation, and testing sets to train and evaluate their big-data mining approaches and Artificial Intelligence models. However, without further information, I cannot provide specific details on the criteria they used to split their data.