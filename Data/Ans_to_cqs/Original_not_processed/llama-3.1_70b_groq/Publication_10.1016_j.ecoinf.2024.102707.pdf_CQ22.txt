Answer: The metrics used to evaluate the performance of the deep learning model are F1 score, precision, and recall. The F1 score is the harmonic mean between precision and recall, and it is a commonly used measure of performance that balances both missing predictions (FN) and not predicting too many instances (FP). Additionally, the model's performance is also evaluated using mean average precision (mAP or mAP[0.5:0.95]), but the authors do not consider this metric to be informative for the current study due to its focus on the exact overlap between the ground truth and predicted bounding boxes.