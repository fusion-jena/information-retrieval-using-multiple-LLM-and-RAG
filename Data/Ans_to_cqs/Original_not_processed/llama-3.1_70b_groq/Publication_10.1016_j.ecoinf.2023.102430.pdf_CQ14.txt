Answer:::
The provided context does not explicitly mention how the hyperparameters of the model are optimized. It only mentions that the hyperparameters for the classical machine-learning algorithms (AB, GB, HB, and LD) were left at scikit-learn default values, except for the learning rate of GB and HB (which were set to 0.15) and the tolerance threshold value for LD (set to 1 Ã— 10^-10). For the AN model implemented in MATLAB, it mentions that the stochastic gradient descent with momentum optimizer was used with default settings, except for the initial learning rate (set to 0.001) and the maximum number of epochs (set to 15). However, it does not provide information on how these hyperparameters were chosen or optimized.