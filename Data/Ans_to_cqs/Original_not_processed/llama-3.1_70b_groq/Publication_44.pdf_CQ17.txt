Answer:::

Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention some techniques that can help reduce overfitting, such as:

* Data augmentation: The context mentions that data augmentation techniques like flipping and rotation were applied to the training images to help the model generalize better.
* Reducing the dimension of the fully connected layer: The context mentions that the feature vector of the fully connected layer was reduced from 2048 units to 128 units, which helped in reducing the computational complexity without sacrificing much on performance.

While these techniques can help reduce overfitting, they are not traditional regularization methods like dropout or L2 regularization. The context does not mention the use of dropout or L2 regularization explicitly.

Therefore, based on the provided context, I do not know the specific regularization methods used to prevent overfitting in the deep learning pipeline.