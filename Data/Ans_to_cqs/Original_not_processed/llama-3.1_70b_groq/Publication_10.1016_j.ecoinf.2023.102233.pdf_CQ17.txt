Answer:

Unfortunately, the provided context does not mention specific regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily focuses on the active learning approach, CNN model development, and hyperparameter tuning using a grid search technique. It mentions the use of a learning rate of 0.001, batch size of 64, and the number of epochs, but does not provide information on regularization methods.

Therefore, I don't know the specific regularization methods used to prevent overfitting in the deep learning pipeline.