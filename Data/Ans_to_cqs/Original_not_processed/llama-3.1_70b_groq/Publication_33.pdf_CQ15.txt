Answer:::
Unfortunately, the provided context does not explicitly mention the optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. However, it does mention the use of back-propagation, which is a process used to optimize the parameters of the Convolutional Neural Network (CNN) through the comparison between its output and the correct class of the training element. 

Additionally, the context mentions the use of TensorFlow, which is a system for large-scale machine learning that supports various optimization techniques, including SGD and Adam. However, it does not specify which optimization technique is used in this particular case.

Therefore, based on the provided context, we cannot determine the specific optimization techniques applied in the deep learning pipeline.