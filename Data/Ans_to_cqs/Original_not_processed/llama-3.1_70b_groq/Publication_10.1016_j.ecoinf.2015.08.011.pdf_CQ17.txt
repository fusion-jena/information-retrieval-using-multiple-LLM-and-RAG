Answer: 

The provided context does not explicitly mention the use of regularization methods such as dropout or L2 regularization to prevent overfitting. However, it does mention the use of early stopping as a regularization technique to prevent overfitting. According to the text, the training process was stopped when the network began to overfit the data, i.e., when the error on the validation set started to increase. This is a common technique used to prevent overfitting, but it is not the same as dropout or L2 regularization. Therefore, based on the provided context, the answer to the query is that early stopping is the regularization method used to prevent overfitting, but not dropout or L2 regularization.