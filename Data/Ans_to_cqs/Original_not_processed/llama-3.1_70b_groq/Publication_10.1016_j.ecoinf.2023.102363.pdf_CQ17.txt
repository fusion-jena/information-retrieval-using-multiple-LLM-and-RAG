Answer:::
The regularization methods used to prevent overfitting in the deep learning pipeline are dropout and DropConnect. According to the text, "Drop out layers randomly discard the output of the hidden nodes during training, DropConnect randomly discards the input of the hidden layer." This suggests that both dropout and DropConnect are employed to prevent overfitting. Additionally, a dropout rate of 0.2 is used during fine-tuning. There is no mention of L2 regularization in the provided context.