Answer:::

The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does describe the K-fold cross-validation technique used for model validation.

According to the context, the dataset was divided into four mutually exclusive folds through stratified sampling. Each fold served as the validation set, while the remaining three folds constituted the training set for model training. This process iterated four times with distinct validation folds, resulting in four different prediction arrays.

Additionally, the context mentions that random under-sampling (RUS) was applied to the training set to address imbalances, while the validation set remained unchanged.

It is not explicitly stated how the data was split for the deep learning model training, but it can be inferred that the K-fold cross-validation technique was used to split the data into training and validation sets. However, the exact criteria used to split the data (e.g., train, test, validation) are not specified in the provided context.