Answer:::

The metrics used to evaluate the performance of the deep learning models (CNN and XGB) in the provided context include:

1. Overall Accuracy (%): This metric measures the proportion of correctly classified samples out of the total number of samples.
2. Kappa Statistic: This metric measures the agreement between the predicted and actual class labels, taking into account the chance agreement.
3. Mean F1-Score: This metric measures the average F1-score across all classes, where F1-score is the harmonic mean of precision and recall.
4. User Accuracy (UA) and Producer Accuracy (PA): These metrics are used in the confusion matrices (Tables A3 and A4) to evaluate the performance of the models. User accuracy measures the proportion of correctly classified samples for a given class, while producer accuracy measures the proportion of actual samples that are correctly classified for a given class.
5. F1-Score (per-class): This metric is used to evaluate the performance of the models for each class separately, as shown in Figure 3.

These metrics provide a comprehensive evaluation of the performance of the deep learning models, including their accuracy, precision, and recall.