Answer:::
The provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model. However, it does mention that the models were trained for 150 epochs using Nvidia Tesla K80 or P100 GPUs, and the learning rate was reduced by a factor of 10 after steps of 30 epochs. 

Additionally, the context mentions that the models were compared based on their performance on a test dataset, as shown in Table 1. This suggests that the models were evaluated on a separate test set, which is a common practice to ensure the generalizability of a model. However, it does not provide information on whether the dataset was diverse, or if cross-validation or stratified splitting was used.

It is also worth noting that the context mentions the use of batch normalization, which can help improve the generalizability of a model by normalizing the input data for each layer. However, this is not a direct measure to ensure generalizability.

Overall, while the context provides some information on the training and evaluation of the models, it does not provide a clear answer to the question of what measures were taken to ensure the generalizability of the deep learning model.