Answer:::
The optimization technique applied in the deep learning pipeline is stochastic gradient descent (SGD) with a momentum of 0.9. This is mentioned in the provided context as "we applied a stochastic gradient descent algorithm with a momentum of 0.9". There is no mention of Adam or other optimization techniques being used in the pipeline.