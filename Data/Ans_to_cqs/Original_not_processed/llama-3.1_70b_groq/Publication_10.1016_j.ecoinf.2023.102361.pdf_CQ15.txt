Unfortunately, the provided context does not mention the optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily discusses the datasets, deep learning models (e.g., VGG16, VGG19, ResNet-50, Inception-V3, etc.), and their performance metrics (Precision, Recall, F1 Score). It does not provide information on the optimization techniques used for training the models.

Therefore, I don't know the answer to this question based on the provided context.