Answer:

Unfortunately, the provided context does not specifically mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on annotation campaigns, inter-annotator variability, and the impact of annotator behavior on model performance.

However, it does mention the importance of representative training data and the potential for bias in the initial training of annotators. It also suggests that instructing annotators to adopt a more conservative approach could be beneficial in future annotation campaigns.

Regarding the specific techniques mentioned in the query (Stratified splitting, oversampling, undersampling, Diverse data collection), the context does not provide any information on their use or effectiveness in addressing data bias in this particular study.

Therefore, I do not have enough information to provide a comprehensive answer to the query.