Answer: Unfortunately, the provided context does not mention the optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on the performance metrics used to evaluate the deep learning models, the architectures of the models (e.g., EfficientNet, InceptionResNetv2, ResNet50v2), and the results of the experiments. Therefore, I don't know the answer to this question based on the provided context.