Answer:::
The optimization technique applied in the deep learning pipeline is the Adam optimizer. According to the text, "Each CNN was trained for 50 epochs using the Adam optimiser (Kingma and Ba, 2014) and a batch size of 32." This indicates that the Adam optimizer was used to optimize the CNNs during training. There is no mention of other optimization techniques such as SGD being used in the pipeline.