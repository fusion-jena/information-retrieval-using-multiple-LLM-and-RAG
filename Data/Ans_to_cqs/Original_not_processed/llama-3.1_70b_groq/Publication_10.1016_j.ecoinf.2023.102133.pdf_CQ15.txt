Answer:::
According to the provided context, the optimization technique applied in the deep learning pipeline is Adam, which is a method for stochastic optimization. This is mentioned in the context as "Adam solver (Kingma and Ba, 2014)" and is cited as a reference. Additionally, the context mentions that the learning rate is constant, but it does not provide information about other optimization techniques such as SGD. Therefore, the answer is that Adam is the optimization technique applied in the deep learning pipeline, but it is not clear if other techniques like SGD are also used.