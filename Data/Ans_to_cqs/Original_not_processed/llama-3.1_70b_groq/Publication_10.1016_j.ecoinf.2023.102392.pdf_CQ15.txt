Answer:::
The provided context does not specifically mention the optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. However, it does mention the use of the eXtreme gradient boosting (XGBoost) model, which is a type of gradient boosting framework. Additionally, it mentions the use of ABC (Artificial Bee Colony) optimization technique in an inference system to enhance the prediction model's performance. But it does not provide information about the optimization techniques used in the deep learning pipeline.