Answer:::
The provided context does not explicitly mention regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention "network training by reducing internal covariate shift" which is related to the concept of batch normalization, a technique used to reduce overfitting. 

Additionally, the context does not provide a comprehensive list of regularization methods. However, it does discuss the importance of high-quality training datasets in preventing underperforming algorithms. It also mentions the limitations of deep learning models, including their reliance on the quality and completeness of the training datasets.

It is worth noting that the context does not provide enough information to give a comprehensive answer to the query. However, based on general knowledge, some common regularization methods used to prevent overfitting in deep learning pipelines include dropout, L2 regularization (also known as weight decay), and batch normalization.