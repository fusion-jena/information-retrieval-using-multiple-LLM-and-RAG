Answer:::

Unfortunately, the provided context does not mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context appears to be related to remote sensing, feature selection, and classification models, but it does not discuss deep learning or regularization methods specifically.

However, I can suggest that the context does mention the use of ensemble methods such as Random Forest (RF), AdaBoost, XGBoost, and LightGBM, which can help to prevent overfitting by combining the predictions of multiple models. Additionally, the context mentions the use of Recursive Feature Elimination and Cross-Validation (RFECV) for feature selection, which can also help to reduce overfitting by selecting the most relevant features.

But, I couldn't find any specific information about regularization methods such as dropout or L2 regularization in the provided context.