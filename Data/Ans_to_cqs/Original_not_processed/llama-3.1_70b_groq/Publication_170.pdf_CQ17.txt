Answer:::

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that the DCNN model used in the study, AlexNet, performs Local Response Normalization (LRN) processing and Rectified Linear Unit (ReLU) activation function processing in each layer, except for the last fully connected layer.

LRN is a type of regularization technique that helps to prevent overfitting by normalizing the responses of neurons in a layer. However, it is not explicitly mentioned whether dropout or L2 regularization were used in the study.

Therefore, based on the provided context, the only regularization method that can be confirmed is Local Response Normalization (LRN).