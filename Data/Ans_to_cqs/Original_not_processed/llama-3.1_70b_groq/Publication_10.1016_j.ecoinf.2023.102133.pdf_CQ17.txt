Answer:::
Unfortunately, the provided context does not mention specific regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily focuses on the configuration of the neural network model, including the Adam solver, learning rate, and rectifier activation function (ReLU), as well as the hyperparameters of the Random Forest (RF) model. However, it does not provide information on regularization methods used to prevent overfitting. Therefore, I do not know the answer to this question based on the provided context.