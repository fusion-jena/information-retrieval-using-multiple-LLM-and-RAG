Answer: The text does not mention how the hyperparameters of the model are optimized. It only mentions the specific hyperparameters used to train the models, such as the number of epochs (500), initial learning rate (0.01), weight decay (0.005), and optimizer (Adam with beta1 of 0.937). It does not provide information on the method used to select or optimize these hyperparameters, such as grid search or random search.