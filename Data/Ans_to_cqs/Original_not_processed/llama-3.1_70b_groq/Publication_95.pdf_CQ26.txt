Answer:::

To address data bias during preprocessing of the deep learning pipeline, the provided context mentions the following techniques:

1. **Stratified splitting**: The context mentions that samples in each set (training, validation, and test sets) must be independent and have similar class distributions. This implies that stratified splitting is used to ensure that the class distribution is maintained across the different sets.

2. **Diverse data collection**: The context mentions that the na√Øve approach of randomly sampling images from the full data set may lead to information leakage between the data sets due to images being captured in close proximity and having overlapping fields of views. This suggests that diverse data collection is used to collect data from different sources or environments to minimize this issue.

No mention is made of **oversampling** or **undersampling** in the provided context. These techniques are commonly used to address class imbalance issues in datasets, but they are not mentioned in the provided text.

It is worth noting that the context also mentions a three-step data augmentation procedure that is applied to the images during training. This procedure includes randomly flipping images horizontally, scaling the contrast of each image channel, and randomly cropping the image. While this is not a technique specifically used to address data bias, it can help to increase the diversity of the training data and reduce overfitting.