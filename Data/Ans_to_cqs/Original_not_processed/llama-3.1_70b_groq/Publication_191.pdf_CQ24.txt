Answer:::

Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed values. However, it does mention that the authors "randomly subsample some of the feature maps/channels in each layer" to gain insights into the local responses of individual filters in each convolution layer. This suggests that randomness is used as a tool for analysis, but it does not provide information on how randomness is handled in the deep learning pipeline.

Additionally, the context mentions that the authors "pre-train each network using its corresponding leaf data" and combine the softmax outputs using fusion methods such as average (ave) or max voting (mav). This suggests that the authors may be using ensemble methods to reduce the impact of randomness, but this is not explicitly stated.

Overall, the provided context does not provide a clear answer to the question of how randomness is handled in the deep learning pipeline.