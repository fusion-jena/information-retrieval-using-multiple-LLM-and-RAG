Answer:

Based on the provided context, it appears that data augmentation is used to address data bias during preprocessing of the deep learning pipeline. Specifically, the text mentions that "Performing data augmentation on training datasets is a widely used technique in deep learning, including sound classification applications, to regularize models and provide more robust features." The technique used for data augmentation in this context is splitting the merged .wav training file for each species in half and then adding these two halves sample-wise. This augmented .wav file is then split into 2-s increments and mel-spectrograms are computed.

Additionally, the text mentions that the dataset was increased by 50% after data augmentation, which suggests that this technique is used to address the issue of limited training data.

There is no mention of stratified splitting, oversampling, or undersampling in the provided context. However, it is mentioned that the authors sought to explore different network sizes in conjunction with pre-training with additional acoustic reference data from outside of their audio domain, followed by fine-tuning with ROI data from their study site. This suggests that diverse data collection is used to some extent, but the details of this process are not provided.

Overall, the primary technique used to address data bias in this context appears to be data augmentation through splitting and recombining audio files.