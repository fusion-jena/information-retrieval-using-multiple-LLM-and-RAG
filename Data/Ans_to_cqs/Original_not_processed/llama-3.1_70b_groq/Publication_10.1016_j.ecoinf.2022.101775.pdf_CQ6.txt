Answer:::
According to the provided context, before training a deep learning model, the following preprocessing steps are involved:

1. Manual removal of the testing set from the available data.
2. Splitting the remaining data into training and validation sets, where 10% of the data serves as the validation set to check for overfitting.
3. Scaling the data using a min-max scaler, which is later reverted to compute the performance metrics in the test set.

No specific cleaning steps are mentioned in the context. However, it is mentioned that the data from low-cost Wireless Sensor Networks (WSNs) should be pre-processed to maintain data assurance and quality. But the specific cleaning steps are not provided.

Additionally, the context mentions that embedding layers can be used to solve the one-hot encoding problem, which can help in reducing the dimensionality of sparse data. But this is not a traditional preprocessing step, rather a technique used in deep learning models.