Answer:::

Unfortunately, the provided context does not mention the specific criteria used to split the data for deep learning model training. The context primarily focuses on explaining the architecture of a Convolutional Neural Network (CNN) and its application in species distribution modeling, but it does not discuss data splitting strategies.

However, in general, common practices for splitting data in deep learning include:

* Random splitting: dividing the data into training, validation, and testing sets randomly, often with a ratio of 80% for training, 10% for validation, and 10% for testing.
* Stratified splitting: dividing the data into training, validation, and testing sets while maintaining the same class distribution in each set.
* K-fold cross-validation: dividing the data into k folds, using k-1 folds for training, and one fold for testing, and repeating the process k times.

These strategies help ensure that the model is trained and evaluated on different subsets of the data, reducing overfitting and improving the model's generalizability. However, without more specific information, it is unclear which strategy was used in the context provided.