Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context primarily focuses on hyperparameter optimization for LSTM neural networks using the TPEBO algorithm, and does not provide information on data splitting criteria.

However, in general, common practices for splitting data in deep learning model training include:

* Random splitting: randomly dividing the data into training, test, and validation sets.
* Stratified splitting: dividing the data into training, test, and validation sets while maintaining the same proportion of class labels in each set.
* K-fold cross-validation: dividing the data into k subsets and using each subset as a validation set while the remaining subsets are used for training.

But again, the provided context does not specifically mention these criteria, so I couldn't provide a more specific answer based on the given text.