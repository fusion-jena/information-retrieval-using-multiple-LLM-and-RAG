Answer: The metrics used to evaluate the performance of the model are Accuracy, Precision, Recall, and F-measure. 

Accuracy is defined as the proportion of correct predictions out of total predictions, and can be calculated as (TP + TN) / (TP + TN + FP + FN), where TP is the number of true positive predictions, TN is the number of true negative predictions, FP is the number of false positive predictions, and FN is the number of false negative predictions.

Precision is the fraction of relevant instances among the retrieved instances for a class, and can be calculated as TP / (TP + FP).

Recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances, and can be calculated as TP / (TP + FN).

The F-measure score is the harmonic mean of Precision and Recall, and can be calculated as 2 * (Precision * Recall) / (Precision + Recall).

These metrics are used to evaluate the performance of the model, with the F-measure being used to rank the applied algorithms from worst to best.