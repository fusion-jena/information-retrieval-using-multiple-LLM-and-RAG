Answer:::

The hyperparameters used in the deep learning models are as follows:

* Learning rate:
	+ For Vanilla Inception-V3 and ViT, the learning rate was set to 10^-5.
	+ For Deep Otolith ResNet, the learning rate was set to 10^-4, as suggested by Politikos et al. (2021).
	+ For Inception, the learning rate was set to 4 Ã— 10^-4.
* Optimizer:
	+ For Hugging Face models (ViT), the AdamW optimizer was used, which is the default optimizer in the transformers library by Hugging-Face.
	+ For Inception-V3, the Adam optimizer was used, as it was used in previous work (and AdamW is not available in Keras).
* Batch size: The batch size was set to 16 examples.

Note that these hyperparameters are specific to the deep learning models used in the study and may not be applicable to other models or tasks.