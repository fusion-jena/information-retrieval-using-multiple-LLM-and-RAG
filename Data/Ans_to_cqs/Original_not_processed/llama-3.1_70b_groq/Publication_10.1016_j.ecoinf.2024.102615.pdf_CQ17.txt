Answer: 

The provided context does not explicitly mention the use of L2 regularization as a regularization method to prevent overfitting in the deep learning pipeline. However, it does mention the use of dropout layers as a regularization method. The context states that the percentage values of the dropout layers were one of the hyperparameters that were optimized using the grid search method. This suggests that dropout was used as a regularization technique to prevent overfitting in the model. 

Additionally, the context mentions that the optimal model was obtained with an R value of 0.76 after optimizing the hyperparameters, including the percentage values of the dropout layers. This implies that the use of dropout layers was effective in improving the model's performance and preventing overfitting. 

Therefore, based on the provided context, the regularization method used to prevent overfitting in the deep learning pipeline is dropout. However, it is not clear if other regularization methods, such as L2 regularization, were also used.