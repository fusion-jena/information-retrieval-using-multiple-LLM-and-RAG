Answer:::

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that the model is regularized during the validation process, but it does not specify the methods used for regularization.

It is mentioned that the Adam optimizer is used to fine-tune the model, which has an exponential decay rate of first-moment estimation of 0.9. This could be related to regularization, but it is not explicitly stated.

Additionally, the context mentions k-fold cross-validation as a resampling technique to avoid overfitting. This is a method used to evaluate the model's performance on unseen data and prevent overfitting, but it is not a regularization method per se.

Therefore, based on the provided context, we cannot determine the specific regularization methods used to prevent overfitting in the deep learning pipeline.