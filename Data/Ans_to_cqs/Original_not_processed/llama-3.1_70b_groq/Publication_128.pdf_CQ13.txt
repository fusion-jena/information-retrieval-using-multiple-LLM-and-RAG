Answer:::

The provided context mentions some of the hyperparameters used in the deep learning models. The hyperparameters mentioned are:

* Batch size: 30 (during training), but images are tested one by one.
* Learning rate: 0.001
* Dropout rate: 0.001
* Bias value: 0
* Activation function: Leaky ReLU (an optimized rectified linear activation)
* Width multiplier (for MobileNet): 1.2
* Resolution multiplier (for MobileNet): 1
* Number of epochs: 60 (for models with less than 100 layers) or 80 (for models with 100 layers or more)

However, the optimizer used in the model is not explicitly mentioned in the provided context. It only mentions that the activation function used is Leaky ReLU, but it does not provide information about the optimizer.

Additionally, the context mentions that the models use a fully connected layer with softmax activation, which has 28 nodes, but this is not a hyperparameter in the classical sense.

It's worth noting that the context provides more information about the model architecture and the computational resources used, but it does not provide a comprehensive list of hyperparameters used in the model.