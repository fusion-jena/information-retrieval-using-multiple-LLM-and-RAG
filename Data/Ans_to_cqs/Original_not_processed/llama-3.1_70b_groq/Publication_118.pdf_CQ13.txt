Answer: 
Unfortunately, the provided context does not mention the hyperparameters used in the deep learning model, such as the learning rate and optimizer. The context only provides information about the network architecture, including the number of layers, kernel sizes, strides, and padding. It also mentions the use of a rectified linear unit (ReLU) activation function to mitigate the vanishing/exploding gradient problem. However, it does not provide details about the hyperparameters used for training the model.