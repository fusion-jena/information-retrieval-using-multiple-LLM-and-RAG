Answer: The hyperparameters of the model are optimized using a combination of random search and grid search. For the random forest model, a random search is used to identify an optimal parameter set, where 100 sets are sampled and compared using three-fold cross validation. The search parameter ranges include the number of trees, minimum samples split, minimum samples per leaf, maximum depth, bootstrap, and maximum features for split. The results are then refined using a grid-search with the parameter ranges set to ±50 for the number of estimators and ±1 for the other parameters. 

For the CNN model, the hyperparameters are not explicitly stated to be optimized using a specific method such as grid search or random search. However, the use of an ensemble of three models with different pooling methods (max pooling and average pooling) and the selection of the best-performing model based on validation data across training epochs can be seen as a form of hyperparameter tuning.