Answer: 

The provided context does not specifically mention the evaluation metrics of a deep learning model. However, it does mention the evaluation metrics used for the machine learning models in the context of species distribution modeling. According to the text, the performance of the machine learning models is evaluated using the Area Under the Curve (AUC) values, which is a critical measure of model performance. Additionally, the text mentions the true positive rate (sensitivity) and the false positive rate (1-specificity) as metrics used to quantify the proportion of correctly and incorrectly classified samples, respectively.

It's worth noting that the context does not mention deep learning models specifically, but rather machine learning models in general. Therefore, we cannot assume that the same metrics are used to evaluate the performance of deep learning models. If you are looking for information on the evaluation metrics of deep learning models, you may need to refer to a different source.