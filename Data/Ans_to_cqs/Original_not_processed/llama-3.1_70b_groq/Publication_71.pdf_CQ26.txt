Answer:::

The provided context does not explicitly mention techniques such as Stratified splitting, oversampling, or undersampling to address data bias during preprocessing of the deep learning pipeline. However, it does mention that heavily imbalanced datasets can lead to biased loss functions, resulting in poor classification performance for underrepresented classes.

One potential strategy mentioned in the context to mitigate issues with imbalanced datasets is data augmentation. This involves augmenting the training dataset using different techniques such as:

* Adding different brightness levels
* Adding vertically and horizontally flipped versions of the training images
* Shifting or rotating the training images
* Adding noisy versions of the training images

These techniques can help increase the size and diversity of the training dataset, which may help reduce the impact of data bias. However, it is not explicitly stated that these techniques are used to address data bias specifically.

Additionally, the context mentions the importance of having a vast amount of training data with similar characteristics to the testing data. This suggests that collecting diverse data may be important for reducing data bias, but it is not explicitly stated as a technique for addressing data bias during preprocessing.