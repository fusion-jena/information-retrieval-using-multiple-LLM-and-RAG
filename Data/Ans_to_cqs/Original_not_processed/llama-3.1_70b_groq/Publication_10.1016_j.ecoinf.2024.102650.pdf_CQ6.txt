Answer:

According to the provided context, the preprocessing steps involved before training a deep learning model include:

1. **Text filtering**: This step involves filtering out unnecessary symbols and noise, such as notes, advertisements, useless numbers, punctuation marks, stop words, and repeated texts on websites.
2. **Text segmentation**: This step involves dividing the natural language composed of Chinese text into meaningful words. The context mentions using Python's Jieba Library for Chinese text segmentation.
3. **Stop word removal**: This step involves removing common words that do not add much value to the text, such as "the", "and", etc.
4. **Data cleaning**: This step involves removing user-generated text that deviates from the theme through manual review.

Additionally, the context mentions that the ERNIE model, which is a deep learning model, requires text preprocessing, such as word segmentation and stop word removal, followed by the selection of a text portion to manually annotate emotions for accuracy verification.

It is worth noting that the context does not mention normalization or scaling as preprocessing steps, which are common in deep learning. However, it does mention that the preprocessing steps are necessary to support subsequent analyses.