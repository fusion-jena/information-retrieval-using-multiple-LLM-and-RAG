Answer: The optimization technique applied in the deep learning pipeline is Adagrad. According to the provided context, "The EfficientNet was trained by the Adagrad in 100 epochs." This indicates that Adagrad is the optimization algorithm used to train the EfficientNet model. There is no mention of other optimization techniques such as SGD or Adam being used in the pipeline.