Answer: The data was randomly shuffled and then divided into training, validation, and test sets. The data partitioning ratio between the training, validation, and test sets was set as 8:1:1. This means that 80% of the data was used for training, 10% for validation, and 10% for testing. Additionally, the random partition was repeated ten times to reduce the influence of random splitting while ensuring converged performance.