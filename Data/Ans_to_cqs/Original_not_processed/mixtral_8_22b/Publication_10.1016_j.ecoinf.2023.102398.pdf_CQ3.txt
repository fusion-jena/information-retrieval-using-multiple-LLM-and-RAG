Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

In  order  to  determine  more  accurate  training  results  and  also  to 
explore the effect of epoch upon training result, apart from 150 epochs, 
the model with attention layer is trained with epoch values 100, 200, 
and  250  under  a  uniform  training  environment  and  with  the  same 
dataset.  The  training  summary  for  each  of  these  epochs  is  shown  in 
Tables 5, 6 and 7 for epochs 100, 200, and 250, respectively. The trends 
of mAP values with increasing epochs are shown in Figs. 14 and Fig. 15. 
The size of the dataset used for custom training is sufficiently large. 
Further, the DL model used in this work is tuned with optimized hyper 
parameters  for  which  overfitting  and  under  fitting  situations  are  pre-
vented from occurring. As mentioned above, the effort to over-train the 
model has been avoided and graded MSE convergence (Figs. 7 to 11) has 
been  adopted  to  fine-tune  the  model.  Results  obtained  for  different

The  global  average  pooling  is  used  in  the  squeeze  step  to  lower  the 
spatial  dimension  of  the  input  feature  maps,  which  results  in  a  com-
pressed  representation of those maps. Once again, during the  time of 
excitation, channel-wise dependencies are represented by modelling the 
interdependencies  among the  compressed feature maps  that were ob-
tained from the squeezing step. The term “excitation layer” refers to the 
two layers that are completely coupled to one another. The channel-wise 
attention  weights  are  produced  once  the  excitation  block  has  been 
processed. When everything is done, scaling and rescaling are accom-
plished by multiplying the attention weight by the initial feature maps. 
This reduces the weight of the channels that are not important while 
increasing the weight of the channels that are significant. As a result of 
this,  the  model’s  performance  can  be  improved  by  increasing  the

The confusion matrix (Fig. 6), F1 curve (Fig. 7), P curve (Fig. 8), PR 
curve (Fig. 9), R curve (Fig. 10) and final training plots (Fig. 11) are 
shown for the training of the model with attention layer with epoch-150. 
Some training batch outputs are shown in Fig. 12, and some validation 
outputs are shown in Fig. 13. 

EcologicalInformatics79(2024)10239812B. Bhagabati et al.                                                                                                                                                                                                                              

Fig. 12. Training Output (Batch-1) showing the labels of the detected object.  

Fig. 13. Validation Output (with images from the dataset). The bounding box and class name are generated and shown for the validated object by the model.

networks for visual recognition. IEEE Trans. Pattern Anal. Mach. Intell. 37, 
1904–1916. 

He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. In: 
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las 
Vegas, NV, USA, pp. 770–778. https://doi.org/10.1109/CVPR.2016.90. 

Hosang, J., Benenson, R., Schiele, B., 2017. Learning non-maximum suppression. arXiv. 
Hu, J., Shen, L., Albanie, S., et al., 2019. Squeeze-and-excitation networks, arXiv: 

1709.01507v4 [cs.CV] 16 May 2019. 

Khalajzadeh, H., Manthouri, M., Teshnehlab, M., 2014. Face recognition using 

convolutional neural network and simple logistics classifier. Adv. Intell. Syst. Comp. 
223, 197–207. 

K¨orschens, M., Denzler, J., 2019. ELPephants: A fine-grained Dataset for elephant re- 
identification. In: 2019 IEEE/CVF international conference on computer vision 
workshop (ICCVW), pp. 263–270.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the authors have utilized bounding box annotations for their deep learning pipeline. This is evident from Figure 13, where the output shows the bounding boxes around the objects along with their respective class names. However, there is no explicit mention or evidence of other data annotation techniques such as instance segmentation being employed in this study. Therefore, we can only confirm that bounding box annotation was used in this particular case.