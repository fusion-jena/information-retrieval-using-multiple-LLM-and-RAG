Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The last step in configuring the model involves feeding in predictors 
that  the  advanced  deep  learning  algorithm  feeds  by  the  decomposed 
components  resulting  from  the  previous  steps.  The  primary  model  is 
CNN-BiGRU  with  three  comparative  ML  methods  (KELM,  RVFL  and 
CNN-BiRNN),  which  provide  four  complementary  models  including 
MVMD-CNN-BiGRU,  MVMD-RVFL,  MVMD-KELM  and  MVMD-CNN- 
BiRNN.  These  models  are  used  to  create  the  multi-temporal  fore-
casting model of daily streamflow (Qflow). Setting hyperparameters and 
their structural architecture is the most important aspect of executing 
ML-based  predictive  models  (Jamei  et  al.,  2023b).  Based  on  recent 
research, the main approaches to tuning parameters are algorithms of 
metaheuristic optimization, schemes of cross-validation schemes (Nes-
ted/rolling  basis  cross-validation)  (Huyghues-Beaufond  et  al.,  2020),

The application of a pooling layer allows data compression and the 
removal of irrelevant data. In this particular case, the max-pooling layer 

EcologicalInformatics80(2024)10245511M. Jamei et al.                                                                                                                                                                                                                                  

Fig. 9. MVMD-based decomposed sub-components (IMFs and residuals) related to all the climate signals implemented in forecasting of streamflow the Bear River 
(Qflow  (t + 1) and Qflow  (t + 3)) using decomposition level (k = 10). (as a sample). 

has been chosen. The aggregation of feature information extracted from 
the convolutional layer occurs in the fully connected layer, creating the 
final prediction data.

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

Phase 

Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 

R 

0.985 
0.960 
0.960 
0.949 
0.972 
0.930 
0.999 
0.955 
0.921 
0.698 
0.865 
0.662 
0.843 
0.668 
0.873 
0.689 
0.998 
0.933 
0.952 
0.930 
0.964 
0.928 
0.997 
0.929 
0.792 
0.603 
0.826 
0.594 
0.783 
0.591 
0.801 
0.598 

RMSE 

0.072 
0.098 
0.117 
0.113 
0.100 
0.130 
0.024 
0.105 
0.164 
0.253 
0.210 
0.266 
0.225 
0.263 
0.205 
0.256 
0.010 
0.130 
0.128 
0.130 
0.112 
0.133 
0.024 
0.141 
0.256 
0.284 
0.236 
0.287 
0.261 
0.287 
0.251 
0.285 

MAPE

could  be  vital  in  the  local  flood  decision-making  process,  in  the  absence  of  streamflow  information  as  input 
modeling, during the flood seasons to reduce flood damage in residential areas.   

Nomenclature 

Artificial neural network 
Bidirectional Gated Recurrent Unit 
Bidirectional Recurrent Neural Network 

ANN 
BiGRU 
BiRNN 
Boruta-CART Boruta-Classification and Regression Trees 
CNN 
COV 
ELM 
IMFs 
KELM 
KGE 
LSTM 
MAPE  Mean Absolute Percentage Error 
ML 
MVMD  Multivariate Variational Mode Decomposition 

Convolutional Neural Network 
Coefficient of Variation 
Extreme Learning Machine 
Intrinsic Mode Functions 
Kernel Extreme Learning Machine 
Kling-Gupta efficiency 
Long Short-Term Memory 

Machine learning 

NIS 
NSE 
PEI 
PIS 
Qflow 
R 
RMSE 
RNN 
RVFL 
Std. D 
SquD 
TOPSIS  Technique for Order Preference by Similarity to Ideal

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't any specific mention or discussion about the methodologies employed for gathering raw data within the given context. Therefore, I cannot provide a definitive response based solely on the available information. However, it can generally involve various techniques such as utilizing sensor networks, conducting surveys, accessing publicly accessible databases, or even employing web scraping tools depending upon the nature of the problem being addressed.

Based on the context provided, we understand that the study focuses on developing a multi-temporal forecasting model of daily streamflow (Qflow) using machine learning methods. However, no explicit details were mentioned regarding how the raw data was collected. Typically, in similar studies involving hydrological modeling, researchers might use data obtained from meteorological stations, satellite imagery, or other relevant sources like water resource management agencies. Nonetheless, without further clarification, one cannot pinpoint the exact methods used for data collection in this specific scenario.