Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1. Training parameters used in DeepLabV3+.

Training Parameter

Value

Learning policy
Base learning rate
Learning rate decay factor
Learning rate decay step
Learning power
Training number of steps
Momentum
Train batch size
Weight decay
Train crop size
Last layer gradient multiplier
Upsample logits
Drop path keep prob
tf_initial_checkpoint
initialize_last_layer
last_layers_contain_logits_only
slow_start_step
slow_start_learning_rate
ﬁne_tune_batch_norm
min_scale_factor
max_scale_factor
scale_factor_step_size
atrous_rates
output_stride

Poly
0.0001
0.1
2000
0.9
≥100,000
0.9
2
0.00004
‘513,513’
1
True
1
deeplabv3_pascal_train_aug
False
True
0
1 × 10
False
0.5
2
0.25
[6,12,18]
16

−4

work can be seen in Table 1. Table 1. Training parameters used in DeepLabV3+. Training Parameter Value Learning policy Poly Base learning rate 0.0001 Learning rate decay factor 0.1 Learning rate decay step 2000 Learning power 0.9 Training number of steps ≥100,000 Momentum 0.9 Train batch size 2 Weight decay 0.00004 Train crop size ‘513,513′ Last layer gradient multiplier 1 Upsample logits True Drop path keep prob 1 tf_initial_checkpoint deeplabv3_pascal_train_aug initialize_last_layer False last_layers_contain_logits_only True slow_start_step 0 slow_start_learning_rate 1e-4 fine_tune_batch_norm False min_scale_factor 0.5 max_scale_factor 2 scale_factor_step_size 0.25 atrous_rates [6,12,18] output_stride 16   Remote Sens. 2020, 12, 2502

7 of 23

Figure 4. Block diagram of DeepLabV3+ [42].

A PC with Windows 10 operating system, a GPU card (RTX2070), and 16GB memory is
used for DeepLabv3+ model training and testing which uses the TensorFlow framework to run.
For training a land cover model using the training datasets, the weights of a pre-trained model
with the exception of the logits are used as the starting point and these weights are ﬁne-tuned with
further training. These initial weights belong to a pre-trained model for the PASCAL VOC 2012
dataset (“deeplabv3_pascal_train_aug_2018_01_04.tar.gz”). This model was based on the Xception-65
backbone [42]. Because the number of land covers in the Vasiliko and Kimisala dataset is diﬀerent from
the number of classes in the PASCAL VOC-2012 dataset, the logit weights in the pre-trained model are
excluded. The training parameters used for training a model with DeepLabv3+ in this work can be
seen in Table 1.

Table 1. Training parameters used in DeepLabV3+.

Remote Sens. 2020, 12, x FOR PEER REVIEW 7 of 23  Figure 4. Block diagram of DeepLabV3+ [42]. A PC with Windows 10 operating system, a GPU card (RTX2070), and 16GB memory is used for DeepLabv3+ model training and testing which uses the TensorFlow framework to run. For training a land cover model using the training datasets, the weights of a pre-trained model with the exception of the logits are used as the starting point and these weights are fine-tuned with further training. These initial weights belong to a pre-trained model for the PASCAL VOC 2012 dataset (“deeplabv3_pascal_train_aug_2018_01_04.tar.gz”). This model was based on the Xception-65 backbone [42]. Because the number of land covers in the Vasiliko and Kimisala dataset is different from the number of classes in the PASCAL VOC-2012 dataset, the logit weights in the pre-trained model are excluded. The training parameters used for training a model with DeepLabv3+ in this work can be seen in Table 1. Table 1. Training

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the specific platform used to deploy the deep learning model. It only mentions that a PC with Windows 10 operating system, a GPU card (RTX2070), and 16GB memory was used for training and testing the DeepLabv3+ model, which runs on the TensorFlow framework. However, it does not specify whether the trained model was deployed on any cloud platforms such as AWS, Azure, or Google Cloud Platform. Therefore, I cannot determine which platform was used to deploy the deep learning model based on the provided context.