Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

stratification improved the identification of less frequent topics by some 
classification  tasks  emphasises  the  need  for  researchers  to  manually 
inspect  their  datasets,  especially  when  collected  from  online  sources, 
and  consider  the  use  of  data  augmentation.  The  need  for  manually 
labelled training data is a factor often cited as a barrier to using machine 
classification.  Whilst  our  experiments  did  not  identify  performance 
gains from using data selected by active learning algorithms, for some 
BERT classifiers, accuracy of >90% was achieved with as little as 400 
training examples. Consequently, it is possible to train high performing 
custom  classifiers  with  minimal  labelling  effort.  Overall,  this  study 
highlights that, whilst the use of automated text classification provides 
an  opportunity  to  leverage  increasingly  large  online  datasets  for 
ecological  analyses,  application  of  these  tools  should  be  done  with

As well as the comparator models, we also tested the classification 
performance of a fine-tuned transformer model. Transformer models are 
a  class  of  large  language  model,  characterised  by  a  self-attention 
mechanism, which can weight the influence of different parts of a text 
sequence, to capture dependencies between words in the text (Vaswani 
et al., 2017). We chose to use BERT (Bidirectional Encoder Represen-
tations  from  Transformers),  as  it  is  one  of  the  most  well-known  and 
widely-used  transformer  models.  BERT  uses  the  transformer  self- 
attention  mechanism  to  generate  representations  of  words  in  a  text 
sequence that consider both the right and left contexts around words. It 
is trained using a large Wikipedia text corpus, via both masked-language 
modelling, whereby model must predict missing tokens (words or parts 
of  text,  such  as  punctuation)  in  text,  and  next-sentence  prediction,

sifiers, that can be tailored for specific research questions. In addition, 
training data in which the target class makes up a small proportion of 
text generally leads to poor classification performance, as demonstrated 
with web articles for classification task 2 in this study (Fig. 3). Never-
theless, although not applied in our pipeline, augmenting training data 
by  oversampling  of  the  minority  class  can  help  to  alleviate  this  issue 
(Padurariu and Breaban, 2019).

fields, such as biomedical sciences. Therefore, these demonstrations of 
high  performance  by  transformer-based  classifiers  could  encourage 
wider adoption of automated classification tools in this field, particu-
larly in more complex or specific data collection scenarios.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information on the specific data augmentation techniques used in the deep learning pipeline. However, it mentions that data augmentation can improve the identification of less frequent topics and alleviate issues related to imbalanced classes in the dataset. One technique mentioned indirectly is oversampling of the minority class, which involves creating additional instances of the underrepresented class to balance the dataset. Other common data augmentation techniques include flipping, rotating, scaling, cropping, and adding noise to images, but these are not explicitly discussed in the provided context.