Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

1728 
12,146 
17,616 
7891 
14,993 
11,202 
10,601 
904 
1117 
1078 
1061 
19,549 
17,411 
1000 
8515 
1003 
9540 
1168 
138,523 
7696  

EcologicalInformatics72(2022)1019095G. Morales et al.

The  implemented  CNN  corresponded  to  a  modified  version  of 
ResNet50, one of the dominant architectures in bioacoustic tasks, and, 
although other authors have applied previous ImageNet training to the 
bioacoustic  domain  (LeBien  et  al.,  2020;  Zhong  et  al.,  2021),  other 
datasets such as Audio Set (Gemmeke et al., 2017) or VGG-Sound (Chen 
et al., 2020) can be just as good as ImageNet for pre-training, either on 
ResNet or on other architectures, such as VGGish, Inception or Mobile-
Net. Another viable option is to pretrain with synthetic clicks or chirps 
(Glotin  et  al.,  2017;  Yang  et  al.,  2021).  Models  already  available  in 
mobile  apps  that  perform  this  same  spectrogram-based  identification 
task are advancing rapidly. To date (October 2022), the BirdNet appli-
cation (Kahl et al., 2021) allows for the identification of more than 3000 
bird species (Wood et al., 2022). In the short term, this particular model

2021. Deep learning as a tool for ecology and evolution. Methods Ecol. Evol. https:// 
doi.org/10.1111/2041-210X.13901. 

EcologicalInformatics72(2022)10190910G. Morales et al.                                                                                                                                                                                                                                

Bravo, S.P., Cueto, V.R., Gorosito, C.A., 2017. Migratory timing, rate, routes and 

wintering areas of White-crested Elaenia (Elaenia albiceps chilensis), a key seed 
disperser for Patagonian forest regeneration. PLoS One 12, e0170188. https://doi. 
org/10.1371/journal.pone.0170188. 

Butt, N., Chauvenet, A.L., Adams, V.M., Beger, M., Gallagher, R.V., Shanahan, D.F., 

Navarino, comuna Cabo de Hornos, Chile., in: Anales del Instituto de la Patagonia, 
pp. 25–33.

We applied the transfer learning and fine-tuning technique with the 
deep learning model ResNet50 (He et al., 2016; Tan et al., 2018), which 
was already pre-trained on ImageNet data (Deng et al., 2009). Transfer 
learning is a technique that enabled us to overcome the issue of shortage 
of  training  data  and  construct  a  model  efficiently  by  transferring 
knowledge  from  a  similar  task  to,  in  this  case,  our  target  task.  The 
implemented  architecture  received  RGB  images  of  224×224×3  as 
inputs—in this case, color spectrograms of two-second durations—and 
included  only  the  feature  extraction  layers  from  the  ResNet50,  dis-
carding the superior classification layers (known as the top network). 
The newly created model reconfigured the top network with two fully 
connected  layers  (FC)  that  could  learn  new  features.  To  reduce  over-
fitting and imitate the training of a set of different models, a dropout

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention of any specific code repository links related to the deep learning pipeline used in the research. Therefore, I cannot provide the requested information.