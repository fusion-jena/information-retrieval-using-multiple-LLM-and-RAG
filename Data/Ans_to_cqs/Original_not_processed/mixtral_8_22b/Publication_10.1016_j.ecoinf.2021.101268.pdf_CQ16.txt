Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

Accuracy 

Raw 

Train 

98.75% 
96.77% 
82.25% 
93.71% 

Validation 

97.16% 
98.30% 
89.04% 
91.30% 

Test 

96.16% 
95.15% 
83.30% 
86.48% 

Pre-processed  

Train 

98.21% 
96.94% 
77.25% 
91.61% 

Validation 

97.92% 
97.92% 
79.02% 
87.33% 

Test 

95.98% 
96.52% 
75.44% 
86.29%  

Table 5 
Accuracy of the models swapping the testing sets (source → target).  

Model 

Accuracy 

Raw → Pre-processed 

Pre-processed → Raw 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

82.35% 
82.70% 
69.22% 
65.26% 

54.76% 
78.87% 
29.56% 
33.97%  

Fig. 5. Confusion matrices for the VGG-19 architecture.  

et al., 2017) and SmoothGrad (Smilkov et al., 2017) methods over each 
model. These methods plot a point cloud, where the density denotes the 
input space relevance. Thus, a higher density in a region suggests that 
the network ponderates it the most when classifying.

2. Peruvian Amazon forestry dataset

H . 
. (4c) Adaptive equalization of the Lightness - IRGB
ICanny. (4f) Final. (For interpretation of the references to color in this figure legend, the 

S

Table 3 
Architectures comparison: AlexNet, VGG-19, ResNet-101, and DenseNet-201.  

Network 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

Year 

2012 
2014 
2016 
2017 

Depth 

#parameters 

8 
19 
101 
201 

60 M 
144 M 
44.8 M 
20 M  

validation samples are selected randomly from the first group. The data 
distribution is 70.12% for training, 1.69% validation, and 28.19% for 
testing. The model feeds off with 16 elements per mini-batches using the 
ADAM optimizer (Kingma and Ba, 2014) with a learning rate of 1e-3. To 
run our experiments, we use Pytorch 1.3 framework in a PC with the 
following specifications: 4.0 GHz Intel Core i9 processor, 32 GB 3000 
MHz DDR4 memory, and NVIDIA Titan RTX. 

5. Results

X[i, j] (cid:0) 1.5371⋅Ih
X[i, j] + 1.8760⋅Ih
X[i, j] (cid:0) 0.2040⋅Ih

Y [i, j] (cid:0) 0.4985⋅Is
Y [i, j] + 0.0416⋅Is
Y [i, j] + 1.0572⋅Is

Z[i, j]

Z[i, j]

Z[i, j]

(7) 

4.3. Training details 

Henceforth, a mask performs a partial background removal following 

We split the dataset by the camera model: DC, CP1, and CP2 models 
are  for  training/validation,  and  CP3,  CP4,  and  CP5  for  testing.  The 

EcologicalInformatics62(2021)1012685G. Vizcarra et al.                                                                                                                                                                                                                               

Fig. 4. Intermediate results of the background removal algorithm: (4a) Input image - IRGB (4b) Sharpen Image IRGB
(4d) Masked green channel - IG
reader is referred to the web version of this article.) 
segmentation mask - MaskF. 

b  (cid:0)
H. (4e) Canny edge detection applied on IG

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the criteria used to determine when training is complete. However, based on common practices in machine learning, some possible criteria include reaching a predefined number of epochs or iterations, achieving a desired level of performance on the validation set (such as a minimum accuracy or maximum validation loss), or observing no significant improvement in validation metrics after several consecutive epochs (also known as early stopping). In this case, since the authors mention using ADAM optimizer with a learning rate of 1e-3 and feeding the model with 16 elements per mini-batch, they might have chosen one of these criteria to decide when to stop training their models.