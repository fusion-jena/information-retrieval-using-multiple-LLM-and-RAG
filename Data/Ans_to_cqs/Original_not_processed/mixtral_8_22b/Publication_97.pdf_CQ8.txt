Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

58. Yu, L.C.; Sung, W.K. Understanding geometry of encoder-decoder CNNs. arXiv 2019, arXiv:1901.07647v2.
Ioﬀe, S.; Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate
59.
shift. arXiv 2015, arXiv:1502.03167v3.
Srivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; Salakhutdinov, R. Dropout: A simple way to prevent
neural networks from overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958.

60.

61. Evaluation of the CNN Design Choices Performance on ImageNet-2012. Available online: https://github.

com/ducha-aiki/caﬀenet-benchmark (accessed on 24 March 2020).

62. Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G.S.; Davis, A.; Dean, J.;
Devin, M.; et al. TensorFlow: Large-scale machine learning on heterogeneous systems. arXiv 2016,
arXiv:1603.04467v2.

Remote Sens. 2020, 12, 1145

6 of 17

Training data were generated as batches of size (m, 256, 256, 3), where m is the batch size (m =
20 in our experiments). The batches consisted of sub-images of size 256 × 256 that were randomly
cropped out from the original satellite images presented in Table 1. We had a stream (internally, a
Python generator) of almost never repeated sub-images; these sub-images were combined into batches
and used for the neural network training. Satellite images for sites #1, #3, #5, #7–10 were used for
training and #2, #4, #6 for validation. Corresponding batches of mask data had shape (20, 256, 256, 1).
The network training assessment was performed on sub-images generated from image #2 (Table 1).
Images #4 and #6 were used for visualization and demonstration of the algorithm eﬃcacy.

case for further investigations for the appliance of deep learning approaches in vegetation science.

To tune the architecture of the neural network, we tested the following combinations of parameters
(Algorithm A1, line #24), which correspond to diﬀerent U-Net architectures: num_layers = {64, 32, 16},
depth = {2, 3, 4}, layer_rate = {2, 1.5, 1.2}, batch_norm = {True, False}, residual = {True, False}, dropout
= {0, 0.5}. Thus, we performed a grid search over 216 diﬀerent U-Net-like architectures and found
several of the best ones which are suitable for forest damage segmentation.

All of the best results corresponded to the conﬁguration when the number of layers was equal to
64, and dropout was applied. The best one, whereby an additional batch normalization is applied,
corresponds to the following parameters: num_layers = 64, depth = 4, layer_rate = 2, batch_norm =
True, residual = False, dropout = 0.5.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there is no explicit information about the location or availability of the code repository for the deep learning pipeline. It does not mention any specific links to platforms such as GitHub, GitLab, or BitBucket. Therefore, it is not possible to provide accurate information regarding the code repository's location.