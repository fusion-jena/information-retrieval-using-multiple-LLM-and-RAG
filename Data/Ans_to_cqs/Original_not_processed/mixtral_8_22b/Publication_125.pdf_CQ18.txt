Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Training Run-Time

Prediction Run-Time

VGG16
Xception
ResNet50
DenseNet121
The proposed model

22 min 27 s
21 min 26 s
30 min 8 s
18 min 34 s
16 min 43 s

0.803 s
0.827 s
1.835 s
4.134 s
0.976 s

5.5. Discussion

Recent years have seen increasing concerns about protecting the privacy of conﬁdential
information when processing data using models. This leads to the need for cryptographic
techniques to solve privacy concerns in data-driven models. Several PPDL techniques have
been proposed in the literature to solve these concerns. This research is, to the best of our
knowledge, the ﬁrst work that investigates PPDL for satellite image classiﬁcation.

Execution Time

All runtimes reported in this section were measured on the Google Colab repository
with a CPU running at 2.30GHz. Table 10 presents a detail of the runtime for each CNN
model. The training runtime for VGG16, Xception, and ResNet50 is 22.27, 21.26, and
30.8 min, respectively. Additionally, the prediction runtime for these models is 0.803,
0.827, and 1.835 s, respectively. The training runtime for DenceNet121 and the proposed
model is 18.34 and 16.43 min, and the prediction runtime is 4.134 and 0.976 s, respectively.
Accordingly, the computation overhead varies from one model to another. However,
PHE data are signiﬁcantly fast during both training and prediction and therefore the
computation overhead of the proposed encryption schema is low.

Remote Sens. 2021, 13, 2221

21 of 26

Figure 9. Training accuracy of different CNN models.

Table 10. CNN models’ run-time.

CNN Models

Training Run-Time

Prediction Run-Time

Remote Sens. 2021, 13, 2221

18 of 26

Figure 6. Sample image data augmentation. (a) Rotation results; (b) Zoom results; (c) Shearing results; (d) Horizontal shift
results; (e) Vertical shift results; (f) brightness results; (g) Horizontal ﬂip results; (h) Vertical ﬂip results.

Remote Sens. 2021, 13, 2221

19 of 26

Figure 7. Model accuracy over plain data. (a) Training accuracy; (b) Validation accuracy.

Figure 8. Model accuracy over encrypted data. (a) Training accuracy; (b) Validation accuracy.

9730
8440
9124
10,480

The considered dataset is further divided into three datasets, resulting in 22,666 images
for training the model (training set), 7554 images for validating the trained model (valida-
tion set), and 7554 images for assessing the model performance (testing set).

To obtain this dataset, a semantic segmentation is conducted using our previous
works [51–53]. The four classes—namely, urban, bare soil, vegetation and road—are
extracted from the satellite images, meaning that the resulting images each contain both
the real value of pixels of the extracted class and zero for the values of the other classes.
Then, each image containing a given class is divided into non-overlapping blocks of
256 × 256 pixels and saved into folders, each with the name of the corresponding class. A
sample of this dataset is depicted in Figure 4, wherein the white represents a given land
cover class and the black represents the values of other classes.

5.2. Experimental Set-Up

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

From the provided information, it appears that the strategy implemented to monitor the model performance during training involves dividing the dataset into three subsets: a training set, a validation set, and a testing set. The training set consists of 22,666 images used to train the model. The validation set contains 7554 images utilized to validate the trained model, which likely means evaluating its performance after each epoch or iteration during training. Lastly, the testing set also includes 7554 images employed to assess the final performance of the model once the training process has been completed. By employing separate sets for training, validation, and testing, the researchers can effectively track the progress of their model throughout the training phase while minimizing the risk of overfitting.