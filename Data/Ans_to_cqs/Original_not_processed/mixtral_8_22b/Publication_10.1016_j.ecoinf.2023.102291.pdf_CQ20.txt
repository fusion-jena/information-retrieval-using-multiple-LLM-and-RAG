Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

for the customised architecture (see Convolutional neural networks sec-
tion),  and  the  smallest  one  comprised  3900  images  combining  two 
seconds  window  size  and  90  dpi  for  the  transfer  learning  approach 
(Table 1).

d
e
s
i

m
o
t
s
u
C

g
n
i
n
r
a
e
L

r
e
f
s
n
a
r
T

1
≥
R
N
S

y
r
a
r
b
i
L

i
p
d

e
z
i
s
w
o
d
n
i
W

size of 32. The most suitable architecture was chosen based on the best 
validation accuracy (proportion of all correct predictions) and precision 
(number of true positives divided by true positives and false positives) 
obtained during training. The model training and prediction procedures 
were  executed  on  Microsoft  Azure  using  instance  NV12s  v3  with  12 
vCPUs and 112 GB RAM. The CNNs were implemented using Tensor-
Flow (Abadi et al., 2016) and Python 3. The Ubuntu 20.04 operating 
system was used and obtained via the Ubuntu 20.04 Data Science Virtual 
Machine  on  Microsoft  Azure.  The  algorithm  scripts  are  available  in 
Supporting Information B. 

2.5. Inference and post-processing

Appendix A. Supplementary data 

Supplementary data to this article can be found online at https://doi. 

org/10.1016/j.ecoinf.2023.102291. 

References 

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., 

Davis, A., Dean, J., Devin, M., 2016. Tensorflow: large-scale machine learning on 
heterogeneous distributed systems arXiv preprint arXiv:160304467.  

Allen, A.N., Harvey, M., Harrell, L., Jansen, A., Merkens, K.P., Wall, C.C., Cattiau, J., 

Oleson, E.M., 2021. A convolutional neural network for automated detection of 
humpback whale Song in a diverse, long-term passive acoustic dataset. Front. Mar. 
Sci. 8 https://doi.org/10.3389/fmars.2021.607321. 

Au, W.L., 2000. Hearing in whales and dolphins: An overview. In: Au, W.L., Richard, R.F. 
(Eds.), Hearing by Whales and Dolphins. Springer, New York, pp. 1–42. https://doi. 
org/10.1007/978-1-4612-1150-1_1.

training library sizes (8 k and 12 k) demonstrated higher accuracy for 
the one built using a smaller training dataset. Inference using transfer 
learning  was  nearly  twice  as  long  as  the  custom  CNN  architectures 
(Table 1).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The model training and prediction procedures were executed on Microsoft Azure using instance NV12s v3 with 12 vCPUs and 112 GB RAM. This suggests that the hardware resources used for training the deep learning model include CPUs and RAM, but it does not explicitly mention the use of GPUs or TPUs. However, considering that the task involves training a Convolutional Neural Network (CNN) and the fact that GPU acceleration is commonly used for such tasks due to their computational requirements, it is reasonable to infer that GPUs might have been utilized. Nonetheless, without explicit information about the use of GPUs or TPUs, we cannot definitively state which specific hardware resources were employed for training the deep learning model.