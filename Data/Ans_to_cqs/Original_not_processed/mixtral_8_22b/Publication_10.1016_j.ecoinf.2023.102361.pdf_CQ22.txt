Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Performance metrics 

The  performance  of  image  classification  models  can  be  evaluated 
using several metrics which can provide valuable insights about their 
effectiveness.  The  choice  of  metrics  depends  on  the  specific  re-
quirements and characteristics of the task. In our study, we have chosen 
the  following  commonly  used  metrics  to  evaluate  the  efficacy  of  the 
deep learning models: 

• Accuracy: Accuracy measures the proportion of correctly classi-
fied images out of the total number of images. The metric provides a 
general overview of model performance. 

Accuracy=

TruePositives+TrueNegatives
TruePositives+True Negatives+FalsePositives+FalseNegatives

.

In these metrics, true positives are correct positive predictions, true 
negatives  are  correct  negative  predictions,  false  positives  are  incorrect 
positive  predictions,  and  false  negatives  are 
incorrect  negative 
predictions.

2.2. Split the datasets 

In this research, the datasets were randomly divided into three parts 
for training, validation and testing. Here, 60% of the data was used to 
train the deep learning models, and 20% of them was kept to validate the 
models. The remaining 20% data was used to evaluate the performance 
of the models. Table 1 show the number of data in the dataset and how 
they are separated for training, testing and validation. 

2.3. Deep learning models

Precision × Recall
.
Precision + Recall

• Confusion Matrix: A confusion matrix tabulates the true positive, 
true  negative,  false  positive,  and  false  negative  counts.  It  provides  a 
detailed breakdown of model performance. It is helpful to visualise how 
well the deep learning model is performing and what prediction errors it 
is making. 

2.5. Traditional approach 

In this approach, the images were resized to 256 × 256 and used to 
train  the  models.  For  this  study,  we  have  selected  ten  deep  learning 
models as discussed in Section 2.3. The performance of the models was 
evaluated using several well-known metrics (see Section 2.6.5) such as 
accuracy, precision, recall and F1 score. We also used a confusion matrix 
to show how accurate the models were in classifying different classes of 
images  in  the  datasets  (Hasan  et  al.,  2021;  Kamilaris  and  Prenafeta- 
Boldú, 2018).

Resize 

GAN 

Change 

Resize 

GAN 

Change 

MobileNetV2 

VGG16 

VGG19 

ResNet-50 

Inception-V3 

Inception-ResNetV2 

Xception 

DenseNet121 

DenseNet169 

DenseNet201 

Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 
Precision 
Recall 
F1 Score 

93.84 
93.84 
93.76 
89.23 
88.97 
88.72 
87.88 
87.92 
87.61 
91.71 
91.65 
91.47 
93.37 
93.39 
93.32 
92.51 
92.53 
92.38 
93.91 
93.90 
93.85 
94.63 
94.61 
94.58 
94.36 
94.39 
94.35 
96.38 
96.38 
96.37 

95.29 
95.30 
95.26 
93.70 
93.70 
93.63 
93.02 
92.96 
92.83 
95.71 
95.73 
95.70 
93.09 
93.07 
93.01 
96.24 
96.21 
96.19 
96.18 
96.15 
96.14 
96.69 
96.69 
96.68 
97.11 
97.12 
97.11 
98.49 
98.49 
98.49

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: Several metrics are used to evaluate the performance of the deep learning models in this study. These include accuracy, precision, recall, and F1 score. Additionally, a confusion matrix is utilized to provide detailed information about the model's performance and prediction errors.

Accuracy measures the proportion of correctly classified images out of the total number of images, providing a general overview of the model's performance. Precision represents the ratio of correctly predicted positive observations to the total predicted positive observations. Recall, or sensitivity, indicates the ratio of correctly predicted positive observations to all actual positive observations. The F1 score combines both precision and recall by taking their harmonic mean, offering a more balanced evaluation of the model's performance. Lastly, the confusion matrix presents a table with true positive, true negative, false positive, and false negative counts, allowing for a comprehensive understanding of the model's strengths and weaknesses.