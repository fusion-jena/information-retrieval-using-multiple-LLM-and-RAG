Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Other  ML  algorithms,  in  general,  and  deep  learning  algorithms,in 
particular,  can  be  applied  to  hyperspectral  data  to  predict  the  water 
quality parameters with better accuracy and performance using orbital 
hyperspectral data. The number and spatial distribution of the samples, 
and influence of different atmospheric correction algorithms (Vanhel-
lemont and Ruddick, 2021) are among essential parameters that should 
be noticed in  all future studies  to create  a representative dataset and 
make  a  ML-based  model  with  acceptable  generalisation  (Menezes  de 

EcologicalInformatics75(2023)1020589M. Saberioon et al.

Maier, P.M., Keller, S., Hinz, S., 2021. Deep learning with wasi simulation data for 

estimating chlorophyll a concentration of inland water bodies. Remote Sens. 13, 718. 
https://doi.org/10.3390/rs13040718. 

Novo, E.M.L.M., Steffen, C.A., Braga, C.Z.F., 1991. Results of a laboratory experiment 
relating spectral reflectance to total suspended solids. Remote Sens. Environ. 36, 
67–72. https://doi.org/10.1016/0034-4257(91)90031-Z. 

Olmanson, L.G., Brezonik, P.L., Bauer, M.E., 2013. Airborne hyperspectral remote 

sensing to assess spatial distribution of water quality characteristics in large rivers: 
The mississippi river and its tributaries in minnesota. Remote Sens. Environ. 130, 
254–265. https://doi.org/10.1016/j.rse.2012.11.023.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Biophysical properties 
Hyperspectral imagery 
Machine learning 
Remote sensing 
Satellite imagery 
Water quality

artificial neural networks (ANN) (Silveira Kupssinskü et al., 2020; Maier 
and Keller, 2019), and extreme machine learning (Peterson et al., 2018) 
became  popular  for  developing  semi-empirical  models.  They  provide 
intelligent  ways  of  eliminating  irrelevant  spectral  wavelengths  while 
unraveling  the  complex  relationship  between  response  and  predictor 
variables  with  limited  assumption  and  prior  knowledge  (Saberioon 
et al., 2020; Chen et al., 2022).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting is a method where the training set is divided into subsets or strata based on specific criteria such as class labels. This ensures that each subset has roughly the same proportion of examples from each target class as the complete set. It helps maintain the overall balance of classes when creating training and validation sets.

Oversampling involves increasing the frequency of minority class instances by duplicating them or generating synthetic examples. This technique aims to balance the class distribution and reduce the impact of imbalanced datasets on the learning algorithm. Synthetic Minority Over-sampling Technique (SMOTE) is one commonly used oversampling approach.

Undersampling is another strategy to handle class imbalance by reducing the majority class size. Random undersampling removes random instances from the majority class until it reaches the desired ratio with the minority class. However, this may lead to loss of valuable information. More sophisticated methods like NearMiss and Condensed Nearest Neighbor (CNN) rule focus on removing only those majority class instances that do not contribute much to the classification task.

Diverse data collection refers to gathering a wide range of data samples representing various scenarios, conditions, and environments. This practice promotes fairness and reduces biases in the trained models by exposing them to more comprehensive and realistic situations.

These techniques help mitigate data bias during preprocessing of the deep learning pipeline, ensuring improved model performance and generalization capabilities.