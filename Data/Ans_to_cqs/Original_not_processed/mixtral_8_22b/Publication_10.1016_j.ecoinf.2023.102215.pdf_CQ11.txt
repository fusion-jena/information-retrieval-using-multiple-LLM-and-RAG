Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

72 
72 
128 
64 

DN-3 
72 
72 
256 
64 

36 
36 
256 
128 

DN-4 
36 
36 
512 
128 

18 
18 
512 
256 

DN-5  
18  
18  
1024  
256   

9 
9 
512 
256         

networks often fail in extracting global information from shallow layers 
because of the small receptive fields (Liu et al., 2019b; Liu et al., 2021). 
For  creating  feature  maps  with  much  global  information,  multiple 
dilated convolutions are used for shallow layers (Zhao et al., 2020)— 
which, however, entail more computation resources. U2-Net defines a 
two-level  nested  model  (i.e.,  a  stack  of  nested  encoder-decoder)  to 
capture the contextual information in different scales at a moderate level 
of computation cost.

of dilated convolution with various dilated rates to enlarge the receptive 
field, which not only extracts richer global information but also saves 
significant time and memory resources.

2.2.1. Overall architecture 

As indicated in Fig. 4, the presented TrunkNet model can be divided 
into two parts (or stages): the feature extraction and aggregation. The 
two parts are armed with novel designs: the Multiscale Information Fusion 
(MIF) block and the Texture Attention (TA) module. 

In the feature extraction part, we employ U2-Net (Qin et al., 2020) as 
our  base  network.  For  SOD  applications,  conventional  CNN-based 

EcologicalInformatics77(2023)1022155R. Li et al.                                                                                                                                                                                                                                        

Table 2 
Configurations of MIF block’s local-feature extractor.   

EN-1 

EN-2 

EN-3 

EN-4 

EN-5 

EN-6 

H 
W 
C 
′ 
C

H 
W 
C 
′ 
C

288 
288 
3 
32 

DN-1 
288 
288 
64 
32 

144 
144 
64 
32 

DN-2 
144 
144 
128 
32 

72 
72 
128 
64 

DN-3 
72 
72 
256 
64

and reconstruction mechanism for harvesting robot via convolutional neural 
network and image segmentation. Comput. Electron. Agricult. 192, 106609. 

Liu, G., Fan, D., 2013. A model of visual attention for natural image retrieval. In: 2013 
International Conference on Information Science and Cloud Computing Companion. 
IEEE, pp. 728–733. 

Wan, H., Zeng, X., Fan, Z., Zhang, S., Kang, M., 2023. U2espnet—a lightweight and high- 
accuracy convolutional neural network for real-time semantic segmentation of 
visible branches. Comput. Electron. Agricult. 204, 107542. 

Liu, J., Wang, X., Wang, T., 2019a. Classification of tree species and stock volume 

Wang, T., Chen, B., Zhang, Z., Li, H., Zhang, M., 2022. Applications of machine vision in 

estimation in ground forest images using deep learning. Comput. Electron. Agricult. 
166, 105012.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide any information about the data repository link of the deep learning pipeline. Therefore, I cannot provide an accurate response to this query based on the available context.