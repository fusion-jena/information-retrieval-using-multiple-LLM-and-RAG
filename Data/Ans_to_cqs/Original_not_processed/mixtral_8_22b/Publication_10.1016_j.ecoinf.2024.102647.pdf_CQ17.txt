Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Feature selection

automated deep learning convolutional neural network algorithm applied for soil 
salinity distribution mapping in Lake Urmia, Iran. Sci. Total Environ. 778, 146253. 
Geng, X., Boufadel, M.C., 2017. The influence of evaporation and rainfall on supratidal 
groundwater dynamics and salinity structure in a sandy beach. Water Resour. Res. 
53 (7), 6218–6238. 

Ghazali, M.F., Wikantika, K., Harto, A.B., Kondoh, A., 2020. Generating soil salinity, soil 
moisture, soil pH from satellite imagery and its analysis. Inform. Process. Agric. 7 
(2), 294–306. 

Ghiglieri, G., Oggiano, G., Fidelibus, M.D., Alemayehu, T., Barbieri, G., Vernier, A., 2009.

Table 5 
Model  performance statistics  in  predicting groundwater  (GW)  salinity  hazard 
maps for the training and testing datasets by statistical (frequency ratio (FR) and 
statistical index (SI)) and machine learning (Random Forest (RF) and Classifi-
cation and Regression Trees (CART)) models.  

Model 

Statistical models 

Machine learning 

models 

Performance 
statistics 

NSE 
Accuracy 
Sensitivity 
Kappa 
AUC 

NSE 
COR 
KGE 
R2 

Training 

Testing 

FR 

SI 

FR 

SI 

0.85 
0.897 
0.794 
0.794 
0.923 
RF 
0.88 
0.95 
0.79 
0.96 

0.77 
0.867 
0.735 
0.735 
0.905 
CART 
0.69 
0.83 
0.70 
0.89 

0.73 
0.897 
0.794 
0.794 
0.920 
RF 
0.70 
0.85 
0.75 
0.91 

0.68 
0.882 
0.764 
0.764 
0.920   
CART 
0.63 
0.82 
0.75 
0.89  

necessary  to  make  a  fair  judgment  about  how  models  perform  under 
similar conditions. 

3.4. GW salinity vulnerability maps 

3.4.1. Development of standard maps

The selection of appropriate features in the current work was critical 
as the selections are used to assess over-fitting (or under-fitting) and thus 
improve  classification  performance.  On  this  basis,  variables  were 
selected  in  the  current  work  to  develop  GW  salinity  hazard  maps  by 
applying the recursive feature elimination (RFE) method (Guyon et al., 
2002). RFE uses the generalization ability of supportive vector machines 
and, thus, is suitable for small(er) sample sizes (Chen and Jeong, 2007). 
The RFE approach is a machine learning method that develops a model 
based  on  predictive  subsets,  estimating  each  data  subset  individually 
and ultimately obtaining their values by selecting their characteristics. 
The model only examines the most significant predictors and attempts to 
eliminate all dependencies, collinearities, and less significant predictors. 
The number and size of subsets can be adjusted to optimize the perfor-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, there isn't any explicit mention of specific regularization methods such as dropout or L2 regularization being used to prevent overfitting in the deep learning pipeline. However, it does discuss the use of Recursive Feature Elimination (RFE) as a method for feature selection. While not directly mentioned as a regularization technique, RFE can help reduce overfitting by removing irrelevant features, which in turn simplifies the model and reduces its complexity. This process can be seen as a form of regularization, although it doesn't fall into the categories of dropout or L2 regularization. Therefore, based on the provided context, while we cannot confirm the use of dropout or L2 regularization, we do see evidence of using RFE as a potential means to mitigate overfitting.