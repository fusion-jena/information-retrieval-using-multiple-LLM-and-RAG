Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We applied the  standard machine learning hyperparameter  search 
over  two  sites  because  of  computational  cost.  In  our  research,  we 
considered the activation function, the optimizer, and the learning rate. 
In addition, we performed an exhaustive search for the fully connected 
architecture for all mono-site and multi-site models. In all these cases, 
we compare the training, validation, and testing performance to avoid 
overfitting.  We  could  have  achieved  the  same  results  using  hyper-
parameter search software such as Optuna and Sklearn. However, even 
though they could save coding time, we prefer to control every aspect of 
the process to avoid problems. The hyperparameter search involved a 
small grid search selecting the following hyperparameters and values:  

1.  Hidden activation function: ReLU, sigmoid, or elu,  
2.  Optimizer: RMSprop or adam  
3.  Learning rate: 0.1, 0.001, 0.0001, and 0.00001.

While  adopting  deep  learning  techniques  in  remote  sensing  has 
surged, providing novel solutions to complex problems and the devel-
opment of model validation frameworks has lagged, creating a gap in the 
reliability  of  these  advanced  models  (Filippelli  et  al.,  2024).  Deep 
learning models, including CNN architectures and traditional machine 
learning models, frequently underperform in predicting species presence 
or  coverage  in  previously  unconsidered  areas.  This  limitation,  often 
referred  to  as  the  model's  inability  to  generalize  or  transfer  learned 
patterns to new contexts (transfer learning), becomes particularly pro-
nounced in diverse landscapes characterized by significant variations in 
terrain  and  spectral properties  (Barela  et  al., 2021; Kattenborn et  al., 
2022;  Meyer  and  Pebesma,  2021).  The  complex  nature  of  these  het-
erogeneous  environments  poses  significant  challenges  for  model  vali-

of the models. For instance, Mil`a et al. (2022) used the Nearest Neighbor 
Distance Matching (NNDM) LOO CV method to delineate a geographic 
space  in  which  predictions  can  be  made.  Many  of  these  approaches 
accurately  demonstrate  the  model's  transfer  learning  capabilities,  yet 
they  impose  limitations  on  the  training  domain,  leading  to  reduced 
training  heterogeneity  (Meyer  and  Pebesma,  2021).  However,  con-
ducting large CV experiments with deep learning-based models is often 
infeasible due to  their high computational costs. Deep  learning-based 
models  typically  employ  simple  data  partitioning  strategies,  such  as 
training, validation, and testing (Ocer et al., 2020). This simple scheme 
can help to add heterogeneous information to the training procedure, 
but may also overlook the diversity of heterogeneous spatial information 
in remotely sensed data that is aligned with different learning domains

2. Methodology 

Fig.  1  illustrates  the  six-step  workflow  implemented  to  assess  the 
transfer  learning of CNN regression  models under different scenarios. 
Firstly,  we  visually  interpreted  five  UAV-based  orthomosaics  from 
diverse geographic scenarios to delineate areas with P. radiata presence 
(Fig. 1a). Secondly, we used these visual boundaries to generate binary 
model labels indicating the presence or absence of the invasive species 
(Fig.  1b).  Thirdly,  we  employed  pre-trained  CNN-based  regression 
models with various architectures to train and evaluate model accuracy 

EcologicalInformatics82(2024)1026842A. Bravo-Diaz et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not provide any explicit information about where the code repository of the deep learning pipeline is available. Therefore, I cannot determine if it is hosted on platforms like GitHub, GitLab, or BitBucket. To find this information, one would need additional details regarding the authors, project name, or other relevant keywords to conduct a proper search.

Based on the provided context, here are some key points related to the study:

* A hyperparameter search was conducted over two sites considering the activation function, optimizer, and learning rate.
* An exhaustive search was carried out for the fully connected architecture for both mono-site and multi-site models.
* Training, validation, and testing performances were compared to prevent overfitting.
* Hyperparameter search software like Optuna and Sklearn could have been used but were avoided to maintain full control over the process.
* The small grid search included hidden activation functions (ReLU, sigmoid, or elu), optimizers (RMSprop or Adam), and learning rates (0.1, 0.001, 0.0001, and 0.00001).
* The study focuses on applying deep learning techniques in remote sensing while addressing the challenge of developing reliable model validation frameworks.
* The researchers aim to improve the ability of deep learning models to generalize and transfer learned patterns to new contexts, especially in diverse landscapes with significant terrain and spectral property variations.
* The methodology involves a six-step workflow to assess the transfer learning of CNN regression models under different scenarios.