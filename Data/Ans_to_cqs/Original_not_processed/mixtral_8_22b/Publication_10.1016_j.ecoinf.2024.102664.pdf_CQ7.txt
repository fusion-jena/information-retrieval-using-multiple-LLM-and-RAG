Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1 
The  adjustment  process  of  solver  for  training  network  and  input  time  series 
length for all deep learning models.  

RMSE (10 μg/L) 

Solver for training network (5 Days) 

Input time series length 

adam 

sgdm 

RMSProp 

3 Days 

7 Days 

CNN 

LSTM 

CNN-LSTM 

A 
B 
C 
A 
B 
C 
A 
B 
C 

3.17 
0.62 
0.43 
2.09 
0.54 
0.33 
2.19 
0.56 
0.35 

3.23 
0.67 
0.44 
2.13 
0.55 
0.33 
2.20 
0.57 
0.38 

3.22 
0.63 
0.42 
2.18 
0.55 
0.37 
2.27 
0.60 
0.36 

2.69 
0.64 
0.46 
2.13 
0.65 
0.48 
2.18 
0.61 
0.36 

3.32 
0.63 
0.41 
2.13 
0.57 
0.73 
2.21 
0.52 
0.34

In this study, the structure of the CNN model includes an image input 
layer, a convolutional layer with a kernel size of 2 × 2 × 25, a maximum 
pooling layer with a kernel size of 2 × 2, two fully connected layers, and 
a regression output layer (Fig. 2c). The number of nodes in the first fully 
connected layer is 10, and in the second fully connected layer is 1. The 
structure of the LSTM model includes a sequence input layer, an LSTM 
layer with 60 nodes, two fully connected layers, and a regression output 
layer (Fig. 2c). The number of nodes in the first fully connected layer is 
10, and in the second fully connected layer is 1.

All the collected data is divided into three parts: data from 2003 to 
2020 for training, 2021 data for validation, and 2022 data for testing. 
We  determine  the  structure  and  hyperparameters  of  the  model  by 
assessing the effectiveness of validation data forecasts using data from 
points  A,  B,  and  C.  The  structure  of  all  models,  including  hyper-
parameters such as kernel size and number of nodes, is determined using 
a method that controls variables. This involves keeping other variables 
constant and selecting the parameters that optimize the validation data 
forecast results as the model’s hyperparameters. Table 1 illustrates the 
adjustment process of the solver for training the network and the input 
time  series  length  for  all  models.  In  the  vast  majority  of  cases,  when 
using  Adam  as  the  solver  for  training  the  network,  the  RMSE  of  the 
validation data forecasting results is lower. Adam combines the benefits

Algal bloom forecasts for the Zhoushan fishery in 2022 were evalu-
ated using various deep learning models, as summarized in Table 3. The 
hybrid  CNN-LSTM  model  demonstrated 
superior  performance 
throughout  the  year,  achieving  the  highest  values  for  POD  and  HSS 
compared to other models. Notably, the LSTM model outperformed the 
CNN model. The Zhoushan fishery exhibits pronounced seasonal varia-
tion in algal blooms, with the highest occurrence in summer, totaling 
8468 bloom days, followed by Spring with 4720 bloom days. Among all 
seasonal forecasts, the hybrid CNN-LSTM model consistently achieved 
the  highest  HSS  values.  Specifically,  during  the  peak  algal  bloom 
occurrence in summer, the hybrid CNN-LSTM model excelled with both 
POD and HSS at 0.32. In contrast, during winter and autumn, the hybrid 
CNN-LSTM model displayed lower HSS values, primarily due to elevated 
FAR.  Across  all  model  forecasts  and  seasonal  variations,  the  POCR

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: In this study, the collected data was divided into three parts for the purpose of training, validating, and testing the deep learning models. The division of data was based on temporal criteria. Data from 2003 to 2020 was used for training the models. The data from 2021 was utilized for validation purposes, which involved assessing the effectiveness of the models' predictions using data from points A, B, and C. Lastly, the data from 2022 was reserved for testing the final performance of the trained models.