Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4.2. Data model & vocabularies

A conceptual diagram of the many types of data that can be gen-
erated from one fish is shown in Fig. 1. There are 4 parameters of

Ecological Informatics 59 (2020) 101115

Samples are assigned a persistent unique identifier physically, and then catalogued into the
digital system using the identifier.
The Data Model in Fig. 2 and the O&M Model in Fig. 4 outlines the rich metadata model for
sample data description.
The unique identifier is clearly outlined on the physical sample, and links it to the digital
system (Fig. 2). Furthermore, resulting images of the sample are also permanently linked to
the unique identifier.
Metadata are indexed and searchable locally, and further work is being doing to make it more
widely searchable
The metadata are stored in a Web-based system which uses a standard HTTP to retrieve
metadata from a Web address based on the sample's unique identifier.
Even if samples have been destroyed for analyses, their metadata is still recorded and
preserved. The dataset to which the destroyed samples belonged can be accessed from within
the MI Data Catalogue system.

Fig. 1. A mind map of the potential information associated with a fish scale or otolith sample.

3

E. Tray, et al.

Ecological Informatics 59 (2020) 101115

Fig. 2. Data model for the IFBA fish scale and otolith archive.

Table 1
Some of the external vocabulary servers used for various parameters in the data model.

Vocabulary server

CM Parameter

Description

Link to parameter

Terms used

International Council for the Exploration of the Seas

Fish Origin

(ICES)

Developmental Stage

The genetic origin of the sampled
specimen
The life stage of sampled specimen

World Register of Marine Species (WoRMS)

Species

The species of the sampled specimen

Gender

The gender of the sampled specimen

FishBase

Maturity

The observed maturity of the sampled
specimen

https://vocab.ices.dk/?ref=52

https://vocab.ices.dk/?ref=153

https://vocab.ices.dk/?ref=1478

Malde, K., Handegard, N.O., Eikvil, L., Salberg, A.B., 2019. Machine intelligence and the
data-driven future of marine science. ICES J. Mar. Sci. https://doi.org/10.1093/
icesjms/fsz057.

Mao, X., Cai, T., Olyarchuk, J.G., Wei, L., 2005. Automated genome annotation and

pathway identification using the KEGG Orthology (KO) as a controlled vocabulary.
Bioinformatics 21 (9), 3787–3793. https://doi.org/10.1093/bioinformatics/bti430.
Mapp, J., Hunter, E., Van Der Kooij, J., Songer, S., Fisher, M., 2017. Otolith shape and
size: the importance of age when determining indices for fish-stock separation. Fish.
Res. 190, 43–52. 4.2.. https://doi.org/10.1016/j.fishres.2017.01.017.

Marine Institute, 2019. The Stock Book 2019: Annual Review of Fish Stocks in 2019 with

Management Advice for 2020. Marine Institute, Galway, Ireland.

Matta, M.E., Black, B.A., Wilderbuer, T.K., 2010. Climate-driven synchrony in otolith

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To handle randomness in the deep learning pipeline, several strategies can be employed. One common approach is to use fixed random seeds during training to ensure reproducibility of results. This involves setting the same seed value before each run of the model, so that the initial weights and biases, as well as any other stochastic processes such as dropout or shuffling of input data, remain consistent across runs. Another strategy is to perform multiple runs with different random seeds and average the results to reduce variability due to random initialization. Additionally, techniques such as batch normalization and weight decay can help stabilize the optimization process and improve generalization performance. Finally, careful hyperparameter tuning and regularization methods like early stopping can also mitigate the effects of randomness in the deep learning pipeline.