Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

When training a deep convolutional neural network, it is important to split the data
into a training set, a validation set, and a test set. The training set is used for optimizing the
parameters of the network, while the validation set is used for monitoring the performance
of the network during training and for comparing the performance of different networks
with, for example, different hyperparameters or network structures. The test set acts as a
ﬁnal evaluation of a network. To ensure a proper evaluation on both the validation set and
the test set, samples in each set must be independent and have similar class distributions.
The full data set can be split in various ways. The naïve approach is to randomly
sample images from the full data set. However, due to the images being captured in
close proximity and potentially having overlapping ﬁelds of views, information may leak
between the data sets when using the naïve approach. Another approach would be to

All networks were trained on the training set for 100 epochs, using the Adam opti-
mizer [27] with a learning rate of 0.001 and cross-entropy loss. The image batch size varied
from 1 to 32 images, depending on the input image resolution with larger batch sizes
for smaller image sizes. After each epoch, the network was evaluated on the validation
set. The epoch model with the highest accuracy on the validation set during training was
saved for further analysis. Before training the networks, the training set was balanced by
upsampling the images from the underrepresented classes through repetition to match the
number of images of the most represented class, “No species”.

the collected data. Finally, the deep learning algorithms are evaluated and the challenges
of monitoring IAPS are discussed.

A preliminary test showed that the processing platform could evaluate images with
a resolution of 224 × 224 pixels in real time, using ResNet50-v2 [22]. MobileNet-v2 [23]
is a network structure designed with mobile devices in mind. In other words, it aims
for good performance with a low computational load. Both network structures are avail-
able in Keras [24] that is a high-level API based on Tensorﬂow [25], and they include
weights pre-trained on ImageNet [26], making them easy to evaluate in the case at hand.
Therefore, the two network structures ResNet50-v2 and MobileNet-v2 were explored for
image classiﬁcation.

5.1.1. Network Training Procedure

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

From the given context, there isn't explicit mention of specific datasets like MNIST, CIFAR, or ImageNet being used in the deep learning pipeline. However, it does indicate that the networks were trained on a dataset referred to as the 'training set'. This training set was likely derived from the 'full data set', which consisted of images captured in close proximity and possibly with overlapping fields of view.

Additionally, it mentions that the networks ResNet50-v2 and MobileNet-v2 were explored for image classification, and these networks included weights pre-trained on ImageNet. This suggests that although the primary dataset used for training might not be explicitly mentioned, the models did leverage transfer learning from ImageNet.

In summary, while the exact names of the datasets used aren't specified, we do know that a 'full data set' was used to create a 'training set', and the models utilized transfer learning from ImageNet.