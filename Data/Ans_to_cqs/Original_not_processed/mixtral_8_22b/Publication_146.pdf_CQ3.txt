Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

for deep learning. arXiv 2019, arXiv:1910.05446.

17. Ruder, S. An overview of gradient descent optimization algorithms. arXiv 2016, arXiv:1609.04747.
18. Taqi, A.M.; Awad, A.; Al-Azzo, F.; Milanova, M. The impact of multi-optimizers and data augmentation on
TensorFlow convolutional neural network performance. In Proceedings of the 2018 IEEE Conference on
Multimedia Information Processing and Retrieval (MIPR), Miami, FL, USA, 10–12 April 2018; pp. 140–145.
19. Olson, M.; Wyner, A.; Berk, R. Modern neural networks generalize on small data sets. In Proceedings of
the Advances in Neural Information, Neural Information Processing Systems 31 (NeurIPS 2018), Montreal,
BC, Canada, 3–8 December 2018; pp. 3619–3628.

20. Ammar, A.; Koubaa, A.; Ahmed, M.; Saad, A. Aerial images processing for car detection using convolutional

neural networks: Comparison between faster r-cnn and yolov3. arXiv 2019, arXiv:1910.07234.

•
•
•

R = HH or VH
G = HV or VV
B = HH or VH

The initial objects are outlined as vectors in the given Sentinel-1 images (see Figure 2), and they are
converted into the darknet annotation format with text ﬁles containing information on the label class
of objects and positions in the image. The Sentinel-1 images are cropped into image tiles in the sizes of
640 × 640 pixels, resulting in a total of 1609 images with corresponding label ﬁles. Code for darknet
conversion is available at GitHub (see Supplementary Materials). Out of these images, 20% (322) are
selected as validation data, and the remaining 80% (1288) for model training.

Figure 2. Samples of training objects’ bounding boxes, icebergs in top row and ships in bottom row.
The targets are shown in single-polarization greyscale, HH (top) and VH (bottom).

2.2. YoloV3 Model Architecture

21. Manning, C.D.; Schütze, H.; Raghavan, P. Introduction to Information Retrieval; Cambridge University Press:

Cambridge, UK, 2008.

22. Rezatoﬁghi, H.; Tsoi, N.; Gwak, J.; Sadeghian, A.; Reid, I.; Savarese, S. Generalized intersection over union:
A metric and a loss for bounding box regression. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, Long Beach, CA, USA, 15–20 June 2019; pp. 658–666.
Soldal, I.H.; Dierking, W.; Korosov, A.; Marino, A. Automatic Detection of Small Icebergs in Fast Ice Using
Satellite Wide-Swath SAR Images. Remote Sens. 2019, 11, 806. [CrossRef]

23.

Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional
aﬃliations.

© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

Due to the lack of existing quality data, we set out to create our own data set for the purpose of
the project. The data set created is, in a deep learning context, still at a relatively small size. However,
testing the model under very diﬃcult circumstances and complex backgrounds still yielded good
detection capabilities, paving the way for future work.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the initial objects are outlined as vectors in the given Sentinel-1 images and then converted into the darknet annotation format. The conversion process involves creating text files containing information on the label class of objects and their positions in the image. The Sentinel-1 images are also cropped into smaller image tiles of 640 x 640 pixels, resulting in a total of 1609 images with corresponding label files. Out of these images, 20% are selected as validation data, while the remaining 80% are used for model training. The targets are displayed in single-polarization greyscale, either HH or VH. Therefore, it can be concluded that the primary data annotation technique used in this deep learning pipeline is bounding box annotation.