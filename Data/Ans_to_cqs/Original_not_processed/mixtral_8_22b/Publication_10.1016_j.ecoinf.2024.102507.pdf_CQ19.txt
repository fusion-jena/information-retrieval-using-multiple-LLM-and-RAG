Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

built using the following steps:  

1.  Prepare  data:  Prepare  the  above  eight  categories  of  ground  truth 

images, and extract training samples.  

2.  Build  the  model:  Use  Keras  to  build  mathematical  functions  in 

TensorFlow.  

3.  Compilation: After the model built with mathematical functions, the 
shortest path is set in deep learning through code compilation.  
4.  Training:  The  fitting  action  (fit)  on  the  data  and  the  model  was 
performed  through  the  code,  and  deep  learning  parameters  were 
automatically adjusted according to the set number of epochs. In the 
process, the CPU and GPU were used to operate repeatedly as much 
as possible, and finally, the answer that conformed to the shortest 
path was found from each data.  

5.  Test: After Step (4), the feature weight and optimal solution in the 
model  were  obtained,  and  then  the  correct  rate  was  calculated 
through model evaluation.

VGG19 network architecture and adds a residual unit involving a short- 
circuit  mechanism,  which  can  overcome  the  issue  of  gradient  disap-
pearance and accuracy reduction in deep networks. 

2.6. Overall study process 

In summary, the complete process is illustrated in the figure below, 
with elements in blue indicating the Python packages or modules uti-
lized in each step. The objectives and tools used for each process below 
are also outlined. The detailed parameter settings and outcomes for each 
process are presented in the Results section. 
The complete process of data processing. 

EcologicalInformatics80(2024)1025076F.-C. Lin et al.                                                                                                                                                                                                                                   

1.  Spectral segmentation and band selection

EcologicalInformatics80(2024)1025078F.-C. Lin et al.                                                                                                                                                                                                                                   

Table 2 
Number of bands used in deep learning and the band numbers selected after SSDM.  

Number of bands 

Corresponding number 

3 
4 
8 
36 
72 

(13,20,32) 
(2,5,38,41) 
(2,5,8,38,41,52,63,66) 
(1,2,3,4,5,6,7,8,9,10,11,36,37,38,39,40,41,42,43,49,51,52,53,55,59,61,62,63,64,65,66,67,69,70,71,72) 
All bands  

result is shown in Fig. 4.

When  the  image  units  of  bands  36  and  72  are  input  to  the  deep 
learning model, the memory capacity may be insufficient given the large 
dimensions. Therefore, when inputting sample images for bands 36 and 
72, we used Python's Rasterio module to disassemble them into single- 
band  images,  i.e.,  the  image  units  with  36  bands  were  disassembled 
into 36 single-band images and 72-band images were disassembled into 
72  single-band  images.  This  data  conversion  method  is  equivalent  to 
flattening the thick convolution kernel. During testing, we found that 
through  the  optimization  of  this  process,  the  hardware resources  and 
computing time required for deep learning can be considerably reduced, 
while the corresponding impact on the model's accuracy is limited. 

3.2. Deep learning model and testing results 

After selecting the model, the CNN model in this study was further 

built using the following steps:

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model in this study is built using Keras, which is a high-level neural networks API written in Python. It runs on top of TensorFlow, another popular open-source library for machine learning and artificial intelligence tasks. So, both TensorFlow and Keras are used to build the deep learning model in this study.