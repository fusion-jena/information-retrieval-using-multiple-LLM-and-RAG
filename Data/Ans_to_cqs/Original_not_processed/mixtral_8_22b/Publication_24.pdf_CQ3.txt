Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ditional  methods  (Farinha- Marques,  Lameiras,  Fernandes,  Silva,  & 

automatically  based  on  the  annotated  training  data  provided. 

Guilherme, 2011). This inhibits our ability to conduct the large- scale 

Convolutional Neural Networks, CNNs (or Deep learning) (LeCun, 

assessment that is necessary for understanding urban ecosystems.

Bengio,  &  Hinton,  2015)  can  even  choose,  based  on  the  annota-

Ecoacoustic surveying has emerged as a useful method of large- 

tions in the training dataset, the features that discriminate different 

scale  quantification  of  ecological  communities  and  their  habitats 

classes  in  datasets  without  being  specified  a  priori,  and  can  take 

(Sueur  &  Farina,  2015).  Passive  acoustic  recording  equipment  facil-

advantage of large quantities of training data where their ability to 

itates the collection of audio data over long time periods and large

sults  generalised  well. To  optimise  the  quality  of  the  annotations 

oriented horizontally at a height of 1 m. Files were saved in .wav for-

mat  onto  a  SD  card.  Audio  was  recorded  in  computationally  man-

in  CitySounds2017test,  we  selected  five  human  labellers  to  sepa-
rately annotate the sounds within the audio recordings (using the 

ageable chunks of 29 min of every 30 min (23.2 hr of recording per 

same methods as above) to create a single annotated test dataset. 

day), which were divided into 1- min audio files using Slice Audio File 

Conflicts were resolved using a majority rule, and in cases where 

Splitter (NCH Software Inc. 2014), leading to a total of 613,872 dis-

there  was  no  majority,  we  used  our  own  judgement  on  the  most 

crete minutes of audio recording (9,744 min for each of the 63 sites). 

suitable  classification.  Overall,  we  found  the  labellers  to  be  rea-

This constituted the CitySounds2017 dataset.

Supporting Information section at the end of the article.

How to cite this article: Fairbrass AJ, Firman M, Williams C, 

Brostow GJ, Titheridge H, Jones KE. CityNet—Deep learning 

tools for urban ecoacoustic assessment. Methods Ecol Evol. 

2019;10:186–197. https://doi.org/10.1111/2041-210X.13114

FAIRBRASS et Al. 2041210x, 2019, 2, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13114 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

436–444. https://doi.org/10.1038/nature14539

Lee, H., Pham, P., Largman, Y., & Ng, A. Y. (2009). Unsupervised feature 
learning for audio classification using convolutional deep belief networks 
(pp. 1096–1104). Proceedings of the 22nd International Conference 
on Neural Information Processing Systems, Istanbul, Turkey.

Lin,  T.-H.,  Fang,  S.-H.,  &  Tsao,  Y.  (2017).  Improving  biodiversity  as-
sessment  via  unsupervised  separation  of  biological  sounds  from 
long- duration  recordings.  Scientific  Reports,  7,  4547.  https://doi.
org/10.1038/s41598-017-04790-7

McFee, B., Raffel, C., Liang, D., Ellis, D. P., McVicar, M., Battenberg, E., 
&  Nieto,  O.  (2015).  librosa: Audio and music signal analysis in python 
(pp. 18–25). Proceedings of the 14th python in science conference, 
Austin, TX.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific data annotation techniques used in the deep learning pipeline. However, it mentions that the process involves selecting human labellers to separately annotate the sounds within the audio recordings. The conflicts between these annotations are then resolved using a majority rule or personal judgment if there is no clear majority. This suggests that the annotation technique might involve some form of sound categorization or labeling, but the exact nature of the annotation (such as whether it uses bounding boxes or instance segmentation) cannot be determined from the given information.