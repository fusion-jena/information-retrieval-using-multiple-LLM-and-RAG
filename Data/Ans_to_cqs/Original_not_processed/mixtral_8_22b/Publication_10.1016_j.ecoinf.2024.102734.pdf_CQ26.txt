Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

samples (red line) compared to randomly ordered samples, no active
learning (blue line), and active learning using high-certainty samples
(yellow line). The baseline accuracy is calculated using a 2-shot, 2-way
test accuracy without fine-tuning (81.4%). The AST feature extraction
model is fine-tuned on a subset of 500 training samples. Model perfor-
mance is re-evaluated on the test set at 10 sample increments using each
of the three sample orderings. Low certainty refers to queries with a
similar Euclidean distance to prototypical embeddings and therefore lie
along decision boundaries. For high-certainty samples, the order is
reversed with query embedding in close proximity to prototypical em-
beddings being prioritised for model fine-tuning.

Fig. 2. Raw field data are segmented into 5-s spectrograms. A pre-trained feature extraction generates 527-dimensional embedding vectors for each segment.
Coloured vectors denote embeddings that were previously labelled.

EcologicalInformatics82(2024)1027344B. McEwen et al.

Fig. 3. Transfer learning using pre-trained feature extraction model and fully connected layers with adjustable output nodes.

Fig. 4. Prototypical learning provides a class probability distribution that a query belongs to each class. The probability distribution is used to rank the priority of
samples. The colours denote the class distributions in a simplified 2-dimensional view.

2.1. State of the art

Machine learning tasks designed for low-data contexts are referred to
as few-shot learning tasks. Within the context of bioacoustic applications,

EcologicalInformatics82(2024)1027342B. McEwen et al.

the field of computational bioacoustics (Stowell, 2021) has experienced
significant development over the last few years, in part due to public
challenges such as the Detection and Classification of Acoustic Scenes
and Events (DCASE) (Nolasco et al., 2023).

We compare three classification models - ResNet-50 (He et al., 2016),
Audio Spectrogram Transformer (AST) (Gong et al., 2021) and HuBERT
(Hsu et al., 2021). The classification models compared in Section 4.1
were trained on a dataset containing 3000 5 s segments automatically
generated by the annotator. The dataset includes 1130 possum vocal-
isations and 1870 noise sources. The dataset has an 80/20% training-
validation split which is used to evaluate model performance during
training. Model hyperparameters are implemented based on the
recommendation outlined by the model authors. Each segment has been
manually reviewed by a human. 500 segments are separated into a test
set containing 187 possum vocalisations and 313 noise samples. The
distribution of target features to non-target features is representative of
the true distribution post-segmentation. Both validation and test dataset
performance are reported. Using the test dataset we evaluate the model

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions that both validation and test datasets have a representative distribution of target features to non-target features, indicating that some form of stratified sampling or balanced data collection might be employed. Additionally, the use of transfer learning and pre-trained feature extraction models could help mitigate potential biases introduced by limited or imbalanced datasets.