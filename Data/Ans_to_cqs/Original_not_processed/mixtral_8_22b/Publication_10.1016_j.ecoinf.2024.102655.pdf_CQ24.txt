Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Unraveling longitudinal pollution patterns of organic micropollutants in a river by

non-target screening and cluster analysis. Sci. Total Environ. 727, 138388 https://
doi.org/10.1016/j.scitotenv.2020.138388.

Bilbao, I., Bilbao, J., 2017. Overfitting problem and the over-training in the era of data:
Particularly for Artificial Neural Networks. In: 2017 Eighth International Conference
on Intelligent Computing and Information Systems (ICICIS). Presented at the 2017
Eighth International Conference on Intelligent Computing and Information Systems
(ICICIS), pp. 173–177. https://doi.org/10.1109/IN℡CIS.2017.8260032.

Bo¨enne, W., Desmet, N., Looy, S.V., Seuntjens, P., 2014. Use of online water quality

monitoring for assessing the effects of WWTP overflows in rivers. Environ Sci Process
Impacts 16, 1510–1518. https://doi.org/10.1039/C3EM00449J.

model combining Artificial Bee Colony and Back Propagation Neural
Network algorithms, obtaining significantly higher prediction accuracy
compared to SVM and Long Short-Term Memory (LSTM) neural net-
works (Chen et al., 2023). Other approaches include a previous data
transformation to optimize the response of the predictive algorithm
applied. For example, variational mode decomposition was applied to
decompose water quality data into a series of relatively stable compo-
nents used to train a LSTM neural network (Wang et al., 2023). This
approach produced higher prediction accuracy compared to a single
LSTM and Recurrent Neural Network.

4.2. Machine learning models

2.2. Data pre-processing

The complete dataset of 42 WQPs (Appendix A) for the 13 moni-
toring sites was subjected to an outlier detection and artificial data
replacement process, as Casillas-García et al. (2021) reported. Processed
data were used subsequently to train machine learning models, first with

EcologicalInformatics82(2024)1026552A.F. del Castillo et al.

Fig. 1. Study area and geographical distribution of sampling points along the Santiago-Guadalajara River.

the full dataset of 13 monitoring sites and secondly with the best training
subset (BTS) composed of sites selected by CA and TSA. Predictions from
all models were evaluated by comparing the root-mean-square-error
(RMSE), mean squared error (MSE), mean absolute error (MAE) and
coefficient of determination (R2) and finally, the BTS-ANFIS was tested
against new data and individual data from each monitoring site. The
general procedure for the training data selection and model develop-
ment is described in Fig. 2.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
None of the provided sources directly address the issue of handling randomness in the deep learning pipeline, such as managing random seed values. However, some general strategies can be employed to manage this type of randomness. One common approach is to set a fixed random seed value before running any code involving random processes, which ensures reproducibility of results across different runs or machines. Another strategy involves using techniques like cross-validation or bootstrapping to estimate the performance of a model while accounting for variations due to randomness. Additionally, ensemble methods, where multiple models are trained independently and their predictions combined, can help reduce the impact of randomness on overall performance.