Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

feature  images  while  retaining  crucial  features.  The  Dropout  layer  is  integrated  to  mitigate 

overfitting. Additionally, the Global Average Pooling layer summarizes features, generating input 

for the fully connected layer. This layer also facilitates the visualization of regions relied upon by 

the network for predictions. The subsequent three fully connected layers generate the predicted 

class for the original image 

Table 1: Main parameters of the classification network 

[

Input size 

Output size 

Journal Pre-proof

[

[

[

Parameters 

  conv, strides 1] 

  conv, strides 1] 

  max pool 

  conv, strides 1] 

  conv, strides 1] 

Probability 0.5 

  max pool 

[

  conv, strides 1] 

Layers 

Convolution 

Convolution 

Pooling 

Convolution 

Convolution 

Dropout 

Pooling 

Convolution 

Global Average Pooling 

Dense 

Dense 

Classification layer (Dense) 

128 

128 

128 

128 

128 

128 

1 

- 

- 

- 

-

CNN architecture but  with  different  filter sizes.  The obtained  results depend on the number of 

hidden layers, filter size, and the number of filters in convolution layers. The higher the number of 

hidden layers, filter size, and filters, the higher the accuracy of classification. In [29], the authors 

proposed  four  different  models  for  bee  image  classification,  serving  different  tasks  in  beehive 

monitoring. All these models were based on different Deep Neural Networks (DNNs) that have 

been  pre-trained  on  the  ImageNet  dataset  [30]  including  AlexNet,  DenseNet-201,  GoogLeNet, 

ResNet-101, ResNet-18, VGG-16, VGG-19. In the first model, the authors used a transfer learning 

method based on these pre-trained DNNs. Meanwhile, in the second, third, and fourth models, the 

authors used the SVM classifier with deep features, shallow features, and deep+shallow features

[8] 

V.  Krishnasamy,  N.  Sridhar,  L.  Niranjan,  An  iot-based  beehive  monitoring  system  for 

real-time  monitoring  of  apis  cerana  indica  colonies,  Sociobiology  70  (4)  (2023) 

Journal Pre-proof

e9352–e9352. 

[9] 

V. Kulyukin, S. Mukherjee, P. Amlathe, Toward audio beehive monitoring: Deep learning 

vs. standard machine learning in classifying beehive audio samples, Applied Sciences 8 (9) 

(2018) 1573. 

[10]  Y. Zhao, G. Deng, L. Zhang, N. Di, X. Jiang, Z. Li, Based investigate of beehive sound to 

detect  air  pollutants  by  machine  learning  ,  Ecological  Informatics  61  (2021)  101246. 

[11]  T. H. Truong, H. Du Nguyen, T. Q. A. Mai, H. L. Nguyen, T. N. M. Dang, et al., A deep 

learning-based  approach  for  bee  sound  identification,  Ecological  Informatics  78  (2023) 

https://www.sciencedirect.com/science/article/pii/S15749541

doi:https://doi.org/10.1016/j.ecoinf.2021.101246. 

URL 

21000376 

102274. 

23269–23296. 

Journal Pre-proof

VnPollenBee dataset. The best metrics values are shown in bold font. 

Method 

Evaluation metrics 

Journal Pre-proof

Our proposed methods 

Baseline methods 

0.12  0.004 

0.15  0.009 

0.086  0.03 

0.99 

0.99 

0.58 

0.96 

0.41 

0.91 

0.85 

0.88 

0.88 

MR 

Yolov5 + classification  0.11 

Yolov5 + focal loss 

Yolov5 [39] 

Faster RCNN [40] 

0.91 

0.93 

0.70 

0.93 

FAR  Precision  Recall  F1-score 

Faster RCNN 

+ Overlap Sampler 

0.07 

0.01 

0.99 

0.93 

0.95 

Figure 14: Evaluation metrics of the pollen-bearing bee detection results. 

Figure 15: Detection results of the proposed improvement: (above) YOLOv5 + focal loss, (below) 

Faster  RCNN  +  Overlap  sampler.  The  green  and  red  boxes  indicate  pollen-bearing  and 

 
 
Journal Pre-proof

non-pollen-bearing bees, respectively. Values indicate the confidence score. 

Furthermore,  Fig.  15  depicts  some  detection  outcomes  of  the  second  proposed

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not explicitly mention the specific data format used in the deep learning pipeline. However, it can be inferred from the context that the primary focus is on image data. The text discusses various aspects related to image processing and analysis using Convolutional Neural Networks (CNN), such as feature extraction, dropout layers, global average pooling, and fully connected layers. Furthermore, there are references to pre-training models like AlexNet, DenseNet-201, GoogLeNet, ResNet-101, ResNet-18, VGG-16, and VGG-19 on the ImageNet dataset, which consists mainly of images. Therefore, it can be concluded that the deep learning pipeline primarily uses image data.