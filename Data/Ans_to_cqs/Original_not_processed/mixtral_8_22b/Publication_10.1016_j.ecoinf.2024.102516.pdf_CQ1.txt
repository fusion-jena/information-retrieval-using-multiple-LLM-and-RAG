Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Appendix A. Supplementary data 

Supplementary data to this article can be found online at https://doi. 

org/10.1016/j.ecoinf.2024.102516. 

References 

Altalak, M., Ammad uddin, M., Alajmi, A., Rizg, A., 2022. Smart agriculture applications 

using deep learning technologies: A survey. Appl. Sci. 12 (12), 5919. 

Bambil, D., Pistori, H., Bao, F., Weber, V., Alves, F.M., Gonçalves, E.G., de Alencar 
Figueiredo, L.F., Abreu, U.G., Arruda, R., Bortolotto, I.M., 2020. Plant species 
identification using color learning resources, shape, texture, through machine 
learning and artificial neural networks. Environ. Syst. Decis. 40 (4), 480–484. 
Bauer, T., Strauss, P., 2014. A rule-based image analysis approach for calculating 

residues and vegetation cover under field conditions. Catena 113, 363–369. 

Blaschke, T., 2010. Object based image analysis for remote sensing. ISPRS J. 

Photogramm. Remote Sens. 65 (1), 2–16.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Plant biodiversity 
Plant cover 
Deep learning 
Convolutional neural networks 
Semantic segmentation 
Artificial intelligence

extract  plant  cover  information  without  training  on  actual  annotated 
plant cover data. 

2.3.1. Base network

2.4. Network setup for investigations 

For extracting plant species cover information for our investigations, 
we  use  the  same  setup  as  described  in  K¨orschens  et  al.  (2021b)  with 
slight differences. During all three phases, we use a ResNet50 (He et al., 
2016),  which  is  initialized  with  ImageNet  (Russakovsky  et  al.,  2015) 
weights from Keras (Chollet et al., 2015) before phase 1 and phase 2, as 
well as the AdamW optimizer (Kingma and Ba, 2014; Loshchilov and 
Hutter, 2017). During each phase, we use the ResNet in conjunction with 
a  Feature  Pyramid  Network  (FPN)  (Lin  et  al.,  2017)  to  increase  the 
network output resolution. Phase-specific parameters are listed in the 

EcologicalInformatics80(2024)1025167M. K¨orschens et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide explicit details about the method used for collecting raw data in their deep learning pipeline. However, it mentions that they use a ResNet50 architecture pretrained on ImageNet weights, suggesting that they might have used images as input data. Additionally, the authors reference other papers such as "Smart agriculture applications using deep learning technologies" by Altalak et al. and "Plant species identification using color learning resources, shape, texture, through machine learning and artificial neural networks" by Bambil et al., indicating that these studies could potentially involve similar data collection methods like image acquisition or sensor data. Nevertheless, without specific information regarding the data collection process in this study, one cannot definitively state what methods were employed.