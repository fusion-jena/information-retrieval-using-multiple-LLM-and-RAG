Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

compressed,  reducing  to  only  a  few  pixels  in  deeper  CNN  layers.  For 
instance, an object with dimensions of 15 Ã— 15 pixels in a UAV thermal 
image might be represented by just 1 pixel in the feature map from Layer 
4 of ResNet152 (refer to Fig. 4). The limited spatial resolution can lead to 
loss of fine details, making it difficult for the model to distinguish small 
objects from the background. Through FPN, different feature maps from 
different layers can complement each other, and deeper feature map can 
receive some spatial information from shallower layers. However, still 
certain  spatial  features  might  have  been  lost  during  the  process  of 
convolution operations. Consequently, the models of FRC_ResNet18FPN 
and FRC_ResNet34FPN can obtain higher AP for medium and large ob-
jects than the remaining models because they have less CNN layers than 
others.  Notably,  the  FRC_ResNet152FPN  obtains  the  best  detection

precision and recall trade-offs, providing a method to assess the overall 
effectiveness of a model.

performance for small objects (Fig. 12 (a)) with an AP of 78.3%, which is 
explicitly  higher  than  other  models.  Specifically,  the  AP  of  FRC_Res-
Net152FPN is approximately 5% higher than that of FRC_ResNet18FPN 
and 8% higher than that of FRC_ResNet34FPN. According to Table 2 and 
Fig. 12 (a), the sizes of small objects in the UAV imagery in this paper are 
<200 pixels, and the related spatial information is possibly not enough

for a model to detect and identify them. Under this condition, more CNN 
layers mean that more abstractly semantic information can be extracted. 
Therefore, FRC_ResNet152FPN has more advantages than others in this 
sense.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text discusses the use of Feature Pyramid Network (FPN) with various ResNet architectures (ResNet18, ResNet34, and ResNet152) for object detection in Unmanned Aerial Vehicle (UAV) thermal images. To evaluate the performance of these models, the Average Precision (AP) metric is primarily used. AP is a popular evaluation metric for object detection tasks, which considers both precision and recall values. In this case, the AP is calculated separately for small, medium, and large objects based on their size in pixels.

According to the given context, the FRC\_ResNet152FPN model achieves the highest AP for small objects (78.3%) compared to other models like FRC\_ResNet18FPN and FRC\_ResNet34FPN. This indicates that FRC\_ResNet152FPN provides better detection precision and recall trade-offs, thus being more effective overall. The superior performance of FRC\_ResNet152FPN for small objects is attributed to its ability to extract more abstractly semantic information due to having more convolutional neural network (CNN) layers.

In summary, the primary metric used to evaluate the performance of the deep learning models discussed in the given context is Average Precision (AP). Other common metrics such as accuracy, precision, or recall are not explicitly mentioned but could also be relevant when evaluating object detection models.