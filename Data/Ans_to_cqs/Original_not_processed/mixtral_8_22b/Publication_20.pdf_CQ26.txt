Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet Classiﬁcation with Deep
Convolutional Neural Networks. InAdvances in Neural Information Processing
Systems. pp. 1097–1105.

Krueck, N.C., Ahmadia, G.N., Possingham, H.P., Riginos, C., Treml, E.A., Mumby, P.J.,

2017. Marine reserve targets to sustain and rebuild unregulated ﬁsheries. PLoS Biol.
15 (1), e2000537.

Kulbicki, M., Parravicini, V., Bellwood, D.R., Arias-Gonzàlez, E., Chabanet, P., Floeter,
S.R., ... Mouillot, D., 2013. Global biogeography of reef ﬁshes: a hierarchical quan-
titative delineation of regions. PLoS One 8 (12), e81847.

Langlois, T.J., Harvey, E.S., Fitzpatrick, B., Meeuwig, J., Shedrawi, G., Watson, D., 2010.
Cost-eﬃcient sampling of ﬁsh assemblages: comparison of baited video sta=tions

244

and diver video transects. Aquat. Biol. 9, 155–168.

A link to a depository with architecture details is given at the end of
references. We stopped the network training after 70 epochs (i.e. a
complete scope of the dataset where each image is used only once), to
−5, an exponential
prevent overﬁtting. We used a learning rate of 10
learning decay with a Gamma of 0.95, a dropout of 50% and an Adam
Solver type as learning parameters. Those are classic hyper-parameters
for a fast convergence of the network without over-ﬁtting (Srivastava
et al., 2014). The weight initialization is also classic with a random
Gaussian initialization. The training lasted 8 days on our conﬁguration;
we trained and ran our code on a computer with 64GB of RAM, an i7
3.50GHz CPU and a Titan X GPU card for 900,000 images.

We used at least 2200 thumbnails per ﬁsh species class, and batches

240

S. Villon et al.

Ecological Informatics 48 (2018) 238–244

The model was trained using thumbnails of whole ﬁsh, part of ﬁsh species and
environment (T?). Raw outputs were post-processed applying two decision
rules: (r1) keeping most likely ﬁsh class if “environment” was the most likely
class, and (r2) considering “part of species X" equivalent to “species X".

Species

Number of thumbnails
tested

Deep-learning
model

Humans

Abudefduf sparoides
Abudefduf vaigiensis
Chaetodon trifascialis
Naso elegans
Pomacentrus sulfureus
Pygoplites diacanthus
Thalassoma hardwicke
Zanclus cornutus
Zebrasoma scopas
Average success rate

88
47
149
165
443
35
73
53
144
1197

93.4
97.3
95.1
98.4
97.9
90.4
96
97.1
96.2
95.7

87.7
84.7
89.4
94.8
93.2
77.4
91
97.8
88.3
89.3

The fourth training dataset T4 contained thumbnails from T3 minus
the “part of ﬁsh”, which is replaced by 20 classes “part of species”
obtained by splitting thumbnails from each species. The diﬀerence
between T3 and T4 was that T3 contained only one global class “part of
ﬁsh” whereas T4 contained as many “part of species” classes as there
were “ﬁsh” species.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it appears that the authors have employed several strategies to mitigate potential data bias during the preprocessing stage of their deep learning pipeline. However, they do not explicitly mention specific techniques such as stratified splitting, oversampling, undersampling, or diverse data collection. Nevertheless, we can infer some methods based on the information available.

Firstly, the authors ensured that they had a sufficient number of thumbnail samples for each fish species class, with at least 2200 thumbnails per class. This approach could be considered a form of oversampling, as it ensures that even underrepresented classes have enough examples to train the model effectively.

Secondly, the authors applied two decision rules during post-processing to handle cases where the environment or parts of fish species were present in the input data. Rule r1 addresses situations where the environment is the most likely class, ensuring that the focus remains on identifying fish species rather than background elements. Meanwhile, rule r2 treats "part of species X" as equivalent to "species X," allowing the model to recognize partial representations of fish species accurately. These decision rules help maintain consistency and accuracy when dealing with potentially ambiguous inputs.

Lastly, the authors created different datasets (T3 and T4) to manage variations in the input data. Dataset T3 included a single global class called "part of fish," while dataset T4 contained multiple "part of species" classes corresponding to individual fish species. By creating these distinct datasets, the authors aimed to improve the model's ability to distinguish between various fish species and reduce any potential bias caused by inconsistent labeling or classification schemes.

In conclusion, although the authors did not directly discuss traditional techniques like stratified splitting, oversampling, undersampling, or diverse data collection, they implemented several strategies to minimize data bias during preprocessing. These include employing adequate sample sizes, applying decision rules to handle ambiguous inputs, and managing input variations through separate datasets.