Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5.2. Result analysis 

The datasets are divided into training set and test set according to the 
ratio of 8:2. And the number of test samples and training samples are 
3094 and 12,340, respectively. The classification models are built with 
the training set, and accuracy on test set is used as indicator to evaluate 
performance of classification models. 

5.2.1. Classic CNN model 

The three features of F1, F2 and F3 are input into CNN model, and 

their classification performance on the test set is shown in Table 6. 

Feature 

F1 
F2 
F3 

CNN 

81.00 
88.36 
89.11 

Number of features 

500 
500 
500  

Table 7 
Test accuracy (in %) of various features.  

Feature 

F4 
F5 
F6 
F7 
F4⊕F5⊕F6 
F4⊕F5⊕F6⊕F7 
Fdh 

RF 

82.92 
87.93 
88.47 
85.70 
90.76 
91.10 
95.43 

SVM 

85.59 
91.11 
91.60 
64.51 
93.96 
93.96 
96.19 

MLP 

83.85 
89.53 
90.46 
73.45 
93.40 
93.53 
96.03 

Number of features 

500 
500 
500 
13 
1500 
1513 
96  

5.2.3. Proposed models

shown in the Fig. 6. 

The network is designed with four convolution kernel pooling layers 
to extract deep features. After the convolution pooling, the data enters 
the fully connected layer for connection. The network adds a dropout 
layer  to  the  fully  connected  layer  to  reduce  network  parameters.  A 
Dense_1 layer is added after flatten to reduce the dimension of the deep 
features, and sets the parameter to 500, which is the parameter of the 
deep feature dimension extracted from different views. 

4.2. Feature selection

The  hardware  platform  used  in  this  experiment  is  a  desktop  com-
puter with 128G memory, 16 core and 32 thread CPU, 3.40 GHz fre-
quency  and  24G  GPU.  The  operating  system  is  Windows  10  64-bit 
professional operating system. Annaconda3, PyCharm 2020.1, Python 
3.7, TensorFlow 2.6 as deep learning platform and MATLAB 2018b as 
data processing platform are exploited. Table 4 shows the labels used for 
various features. 

To verify the effectiveness of the proposed method, two groups of 
experiments are designed for comparison and analysis. The one exper-
iment is to compare the proposed model with the classic CNN model. 
That is, using the CNN to classify the spectrums of HHT, WT and STFT. 
Another experiment is to compare the proposed model with the machine

As important members of the ecosystem, birds are good monitors of the ecological environment. Bird recogni-
tion, especially birdsong recognition, has attracted more and more attention in the field of artificial intelligence. 
At  present,  traditional  machine  learning  and  deep  learning  are  widely  used  in  birdsong  recognition.  Deep 
learning can not only classify and recognize the spectrums of birdsong, but also be used as a feature extractor. 
Machine learning is often used to classify and recognize the extracted birdsong handcrafted feature parameters. 
As the data samples of the classifier, the feature of birdsong directly determines the performance of the classifier. 
Multi-view features from different methods of feature extraction can obtain more perfect information of bird-
song. Therefore, aiming at enriching the representational capacity of single feature and getting a better way to

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
According to the given context, the metric used to evaluate the performance of the deep learning model is accuracy. Specifically, the dataset is divided into training and testing sets with a ratio of 8:2, resulting in 3094 test samples and 12,340 training samples. The classification models are then built using the training set, and their performance is evaluated based on the accuracy achieved on the test set. This evaluation approach is consistent across all presented results, including those obtained using the classic CNN model and other proposed models. However, it should be noted that while accuracy is a commonly used metric for evaluating the performance of deep learning models, other metrics such as precision, recall, or F1 score could also have been considered depending on the specific requirements and goals of the study.