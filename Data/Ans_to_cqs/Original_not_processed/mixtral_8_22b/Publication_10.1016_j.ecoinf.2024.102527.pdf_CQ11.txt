Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

When it comes to selecting update layers, we recommend selectively 
updating the last few layers of the DCNN model to enhance its perfor-
mance in empty image recognition. This approach can lead to a signif-
icant  improvement  in  the  model’s  performance,  as  opposed  to  solely 
updating  the  fully  connected  layer.  Specifically,  when  using  a  model 
from  the  ResNext  or  ResNet  family  pre-trained  on  ImageNet  as  the 
source model, we recommend using TLS_4 as the transfer strategy. In 
contexts where pronounced discrepancies exist between the target and 
source  domain  datasets,  it  could  prove  advantageous  to  augment  the 
number of convolutional layers subject to update. For example, in the 
case  of  ResNext  series  models,  using  TLS_3  can  further  enhance  the 
performance of the transfer model.

respectively.  N  represented  the  number  of  images  in  the  test  set  or 
validation set. 

2.2.6. Model training and hyper-parameters 

We  trained  models  on  the  training  sets  and  tracked  the  model 
training process on the validation set. The training process was stopped 
when  the  loss  value  of  the  model  on  the  validation  set  no  longer 
decreased. We then tested the model performance on the test set. Our 
computing platform was a Dell PowerEdge C4130 rack server with two 
Tesla  K80  GPUs  and  256  GB  of  memory.  For  the  deep  learning  envi-
ronment,  we  utilized  the  PyTorch  1.7.1  platform.  We  employed  the 
Stochastic Gradient Descent (SGD) optimizer with a momentum value of 
μ  = 0.9 to train the model. Other hyper-parameter settings for model 
training were shown in Table S.4 of the Supporting Information. 

3. Results 

3.1. Experiment results of transfer strategy optimization

2.2.3. Data splitting 

Based on the conceptual model mentioned above, we split the data to 
construct  the  source  and  target  domain  datasets  to  carry  out  transfer 
learning experiments.  For the  ImageNet  dataset, we directly  used the 
pre-trained model on ImageNet-1 k as the source model, so there was no 
need to split the dataset. Both the SS and the LSM dataset are camera 
trap  image  datasets.  Each  time  the  camera  is  triggered,  it  captures 
multiple images in succession, called a capture event. A capture event 
frequently  comprises  three  images.  Notably,  images  within  the  same 
event are significantly similar to each other. Splitting the images in an 
event into training and test sets may lead to poor generalization of the 
DCNN  model. To  prevent  this, we kept  the integrity  of events  during 
data splitting, putting all images of an event into the same dataset.

Data availability 

The ImageNet dataset can be accessed at the URL (https://image-net. 
org/download.php).  Camera  trap  images  of  the  SS  dataset  can  be 
accessed on Dryad (https://doi.org/10.5061/dryad.5pt92). Camera trap 
images of the LSM dataset are not publicly available to protect endan-
gered  species  from  poaching  but  the  specific  requirements  can  be 
addressed  directly  to  the  corresponding  author  by  interested  third 
parties. 

Acknowledgments 

This study was supported by the National Natural Science Founda-
tion of China (32260131, 31960119, 62262001), the Yunnan Young and 
Middle-aged Academic and Technical Leaders Reserve Talent Project in 
China (202405AC350023), the Project for Talent and Platform of Sci-
ence  and  Technology  in  Yunnan  Province’s  Science  and  Technology 
Department of China (202105AM070008), and Scientific Research Fund 
project  of  Education  Department  of  Yunnan  Province  of  China 
(2024Y850).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the information regarding the data repository link of the deep learning pipeline is not explicitly stated in the given context. However, based on the context, it appears that the ImageNet dataset can be accessed through the URL provided (<https://image-net.org/download.php>). Additionally, camera trap images of the SS dataset can be accessed on Dryad (<https://doi.org/10.5061/dryad.5pt92>). It should be noted that the camera trap images of the LSM dataset are not publicly available due to concerns about protecting endangered species from poaching. Therefore, if you require access to these images, you will need to contact the corresponding author directly.