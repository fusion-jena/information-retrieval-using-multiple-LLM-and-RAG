Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

23. Sutskever I, Vinyals O, Le QV (2014) Sequence to sequence learning with neural
networks. 2014 Advances in Neural Information Processing Systems (NIPS) (Neural
Information Processing Systems Foundation, La Jolla, CA).

24. Cho K, et al. (2014) Learning phrase representations using RNN encoder-decoder for

statistical machine translation. arXiv:1406.1078.

25. He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition.
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (IEEE, New
York).

yellow-billed oxpeckers roosting on their large mammalian hosts. Afr J Ecol.

26. Simonyan K, Zisserman A (2014) Very deep convolutional networks for large-scale

13. Goodfellow I, Bengio Y, Courville A (2016) Deep Learning (MIT Press, Cambridge,

image recognition. arXiv:1409.1556.

MA).

27. Mnih V, et al. (2015) Human-level control through deep reinforcement learning.

Perhaps most importantly, our results show that using deep-
learning technology can save a tremendous amount of time for
biology researchers and the human volunteers that help them
by labeling images. In particular, for animal identiﬁcation, our
system can save 99.3% of the manual labor (>17,000 h) while
performing at the same 96.6% accuracy level of human volun-
teers. This substantial amount of human labor can be redirected
to other important scientiﬁc purposes and also makes knowledge
extraction feasible for camera-trap projects that cannot recruit
large armies of human volunteers. Automating data extraction
can thus dramatically reduce the cost to gather valuable infor-
mation from wild habitats and will thus likely enable, catalyze,
and improve many future studies of animal behavior, ecosystem
dynamics, and wildlife conservation.

Deep learning only works well with lots of labeled data, sig-
niﬁcant computational resources, and modern neural network
architectures. Here, we combine the millions of labeled data
from the SS project, modern supercomputing, and state-of-
the-art deep neural network (DNN) architectures to test how
well deep learning can automate information extraction from
camera-trap images. We ﬁnd that the system is both able to
perform as well as teams of human volunteers on a large frac-
tion of the data and identiﬁes the few images that require
human evaluation. The net result is a system that dramatically
improves our ability to automatically extract valuable knowledge
from camera-trap images. Like every method, deep learning has
biases (discussed below) that must be kept in mind, corrected,
and/or accounted for when using this technology. Swanson et
al., 2016 (14) showed that the citizen-scientist approach also has
its own set of systematic biases, but that they can be adequately

creating labeled datasets of different sizes from SS data. To con-
duct transfer learning, we ﬁrst trained on the ImageNet dataset
(59) and then further trained the network on a small simu-
lated camera-trap dataset. ImageNet has 1.3 million labeled
images for 1,000 categories (from synthetic objects such as bicy-
cles and cars to wildlife categories such as dogs and lions). This

dataset is commonly used in computer vision research, includ-
ing research into transfer learning (32). Training on images from
the real world can be helpful, even if the classes of images
are dissimilar, because many lower-level image features (e.g.,
edge detectors of different orientations, textures, shapes, etc.)
are common across very different types of images (32, 33, 58).

E5722 | www.pnas.org/cgi/doi/10.1073/pnas.1719367115

Norouzzadeh et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit details about the specific data annotation techniques used in the deep learning pipeline. However, it mentions that the study uses "millions of labeled data" and discusses training on the ImageNet dataset, which consists of 1.3 million labeled images for 1,000 categories. These statements suggest that the authors might have employed some form of object detection or classification annotations, such as bounding boxes or class labels, respectively. Additionally, the paper states that the system performs as well as teams of human volunteers, implying that human annotators were involved in creating the labeled dataset. Nevertheless, without more detailed information regarding the nature of these labels, it is impossible to definitively determine the exact data annotation techniques utilized in the deep learning pipeline.