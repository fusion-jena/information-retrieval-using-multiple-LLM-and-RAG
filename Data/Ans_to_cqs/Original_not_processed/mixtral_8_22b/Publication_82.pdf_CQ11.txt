Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5

September 2016 | Volume 7 | Article 1419

Mohanty et al.

Deep Learning for Plant Diseases

30/3 epochs),
• Momentum: 0.9,
• Weight decay: 0.0005,
• Gamma: 0.1,
• Batch size: 24 (in case of GoogLeNet), 100 (in case of AlexNet).

All the above experiments were conducted using our own fork of
Caﬀe (Jia et al., 2014), which is a fast, open source framework for
deep learning. The basic results, such as the overall accuracy can
also be replicated using a standard instance of caﬀe.

RESULTS

representations of

To summarize, we have a total of 60 experimental

conﬁgurations, which vary on the following parameters:

1. Choice of deep learning architecture:

AlexNet,
GoogLeNet.

2. Choice of training mechanism:

Transfer Learning,
Training from Scratch.

3. Choice of dataset type:

Color,
Gray scale,
Leaf Segmented.

4. Choice of training-testing set distribution:

Train: 80%, Test: 20%,
Train: 60%, Test: 40%,
Train: 50%, Test: 50%,
Train: 40%, Test: 60%,
Train: 20%, Test: 80%.

this paper, we have used the notation of

Throughout
Architecture:TrainingMechanism:DatasetType:Train-Test-
Set-Distribution to refer
experiments. For
to particular
instance,
to refer to the experiment using the GoogLeNet
learning
architecture, which was
on the gray-scaled PlantVillage dataset on a train—test
set distribution of
the notation
GoogLeNet:TransferLearning:GrayScale:60–40.

trained using transfer

60–40, we will use

Frontiers in Plant Science | www.frontiersin.org

4

September 2016 | Volume 7 | Article 1419

Mohanty et al.

Deep Learning for Plant Diseases

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The article does not provide information about the specific data repository link of the deep learning pipeline. However, it mentions that all the experiments were conducted using their own fork of Caffe (Jia et al., 2014), which is a fast, open source framework for deep learning. It also states that the basic results, such as the overall accuracy, can be replicated using a standard instance of Caffe. Therefore, one might infer that the authors may have made their code and possibly some datasets available through their GitHub or another platform related to Caffe. To find this information, readers would need to search for the authors' GitHub profiles or other relevant platforms associated with Caffe.