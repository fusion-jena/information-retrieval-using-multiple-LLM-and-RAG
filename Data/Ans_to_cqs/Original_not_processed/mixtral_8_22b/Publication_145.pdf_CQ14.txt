Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

∼

80(cid:176)W70(cid:176)W60(cid:176)W50(cid:176)W40(cid:176)W10(cid:176)S0(cid:176)NBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBrazilian Amazon forestBRAZIL05001000 km(a)01020 kmN62(cid:176)W61.8(cid:176)W61.6(cid:176)W61.4(cid:176)W61.2(cid:176)W61(cid:176)W10.3(cid:176)S10.2(cid:176)S111111111222222222333333333444444444555555555666666666777777777888888888999999999Forest FormationsOther Non Forest Natural FormationAgriculture or PastureWater bodiesregions of interestGeoEye image extents(b)Remote Sens. 2020, 12, 2225

5 of 20

2.3. Forest Cover Mask and Clear-Cut Deforestation History from PRODES

the validation dataset and the model segmented 1195 objects.

×

×

3.7. Algorithm

The model was coded in the programming language R [48] with Rstudio interface to Keras [51,52]
2–20 hours using GPU of an Nvidia
and Tensorﬂow backend [53]. The training of the models took
RTX2080 graphics card with 8 GB of dedicated memory. Prediction using GPU of a single tile of 16,384

∼

16,384 pixels (

∼

×

67.10 km2) took approximately 6 min.

Remote Sens. 2020, 12, 2225

8 of 20

4. Results

as a sum of two terms: binary cross-entropy and Dice coefﬁcient-related loss of the three predicted
masks [50–52]. We used the optimizer RMSprop (unpublished, adaptive learning rate method proposed
by Geoff Hinton here http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
with an initial learning rate of 0.0001. We trained our network for 300 epochs with 24 images per batch.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
According to the given information, it appears that the hyperparameters of the model were not explicitly mentioned to be optimized through methods such as grid search or random search. However, some details about the optimization process can still be inferred.

In the context provided, it is stated that the model uses the optimizer RMSprop with an initial learning rate of 0.0001. This suggests that the learning rate was one of the hyperparameters considered during the optimization process. Furthermore, the model was trained for 300 epochs with 24 images per batch, indicating that the number of epochs and batch size were also taken into account as part of the optimization strategy.

While there isn't explicit mention of specific techniques like grid search or random search being employed, these choices of learning rate, number of epochs, and batch size could have been determined through experimentation or based on prior knowledge and experience. Therefore, although we cannot definitively state how the hyperparameters were optimized, we can infer that they were chosen carefully to achieve optimal performance.