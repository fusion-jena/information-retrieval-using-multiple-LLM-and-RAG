Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3.  Model training 

2.3.1.  Training data preprocessing 

The  CNN  model  used  in  this  study  requires  equally  sized  input 
images. We chose a time-frequency input window size of 2 s as it is near 
the mean and median template duration across target call types (Fig. 2). 
Most  call  types  have  a  duration  below  1  s,  and  for  those  above  2  s,

learning, wherein a model already optimized for a similar dataset is re- 
trained with new data. We used a ResNet50 model, pre-trained on the 
ImageNet dataset, which contains over one million photo images across

Our implementation only included the feature extraction layers of 
ResNet50,  excluding  the  remaining  layers  used  for  ImageNet  classifi-
cation,  referred  to  as  the  network  “top”.  The  network  top  consists  of 
fully  connected  (FC)  layers  for  learning  a  predictive  model  from  the 
input  features.  An  FC  layer  consists  of  a  set  of  nodes,  each  of  which 
takes  a  weighted  sum  of  the  input's  values  and  passes  it  through  a 
transfer function. The weights of an FC layer are learnable. In our case, 
we used two FC layers separated by a drop-out layer. The drop-out layer 

6

J. LeBien, et al.   

Ecological Informatics 59 (2020) 101113

and  stretching  of  target  signals,  and  adding  Gaussian  noise  or  noise 
from soundscapes (Koh et al., 2019; Lasseck, 2019). This competition's 
training  data  consisted  primarily  of  recordings  targeting  single  fore-
ground species, but also a smaller validation set of annotated sounds-
capes  like  those  in  the  test  set.  Results  from  this  challenge  showed  a 
significant  increase  in  performance  for  submissions  that  incorporated 
the validation soundscape data in training (Kahl et al., 2019). Specifi-
cally,  Lasseck  (2019)  found  that  adding  background  noise  from  the 
validation  soundscapes  to  training  samples  significantly  improved 
performance  on  the  test  soundscapes.  This  indicates  that  acoustic 
monitoring  systems  can  benefit  significantly  from  location-specific 
training data.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't explicit information about how the data was split into training, testing, and validation sets for the deep learning model. However, we can infer some general practices based on common machine learning methodologies. Typically, datasets are randomly divided into three subsets: training, validation, and testing. The training set is used to fit the model, while the validation set is used to tune hyperparameters and prevent overfitting. Lastly, the testing set is used to evaluate the final model's performance.

In this specific context, the authors mention using a pre-trained ResNet50 model, which suggests they might have followed transfer learning techniques. They also discuss incorporating additional validation soundscape data during training, indicating that they likely had separate training and validation sets. Unfortunately, without more detailed information, we cannot provide exact percentages or ratios used for splitting their data.