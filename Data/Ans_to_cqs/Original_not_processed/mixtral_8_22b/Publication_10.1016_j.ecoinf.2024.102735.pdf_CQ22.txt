Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The significant parameters tuned to improve model performance are
the kernel function, epsilon, regularization parameter (C), and degree.
The kernel function aids in finding the nonlinear relationships in the
data without explicitly transforming it into a higher-dimensional space,
epsilon determines the width of the margin, C describes the penalty for
margin violation, and degree controls the complexity of the nonlinear
decision boundary (Ghosh et al., 2019).

3.2.3.2. Experimental setup. Objective 1

0.58
0.69
0.71
0.57
0.54
0.58
0.21
0.41

Uncertainty bands were calculated for each ML model based on the
distribution of predictions made for individual test data points. The
prediction distributions were used to estimate the amount of uncertainty
covered for every instant prediction made by each model. These pre-
diction distributions stem from utilizing optimized models developed
through randomized subsets of training data. This strategy emulates the

EcologicalInformatics82(2024)10273512I. Busari et al.

Fig. 10. Uncertainty bands for predictions made using random forest model for (a) RF_w/o_Sensor (b) RF_with_Sensor (c) RF_with_Sensor_cont (d) RF_w/
o_Sensor_cont.

References

Abbaszadeh Shahri, A., Shan, C., Larsson, S., 2022. A novel approach to uncertainty
quantification in groundwater table modeling by automated predictive deep
learning. Nat. Resour. Res. 31 (3), 1351–1373. https://doi.org/10.1007/s11053-
022-10051-w.

Akiba, T., Sano, S., Yanase, T., Ohta, T., Koyama, M., 2019. Optuna: A next-generation
hyperparameter optimization framework. In: Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery \& Data Mining, pp. 2623–2631.
https://doi.org/10.1145/3292500.3330701.

Alarab, I., Prakoonwit, S., Nacer, M.I., 2021. Illustrative discussion of MC-dropout in

general dataset: uncertainty estimation in bitcoin. Neural. Process. Lett. 53 (2),
1001–1011. https://doi.org/10.1007/s11063-021-10424-x.

Lake in upstate South Carolina using machine-learning approaches. J. South
Carolina Water Resour. 9 (1), 1–14.

Busari, I., Sahoo, D., Jana, R.B., 2024. Prediction of chlorophyll-a as an indicator of
harmful algal blooms using deep learning with Bayesian approximation for
uncertainty assessment. J. Hydrol. 630, 130627.

Cen, H., Jiang, J., Han, G., Lin, X., Liu, Y., Jia, X., Ji, Q., Li, B., 2022. Applying deep

learning in the prediction of chlorophyll-a in the East China Sea. In: Remote Sensing
(Vol. 14, Issue 21). https://doi.org/10.3390/rs14215461.

Cunningham, P., Delany, S.J., 2021. K-nearest neighbour classifiers-a tutorial. ACM

Comput. Surv. 54 (6) https://doi.org/10.1145/3459665.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no explicit mention of specific evaluation metrics used to assess the performance of the deep learning model. However, common metrics used in evaluating deep learning models include accuracy, precision, recall, F1 score, ROC curve, and area under the curve (AUC). Accuracy measures the proportion of correct predictions out of total instances; precision indicates the ratio of true positive predictions to all predicted positives; recall shows the fraction of relevant instances retrieved among all relevant instances; F1 score combines both precision and recall; ROC curve plots true positive rate against false positive rate; and AUC represents the probability that a randomly chosen positive instance will have a higher predicted value than a randomly chosen negative one. It is important to note that the choice of evaluation metric depends on the problem type and requirements.