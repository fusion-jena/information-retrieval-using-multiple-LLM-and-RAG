Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

to three dental variables and two climate variables. In the second run, 
we allowed dental queries to involve disjunctions, and climate queries to 
contain up to three variables, but tightened the requirement of accuracy 
gain.  Specifically,  under  this  constraint,  a  candidate  query  can  be 
extended by automatically adding the next variable only if the accuracy, 
as measured by the Jaccard coefficient, increases by a least 0.1. The goal 
is to obtain interpretable, not overly complex (long) queries. This can be 
achieved either explicitly, by limiting the number of variables and the 
operators  used  in  the  queries,  as  in  the  first  run,  or  implicitly,  by 
allowing increased complexity only if it brings substantial improvement 
in terms of accuracy, as in the second run. 

4.3. Selecting individual redescriptions for further analyses

The method requires manually setting several parameters, described 
in more details in the user guide.7 In particular, about half a dozen pa-
rameters allow to set thresholds on the size of the support of the output 
redescriptions and to control the length and complexity of their queries. 
We required that at least 1% of localities satisfy both queries (Min-
SuppIn) and that at least 30% of localities satisfy neither of the queries 
(MinSuppOut). In other words, the intersection of the supports of the 
two  queries  (the  support  of  the  redescription)  and  their  union  were 
required to contain at least 1% and at most 70% of all localities. This is 
an inclusive choice, not overly restrictive, that aims at capturing local 
patterns. Increasing the upper threshold further would jeopardize the 
local aspect of the analysis, and would lead to something more akin to 
non-linear regression. For a redescription to be informative, its support

The  first  run,  with  strict  explicit  constraints,  generated  271  re-
descriptions while the second run, with stringent threshold on accuracy 
gains,  generated  188  redescriptions.  Either  run  took  about 50  min  to 
complete on a commodity laptop. 

We filter the two collections separately, ranking the redescriptions 
by  decreasing  accuracy  and  removing  any  redescription  having  more 
than 90% of its support in common with a higher-ranked one. That is, a 
redescription Rx is removed from the set of results if it contains a more 
accurate redescription Ry such that 
(cid:0)

⃒
⃒supp(Rx) ∩ supp
(cid:0) ⃒
⃒supp(Rx) |,|supp

)⃒
⃒
)

Ry
(cid:0)

Ry

min

) > 0.9.

|

EcologicalInformatics63(2021)1013149E. Galbrun et al.                                                                                                                                                                                                                                

Fig.  6. Focus  maps  of  example  redescriptions.  Lo-
calities  that  support  both  queries,  only  the  dental 
trait query and only the climate query, are drawn in 
purple,  in  red  and  in  blue,  respectively.  For  each 
redescription,  we  list  the  query  over  dental  traits 
variables  (qD),  the  query  over  bioclimatic  variables 
(qC), the accuracy of the redescription (J) as well as 
the  size  of  its  support  as  a  percentage  of  the  total 
number of localities (supp %). (For interpretation of 
the  references  to  colour  in  this  figure  legend,  the 
reader is referred to the web version of this article.)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not provide information regarding the collection of raw data in the deep learning pipeline. Therefore, I cannot provide a helpful response based solely on the provided context.