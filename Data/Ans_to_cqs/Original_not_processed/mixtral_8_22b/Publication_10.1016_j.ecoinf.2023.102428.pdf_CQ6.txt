Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 7 
MLP parameters and performance.  

S/N 

1. 
2. 
3. 
4. 
5. 
6. 
7. 
8. 
9. 
10. 
11. 
12. 
13. 
14 

Variables 

Input layer neurons 
Hidden layer nodes 
Output layer neurons 
Requested samples per class 
Start learning rate 
End learning rate 
Momentum factor 
Sigmoid constant 
Iterations 
Acceptable RMS 
Training RMS 
Testing RMS 
Accuracy Rate 
Skill measure (%) 

Results 

8 
10 
8 
1688 
0.0008 
0.0001 
0.5 
1.0 
10,000 
0.01 
0.1430 
0.1446 
88.79% 
0.8719

2.5. Model description 

2.5.1. MLPnn-MC modelling 

MLPnn-MC  modelling  integrates  the  multi-layer  perceptron  (MLP) 
algorithm  and  Markov  chain,  which  unravels  robust  future  LULC 
simulation (Gebresellase et al., 2023; Nasiri et al., 2019). The novelty of 
this model lies in the fact that it utilises deep machine learning to learn 
the model in automated mode in less calibration time through complex, 
multivariate, and non-linear relationships to create several transitions 
and predict unseen data within the model at a single time by compre-
hending the hidden relationships (Kumar and Agrawal, 2023). MLP is 
the  most  prevalent  machine  learning  algorithm  in  ANN  (Artificial 
Neural Network) modelling (Alla et al., 2021; Band et al., 2020), which 
uses  back  propagation  (BP)  or  the  reverse  method  of  automatic

2.4. LULC classification and accuracy assessment

each layer is a neuron that operates on non-linear activation function, 
such as  sigmoid. These  neurons are  organised in such a way that the 
networks are directed only from lower to upper layers, and the neurons 
within  the  same  layer  are  independent.  Input  data  is  provided  to  the 
input node, processed through the hidden layers in an iterative manner, 
and  the  output  layer  provides  the  pattern  classification.  The  Markov 

EcologicalInformatics79(2024)1024284P. Verma et al.                                                                                                                                                                                                                                  

Table 1 
Raster and supplementary data information used in the study.  

S. No. 

Data type 

Source 

Date Acquired (yyyy/mm/dd) 

Path and rows 

Resolution 

Columns and rows 

Bands 

USGS Earth Explorer 
USGS Earth Explorer 
USGS Earth Explorer

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, various preprocessing steps can be applied to improve its performance. Some common preprocessing techniques include:

1. Normalization: This involves rescaling input features so they fall within a specific range, typically between 0 and 1 or -1 and 1. Normalization helps prevent certain features with larger magnitudes from dominating the learning process.

2. Scaling: Similar to normalization, scaling also adjusts feature values but does not necessarily restrict them to a fixed range. Common methods for scaling include standardizing (subtracting the mean and dividing by the standard deviation) and min-max scaling (rescaling features to lie between 0 and 1).

3. Cleaning: Data cleaning involves identifying and handling missing, inconsistent, or erroneous data points. Techniques for dealing with these issues may include removing problematic instances, imputing missing values using statistical measures like mean or median, or employing more advanced algorithms like KNN or regression models.

4. Feature engineering: This step involves creating new features based on existing ones to better capture underlying patterns in the data. Examples include polynomial expansion, binning, and encoding categorical variables into numerical representations.

5. Dimensionality reduction: In cases where high-dimensional datasets pose computational challenges or lead to overfitting, dimensionality reduction techniques like Principal Component Analysis (PCA) or t-distributed Stochastic Neighbor Embedding (t-SNE) can help reduce the number of input features while preserving essential information.