Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

processing instructions can be found in Text S1. The final available data 
elements totaled 6802.

Machine learning methods require text preprocessing, such as word 
segmentation and stop word removal, followed by the selection of a text 
portion to manually annotate emotions for accuracy verification. Among 
machine  learning  models,  the  enhanced  representation  through 
knowledge  integration  (ERNIE)  model  achieved  significant  results  in 
previous studies by learning prior semantic relationships and word order 
features from massive amounts of data (Sun et al., 2019). The ERNIE 
model  directly  models  prior  semantic  knowledge  units,  thereby 
enhancing model semantic representation (Wang et al., 2020). Test re-
sults for various Chinese tasks showed that the model performed better 
than  the  bidirectional  encoder  representations  from  the  transformer 
model proposed by Google AI (Sun et al., 2019). At the International 
Workshop on Semantic Evaluation 2020, the ERNIE model earned first 
place  for  a  mixed-language  emotional  analysis  task.  Detailed  de-

⎛

P(D) = exp

⎜
⎜
⎜
⎝

∑M

d=1

(cid:0)

⎞

⎟
⎟
⎟
⎠

logDp(wd)

∑M

d=1

Nd

∑M

d=1

p(θkd)

M

Sk =

(1)  

(2)  

where P(D) represents perplexity, D represents the test set in the corpus, 
M represents the number of texts, Nd  represents the number of words in 
text  d,  wd  represents  the  words  in  text  d,  and  p(wd) represents  the 
probability of the occurrence of the word wd  in text d. Sk  represents the 
intensity of the kth topic, and p(θkd) represents the probability of topic k 
appearing in text d. We used Python’s pyLDAvis Library to cluster and 
visualize  topics  in  tweets  involving  contaminated  sites.  The  pyLDAvis 
interface  displays  the  ranking  of  keywords  related  to  each  topic,  for 
which relevance was determined by λ  and could be adjusted between 
0 and 1. The setting λ = 1 indicates ranking themes by frequency, and 
the setting λ = 0 indicates ranking themes based on uniqueness. 

2.2.2. Social network analysis

Table 1 
First 30 high-frequency and unique topic words for different topics and topic 
intensities in the study areas.  

Topic 
number 

Theme 
word type 

Top 30 theme words 

Topic content 

Topic 
intensity 

1 

2 

3 

4 

5

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the machine learning model has been trained using techniques like word segmentation, stop word removal, and emotion annotation, there are several postprocessing steps that can be taken to evaluate its performance and understand its predictions. Some common postprocessing steps include:

1. Saliency Maps: These visualizations highlight which parts of the input data were most important in making a prediction. They can help identify if the model is focusing on relevant features or if it might be biased towards certain inputs.

2. Metrics Calculation: Various metrics can be calculated to assess the model's performance, including accuracy, precision, recall, F1 score, and area under the ROC curve (AUC-ROC). These metrics provide insights into how well the model generalizes to new data and whether it is prone to overfitting or underfitting.

3. Confusion Matrix: This table summarizes the predicted and actual classifications made by the model. It helps identify where the model tends to make mistakes and provides insight into potential sources of bias or imbalance in the dataset.

4. Model Interpretation: Techniques like LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) can be used to explain individual predictions made by the model. These explanations can help build trust in the model and ensure that it is behaving as intended.

In summary, postprocessing steps after model training involve evaluating the model's performance, understanding its predictions, and ensuring that it is behaving as expected. Common techniques include saliency maps, metrics calculation, confusion matrices, and model interpretation tools.