Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

as a sum of two terms: binary cross-entropy and Dice coefﬁcient-related loss of the three predicted
masks [50–52]. We used the optimizer RMSprop (unpublished, adaptive learning rate method proposed
by Geoff Hinton here http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
with an initial learning rate of 0.0001. We trained our network for 300 epochs with 24 images per batch.

ability to identify features in large amounts of data, including very high-resolution imagery, achieving
accuracy similar to human-level classiﬁcation accuracy, but in a consistent and fast way, enabling
rapid application over very large areas and/or through time [14]. For example, individual tree species
mapping in tropical forests, that was in the past only possible on small scale with traditional machine
learning methods [15,16] is now feasible on a large scale (>5000 km2) with a deep learning method
called U-net [17–20].

the validation dataset and the model segmented 1195 objects.

×

×

3.7. Algorithm

The model was coded in the programming language R [48] with Rstudio interface to Keras [51,52]
2–20 hours using GPU of an Nvidia
and Tensorﬂow backend [53]. The training of the models took
RTX2080 graphics card with 8 GB of dedicated memory. Prediction using GPU of a single tile of 16,384

∼

16,384 pixels (

∼

×

67.10 km2) took approximately 6 min.

Remote Sens. 2020, 12, 2225

8 of 20

4. Results

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the authors use the RMSprop optimizer, which is an unpublished, adaptive learning rate method proposed by Geoff Hinton. This optimizer is not commonly known like Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam), but it has been shown to be effective in certain applications. The initial learning rate used was 0.0001, and the network was trained for 300 epochs with 24 images per batch. The implementation was done in the programming language R with RStudio interface to Keras and TensorFlow backend. Training took between 2-20 hours using a GPU from an Nvidia RTX2080 graphics card with 8GB of dedicated memory.