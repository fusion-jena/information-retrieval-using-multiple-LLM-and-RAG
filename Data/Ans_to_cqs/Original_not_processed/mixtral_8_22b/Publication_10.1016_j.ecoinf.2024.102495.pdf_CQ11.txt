Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

10 

20/40/60/80 

20/40/60 

11 

20/40/60/80 

20/40/60 

128 
128 
128 
128 
128 
128 
64 
256 
512 
64/256/ 
512 
64/256/ 
512 

1024 
1024 
1024 
1024 
1024 
1024 
1024 
1024 
1024 

512 

2048  

Table 3 
Combination  of  the  convolutional  neural  network  deep  learning  model 
parameters.  

No 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 

Model 

Optimizer 

Learning Rate 

Without Dropout 

With Dropout 

RMSProp 

Adam 

SGD 

RMSProp 

Adam 

SGD 

0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01  

EcologicalInformatics80(2024)1024958E. Joelianto et al.                                                                                                                                                                                                                               

Fig. 8. Performance test of each configuration.  

Table 4 
The standard deviation values for each performance metric.  

Configurations 

Accuracy 
(%) 

Precision 
(%)

Fig. 6. Feature extraction flowchart.  

EcologicalInformatics80(2024)1024957E. Joelianto et al.                                                                                                                                                                                                                               

of the FFT window, 1024. The feature extraction parameters that yielded 
the best performance were employed during the feature extraction phase 
in optimizing the CNN deep learning model. The results of model opti-
mization  were  acquired  by  employing  identical  performance  metrics 
used in optimizing the feature extraction parameters (Fig. 13).

Length of the FFT window: 512, 1024, and 2048. 
The spectrogram log form, normalized to the range of (cid:0) 80 to 0 dB, 
was obtained by changing the value on the Mel spectrogram. The results 
of feature extraction were obtained using a spectrogram log in the form 
of an array with dimensions of 1 × bands × frames as the input for CNN 
model training (Fernandes et al., 2021).

2.2.3. Deep learning 

Once transformed into a matrix or vector, the results of voice feature 
extraction serve as the input for a deep learning algorithm. This algo-
rithm discerns patterns within the data, enabling it to make predictions 
based on these learned patterns, all without the need for explicit pro-
gramming (França et al., 2021; Navamani, 2019). A critical distinction 
between deep learning and traditional machine learning is the feature- 
extraction  process  during  classification.  Feature  extraction  from  data 
typically requires manual or human intervention in traditional machine 
learning.  Contrastingly,  deep  learning  models  are  designed  to  auto-
matically perform feature extraction.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention of any specific data repository links related to the deep learning pipeline used in this study. Therefore, I cannot provide the requested information.