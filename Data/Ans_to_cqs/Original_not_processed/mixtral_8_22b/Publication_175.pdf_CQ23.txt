Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Comput. Vis. 211–252. 

Salman, A., et al., 2016. Oceanography : Methods Fish Species Classification in 

Unconstrained Underwater Environments Based on Deep Learning, pp. 570–585. 

Shiu, Y., et al., 2020. Deep Neural Networks For Automated Detection of Marine 

Mammal Species, pp. 1–12. 

Stuart-smith, R.D., et al., 2013. Integrating abundance and functional traits reveals new 

global hotspots of fish diversity. Nature 501 (7468), 539–542. 

Sun, Q., Chua, Y.L.T., 2018. Meta-transfer learning for few-shot learning. Conf. Comput. 

Vis. Pattern Recognit. 403–412.

1)  We  trained  a  classic  DL  algorithms  architecture  with  our  biggest 

dataset AT0 as a baseline for the DL accuracy;  

2)  We  trained  the  same  DL  architecture  with  the  same  hyper- 
parameters (e.g. model architecture and training process) but on a 
much  more  limited  dataset  (AT1).  Hyper-parameters  are  the  pa-
rameters  defining  the  architecture (number of  layers, number and 
size of convolutions, connections between layers) and the training 
process  of  a  Deep  Model  (learning  rate,  neurone  activation,  back- 
propagation compotation).;  

3)  We trained the same DL architecture with limited datasets obtained 
by  subsampling  T0  to  250  and  500  images  per  class  (here  after 
“species” when we are referring to our experiments), corresponding 
to 2500 and 5000 thumbnails in AT0;

a new task with a very limited dataset, usually only 1–5 thumbnails per 
class.

3. Results 

The  deep  ResNet  model  trained  on  the  large  AT0  dataset  (3458 
natural thumbnails in average per species) during the first experiment 
obtained a mean accuracy (i.e. percentage of correct classification) of 
78.00%  (standard  deviation  (SD)  of  15.16%)  on  T2  test-dataset 
(Table  2).  With  this  model,  accuracy  varied  among  species  between 
54.14% (Naso brevirostris) and 99.07% (Abudefduf vagiensis). The same 

EcologicalInformatics63(2021)1013203S. Villon et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of their deep learning model, several measures were taken by the authors. Firstly, they used diverse datasets for training and testing purposes. They utilized two main datasets, namely AT0 and AT1, where AT0 was significantly larger than AT1. This allowed them to evaluate the performance of the model under different data availability scenarios. Additionally, they created smaller subsets from the original dataset by randomly selecting 250 or 500 images per class, further demonstrating the robustness of the model across various dataset sizes.

Moreover, the authors employed stratified sampling techniques while creating these subsets. Stratified sampling ensures that each subset maintains the same distribution of classes as the original dataset, which is crucial for maintaining the representativeness of the sample population. By using stratified sampling, the authors ensured that the model would be exposed to a balanced representation of all classes during training, thus improving its ability to generalize well to unseen data.

Furthermore, the authors conducted multiple experiments using different architectures and hyperparameters. In one such experiment, they trained a classic deep learning algorithm architecture with the largest dataset, AT0, serving as a baseline for evaluating the accuracy of the deep learning models. Subsequently, they maintained the same architecture and hyperparameters but trained it on a much more limited dataset, AT1. This approach helped assess how well the model could adapt to varying amounts of available data without compromising its overall performance.

Lastly, the authors evaluated the performance of their deep learning model using a separate test dataset, T2. This step is essential for validating the model's ability to generalize to previously unseen data accurately. Overall, these measures collectively contributed towards ensuring the generalizability of the deep learning model developed by the authors.