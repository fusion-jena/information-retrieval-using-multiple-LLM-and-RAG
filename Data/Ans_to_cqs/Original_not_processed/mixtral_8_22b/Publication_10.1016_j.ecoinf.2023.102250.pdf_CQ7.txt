Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Dataset 

MobileNetV2 

ResNet18 

VGG16 

Ori 
G1_Dataset1 
G1_Dataset2 
G1_Dataset3 
G1_Dataset4 
G1_Dataset5 
G2_Dataset1 
G2_Dataset2 
G2_Dataset3 
G2_Dataset4 
G3_Dataset1 
G3_Dataset2 
G3_Dataset3 
G3_Dataset1_mixup 
G3_Dataset2_mixup 
G3_Dataset3_mixup 
Ori 
G1_Dataset1 
G1_Dataset2 
G1_Dataset3 
G1_Dataset4 
G1_Dataset5 
G2_Dataset1 
G2_Dataset2 
G2_Dataset3 
G2_Dataset4 
G3_Dataset1 
G3_Dataset2 
G3_Dataset3 
G3_Dataset1_mixup 
G3_Dataset2_mixup 
G3_Dataset3_mixup 
Ori 
G1_Dataset1 
G1_Dataset2 
G1_Dataset3 
G1_Dataset4 
G1_Dataset5 
G2_Dataset1 
G2_Dataset2 
G2_Dataset3 
G2_Dataset4 
G3_Dataset1 
G3_Dataset2 
G3_Dataset3 
G3_Dataset1_mixup 
G3_Dataset2_mixup 
G3_Dataset3_mixup 

Recall

Operations 

spectral normalization 
spectral normalization 
spectral normalization 
spectral normalization 
spectral normalization  
spectral normalization  

Activation 

LeakyReLU 
LeakyReLU 
LeakyReLU 
LeakyReLU 

Output size 

(16,256,256) 
(32,128,128) 
(64,64,64) 
(128,32,32) 
(128*32*32,1) 
(128*32*32,17)  

number of convolutional weights by a factor of K, resulting in a lack of 
compactness  in  the  model.  Secondly,  jointly  optimizing  dynamic 
attention and static convolutional kernels becomes a challenging task. 
To address these issues, Li proposed the dynamic convolutional kernel 
decomposition in 2021 (Li et al., 2021). This approach effectively re-
duces the number of parameters in dynamic convolution and improves 
the classification performance of neural networks that utilize dynamic 
convolutional kernels. 

In (Li et al., 2021), the static convolution kernel can be re-defining by 

the formula 9. 

Wk = W0 + ΔWk, k ∈ {1, …, K}

(9)  

∑

iii.  Experimental group III: Take 40%, 60%, and 80% of the original 
dataset as the new dataset, and then replace 80% of these three 
datasets with the generated images. 

Table 6 presents the detailed division of the datasets. The datasets 
were  split  into  train  and  test  sets  in  an  8:2  ratio,  and  all  evaluation 
metrics were computed on the test set. 

To conduct the classification experiments on all datasets, we utilized 
ResNet18, VGG16, and MobileNetV2 as the base classifier model. The 
experiments  were  conducted  with  consistent  hyperparameters, 
including a learning rate of 0.001, a batch size of 32, and 40 epochs. 

The  classification  results  of  Experiment  Group  I  are  presented  in 
Fig.  10.  The  bar  graphs  represent  the  Top-1  accuracy  of  the  Mobile-
NetV2, ResNet18, and VGG16 models on the six datasets. The fold line 
corresponds to their respective Top-5 accuracy. When 1000 generated

Table 9 
Comparison of classification results of adding dynamic convolutional decomposition model on different models.  

Network 

MobileNetV2 

MobileNetV2_DCD 

ResNet18 

ResNet18_DCD 

VGG16 

VGG16_DCD 

Dataset 

Ori 
G1_Dataset5 
G2_Dataset4 
Ori 
G1_Dataset5 
G2_Dataset4 
Ori 
G1_Dataset5 
G2_Dataset4 
Ori 
G1_Dataset5 
G2_Dataset4 
Ori 
G1_Dataset5 
G2_Dataset4 
Ori 
G1_Dataset5 
G2_Dataset4 

Recall 

87.75% 
95.21% 
93.48% 
90.23% 
96.42% 
95.76% 
91.14% 
95.78% 
95.37% 
92.41% 
96.23% 
96.09% 
94.63% 
97.27% 
96.87% 
95.27% 
97.58% 
97.13% 

Precision 

F1-score 

Accuracy 

Top-1 error 

Top-5 error 

88.91% 
95.46% 
93.36% 
91.01% 
96.62% 
95.94% 
91.47% 
96.00% 
96.21% 
93.26% 
96.36% 
96.57% 
95.26% 
97.39% 
97.17% 
95.71% 
97.65% 
97.47% 

88.11% 
95.32% 
93.39% 
90.19% 
96.50% 
95.82% 
91.25% 
95.87% 
95.95% 
92.78% 
96.28% 
96.31% 
94.90% 
97.32% 
96.96% 
95.46% 
97.61% 
97.29%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The datasets were split into train and test sets in an 8:2 ratio. All evaluation metrics were computed on the test set. To conduct the classification experiments on all datasets, ResNet18, VGG16, and MobileNetV2 were utilized as the base classifier model. The experiments were conducted with consistent hyperparameters, including a learning rate of 0.001, a batch size of 32, and 40 epochs.