Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 3. CNN Architecture.

No.

Layers

Output Shape

Parameters

Dropout Rate

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Dropout
Flatten
Fully Connected
Activation (ReLu)
Fully Connected
Activation (softmax)

128 × 128 × 3
128 × 128 × 32
—
64 × 64 × 32
64 × 64 × 32
—
32 × 32 × 32
32 × 32 × 64
—
16 × 16 × 64
16 × 16 × 64
16,384
64
—
4
—

—
896
—
—
9248
—
—
18,496
—
—
—
—
1,048,640
—
—
260

—
—
—
—
—
—
—
—
—
—
0.4
—
—
—
—
—

4.2.1. Data Augmentation

9730
8440
9124
10,480

The considered dataset is further divided into three datasets, resulting in 22,666 images
for training the model (training set), 7554 images for validating the trained model (valida-
tion set), and 7554 images for assessing the model performance (testing set).

To obtain this dataset, a semantic segmentation is conducted using our previous
works [51–53]. The four classes—namely, urban, bare soil, vegetation and road—are
extracted from the satellite images, meaning that the resulting images each contain both
the real value of pixels of the extracted class and zero for the values of the other classes.
Then, each image containing a given class is divided into non-overlapping blocks of
256 × 256 pixels and saved into folders, each with the name of the corresponding class. A
sample of this dataset is depicted in Figure 4, wherein the white represents a given land
cover class and the black represents the values of other classes.

5.2. Experimental Set-Up

Remote Sens. 2021, 13, 2221

18 of 26

Figure 6. Sample image data augmentation. (a) Rotation results; (b) Zoom results; (c) Shearing results; (d) Horizontal shift
results; (e) Vertical shift results; (f) brightness results; (g) Horizontal ﬂip results; (h) Vertical ﬂip results.

Remote Sens. 2021, 13, 2221

19 of 26

Figure 7. Model accuracy over plain data. (a) Training accuracy; (b) Validation accuracy.

Figure 8. Model accuracy over encrypted data. (a) Training accuracy; (b) Validation accuracy.

except for the ﬁrst and last modules. The FC layer is replaced with a global average
POOL layer and the default input size is 299 × 299 × 3 [25].
DenseNet121: Huang et al. (2017) proposed the architecture of the DenseNet121 model,
another CNN-based architecture trained on the ImageNet dataset. DenseNet121 is
composed of 5 dense blocks. The ﬁrst block consists of a convolution layer with
a 7 × 7 ﬁlter and stride of 2 and a MaxPooling layer with a 3 × 3 max ﬁlter and
stride of 2. The remaining blocks consist of BatchNormalization, the ReLU activation
function, and two CONV layers with 1 × 1 and 3 × 3 ﬁlters. A transition layer follows
each block except for the last, which instead is followed by a classiﬁcation layer. In
DenseNet121, all previous feature-maps are used as input in each layer. The default
input size is 224 × 224 × 3 [26].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, there is no explicit mention of specific data annotation techniques such as bounding box annotation or instance segmentation. However, it does discuss a form of semantic segmentation applied to extract four classes - urban, bare soil, vegetation, and road - from satellite images. This process involves assigning labels to individual pixels based on their respective classes, effectively creating pixel-wise masks for each class. While not explicitly mentioned, this could be seen as a type of data annotation technique within the deep learning pipeline.

It should also be noted that the context mentions dividing these labeled images into non-overlapping blocks of 256 x 256 pixels, which can be interpreted as another step in preparing the dataset for use in the deep learning pipeline. Although this isn't directly related to data annotation techniques like bounding boxes or instance segmentation, it still plays a crucial role in organizing and structuring the dataset for efficient processing during model training.