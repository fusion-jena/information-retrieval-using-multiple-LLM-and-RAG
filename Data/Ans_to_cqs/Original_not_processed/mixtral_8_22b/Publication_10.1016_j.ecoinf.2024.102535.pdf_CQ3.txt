Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2019;  Simon-Lled´o  et  al.,  2019a;  Taylor  et  al.,  2017).  Nevertheless, 
manual annotation of seabed images is costly and biased due to operator 
subjectivity and self-learning when annotating large datasets (Schoen-
ing et al., 2016; Schoening et al., 2017a). Those limitations led to the 
emergence  of  a  scientific  community  dedicated  to  devising  computer 
tools  capable  of  automatically  analyzing  the  related,  ever-increasing 
volume of data.

Cromwell, M., Butler, E., Woodward, B., et al., 2022. Fathomnet: a global image 
database for enabling artificial intelligence in the ocean. Sci. Rep. 12, 1–14. 

marine image annotation: lessons learned and future directions. Front. Mar. Sci. 3, 
59. 

Kim, H., Loh, W.Y., 2001. Classification trees with unbiased multiway splits. J. Am. Stat. 

Assoc. 96, 589–604. 

Kingma, D.P., 2017. Variational Inference & Deep Learning: A New Synthesis. PhD 

Thesis, pp. 1–162. 

Langmuir, C., Jean-Luc, Charlou, Colodner, D., Daniel, Desbruyeres, Desonie, D., 
Emerson, T., Fornari, D., Yves, Fouquet, Humphris, S., Fiala-Medioni, A., 
Saldanha, L., Sours-Page, R., Thatcher, M., Tivey, M.K., Van Dover, C., von 
Damm, K., Wiese, K., Wilson, C., 1993. Lucky strike - a newly discovered 
hydrothermal site on the Azores platform. RIDGE Events 4, 3–5. URL: https://arch 
imer.ifremer.fr/doc/00070/18096/. 

Schoening, T., Durden, J., Preuss, I., Branzan Albu, A., Purser, A., De Smet, B.,

The batch size was 32, and the early stopping procedure was used to 
avoid over-fitting. The patience parameter, which controls the number 
of epochs without improvements in the validation loss, was set to 10. 
Each network, with a particular architecture and considering a specific 
substratum characterization, was trained and executed three times, each 
time with a different (random) initialization of the trainable parameters 
and with a different data fold. As already mentioned, the results shown 
in  the  next  section  are  averages  of  those  three  executions.  Data 
augmentation was applied to all extracted patches: a 90∘  rotation and 
vertical and horizontal flips. 

4.4. Performance metrics

Variants  of  the  VGG  network  have  demonstrated  that  increasing 
network  depth  can  improve  classification  accuracy  by  enabling  the 
learning  of  semantically  enriched  features.  In  the  present  work,  we 
adopted a particular architecture inspired by VGG that has 14 layers (13 
convolutional  and  one  dense  layer).  A  detailed  description  of  the  ar-
chitecture implemented in this work can be found in Section 7. 

3.2. ResNet

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In the given context, there isn't explicit information about the specific data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, it does mention manual annotation of seabed images, which could potentially involve various annotation methods depending on the task requirements.

Manual annotation involves human experts labeling the data, often using tools like bounding boxes, polygons, or pixel-wise masks to identify objects or regions of interest within images. This process can be time-consuming and subjective, leading to potential inconsistencies between annotators.

While not explicitly stated, the use of Convolutional Neural Networks (CNNs), specifically variants of the VGG network, suggests that the dataset may consist of labeled images used for object recognition tasks. CNNs are commonly employed for image classification, detection, and segmentation tasks, requiring appropriate annotations based on the problem at hand.

Given the lack of concrete details regarding the specific annotation techniques used in the deep learning pipeline, it would be speculative to provide further insights into the exact methodologies utilized. Nonetheless, it is reasonable to infer that some form of manual annotation was involved in preparing the dataset for training and evaluating the deep learning models discussed in the context.