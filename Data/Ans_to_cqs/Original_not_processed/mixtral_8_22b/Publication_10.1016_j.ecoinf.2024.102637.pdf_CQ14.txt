Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

related fields, and lays the foundation for future model optimisation and 
performance improvement.

Aʹ(x) = (1 (cid:0) λ)A(x) + λ(x)

(10)  

where,  λ  is  a  hyperparameter  used  to  adjust  the  balance  relationship 
between the nonlinear factors of the activation function and the identity 
mapping of Aʹ(x) based on the number of training iterations, which can 
be expressed as λ = e
E. Here, e represents the current number of rounds of 
training and E represents the total number of rounds of model training. 
→0, and Aʹ(x)→A(x). At this point, a strong 
nonlinear  factor  exists  between  the  two  convolutional  layers  of  the 
network, which can achieve better training of the model. When e→E, 
λ→1, and Aʹ(x)→x. Nonlinear factors are gradually integrated into the 

Starting training, λ = e
E

The  evaluation  indicators  of  the  experiment  mainly  included  the 
testing accuracy, inference time, precision, recall, specificity, F1 score, 
and sensitivity. In the experiment, the batch size was set to 16, and the 
learning rate was 0.00005, which was optimised using the Adam opti-
miser. For the AlexNet and SIAlex models, the number of epochs was set 
as 200. A cross-entropy loss function was adopted the cross entropy loss 
function. 

Table 2 
The Birdsdata dataset collected 20 types of bird sounds both indoors and out-
doors in the form of actual collection and network collection.  

Types of birds 

Number of 
samples 

Types of birds 

Number of 
samples

}

{

x, x ≥ 0
ax, x < 0

(12)  

where, x represents the input data and a represents the hyperparameter 
of the activation function. 

To further enhance the nonlinear expression ability of the model, an 
innovative method of cascading activation functions (Chen et al., 2023; 
Mhaskar and Poggio, 2016) is adopted. The method enables the model to 
exhibit  richer  and  deeper  nonlinear  characteristics  when  processing 
complex data using multiple cascading activation functions (Eldan and 
Shamir,  2016).  Using  this  optimisation  strategy,  we  can  effectively 
improve the performance of the model and provide powerful tools for 
solving various complex practical problems.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, it appears that the optimization of the hyperparameters of the model is not explicitly mentioned or described in detail. However, there are some clues about how certain hyperparameters might be adjusted during the training process.

For instance, the value of the hyperparameter lambda (λ), which is used to control the balance between the nonlinear factors of the activation function and the identity mapping of A'(x), is determined by the ratio of the current number of training rounds (e) to the total number of training rounds (E). This suggests that the value of lambda changes dynamically throughout the training process, rather than being fixed beforehand through methods such as grid search or random search.

Additionally, the learning rate of the model is set to 0.00005, but it is unclear whether this value was chosen arbitrarily or through some sort of optimization technique. Similarly, the batch size is set to 16 without any explanation of why this particular value was selected.

Overall, while the text does mention some aspects of the model's design and implementation, it does not provide enough information to determine exactly how the hyperparameters were optimized.