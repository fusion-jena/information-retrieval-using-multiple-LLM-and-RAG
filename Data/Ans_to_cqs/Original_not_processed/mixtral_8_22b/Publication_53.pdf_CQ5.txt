Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We trained our deep learning CNN on 7362 labelled images using the same parameters
detailed above, and we achieved an error rate of 0.1195 (11.95%) with a training loss of
0.3462 and a validation loss of 0.2847. We further ﬁne-tuned the model by unfreezing the
entire model and training at a 10-fold lower learning rate (10−4). The ﬁnal model achieved
an accuracy of 94.8% (error rate of 5.2%) with a training loss of 0.1397 and a validation loss
of 0.1446 with ten epochs (see confusion matrix in Figure S1).

2.2.2. Correcting for False Positives

Locations falsely classiﬁed as containing a dam (i.e., false positives, or commission
error) act to overpredict the real number of dams in Australia. Therefore, we calculated
the probability of false positives by using our deep learning CNN to analyse and validate
ca. 2000 dams in each State and Territory sampled from our compiled database. To do so,

Remote Sens. 2021, 13, 319

4 of 15

To avoid manual labelling of all 7362 downloaded images, we took a random subsam-
ple of 400 images and labelled them into “dam” or “not dam” and we trained a classiﬁcation
model on the labelled data. We utilised transfer learning by initialising an ImageNet pre-
trained ResNet34 model [30]. We applied an 80–20% split for training and validation
datasets, respectively. To help generalise the model, we used data augmentation with the
fastai get_transforms function [30] and the following arguments: “ﬂip_vert = TRUE” to
allow for vertical ﬂipping of images, “max_lighting = 0.02” to limit overly exposing the
images, “max_zoom = 1” to disable the zooming augmentation, and “to_fp16 = TRUE” to
reduce the memory load on the graphical processing unit (GPU). We set the batch size to
300 images and trained the model with a learning rate of 10−3 for ten epochs. At epoch 5,
we achieved an error rate of 0.1538 (15.38%) a validation loss of 0.4211 and a training loss

2.4. Statistical Analyses

We used Python [35] and fastai [30] for developing the deep learning CNN. We used
R [36] for all statistical analyses, using packages sf [37] and raster [38] for data manipulation;
ggplot2 [39], rasterVis [40] and cowplot [41] for plotting. We also used R for designing
the website AusDams.org, using Shiny [42], Leaﬂet [43], Plotly [44] and using Joe Cheng’s
Superzip template (https://shiny.rstudio.com/gallery/superzip-example.html).

3. Results
3.1. Reported Farm Dams

There were 1,694,675 farm dams reported by regional and Federal authorities in
Australia. The majority of farm dams were in New South Wales (37%), Victoria (26%),
Queensland (17%) and Western Australia (10%; Table S1). Around three-quarters of Aus-
tralia recorded at least one dam per 2000 km2, but the typical density near urban centres
was 2–5 farm dams per km2 (Figure 2). The average size of a dam was ca. 1000 m2, ranging
from 100 m2 to >105 m2 (Figure 3).

3.2. Data Veriﬁcation

Abstract: Farm dams are a ubiquitous limnological feature of agricultural landscapes worldwide.
While their primary function is to capture and store water, they also have disproportionally large
effects on biodiversity and biogeochemical cycling, with important relevance to several Sustainable
Development Goals (SDGs). However, the abundance and distribution of farm dams is unknown
in most parts of the world. Therefore, we used artiﬁcial intelligence and remote sensing data to
address this critical global information gap. Speciﬁcally, we trained a deep learning convolutional
neural network (CNN) on high-deﬁnition satellite images to detect farm dams and carry out the
ﬁrst continental-scale assessment on density, distribution and historical trends. We found that in
Australia there are 1.765 million farm dams that occupy an area larger than Rhode Island (4678 km2)
and store over 20 times more water than Sydney Harbour (10,990 GL). The State of New South Wales

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The dataset used in the deep learning pipeline is not explicitly mentioned in the given context. However, it can be inferred that the authors utilized a custom dataset consisting of around 7362 labeled images of dams and non-dams. They employed transfer learning by initializing an ImageNet pre-trained ResNet34 model, which suggests that the original dataset used for pretraining the ResNet34 model was ImageNet.

In summary, while the exact dataset used for training the deep learning model isn't specified, it appears that the researchers created their own dataset of approximately 7362 images and leveraged transfer learning from an ImageNet pre-trained ResNet34 model.