Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1026153M. Zhou et al.                                                                                                                                                                                                                                   

Fig. 3. The performance optimization of the MLP model.  

Table 1 
Hyperparameters tuning ranges.  

Hyperparameters 

Type 

Tuning range 

The number of neural network layers 
The number of neurons per layer 
Dropout 
Learning rate 
Batch size 

Integer 
Integer 
Float 
Float 
Integer 

1â€“5 
64, 128, 256, 512, 1024, 2048 
0.1, 0.25, 0.35, 0.5 
0.001, 0.0001, 0.00001 
32, 64, 128, 256  

Table 2 
the optimal MLP architecture and parameters.  

Layer type 

Input 
Dense 
Batch normalization 
Dropout 
Dense 
Batch normalization 
Dropout 
Dense(output) 
Total parameters 

Layer size 

4200 
2048 
2048 
2048 
1024 
1024 
1024 
1 
10,715,137  

Parameters 

0 
8,603,648 
8192 
0 
2,098,176 
4096 
0 
1025

an input layer with the 4200 dimensions of the spectral reflectance data; 
ii) the first hidden layer containing 2048 neurons, which uses the ReLu 
activation function to learn the nonlinear expression of the data; iii) a 
batch normalization layer followed by a dropout layer (random dropout

ment ranges were determined based on a review of existing literature 
(Chien, 1994; Peng et al., 2022; Shen et al., 2022; Srivastava et al., 2014; 
Wilson and Martinez, 2001; Zhang et al., 2019). The following hyper-
parameters  were  selected  to  optimize  the  MLP  network  architecture: 
number  of  neural  network  layers,  number  of  neurons  per  layer,  per-
centage values of the dropout layers, learning rate, and batch size. The 
specific tuning ranges of these hyperparameters are shown in Table 1. 
Each  set  of  parameters  in  Table  2  was  trained  based  on  a  set  of 
training data (80%) and verified using validation data (10%). The re-
sults of each group of parameters represent the average of ten experi-
ments (Tsimpouris et al., 2021), and the data were shuffled each time. 
Because the calculations are binary, the number of neuron nodes in the 
network architecture was set to the nth  power of 2 (Peng et al., 2022). In

the percentage value of the dropout layers, the learning rate, and the 
batch size, the optimal model was obtained with an R value of 0.76.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the given context does not provide information about the specific framework or library used to build the deep learning model. Therefore, it is not possible to determine whether TensorFlow, PyTorch, or any other framework was utilized for this purpose.