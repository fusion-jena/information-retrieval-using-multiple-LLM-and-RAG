Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

and TensorFlow 2.5.0 (https://www.tensorflow.org) libraries, and all

statistical analyses were conducted with R 4.1.0 (R Core Team, 2021).

Between-datasets classification

For the between-dataset prediction, the CNN model was trained with

RE SU LT S

a source dataset to predict images from a different target dataset. The

NN was trained with N images randomly selected from the source

Performance of within-dataset classification

dataset, which was then used to predict all images of the target data-
set and AccT and ΔAcc were measured. We ran the above procedures
for three source–target pairs (training dataset!predicted dataset),
GH!LH, GH!LL and LL!LH. These settings simulate two alternative
scenarios: (i) a global image database is used to predict local samples
(GH!LH and GH!LL) and (ii) conventional

images, as

those

Effects of datasets and the number of images

The accuracy of within-dataset classification and the effect of the

representing single-specimen photographs by local taxonomists, are
used to predict local high-resolution images (LL!LH).

Between-datasets classification with domain adversarial
training

In addition to the standard CNN setups described above, we employed

large reduction of accuracy, hence difficulty in transfer.

the domain adversarial training of neural networks (DANN, Ganin

Divergence between the source and target datasets was mea-

et al., 2016) which incorporates a certain portion of the unknown tar-

sured with a dataset classification error. A linear support vector

gets in the model. The DANN model jointly predicts the class (family

machine (SVM) was trained to classify images to the source or target

label) of the source images and the dataset (domain) of all input images

dataset with the features of 200 randomly selected images from both

(as in the previous section) by adding layers for the dataset classifica-

training was done using taxon labels from the source images and data-

training images on prediction accuracy, whereby the CNN model was

trained with N images randomly selected from the dataset and predicted

the class (family label) of n test images randomly selected from the rest.

N ranged between 100 and 700 for LH (with intervals of 100 images),
between 50 and 250 for LL (with intervals of 50 images) and between
100 and 900 for GH (with intervals of 100 images). The number of test
images n was set to 200 for LH and GH, and 50 for LL due to the small
size of the dataset. To evaluate the consistency of prediction accuracy,

imaging procedure. An algorithm for domain adaptation, domain adversarial training of neural

networks (DANN), significantly improved the prediction performance of models trained by

non-standardized, low-quality images. Our findings demonstrate that existing databases can

be used to train models and successfully classify images from unexplored biota, but the imag-

ing conditions and classification algorithms need careful consideration.

K E Y W O R D S
biodiversity assessment, bulk sample, coleoptera, convolutional neural network, domain adaptation,
image classification, machine learning

I N T R O D U C T I O N

Biological

identifications

increasingly rely on machine learning

algorithms that use photographic images to place unidentified speci-

Tomochika Fujisawa and Víctor Noguerales contributed equally to this study.

mens into a taxonomic classification. As these methods are proving to

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific data annotation techniques such as bounding box annotation or instance segmentation being used in their deep learning pipeline. However, it does state that they used taxon labels from the source images during training, suggesting some form of supervised learning. It also mentions that they used a Convolutional Neural Network (CNN) for image classification tasks, which typically requires labeled data for training. Therefore, while not explicitly stated, it can be inferred that some form of data annotation technique would have been necessary to provide the required labeled data for training their CNN model.