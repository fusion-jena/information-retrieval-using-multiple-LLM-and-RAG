Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

easy to train with reduced complexity, even though they have deeper 
layers than CNN models, because of the presence of skip connections 
between the input and output of each block (He et al., 2016). ResNet has 
different variants with a variety of convolution layers. We trialled three 
depths, ResNet-18, (cid:0) 50 and (cid:0) 101, and compared their training times 
and validation accuracies. They behaved similarly but ResNet-50 had a 
marginally  higher  validation  accuracy  (Section  3.1.1)  leading  us  to 
choose it for feature extraction.

ran in approximately 1.2 min for our experiments on the CPU, whilst 
softmax  took  12  min  on  the  GPU  to  complete  the  same  task.  So, 
although, softmax can accomplish our classification task, our proposed 
method has advantages.

Fig. 5. The software classifier showing the structure of ResNet-50 generating a feature vector of size 1000. This is used to train the SVM classifier to classify the insect 
image backgrounds into two classes. The notation ‘axa, b’ in the convolution blocks 1–5 represent a filter of size a and b channels. The output of each convolution block is 
represented by ‘Size x’. The repetition of each square shape in each convolution block represents the repetition of each unit.. 

connected layer, that outputs a 1000-dimensional feature vector. 

3.1. The discovery of exceptions and special cases during the manual 
classification of image backgrounds 

2.4.3. Training and validating the classifier model

The  next step  was  to  gather  standard  visual  information  and  low- 
level  image  features  from  the  datasets  that  include  traits  such  as 
colour, texture, shape, etc. (Shih et al., 2001). These features can be used 
by classifiers or deep learning models for image segmentation, image 
classification  and  object  detection.  There  are  various  techniques  for 
conducting  image  feature  extraction.  With  advancements  in  machine 
learning,  specifically  deep  learning  and  convolution  neural  networks 
(CNNs), feature extraction from images can be performed automatically 
to obtain high levels of classification accuracy (Acharya and Khoshel-
ham, 2020). Therefore, we used a deep-learning model to extract fea-
tures  of  our  image  backgrounds  for  training  a  classifier  model.  We 
adopted  a  ResNet-50  model  (He  et  al.,  2016)  for  extracting  image 
background features for classification. ResNets (Residual Networks) are

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: Unfortunately, there isn't any explicit mention of specific optimization techniques like Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) being applied in the given context. However, based on common practices in deep learning pipelines, these optimization techniques could potentially be employed. For instance, when training the ResNet-50 model mentioned in the text, one might use either SGD or Adam as the optimizer. But without further details, I cannot provide a definitive answer regarding which optimization technique was actually utilized in this case.