Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Methods 

Fig. 2 summarizes a series of processes in designing a deep-learning 
architecture that acts as a toxicovigilance tool. Subsequent sections will 
provide a comprehensive description of each section. 

2.1. Data collection

2.6. Performance metrics 

Conventional  metrics  were  used  to  evaluate  the  model’s  perfor-
mance, such as confusion matrices, accuracy, recall, precision, F1-score, 
Cohen  Kappa,  and  the  area under  the  ROC curve,  some of  which  are 
defined below (Johnson and Khoshgoftaar, 2019).  

Table 1 
List of hyperparameters utilized for training the Recurrent Neural Network 
model.  

Hyperparameter 

Value 

Optimizer 
Learning rate 
Batch size 
Epochs 
Dropout rate 
Loss function 

ADAM (Kingma and Ba, 2017) 
0.003 
32 
100 
0.5 
Binary Cross Entropy  

●  Confusion Matrix

This study used the train_test_split function from the scikit-learn library 
(version 1.2.2), a function that facilitates randomized shuffling and di-
vision of datasets into distinct training and testing subsets. Specifically, 
70%  of  the  data  was  designated for  training  the  classification  model, 
while the remaining 30% was set aside for testing (Dobbin and Simon, 
2011). Individuals from the control and pesticide-exposed groups were 
evenly  distributed  between  these  subsets,  guaranteeing  a  balanced 
representation of each class. The recurrent neural network (RNN) model 
was designed to incorporate three primary input parameters: the bee’s 
age, the daily number of flights, and the total time spent outside daily. 
Following  data  preparation,  labels  for  both  training  and  testing 
datasets  underwent  a  transformation  known  as  one-hot  encoding, 
facilitated  by  the  OneHotEncoder  function  from  the  scikit-learn  library

EcologicalInformatics81(2024)10265310U. Olivares-Pinto et al.                                                                                                                                                                                                                        

Santos, M.S., Soares, J.P., Abreu, P.H., Araujo, H., Santos, J., 2018. Cross-validation for 
imbalanced datasets: avoiding overoptimistic and overfitting approaches [research 
frontier]. IEEE Comput. Intell. Mag. 13 (4), 59–76. https://doi.org/10.1109/ 
MCI.2018.2866730. 

Sgolastra, F., Medrzycki, P., Bortolotti, L., Maini, S., Porrini, C., Simon-Delso, N., 
Bosch, J., 2020. Bees and pesticide regulation: lessons from the neonicotinoid 
experience. Biol. Conserv. 241, 108356.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information on specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions that individuals from the control and pesticide-exposed groups were evenly distributed between the training and testing subsets, ensuring a balanced representation of each class. This suggests that stratified sampling or similar methods might have been employed to maintain class balance and mitigate potential biases. Additionally, the use of conventional performance metrics like confusion matrices, accuracy, recall, precision, F1-score, Cohen Kappa, and the area under the ROC curve indicates that the authors paid attention to evaluating their model's performance with respect to different aspects of imbalance and bias. Nonetheless, without further details, we cannot confirm whether other techniques such as oversampling, undersampling, or diverse data collection were also implemented.