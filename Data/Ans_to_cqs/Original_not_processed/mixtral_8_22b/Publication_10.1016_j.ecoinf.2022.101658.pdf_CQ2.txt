Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

our study, is due to the deep learning method’s loss function, which is 
biased toward overrepresented classes. This represents a performance 
barrier for any study using semantic segmentation with few images and 
high class-imbalance.

Further,  in general, datasets generated from natural scenes for  se-
mantic  segmentation  have  significant  variation  in  the  occurrence  fre-
quencies of different classes. To address this, we used median frequency 
balancing to weight the loss based on the correct label/class, where the 
weight given to each class in the loss function is the ratio of the median 
of  class  frequencies  over  the  entire  dataset  divided  by  the  class  fre-
quency (Eigen and Fergus, 2015). 

2.6. Testing and independent validation 

The deep convolutional neural network was tested using 40 of the 
manually classified photos collected at PM and CL field sites that were 
withheld from training. The algorithm was then subjected to an inde-
pendent validation exercise in which it was applied to a set of photos 

Fig. 3. Field plot layout and configuration of litter and herbaceous destructive 
samples used to compute fuel loads.

Fig.  2. Schematic  diagram  of  methodolog-
ical 
steps.  Field  measurements  were 
collected at three field sites: Pelican Moun-
tain  (PM),  Calling  Lake  (CL)  and  Conklin 
(CK). Manual classification of fuel types used 
in  semantic  segmentation  training  and 
testing were limited to data collected at PM 
and  CL.  Field  measurement  data  and  raw 
photos  from  the  CK  field  site  were  used 
solely for independent validation. R refers to 
the  R  programming  language  and  environ-
ment for statistical computing (R Core Team, 
2020).  DCNN  refers  to  deep  convolutional 
neural network.   

m (class 5). Overstory composition for each transect was estimated for 
up to two species. Fuel load for each FWD size class was calculated by 
transect using the following formula: 
)

([

([

]

]

)

Wfwd =

π2 G1sec(h)n QMD2 c
8L

× S1

+

π2 G2sec(h)n QMD2 c
8L

× S2

(1)

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

Estimating boreal forest ground cover vegetation composition from nadir 
photographs using deep convolutional neural networks 

Hilary A. Cameron a, Pranoy Panda b, Martin Barczyk c, Jennifer L. Beverly a, * 
a Department of Renewable Resources, University of Alberta, Edmonton, AB T6G 2H1, Canada 
b Department of Computer Science and Engineering, IIT Hyderabad, Sangareddy, Telangana 502285, India 
c Department of Mechanical Engineering, University of Alberta, Edmonton, AB T6G 1H9, Canada  

A B S T R A C T

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, the deep learning pipeline uses images as its primary data format. Specifically, the study employs manually classified photos collected at various field sites for training and testing purposes. These photos are likely stored in standard image file formats such as JPEG or PNG. Additionally, the study mentions the use of the R programming language and environment for statistical computing, suggesting that other data formats like CSV might also be utilized for storing metadata or intermediate results during the analysis process. However, the main focus of the deep learning pipeline remains on processing and analyzing image data.