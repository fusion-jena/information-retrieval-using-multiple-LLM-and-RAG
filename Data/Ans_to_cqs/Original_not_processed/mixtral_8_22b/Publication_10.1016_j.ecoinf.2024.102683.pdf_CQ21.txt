Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

and  the  remaining  20%  was  used  to  test  the  model  and  improve  the 
generalization performance of the models.

crucial  information  in  the  feature  maps.  Therefore,  we  can  receive 
important  information  through  a  variety  of  receptive  fields.  In  this 
study, we use a similar configuration to ResNeSt, along with the com-
bined improved attention module. Fig. 4 indicates the proposed model 
block diagram.

Fig. 7. Data splitting in the proposed model.  

different  plants  with  99.78%  accuracy,  demonstrating  the  excellent 
performance of the proposed model in focusing and quickly extracting 
important  features  and  a  high  recognition  rate.  Also,  the  SCAM-Herb 
model based on gated-CA module was able to achieve a high accuracy 
of 99.52% with 90% of training data (Fig. 8b). Moreover, the SCAM- 
herb model based on mixed-CA and GAP-CA modules with 50% of the 
training data achieved accuracies of 94.15% and 93. 23%, respectively, 
which performed relatively poorly compared to the two aforementioned 
models (Fig. 8c and d). However, with increasing the training data, the 
accuracy of the two models increased to 99.38% and 99.43%, respec-
tively. Notably, when more than 80% of the data were used to train the 
models, the accuracy of the models was nearly constant or less variable. 
Therefore, 80% of the total data was sufficient for training the models,

formed a comparative analysis with several models with similar struc-
tures, namely ResNet, ResNeXt, and ResNeSt. Our evaluation of these 
models considered various performance metrics such as accuracy, pre-
cision, recall, specificity, and F1-score. The results show the effective-
ness of our attention module in improving the classification performance 
of medicinal and poisonous plants. According to the data presented in 
Table 3, the integration of both CA and SA modules greatly enhanced the 
the 
model's  ability 
ResNeSt101  + SCAM  model  is  slightly  superior  to  the  ResNeSt50  +
SCAM model with the lowest number of parameters and showed the best 
performance among the other models with accuracy, precision, recall, 
specificity,  and  F1-score  of  99.56%,  99.53%,  99.76%,  99.54%,  and 
99.64%, respectively. Also, the ResNeSt50-SCAM model had a satisfac-
tory performance with an accuracy rate of 99.12%.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, there are several postprocessing steps that can be taken to evaluate and analyze the performance of the trained model. Based on the given context, it appears that the authors have conducted some of these steps.

One common postprocessing step is calculating various performance metrics, which help assess the effectiveness of the model. From the context, it is clear that the authors calculated several performance metrics, including accuracy, precision, recall, specificity, and F1-score. These metrics provide insights into how well the model performs in classifying medicinal and poisonous plants.

Additionally, the authors also seem to have created confusion matrices, although they are not explicitly mentioned. This can be inferred from their comparison of different models using various performance metrics, which typically involves creating confusion matrices to calculate those metrics.

However, there is no mention of saliency maps in the provided context. Saliency maps are visualizations that highlight important regions in input images that contribute significantly to the model's predictions. They can be useful for understanding what parts of the image the model focuses on while making its decisions. It is possible that the authors did not create saliency maps or simply did not discuss them in the given context.

In summary, based on the provided context, the postprocessing steps involved after the model training include calculating performance metrics like accuracy, precision, recall, specificity, and F1-score, and possibly creating confusion matrices. There is no explicit mention of generating saliency maps.