Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ditional  methods  (Farinha- Marques,  Lameiras,  Fernandes,  Silva,  & 

automatically  based  on  the  annotated  training  data  provided. 

Guilherme, 2011). This inhibits our ability to conduct the large- scale 

Convolutional Neural Networks, CNNs (or Deep learning) (LeCun, 

assessment that is necessary for understanding urban ecosystems.

Bengio,  &  Hinton,  2015)  can  even  choose,  based  on  the  annota-

Ecoacoustic surveying has emerged as a useful method of large- 

tions in the training dataset, the features that discriminate different 

scale  quantification  of  ecological  communities  and  their  habitats 

classes  in  datasets  without  being  specified  a  priori,  and  can  take 

(Sueur  &  Farina,  2015).  Passive  acoustic  recording  equipment  facil-

advantage of large quantities of training data where their ability to 

itates the collection of audio data over long time periods and large

could be averaged to inspect the level of biotic and anthropogenic 

Methods), which gave considerable improvements to network ac-

activity at different times of day.

curacy above any single normalisation scheme in isolation. After 

applying different normalisation strategies, the input to the net-

The ML pipeline was written in python v.2.7.12 (Python Software 

work consisted of a 32 × 21 × 4 tensor.

Foundation,  2016)  using  theano  v.0.9.0  (The  Theano  Development 

5.  Apply CNN classifier:  As  described  above,  classification  was  per-

Team,  et al.  2016)  and  lasagne  v.0.2  (Dieleman  et al.,  2015)  for  ML 

formed with a CNN, whose parameters were learnt from training 

and librosa v.0.4.2 (McFee et al., 2015) for audio processing.

data. The CNN comprised a series of layers, each of which modi-

fied  its  input  data  with  parameterised  mathematical  operations 

which were optimised to improve classification performance dur-

2.1 | Acoustic dataset

436–444. https://doi.org/10.1038/nature14539

Lee, H., Pham, P., Largman, Y., & Ng, A. Y. (2009). Unsupervised feature 
learning for audio classification using convolutional deep belief networks 
(pp. 1096–1104). Proceedings of the 22nd International Conference 
on Neural Information Processing Systems, Istanbul, Turkey.

Lin,  T.-H.,  Fang,  S.-H.,  &  Tsao,  Y.  (2017).  Improving  biodiversity  as-
sessment  via  unsupervised  separation  of  biological  sounds  from 
long- duration  recordings.  Scientific  Reports,  7,  4547.  https://doi.
org/10.1038/s41598-017-04790-7

McFee, B., Raffel, C., Liang, D., Ellis, D. P., McVicar, M., Battenberg, E., 
&  Nieto,  O.  (2015).  librosa: Audio and music signal analysis in python 
(pp. 18–25). Proceedings of the 14th python in science conference, 
Austin, TX.

methods for preprocessing spectrograms before they are used in 

were repeated independently for CityBioNet and CityAnthroNet 

ML; for example, whitening (Lee, Pham, Largman, & Ng, 2009) and 

to  predict  the  presence/absence  of  biotic  and  anthropogenic 

subtraction of mean values along each frequency bin (Aide et al., 

sound in every 1 s chunk throughout the audio file, allowing each 

2013). CNNs are able to accept inputs with multiple channels of 

chunk to be categorised into one of four states (Figure 2).

data, for example, the red, green, and blue channels of a colour 

7.  Summarise: Where appropriate, the chunk-level predictions were 

image. We exploited the multiple input channel capability of our 

summarised to gain insights into trends over time and space. For 

CNN by providing as input four spectrograms each preprocessed 

example,  predicted  activity  levels  for  each  half-hour  window 

using  a  different  normalisation  strategy  (see  Supplementary

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model such as Convolutional Neural Networks (CNNs), several preprocessing steps may be applied to the input data. These steps aim to enhance the quality of the data and improve the overall performance of the model. Some common preprocessing techniques include normalization, scaling, and cleaning. Normalization involves adjusting the range of pixel intensity values in images or spectrograms to a specific range, often between 0 and 1. Scaling refers to resizing the input data to fit the required dimensions of the neural network architecture. Cleaning involves removing noise or irrelevant information from the input data to prevent it from negatively impacting the model's performance. In this case, the authors mention applying different normalization strategies to spectrograms before feeding them into the CNN. They also discuss using multiple input channels in the CNN, which allows for the use of various preprocessing techniques simultaneously.