Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Data pre-processing 

2.2. Convolutional neural networks 

The  idea  behind  convolutional  neural  networks  (CNNs)  was  first 

As mentioned in the previous sections, the data is first split up into 
several  larger  blocks,  depending  on  coordinates,  with  the  purpose  to 
cross validate the model. These blocks are then split into many smaller 
areas of 80 × 80 pixels, due to limitations in the available amount of 

EcologicalInformatics68(2022)1015572N. Ståhl and L. Weimann

A 10-fold cross validation is performed in order for the result to be 
generalizable for the remaining maps, to which the CNN is also applied. 
To create the 10 different sets for the cross validation, we split the map 
by placing a 3 × 3 grid over the map. The region that is studies is not 
shaped  as  a  square,  and  the  central  cell  contains  more  area  than  the 
other 8. This cell is, therefore, split into two cells making it 10 sets in 
total. The division of the different sets are shown in Fig. 2. During the 
training of the CNN 9 of these sets are used for the training and the final 
one is used for evaluation. A challenge to the CNN is that the terrain 
differs in the different areas, as well as the style of the maps, and thus 
splitting the dataset in this way would give a good hint on the capability 
of  the  CNN  to  generalise.  Among  the  samples  that  are  used  for  the 
training  20%  is  used  as  a  validation  set  to  prevent  the  method  from

overfitting. These samples are selected randomly from all areas that are 
used in the training set, and are never used to fit the model. The model is 
trained for 150 epochs and with a batch size of 128. Dropout (Srivastava 
et al., 2014) with a rate of 0.3 is used during the training to make it more 
stable. Furthermore, ADAM optimisation (Kingma and Ba, 2014) with a 
learning  rate  of  0.0001  is  used  to  find  optimal  weights  in  the  neural 
network in order to minimise the cross entropy loss between the net-
work’s predictions and the pre-labelled data.

Minaee, S., Boykov, Y.Y., Porikli, F., Plaza, A.J., Kehtarnavaz, N., Terzopoulos, D., 2021. 
Image segmentation using deep learning: a survey. IEEE Trans. Pattern Anal. Mach. 
Intell. 

OpenStreetMap Contributors, 2017. Planet Dump. retrieved from. https://planet.osm. 

org. https://www.openstreetmap.org. 

Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., 
Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., 
Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., Chintala, S., 2019. Pytorch: 
an imperative style, high-performance deep learning library. In: Wallach, H., 
Larochelle, H., Beygelzimer, A., d’Alch´e-Buc, F., Fox, E., Garnett, R. (Eds.), Advances 
in Neural Information Processing Systems, 32. Curran Associates, Inc., 
pp. 8024–8035

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific datasets such as MNIST, CIFAR, or ImageNet being used in the deep learning pipeline. However, it does state that OpenStreetMap data is utilized, specifically referring to a planet dump from OpenStreetMap contributors in 2017. Additionally, the context discusses the use of a 10-fold cross-validation technique, where the data is divided into ten subsets, nine of which are used for training and one for testing. It can be inferred that the dataset consists of images or maps, considering the application of Convolutional Neural Networks (CNNs). Nevertheless, without further information, it cannot be definitively stated what other datasets might have been employed in the deep learning pipeline.