Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  classification  performance  of  each  considered  deep  learning 
model is compared with the original dataset and augmented dataset to 
validate  the  performance  of  the  proposed  EMViT  on  the  imbalanced 
dataset. The results presented in Table 6. show the evaluated classifi-
cation performance of the considered deep learning model on the orig-
inal dataset and augmented dataset. It can be seen that the performance 
obtained by CNN models after augmentation is higher than the perfor-
mance obtained under the original dataset. The performance ranking of 
each  CNN  model  is  also  changed  under  the  original  dataset  when 
compared with  the augmented dataset.  The performance achieved by 
EMViT-Net  is  still  giving  the  highest  classification  accuracy  in  both 
cases. These comparison findings further transmit the advantage as well 
as the effectiveness of the proposed network.

b)  Some preprocessing steps like data augmentation and normalization 
are  performed  to  address  the  diversity  of  training  data  and  data 
imbalance problems in classification tasks.  

c)  The preprocessed images are fed to the transformer-based network 
EMViT-Net for extracting the both local and global features of mi-
crobes from EM images.  

d)  The integration of the SCPSA block in the CNN module of the EMViT- 
Net makes the model more efficient in extracting depth-wise features 
from the images.  

e)  The  extracted  features  are  then  given  to  a  multilayer  perceptron 

module for final feature fusion and classification.  

f)  Finally, the performance of the proposed EMViT-Net is evaluated on 
unseen test sets of the datasets by calculating performance metrics 
accuracy, precision, recall and f1-Score. 

2.1. EMViT-Net

Table 6 
Performance comparison of EMViT Net with different deep learning models on EMDS-6 test set.  

Model 

Original dataset 

After Augmentation 

Avg. Precision 

Avg. Recall 

Avg. F1-score 

Accuracy 

Avg. Precision 

Avg. Recall 

Avg. F1-score 

Accuracy 

DenseNet121 
Alex Net 
ViT 
ResNet50 
Xception Net 
VGG19 
Inception V3 
VGG16 
EMViT-Net 

39.20% 
32.53% 
34.92% 
41.96% 
44.25% 
41.20% 
50.78% 
38.21% 
57.31% 

33.01% 
31.90% 
33.24% 
37.14% 
39.37% 
31.43% 
43.97% 
37.47% 
53.71% 

33.79% 
29.32%` 
32.63% 
36.93% 
39.07% 
29.97% 
43.41% 
36.80% 
53.45% 

33.02% 
31.91% 
33.23% 
37.14% 
39.37% 
31.43% 
43.97% 
37.46% 
53.71% 

34.92% 
38.19% 
43.55% 
46.57% 
50.87% 
52.40% 
51.91% 
50.86% 
69.53% 

33.77% 
35.87% 
37.65% 
41.58% 
44.76% 
48.57% 
48.88% 
50.15% 
67.62% 

32.45% 
35.35% 
37.92% 
42.06% 
43.03% 
47.67% 
48.10% 
50.64% 
66.89% 

33.77% 
35.87% 
37.65% 
41.58% 
44.76% 
48.57% 
48.88% 
50.15% 
67.62%

configuration of optimizer and learning rate which has been considered 
for the training of the framework. The EMViT-Net framework achieves 
prominent results as compared to other deep learning models and per-
forms better with an augmented set of EMDS-6 datasets.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the provided context does not explicitly mention the specific data augmentation techniques used in the deep learning pipeline. However, it does state that some preprocessing steps such as data augmentation were performed to address the diversity of training data and data imbalance problems in classification tasks. Commonly used data augmentation techniques include flipping, rotation, scaling, cropping, translation, and adding noise. Therefore, it can be inferred that similar techniques might have been employed here, but without explicit confirmation, we cannot definitively determine which ones were utilized.