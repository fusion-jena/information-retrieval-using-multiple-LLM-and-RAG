Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3. Imagery splitting ratio 

We split the dataset in a ratio of 80:10:10 for training, validation, and 
testing sets, respectively. This ratio was used due to prior evidence of 
exceed performances in detecting small insects and diseases using deep 
learning models (Kiratiratanapruk et al., 2022; Krishnadas and Sampa-
thila, 2021; Mulchandani et al., 2019). The training dataset consisted of 
1543 images, 243 images for the validation set, and 247 images for the 
testing set and all were at input resolution of 640 × 640 pixels. The 1280 
× 1280 pixels input resolution consisted of 1637 images for the training 
set, 255 images for the validation set, and 262 images for the testing set. 
Independently,  we  trained  5  different  versions  of  the  YOLOv5  model 
family  including:  YOLOv5n,  YOLOv5s,  YOLOv5m,  YOLOv5l,  and 
YOLOv5x models to detect alates on sorghum leaves. 

2.4. Characteristics of deep learning models

2.5. Description of hyperparameters and training aspects 

The  five  detection  models  were  trained  using  a  manually  labeled 
image dataset for alate detection. After conducted initial computational 
experiments with different combinations of epochs of 300, 400 and 500 
with batch sizes of 8, 16, and 32, it was determined that the optimal 
hyperparameters for our training were 400 epochs with a batch size of 8 
and were constant when comparing the five detection models using 640 
× 640, and 1280 × 1280 pixels input resolutions on each model type. 
The batch defines the number of samples to be worked through before 
moving on to update the internal model parameters (Radiuk, 2017). The 
epoch  number  used  in  training  determines  the  number  of  times  the 
detection model processes the dataset dedicated to training the model 
(Brownlee,  2018).  The  computer  infrastructure  used  for  training 

2.6. Evaluation metrics of the trained models

Nearest Neighbors, Support Vector Machines, Decision Trees, Boosting, 
and Random Trees (Yang et al., 2010). However, a growing subarea in 
machine learning, called deep learning, can leverage large image data-
sets  to train  deep neural networks such as  Convolutional Neural  Net-
works (CNNs) (Jordan and Mitchell, 2015) to make accurate predictions 
on new, unseen images.

2.4. Characteristics of deep learning models 

The  You  Only  Look  Once,  or  YOLO,  family  of  models  are  open- 
sourced  computer  vision  models  used  for  detecting  objects.  These 
state-of-the-art, single-stage detector models created by Ultralytics are 
built on PyTorch machine learning framework (Ultralytics, 2023). The 
YOLOv5 family consists of 5 different versions that differ in complexity 
including the nano (n), small (s), medium (m), large (l), and extra-large 
(x)  detector  models.  Each  version  of  YOLOv5  contains  a  different 
number of  layers  and  parameters, which  differ in  model sizes.  Model 
accuracy is  lost  when size  is  reduced,  but training speed  is  improved 

EcologicalInformatics80(2024)1025402I. Grijalva et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of their deep learning model, I. Grijalva et al. employed several strategies. Firstly, they utilized a diverse dataset consisting of various types of images with different input resolutions (640 x 640 pixels and 1280 x 1280 pixels). This diversity allowed the model to learn from a wide range of examples, improving its ability to perform well on previously unseen data. Secondly, they adopted a stratified splitting approach to divide their dataset into three distinct sets: training, validation, and testing. By maintaining a consistent ratio of 80:10:10 across these sets, they ensured that the distribution of classes remained balanced during both training and evaluation phases. Lastly, they independently trained five different versions of the YOLOv5 model family, namely YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x, to detect alates on sorghum leaves. Training multiple models helped them assess the robustness and consistency of their results, further contributing to the overall generalizability of their study.