Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model 

Accuracy 
(%) 

Loss 

VGG-19 
InceptionV3 
EfficientNet 
ResNet50 
InceptionResNetV2 
MobileNet 
LSTM 
BiLSTM 
GRU 
MobileNet-BiLSTM 
MobileNet-LSTM 
MobileNet-GRU 
SRNN 
TCN 

97.08 
98.18 
97.08 
52.19 
98.91 
98.91 
52.19 
71.53 
66.42 
99.27 
99.27 
99.27 
55.56 
66.67 

0.08 
0.04 
0.06 
25.25 
0.03 
0.04 
0.67 
0.57 
0.51 
0.02 
0.02 
0.02 
0.66 
1.20 

Model 
training 
time (sec) 

924.49 
947.13 
1004.30 
952.39 
1022.48 
918.23 
934.22 
984.55 
183,298 
912.35 
948.31 
890.16 
12.16 
35.60 

28,416,066 
40,680,226 
36,820,638 
76,019,586 
68,495,586 
20,009,154 
183,298 
430,594 
183,298 
12,274,882 
12,405,954 
11,864,770 
7,489,474 
6,564,738 

4 
4 
4 
4 
4 
4 
8 
8 
8 
6 
6 
6 
5 
5  

like MobileNet.

Fig. 7. Training loss vs validation loss - MobileNet-BiLSTM.  

Fig. 8. Training accuracy vs validation accuracy - MobileNet-LSTM.  

Fig. 9. Training LOSS VS VALIDATION LOSS - MobileNet-LSTM.  

EcologicalInformatics81(2024)102548924681000.20.40.60.81EpochsLossTrainingLossValidationLossT. Chawla et al.                                                                                                                                                                                                                                 

Table 2 
Comparison of performance metrics of different models in terms of accuracy, 
binary cross entropy loss, model training time, total parameters and total layers.  

significantly. The results across different metrics of six transfer learning 
models, three RNNs and three hybrid models implemented are presented 
in Table 2. 

Total 
parameters 

No. of 
layers 

5.3. Error analysis 

Model 

Accuracy 
(%) 

Loss

classification tasks. The evaluation of model performance was based on 
the  accuracy  metric.  Each  model  underwent  training  for  10  epochs, 
utilizing  a  batch  size  of  32.  The  class  mode  was  set  to  ‘categorical,’ 
indicating  that  the  labels  were  encoded  using  one-hot  encoding  for 
multi-class  classification  tasks.  These  generalized  parameter  settings 
were consistently applied across all models, ensuring comparability and 
standardization throughout the study experiments.

A =

TP + TN
TP + TN + FP + FN

(9) 

Here,  TP  represents  the  number  of  true  positive  predictions,  TN 
corresponds to the number of true negative predictions, FP signifies the 
number  of  false  positive  predictions,  and  FN  indicates  the  number  of 
false negative predictions. 

5.1.3. Model training time 

Model training time quantifies the time required for a neural network 
to converge to a predefined accuracy or loss threshold. This metric is 
inherently linked to the model’s architectural complexity, the volume 
and  dimensionality  of  the  training  dataset,  and  the  computational 
throughput  of  the  training  environment  (e.g.,  GPU  acceleration).  In 
practical scenarios, optimizing training time is useful for resource allo-
cation and rapid model iteration. 

5.1.4. Total model parameters

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning models is evaluated based on various metrics such as accuracy, binary cross entropy loss, model training time, total parameters, and total layers. However, the primary metric used to assess the model performance in this case is accuracy. Each model undergoes training for 10 epochs with a batch size of 32, utilizing 'categorical' class mode which employs one-hot encoding for multi-class classification tasks. The accuracy metric is calculated using the formula A = (TP + TN)/(TP + TN + FP + FN), where TP represents true positives, TN corresponds to true negatives, FP denotes false positives, and FN stands for false negatives. Additionally, other metrics like model training time and total parameters are also considered for evaluating the overall efficiency and effectiveness of the deep learning models.