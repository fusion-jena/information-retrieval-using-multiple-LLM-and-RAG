Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We  also  tested  four  ‘classical’  machine-learning  algorithms:  Ada-
Boost Multi-Class Adaptive Boosting (‘AB’ hereafter), Gradient Boosting 
(‘GB’  hereafter),  Histogram-based  Gradient  Boosting  (‘HB’  hereafter), 
and  a  linear  discriminant  model  (‘LD’  hereafter).  Instead  of  directly 
taking  pictures  as  input,  these  algorithms  use  numerical  ‘features’ 
extracted from, and representing attributes of, those pictures. We used 
Inovtaxon (Bambil et al., 2020) to extract 226 picture features (namely, 
36  colour  features,  135  shape  features,  and  55  texture  features)  that 
were used as input to feed the algorithms (see Bambil et al., 2020 and htt 
ps://github.com/DeborahBambil/Inovtaxon  for  details;  see  also  Hu, 
1962;  Zhao  and  Pietikainen,  2007;  Flusser  et  al.,  2009;  Deniz  et  al., 
2011; Nascimento et al., 2023).

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Automated identification 
Machine learning 
Accuracy 
Specificity 
Low-resolution pictures 
Triatominae

database into training (80%) and testing sets (20%), and then trained and tested a convolutional neural network 
(AlexNet,  AN);  three  boosting-based  classifiers  (AdaBoost,  AB;  Gradient  Boosting,  GB;  and  Histogram-based 
Gradient Boosting, HB); and a linear discriminant model (LD). We assessed identification accuracy and speci-
ficity with logit-binomial generalized linear mixed models fit in a Bayesian framework. Differences in perfor-
mance across algorithms were mainly driven by AN’s essentially perfect accuracy and specificity, irrespective of 
picture angle or bug position. HB predicted accuracies ranged from ~0.987 (Panstrongylus, dorsal-oblique) to 
>0.999  (Triatoma,  dorsal-flat).  AB  accuracy  was  poor  for  Rhodnius  (~0.224–0.282)  and  Panstrongylus 
(~0.664–0.729), but high for Triatoma (~0.988–0.991). For Panstrongylus, LD and GB had predicted accuracies

2.3. Algorithm training and testing 

We trained all algorithms on a random subset of 5256 pictures (80% 

of  the  6570-picture  dataset).  To  gauge  performance  consistency,  the 
training-testing  process  was  repeated  10  times  for  each  algorithm;  in 
each of these (pseudo-)replicate runs, all five algorithms used the same 
training and testing picture subsets.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The deep learning pipeline described in this context uses images as its primary data format. Specifically, it processes low-resolution pictures of insects belonging to the subfamily Triatominae. However, instead of feeding the raw images directly into the machine learning algorithms, they first extract 226 numerical 'features' from the images using Inovtaxon software. These extracted features represent various attributes of the images such as color, shape, and texture. Therefore, while the initial input is in image format, the actual data fed into the machine learning algorithms consists of these numeric feature vectors.