Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

solely using the hand-annotated data. This allows for a direct comparison of the contribution of
high-quality annotations when compared to the self-supervised model or the full model combining
both self-supervision and hand-annotation data.

improve with a combination of better validation data and more hand-annotated training samples.

combined with labeled data in a semi-supervised framework (sensu [14]), which may improve deep
learning on limited training data by providing neural networks the opportunity to learn generalized
features on a wider array of training examples, followed by retraining on a smaller number of high
quality annotations [16]. It is unknown whether moderate to low quality annotations can be used
to generate trees for initial model training, given the imperfect nature of existing unsupervised tree
delimitation approaches.

9 of 13

The full model reduces the extraneous boxes and improves the segmentation of large trees by
combining the self-supervised and the hand annotated datasets (Figure 7). The full model has optimal
performance in areas of well-spaced large trees (Figure 7B), but it tends to under-segment small clusters
of trees (Figure 7C).

Figure 7. Predictions from the full model on data withheld from model training. Canopy complexity
increases from (A) well-deÔ¨Åned large trees to (B) mixed-species canopies to (C) tightly packed clusters
of trees. As canopy complexity increases, the full model tends to under-segment small tree clusters.

4. Discussion

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided information, there isn't explicit mention of a specific strategy implemented to monitor the model performance during training. However, we can infer some strategies based on the context.

Firstly, the use of both self-supervised learning and hand-annotated data suggests that the model's performance was monitored during training through the comparison of these two methods. By comparing the results obtained solely from the hand-annotated data and those from the self-supervised model, researchers could gauge the effectiveness of each method and their combined impact on the model's performance.

Secondly, the text mentions the improvement of the model with a combination of better validation data and more hand-annotated training samples. This implies that the model's performance was also monitored through the use of validation data, which is a common practice in machine learning to evaluate how well a model is performing during training.

Lastly, the discussion about the full model's performance on different types of canopy complexity indicates that the model's performance was evaluated post-training on various scenarios. This evaluation would have allowed researchers to understand the strengths and weaknesses of the model, thereby monitoring its overall performance.