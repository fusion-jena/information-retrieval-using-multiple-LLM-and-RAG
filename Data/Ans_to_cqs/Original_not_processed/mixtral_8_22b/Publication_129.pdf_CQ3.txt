Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.2. Faster R-CNN approach

The Faster R-CNN presents recent advancement of both Fast
R-CNN and R-CNN by Ren et al. [16]. It merges a Region
Proposal Network (RPN) as object bounds predictor and Fast
R-CNN for target detection in processed images. The role of
RPN module is to serve as the ‘‘attention” mechanism of this
uniﬁed Faster R-CNN, as depicted in Fig. 2. Three basic com-
ponents of the Faster R-CNN can be described as follow.
First, the feature extractor network to generate feature maps

[34]. Second,

[34]. Second,

from the input image (see Fig. 2). It can be a pre-trained
CNN architecture such as Inception [32], Residual Neural Net-
work (Resnet) [33], and Dense Convolutional Network (Den-
senet)
the RPN module proposes object
locations of the feature maps. Third, a regressor and classiﬁer
are trained using the loss function L in (1) for the CNN detec-
tion network to adjust these proposed locations and to predict
single or multi-object classes with the corresponding bounding
box area in the resulted image, as shown in Fig. 2.

Lð pif g;

tif gÞ ¼

1
Ncls

X

i

Lclsðpi

i Þ þ k 1
; p(cid:3)
Nreg

X

i

i Lregðti; t(cid:3)
p(cid:3)

i Þ: ð1Þ

IoU ¼

A \ B
A [ B

ð2Þ

Next, the Region of Interest (RoI) pooling layer takes the
region corresponding to a proposal from the backbone feature
map and dividing it into sub-windows. The maximum pooling
is performed over these sub-windows to give the output of RoI
pooling layer, which has a size of (N, 7, 7, 512), and N is the
number of generated region proposals by the RPN mechanism,
as shown in Fig. 2. After passing through two fully connected
layers (FCs), the features are fed into the classiﬁer and regres-
sor branches as follow. The classiﬁcation layer calculates the
probability of the region proposal contains an object such that
the probability Pi of each element in the feature map i contains
the target object using softmax function. The regions with the
top score of 300 Pi in the total rankings present the detected
target object. In addition, the regressor provides the IoU index

A new mobile application of agricultural pests recognition

4427

Fig. 3

[18] H. Chen, A. Chen, L. Xu, H. Xie, H. Qiao, Q. Lin, K. Cai, A
deep learning CNN architecture applied in smart near-infrared
analysis of water pollution for agricultural irrigation resources,
Agric. Water Manag. 240 (2020) 106303.

[19] X. Wu, C. Zhan, Y. Lai, M. Cheng, J. Yang, IP102: A Large-
Scale Benchmark Dataset for Insect Pest Recognition, IEEE/
CVF Conference on Computer Vision and Pattern Recognition
(CVPR) 2019 (2019) 8779–8788.

[20] W. Li, P. Chen, B. Wang, C. Xie, Automatic Localization and
Count of Agricultural Crop Pests Based on an Improved Deep
Learning Pipeline, Sci. Rep. 9 (2019) 7024.

[21] A. Gutierrez, A. Ansuategi, L. Susperregi, C. Tubı´ o, I. Rankic´ ,
L. Lenzˇ a, A Benchmarking of Learning Strategies for Pest
Detection and Identiﬁcation on Tomato Plants for Autonomous
Scouting Robots Using Internal Databases, J. Sens. 2019 (2019)
5219471.

4432

M.E. Karar et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the context of deep learning pipelines for agricultural pests recognition, various data annotation techniques have been employed. These include bounding box annotation and instance segmentation.

Bounding box annotation involves drawing rectangular boxes around objects of interest within an image. This technique is commonly used in object detection tasks where the goal is to identify the presence and location of specific objects within an image. For example, in the case of agricultural pests recognition, bounding boxes could be drawn around individual pests within an image to help train a model to detect their presence.

Instance segmentation, on the other hand, involves not only identifying the presence and location of objects within an image but also delineating their boundaries. This allows for more precise identification of individual instances of objects within an image. Instance segmentation can be particularly useful in cases where multiple instances of the same type of object may overlap or occlude one another.

Both bounding box annotation and instance segmentation require significant manual effort to create accurate labels for training datasets. However, advances in machine learning algorithms and hardware have made it increasingly feasible to automate much of this process. For example, some approaches use weakly supervised learning methods to automatically generate bounding boxes or instance masks based on limited human input. Other approaches leverage transfer learning to fine-tune models pre-trained on large-scale datasets for specific applications like agricultural pests recognition.

Overall, the choice of data annotation technique will depend on the specific requirements of the task at hand. While bounding box annotation may be sufficient for simple object detection tasks, instance segmentation may be necessary for more complex scenarios involving overlapping or occluded objects.