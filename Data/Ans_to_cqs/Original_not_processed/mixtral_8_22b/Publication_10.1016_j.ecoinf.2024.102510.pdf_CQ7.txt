Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

64, 128, 256, 512 

64, 128, 256, 512 

EcologicalInformatics80(2024)1025107S.V.S. Kumar and H.K. Kondaveeti                                                                                                                                                                                                         

Table 8 
Performance comparison of the selected models evaluated using a 60:40 split of training and testing data.   

Validation accuracy 

Precision 

Recall 

F1-score 

Model name 

Feature extractor 

Fine tuner 

Feature extractor 

Fine tuner 

Feature extractor 

Fine tuner 

Feature extractor 

Fine tuner 

MobileNetV2 
EfficientNetB0 
GoogleNet 
DenseNet201 
InceptionV3 
ResNet18 
InceptionResNetV2 
NASNetMobile 

91.21% 
94.47% 
88.47% 
92.41% 
92.99% 
87.81% 
93.04% 
92.83% 

93.16% 
96.56% 
90.16% 
94.21% 
94.56% 
89.33% 
95.44% 
94.68% 

92.54% 
94.99% 
89.98% 
93.22% 
93.86% 
89.38% 
93.73% 
93.41% 

94.11% 
95.31% 
90.97% 
95.02% 
95.12% 
91.25% 
95.13% 
95.44%

Yang, L., Shami, A., 2020. On hyperparameter optimization of machine learning 

algorithms: theory and practice. Neurocomputing 415, 295–316. 

Shorten, C., Khoshgoftaar, T.M., 2019. A survey on image data augmentation for deep 

Yang, C.-L., Harjoseputro, Y., Hu, Y.-C., Chen, Y.-Y., 2022a. An improved transfer- 

learning. J. Big Data 6 (1), 1–48. 

Sitepu, A.C., Liu, C.-M., Sigiro, M., Panjaitan, J., Copa, V., 2022. A convolutional neural 
network bird’s classification using north american bird images. J. Health Sci. 6 (S2), 
15067–15080. 

Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N., Patwary, M., 

Prabhat, M., Adams, R., 2015. Scalable bayesian optimization using deep neural 
networks. In: International Conference On Machine Learning. PMLR, pp. 2171–2180. 

learning for image-based species classification of protected indonesians birds. CMC 
Comp. Mater. Continua 73 (3), 4577–4593.

Experiments are conducted to determine the bird species recognition 

capabilities  of  selected  models  employed  such  as  60:40,  80:20,  and 
90:10.  The  performance  evaluation  results  of  all  models  are  docu-
mented. The dataset is split into a training set and a validation set using 
three data split strategies (i.e., 60:40,80:20, and 90:10). This was done 
to evaluate the abilities of different models to learn from a larger dataset 
and identify any underfitting/overfitting issues. The benchmark dataset 
CUB 200–2011 is used to evaluate the models to ensure a fair compar-
ison between the models.

search  tests  various combinations of  the hyperparameters  identified in  manual  search and  trains the selected 
models to achieve the maximum possible accuracy through multiple iterations. Experimental analysis revealed 
that the Fine-tuned EfficientNetB0 model exhibited superior performance, achieving an accuracy of 99.12%. In 
contrast, the performance of the ResNet18 model was disappointing with an accuracy of 93.24%, while other 
models outperformed it.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data can be split into three sets: training, validation, and testing. The training set is used to fit the model, the validation set is used to tune the parameters of the model, and the testing set is used to assess the final performance of the model. The ratio of splitting the data depends on the size of the dataset and the complexity of the problem. Commonly used ratios include 60:40, 80:20, and 90:10 for training and validation or testing respectively. For example, in the given context, the dataset is split into a training set and a validation set using three data split strategies (i.e., 60:40, 80:20, and 90:10) to evaluate the abilities of different models to learn from a larger dataset and identify any underfitting/overfitting issues.