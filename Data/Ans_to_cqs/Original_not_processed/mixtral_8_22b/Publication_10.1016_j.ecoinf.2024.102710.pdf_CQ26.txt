Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The active learning experiments are carried out in the embedding
space of the selected transfer learning model (BirdNet-1, see Section
3.1). We explore a range of sampling strategies: uncertainty and di-
versity based, myopic (greedy) and adaptive (batch mode), and com-
binations thereof. Fig. 2 provides a schematic overview of the pure
families of sampling strategies: Random sampling selects samples arbi-
trarily, uncertainty sampling targets samples near the decision bound-
ary, and diversity sampling focuses on samples that span the entire data
space. In all cases, 5% of the samples are selected at random. Class labels
are available for all samples used in this study, and an active learning
scenario is emulated by hiding all labels from the classifier at first and
incrementally revealing the ones for each batch of samples queried by
the sampling methods. We use a batch size of 20 samples. The classifier
heads are identical to those from the transfer learning training process.

Combined sampling strategies address the limitations of pure
strategies. Uncertainty sampling selects samples close to the decision
boundaries, but may introduce redundancy. Diversity sampling covers
the entire input space, but may miss critical regions. We therefore

Fig. 2. Schematic representation of the random, uncertainty, and diversity
sampling strategies. Random sampling selects arbitrary samples. Uncertainty
sampling selects samples based on their proximity to the model's decision
boundary, calculated using the existing class 1 and class 2 labels. Diversity
sampling uses the internal data structure for sampling purposes, such as clus-
tering the data and selecting samples from each cluster.

Fig. 3. Uncertainty scores for binary inputs computed with the methods ‘ratio’
(ΦRC bi), ‘least confidence’ (ΦLC bi) and ‘entropy’ (ΦEN bi), given a model pre-
diction y.

EcologicalInformatics82(2024)1027104computed on the held-out evaluation sets described in section 2.1.

H. Kath et al.

investigate methods that combine uncertainty and diversity strategies.
Filtering pre-selects 50% of the samples by diversity sampling and uses
uncertainty sampling to sample from this pre-selection. We use this
method for ‘combi: ratio max + clustering’. Hybrid sampling selects
50% of the samples from each of the two methods. All other combination
methods use hybrid sampling.

2.4. Computational resources

The computational analyses4 including pre-processing steps are
conducted using Python programming language version 3.10. Key li-
braries include librosa for audio processing, scikit-maad for spectrogram
computation, and TensorFlow for learning processes. We used BirdNet
V2.4,5 VGGish,6 YAMNet,7 VGG168 and ResNet152-V29 as embedding
models for the present study.

of different active learning strategies. We investigate a range of sam-
pling strategies: uncertainty and diversity based methods, myopic
(greedy) and adaptive (batch mode) methods, and combinations thereof.
Finally, we evaluate the resulting learning curves through the lens of

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it does not explicitly mention any specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, some general approaches to addressing data bias can be discussed. These include stratified splitting, which ensures that the distribution of classes or features in the dataset remains consistent across train/test splits; oversampling, where minority classes are duplicated to balance the dataset; undersampling, where majority classes are reduced to achieve balance; and diverse data collection, which aims to gather a wide variety of examples representative of real-world scenarios. It should be noted that these techniques were not mentioned in the provided context, so they might not necessarily apply to the research being conducted.