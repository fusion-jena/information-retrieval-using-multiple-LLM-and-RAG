Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

both training and testing. A critical point to highlight is that models are 
retrained  for  each  fold,  preventing  previous  fold’s  information  from 
being transferred. We utilized the pretrained ResNet-34 (Which consists 
of  a  34-layer  convolutional  neural  network)  architecture  which  is  a 
variant of the ResNet (Residual Network) family, widely used for deep 
learning tasks, particularly in computer vision (He et al., 2016). ResNet- 
34 was used inside the fast.ai framework (Howard and Gugger, 2020) to 
leverage  existing  knowledge,  this  is  particularly  useful  in  our  dataset 
since its small size. Transfer learning generally consists in using a model 
pre-trained  on  broad  datasets,  like  ImageNet  (Deng  et  al.,  2009),  to 
specialized tasks with more limited data. As part of the cross-validation 
of the Leave-One-Group-Out approach, the test directory containing the 
multitemporal transect was temporarily moved to test, and DataLoaders

To expand our dataset, we tripled the image pool for each transect by 
incorporating multi-temporal data. By drawing data from a three-month 
span (March, September and October 2015) across three environments, 
we could more effectively train and test deep learning models, which 
inherently  demand  many  images  to  learn  effectively,  however,

2.5.1. Classification problem (Q1): Deep learning applied to 2D LiDAR 
images for Forest classification 

We  employed  the  fast.ai  platform  (Howard  and  Gugger,  2020)  to 
train and validate models for the classification of 2D point cloud images, 
utilizing  a  LOGO  (Leave-One-Group-Out)  cross-validation.  In  this 
approach, our target classes were "Plateau", "White-sand", and "Ripar-
ian",  designated  as  "p",  "w",  and  "r"  respectively.  In  each  iteration,  a 
complete 450 m multitemporal transect was omitted from the training 
process  (the  grouping  factor  giving  the  lack  of  independence  in  the 
multi-temporal data) and subsequently tested. This approach ensured an 
assessment  of  the  model’s  performance,  accounting  for  our  data  con-
straints and guaranteeing that every multitemporal transect undergoes

2.5.2. Regression problem (Q2): Unveiling the gradient of Forest structural 
shifts along a topographic gradient- a hybrid machine learning approach 
with convolutional autoencoders and partial least squares regression

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit details about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions the use of a Leave-One-Group-Out (LOGO) cross-validation approach, where a complete 450m multitemporal transect was omitted from the training process in each iteration and then tested. This method ensures an assessment of the model's performance while considering data constraints. Additionally, the dataset was expanded by incorporating multi-temporal data from a three-month span across three environments, which helped improve the effectiveness of training and testing deep learning models. Although these methods do not directly address data bias, they contribute to improving the robustness and generalizability of the models by ensuring diverse data representation and reducing overfitting.