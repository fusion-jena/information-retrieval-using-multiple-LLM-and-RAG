Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

the collected data. Finally, the deep learning algorithms are evaluated and the challenges
of monitoring IAPS are discussed.

5.1.1. Network Training Procedure

In both network structures, the ﬁnal classiﬁcation layer was adapted to match the
seven classes (six IAPS and “no species” (Table 2)). The input image size affects the
processing time of each image, but can also impact the classiﬁcation accuracy. Therefore,
the network models were trained on ﬁve different image sizes: 96 × 128 px, 192 × 256 px,
384 × 512 px, 768 × 1024 px, and 1536 × 2048 px (see Supplementary Materials for a visual
comparison of the image sizes). For each image size, a network was trained using either
random weights or weights pre-trained on ImageNet and with global max pooling or
global average pooling before the ﬁnal classiﬁcation layers.

When training a deep convolutional neural network, it is important to split the data
into a training set, a validation set, and a test set. The training set is used for optimizing the
parameters of the network, while the validation set is used for monitoring the performance
of the network during training and for comparing the performance of different networks
with, for example, different hyperparameters or network structures. The test set acts as a
ﬁnal evaluation of a network. To ensure a proper evaluation on both the validation set and
the test set, samples in each set must be independent and have similar class distributions.
The full data set can be split in various ways. The naïve approach is to randomly
sample images from the full data set. However, due to the images being captured in
close proximity and potentially having overlapping ﬁelds of views, information may leak
between the data sets when using the naïve approach. Another approach would be to

12825651210242048Image width0.7000.7250.7500.7750.8000.8250.8500.875Ratio of clusters(a)MobileNetV2ResNet50V212825651210242048Image width0.500.550.600.650.700.75Average cluster precision(b)MobileNetV2ResNet50V2Sensors 2021, 21, 6126

15 of 22

validation is 92% indicating that there are differences between the appearance of plants
in the different data sets. This difference is likely caused by the spatial distance between
locations where the train, validation, and test sets were collected. The average precision is
77% for the detected plant species, where the most difﬁcult species to detect is Pastinaca
sativa with a precision of 47%. The result also shows that the trained ResNet50V2 network
model outperforms YOLOv3 for Rosa rugosa, while YOLOv3 is best at detecting the more
difﬁcult species Lupinus polyphyllus and Pastinaca sativa.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there is no information about which platform was used to deploy the deep learning model. It could be any of the mentioned platforms such as AWS, Azure, or Google Cloud Platform, or even another platform not listed here. Without additional context, we cannot determine which platform was used.