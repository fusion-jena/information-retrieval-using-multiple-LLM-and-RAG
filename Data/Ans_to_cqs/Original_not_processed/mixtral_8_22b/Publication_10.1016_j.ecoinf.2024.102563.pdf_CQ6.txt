Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Mohammadi, J., Toomanian, N., 2016. Database extension for digital soil mapping 
using artificial neural networks. Arab. J. Geosci. 9 (18), 701. https://doi.org/ 
10.1007/s12517-016-2732-z. 

Breiman, L., 2001. Random forests. Mach. Learn. 45 (1), 5–32. https://doi.org/10.1023/ 

A:1010933404324. 

Carr´e, F., McBratney, A.B., Mayr, T., Montanarella, L., 2007. Digital soil assessments: 

beyond DSM. Geoderma 142, 69–79. https://doi.org/10.1016/j. 
geoderma.2007.08.015. 

Clausi, D.A., 2002. An analysis of co-occurrence texture statistics as a function of grey 
level quantization. Can. J. Remote. Sens. 28 (1), 45–62. https://doi.org/10.5589/ 
m02-004. 

Congalton, R.G., Green, K., 2009. Assessing the Accuracy of Remotely Sensed Data: 

Principles and Practices, 2nd ed. CRC Press, Boca Raton, Florida.

Liu, X.Q., Zhu, A.X., Yang, L., Pei, T., Liu, J.Z., Wang, D.S., 2020. A graded proportion 
method of training sample selection for updating conventional soil maps. Geoderma 
357, 1–9. https://doi.org/10.1016/j.geoderma.2019.113939. 

Lu, D., Hetrick, S., Moran, E., 2010. Land cover classification in a complex urban-rural 
landscape with quickbird imagery. Photogramm. Eng. Remote. Sens. 76 (10), 
1159–1168. https://doi.org/10.14358/PERS.76.10.1159. 

Lu, H., Liu, C., Li, N., Fu, X., Li, L., 2021. Optimal segmentation scale selection and 

Berlin/Heidelberg.  

Saboori, M., Torahi, A.A., Bakhtyari, H.R.R., 2019. Combining multi-scale textural 

features from the panchromatic bands of high spatial resolution images with ANN 
and MLC classification algorithms to extract urban land uses. Int. J. Remote Sens. 40 
(22), 8608–8634. https://doi.org/10.1080/01431161.2019.1620371. 

Sheykhmousa, M., Mahdianpari, M., Ghanbari, H., 2020. Support vector machine versus

Fig.  4. Classification  results  obtained  using  a  19  × 19  window  size  for  the 
mean parameter. (a) MLC, (b) SVM, (c) ANN, and (d) RF methods. 

EcologicalInformatics81(2024)1025636M. Duan et al.

We employed a graded-proportion method that utilizes area-based 
grading  of  soil  groups  to  select  training  samples  (Liu  et  al.,  2020). 
This  approach  involved  two  primary  steps.  Initially,  soil  groups  were 
graded  according  to  their  corresponding  areas.  Subsequently,  the 
training samples were determined for each soil group according to the 
gradational  relationship  derived  from  typical  sample  points.  This 
method  resulted  in  444  training  samples  from  seven  soil  groups,  as 
detailed in Table 1. Of these, 423 samples were sourced from the his-
torical  soil  map.  Simultaneously,  a  comprehensive  field  investigation 
was conducted to collect 29 samples using soil drills and examine six soil 
profiles. Fifteen of these soil drill samples and all six soil profiles were 
used as training samples, whereas the remaining 14 soil drill samples 
were reserved for validation. The training samples were used to classify

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers referenced do not provide specific information on the preprocessing steps involved before training a deep learning model. However, common preprocessing steps include data cleaning, which involves removing or correcting erroneous data; data normalization, which scales numeric columns to a standard range to prevent differences in scales from influencing outcomes; and data transformation, such as converting categorical variables into numerical ones through encoding techniques like one-hot encoding or label encoding. These preprocessing steps help improve the performance and efficiency of the deep learning models.