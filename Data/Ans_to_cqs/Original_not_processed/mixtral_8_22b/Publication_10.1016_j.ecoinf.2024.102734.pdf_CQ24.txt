Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

samples (red line) compared to randomly ordered samples, no active
learning (blue line), and active learning using high-certainty samples
(yellow line). The baseline accuracy is calculated using a 2-shot, 2-way
test accuracy without fine-tuning (81.4%). The AST feature extraction
model is fine-tuned on a subset of 500 training samples. Model perfor-
mance is re-evaluated on the test set at 10 sample increments using each
of the three sample orderings. Low certainty refers to queries with a
similar Euclidean distance to prototypical embeddings and therefore lie
along decision boundaries. For high-certainty samples, the order is
reversed with query embedding in close proximity to prototypical em-
beddings being prioritised for model fine-tuning.

∑

x∈Sd

fθ(x)

3.4. Active learning

(1)

A recommender system, Fig. 4, ranks segment embeddings in order
of lowest certainty to highest certainty. Low-certainty embeddings
correspond to features on decision boundaries. The Euclidean distance ld
is computed between existing prototypes cd and the query embeddings q
providing both class suggestion and class probability using P(q ∈ d | ld)
= softmax(1 (cid:0) norm(ld)). The recommender ranks queries in terms of

This methodology has been implemented into the Listening Lab
Annotator Tool (McEwen et al., 2023b), shown in Fig. 5. The following
section demonstrates the functionality of the annotator and methodol-
ogy workflow.

Fig. 2. Raw field data are segmented into 5-s spectrograms. A pre-trained feature extraction generates 527-dimensional embedding vectors for each segment.
Coloured vectors denote embeddings that were previously labelled.

EcologicalInformatics82(2024)1027344B. McEwen et al.

Fig. 3. Transfer learning using pre-trained feature extraction model and fully connected layers with adjustable output nodes.

Fig. 4. Prototypical learning provides a class probability distribution that a query belongs to each class. The probability distribution is used to rank the priority of
samples. The colours denote the class distributions in a simplified 2-dimensional view.

implementation is based on work by Priyadarshani et al. (Priyadarshani
et al., 2016) and achieves a precision/recall of 0.365/0.861 and an AUC
of 0.545. This stage is demonstrated in Fig. 2.

lowest to highest probability. Similar to Wang et al. (Wang et al., 2022)
the recommender actively queries the user to label these samples. User-
updated samples are used to fine-tune the feature extractor and update
class prototypes cd.

3.2. Transfer learning

3.5. Annotation tool

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about handling randomness in the deep learning pipeline or any specific strategies related to managing randomness such as random seed values. Therefore, I cannot provide a helpful answer to this query based on the provided context.