Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.5.3. Spatial KDE weighting 

Predictive accuracy metrics were calculated and weighted using es-
timates of spatial density (i.e., inverse sampling intensity weighting; de 
Bruin et al., 2022). A spatial kernel density estimate (KDE) layer  ̂K(s)
was calculated from the simulated sample points using the ‘spatialEco’ 
package (Evans, 2021) in R v.4.1.2 (R Core Team, 2021), which relies on 
the ‘MASS’ package (Venables and Ripley, 2002). This implementation 
uses a Gaussian kernel, and the bandwidth was determined using the 
rule proposed by Scott (1992), as implemented in ‘MASS’. The model for 
the response variable was trained using all sample points, and out-of-bag 
predictions  for  each  point  obtained  from  the  bagging  process  were 
assigned a weight,

selected approach (e.g., cross-validation) to simulate map validation in a 
“real-world” context. The variance explained (̂ve) was used as a relative 
measure of performance, and the root mean square error ( ̂rmse) as an 
absolute performance metric, in response units. The variance explained 
and root mean squared error were calculated by

Fig. 6. Change in true performance at predicting each response variable after applying bagging weights based on KDE (black) and spatial covariance (grey) ap-
proaches for all simulation runs. Dots indicate the mean. Note that RMSE values have been scaled from 0 to 1 for plotting. 

2.5. Covariance-weighted validation

To assess the capacity for unbiased validation using the covariance- 
weighted  bagging  approach,  results  were  benchmarked  against  five 
other methods. 

2.5.1. Out-of-bag validation 

The accuracy of the model was evaluated at the simulated locations 
using  an  out-of-bag  validation.  Out-of-bag  predictions  for  each  simu-
lated data point are obtained during the bagging process by predicting 
the values at the data points that were not selected for each bootstrap 
sample,  and averaging the  results of  these predicted values across  all 

EcologicalInformatics77(2023)1021817B. Misiuk and C.J. Brown

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about a deep learning model or its evaluation metrics. However, it mentions two metrics used to measure the performance of a model: variance explained (^ve) and root mean square error (^rmse). Variance explained is a relative measure of performance, while root mean square error is an absolute performance metric measured in response units. These metrics are used to calculate the change in true performance at predicting each response variable after applying bagging weights based on KDE and spatial covariance approaches for all simulation runs.

Answer:::
Answer: The text does not explicitly mention the use of a deep learning model. However, it discusses the use of two metrics to evaluate the performance of a model: variance explained (^ve) and root mean square error (^rmse). Variance explained is a relative measure of performance, while root mean square error is an absolute performance metric measured in response units. These metrics are used to calculate the change in true performance at predicting each response variable after applying bagging weights based on KDE and spatial covariance approaches for all simulation runs.