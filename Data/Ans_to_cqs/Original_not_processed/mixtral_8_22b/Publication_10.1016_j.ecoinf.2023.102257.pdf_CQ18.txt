Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

classification outcomes from our experiment; and (3) Evaluate the ef-
fects  of  ML  model  performance  on  tagging  efficiency,  including  an 
assessment  of  the  overall  utility  of  the  ML  bounding  box  model  for 
accelerating the data labelling process. 

2. Materials and methods 

2.1. Objective 1: perform tagging efficiency experiment

Maine, USA (January–September 2022) using three tagging methods (one with ML bounding box assistance and 
two  without  assistance).  We  used  a  generalized  linear  mixed  model  to  examine  the  influence  of  ML  model 
performance  and  tagging  method  on  tagging  efficiency.  We  found  that  ML  bounding  boxes  offer  significant 
improvement in tagging efficiency when labelling data compared to unassisted tagging. Additionally, the time 
taken to label with bounding boxes was not statistically different from an unassisted tagging approach. However, 
we  found  that  gains  in  efficiency  are  contingent  on  the  ML  algorithm’s  performance  and  that  incorrect  ML 
predictions, particularly the 4.2% false positive and 3.6% false negative predictions, can slow the tagging process 
compared to a non-hybrid approach. These findings indicate that although practitioners usually forgo the pro-

sensitivity was set to “normal”  (60 ft), the triggering speed was set to 
“fast” (0.1 s), and the Infrared LED flash was set to “economy”.

As  ML-techniques  become  more  pervasive  in  the  field  of  remote 
wildlife monitoring, further study of how ML model performance im-
pacts their utility could become increasingly important. Several open- 
source  species-level  classification  models  have  recently  been  released 
(B¨ohner et al., 2022; Norouzzadeh et al., 2018; Tabak et al., 2019; Tabak 
et al., 2020; Tabak et al., 2022; Vecvanags et al., 2022; Whytock et al., 
2021) which can similarly be used in tandem with human tagging to 
improve tagging efficiency (Willi et al., 2019). Yet, species-level classi-
fication models can also be geographically constrained and underper-
form when applied on “out-of-sample” data from locations or in contexts 
that differ from the original training data (Tabak et al., 2019). Under-
standing the role of model performance on tagging efficiency for species- 
detection could prove useful in determining in what circumstances these 
models are effective. 

Author contributions

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about the specific strategy implemented to monitor the model performance during training. However, it mentions that the researchers conducted experiments using machine learning (ML) techniques, specifically focusing on bounding box models for accelerating the data labelling process. They evaluated the effects of ML model performance on tagging efficiency and found that ML bounding boxes significantly improved tagging efficiency compared to unassisted tagging. Furthermore, they discovered that gains in efficiency were dependent on the ML algorithm's performance, indicating that some form of performance monitoring must have taken place. Nevertheless, the exact strategy employed to monitor the model performance during training remains undisclosed within the given context.