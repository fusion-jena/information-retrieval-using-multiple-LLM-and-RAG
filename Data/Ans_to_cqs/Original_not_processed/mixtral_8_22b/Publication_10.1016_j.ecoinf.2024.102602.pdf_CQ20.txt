Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.5.1. Model selection and parametrization 

For  the  classification  task,  before  the  implementation  of  deep 
learning models, all images were resized to the same resolution (227×
197  pixels)  by  considering  the  mean  dimensions  of  the  set,  and  then 
normalized to the [0,1] range (Na and Fox, 2020). Then, six open source 
CNNs  were  selected:  VGG16  (Simonyan  and  Zisserman,  2015), 
ResNet50,  ResNet101  (He  et  al.,  2016),  Inception-v3  (Szegedy  et  al., 
2016), DenseNet201 (Huang et al., 2017) and EfficientNetB0 (Tan and 
Le,  2019).  These  algorithms  were  selected  because  of  their  ease  for 
transfer  learning and  high  performance  on  similar classification  tasks 
(Arun  and  Viknesh,  2022;  Vallabhajosyula  et  al.,  2022).  For  model 
optimization, we used the Adam optimizer algorithm (Kingma and Ba, 
2015), a batch size of 10 and 100 epochs. The learning rates were chosen 
(cid:0) 6 showing 
from empirical trials over 100 epochs, with and 10

EcologicalInformatics81(2024)1026029Faster R-CNN ResNet101 iNaturalistFaster R-CNN ResNet101 MS COCOFaster R-CNN ResNet50 iNaturalistFaster R-CNN ResNet50 MS COCOFaster R-CNN Inception-v2 MS COCOAverage inference time per image (ms)3951063668958mAP@0.50IOU76.8579.2374.9380.8081.71Total loss2.241.142.241.201.08A.S. Cardoso et al.                                                                                                                                                                                                                              

with other plant species. Moreover, there are no other plant species in 
Portugal (our study area) with the same features as C. selloana. Both of 
these particularities may be the source of the high results observed in 
this study. 

4.4. Monitoring the invasive alien Cortaderia selloana from online digital 
images

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Artificial intelligence 
Convolutional neural networks 
Computer vision 
Pampas grass

Table 2 
Performance metrics for both learning rates scenarios trained for each classification model (mean ±
standard deviation of the five folds). ACC – Accuracy, TPR – Sensitivity, TNR – Specificity and F1 – 
F1-score. Light grey cells highlight the best performance results for learning rate and metric. 

Table 3 
Performance metric (mAP@0.50IOU; mean average precision), average inference time per image and total 
loss (sum of the classification and localization losses) for each model. Light grey cells highlight the best model 
results for performance (mAP), total loss and speed. 

3.3. Mapping the spatial distribution of Cortaderia selloana

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the specific hardware resources used for training the deep learning models. Therefore, it is not possible to determine whether GPUs, TPUs, or any other hardware resources were utilized during the training process based solely on this context.