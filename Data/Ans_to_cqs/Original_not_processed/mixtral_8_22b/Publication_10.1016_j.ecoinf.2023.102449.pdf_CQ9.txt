Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

quency response that create a potential bias; we demonstrate how a simple linear transformation can be used to 
mitigate the effect of hardware variance on the learned representation under our approach. Our novel approach 
paves the way for development of a new class of deep neural networks that afford more interpretable learned 
ecoacoustic representations to advance both fundamental and applied science and support global conservation 
efforts.

The  encoder  uses  a  pre-processing  block  containing  a  convolution 
with a wide receptive field (5 × 5 kernel) and signal coarsening along 
the time axis (2 × 1 kernel) (Kahl et al., 2021). Coarsening follows the 
changes suggested in (He et al., 2018) and replicates later versions of 
BirdNet’s  down-sampling  strategy  by  recombining  the  concatenated 
output  of  2 × 2  maximum and  2  × 2 average  pooling using  a  1 × 1 
convolution.  After  convolution,  feature  representations  are  chunked 
along the time axis into T = 19 independent frames each corresponding 
to 3.072 s. Each frame is flattened and passed through a final linear layer 
to  output  T  d-dimensional  mean  μ  and  log  variance  logσ2  vectors  as 
parameters  for  the  Gaussian  variational  posterior.  A  latent  vector  for 
each frame in the time-series is sampled from the posterior using the 
reparameterisation trick. We set d = 128 for comparability with ecoa-

2.4. Model architecture 

The  encoder  and  decoder  are  deep  CNNs  setup  as  wide  residual 
networks (Fig. 1) (Zagoruyko and Komodakis, 2017). Residual networks 
(ResNets) describe a class of functions that allow for deeper architec-
tures and increased model complexity by learning a perturbation of the 
input  signal  at  each  layer  rather  than  a  transformation  as  in  conven-
tional  neural  architectures  (He  et  al.,  2015a).  The  perturbation  is 
implemented  using  skip  connections  in  residual  blocks  allowing  the 
input signal to persist through the network (He et al., 2015a). Each skip 
connection  increases  the  variance  between  the  input  and  output  at  a 
given  layer,  causing  an  exponential  growth  in  memory  usage  as  the 

Table 1 
Architectural layout of the soundscape VAE.

2.5. Pre-training 

The VAE was trained under variational inference to reconstruct mini- 
batches of 6 spectrograms over a maximum of 100,000 batches with a 
hold out split for both validation and test of 20%. Stochastic gradient 
descent is performed using the Adam optimiser (Diederik and Ba, 2017) 
using weight decay. To maximise reconstruction quality without over- 
fitting the learning rate was tweaked to an optimal configuration of η =
0.0005, undergoing annealing by a factor of 100 using a cosine function 
over  the  duration  of  the  training  (He  et  al.,  2018).  The  means  μ  and 
standard  deviations  σ  of  the  latent  distribution  for  all  T  frames  were 
encoded  as  a  set  of  feature  embeddings  and  used  in  subsequent 
experiments. 

2.6. Experiments 

2.6.1. Accommodating sensitivity to differences in device

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of where the data repository of the deep learning pipeline is available. It could be hosted on platforms such as Zenodo, Figshare, Dryad, or GBIF, but without specific details, it is not possible to provide a definitive answer.