Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Yu, F., Koltun, V., 2016. Multi-scale context aggregation by dilated convolutions. In: In 
4th International Conference on Learning Representations, ICLR 2016, San Juan, 
Puerto Rico, May 2-4, 2016, Conference Track Proceedings. 

Tan, X.L., Chen, J.L., Benelli, G., Desneux, N., Yang, X.Q., Liu, T.X., Ge, F., 2017. Pre- 

Zhong, Y., Gao, J., Lei, Q., Zhou, Y., 2018. A vision-based counting and recognition 

infestation of tomato plants by aphids modulates transmission-acquisition 

system for flying insects in intelligent agriculture. Sensors 18 (5), 1489. 

EcologicalInformatics78(2023)10238411

Simonyan, K., Zisserman, A., 2015. Very deep convolutional networks for large-scale 

image recognition. In: In 3rd International Conference on Learning Representations, 
ICLR 2015, San Diego, CA, USA, May 7-9, 2015. Proceedings, Conference Track.  

Tian, H., Wang, T., Liu, Y., Qiao, X., Li, Y., 2020. Computer vision technology in 
agricultural automation —a review. Inform. Proc. Agricult. 7 (1), 1–19. 
Tshernyshev, W.B., 1995. Ecological pest management (epm): general approaches. 

J. Appl. Entomol. 119 (1–5), 379–381. 

Wang, Q.-J., Zhang, S.-Y., Dong, S.-F., Zhang, G.-C., Yang, J., Li, R., Wang, H.-Q., 2020. 
Pest24: A large-scale very small object data set of agricultural pests for multi-target 
detection. Comput. Electron. Agric. 175, 105585. 

Wang, D., Wang, Y., Li, M., Yang, X., Wu, J., Li, W., 2021. Using an improved YOLOv4 
deep learning network for accurate detection of whitefly and thrips on sticky trap 
images. Trans. ASABE 64 (3), 919–927.

we break them down into smaller patches. Specifically, in the training 
stage,  we  randomly  crop  square  patches  (experimenting  with  various 
patch sizes, namely 256, 320, 480, 640, and 800 pixels), and we apply a 
simple  augmentation  strategy,  flipping  the  patches  horizontally  and 
vertically with a 50% probability. On the other hand, during the vali-
dation phase, we divide the images of the validation split into regularly- 
spaced,  overlapping  patches,  using  the  same  size  employed  during 
training.  We  process  these  patches  individually,  reconstructing  the 
overall  output  by  combining  the  predictions  from  the  patches,  and 
subsequently, we calculate metrics over the complete image. For clarity, 
Fig.  2  provides  a  graphical  representation  of  this  procedure.  In  more 
detail,  for  the  solution  based  on  detection,  we  reconstruct  the  final 
global  output  using  non-maximum  suppression  among  the  bounding

Ren, S., He, K., Girshick, R., Sun, J., 2017. Faster r-CNN: Towards real-time object 

detection with region proposal networks. IEEE Trans. Pattern Anal. Mach. Intell. 39 
(6), 1137–1149. 

Ronneberger, O., Fischer, P., Brox, T., 2015. U-net: Convolutional networks for 

biomedical image segmentation. In: Medical Image Computing and Computer- 
Assisted Intervention - MICCAI 2015 - 18th International Conference Munich, 

EcologicalInformatics78(2023)10238410L. Ciampi et al.                                                                                                                                                                                                                                  

Germany, October 5 - 9, 2015, Proceedings, Part III, volume 9351 of Lecture Notes in 
Computer Science. Springer, pp. 234–241. 

relationship among whiteflies, tomato yellow leaf curl virus (TYLCV) and plants. 
Frontiers. Plant Sci. 8.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers cited primarily focus on computer vision applications in agriculture, specifically for detecting and recognizing pests such as aphids, whiteflies, and thrips. The primary data format used in these studies is digital images or videos of crops and pests. These visual datasets are then processed through deep learning pipelines, often involving convolutional neural networks (CNNs). Some examples include Yu and Koltun's work on multi-scale context aggregation by dilated convolutions, Simonyan and Zisserman's research on very deep convolutional networks for large-scale image recognition, and Ren et al.'s paper on faster R-CNN for real-time object detection. Additionally, Wang et al.'s study introduces a dataset called Pest24, which consists of a large-scale collection of images featuring agricultural pests. Overall, the main data format utilized in these deep learning pipelines is digital imagery.