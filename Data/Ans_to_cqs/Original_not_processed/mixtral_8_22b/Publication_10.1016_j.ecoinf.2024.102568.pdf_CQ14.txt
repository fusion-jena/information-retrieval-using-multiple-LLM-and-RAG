Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

parameters optimization. In: 2012 IEEE 14th International Conference on 
Communication Technology, pp. 1022–1026. https://doi.org/10.1109/ 
ICCT.2012.6511415. 

ISO, 2011. ISO 19156:2011 - Geographic Information – Observations and Measurements. 

https://doi.org/10.13140/2.1.1142.3042. 

Kingma, D.P., Ba, J., 2015. Adam: A method for stochastic optimization. In: Bengio, Y., 

LeCun, Y. (Eds.), 3rd International Conference on Learning Representations, ICLR 
2015, San Diego, CA, USA, May 7–9, 2015. Conference Track Proceedings. URL. 
http://arxiv.org/abs/1412.6980. 

Li, J., Heap, A.D., 2014. Spatial interpolation methods applied in the environmental 

sciences: a review. Environ. Model Softw. 53, 173–189. URL. http://www.sciencedi 
rect.com/science/article/pii/S1364815213003113. https://doi.org/10.1016/j. 
envsoft.2013.12.008. 

Maag, B., Saukh, O., Hasenfratz, D., Thiele, L., 2016. Pre-deployment testing,

Zou, H., Hastie, T., 2005. Regularization and variable selection via the elastic net. J. R. 

Stat. Soc. Ser. B 67, 301–320. 

EcologicalInformatics81(2024)10256818

and 

4.2. Assessment metrics 

Four metrics are taken into consideration when evaluating the per-
formances  of  the  algorithms:  Root  Mean  Square  Error  (RMSE),  Mean 
Absolute Error (MAE), Mean Relative Error (MRE), and accuracy. 

Given  the  calibrated  value  ̂yi  and  the  corresponding  ground  truth 

value yi, RMSE is calculated by the formula: 

RMSE =

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
√
1
i=1(̂yi (cid:0) yi)2
Σn
n

where n is the total number of observations. Since the errors are squared 
before they are averaged, the RMSE gives a relatively high weight to 
large errors. On the other hand, MAE measures the average magnitude of 
the errors weighing all the errors in the same way and without consid-
ering the error direction, following the formula: 

MAE =

1
Σn
i=1∣̂yi (cid:0) yi∣ 
n

Table 5 
Exp.1 results. 

of RMSE and MAE higher than 20 and in green the values lower than 8; 
while  the  values  of  MRE  are  in  green  if  lower  than  0.4  and  in  red  if 
higher than 1. In the end, we used green for accuracy higher than 0.9 
and red for values lower than 0.75. In addition, the number of obser-
vations in the training set is reported in the column “train size”, while 
the column “% out of range” shows the number of observations in the 
test set with the value of at least one of the two channels out of the range 
between the minimum and the maximum values of the training set. 

6.1. Exp.1

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The paper does not provide explicit information about how the hyperparameters of the model were optimized. However, based on the given context, it can be inferred that some form of parameter optimization was performed, possibly using techniques such as grid search or random search. This assumption is supported by the mention of parameters optimization in the first reference [1]. Additionally, the use of Adam, a popular algorithm for stochastic optimization, suggests that some level of hyperparameter tuning may have been involved [3]. Nevertheless, without more specific details from the authors, it remains uncertain which exact method was employed for hyperparameter optimization.