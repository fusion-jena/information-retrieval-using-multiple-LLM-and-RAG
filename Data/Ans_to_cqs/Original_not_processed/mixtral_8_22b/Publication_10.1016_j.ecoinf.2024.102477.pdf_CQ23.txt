Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

regularization parameter used to control model complexity and prevent 
overfitting  by  constraining  the  loss  function  during  training.  The 
parameter ε  controls the model's fault tolerance, that is, the degree of 
tolerance for differences between predicted and actual values of training 
samples. The term σ represents a parameter of a Gaussian kernel or the 
width parameter of a radial basis function kernel. This parameter con-
trols the relationship between support vectors and hyperplanes and af-
fects model complexity and generalization ability. SVR is formulated as 
follows: 

f (x) = ωT φ(x) + b

R =

1
2

‖ω‖2 + C

)

ξi + ξ*
i

∑N
(cid:0)

i=1

(5)  

(6)  

where ω is a weight vector, φ(x), b is a bias term, C is the regularization 
constant, and ξi and ξ*
i  are slack variables that quantify how far data can 
exist from the ε tube. 

3.4. Deep learning 

3.4.1. SLSTM method

concentration of atmospheric CO. This model was compared with four 
statistical  models  (ARIMA,  SARIMA,  ETS,  and  HWETS),  one  machine 
learning model (SVR), and one deep learning model (SLSTM) in terms of 
its predictive performance. Model performance was evaluated using the 
MAPE and RMSE metrics. Table 3 presents the average values of these 
metrics for the aforementioned models. The MAPE values of the SGRU 
model were lower than those of the ARIMA, SARIMA, ETS, HWETS, SVR, 
and SLSTM models by 67.60%, 55.98%, 79.85%, 55.72%, 42.43%, and 
20.44%,  respectively,  indicating  that  the  accuracy  of  prediction  was 
significantly higher for the SGRU model than for the other models. As 
presented in Fig. 2, the CO values predicted by the SGRU model were 
close to the actual values. Fig. 3 shows scatter plots of the actual CO 
values and those predicted by the ARIMA, SARIMA, ETS, HWETS, SVR, 
SLSTM, and SGRU models. Compared with the other models, the deep

SVR is a machine learning method known for its superior accuracy 
compared  with  other  machine  learning  methods  and  its  ability  to 
simplify parameters, achieve global optimization, and handle nonlinear 
problems  (Chen  et  al., 2017;  Ji et  al.,  2021). In  this  study, the  expo-
(cid:0) 8–21,  σ  =
nential  parameters  were  set  as  follows:  C  = 20–210,  ε  = 2
(cid:0) 8–21 (Yang et al., 2022). Table 2 presents the training results for the 
2
hyperparameter-optimized  SVR  model.  Parameter  C  controls  error 
tolerance during training and determines the maximum deviation that 
the model permits for any individual training example. A higher C value 
allows for a larger error, which makes the model more likely to fit the 
training  data  but  also  increases  the  risk  of  overfitting.  Conversely,  a 
smaller  C  value  imposes  stricter  constraints  on  the  model,  thereby 
increasing  the  difficultly  of  fitting  the  training  data  but  potentially

4.3. Analysis of forecasting results 

In this study, an SGRU-based deep learning approach was adopted to 
develop  a  model  for  accurately  predicting  (over  36  months)  the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific measures taken to ensure the generalizability of the deep learning model, such as using diverse datasets, cross-validation, or stratified splitting. However, it mentions that the SGRU model outperformed several statistical and machine learning models, including another deep learning model called SLSTM, in terms of predictive performance. Additionally, the SGRU model demonstrated significantly higher accuracy in predicting CO concentrations compared to other models. These comparisons suggest that the SGRU model has been tested against various benchmarks, contributing to its robustness and potential generalizability. Nevertheless, without further details regarding the validation process, it remains unclear whether additional steps were taken to enhance the model's generalizability.