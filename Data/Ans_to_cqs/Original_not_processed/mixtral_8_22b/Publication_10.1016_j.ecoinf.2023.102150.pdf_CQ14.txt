Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1 
Number of training images, validation images (used for model validation during 
model  training)  and  out-of-sample  test  images  (used  for  external  model  vali-
dation after training was finished) as well as number of new images selected 
from  the  images  taken  between  summer  2020  and  summer  2021  for  model 
retraining.  

Class 

Number of 
training 
images 

Number of 
validation 
images 

Number of 
out-of-sample 
test images 

Number of new 
training images 
for model 
retraining 

Bad 

6453 

quality 

Bird 
Empty 
Least 

weasel 
Lemming 
Shrew 
Stoat 
Vole 
TOTAL 

3382 
9444 
1725 

9449 
9265 
4024 
9894 
53636 

677 

219 
979 
98 

967 
962 
438 
1024 
5364 

549 

119 
3301 
69 

647 
584 
64 
919 
6252 

306 

195 
533 
424 

449 
416 
425 
528 
3276

Fig. 4. Example images of a vole (A), a lemming (B), a stoat (C), a least weasel (D), a shrew (E), and a bird (F).  

epochs with a one-cycle learning rate policy with a minimum learning 
rate of 0.000001 and a maximum learning rate of 0.001 (Smith, 2018). 
We explored different hyper-parameters and choose the ones that gave 

the best results for training the final model. All images were resized to 
224 x 224 pixels previous to training and image augmentation (shifts, 
horizontal flips, rotations, zooms and shears) was applied to expand the 

EcologicalInformatics76(2023)1021505H. B¨ohner et al.

complete data set. Thus, model performance would be overestimated for 
rare  classes  and  underestimated  for  abundant  classes.  Therefore,  the 
number  of  true  positives,  false  positives  and  false  negatives  was

classification tasks. Inf. Process. Manage. 45, 427–437. https://doi.org/10.1016/J. 
IPM.2009.03.002. 

Steenweg, R., Hebblewhite, M., Kays, R., Ahumada, J., Fisher, J.T., Burton, C., 

Townsend, S.E., Carbone, C., Rowcliffe, J.M., Whittington, J., Brodie, J., Royle, J.A., 
Switalski, A., Clevenger, A.P., Heim, N., Rich, L.N., 2017. Scaling-up camera traps: 
monitoring the planet’s biodiversity with networks of remote sensors. Front. Ecol. 
Environ. 15, 26–34. https://doi.org/10.1002/FEE.1448. 

Tabak, M.A., Norouzzadeh, M.S., Wolfson, D.W., Newton, E.J., Boughton, R.K., Ivan, J.S., 
Odell, E.A., Newkirk, E.S., Conrey, R.Y., Stenglein, J., Iannarilli, F., Erb, J., Brook, R. 
K., Davis, A.J., Lewis, J., Walsh, D.P., Beasley, J.C., VerCauteren, K.C., Clune, J., 
Miller, R.S., 2020. Improving the accessibility and transferability of machine 
learning algorithms for identification of animals in camera trap images: MLWIC2. 
Ecol. Evol. 10, 10374–10383. https://doi.org/10.1002/ece3.6692.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information on how the hyperparameters of the model were optimized. However, it is mentioned that they explored different hyperparameters and chose the ones that gave the best results for training the final model. This suggests that some form of optimization or tuning process was used, but without further details, it cannot be confirmed whether this was done through methods such as grid search, random search, or other techniques like Bayesian Optimization or Gradient Descent.