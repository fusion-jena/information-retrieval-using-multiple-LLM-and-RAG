Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

database for training of deep learning models. Comparable stud-
ies used 1060 (Daood et al., 2016), 13 617 images (Pedersen
et al., 2017) or 19 500 images (Sevillano et al., 2020), while in
our study the CNN classiﬁer was trained with 426 876 images.

We have previously suggested that a minimum of 200 images
per species are required for accurate species identiﬁcation of phy-
toplankton (Dunker et al., 2018). By contrast, in the present
study on pollen, ﬁve out of six species with fewer than 200 pollen
grains were classiﬁed with an accuracy higher than 90%. Based
on these ﬁndings, we concluded that between 50 and 100 pollen
grains represented a reasonable amount of pollen images on a sin-
gle channel to be included in the reference library.

Key words: convolutional neural networks,
deep learning, multispectral imaging ﬂow
cytometry, pollen, pollinator, species
identiﬁcation.

Deep learning

Dataset Our dataset consisted of 35 573 images for each of the
12 channels covering 35 species and resulting in a total of 426
876 images. This dataset was split into three sets for training, val-
idation, and testing in the proportions 80 : 10 : 10. All images
were centre cropped to an equally sized rectangle. In order to gain
a more robust and better generalising classiﬁer, the images in the

New Phytologist (2021) 229: 593–606
www.newphytologist.com

training set were additionally augmented in the following ways:
ﬂipped horizontal, ﬂipped vertically,
adjusted in bright-
ness (cid:3) 12.5%, adjusted in saturation (cid:3) 50.0%, adjusted by
contrast (cid:3) 12.5%, and adjusted in hue (cid:3) 20%.

Pollen ID classiﬁer Analysing the captured set of microscopic
images poses a computer vision problem and makes convolu-
tional neural networks (CNN) the proper choice of model to
train (Nguyen et al., 2018). CNNs are feed-forward artiﬁcial
neural networks composed of layers with learnable ﬁlters. More
speciﬁcally, an inception network architecture (INCEPTION v.3)
with 48 convolution layers was used (Szegedy et al., 2016). In the
prestigious ImageNet competition in 2015, this architecture was
the ﬁrst to beat a human performing the same classiﬁcation task.
Transfer learning is a common procedure for training classiﬁers
with fewer than c. 1000 000 images (Yosinski et al., 2014). That
is, we used a network that was pretrained on the large-scale
ImageNet ILSVRC 2012 dataset (http://www.image-net.org/cha
llenges/LSVRC/) before utilising it for our training. The classi-
ﬁers were trained for 170 epochs (i.e. complete training cycles)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The purpose of the deep learning model in this context is for classification. Specifically, the Convolutional Neural Network (CNN) classifier is being trained to identify different species of pollen grains from microscopic images. The goal is to accurately classify these pollen grains based on their features extracted through the deep learning model.