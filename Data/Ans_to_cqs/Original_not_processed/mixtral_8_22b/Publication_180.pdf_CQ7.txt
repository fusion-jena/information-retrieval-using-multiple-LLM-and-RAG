Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

TensorFlow
TensorFlow is an open-source software platform (Abadi et al. 2016) 
that supports deep learning research and applications, having been 
released  by  researchers  at  Google  (Google  Brain  Team;  https://re-
search.google.com/teams/brain/).  We  adapted  and  configured 
TensorFlow  for  application  and  use  in  our  project  via  Python. We 
adjusted  two  parameters  from  their  default  values:  validation  per-
centage and number of training steps. Although the default setting 
for validation percentage was 10%, given small numbers of images 
available for some species, we had to increase this number to 16%. 
For number of training steps, although the default value was 4000 
steps,  we  explored  different  numbers  and  compared  the  results  to 
find  the  optimum  balance  between  computing  time  and  classifica-
tion efficiency.

Key words: Chagas disease, TensorFlow, deep learning, Triatominae, automated species identification

deep learning? Cell Syst. 2: 12–14.

Ramsey, J. M., M. Elizondo-Cano, G. Sanchez-González, A. Peña-Nieves, and 
A. Figueroa-Lara. 2014. Opportunity cost for early treatment of Chagas 
disease in Mexico. Plos Negl. Trop. Dis. 8: e2776.

Ramsey,  J.  M.,  A.  T.  Peterson,  O.  Carmona-Castro,  D.  A.  Moo-Llanes,  Y. 
Nakazawa, M. Butrick, E. Tun-Ku, K. d. la Cruz-Félix, and C. N. Ibarra-
Cerdeña.  2015.  Atlas  of  Mexican  Triatominae  (Reduviidae:  Hemiptera) 
and  vector  transmission  of  Chagas  disease.  Mem.  Inst.  Oswaldo  Cruz. 
110: 339–352.

Schmidhuber, J. 2015. Deep learning in neural networks: an overview. Neural 

Netw. 61: 85–117.

Schofield, C. J., J. Jannin, and R. Salvatella. 2006. The future of Chagas disease 

control. Trends Parasitol. 22: 583–588.

Coura, J. R., and P. A. Viñas. 2010. Chagas disease: a new worldwide chal-

Sinkins, S. P., and F. Gould. 2006. Gene drive systems for insect disease vectors. 

lenge. Nature. 465: S6–S7.

To evaluate the classifier, it is necessary to set some images aside 
from  classifier  development  entirely.  Given  the  limited  numbers  of 
photographs available for some of the species, we used a leave-one-
out  cross-validation  approach  for  evaluation.  That  is  to  say,  as  a 
trade-off between maximizing numbers of samples for training the 
classifier and optimizing computing time, in each round, we left out 
n images, or one image from among the n species in that country, 
with which to evaluate the model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors used a leave-one-out cross-validation approach for evaluating the classifier due to the limited number of photographs available for some species. This means that they left out 'n' images, or one image from among the 'n' species in that country, with which to evaluate the model. They also adjusted two parameters from their default values: validation percentage and number of training steps. The validation percentage was increased from 10% to 16% because of the small number of images available for some species. For the number of training steps, they explored different numbers and compared the results to find the optimal balance between computing time and classification efficiency. However, the exact method used to split the data into training, testing, and validation sets is not explicitly stated in the provided context.