Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Data-driven models depend on a number of parameters, known as 
hyperparameters,  which  are  employed  to  enhance  and  regulate  the 
learning  procedure.  Optimal  hyperparameter  selection 
leads  to 
improved model accuracy and enhanced prediction performance (Aze-
dou et al., 2023). To fine-tune hyperparameters in data-driven models, 
the development dataset (comprising all data records except the evalu-
ation data records) is divided into two categories: the training dataset 
and the tuning dataset. Given the size constrains of the dataset used in 
the  analysis  and  the  need  to  utilize  all  development  data  records  in 
training  to  enhance  the  modelâ€™s  generalization  ability,  k-fold  cross- 
validation  was  chosen  as  the  preferred  approach  for  hyperparameter 
tuning (Saha et al., 2022). In this technique, the development dataset is 
evenly divided into k groups. During each iteration, one group called the

2.5. Automated machine learning (AutoML) 

2.6. Generative adversarial networks (GANs) 

AutoML offers a substantial level of automation, encompassing tasks 
such  as  including  data  pre-processing,  algorithm  selection,  and  opti-
mizing hyperparameters. These individual steps can pose challenges for 
non-expert data scientists, creating substantial barriers to designing and 
implementing algorithms effectively. Consequently, AutoML was intro-
duced to streamline these intricate processes for non-experts, making it 
more accessible to use these techniques correctly and efficiently (Rah-
man et al., 2023). In this study, two AutoML models, AutoGluon and 
TabPFN, were employed. 

2.5.1. AutoGluon

The suitability of data-driven model predictions depends largely on 
both the quality and quantity of the data used to develop the models 
(Arashpour, 2023). A small training dataset often will lead to overfitting 
issues when developing machine learning models (Jiang et al., 2022). 
There can be several reasons for this, but typically this occurs because 
the small dataset do not satisfactorily represent all possible input data 
combinations. Lack of data will also force the model to learn from the 
noise  and  describe  it,  rather  than  capture  the  data  trends  (Peng  and 
Nagata,  2020).  In  the  context  of  modelling  fire  behaviour,  obtaining 
sufficient  experimental  or  wildfire  spread  data  is  challenging  due  to 
operational, safety, and legal constraints (Anderson et al., 2015); with 
the field of study considered to be data poor (Gould et al. 2024). Syn-
thetic data generation provides a method to enhance real-world datasets

EcologicalInformatics82(2024)1027119S. Khanmohammadi et al.                                                                                                                                                                                                                    

line with the fact that the dataset is limited, comprising only 113 data 
records.  TABPFN  is  better  suited  to  perform  well  on  such  a  limited 
dataset (Hollmann et al., 2022).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The provided context does not mention any specific datasets used in the deep learning pipeline, such as MNIST, CIFAR, or ImageNet. However, it discusses using a limited dataset consisting of 113 data records for modeling fire behavior. Additionally, synthetic data generation is mentioned as a way to enhance real-world datasets.

Based on the given information, we cannot provide the exact datasets used in the deep learning pipeline. It appears that the authors have utilized a custom dataset related to their research topic, i.e., modeling fire behavior, along with potentially employing synthetic data generation methods.