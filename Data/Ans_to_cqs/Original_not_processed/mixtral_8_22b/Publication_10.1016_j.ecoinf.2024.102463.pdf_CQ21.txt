Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

hyperparameters for model architectures.  

2.  Partial training: Models are partially trained (on a small fraction of 
the data) to quickly eliminate underperforming configurations.  
3.  Successive Halving: The remaining configurations are grouped into 
sets of different sizes, and the associated models are trained further. 
The best-performing configurations in each set are promoted to the 
next  stage,  while 
the  under-performing  configurations  are 
eliminated. 

4. Repeat: Steps 2 and 3 are repeated until only one configuration re-
mains, which is then considered the best configuration found.

described in the next section. 

During the training of the model, the data is then standardized. In 
section 4, one of the three datasets will be defined as a training base, on 
which the standardizaion parameters will be calculated and applied to 
the  other  two  datasets  considered  as  test  base.  The  best  result  of  the 
optimisation will allow us to determine the base that will be used for 
training. 

4. Model optimization: Determination hyperparameters and 
parameter training 

4.1. Optimisation algorithm and experimental design

the role of training base and test base of each system is swapped. The 
Hyperband algorithm is applied to each database to determine the best 
model (hyperparameters + parameters). This first treatment will allow 
us to identify the most suitable database to be the training base.

None. 

Data availability 

All methods were written in the Python language and in the PyCharm 
environment 
machine 
(https://www.jetbrains.com/pycharm/). 
learning  methods  were  developed  using  the  freely  available  Keras  li-
brary  (Chollet,  2018)  at  https://github.com/fchollet/keras  with  Ten-
sorflow backend. Free and open-source codes have been employed to 
perform  the  overall  analysis:  the  hyperparameters  ofthe  model  were 
optimised  using  the  custom  HyperBand  algorithm  which  allows  to 
optimize the network architecture with the optimal length of the history. 

8. Conclusion 

Acknowledgement

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't any information about specific postprocessing steps mentioned in the given context. However, based on common practices in machine learning, some possible postprocessing steps could include calculating metrics such as accuracy, precision, recall, or F1 score; creating confusion matrices to visualize the performance of the classifier; generating saliency maps to understand what parts of the input data contribute most to the predictions made by the model; or performing cross-validation to ensure the robustness of the results. These steps can help evaluate the quality of the model and improve its performance if necessary.