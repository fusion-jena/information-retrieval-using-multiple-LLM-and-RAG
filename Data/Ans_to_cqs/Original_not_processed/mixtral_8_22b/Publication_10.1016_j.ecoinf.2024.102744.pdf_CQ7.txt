Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

feature  images  while  retaining  crucial  features.  The  Dropout  layer  is  integrated  to  mitigate 

overfitting. Additionally, the Global Average Pooling layer summarizes features, generating input 

for the fully connected layer. This layer also facilitates the visualization of regions relied upon by 

the network for predictions. The subsequent three fully connected layers generate the predicted 

class for the original image 

Table 1: Main parameters of the classification network 

[

Input size 

Output size 

Journal Pre-proof

[

[

[

Parameters 

  conv, strides 1] 

  conv, strides 1] 

  max pool 

  conv, strides 1] 

  conv, strides 1] 

Probability 0.5 

  max pool 

[

  conv, strides 1] 

Layers 

Convolution 

Convolution 

Pooling 

Convolution 

Convolution 

Dropout 

Pooling 

Convolution 

Global Average Pooling 

Dense 

Dense 

Classification layer (Dense) 

128 

128 

128 

128 

128 

128 

1 

- 

- 

- 

-

loads  and  345  bee  images  without  pollen  loads.  Given  its  focus  on  pollen-bearing  and 

non-pollen-bearing  bee  classification,  we  utilize  this  dataset  to  assess  the  effectiveness  of  the 

Journal Pre-proof

Figure  11:  Examples  of  images  in  PollenDataset  [18]:  (a)  non-pollen-bearing  and  (b) 

pollen-bearing bees. 

We  utilize  K-fold  cross-validation  to  partition  the  dataset  into  5  distinct  subsets.  Each 

subset undergoes evaluation, and the final result is derived from the average of these evaluations. 

Parameters governing the training process include 200 epochs, a learning rate of 0.001, a batch 

size of 22, and the utilization of the Adam optimizer. The results attained through the proposed 

classification network devised in the first improvement. 

 
 
 
Journal Pre-proof

method  are  presented  in  Table  2,  whereas  the  normalized  matrix  is  depicted  in  Fig.  12.

VnPollenBee dataset. The best metrics values are shown in bold font. 

Method 

Evaluation metrics 

Journal Pre-proof

Our proposed methods 

Baseline methods 

0.12  0.004 

0.15  0.009 

0.086  0.03 

0.99 

0.99 

0.58 

0.96 

0.41 

0.91 

0.85 

0.88 

0.88 

MR 

Yolov5 + classification  0.11 

Yolov5 + focal loss 

Yolov5 [39] 

Faster RCNN [40] 

0.91 

0.93 

0.70 

0.93 

FAR  Precision  Recall  F1-score 

Faster RCNN 

+ Overlap Sampler 

0.07 

0.01 

0.99 

0.93 

0.95 

Figure 14: Evaluation metrics of the pollen-bearing bee detection results. 

Figure 15: Detection results of the proposed improvement: (above) YOLOv5 + focal loss, (below) 

Faster  RCNN  +  Overlap  sampler.  The  green  and  red  boxes  indicate  pollen-bearing  and 

 
 
Journal Pre-proof

non-pollen-bearing bees, respectively. Values indicate the confidence score. 

Furthermore,  Fig.  15  depicts  some  detection  outcomes  of  the  second  proposed

Journal Pre-proof

Accuracy 

Dataset 

Mean 

99.3 

99.3 

98.4 

97.9 

97.9 

Fold 1  Fold 2  Fold 3  Fold 4  Fold 5 

97.8 

Figure 12: Normalized confusion matrix obtained with the proposed classification method on the 

Table 2: Accuracy obtained for each fold and mean accuracy for all folds. 

and non-pollen-bearing bees. 

validation set from PollenDataset. 

 
 
 
Journal Pre-proof

Table  3:  Comparison  between  the  proposed  and  state-of-the-art  classification  methods  on 

PollenDataset. The highest accuracy is shown in bold font, while the second-highest values are 

shown in underline font. 

Methods 

Architecture  Accuracy 

Method in [18] 

Method in [18] 

1-Layer 

VGG16 

96.4 

87.2 

5.3. Pollen bearing bee detection results 

Figure 13: GradCAM visualization of the classification network decision. 

90.2 

96.4 

98.4 

The proposed classification method 

VGG19 

5-Layer 

2-Layer 

Method in [28] 

Method in [18] 

Journal Pre-proof

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
K-fold cross-validation was used to split the data for deep learning model training. In this case, the dataset was divided into five distinct subsets. Each subset underwent evaluation, and the final result was derived from the average of these evaluations.

Answer:::

%Explanation
This response provides a concise and accurate answer to the query based on the given context. It explains that K-fold cross-validation was used to divide the dataset into five distinct subsets for deep learning model training. Each subset was evaluated separately, and the final result was calculated as the average of these evaluations.