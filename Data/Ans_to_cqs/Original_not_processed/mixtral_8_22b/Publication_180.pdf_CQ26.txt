Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

TensorFlow
TensorFlow is an open-source software platform (Abadi et al. 2016) 
that supports deep learning research and applications, having been 
released  by  researchers  at  Google  (Google  Brain  Team;  https://re-
search.google.com/teams/brain/).  We  adapted  and  configured 
TensorFlow  for  application  and  use  in  our  project  via  Python. We 
adjusted  two  parameters  from  their  default  values:  validation  per-
centage and number of training steps. Although the default setting 
for validation percentage was 10%, given small numbers of images 
available for some species, we had to increase this number to 16%. 
For number of training steps, although the default value was 4000 
steps,  we  explored  different  numbers  and  compared  the  results  to 
find  the  optimum  balance  between  computing  time  and  classifica-
tion efficiency.

Key words: Chagas disease, TensorFlow, deep learning, Triatominae, automated species identification

l

u
s
e
r
o
n
0
8
S
e
p
e
m
b
e
r
2
0
2
4

t

 
 
 
 
 
 
 
 
 
 
high  capability  of  DNNs  has  resulted  in  widespread  use  of  these 
techniques in other such inference challenges (Schmidhuber 2015). 
DNNs have outperformed traditional methods (e.g., linear discrim-
inant  analyses)  in  various  classification  tasks  (Schmidhuber  2015). 
Here, we used TensorFlow (Abadi et al. 2016), an open-source soft-
ware  platform,  representing  the  most  recent  addition  to  the  deep 
learning  toolbox  (Rampasek  and  Goldenberg  2016;  Google  Brain 
Team;  https://research.google.com/teams/brain/),  to  explore  the 
challenge of automated Chagas disease vector identification.

A  crucial  advantage  of  using  TensorFlow  was  eliminating  the 
need for preprocessing images for our identification system. That is, 
we  compared TensorFlow  classification  performance  based  on  the 
cleaned  and  raw  images  for  the  Mexican  species,  which  were  the 
most challenging to our statistical classifiers (Gurgel-Gonçalves et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions that a crucial advantage of using TensorFlow was eliminating the need for preprocessing images for their identification system. This suggests that they did not employ any preprocessing techniques like stratified splitting, oversampling, undersampling, or diverse data collection. Instead, they directly compared TensorFlow's classification performance based on cleaned and raw images.

Based on general knowledge, there are several techniques used to address data bias during preprocessing of the deep learning pipeline:

1. Stratified Splitting: This technique involves dividing the dataset into training and testing sets while maintaining the same distribution of classes in both sets. It helps prevent overfitting and ensures that the model learns from all classes equally.

2. Oversampling: In cases where one class has significantly fewer samples than others, oversampling can be employed to create synthetic examples of the minority class. This balances the dataset and improves the model's ability to learn from underrepresented classes.

3. Undersampling: Contrary to oversampling, undersampling reduces the size of the majority class to match the minority class. While this may lead to loss of valuable information, it can help improve the overall performance of the model.

4. Diverse Data Collection: Collecting more diverse data can also help mitigate data bias. By gathering data from multiple sources, demographics, or environments, the model becomes better equipped to handle real-world scenarios and reduce biases introduced by limited datasets.