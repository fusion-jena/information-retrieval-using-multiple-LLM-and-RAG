Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

monitoring  globally  and  for  efficient  pest  management  (Preti  et  al., 
2021). Deep-learning methods are increasingly used for classification in 
many fields and are emerging in entomology (Høye et al., 2021). Such 
methods require large training datasets to provide robust predictions, 
which has so far been a limiting factor in entomological applications. 
Specifically,  insects  are  very  diverse  and  their  abundance  is  highly 
variable,  which  often  results  in  unbalanced  datasets  with  numerous 
classes  nested  inside  each  other  in  a  taxonomic  hierarchy.  As  these 
methods mature and are implemented in monitoring programs, the de-
mand for greater taxonomic resolution of classifications will increase. So 
far, the level of fine-grained classification is still rather limited, not least 
because classification models rely on training data where images have 
species labels assigned to them.

Table 4 
Average performance (Avg) and standard deviation (SD) for five trained models. Average precision, recall and F1-score for trained ResNet50 and EfficientNetB3 
(EffNetB3) models modified for multitask learning (MTL) with transfer learning using pre-trained weights from ImageNet. The models are trained and validated on the 
TLm  dataset. The models ResNet50, EfficientNetB3 are trained without MTL.  

Model 

Level 

ResNet50MTL 
EffNetB3MTL 

ResNet50MTL 
EffNetB3MTL 

ResNet50MTL 
EffNetB3MTL 

ResNet50 
EffNetB3 

L1 Order 
L1 Order 

L2 Family 
L2 Family 

L3 Species 
L3 Species 

Species 
Species 

Avg 

0.990 
0.986 

0.987 
0.984 

0.955 
0.948 

0.955 
0.953 

Precision 

SD (10

(cid:0) 3) 

(1.0) 
(4.4) 

(0.8) 
(3.1) 

(4.3) 
(5.2) 

(3.3) 
(2.5) 

Avg 

0.991 
0.993 

0.986 
0.988 

0.961 
0.966 

0.957 
0.966 

Recall 

SD (10

(cid:0) 3) 

(1.1) 
(0.5) 

(0.9) 
(0.7) 

(9.8) 
(5.1) 

(7.3) 
(2.5) 

Avg 

0.991 
0.989 

0.987 
0.986 

0.957 
0.956 

0.955 
0.959

Rl = (Wl2*σrelu(Wl1*R0 + bl1)) + bl2)

(2) 

Here  Wl1  and  Wl2  represent  the  weights,  and  bl1, bl2  represent  the 
biases for the independent FC layer representation. We apply dropout 
regularization  in  the  forward  pass  during  training  so  that  random 

EcologicalInformatics77(2023)1022784K. Bjerge et al.

bounding boxes, in the training dataset, are within this size. Examples of 
full resolution TL images and cropped images of insects may be found in 
A.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific methods used for collecting raw data in the deep learning pipeline. However, it can be inferred that the authors use image data for their study, specifically focusing on insect species identification. They likely collect these images through field surveys or potentially by utilizing existing databases or public datasets containing insect images. Additionally, they might employ various sensors such as cameras or drones to capture high-quality images of insects in their natural habitats. It is also possible that they use bounding box techniques to isolate individual insects within larger images before feeding them into the deep learning model. Nevertheless, the exact methodologies employed for gathering raw data remain undisclosed in the given information.