Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

1.  Dimension reduction by principal component analysis (PCA) 
The first step is to express raw data to functions using 

Xj
s(t) = Xs(t) =

∑P

m=1

cs,j,mbm(t)

(4)  

where b1(t), ….., bP(t) represents the collection of first P basis functions 
(Fourier, Spline, etc). 

Let us recall some FDA notions useful for PCA. The empirical func-

2.2.1. Aggregated data modeling 

To compare with the benchmark work Diogoul et al. (2020), we first 
modeled the layer descriptors by the environmental data, aggregating 
them through the mean. The aggregated variables are: 

tional mean of Xj

s(.) is: 

Xj,n(t) =

1
n

∑

Xj
s(t)

s∈(s1,…,sn)

Xj
s =

1
Ds

∑Ds

p=1

(cid:0)

)

,

tp

Xj
s

(1)  

and the empirical covariance function: 
∑

)(cid:0)

(cid:0)

̂cj,n(t, u) =

1
n (cid:0) 1

s∈(s1,…,sn)

Xj
s(t) (cid:0) Xj,n(t)

Xj
s(u) (cid:0) Xj,n(u)

(5)  

(6) 

)
.

where  Ds  is  the  number  of  depth  where  data  are  available  and 
s ∈ (s1, …, sn).

In  this  study,  we  conducted  an  analysis  of  a  multifrequency  acoustics  dataset  acquired  from  scientific 
echosounders  in  the  West  African  water.  Our  objective  was  to  explore  the  spatial  arrangement  of  marine  or-
ganism aggregations. We investigated various attributes of these intricate biological entities, such as thickness, 
relative density, and depth, in relation to their surroundings. These environmental conditions were represented 
at a fine scale using a towed multiparameter system. This study is closely intertwined with two key domains: 
Fisheries acoustics techniques and functional data analysis. Fisheries acoustics techniques facilitate the collection 
of high-resolution spatial and temporal data concerning marine organisms at various depths and spatial scales, all 
without causing any disturbance. On the other hand, spatial-functional data analysis is a statistical approach for

Fig. 5. Principal Component Analysis (PCA: PC1 on x-axis and PC2 on y-axis) followed by classification (CAH) (red: Cluster 1; blue: Cluster 2) of the mean envi-
ronmental parameters (sea temperature, fluorescence, turbidity, and salinity) measured within the minimum and maximum depths of the sound scattering layer (SSL) 
at different frequencies; 38, 70, 120, and 200 kHz and bottom depth, grouped by diel period (day, sunset, night and sunrise) over Senegalese waters (southern 
continental  shelf)  during  the  AWA  sea  survey.  (For  interpretation  of  the  references  to  colour  in  this  figure  legend,  the  reader  is  referred  to  the  web  version  of 
this article.) 

3.2.2. Clustering

examining  data  characterised  by  functional  attributes  distributed  across  a  spatial  domain.  This  analysis  en-
compasses dimension reduction techniques, as well as supervised and unsupervised methods, which take into 
consideration spatial dependencies within extensive datasets.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the data format used in the deep learning pipeline is not explicitly mentioned. However, considering the nature of the study, which involves analyzing a multifrequency acoustic dataset acquired from scientific echosounders in West African waters, it can be inferred that the data format used is likely related to acoustic signals or waveforms. Acoustic data is typically stored in formats like.wav files for audio signals or specific binary formats for more complex acoustic data. In this case, the data might include information about marine organism aggregations, such as thickness, relative density, and depth, in relation to their environment. Therefore, while the exact data format is not specified, it is reasonable to assume that the data format used in the deep learning pipeline is related to acoustic signal processing rather than common formats like images, videos, or CSV files.