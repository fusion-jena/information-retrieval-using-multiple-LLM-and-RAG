Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4.3. The scalability of the proposed framework

Tian, D., Li, M.C., Shi, J., Shen, Y., Han, S., 2021. On-site text classification and 

knowledge mining for large-scale projects construction by integrated intelligent 
approach. Adv. Eng. Inform. 49, 101355. 

USEPA, 2023. United States Environmental Protection Agency. https://www.epa.gov/su 

perfund/superfund-community-involvement (accessed 22 May 2023).  

Wang, J.S., Jia, Y.H., 2021. Social media’s influence on air quality improvement: 

evidence from China. J. Clean. Prod. 298, 126769. 

Wang, Y., Sun, Y.N., Ma, Z.C., Gao, L.S., Xu, Y., 2020. An ERNIE-based joint model for 

Chinese named entity recognition. Appl. Sci. Basel. 10, 5711. 

Wang, Y.N., Zhang, R.L., Worden, S., Cao, H.L., Li, C.H., 2021. Public participation in 
environmental governance initiatives of chemical industrial parks. J. Clean. Prod. 
305, 127092.

2.2. Theme perception technology 

2.2.1. Latent Dirichlet allocation 

LDA—  proposed  by  Blei  et  al.  (2003)—is  a  topic  model  for  text 
generation based on natural language processing. The basic idea is that 
any text (in this study, microblog tweets) is composed of multiple topics 
with a polynomial distribution and each topic is composed of multiple 
words  with  a  polynomial  distribution.  By  analyzing  the  polynomial 
distribution of words for each topic, similar topics are aggregated into a 
topic category, and topic classification of the text is achieved (Tautorat 
et al., 2023). The advantage of LDA is its unsupervised nature, which 
means that the input corpus does not require labeled data, making it an 
ideal technique for topic modeling when labeled topics are not available 
and the quantity of input texts is large (Palanichamy et al., 2021; Sun 
and Yin, 2017).

Machine learning methods require text preprocessing, such as word 
segmentation and stop word removal, followed by the selection of a text 
portion to manually annotate emotions for accuracy verification. Among 
machine  learning  models,  the  enhanced  representation  through 
knowledge  integration  (ERNIE)  model  achieved  significant  results  in 
previous studies by learning prior semantic relationships and word order 
features from massive amounts of data (Sun et al., 2019). The ERNIE 
model  directly  models  prior  semantic  knowledge  units,  thereby 
enhancing model semantic representation (Wang et al., 2020). Test re-
sults for various Chinese tasks showed that the model performed better 
than  the  bidirectional  encoder  representations  from  the  transformer 
model proposed by Google AI (Sun et al., 2019). At the International 
Workshop on Semantic Evaluation 2020, the ERNIE model earned first 
place  for  a  mixed-language  emotional  analysis  task.  Detailed  de-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the specific deep learning frameworks used to build the model. However, it mentions the use of machine learning methods and specifically discusses the Enhanced Representation through Knowledge Integration (ERNIE) model. While the context does not explicitly state whether TensorFlow or PyTorch were used, these are popular deep learning frameworks that could have been utilized. Without further context, it cannot be definitively stated which framework was used to build the deep learning model.