Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.5. Hyperparameter optimization 

The model training process determines the values for the trainable 
parameters  of  a  model,  e.g.,  Table  4 shows  the  size  of  the  model pa-
rameters. In addition, a DNN model also has other parameters that need 
to be selected, e.g., batch size, that determines the model performance. 
The  model  parameters  define  the  model  and  are  termed  as  hyper-
parameters. Each hyperparameter has a range of values, from which an 
optimum  selection  can  improve  the  model  performance.  The  model 
hyperparameters could be in hundreds, presenting a very large search 
space, but these differ in their relative importance. The common ones for 
a DNN are learning rate, batch size, and dropout.

Hyperparameter  optimization  was  illustrated  with  only  a  single 
dataset  and  one  hyperparameter.  Such  limited  explorations  could  be 
useful unless the aim is to optimize a single model by considering all the 
important model hyperparameters (Kuncheva et al., 2023). The hyper-
parameter  tuning  was  shown  to  improve  the  model  performance 
(Fig. 13) for the selected models. Only a single hyperparameter, that is, 
the learning rate was optimized with hyperband and Bayesian Optimi-
zation techniques. In actual practice, more hyperparameters would need 
to  be  considered  to  design  an  optimized  model.  Another  factor  to 
consider  is  that  different  models  have  different  number  and  types  of 
hyperparameters,  and  trying  to  fully  optimize  each  will  require 
considerable compute resources and time as the hyperparameter search 
space would be large.

Hyperparameter optimization techniques make it simpler to search 
for an optimum hyperparameter configuration, however, it can take a 
significant amount of time depending on the number of hyperparameter 
values being searched (Nazir et al., 2020a). We selected the Keras Tuner 
(O'Malley et al., 2019) which provides Random Search, Hyperband, and 
Bayesian  Optimization  algorithms.  In  this  paper,  we  used  Hyperband 
and Bayesian Optimization as these two algorithms are superior to the 
other search algorithms available in the Keras Tuner.

4.4. Hyperparameter optimization 

The hyperparameter optimization results for the learning rate for the 
EfficientNetV2B0  and  MobileNetV2  model  were  obtained  using  the 
Hyperband and Bayesian Optimization for the Extinction dataset. The 
optimum values determined using the Keras Tuner for the learning rate 
were 0.00001 for both the models. The F1-Scores were then obtained for 
the  optimal  learning  rate  (0.00001),  a  higher  value  (0.0001),  and  a 
lower value (0.000001) and are shown in Fig. 13. It can be seen that the 

optimal learning rate found through the hyperparameter optimization 
provides better model classification performance for the selected models 
and the dataset. 

4.5. Visualising predictions

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In the given context, hyperparameter optimization is performed using the Keras Tuner library, which offers three main algorithms: Random Search, Hyperband, and Bayesian Optimization. For the purpose of this study, Hyperband and Bayesian Optimization were chosen due to their superiority over other search algorithms available in the Keras Tuner.

Hyperband is a multi-armed bandit algorithm designed for hyperparameter optimization. It combines elements of random search and successive halving to efficiently allocate resources across multiple configurations. This allows for faster convergence towards promising hyperparameter settings compared to traditional methods like grid or random search.

On the other hand, Bayesian Optimization is a sequential model-based approach that uses probabilistic models to guide the search for optimal hyperparameters. By iteratively updating its belief about the underlying function based on previous evaluations, Bayesian Optimization aims to find the best possible set of hyperparameters within fewer iterations than exhaustive search strategies.

In this particular case, the hyperparameter optimization focused on finding the optimal learning rate for EfficientNetV2B0 and MobileNetV2 models when applied to the Extinction dataset. Both Hyperband and Bayesian Optimization techniques were employed to determine the optimum learning rate value, resulting in a value of 0.00001 for both models. These findings demonstrate how advanced hyperparameter optimization techniques can significantly enhance model performance by identifying the most suitable hyperparameter configurations.