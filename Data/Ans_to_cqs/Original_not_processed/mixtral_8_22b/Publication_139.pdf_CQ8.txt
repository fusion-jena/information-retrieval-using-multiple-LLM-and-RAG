Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

However, deep learning approaches are not without limitations, such 
as a lack of generalizablity to different recording sites with a different set 
of  target  species.  However,  even  with  state-of-the-art  approaches, 
location-specific  training  data  is  still  often  necessary  to  yield  crucial 
performance improvements (Kahl et al., 2019; Lasseck, 2019). For this 
reason, the neural network architecture implemented in this work was 
designed  to  be  retrained  in  under  20  min,  making  inevitable  dataset 
modifications for new recording sites practical.

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

Long-term deep learning-facilitated environmental acoustic monitoring in 
the Capital Region of New York State 

M.M. Morgan *, J. Braasch 

School of Architecture (Architectural Acoustics), Rensselaer Polytechnic Institute, Troy, NY 12180, USA   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Acoustic environment 
Deep learning 
Biophony 
Passive acoustic monitoring

Transfer learning, where a model pre-trained on one dataset is re- 
trained  to  classify  a  similar  datset,  is  one  convenient  approach  to 
effectively  utilize  the  power  of  CNNs.  Well-known  pre-trained  archi-
tectures such as Inception, MobileNet, and Resnet50 have recently been 
used with great success for the classification of birds in soundscape re-
cordings (Florentin et al., 2020; He et al., 2016; Howard et al., 2017; 
Incze et al., 2018; LeBien et al., 2020; Sevilla and Glotin, 2017; Szegedy 
et  al.,  2014).  Such  networks  are  typically  pre-trained  on  large  image 
databases such as ImageNet, which contains over one million samples 
distributed across 1000 classes (Deng et al., 2009). However, in cases 
where  targeting  foreground  species  is  the  main  task,  or  with  more 
acoustically sparse soundscapes, CNN architectures with far fewer (<10) 
convolutional layers have proven more than sufficient, and indeed, may

This paper seeks to bridge a  similar gap between theoretical deep 
learning-based  bioacoustic  classification  research  and  applied  studies 
that are either limited by time-consuming data analysis techniques, or 
constrained to report only on general soundscape trends, without access 
to species-specific activity. Rather than applying deep learning tools to 
an  existing,  de-contextualized  bioacoustic  dataset  in  order  to  make 
minute  classification  performance  improvements,  this  work  proposes 
and applies a methodological framework for automatic analysis of an 
ongoing terrestrial bioacoustics research project.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The article does not provide information about the availability of the code repository for the deep learning pipeline used in their study. Therefore, it is not possible to determine where the code repository might be located (e.g., GitHub, GitLab, BitBucket).