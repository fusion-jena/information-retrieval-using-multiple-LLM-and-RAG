Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics72(2022)1019047A. Jamali et al.                                                                                                                                                                                                                                  

Table 5 
Results  of  the  proposed  deep  model  (ViT  = Vision  Transformer,  ST  = Swin 
Transformer, KI=Kappa index, AA = Average accuracy, OA = Overall accuracy).  

Class 

ViT 

ST 

CoAtNet 

CNN 
+ ST 
(ours) 

GAN 
+ ST 
(ours) 

3DUNetGSFormer 
(ours) 

Bog 
Fen 
Marsh 
Swamp 
Shallow 
water 

Urban 
Deep 

water 
Upland 
KI (%) 
OA (%) 
AA (%) 
Time (h) 

0.59 
0 
0.46 
0 
0.83 

0.97 
0.93 

0.86 
0.79 
0.88 
0.76 
0.92 

0.99 
0.97 

0.91 
0.86 
0.94 
0.82 
0.98 

0.99 
1 

0.87 
71.31 
75.62 
62.96 
2.2 

0.96 
90.66 
91.99 
88.67 
1.5 

0.97 
94.67 
95.43 
93.21 
5 

0.82 
0.76 
0.95 
0.89 
0.91 

0.98 
1 

0.98 
92.84 
93.87 
90.16 
1.5 

0.89 
0.83 
0.88 
0.9 
0.96 

0.99 
0.99

On the other hand, transformers are the most frequently deployed 
techniques in natural language processing (NLP) (Vaswani et al., 2017). 
Researchers  are now exploring the capability of transformers  in com-
puter  vision  and  remote  sensing,  given  their  huge  success  in  the  lan-
guage domain. They have recently proven to be practical in a variety of 
applications,  including  the  classification  of  remote  sensing  imagery 
(Bazi et al., 2021; D. Hong et al., 2021; J. He et al., 2020). Transformers 
utilize  an  attention-based  approach  rather  than  using  convolutional 
operations utilized by CNNs. As such, transformers, unlike CNNs, can 
acquire global contextual knowledge through self-attention. This means 
that transformers have a better generalization capability as compared to 
CNN algorithms. For example, the state-of-the-art vision transformer of 
Swin Transformer incorporates a hierarchical transformer with shifting

Fig.  8. Wetland  classification  maps  in  pilot  site  of  a)  Avalon,  Grand  Falls-Windsor,  and  Gros  Morne  National  Park  using  b)  Vision  Transformer  (ViT),  c)  Swin 
Transformer, d) CoAtNet, and e) proposed end-to-end algorithm. 

EcologicalInformatics72(2022)1019048A. Jamali et al.                                                                                                                                                                                                                                  

Fig. 9. Examples of extracted features of an Urban (road) object utilizing three convolutional layers of the CNN network.

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

3DUNetGSFormer: A deep learning pipeline for complex wetland mapping 
using generative adversarial networks and Swin transformer

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The pipeline uses several types of deep learning models, including Convolutional Neural Networks (CNN), Generative Adversarial Networks (GAN), and Swin Transformer. Specifically, the paper mentions a combination of GAN + ST (Swin Transformer) and a 3DUNetGSFormer model, which also utilizes Swin Transformer. Additionally, the paper compares these models against other popular architectures like ViT (Vision Transformer) and CoAtNet. Therefore, it can be concluded that the pipeline primarily employs Transformer-based models, along with some use of CNNs and GANs.