Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Detection:  A  Survey. Int  J  Comput  Vis 128, 261–318 
https://doi.org/10.1007/s11263-019-01247-4 
J. Long, E. Shelhamer and T. Darrell,  "Fully convolutional networks for 
semantic segmentation," in 2015 IEEE Conference on Computer Vision 
and Pattern Recognition (CVPR), Boston, MA, USA, 2015 pp. 3431-3440. 
doi: 10.1109/CVPR.2015.7298965 

[4] 

[5]  Hafiz, A.M., Bhat, G.M. A survey on instance segmentation: state of the 
(2020). 

Retr 9, 171–189 

art. Int 
https://doi.org/10.1007/s13735-020-00195-x 

Multimed 

Info 

J 

[6]  Dai, Jifeng & Li, Yi & He, Kaiming & Sun, Jian. (2016). R-fcn: Object 

detection via region-based fully convolutional networks. 

[7]  Szegedy, Christian & Toshev, Alexander & Erhan, Dumitru. (2013). Deep 

Neural Networks for Object Detection. 1-9.

[12]  Wu,  H.,  Zhang,  J.,  Huang,  K.,  Liang,  K.,  &  Yu,  Y.  (2019).  FastFCN: 
the  Backbone  for  Semantic 

Rethinking  Dilated  Convolution 
in 
Segmentation. ArXiv, abs/1903.11816. 

[13]  K.  He,  G.  Gkioxari,  P.  Dollár  and  R.  Girshick,  "Mask  R-CNN," 2017 
IEEE  International  Conference  on  Computer  Vision  (ICCV),  2017,  pp. 
2980-2988, doi: 10.1109/ICCV.2017.322. 

[14]  Ronneberger  O.,  Fischer  P.,  Brox  T.  (2015)  U-Net:  Convolutional 
Networks for Biomedical Image Segmentation. In: Navab N., Hornegger 
J., Wells W., Frangi A. (eds) Medical Image Computing and Computer-
Assisted Intervention – MICCAI 2015. MICCAI 2015. Lecture Notes in 
Computer Science, vol 9351. Springer, Cham.

The  most  time-consuming  step  after  data  gathering  is 
annotation.  Annotation  of  images  means  manual  labelling  of 
data by assigning some keywords/labels on the required areas in 
the  image  to  assign  metadata.  For  annotating  the  dataset,  the 
broders of objects were outlined to associate every single pixel 
of objects in an entire image with a particular tag/label. There 
are various tools available in the market to annotate the images, 
but  this  research  used  Computer  Vision  Annotation  Tool 
(CVAT) [21] which is developed by Intel for labelling of data. 
The annotation data was then converted into COCO 1.0 dataset 
which was formatted in JSON and it is a collection of object id, 
image id, category id, segmentation, area, bbox, attributes, etc. 
The illustration of the annotated data is shown in Fig. 2. Total 
number of objects that are annotated for training and validation 
datastet are 1884. Training image dataset contains totally 1031

both  separately  and  give  instance  segmentation  as  output.  So, 
Mask R-CNN is a combination of Faster R-CNN and FCN [19] 
models with some advancements where a parallel layer of FCN 
is added for the mask implementation in the Faster R-CNN head  
along with some extra convolutional layers on each Region of 
Interest [20] (RoI). 

A.  Data Collection and Annotation 

The data usually is obtained by using different means like 
scraping  from  the  web,  downloading  from  other  sources  or 
buying datasets from re-sellers etc. In the proposed system, the 
dataset will be created from scratch and annotated for custom 
training.  To  collect  the  data  images,  a  KaKaXi  fixed  camera 
shown in Fig. 3 has been used which takes images every hour 
within a fixed period of time each day. These images then get 
saved in  a database.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, the method utilized for collecting raw data in the deep learning pipeline is through the use of a fixed camera called KaKaXi. This camera captures images every hour within a fixed period of time each day, and these images are saved in a database. The process of creating a dataset from scratch and annotating it for custom training is also mentioned. However, no specific details about the use of surveys, sensors, or public datasets are provided in the given context. Therefore, based on the information available, we can only infer that one possible method for collecting raw data in the deep learning pipeline is through the use of cameras such as KaKaXi.