Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

algorithms character vector with the name(s) of the 
algorithms(s) used for the embedding procedure; 
ncov value for the target number of covariates to 
include in the final set; maxncov value for the 
maximum possible number of covariates to include in 
the final set; nthreads value for the number of cores to 
be used during parallel operations    

corcut value of the correlation coefficient threshold 
used for identifying collinearity; categories character 
vector with category-level covariate names; variables 
character vector with variable-level names

Table 1 
The three functions available in covsel (ver. 1.0.) with information on input data and arguments. See https://github.com/N-SDM/covsel and the function help files 
for additional details and examples.  

Function 

Description 

Common inputs 

Specific arguments 

covsel. filteralgo() 

Collinearity filtering (Step A) 

covsel. embed() 

Model-specific embedding (Step B) 

pa numeric vector of species presences (1) and 
absences (0); covdata data frame with continuous 
covariate data; weights (optional) numeric vector 
with the weights for each value in pa; force 
(optional) character vector with the name(s) of the 
covariate(s) to be forced in the final set 

covsel. filter() 

Wrapper function applying the collinearity 
filtering algorithm at each target level(s) 
(e.g. i: variable level; ii: category level; iii: 
all remainders) 

corcut value of the correlation coefficient threshold 
used for identifying collinearity

2.2. Step B: Model-specific embedding 

In Step B, covariates selected after Step A are used to fit models with 
embedded selection procedures. We use GLM with elastic-net regulari-
zation  (GLM-EN)  (Zou  and  Hastie,  2005),  GAM  with  null-space

76 
82 
92 

Fi 

22 
18 
8 

Rd 

Em 

2 
0 
0 

65 
83 
100 

Fi 

35 
17 
0 

Rd 

0 
0 
0 

Em 

82 
76 
94 

Fi 

18 
24 
6 

Rd 

0 
0 
0 

Em 

75 
81 
88 

Fi 

25 
19 
12 

Rd 

0 
0 
0 

Em 

88 
94 
88 

Fi 

12 
6 
12 

Rd 

0 
0 
0  

Fig. 4. Average computation time (seconds) for the 50 species needed for (A) running the overall covariate selection procedure and model fitting steps under each of 
the three main covariate selection procedures (“embedded”, “filter”, and “random”), and (B) model fitting only under each of the three main covariate selection 
procedures and by modelling algorithm (GLM: Generalized Linear Model, GAM: Generalized Additive Model, and RF: Random Forest). Wilcoxon tests were used to 
assess statistical significance in differences between methods with ****: p < .0001; ***: p < .001; **: p < .01; *: p < .05; ns: non-significant. 

(Fig. 2). 

3.4.2. Model accuracy

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it does not appear that a deep learning model such as Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), or Transformer is used in the pipeline. Instead, the context mentions the use of Generalized Linear Models (GLMs) with elastic-net regularization and Generalized Additive Models (GAMs) with null-space penalization. These are both traditional machine learning techniques rather than deep learning approaches. Therefore, there is no clear indication of any specific deep learning model being employed in this case.