Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5. Experimental Results

5.1. Experimental Setup. +e experiments were performed
on a computer running 64-bit Linux OS with two 2.3 GHz
Intel 8-core processors. All of the utilized predictive
models were implemented in the Python programming
language version 3.8.5. Moreover, deep learning model
(i.e., GRU-DNN) implementation is performed using

Hidden layer (s) Outputlayer ...GRUcellGRUcellGRUcellGRUcellGRUcellGRUcell...XXXX......Input layer...FClayerFClayerGRUlayer 8483, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8551167 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [28/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License8

Computational Intelligence and Neuroscience

5.5. GRU-DNN Hyperparameter Analysis. GRU-DNN
model is trained in a supervised learning fashion using lag
features (i.e., using K previous observations), where K
denotes the number of previous observations used in the
training and forecasting task. Typically, K is considered
as a hyperparameter that needs to be optimized. +ere-
fore, we performed a grid search method to obtain the
optimal K value. Figure 6 depicts the grid search for
diﬀerent values of K hyperparameter over search space
ranges from 1 to 15. Speciﬁcally, Figure 6(a) presents the
model performance for water temperature forecasting
using various K values, where K � 6 achieves the lowest
MAE error. Similarly, K � 4 is the optimal value for
signiﬁcant wave height
shown in
Figure 6(b). It is noteworthy that the experiments pre-
sented in Figure 7 are for the ﬁrst dataset of each fore-
casting problem, assuming that the rest of the datasets
have similar behaviour.

forecasting

as

+is paper aims to predict the SST and the SWH for the
Korea Hydrographic and Oceanographic Agency dataset.
+e proposed work is motivated by comparing the statistical,
machine learning, and deep learning models to understand
the performance gap of these models. +e results of this
work should provide scientiﬁc evidence on which model ﬁts
better the marine data. To anticipate the marine features
eﬃciently, the employed deep learning model combines the
gated recurrent units (GRU) with the regular neural net-
work. In the proposed architecture, the GRU layer is pre-
ceded by an input layer and followed by a fully connected
layer. As a result, the predicted values can be produced from
the output layer. To our knowledge, this is the ﬁrst use of a
GRU model architecture for forecasting SST and SWH.
Besides, four diﬀerent ML models have been utilized in the
current study, namely, Linear Regression (LR), Decision
Tree (DT), Support Vector Machine (SVM), and Random

uses the Mean Square Error (MSE) loss function, which is
provided by equation (5). +at is, the proposed GRU-DNN
model is trained with the goal of minimizing the loss
􏼉N
i�1 of N
function given a
training data
observations.

(Xi, Yi)
􏼈

min
w

1
N

N
􏽘
􏽮
j�1

Yj − F Xj, w
􏼐

􏼑

􏽯,

2

(5)

where w signiﬁes the network coeﬃcient, F: Rk ⟶ R1 is
the neural network ﬂow, and k denotes the size of the input
vector (i.e., number of lag features).

4.1.1. GRU-DNN Hyperparameter Optimization. +e opti-
mization of the proposed model hyperparameters is a part of
machine learning methods. +e model parameters (coeﬃ-
cients) utilized to govern the training task are as hyper-
parameters. Such parameters (e.g., learning rate, number of
lag order of ARIMA
layers/neurons of a network/layer,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The experimental setup mentioned in the context does not explicitly state the specific type of hardware resource used for training the deep learning model, such as GPUs or TPUs. However, it mentions that the experiments were performed on a computer running a 64-bit Linux OS with two 2.3 GHz Intel 8-core processors. Therefore, it can be inferred that the deep learning model was trained using CPU resources rather than GPU or TPU resources.