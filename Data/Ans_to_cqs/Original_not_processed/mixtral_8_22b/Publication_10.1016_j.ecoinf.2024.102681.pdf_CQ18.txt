Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

time window. These carefully curated datasets were then used for the 
model training process. This process involved an iterative approach to 
extract the weights assigned to the fully connected layers of the model, 
thus enabling the identification and analysis of evolving patterns in the 
weights associated with each specific influencing factor. 

Fig. 3. Monthly- and seasonal-scale drought propagation times for four land cover types. (a) Cropland (b) Forest land (c) Grassland (d) Unused land (e) seasonal 
scale. The width of each violin plot indicates the probability of drought propagation occurring at the corresponding SPEI scale, and the SPEI scale corresponding to 
the maximum probability of propagation in each month, which is the time of drought propagation in that month, is marked by a solid black line.

to  the  size  and  number  of  convolution  kernels  and  hyperparameters, 
such  as  the  learning  rate.  Introducing  the  hybrid  model  not  only  en-
hances  the  processing  power  of  the  model  but  also  makes  the  model 
more robust and better able to deal with the complexity of the drought 
propagation time and the relationship between the influencing factors. 
Notably,  after  embedding  LSTM  into  the  CNN,  even  without  any  ad-
justments to the hyperparameters, the model's prediction accuracy on 
the  testing  set  has  already  improved  by  about  20%  compared  to  the 
original CNN.

This study compiled a comprehensive dataset to delve deeper into 

EcologicalInformatics82(2024)1026814J. Long et al.                                                                                                                                                                                                                                     

Fig. 2. Schematic of the architecture of the CNN-LSTM(C-L) hybrid model.  

the temporal dynamics of various factors' influence on drought propa-
gation. This dataset encompassed various influencing factors alongside 
an  extensive  drought  propagation  time  series  spanning  from  January 
1950 to December 2020. By employing a sliding window method with a 
window  size  of  30  years  and  a  step  size  of  one  year,  we  successfully 
generated forty-two distinct datasets, each corresponding to a separate

For  this  study,  the  specific  implementation  steps  are  as  follows: 
Firstly,  the  data  of  drought  propagation  time  from  January  1950  to 
December 2020 were divided into training and testing sets in 6:4. Sub-
sequently, a 4 Ã— 2 matrix was constructed using values from eight de-
soil  moisture,  actual 
terminants: 
evapotranspiration, sunspots, ENSO, AO, and PDO. Feature maps were 
extracted  from  the  matrix  using  CNN,  and  the  LSTM  network  was 
employed to capture time dependency and accurately model the inter-
play  between  drought  propagation  times  and  the  eight  factors.  The 
specific architecture of the CNN-LSTM (C-L) hybrid model is shown in 
Fig. 2. In practical applications for datasets of different land cover types, 
the number of convolutional layers in the CNN is initially adjusted, as it 
has the greatest impact on model accuracy. Subsequently, the parame-
ters for the LSTM component are determined, followed by adjustments

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information regarding the strategy implemented to monitor the model performance during training. However, based on common machine learning practices, it can be inferred that the researchers might have employed techniques such as cross-validation or monitoring metrics like loss and accuracy on both the training and validation sets. Additionally, they may have utilized early stopping to prevent overfitting and ensure optimal model performance. Nevertheless, these assumptions cannot be confirmed without further details from the authors.