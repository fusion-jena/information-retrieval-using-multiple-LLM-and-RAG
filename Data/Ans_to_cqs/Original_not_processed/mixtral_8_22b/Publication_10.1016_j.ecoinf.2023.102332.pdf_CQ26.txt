Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., 2018. {BERT:} Pre-training of Deep 
Bidirectional Transformers for Language Understanding. CoRR abs/1810.0. 

Edwards, T., Jones, C.B., Corcoran, P., 2022. Identifying wildlife observations on Twitter. 

Ecol. Inform. 67, 101500. https://doi.org/10.1016/j.ecoinf.2021.101500. 

Egarter Vigl, L., Marsoner, T., Giombini, V., Pecher, C., Simion, H., Stemle, E., Tasser, E., 
Depellegrin, D., 2021. Harnessing artificial intelligence technology and social media 
data to support cultural ecosystem service assessments. People Nat. 3, 673–685. 
https://doi.org/10.1002/pan3.10199. 

Feinerer, I., Hornik, K., 2018. tm: Text mining package. R package version 0.7–6. Retrieved 

from. https://CRAN.R-proje. ct.org/package=tm.

the perceptions mentioned by hikers during their outdoor experience, 
we extracted the most frequent single words (unigrams) from Wikiloc 
posts.  The  extraction  of  unigrams  consisted  of  three  steps:  text  trans-
lation, data pre-processing, and  word frequency  counting. First,  since 
the text description included five different languages (French, English, 
Dutch,  Italian,  and  Spanish),  we  translated  all  text  descriptions  into 
English  using  DeepL  (https://www.deepl.com).  Second,  data  pre- 
processing  consists  of  using  natural  language  processing  (NLP) 
methods  to  perform  automated  text  mining  in  R,  primarily  using  the 
packages  tidytext  (Silge  and  Robinson,  2017)  and  tm  (Feinerer  and 
Hornik, 2018) for tokenization, lemmatization and English stop words 
removal based on a predefined list of common English words (e.g., and, 
the). An additional set of words such as the name of the country, towns,

representations. Sci. Rep. 12, 8043. https://doi.org/10.1038/s41598-022-12027-5. 
Günther, F., Dudschig, C., Kaup, B., 2015. LSAfun - an R package for computations based 
on latent semantic analysis. Behav. Res. Ther. 47, 930–944. https://doi.org/ 
10.3758/s13428-014-0529-0. 

Günther, F., Rinaldi, L., Marelli, M., 2019. Vector-space models of semantic 
representation from a cognitive perspective: a discussion of common 
misconceptions. Perspect. Psychol. Sci. 14, 1006–1033. https://doi.org/10.1177/ 
1745691619861372. 

Haines-Young, R., Potschin, M.B., 2018. Common International Classification of 

Ecosystem Services (CICES) V5.1: Guidance on the Application of the Revised 
Structure. Nottingham, United Kingdom. 

orientations and landscape preferences. Landsc. Urban Plan. 59, 1–11. https://doi. 
org/10.1016/S0169-2046(01)00243-2. 

Lampinen, J., Tuomi, M., Fischer, L.K., Neuenkamp, L., Alday, J.G., Bucharova, A.,

Word2vec  is  a  widely  known  word  embedding  technique  (e.g., 
Mikolov et al., 2013; Naili et al., 2017), and has been a successful tool for 
investigating CES from social media data (e.g., Gugulica and Burghardt, 
2023).  Word2vec  can  be  carried  out  in  two  ways:  by  creating  and 
training your own word2vec space based on two different architectures, 
namely, Skip-gram, which predicts the target word based on a nearby 
word, and Continuous Bag-of-Words (CBOW), which learns to predict a 
target word according to its context (Mikolov et al., 2013), or by using 
pre-trained  models (e.g.,  Baroni et al., 2014). Training a new  custom 
word2vec model requires a very large dataset, increases the computa-
tional effort, and could be biased by the geographic origin of the data. 
Therefore,  we  performed  the  semantic  analysis  using  the  pre-trained 
baroni  word2vec  model  provided  at  http://www.lingexp.uni-tuebin

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions some general approaches related to handling multilingual data and dealing with large datasets. For instance, the authors translate all text descriptions into English using DeepL to handle multiple languages. They also mention using pre-trained models like baroni word2vec instead of training a new custom word2vec model to reduce computational effort and potential geographical bias. These methods do not directly address data bias but help manage linguistic diversity and computational resources. To specifically tackle data bias, one might consider stratified sampling, oversampling, undersampling, or diverse data collection strategies, depending on the nature of the bias present in the dataset.

Reference(s):
[None]