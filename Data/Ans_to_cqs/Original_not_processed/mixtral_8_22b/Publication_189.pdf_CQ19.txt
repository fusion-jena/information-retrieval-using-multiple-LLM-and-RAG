Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

This  system  is  most  compatible  with  tensorflow  version 
1.14.0 and keras version 2.2.4 along with python 3.6. This model 
has been implemented on a machine with 1 GPU which uses 1 
Image per GPU and batch size for mrcnn training is  taken as a 
product of GPU and Images per GPU. The system used resnet 
50 and resnet 101 as backbone structures and used anchor boxes 
of ratio 32, 64, 128, 256, 512. The width and height of images 
in  this  research  is  fixed,  therefore  [a,640,640,3]  becomes  the 
image  shape  here  and  [a,640,640,1]  becomes  the  mask  shape 
where  a  is  the  number  of  training  images  and  true  masked 
images. For training on Mask R-CNN, 20 epochs with 500 steps 
each  are  being  used  for  training  images  and  100  steps  for 
validation images while evaluating the model. The learning rate, 
 used for heads layer training  has been  taken as 0.001 while 
during  all  layers  training    decayed  by  10.  For  weight

[12]  Wu,  H.,  Zhang,  J.,  Huang,  K.,  Liang,  K.,  &  Yu,  Y.  (2019).  FastFCN: 
the  Backbone  for  Semantic 

Rethinking  Dilated  Convolution 
in 
Segmentation. ArXiv, abs/1903.11816. 

[13]  K.  He,  G.  Gkioxari,  P.  Dollár  and  R.  Girshick,  "Mask  R-CNN," 2017 
IEEE  International  Conference  on  Computer  Vision  (ICCV),  2017,  pp. 
2980-2988, doi: 10.1109/ICCV.2017.322. 

[14]  Ronneberger  O.,  Fischer  P.,  Brox  T.  (2015)  U-Net:  Convolutional 
Networks for Biomedical Image Segmentation. In: Navab N., Hornegger 
J., Wells W., Frangi A. (eds) Medical Image Computing and Computer-
Assisted Intervention – MICCAI 2015. MICCAI 2015. Lecture Notes in 
Computer Science, vol 9351. Springer, Cham.

both  separately  and  give  instance  segmentation  as  output.  So, 
Mask R-CNN is a combination of Faster R-CNN and FCN [19] 
models with some advancements where a parallel layer of FCN 
is added for the mask implementation in the Faster R-CNN head  
along with some extra convolutional layers on each Region of 
Interest [20] (RoI). 

A.  Data Collection and Annotation 

The data usually is obtained by using different means like 
scraping  from  the  web,  downloading  from  other  sources  or 
buying datasets from re-sellers etc. In the proposed system, the 
dataset will be created from scratch and annotated for custom 
training.  To  collect  the  data  images,  a  KaKaXi  fixed  camera 
shown in Fig. 3 has been used which takes images every hour 
within a fixed period of time each day. These images then get 
saved in  a database.

[26]  Chang, Chih-Chung and Chih-Jen Lin. “LIBSVM: A library for support 
vector machines.” ACM Trans. Intell. Syst. Technol. 2 (2011): 27:1-27:27. 
[27]  Poojary, Ramaprasad & Raina, Roma & Mondal, Amit Kumar. (2020). 
Effect  of  data-augmentation  on  fine-tuned  CNN  model  performance. 
IAES  International  Journal  of  Artificial  Intelligence  (IJ-AI).  10. 
10.11591/ijai.v10.i1.pp84-92. 

[28]  IKKAKU Project-https://ikkaku.lne.st/en/vision/ 

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on September 08,2024 at 12:02:05 UTC from IEEE Xplore.  Restrictions apply. 

38

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model described in the given context is built using TensorFlow and Keras frameworks. Specifically, it is mentioned that the system is most compatible with TensorFlow version 1.14.0 and Keras version 2.2.4 along with Python 3.6. Therefore, these are the frameworks used to build the deep learning model.