Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4.2. Opportunities of the modeling approach

Segmentation and classiﬁcation strategies in eCognition are still
rapidly evolving; methods and rule sets for automatically selecting
segmentation parameters are under development (Dragut et al.,
2010, 2014; Martha et al., 2012), but there is not yet consensus on
best practices. Better classiﬁcations, which could then better capture
the process of interest, may be possible as these tools develop fur-
ther. Machine learning techniques are being brought together with

M.V. Eitzel et al. / Ecological Informatics 31 (2016) 100–111

109

segmentation to more automatically classify images (Nancy Thomas,
personal communication). This set of approaches with historical im-
agery could become more powerful as new methods are developed.
We do caution that even with machine learning, some supervision
and validation using aerial photo interpretation techniques or
other data sources are still necessary (Sexton et al., 2015).

2.4. Segmentation and classiﬁcation

(Mixed GAM Computation Vehicle; Wood, 2006). The GAM was ideal
for these data for two reasons: 1) a Markovian random ﬁeld (MRF)
basis was available for the smoothing function, which is designed for
use with polygons with potentially irregular sizes (which some of the
cells have after applying the forest-only analysis mask); and 2) mgcv
had extensions for non-normal response variables. The quasi-binomial
family was an appropriate choice, as it allowed for overdispersion. The
response variable was then framed as a number of 1-m by 1-m cells
within the 20-m by 20-m cell of the DEM which were classiﬁed as
‘woody cover’ as binomial successes, and those classiﬁed as ‘herbaceous
cover’ as binomial failures.

2.5. Accuracy assessment

We

assessed classiﬁcation accuracy within the
analysis
regions for each image by selecting 100 random points using ArcGIS's
random point generating utility and visually assessing the class at
that point (see Supplementary data for Python code). Because
herbaceous cover was much less common in the forested area, we
used a proportionally stratiﬁed sampling strategy and ensured that at
least 10 points of classiﬁed herbaceous cover were assessed for accuracy
at each site. Preliminary accuracies were determined to be similar
for individual sites, so we pooled the accuracy assessment across
sites. We then generated an additional 15 random points within
herbaceous cover for the 2009 images so the total across sites was
more than 50.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific strategy used to monitor the model performance during training. However, based on the given context, one can infer that visual assessment was employed to evaluate classification accuracy. Random points were selected within the analysis regions for each image, and the class at those points was manually inspected. A stratified sampling strategy was adopted to ensure sufficient representation of the less frequent classes. Additionally, preliminary accuracies were compared between different sites before pooling the accuracy assessment across them. Furthermore, the use of Generalized Additive Models (GAM) suggests that statistical measures might also have been utilized to track the model performance during training. Nonetheless, without further details regarding the actual implementation, it remains uncertain what exact metrics or methodologies were applied to monitor the model performance.