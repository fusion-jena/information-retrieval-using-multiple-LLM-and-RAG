Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1026075F. Guo et al.                                                                                                                                                                                                                                      

Fig. 4. Flow chart of the overall workflow. 
Note: SSA: Space-spectrum-array. 

Table 3 
Feature variables of the satellite data.  

Feature types 

Feature variable 

Number of feature variable 

Spectral features 

Vegetation Indices 

Blue, Green, Red, 
NIR, SWIR1, SWIR2 
NDVI, EVI, MSAVI, NDTI, 
MNDWI, NDBI, BSI, DBSI  

6*3 

8*3

that larger sample sizes improved the classification accuracy, but with 
larger improvements when the initial sample size was small.

Davidson, A., Fisette, T., Rollin, P., Brisco, B., et al., 2020. Application of Google 
Earth engine cloud computing platform, sentinel imagery, and neural networks for 
crop mapping in Canada. Remote Sens. 12, 3561–3578. 
Breiman, L., 2001. Random forests. Mach. Learn. 45, 5–32. 
Cai, S., Liu, D., 2013. A comparison of object-based and contextual pixel-based 

classifications using high and medium spatial resolution images. Remote Sens. Lett. 
4, 998–1007. 

Campos, J.C., Brito, J.C., 2018. Mapping underrepresented land cover heterogeneity in 
arid regions: the Sahara-Sahel example. ISPRS J. Photogramm. Remote Sens. 146, 
211–220. 

Chen, J., Chen, J., Liao, A., Cao, X., Chen, L., Chen, X., He, C., Han, G., Peng, S., Lu, M., 
et al., 2015. Global land cover mapping at 30m resolution: a POK-based operational 
approach. ISPRS J. Photogramm. Remote Sens. 103, 7–27. 

Chen, B., Huang, B., Xu, B., 2017. Multi-source remotely sensed data fusion for

EcologicalInformatics81(2024)1026076F. Guo et al.                                                                                                                                                                                                                                      

Fig. 5. Structure of the SSA-TPRF model.  

4.3. Effect of tile size on accuracy 

Table 4 
Experimental group design.  

Experimental 
group 

Classification model 

Classification 
approach 

Tile size 
(km) 

EXP1 
EXP2 

EXP3 

EXP4 

EXP5 
EXP6 
EXP7 
EXP8 
EXP9 
EXP10 

Overall model 
Tile model 
Overall model + Multiple 
probabilistic classification 
model 
Tile model + Multiple 
probabilistic classification 
model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 

PBA  
PBA 

PBA  

PBA 

SSA 
SSA 
SSA 
SSA 
SSA 
SSA 

25 

25 

25 
10 
20 
50 
75 
100  

other PBA-based models.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The information provided does not contain details about the deployment process of the trained deep learning model, such as model serialization or platform selection. Therefore, I cannot provide a helpful answer based on the given context.