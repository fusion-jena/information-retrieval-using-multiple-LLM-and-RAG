Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

http://orcid.org/0000-0002-2176-7935 

R E F E R E N C E S

Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., … Kudlur, M. 
(2016). TensorFlow: A system for large- scale machine learning. OSDI, 
16, 265–283.

Anderson, T. M., White, S., Davis, B., Erhardt, R., Palmer, M., Swanson, A., 
… Packer, C. (2016). The spatial distribution of African savannah her-
bivores: Species associations and habitat occupancy in a landscape 
context.  Philosophical  Transactions  of  the  Royal  Society  B:  Biological 
Sciences, 371, 20150314. https://doi.org/10.1098/rstb.2015.0314
Babaee,  M.,  Dinh,  D.  T.,  &  Rigoll,  G.  (2017).  A  deep  convolutional  neu-
ral  network  for  background  subtraction.  Pattern  Recognition,  76, 
635–649.

tification. OCEANS 2016 MTS/IEEE Monterey, 1–5.

Nogueira, K., Penatti, O. A. B., & dos Santos, J. A. (2017). Towards bet-
ter  exploiting  convolutional  neural  networks  for  remote  sensing 
scene  classification.  Pattern  Recognition,  61,  539–556.  https://doi.
org/10.1016/j.patcog.2016.07.001

Pimm, S. L., Alibhai, S., Bergl, R., Dehgan, A., Giri, C., Jewell, Z., … Loarie, 
S.  (2015).  Emerging  technologies  to  conserve  biodiversity.  Trends 
in  Ecology  &  Evolution,  30,  685–696.  https://doi.org/10.1016/ 
j.tree.2015.08.008

Price  Tack,  J.  L.,  West,  B.  S.,  McGowan,  C.  P.,  Ditchkoff,  S.  S.,  Reeves, 
S.  J.,  Keever,  A.  C.,  &  Grand,  J.  B.  (2016).  AnimalFinder:  A  semi- 
automated  system  for  animal  detection  in  time- lapse  camera  trap 
images. Ecological Informatics, 36, 145–151. https://doi.org/10.1016/ 
j.ecoinf.2016.11.003

|  1437

F I G U R E   2  The front screen of the DeepMeerkat GUI. A user 
can select a file or directory of videos to screen using a pre- trained 
model. The path to the model is set under “Advanced settings”

creasing false positives.

majority of hummingbird visitation events (Weinstein, 2015). For the 

For training the fine- tuned neural network, I collected images for 

purposes  of  this  article,  I  assumed  that  all  events  are  captured  by 

each class and trained with a batch size of 100 for 20,000 steps. To 

motion  detection  and  were  passed  to  the  neural  network  for  clas-

reduce training time, the feature vectors for the frozen layers were 

sification.  While  quantitative  benchmarks  are  needed  to  validate 

extracted in parallel using Google Cloud DataFlow. These features 

model performance, they provide a coarse description of the errors 

were then the basis for retraining the new fine- tuned layers. To fit

frames containing only background objects. The combination of mo-

are developing for screening camera trap images (Chen, Han, He, 

tion detection and neural network classification led to an enormous 

Kays, & Forrester, 2014), and finding organisms in remotely sensed 

reduction  in  the  number  of  frames  needing  human  review,  with 

imagery  (Guirado,  Tabik,  Alcaraz- Segura,  Cabello,  &  Herrera, 

often  less  than  2%  of  original  frames  requiring  human  annotation. 

2017). Convolutional neural networks underlie many advances in 

These results confirm that convolutional neural networks can be re-

these areas, and connecting insights across disciplines will be a key 

trained to specific ecological scenes and greatly reduce the time for 

in developing best practices. While the promise of this technology 

video annotation.

has been well advertised (Pimm et al., 2015), the next stage is to 

A high proportion of the remaining misclassified frames were due

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Unfortunately, the given context does not explicitly mention any specific dataset such as MNIST, CIFAR, or ImageNet being used in the deep learning pipeline. However, it mentions collecting images for each class and training with a batch size of 100 for 20,000 steps. It also discusses extracting feature vectors from these images using Google Cloud Dataflow. Therefore, we can infer that some custom image dataset was created and utilized for training the deep learning models discussed in the text.