Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3. Results

2.5.1. Classification problem (Q1): Deep learning applied to 2D LiDAR 
images for Forest classification 

We  employed  the  fast.ai  platform  (Howard  and  Gugger,  2020)  to 
train and validate models for the classification of 2D point cloud images, 
utilizing  a  LOGO  (Leave-One-Group-Out)  cross-validation.  In  this 
approach, our target classes were "Plateau", "White-sand", and "Ripar-
ian",  designated  as  "p",  "w",  and  "r"  respectively.  In  each  iteration,  a 
complete 450 m multitemporal transect was omitted from the training 
process  (the  grouping  factor  giving  the  lack  of  independence  in  the 
multi-temporal data) and subsequently tested. This approach ensured an 
assessment  of  the  model’s  performance,  accounting  for  our  data  con-
straints and guaranteeing that every multitemporal transect undergoes

We  have  also  adopted  a  broader  and  more  conservative  testing 
strategy as in the classification problem (Q1) involving excluding three 
transects (~17% of the data) for testing in each iteration, specifically 
one  from  each  target  class  -  "Plateau"  (p),  "White-sand"  (w),  and  "Ri-
parian" (r), cross-validation is the same as before with the classification 
problem  (see  2.5.1).  In  order  to  measure  the  model’s  performance 
across all transects, a cumulative evaluation was also performed. Instead 
of analyzing each iteration separately, we assess the model using coef-
ficient  of  determination  (R2)  between  true  vs  predicted  for  all  648 
multitemporal transects predictions. 

2.5.3. A comparative evaluation of traditional LiDAR-derived metrics and 
2D point cloud image-based machine learning in Forest type classification 
and regression analysis

both training and testing. A critical point to highlight is that models are 
retrained  for  each  fold,  preventing  previous  fold’s  information  from 
being transferred. We utilized the pretrained ResNet-34 (Which consists 
of  a  34-layer  convolutional  neural  network)  architecture  which  is  a 
variant of the ResNet (Residual Network) family, widely used for deep 
learning tasks, particularly in computer vision (He et al., 2016). ResNet- 
34 was used inside the fast.ai framework (Howard and Gugger, 2020) to 
leverage  existing  knowledge,  this  is  particularly  useful  in  our  dataset 
since its small size. Transfer learning generally consists in using a model 
pre-trained  on  broad  datasets,  like  ImageNet  (Deng  et  al.,  2009),  to 
specialized tasks with more limited data. As part of the cross-validation 
of the Leave-One-Group-Out approach, the test directory containing the 
multitemporal transect was temporarily moved to test, and DataLoaders

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit details about specific postprocessing steps such as saliency maps or confusion matrices. However, it mentions two methods used to evaluate the model's performance: coefficient of determination (R^2) and a leave-one-group-out (LOGO) cross-validation strategy. The R^2 value is calculated by comparing the true versus predicted values across all 648 multitemporal transects. Additionally, the LOGO cross-validation involves leaving out one complete 450m multitemporal transect during each iteration of the training process, ensuring that every transect is eventually tested. These approaches help assess the model's performance while considering the constraints of the available data.