Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

training sets are presented as confusion matrices in Fig. 6 (bottom row). 
Furthermore, the lower half of Table 4 shows the number of patches for 
each class after data augmentation.

In order to solve this problem, we used a DL approach. DL networks 
can be seen as non-linear functions with a large number of parameters. 
The parameters of each DL are adjusted using annotated data (usually 
referred  to  as  a  “supervised  approach”).  Once  this  process  (called 
training the network) is finished, the evaluation of the network on the real 
problem  is  performed  by  feeding  it  an  independent  data  set  not  seen 
during training (the testing data set). DL techniques are currently a hot 
topic in machine learning with applications in a variety of fields, and are 
considered the current state of the art for CV applications. In fact, in 
some disciplines, this technology is considered to have exceeded human 
capabilities (Buetti-Dinh et al., 2019; He et al., 2015).

Table 4 
The number of patches (#patch) and true positive/false Positive rate (TPR/FPR) values for each DL network and species. For the upper half of the table, no data 
augmentation was used. For the lower half of the table, the training set included data augmentation.  

WITHOUT DATA AUGMENTATION 

#patch 

Inutsuge 
Kyaraboku 
Matsu 
Kaede 
Nanakamado 
Sakura 

408 
1061 
449 
736 
1560 
353 

WITH DATA AUGMENTATION 

#patch 

Inutsuge 
Kyaraboku 
Matsu 
Kaede 
Nanakamado 
Sakura 

1060 
1289 
1167 
1042 
1560 
917 

ConvNeXt 

57.31 
84.03 
43.33 
49.45 
91.98 
81.69 

ConvNeXt 

51.21 
89.20 
60.00 
69.59 
89.74 
84.50 

4.07 
7.11 
2.90 
3.64 
12.25 
0.94 

2.15 
6.54 
3.14 
4.68 
8.44 
1.18 

TPR ∣ FPR %  

Resnet 

53.65 
80.28 
40.00 
57.43 
87.50 
80.28 

TPR ∣ FPR %  

Resnet 

60.97 
79.81 
45.55 
61.48 
86.85 
81.69 

5.99 
6.97 
4.47 
4.42 
12.25 
0.71 

6.83 
4.97 
3.99 
4.42 
11.42 
0.82 

Swin 

56.09 
84.50 
38.88 
60.81 
92.94 
92.95 

Swin

conditions or with trees from a different site). Consequently, when there 
is  data  leakage,  properties  of  the  testing  data  leak  into  the  training 
process,  the  estimation  of  the  generalization  power of  the  network is 
compromised. See (Diez et al., 2021), section 3.1 for more details.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about the specific criteria used to determine when training is completed. However, based on common practices in deep learning, some possible criteria include reaching a certain number of epochs, achieving a desired level of performance on a validation dataset, observing a plateau in the validation loss, or meeting other predefined stopping conditions. It should also be noted that the goal of training is to minimize overfitting while maximizing the model's ability to generalize well to unseen data.