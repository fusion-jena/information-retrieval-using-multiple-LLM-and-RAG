Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

LeCun, Y., Bengio, Y. & Hinton, G. (2015) Deep learning. Nature, 521(7553),
436–444. Available from: https://doi.org/10.1038/nature14539
Mukhoti, J., Kulharia, V., Sanyal, A., Golodetz, S., Torr, P.H.S. & Dokania, P.
K. (2020) Calibrating deep neural networks using focal loss. Advances
in Neural Information Processing Systems, 33, 15288–15299. Available
from:
https://proceedings.neurips.cc/paper/2020/hash/aeb7b30ef
1d024a76f21a1d40e30c302-Abstract.html

Noguerales, V., Meramveliotakis, E., Castro-Insua, A., Andújar, C.,
Arribas, P., Creedy, T.J. et al.
(2021) Community metabarcoding
reveals the relative role of environmental filtering and spatial pro-
cesses in metacommunity dynamics of soil microarthropods across a
mosaic of montane forests. Molecular Ecology in press. Available
from: https://doi.org/10.1111/mec.16275

average accuracy reduction. Higher accuracy reduction indicates a
worse performance on prediction compared to the within-dataset
prediction accuracy. The solid and dashed lines represent results of
the convolutional neural network (CNN) and domain adversarial
neural network (DANN), respectively. Note that only the LL to LH
prediction accuracy improved with the use of DANN.

F I G U R E 3

The effect of increasing numbers of training images on

representing single-specimen photographs by local taxonomists, are
used to predict local high-resolution images (LL!LH).

Between-datasets classification with domain adversarial
training

In addition to the standard CNN setups described above, we employed

large reduction of accuracy, hence difficulty in transfer.

the domain adversarial training of neural networks (DANN, Ganin

Divergence between the source and target datasets was mea-

et al., 2016) which incorporates a certain portion of the unknown tar-

sured with a dataset classification error. A linear support vector

gets in the model. The DANN model jointly predicts the class (family

machine (SVM) was trained to classify images to the source or target

label) of the source images and the dataset (domain) of all input images

dataset with the features of 200 randomly selected images from both

(as in the previous section) by adding layers for the dataset classifica-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, there is no direct mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, one technique mentioned is the use of Domain Adversarial Training of Neural Networks (DANN) which can be considered as a method to handle data bias.

DANN is a technique introduced by Ganin et al. (2016) that aims to improve the generalization ability of deep learning models when dealing with different domains or distributions of data. In this approach, a domain classifier is added to the model architecture, which tries to distinguish between the source and target domains while the main task classifier tries to minimize the classification error. By doing so, the model learns to extract domain invariant features that can help reduce the impact of data bias caused by differences in data distribution between the source and target domains.

Although not explicitly stated in the context, other common techniques to address data bias during preprocessing include stratified sampling, where the data is split into training and testing sets based on the proportion of classes present in the original dataset; oversampling, where samples from underrepresented classes are duplicated to balance the dataset; undersampling, where samples from overrepresented classes are removed to balance the dataset; and diverse data collection, where efforts are made to collect more representative data from various sources to reduce bias.