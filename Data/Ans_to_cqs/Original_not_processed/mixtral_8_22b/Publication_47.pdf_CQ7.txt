Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We trained IUC-NN on all species with an IUCN RL as-
sessment and available occurrence records. Prior to the
training, we randomly split the data set into a training
set (90% of the entries) and a test set (10%). We used
20% of the training set for validation. Because the size
of the data set was comparatively small, we performed
cross-validation by shifting the validation set 5 times to
quantify the average validation cross-entropy loss and ac-
curacy. We then used the neural network with the lowest
cross-entropy loss across a range of models with differ-
ent numbers of hidden layers and subsets of features to
predict the conservation status of all orchid species at
2 levels: binary (possibly threatened vs. not threatened)
and detailed (CR, EN, VU, NT, and LC). See Supporting
Information for details on the network architecture and
training. We combined the IUC-NN assessments with dis-
tribution data from WCSP to show the number and pro-

Keywords: biodiversity, data quality, IUC-NN, IUCN Red List, machine learning, Orchidaceae, sampling bias

Evaluación Automatizada de la Conservación de la Familia Orchidaceae mediante Aprendizaje Profundo

IUC-NN all features
not threatened
possibly threatened

Spatial
cleaning

full
full
medium
medium
raw
raw

full
full

full
full

full
full

full
full

IUCN designation

not
threatened

possibly
threatened

Method type∗

75.1
38.8
75.1
36.4
73.8
35.3

68.3
32.5

68.5
32.4

78.9
11.8

81.6
29.4

24.9
61.2
24.9
63.6
26.2
64.7

31.7
67.5

31.5
67.6

21.1
88.2

18.4
70.6

index
index
index
index
index
index

index
index

index
index

prediction
prediction

prediction
prediction

∗For index-based methods, the results are for all species with digitally available occurrence records (n = 866). For prediction-based methods
(IUC-NN), results are from the test data set (n = 89).

Including data on species trade, land use, or life his-
tory, once they are available, may help increase the ac-
curacy of IUC-NN and overcome dependency on threat
category (Supporting Information). Additionally, combin-
ing the binary and detailed model, the results of which
were contradictory in some cases (Supporting Informa-
tion), may increase the performance of IUC-NN. We sug-
gest that labeling species where the binary and detailed
model disagree as data deficient might reduce the num-
ber of false predictions. Future developments of IUC-NN
will quantify the estimation of threat as a continuous pa-
rameter to increase the accuracy for intermediate threat
levels and will implement Bayesian neural networks to
quantify uncertainties in the prediction (Silvestro & An-
dermann 2020).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The data was split into a training set and a test set using a random split method. The training set consisted of 90% of the entries, while the remaining 10% were allocated to the test set. Furthermore, 20% of the training set was utilized for validation purposes. To account for the relatively small dataset size, cross-validation was carried out by shifting the validation set five times. This process aimed to determine the average validation cross-entropy loss and accuracy. Subsequently, the neural network with the lowest cross-entropy loss was selected from a range of models featuring different numbers of hidden layers and feature subsets. This chosen model was employed to predict the conservation status of all orchid species at two distinct levels: binary (possibly threatened vs. not threatened) and detailed (CR, EN, VU, NT, and LC).