Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We  evaluated  the  network  performance  by  calculating  a 
number of different performance measures based on comparing 
predictions to test set data. The accuracy (defined as the ratio of 
correct classifications relative to the total number of examples) 
has  only  limited  value  as  an  evaluation  metric  here,  as  the 
class  distribution  is  very  unbalanced  (only  3.48%  of  the  data 
points  are  classified  as  disturbed).  We  therefore  also  calculated 
precision, recall, and the F1 Score, as well as Conditional Kappa 
and the True Skill Statistic (Allouche et al., 2006; Powers, 2011) 
(Table 1). Conditional Kappa and True Skill Statistic range from 
−1  to  +1,  where  +1  indicates  perfect  agreement  with  test  data, 
and values >0 indicate a performance than is better than random

The hyper-parameters evaluated iteratively were network capacity 
(number of layers and neurons per layer), applied regularization 
techniques, as well as the used loss function and optimizer. The 
training of the individual candidate networks was stopped when 
the accuracy of the network on the test dataset did not increase 
further.  The  thus  determined  network  architecture  was  also 
used for Experiment 2 (Abadi et al., 2016). All experiments and 
predictions  were  conducted  using  the  TensorFlow  framework 
and  run  on  a  desktop  PC  with  an  Intel  QuadCore  CPU  (Intel 
i5-6600) and equipped with an NVidia GTX 1070 GPU.

To  better  contextualize  the  performance  of  the  DNN, 
we  repeated  Experiments  1  and  2  using  other  widely  used 
classification algorithms, i.e., distributed random forest, gradient 
boosting  machine,  and  generalized  linear  model.  We  used  the 
H2O platform (H2O.ai, 2017), which provides a set of fast and 
scalable  learning  algorithms  and  is  integrated  within  the  R 
software and environment.

REsULTs

Keywords: deep neural networks, ecological prediction, machine learning, computational ecology, forest disturbance 

INTRODUCTION

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The performance of the deep learning model was evaluated using several metrics due to the imbalance in the class distribution of the data. Accuracy, defined as the ratio of correct classifications to the total number of examples, was considered to have limited value as an evaluation metric because of this imbalance. Therefore, additional metrics such as precision, recall, and the F1 score were also calculated. Furthermore, Conditional Kappa and the True Skill Statistic were employed, both ranging from -1 to +1, where +1 indicates perfect agreement with test data and values greater than 0 indicate better performance than random. These metrics provide a more comprehensive understanding of the model's performance beyond simple accuracy.