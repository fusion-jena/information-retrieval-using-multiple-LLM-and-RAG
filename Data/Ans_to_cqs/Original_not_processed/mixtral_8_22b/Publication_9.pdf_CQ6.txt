Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

overarching  goal  of  training  a  neural  network  is  to  iteratively  min-

tional  training.  The  utility  of  pre- trained  CNNs  out- of- the- box  is 

imize the error between model output and expected output by op-

constrained by how relevant the novel input data are to the data the 

timally  adjusting  model  weights  and  reaching  model  convergence, 

CNN  was  originally  trained  on.  For  instance,  ImageNet  comprises 

such that the trained neural network generalizes well to novel input 

more  than  14  million  high- resolution  images  across  nearly  22,000 

data. Model weights are adjusted to minimize error on each subse-

categories and is often used as a starting point for recognition tasks 

quent run using an algorithm called stochastic gradient descent with 

with deep learning (Deng et al., 2009; Krizhevsky et al., 2017). Using 

backpropagation  (LeCun  et  al.,  1989;  Rumelhart  et  al.,  1995).  This

a CNN pre- trained on ImageNet, interested users could implement 

approach  optimizes  the  magnitude  of  change  for  model  weights 

a  machine  vision  task  without  needing  to  train  an  entire  neural 

SCHWARTZ And ALFARO 2041210x, 2021, 12, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13712 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseMethods in Ecology and Evolu(cid:13)on

    |  2343

network from the ground up. Although, model performance may be 

downstream  image  analysis  workflows  without  additional  training. 

weak  if  the  contents  of  input  images  are  distantly  related  or  com-

On  the  other  hand,  COCO  can  be  used  as  a  backbone  for  training

He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectifiers: 
Surpassing human- level performance on ImageNet classification. In 
2015 IEEE International Conference on Computer Vision (ICCV). IEEE.

He,  K.,  Zhang,  X.,  Ren,  S.,  &  Sun,  J.  (2016).  Deep  residual  learning  for 
image recognition. In Proceedings of the IEEE conference on computer 
vision and pattern recognition (pp. 770– 778).

Hubel,  D.  H.,  &  Wiesel,  T.  N.  (1962).  Receptive  fields,  binocular  inter-
action  and  functional  architecture  in  the  cat's  visual  cortex.  The 
Journal of Physiology, 160, 106– 154. https://doi.org/10.1113/jphys 
iol.1962.sp006837

Joly,  A.,  Bonnet,  P.,  Goëau,  H.,  Barbe,  J.,  Selmi,  S.,  Champ,  J.,  Dufour- 
Kowalski,  S.,  Affouard,  A.,  Carré,  J.,  Molino,  J.- F.,  Boujemaa,  N., 
&  Barthélémy,  D.  (2016).  A  look  inside  the  Pl@ntNet  experience. 
Multimedia  Systems,  22,  751– 766.  https://doi.org/10.1007/s0053 
0- 015- 0462- 9

specific segmentation models. The full instructions and options are 

cluded in model training are shown in Figure 1.

provided on the GitHub repository.

2.3 | Model training procedure

2.5 | Sashimi online model repository

We first used the VGG Image Annotator Version 1.0.6 (https://www.

We constructed a website to serve as a repository for the fish seg-

robots.ox.ac.uk/~vgg/softw are/via/via- 1.0.6.html;  Dutta  et  al., 
2016) to manually annotate pixel coordinates to create precise po-

mentation model (presented here) and future, community generated 

organismal  segmentation  models  (https://sashi mi.shawn tyler schwa 

lygonal mask contours directly around the fish body boundary (i.e. 

rtz.com). We aim to inspire other biologists interested in automated 

where the foreground pixels of the target fish body meet those of 

segmentation to create pre- trained models for their organism(s) of 

the background). We intentionally assigned all segmentation masks

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific preprocessing steps involved before training a deep learning model such as normalization, scaling, or cleaning. However, it mentions that the overarching goal of training a neural network is to iteratively minimize the error between model output and expected output by optimally adjusting model weights and reaching model convergence. It also states that the utility of pre-trained Convolutional Neural Networks (CNNs) depends on how relevant the novel input data are to the data the CNN was originally trained on. Therefore, one might infer that some form of preprocessing would likely involve ensuring that the input data is appropriately scaled and normalized so that it aligns with the original dataset used to train the pre-trained CNN. Additionally, depending on the nature of the input data, cleaning operations such as removing noise or irrelevant features might also be necessary.