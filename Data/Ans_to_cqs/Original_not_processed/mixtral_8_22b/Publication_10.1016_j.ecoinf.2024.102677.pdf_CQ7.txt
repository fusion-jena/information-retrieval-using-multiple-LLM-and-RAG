Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To ensure the stability of the proposed models, we randomly divided 
the  dataset  into  three  parts:  training  (60%),  validation  (20%),  and 
testing  (20%)  (Meng  et  al.,  2022).  This  division  was  performed  in  a 
stratified manner to maintain class proportions across all of the parts. 
The dataset was randomly divided into a training set (2880 images), a 
validation set (961 images), and a testing set (958 images). The models 
were trained on an NVIDIA 3090 GPU with a 256 Ã— 256 image input 
size. After parameter tuning, the learning rate, batch size, and number of 
epochs were set to 0.0001, 8, and 30, respectively.  

(2)  Model selection

discriminant rules are illustrated in Fig. 3. Finally, we employed deep 
learning techniques to predict the types of landscapes in the case study 
area. The classification process based on deep learning encompasses the 
following stages.

4.2. Landscape type classification 

The  five  network  models  were  evaluated  using  the  performance 
metrics  of  the  validation  and  test  sets.  The  model  accuracy  was 
continuously assessed using the validation set during training, and the 
performance of the testing set guided the final decision. Fig. 6 illustrates 
the  learning  curves,  indicating  a  reduction  in  training  losses  as  the 
number  of  epochs  increases  and  convergence  within  500  epochs. 
Inceptionv3  converges  by  400  epochs,  while  the  other  networks 
converge  within  150  epochs.  The  ResNet  architecture,  especially 
ResNet50 and ResNet101, outperforms the others.

Table 6 presents the accuracy, precision, recall, and F1-scores of the 
five networks. ResNet50 surpasses the other models in terms of all of the 
evaluation metrics, with an accuracy of 0.81, precision of 0.82, recall of 
0.81, and F1-score of 0.81 for the testing set. Considering the challenge 
of manual sample distinction, this result is commendable. Fig. 4 displays 
the  F1-scores  of  the  five  categories  across  all  of  the  networks,  with 
ResNet50 having the best values of the four categories, except for the 
RRP. Therefore, ResNet50 was selected for the case validation. 

After finalization, the model was applied to classify the case study 
area. The classification results correspond to the actual situation (Fig. 7). 
The RRP is primarily concentrated on the eastern and western edges of 
the study area, reflecting the history of top-down planning and devel-
opment in this area. The IRP is primarily situated in the central part of

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The dataset was divided into three parts for deep learning model training: training (60%), validation (20%), and testing (20%). This division was done in a stratified manner to maintain class proportions across all parts. The training set consisted of 2880 images, the validation set had 961 images, and the testing set contained 958 images. The models were trained on an NVIDIA 3090 GPU with a 256 x 256 image input size. The parameters such as learning rate, batch size, and number of epochs were set to 0.0001, 8, and 30, respectively after parameter tuning.

The criteria used to split the data were not explicitly mentioned but can be inferred from the given information. The dataset was divided into three parts - training, validation, and testing - which is a common practice in machine learning and deep learning projects. The purpose of splitting the data is to evaluate how well the model generalizes to new, unseen data. The training set is used to fit the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to provide an unbiased evaluation of the final model. In this case, the data was divided in a stratified manner, meaning that each subset maintained the same proportion of classes as the original dataset. This ensures that the model sees enough examples of each class during training and prevents any class imbalance issues.