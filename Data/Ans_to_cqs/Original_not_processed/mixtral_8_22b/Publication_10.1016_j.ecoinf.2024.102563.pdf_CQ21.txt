Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig.  4. Classification  results  obtained  using  a  19  × 19  window  size  for  the 
mean parameter. (a) MLC, (b) SVM, (c) ANN, and (d) RF methods. 

EcologicalInformatics81(2024)1025636M. Duan et al.

Liu, X.Q., Zhu, A.X., Yang, L., Pei, T., Liu, J.Z., Wang, D.S., 2020. A graded proportion 
method of training sample selection for updating conventional soil maps. Geoderma 
357, 1–9. https://doi.org/10.1016/j.geoderma.2019.113939. 

Lu, D., Hetrick, S., Moran, E., 2010. Land cover classification in a complex urban-rural 
landscape with quickbird imagery. Photogramm. Eng. Remote. Sens. 76 (10), 
1159–1168. https://doi.org/10.14358/PERS.76.10.1159. 

Lu, H., Liu, C., Li, N., Fu, X., Li, L., 2021. Optimal segmentation scale selection and 

Berlin/Heidelberg.  

Saboori, M., Torahi, A.A., Bakhtyari, H.R.R., 2019. Combining multi-scale textural 

features from the panchromatic bands of high spatial resolution images with ANN 
and MLC classification algorithms to extract urban land uses. Int. J. Remote Sens. 40 
(22), 8608–8634. https://doi.org/10.1080/01431161.2019.1620371. 

Sheykhmousa, M., Mahdianpari, M., Ghanbari, H., 2020. Support vector machine versus

Table 3 
Classification accuracies of various methods utilizing multi-textural features with an optimal window. “Mean 19” is the mean parameter extracted using a 19 × 19 
window, “Entropy 23” is the entropy parameter extracted using a 23 × 23 window.   

Spectral 
Spectral + Mean 19 
Spectral + Entropy 23 
Spectral + Mean 19 + Entropy 23 

Overall accuracy (%)  

MLC 

55.50 
62.60 
64.90 
63.60 

SVM 

59.20 
63.70 
66.00 
71.61 

ANN 

59.30 
57.60 
57.60 
60.06 

RF 

62.70 
62.70 
64.70 
64.10 

MLC 

0.45 
0.53 
0.56 
0.54 

Kappa index 

SVM 

0.46 
0.53 
0.56 
0.64 

ANN 

0.48 
0.46 
0.46 
0.50 

RF 

0.51 
0.52 
0.54 
0.53  

EcologicalInformatics81(2024)1025635M. Duan et al.

We employed a graded-proportion method that utilizes area-based 
grading  of  soil  groups  to  select  training  samples  (Liu  et  al.,  2020). 
This  approach  involved  two  primary  steps.  Initially,  soil  groups  were 
graded  according  to  their  corresponding  areas.  Subsequently,  the 
training samples were determined for each soil group according to the 
gradational  relationship  derived  from  typical  sample  points.  This 
method  resulted  in  444  training  samples  from  seven  soil  groups,  as 
detailed in Table 1. Of these, 423 samples were sourced from the his-
torical  soil  map.  Simultaneously,  a  comprehensive  field  investigation 
was conducted to collect 29 samples using soil drills and examine six soil 
profiles. Fifteen of these soil drill samples and all six soil profiles were 
used as training samples, whereas the remaining 14 soil drill samples 
were reserved for validation. The training samples were used to classify

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After model training, several postprocessing steps can be performed depending on the specific requirements of the project or study. Some common postprocessing steps include:

1. Model evaluation: Evaluating the performance of the trained models using metrics such as overall accuracy, kappa index, precision, recall, F1 score, etc. These metrics help assess how well the model has learned to classify the data. In this case, we see that the authors have calculated both overall accuracy and kappa index for different methods (see Table 3).

2. Visualization of results: Creating visual representations of the classified data, such as thematic maps or scatter plots, which can aid in understanding the distribution of classes across the study area. Figure 4 shows examples of classified maps produced by four different methods.

3. Confusion matrices: Generating confusion matrices to understand the misclassifications between different classes. This helps identify patterns in errors made by the model and can guide further improvements. Although not explicitly mentioned in the given context, confusion matrices could potentially be created based on the available information.

4. Saliency maps: Highlighting important regions within input data that contribute significantly to the final output decision. While saliency maps are more commonly associated with deep learning models, they may still be relevant when working with other types of models like those presented here. However, there is no mention of saliency maps in the provided context.