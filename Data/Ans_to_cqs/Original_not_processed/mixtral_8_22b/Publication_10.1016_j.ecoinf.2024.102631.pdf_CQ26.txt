Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Related Work 

Image enhancement plays a crucial role in improving visual quality 
and  extracting  meaningful  information  from  images.  Over  the  years, 
researchers  have  explored  various  methodologies  to  enhance  images, 
with  two  prominent  streams  of  investigation  emerging.  One  branch 
primarily focuses on leveraging traditional image processing techniques, 
while the other harnesses the power of deep learning algorithms. In this 
section,  we  review  some  of  the  currently  available  solutions  using 
classical and deep learning-based approaches. 

2.1. Classical image enhancement techniques

Davg

SA

= 1
C

∑C

c=1

̂
F(i, j, c)

And the max pooling is denoted as: 

max
SA

= max
c

̂
F(i, j, c)

Where  Davg

SA  and  Dmax

SA  represent  the  feature  descriptors  containing 
average  and  max  pooling,  respectively.  C  represents  the  number  of 
̂
F(i, j, c) represents the value in the feature 
channels in the feature map, 
map across all channels at position i and j. The results of these pooling 
operations are concatenated element-wise to create a feature descriptor 
represented as DSA  with dimensions ℝH×W×2. Subsequently, this feature 
descriptor  undergoes  a  convolution  operation  followed  by  a  sigmoid 
activation  function.  This  process  yields  the  spatial  attention  map, 
̂
dSA,  which  has  dimensions  ℝH×W×1.  This  spatial  attention 
̂
F, contributing to 

denoted  as 
̂
dSA  is then multiplied to rescale the feature map 

map 
the refinement of feature representations within the neural network. 

3.2. Disciminator Architecture

set (UCCS) dataset (Liu et al., 2020). 

Experiment Settings: To ensure fairness and comparability in our 
evaluation,  we  conducted  comprehensive  experiments  comparing  our 
model  with  state-of-the-art  (SOTA)  methods.  We  maintained  consis-
tency by either utilizing source codes provided by authors or referring to 
original paper descriptions (Ancuti et al., 2018; Islam et al., 2020a; Li 
et al., 2019a; Li et al., 2020; Peng et al., 2023; Peng and Cosman, 2017). 
All  methods  underwent  identical  testing  and  training  processes 
throughout  the  experiments.  The  evaluation  environment  was  set  up 
with an NVIDIA RTX 6000 48GB GPU, Intel Xeon(R) Gold 6230 CPU @ 
2.10GHz × 80. Additionally, we trained our model for 300 epochs using 
the Adam optimizer with a learning rate set to 0.0001. 

4.1. Evaluation Metrics

Deep learning techniques have been successfully applied to under-
water  image  enhancement  tasks,  helping  to  improve  the  quality  and 
visibility of images captured in underwater environments. In this sec-
tion, we briefly discuss a few examples. For instance, Li et al. (Li et al., 
2018) developed WaterGAN deep learning-based generative adversarial 
network model that performs network training for reducing the color 
deviation  in  underwater  images.  Fabbri  et  al.  (Fabbri  et  al.,  2018) 
developed UGAN by taking the idea of CycleGAN (Zhu et al., 2017) that 
performs domain transformation to reconstruct degraded images. Guo 
et al. (Guo et al., 2019) developed a novel multi-scale dense GAN by 
adding a residual multi-scale dense block to the generator, improving 
enhancement performance. Islam et al. (Islam et al., 2020a) presented 
FUnIE-GAN  by  introducing  a  multi-model  objective  function  in  the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific details about addressing data bias during preprocessing of the deep learning pipeline. However, common techniques used to handle data bias include stratified splitting, oversampling, undersampling, and diverse data collection. Stratified splitting involves dividing the dataset into subsets based on certain criteria, such as class labels, ensuring each subset maintains the original distribution of classes. Oversampling increases the representation of minority classes by duplicating samples, while undersampling reduces the majority class size by removing samples. Lastly, diverse data collection aims to gather more representative datasets by including samples from different sources, demographics, or conditions. These techniques can help mitigate data bias and improve the overall performance of deep learning models.