Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Some model parameters were modified from the default configura-
tion to balance use of resources and training speed. We retained a res-
olution of 704 × 704, batch size 64, 32 subdivisions and trained up to 
6000 iterations. Other parameters were kept to default or set according 
to guidance by the developers (https://github.com/AlexeyAB/darknet). 
Manual annotations were used to generate training, validation and 
testing  datasets.  Biigle  annotations  (label  name,  centre  x,  center  y, 

EcologicalInformatics71(2022)1017863N. Piechaud and K.L. Howell

Beyan, C., Browman, H.I., 2020. Setting the stage for the machine intelligence era in 
marine science. ICES J. Mar. Sci. 77 (4), 1267–1273. https://doi.org/10.1093/ 
icesjms/fsaa084. 

Bisong, E., 2019. Google Colaboratory. In: Bisong, E. (Ed.), Building Machine Learning 
and Deep Learning Models on Google Cloud Platform: A Comprehensive Guide for 
Beginners. Apress, Berkeley, CA, pp. 59–64. https://doi.org/10.1007/978-1-4842- 
4470-8_7. 

Bochkovskiy, A., Wang, C.-Y., Liao, H., 2020. YOLOv4: optimal speed and accuracy of 

object detection. ArXiv, arXiv:2004.10934 [Preprint].  

Borja, A., et al., 2016. Bridging the gap between policy and science in assessing the 
health status of marine ecosystems. Front. Mar. Sci. 3 (175) https://doi.org/ 
10.3389/fmars.2016.00175. 

Brady, H.B., 1883. IV. Note on syringammina, a new type of arenaceous rhizopoda. 

Proceedings of the Royal Society of London 35 (224–226), 155–161.

Appendix A. Supplementary data 

Supplementary data to this article can be found online at https://doi. 

org/10.1016/j.ecoinf.2022.101786. 

References 

Abad-Uribarren, A., et al., 2022. Deep learning-assisted high resolution mapping of 
vulnerable habitats within the Capbreton canyon system, Bay of Biscay. Estuar. 
Coast. Shelf Sci. 275, 107957 https://doi.org/10.1016/j.ecss.2022.107957. 
Ashford, O.S., Davies, D.J., Jones, D.O., 2014. Deep-sea benthic megafaunal habitat 

suitability modelling: A global-scale maximum entropy model for xenophyophores. 
Deep Sea Res. Part I Oceanogr. Res. Pap. 94, 31–44. 

Beijbom, O., et al., 2015. Towards automated annotation of benthic survey images: 

variability of human experts and operational modes of automation. PLoS One 10 (7), 
e0130312. 

Bett, B.J., 2001. UK Atlantic margin environmental survey: introduction and overview of 

bathyal benthic ecology. Cont. Shelf Res. 21 (8–10), 917–956.

challenge of collecting representative datasets in the deep sea.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The code repository of the deep learning pipeline is not explicitly mentioned in the given context. However, there is a reference to a GitHub repository (<https://github.com/AlexeyAB/darknet>) which might contain relevant information about the deep learning pipeline used in the study. It should be noted that without further clarification, it cannot be confirmed if this specific repository contains the exact code used in the research.

Based on the context provided, the authors have made modifications to some model parameters and followed guidelines from the developers of darknet, a popular open-source neural network framework. This suggests that they may have utilized existing tools and libraries rather than developing their own custom deep learning pipeline. Therefore, it would be reasonable to assume that the code used in the study could potentially be found in the referenced GitHub repository or similar repositories containing implementations of deep learning models using darknet.