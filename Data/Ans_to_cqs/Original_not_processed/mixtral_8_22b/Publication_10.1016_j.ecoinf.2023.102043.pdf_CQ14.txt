Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

model for extracting the embeddings. 

These are pulled from YAMNet and then fed as input to a sequential 
and  a  reduce  mean  layer  mapping  to  the  classes  mentioned  above 
(Ntalampiras et al., 2021). At this point, the final layers of the network 
map the YAMNet embeddings to the available labels as shown in Fig. 5. 

3.3. Results on goat vocalization detection 

The  dataset  presented  in  Section  3.2  was  divided  into  70%  for 
training, 10% for validation, and 20% for testing purposes. The division 
was  kept  the  same  when  experimenting  with  RF  and  YAMNet-based 

3  The 

librosa  python  package  available  at  https://librosa. 

org/doc/latest/index.html was employed at this stage 

Fig. 3. A close-up picture of a Sensortile.

EcologicalInformatics75(2023)1020437AnnotationsFarm A: 21%Farm B: 16%Farm C: 19%Farm D: 44%FilesFarm A: 35%Farm B: 29%Farm C: 17%Farm D: 19%DurationsFarm A: 31%Farm B: 37%Farm C: 15%Farm D: 18%S. Ntalampiras et al.                                                                                                                                                                                                                           

table); it is reconstructed based on the start times and durations of both 
entities. A particular scenario is that of event instances whose duration is 
very short (impulsive events, duration d ≈ 0s) or impossible to detect 
(unknown events, duration d = (cid:0) 1). In these cases, the event is auto-
matically associated with all the audio files that cover its start time.

Fig. 6. Left to right: a) settings screen, where the events/activities of interest can be selected; b) page dedicated to F, where she/he can see the list of all interesting 
events/activities; there is the option to correct an erroneous system prediction; c) page dedicated to HF with the possibility to consult a daily graph of activities 
divided by class. The option to access the specific notifications screen is included. 

select  the  activities  marked  as  “viewed”  and  4.  a  form  where  S  can 
indicate the correct prediction in case a model misclassification occurs. 
Such  functionality  is  expected  to  assist  in  gathering  data  in  order  to 
improve the classification algorithm in an online mode. 

4. Dataset overview, annotation, and exploration

In  addition,  most  of 

Thus, the YAMNet-based  classification algorithm was immediately 
put into production to assist in the finer annotation of the detected vo-
calizations as described in the following section. At the same time, the 
present  algorithm  is  updated  on  a  regular  basis  with  new  data  as 
extracted by the clustering process described in Section 4.3 in order to 
further improve its performance. 

Table 1 
Confusion matrix obtained using the YAMNet-based classifier (%). The highest 
rates are emboldened.  

PresentedPredicted 

Goat 

Machinery 

Milk. Mach. 

Noise 

People 

Goat 
Machinery 
Milking machine 
Noise 
People 

98.1 
– 
– 
– 

2.2 

– 

61.9 
6.3 
1.6 
– 

– 

23.8 
81.3 
0.8 
– 

1.3 
9.5 
12.5 
97.6 
– 

0.6 
4.8 
– 
– 

97.8  

3.4. The smartphone application

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the given context does not provide information about how the hyperparameters of the model were optimized. Therefore, I cannot determine whether they used methods such as grid search or random search.