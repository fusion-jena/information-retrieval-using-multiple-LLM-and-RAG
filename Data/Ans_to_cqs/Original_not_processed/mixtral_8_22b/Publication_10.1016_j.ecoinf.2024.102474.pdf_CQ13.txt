Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

In this work, we resorted to purely deterministic variants of these 

architectures.  The  models  were  implemented  using  the  deep  learning 
framework PyTorch Lightning (Falcon, 2019) which is built on top of 
PyTorch  (Paszke  et  al.,  2019)  and  enables  improved  scalability.  The 
hyperparameters were tuned using an Optuna-based (Akiba et al., 2019) 
hyperparameter optimization procedure.

org/10.1016/j.ecoinf.2024.102474. 

References 

Akiba, T., Sano, S., Yanase, T., Ohta, T., Koyama, M., 2019. Optuna: A next-generation 
hyperparameter optimization framework. In: Proceedings of the 25th ACM SIGKDD 
International Conference on Knowledge Discovery & Data Mining, pp. 2623–2631. 
Arnab, A., Dehghani, M., Heigold, G., Sun, C., Luˇci´c, M., Schmid, C., 2021. ViViT: A video 
vision transformer. In: Proceedings of the IEEE/CVF International Conference on 
Computer Vision, pp. 6836–6846. 

Bashfield, A., Keim, A., 2011. Continent-wide dem creation for the european union. In: 
34th International Symposium on Remote Sensing of Environment. The GEOSS Era: 
Towards Operational Environmental Monitoring. Sydney, Australia. Citeseer, 
pp. 10–15.

4.3. The prediction task

3. Results 

3.1. Model training efficiency 

Model  training  on  our  hardware  (NVIDIA  GTX  1080  GPU)  took 
~460  h.  The  optimization  was  stopped  once  the  validation  ENS 
repeatedly  failed  to  improve  compared  to  the  score  evaluated  from 
previous  epochs.  The  model  at  the  epoch  with  the  highest  attained 
validation  score  was  selected.  We  noted  a  significant  acceleration  of 
convergence  when  employing  the  baseline  framework,  as  shown  in

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific details about the hyperparameters used in the deep learning model. However, it mentions that the hyperparameters were tuned using an Optuna-based hyperparameter optimization procedure. This suggests that various hyperparameters such as learning rate, batch size, number of layers, etc., could have been considered during the optimization process. Unfortunately, without further information or access to the original research paper, it is impossible to determine the exact set of hyperparameters used in the final model.