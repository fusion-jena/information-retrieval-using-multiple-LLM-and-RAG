Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., 
Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, ´E., 2011. Scikit-learn: machine 
learning in Python. J. Mach. Learn. Res. 12, 2825–2830. 

Petty, A.M., Setterfield, S.A., Ferdinands, K.B., Barrow, P., 2012. Inferring habitat 

suitability and spread patterns from large-scale distributions of an exotic invasive 
pasture grass in North Australia. J. Appl. Ecol. 49 (3), 742–752. https://doi.org/ 
10.1111/j.1365-2664.2012.02128.x. 

Prasai, R., Schwertner, T.W., Mainali, K., Mathewson, H., Kafley, H., Thapa, S., 

Adhikari, D., Medley, P., Drake, J., 2021. Application of Google earth engine python 
API and NAIP imagery for land use and land cover classification: A case study in 
Florida, USA. Eco. Inform. 66, 101474 https://doi.org/10.1016/j. 
ecoinf.2021.101474.

structures (e.g., roads and buildings) and water from slowing down the 
classification processing. This step reduced the average number of pixels 
per scene the classification model had to analyze to 3,757,323 and took, 
on average, 18 s per scene.

Ustin, S.L., DiPietro, D., Olmstead, K., Underwood, E., Scheer, G.J., 2002. Hyperspectral 

remote sensing for invasive species detection and mapping. In: IEEE International 
Geoscience and Remote Sensing Symposium, 3, pp. 1658–1660. https://doi.org/ 
10.1109/IGARSS.2002.1026212. 

Vali, A., Comai, S., Matteucci, M., 2020. Deep learning for land use and land cover 

classification based on hyperspectral and multispectral earth observation data: a 
review. Remote Sens. 12 (15), 2495. https://doi.org/10.3390/rs12152495. 
Van Der Walt, S., Sch¨onberger, J.L., Nunez-Iglesias, J., Boulogne, F., Warner, J.D., 
Yager, N., Gouillart, E., Yu, T., 2014. Scikit-image: image processing in Python. 
PeerJ 2, e453. https://doi.org/10.7717/peerj.453.

Technologies to remotely collect large streams of environmental data 
combined  with  artificial  intelligence  techniques  create  a  unique  op-
portunity to accelerate and transform how we monitor biodiversity and 
evaluate the efficacy of restoration and conservation actions (Cavender- 
Bares et al., 2022; Galaz García et al., 2023a; Tuia et al., 2022), opening 
the  door  to  understanding  biodiversity  and  ecosystems  at  spatial  and 
temporal scales that would not be achievable through intensive empir-
ical data collection (Beery et al., 2022; Brown et al., 2022; Murray et al., 
2020). Indeed, machine learning (ML) applied to remotely sensed im-
ages has shown great promise in detecting and mapping the occurrence 

* Corresponding author at: National Center for Ecological Analysis and Synthesis, University of California, Santa Barbara, CA 93101, United States of America. 

E-mail address: c_galazgarcia@ucsb.edu (C. Galaz García).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide specific information about the data annotation techniques used in the deep learning pipeline. However, common data annotation techniques used in deep learning include bounding box annotation, semantic segmentation, and instance segmentation. Bounding box annotation involves drawing rectangular boxes around objects of interest within images or video frames. Semantic segmentation is the process of classifying each pixel in an image into a category, such as sky, road, or building. Instance segmentation combines object detection and semantic segmentation by identifying individual instances of objects within an image and assigning them a label. These techniques can be used to train deep learning models for various applications, including object detection, image recognition, and autonomous driving.