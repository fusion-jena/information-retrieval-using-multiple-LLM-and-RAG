Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5ValidationFramesValidationEC ClassesPredictedEC ClassesPerformance* environmentalconditionswith highestprobabilitiesPredictedEC ClassesProbabilityTurbidity79.12 %Biofilm14.11 %Overexposure6.65 %Bubbles0.07 %Clear0.05 %Low Light0.0 %decending orderJ. Soom et al.

. 

2.4.1. Training the environmental condition model

classification  pipeline.  The  validation  performance  of  CNN  Model  4 
with respect to each of the six environmental conditions is shown in the 
confusion matrix of Fig. 7 (b).

Model 2 

Model 3 

Model 4 *  Model 5 

Accuracy 
Precision 
Recall 

Sensitivity 

99.1% 
97.3% 
97.3% 

99.1% 
97.4% 
97.4% 

98.8% 
96.5% 
96.5% 

99.2% 
97.5% 
97.5% 

98.9% 
96.8% 
96.8% 

Recall 

99.5% 

99.5% 

99.3% 

99.5% 

99.4% 

Specificity 

F1 Score 
Avg. True 
Positives 
Avg. False 
Positives 
Avg. True 

Negatives 

Avg. False 

Negatives 

97.3% 
243.2 
(16.2%) 
6.8 
(0.5%) 
1243.2 
(82.8%) 
6.8 
(0.5%) 

97.4% 
243.5 
(16.2%) 
6.5 
(0.4%) 
1243.5 
(83.0%) 
6.5 
(0.4%) 

96.5% 
241.3 
(16.0%) 
8.7 
(0.6%) 
1241.3 
(82.8%) 
8.7 
(0.6%) 

97.5% 
243.7 
(16.2%) 
6.3 
(0.4%) 
1243.7 
(83.0%) 
6.3 
(0.4%) 

96.8% 
242 
(16.2%) 
8 (0.5%) 

1242 
(82.8%) 
8 (0.5%)  

* Best CNN model based on Accuracy.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific criteria used to determine when training is complete for the environmental condition models. However, it can be inferred from general machine learning practices that common stopping criteria include reaching a certain number of epochs or iterations, achieving a desired level of accuracy or loss, or observing no significant improvement in the validation set performance over several epochs (i.e., a validation loss plateau). In this case, since the authors present various metrics such as accuracy, precision, recall, sensitivity, and F1 score for different models, they might have chosen one or more of these metrics as their stopping criterion during training.