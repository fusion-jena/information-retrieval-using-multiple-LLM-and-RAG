Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The Inception-V3 model accepts images resized to (299, 299) pixels 
but ViT and ResNet resize to (224, 224) pixels. Dataset imbalance was 
dealt with by including class weights in the cross-entropy loss function. 
For the training we used AdamW optimizer for Hugging Face models, 
which is the default optimizer in the transformers library by Hugging-
Face. For Inception-V3, we used Adam since that was the optimizer used 
in  previous  work  (and  AdamW  is  not  available  in  Keras).  We  used  a 
(cid:0) 4  for 
batch  size  of  16  examples  and  the  learning  rate  was  set  to  10
(cid:0) 5  for  Vanilla  Inception-V3  and  ViT.  For  Deep  Otolith 
ResNet  but  10
(cid:0) 4 as suggested by Politikos 
Inception we used a learning rate of 4 × 10
et  al.  (2021).  For  every  fine-tuning  experiment,  the  model  with  the 

smallest validation loss was used for evaluation on the test set. 

2.3. Performance

ResNet-50 is a convolutional neural network model that uses skip 
connections,  which  made  it  possible  to  get  good  performance  with 
deeper models than was previously possible (He et al., 2015). Training 
deep neural networks can result in exploding gradients, and skip con-
nections  were  introduced  to  ameliorate  that  problem.  ResNet-50  was 
chosen  for  comparison  as  it  is  a  proven  CV  classification  model.  It  is 
commonly used and provides a well-performing baseline. 

Inception-V3  is  a  convolutional  neural  network  used  for  image 
classification, that has an auxiliary classifier that acts as a regularizer 
(Szegedy et al., 2015b). The Inception-V3 architecture is built on pre-
vious Inception models, with the aim of making the V3 computationally

In addition to adding more features to improve our machine learning 
models,  we  also  studied  the  value  of  adding  more  training  data.  The 
learning curve in Fig. 11 shows that our models achieved relatively high 
accuracy  even  with  a  training  dataset  of  only  100  images.  The  CLIP 
regression model had an accuracy of 48.95%, while the ViT fine-tuning 
model  had  an  accuracy  of  42.35%.  The  slope  of  the  learning  curve 
suggests that the CLIP regression model benefits more from additional 
training data than the ViT fine-tuning model in the range of hundreds to 
a  few  thousand  examples.  It  is  unclear,  however,  whether  the  fine- 
tuning  approach  could  eventually  outperform  the  CLIP  regression 
model,  or  how  many  labeled  examples  would  be  needed  for  this  to 
happen. It is also unclear at what point the accuracy of the models will 
reach a saturation point, and whether they will be able to achieve the

For fine-tuning, we used the HuggingFace implementations of ViT 
(“google/vit-hugepatch14–224-in21k”) and ResNet (“microsoft/resnet- 
50”)  but  the  Keras  implementation  of  Inception-V3.  All  fine-tuning 
models  had  been  pre-trained  on  the  ImageNet  (Deng  et  al.,  2009) 
dataset. 

We replaced the classifier head on all models so that it received the 
output of the models along with the additional parameters, quarters and 
length. We also tried adding additional dropout and dense layers at the 
end of the Inception model as for the DeepOtolith model Politikos et al. 
(2021). To differentiate we use Deep Otolith Inception-V3 for the model 

EcologicalInformatics76(2023)1020463A.R. Sigurðard´ottir et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. One such technique is stratified splitting, where the dataset is divided into training and testing sets while maintaining the same distribution of classes within each set. This ensures that both sets have similar representations of each class, reducing any potential biases caused by uneven distributions.

Another method to tackle data bias is through oversampling or undersampling. Oversampling involves duplicating samples from underrepresented classes to balance the dataset, while undersampling removes samples from overrepresented classes. Both methods help create a more balanced dataset, improving the overall performance of the deep learning model.

Additionally, diverse data collection plays a crucial role in addressing data bias. By collecting data from various sources and ensuring diversity among samples, the risk of having a skewed dataset is minimized. This helps prevent the model from being biased towards certain characteristics present in the majority of the collected data.

In the given context, the issue of dataset imbalance was dealt with by including class weights in the cross-entropy loss function. Class weights assign higher importance to minority classes, helping the model learn better from these classes and reducing the impact of dominant classes on the final predictions.