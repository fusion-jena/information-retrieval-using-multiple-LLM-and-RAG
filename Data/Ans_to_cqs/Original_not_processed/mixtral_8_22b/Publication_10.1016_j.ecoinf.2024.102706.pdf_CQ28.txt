Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

linear to machine learning methods, were fitted in training data to
construct regression equations. We used multiple linear regression, Enet,
SVM, RF, XGboost and LightGBM to predict canopy cover from planet
data. In general, all the mentioned models are used in machine learning
as they use algorithms to automatically learn patterns and relationships
from data to make predictions or decisions. However, we categorised

EcologicalInformatics82(2024)1027065A. Gyawali et al.

Table 4
The optimised hyperparameter values with grid search range in machine
learning models.

Model

Hyperparameters

Grid search

Optimised value

Enet

SVM

RF

Xgboost

LightGBM

α
l1_ratio

Cost (C)
gamma
Kernal
epsilon

n_estimators
max_features
max_depth
min_samples_split
min_samples_leaf

n_estimators
max_depth
colsample_bytree
min_child_weight
subsample
learning_rate

n_estimators
max_depth
learning_rate
num_leaves
feature_fraction
bagging_fraction
bagging_freq

approach (Li et al., 2022) have also been efficiently used in satellite
image-based vegetation indices for predicting forest canopy cover. The
application of deep convolutional neural networks (DCNN) for semantic
segmentation has also been investigated across various types of young
vegetation cover (Cameron et al., 2022). Regarding advanced machine
learning approaches, the RF and SVM were the foremost priorities for
the researchers for canopy cover modelling from O'brien, 2007 to 2017,
as reported by Thanh Noi and Kappas (2017). Other advanced ML ap-
proaches have recently been added to similar studies (Li et al., 2022;
Zhou et al., 2020). The boosting methodology represents a synthesis of
robust prediction techniques, frequently surpassing the performance of
individual models such as single decision trees. The emergence of
refined ensemble machine learning techniques like light gradient
boosting machines
represents notable advancements

100
5
0.05
20
0.9
0.8
5

linear as a simple statistical model and the rest of the advanced machine
learning models as machine learning. The regression analyses were
conducted using Python 3.12.2, distributed by Anaconda Inc. The Scikit-
learn library (Pedregosa et al., 2011) was employed for all models except
those utilising XGboost and LightGBM. For XGboost and LightGBM
models, the respective Python libraries “xgboost” (Chen and Guestrin,
2016) and “lightgbm” (Ke et al., 2017) were utilised. Additionally, a 5-
fold cross-validation grid search strategy was implemented to tune
hyperparameters within the training dataset for all machine learning
models, leveraging functionalities inherent in their respective Python
packages. The information on hyperparameters and their optimised
value for all machine learning models are presented in Table 4. More-
over, we converted the canopy cover output percentage to a fraction
(0–1) for convenience and smoothness in the further calculation.

imagery products equipped with three
different instruments: PlanetScope2 (PS2), PlanetScope2 Super Dove
(PS2 SD), and next-generation PSBlue Super Dove (PSB.SD) (Planet
Team, 2017). The most recent is PSB.SD, which offers three bands
(RGB), four bands (RGB - NIR) and eight bands (RGB - NIR - Coastal Blue
- Green I -Yellow-Red Edge) imagery which is available from mid-March
2020 to date. The PS2.SD (March 2019–April 2022) and PS2 (July
2014–April 2022) offer three and four-band imagery. In our study, four
bands of imagery from PS2 were acquired on 27 July 2020, only two
days before the LiDAR scanning. This cloud-free imagery was the most
proximate one accessible from a selection including 3,4, and 8 bands
PS2, PS2.SD, and PSB.SD, retrieved from the Planet Lab database. The
details of Planet's sensor specifications are given in Table 2. We used an
orthorectified, radiometrically calibrated surface reflectance image
(Level 3B) and atmospherically corrected raster products (Frazier and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, there is no explicit mention of any specific platform being used to deploy the deep learning model. Therefore, it cannot be determined which platform was used to deploy the deep learning model based solely on this context.