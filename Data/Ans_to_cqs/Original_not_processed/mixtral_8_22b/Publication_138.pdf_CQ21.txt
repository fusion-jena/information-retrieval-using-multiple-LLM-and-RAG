Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The pooling operator is connected after this layer for extracting the main features of a certain area, 
reducing the number of parameters, and preventing the model from over fitting. The maximum pooling 
with a 2 × 2 window and 2 strides is used in this layer. The pooling result is the data with the size of 56 
× 56 × 64.  

After pooling, the LRN (Local Response Normalization) is used to normalize the local response. 
The LRN enhances the larger response value and reduce the smaller response value. Thus, the LRN 
also can improve the generalization of the model. The output result of the LRN is the data with the size 
of 56 × 56 × 64.

After first inception modules, second and third inception modules are set in turn. The output is the 
data with the size of 28 × 28 × 480. Then, the pooling and LRN are performed, the data with the size of 
14 × 14 × 480 is output. 

Ninth  layer: It  is a convolution layer with  480  3  ×  3  filters  and  their stride  is  1. The ReLU is 
selected as the activation function. The result of this layer is the data with the size of 14 × 14 × 480. 
After convolution, the data is performed by LRN. Then, the maximum pooling with a 3 × 3 window 
and 2 strides is used. The output result is the data with the size of 6 × 6 × 480. 

Tenth layer: This layer is dropout layer which is used to improve the generalization capability. 

The size of output result is 17,280.

Second  layer:  It is a convolution layer, which is with 128 3 × 3 filters and the stride is 1. The 
ReLU is selected as the activation function. The LRN is connected after this layer, the output results is 
the data with the size of 56×56×128. Then above data is processed by pooling operator with a 3 × 3 
window and 2 strides. The output result of this layer is the data with the size of 28 × 28 × 128. 

Third  to  eighth  layer:  These  layers  consist  of  three  inception  modules  which  consist  of  seven 

convolution modules and a pooling module. They are divided into the following four branches.

B 

1521 
6705 
1564 
6748 
1185 
6885 
1160 
6661 
1786 
6452 
1004 
6885 
2109 
6314 
1805 
6471 
478 
6979 
1634 
6294 

1131 

Accuracy (%) 

93.00 

93.00 

94.48 

94.41 

90.12 

95.42 

89.60 

91.22 

97.57 

91.18 

93.00 

Figure 7 shows the relation between Min-batch size and Accuracy, Epoches. As we see in Figure 
7(a), when the Min-batch size is 128, the accuracy is the highest. This indicates the Min-batch size is 
relation to the accuracy of algorithm. In Figure 7(b), the larger is the Min-batch size, the larger is the 
number of epochs. When the Min-batch size is more than 256, the number of epochs is sharp large. The 
larger is the number of the epochs, the more is the consumed time when the algorithm converges. We 
also  can  see,  when  the  Min-batch  size  is  128,  the  accuracy  of  algorithm  is  high,  and  the  number  of 
epochs is relatedly small.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no explicit information about the specific postprocessing steps involved after the model training. However, it does mention some techniques used during the model building process such as Local Response Normalization (LRN), Dropout, Maximum Pooling, and Convolution Layers.

Typically, after training a deep learning model like the one described here, common postprocessing steps might include generating saliency maps to visualize important regions in input images, calculating metrics such as accuracy or loss to evaluate the performance of the model, and creating confusion matrices to understand misclassifications made by the model. But without further details about the specific task or application of this model, it's not possible to provide a definitive list of postprocessing steps.