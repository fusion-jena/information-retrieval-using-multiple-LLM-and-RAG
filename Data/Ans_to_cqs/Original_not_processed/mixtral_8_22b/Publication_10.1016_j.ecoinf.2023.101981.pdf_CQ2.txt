Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

different Sika Deer vocalizations (range 2–70%, Enari et al., 2019). A 
recent study using the Red Deer as a study species obtained recall rates 
of  approximately  90%  for  the  five  supervised  machine  learning  algo-
rithms tested, suggesting that the creation of sophisticated models could 
clearly improve the detection of ungulate vocalization.

The ROIs identified by Kaleidoscope were automatically grouped by 
k-means  clustering  into  groups  of  similar  sounds  using  the  cluster 
analysis  function  of  Kaleidoscope.  ROIs  within  the  clusters  were  also 
automatically shortened by similarity, and therefore, clusters are mainly 
composed  of sounds of the same species, while the first ROIs of each 
cluster  are  the  best  examples  of  the  sounds  within  that  cluster.  The 
“maximum  distance  from  cluster  center  to  include  outputs  in  cluster. 
csv”  parameter  was  set  to  its  maximum  (2.0),  which  maximized  the 
number of ROIs detected by Kaleidoscope. Such a parameter can be used

is the FFT window size. We opted for a larger FFT window size, which 
should  improve  the  resolution  at  lower  frequencies  on  which  cows 
vocalize. Finally, while Karmiris et al. (2021) used the same settings for 
detecting  the  three  ungulate  species  (e.g.,  their  minimum  frequency 
introduced  for  detecting  cow  vocalization  was  much  higher,  500  Hz, 
than the mean minimum frequency measured in our dataset, approxi-
mately 250 Hz), we fitted cow-specific parameters in the model, which 
could also partly explain why our model detected a much larger number 
of cow vocalizations.

was removed from the analyses, while we verified (acoustically and/or 
visually) each ROI within the cluster “Cow” to remove false positives. 
The recognizer’s performance was evaluated by measuring its recall 
rate and precision (Knight et al., 2017). The recall rate was estimated by 
dividing  the  number  of  cow  calls  detected  by  Kaleidoscope  by  the 
number of cow calls present in the sound recordings and is interpreted as 
an index of the percentage of calls that the recognizer is able to detect 
(Knight et al., 2017). The number of cow calls in sound recordings was 
estimated by the same experienced observer who visually and acousti-
cally  checked  200  selected  recordings  (100  recordings  with  known 
presence, 25 per site, and 100 randomly selected recordings from those 
recorded between 4 p.m. and 6 p.m.). During the review process, the 
observer had no information about the date, hour, or station identifi-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the deep learning pipeline primarily uses audio data. This is evident from the mention of various animal vocalizations, such as those of the Sika Deer and Red Deer, as well as the use of Kaleidoscope, a software tool designed for analyzing bioacoustic signals. Furthermore, the context discusses the use of Fast Fourier Transform (FFT) window sizes, which is a common technique used in signal processing, including audio analysis. Additionally, the context mentions the evaluation of the recognizer's performance based on the recall rate and precision, which are metrics often used in evaluating the performance of audio recognition systems. Therefore, it can be concluded that the primary data format used in this deep learning pipeline is audio data.