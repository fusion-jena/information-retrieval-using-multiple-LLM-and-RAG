Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

PConv networks 

256 × 256/512 × 512 

1 
2e-4 

Adam optimizer 
per-pixel loss, perceptual 
loss, style loss and total 
variation loss 
50 
Pre-trained on ImageNet 

Pix2Pix 
networks 

256 × 256/512 
× 512 
1 
9e-5 

Classification 
networks 

256 × 256/512 
× 512 
32 
0.03 

Adam optimizer 
Adversarial loss 
and L1 loss 

Adam optimizer 
Cross-entropy 
loss 

50 
Trained from 
Scratch 

20 
Pre-trained on 
ImageNet  

Input 

dimension 

Batch size 
Learning 
rate 
Optimizer 
Loss function 

Epochs 
Pre-trained 
network 

applied.  All  input  images  were  preprocessed  by  mean  centering  the 
image with ImageNet values and then rescaled between 0 and 1. Since 
our dataset was balanced, both networks were trained with a learning 
rate of 0.03, cross-entropy loss as a loss function optimized by Adam 
optimizer (Kingma and Ba, 2014). Table 2 summarizes the parameter 
used for training each model. 

3.4. Performance evaluation

ments.  Since  all  networks  used  present  different  architectural  setups, 
different training procedures have been discussed. Each category of a 
CNN  (i.e.  PConv  networks,  Pix2Pix  networks  and  classification  net-
works)  consisted  of  multiple  trained  models  so  the  same  training

Fig. 4. (a)Sample image, (b) the generated mask and the masked image in (c) used for training reconstruction models.  

EcologicalInformatics61(2021)1012435B.R. Hussein et al.                                                                                                                                                                                                                              

parameters  were  used  in  each  category  unless  otherwise  specified. 
Where available, the original implementation reported earlier in liter-
ature were used (Isola et al., 2017; Liu et al., 2018). 

3.3.1. PConv network

The original implementation of PConv network required a two-phase 
training process (Liu et al., 2018). This is because the generated holes 
presented  a  problem  for  batch  normalization  layer  when  computing 
mean  and  variance  of  the  hole  pixels.  In  this  study,  all  models  were 
trained in a single process while freezing the batch normalization layer 
in the encoder part as the network used pre-trained weights with a small 
batch size of 1. The models were optimized using Adam optimizer with a 
learning rate of 0.0002 while using relu activation for encoder part and 
leakyRelu  activation  for  the  decoder  part  of  the  network.  All  models 
were  trained  for  50  epochs.  For  each  training  epoch,  a  model  was 
evaluated using the validation set and was saved as the best model based 
on a validation loss. 

3.3.2. Pix2Pix network

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no information provided about which platform was used to deploy the deep learning model. Therefore, I cannot provide an accurate answer to this query.