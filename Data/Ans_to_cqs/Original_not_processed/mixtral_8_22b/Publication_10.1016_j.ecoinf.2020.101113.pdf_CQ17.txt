Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3.  Model training 

2.3.1.  Training data preprocessing 

The  CNN  model  used  in  this  study  requires  equally  sized  input 
images. We chose a time-frequency input window size of 2 s as it is near 
the mean and median template duration across target call types (Fig. 2). 
Most  call  types  have  a  duration  below  1  s,  and  for  those  above  2  s,

causes nodes in the previous FC layer to be probabilistically ignored in 
each  training  iteration,  such  that  a  different  subset  of  nodes  is  con-
nected to the final FC layer at each iteration. This emulates training a 
group  of  different  models  and  reduces  the  chance  of  overfitting.  The 
first  FC  layer  consisted  of  512  nodes  and  used  the  common  “ReLU” 
activation  function,  which  simply  converts  negative  inputs  to  0.  The 
following drop-out layer was assigned a drop-out rate of 0.5, such that 
each node was ignored with a 50% probability. The final layer consists 
of 24 nodes, corresponding to the number of target species, and each 
node was assigned a sigmoid activation function. The sigmoid function 
S, defined below, maps the input to the range [0,1], and is commonly 
used for the prediction of binary outcomes. In our case, an independent 
output  score  within  [0,  1]  for  each  species  was  desired,  to  allow  for

learning, wherein a model already optimized for a similar dataset is re- 
trained with new data. We used a ResNet50 model, pre-trained on the 
ImageNet dataset, which contains over one million photo images across

1000 classes (Deng et al., 2009). Although ImageNet does not contain 
spectrograms,  models  pre-trained  with  the  dataset  learn  a  variety  of 
image features that have been successfully tuned to spectrogram clas-
sification  previously  (Lasseck,  2019;  Florentin  et  al.,  2020).  While 
previous  studies  have  found  optimal  performance  using  ensembles  of 
multiple CNN models (Kahl et al., 2017; Lasseck, 2019; Florentin et al., 
2020), in the interest of prediction efficiency and reasonable memory 
requirements, we chose to evaluate a single ResNet50 model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, there is mention of a specific regularization method used to prevent overfitting in the deep learning pipeline - Dropout. Dropout is a technique where during training, some number of neuron outputs are randomly ignored or "dropped out." This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In doing so, it reduces overfitting by providing a way of automatically and adaptively regularizing neural networks.

In the described model, a drop-out layer was assigned a drop-out rate of 0.5, meaning each node was ignored with a 50% probability. This means that half of the nodes in the first fully connected (FC) layer were dropped out in each training iteration, causing nodes in the previous FC layer to be probabilistically ignored. This emulated training a group of different models and reduced the chance of overfitting.