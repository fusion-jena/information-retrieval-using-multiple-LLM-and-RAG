Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

sample with its corresponding remote sensing sequence of data. Finally, 70% of the data were used for training 
the algorithms whereas the remaining 30% were used only for validation.

https://doi.org/10.1038/s41598-020-74215-5

10

Vol:.(1234567890)www.nature.com/scientificreports/ 15.  Chen, Y., Lin, Z., Zhao, X., Wang, G. & Gu, Y. Deep learning-based classification of hyperspectral data. IEEE J. Sel. Top. Appl. Earth 

Observ. Remote Sens. 7, 2094–2107 (2014).

 16.  Li, W., Fu, H., Yu, L. & Cracknell, A. Deep learning based oil palm tree detection and counting for high-resolution remote sensing 

images. Remote Sens. 9, 22 (2017).

 17.  Hu, F., Xia, G.-S., Hu, J. & Zhang, L. Transferring deep convolutional neural networks for the scene classification of high-resolution 

remote sensing imagery. Remote Sens. 7, 14680–14707 (2015).

 18.  Liang, H. & Li, Q. Hyperspectral imagery classification using sparse representations of convolutional neural network features. 

Remote Sens. 8, 99 (2016).

 19.  Zhang, L., Zhang, L. & Du, B. Deep learning for remote sensing data: A technical tutorial on the state of the art. IEEE Geosci. 

Remote Sens.Mag. 4, 22–40 (2016).

ings of the 23rd ACM Sigkdd International Conference on Knowledge Discovery and Data Mining, 1663–1672 (2017).

  6.  Shi, X. et al. Deep learning for precipitation nowcasting: A benchmark and a new model. Adv. Neural Inf. Process. Syst. 20, 

5617–5627 (2017).

  7.  Reichstein, M. et al. Potential of new machine learning methods for understanding long-term interannual variability of carbon 

and energy fluxes and states from site to global scale. AGUFM 2016, B44A-07 (2016).

  8.  Liu, Y. et al. Deep learning for pixel-level image fusion: Recent advances and future prospects. Inf. Fusion 42, 158–173 (2018).
  9.  Wang, S. et al. A deep learning framework for remote sensing image registration. ISPRS J. Photogramm. Remote Sens. 145, 148–164 

(2018).

 10.  Lyu, H., Lu, H. & Mou, L. Learning a transferable change rule from a recurrent neural network for land cover change detection. 

Remote Sens. 8, 506 (2016).

Recently, some approaches have been proposed to evaluate the interpretability of deep learning  models33,34 
including methods based on model decomposition, sensitivity analysis, and feature visualisation. The relevance of 
network inputs can for example be obtained by the gradient-based sensitivity analysis (GBSA), which computes 
the prediction function squared partial derivatives with a standard gradient  backpropagation35. The Layer-wise 
Relevance Propagation (LRP)36 propagates the prediction backward in the neural network using propagation 
rules until the input features are reached. Arras et al.37 proposed a LRP for LSTM networks that provided better 
results than the GBSA on a five-class prediction task. Class activation maps were used to point out the most 
discriminative regions used by a CNN to identify a  class38.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide specific information about addressing data bias during preprocessing of the deep learning pipeline. However, it mentions that 70% of the data was used for training while the remaining 30% was used for validation. This suggests that stratified sampling might have been employed to ensure that both training and validation sets contain representative samples from all classes.

Stratified sampling is a technique where the dataset is divided into subsets or strata based on certain criteria such as class labels. Then, samples are drawn randomly from each stratum to create the final dataset. This ensures that the resulting dataset has a similar distribution of classes as the original dataset.

Other common techniques to address data bias include oversampling, undersampling, and diverse data collection. Oversampling involves duplicating examples from the minority class to balance the dataset, while undersampling removes examples from the majority class. These techniques should be used carefully as they may introduce overfitting or loss of important information.

Diverse data collection aims to collect more data from underrepresented groups or classes to improve the overall representation in the dataset. This approach requires careful consideration of ethical implications and privacy concerns.

In summary, although the given context does not explicitly mention any techniques to address data bias during preprocessing of the deep learning pipeline, stratified sampling could have been employed to maintain class balance between training and validation datasets. Other commonly used techniques include oversampling, undersampling, and diverse data collection.