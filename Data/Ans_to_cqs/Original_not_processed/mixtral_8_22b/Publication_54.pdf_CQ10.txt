Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

acquired while learning the 27 endemic bird species should be
used to solve related tasks pertaining to the 29 endemic bird
species. Otherwise, considerable time would be spent every
time a new dataset of birds is used. Therefore, to implement
the entire process, we adopted a deep-learning-based model
(Inception-ResNet-v2) to train and learn the features of 27
endemic bird species (source domain). Then, the learned fea-
tures were transferred to a second target network to train the
newly added dataset on endemic bird species (target domain).
Thus, the problem was deﬁned as follows: for a given source
domain DS and learning task LT and target domain DT
and learning task TL, the transfer learning technique helps
improve the learning of the target predictive function fT (·)
in DT using the knowledge acquired from DS and LT , where
DS (cid:54)= DT or LT (cid:54)= TL [25], [26]. Transfer learning method
enables to utilize knowledge from previously learned tasks

102976

VOLUME 9, 2021

Y.-P. Huang, H. Basanta: Recognition of Endemic Bird Species Using Deep Learning Models

A. ACCURACY COMPARISONS OF BENCHMARK
NETWORK MODELS
Several experiments were conducted to evaluate the accuracy
and practicability of the proposed method. For the quantita-
tive analysis of the models, we ﬁrst compared state-of-the-art
deep learning backbone models, such as Inception-ResNet-
v2 [27], Inception-v3 [28], Xception [32], ResNet101 [29],
and MobileNetV2 [33]. Fig. 5 lists the classiﬁcation accura-
cies achieved by the learning models.

Inception-ResNet-v2 was found to consistently outperform
the other existing learning networks by attaining 100% train-
ing accuracy, 97.47% validation accuracy, and 97.11% test
accuracy.

FIGURE 5. Comparison performance of various AI models.

IV. EXPERIMENTAL SETTINGS
To extract the relevant features of birds, we randomly split
the endemic bird data into 3,132 images for training and
760 images for testing. To allow the deep networks to con-
verge and improve the ability of the model to generalize
adeptly, we augmented the training dataset 10 times, resulting
in a total of 31,320 images. Then, 25,056 (80%) images were
used for training and 6,264 (20%) were used for validation.
The Inception-ResNet-v2 model was trained using the mini-
batch gradient descent algorithm with the batch size set to
32 and the learning rate maintained at 0.0001. The Adam
optimizer was used to ﬁne-tune the model with the following
parameters:

• Exponential decay rate of ﬁrst-moment estimation

of 0.9.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the provided information, there is no mention of a specific code repository link for the deep learning pipeline used in this study. It appears that the authors have not shared their implementation details publicly via platforms like GitHub, GitLab, or BitBucket. However, if you are interested in replicating their work, I recommend reaching out to the corresponding author directly or checking any supplementary materials associated with the paper.