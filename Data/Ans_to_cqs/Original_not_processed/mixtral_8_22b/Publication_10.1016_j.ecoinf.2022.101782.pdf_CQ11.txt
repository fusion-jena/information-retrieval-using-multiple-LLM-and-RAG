Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5. Discussion 

In this study we developed a workflow which leveraged citizen sci-
ence data to extract further relevant records from social media posts in 
the  same  region.  The  workflow  functions  as  a  data  filter  enabling 
downsampling of an initially very large dataset into a human analysable 
subset - in our case containing 0.5% of the original posts. By massively 
reducing  data  volumes,  it  becomes  realistic  to  analyse  the  remaining 
data by hand to select true positives, with around one hour required for 
the  4000  or  so  candidate  posts  we  identified.  Our  workflow  thus  ad-
dresses  the  research  gap  identified  by  Burke  et  al.,  2022,  using  gen-
eralisable  methods  to  extract  target  data  from  various,  unverified 
sources to enrich data.

EcologicalInformatics71(2022)10178210M.C. Hartmann et al.                                                                                                                                                                                                                          

Data availability 

The  code  and  data  are  available  at  https://gitlab.vgiscience. 

de/integration-quality/integration-quality 

Acknowledgements

identified by both textual and visual analysis, we could achieve almost 
perfect  precision  (0.992),  at  the  cost  of  lower  recall.  Thirdly,  by 
combining the two approaches, we increased the extracted data volume 
by almost 14%, while still downsamping the original dataset by around 
99.5% and with a precision 0.636. Recall for the workflow overall is not 
known, since this would require manual analysis of over 600,000 posts. 
Our results thus go further than previous work by demonstrating how 
images  retrieved  using  text  and  image  metadata  can  be  combined  to 
achieve  very  high  precision,  or  merged  to  increase  recall  while  still 
filtering initial datasets very effectively. To better understand our results 
and their transferability to other species, we looked more closely at data 
quality.  Flickr  users  often  used  relevant  textual  descriptions  to  label 
their  red  kite  sightings  with  their  captured  images.  This  high  textual

Interest  in  the  potential  of  big  data,  or  more  generally  new  data 
sources,  for  indicator  production  has  been  fuelled  by  an  explosion  of 
interest  in  data  driven  research,  made  possible  by  both  increased 
accessibility to a wide variety of novel data sources and increasing ease 
of  use  of  technology  to  build  workflows  incorporating,  for  example, 
classification tools trained on very large datasets and running externally 
in the cloud (Yang et al., 2017).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data and code for the deep learning pipeline discussed in the paper are available at <https://gitlab.vgiscience.de/integration-quality/integration-quality>. However, please note that this information was taken directly from the given context and I do not have any additional knowledge about the specific project or its details beyond what was provided.