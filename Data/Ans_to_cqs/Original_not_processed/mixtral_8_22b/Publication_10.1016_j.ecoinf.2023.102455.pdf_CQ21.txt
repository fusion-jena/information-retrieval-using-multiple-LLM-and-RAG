Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

MVMD-KELM 

MVMD-CNN-BiRNN 

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

MVMD-CNN-BiGRU 

MVMD-RVFL 

MVMD-KELM 

MVMD-CNN-BiRNN 

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

Phase 

Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 

R 

0.985 
0.955 
0.918 
0.944 
0.904 
0.928 
0.998 
0.943 
0.903 
0.811 
0.844 
0.783 
0.845 
0.803 
0.895 
0.815 
0.998 
0.924 
0.907 
0.921 
0.904 
0.887 
0.998 
0.911 
0.778 
0.545 
0.623 
0.509 
0.682 
0.525 
0.839 
0.496 

RMSE 

MAPE 

0.179 
0.247 
0.364 
0.257 
0.395 
0.289 
0.072 
0.289 
0.398 
0.432 
0.492 
0.497 
0.491 
0.459 
0.410 
0.429 
0.022 
0.330 
0.386 
0.296 
0.397 
0.387 
0.070 
0.320 
0.619 
0.706 
0.717 
0.654 
0.671 
0.639 
0.511 
0.629

3.3. Machine learning tuning

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

Phase 

Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 

R 

0.985 
0.960 
0.960 
0.949 
0.972 
0.930 
0.999 
0.955 
0.921 
0.698 
0.865 
0.662 
0.843 
0.668 
0.873 
0.689 
0.998 
0.933 
0.952 
0.930 
0.964 
0.928 
0.997 
0.929 
0.792 
0.603 
0.826 
0.594 
0.783 
0.591 
0.801 
0.598 

RMSE 

0.072 
0.098 
0.117 
0.113 
0.100 
0.130 
0.024 
0.105 
0.164 
0.253 
0.210 
0.266 
0.225 
0.263 
0.205 
0.256 
0.010 
0.130 
0.128 
0.130 
0.112 
0.133 
0.024 
0.141 
0.256 
0.284 
0.236 
0.287 
0.261 
0.287 
0.251 
0.285 

MAPE

CNN Layers = 2, filters = 64, kernel_size =
[1,4], BiGRU Layers = 1, BiGRU neurons =
30, Optimizer: Adam, activation function =
‘relu’, epochs = 43,batch_size = 32, 
learning_rate = 0.000455, Dense = 100 
CNN Layers = 2, filters = 64, kernel_size =
[1,4], BiGRU Layers = 1, BiGRU neurons =
30, Optimizer: Adam, activation function =
‘relu’, epochs = 1000,batch_size = 32, 
learning_rate = 0.0015, Dense = 100 
num_nodes: 20, regular_para = 0.2, 
weight_random_range = [(cid:0) 1,1], 
bias_random_range = [0,1], 
num_nodes: 50, regular_para = 0.9, 
weight_random_range = [(cid:0) 1, 1], 
bias_random_range = [0, 1], 
Regularization_coefficient = 3E+05, 
kernel_parameter =7000 
Regularization_coefficient = 9E+06, 
kernel_parameter =9E+05 
CNN Layers = 2, filters = 64, kernel_size =
[1,4], BiRNN Layers = 1, BiRNN neurons =
30, Optimizer: Adam, activation function =
‘relu’, epochs = 200,batch_size = 32, 
learning_rate = 0.0002, Dense = 100 
CNN Layers = 2, filters = 64, kernel_size =

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide explicit information about the specific postprocessing steps involved after the model training for each machine learning algorithm mentioned. However, based on general practices and common procedures in machine learning, some possible postprocessing steps could include metrics calculation, confusion matrices, saliency maps, or other visualizations depending on the type of data and problem being addressed.

Metrics calculation is a crucial step in evaluating the performance of a trained model. Commonly used evaluation metrics include accuracy, precision, recall, F1 score, ROC AUC, RMSE, MAPE, etc. These metrics help quantify how well the model has learned from the training data and its ability to generalize to unseen data.

Confusion matrices can be generated to summarize the performance of a classification model by comparing actual class labels with predicted ones. This provides insights into the types of errors made by the model, such as false positives and false negatives.

Saliency maps are often employed in computer vision tasks to highlight important regions within input images that contribute significantly towards the final prediction. They offer valuable interpretability and explainability aspects to deep learning models.

In summary, while the exact postprocessing steps may vary depending on the specific application and requirements, typical steps might involve calculating relevant evaluation metrics, generating confusion matrices, creating saliency maps, or employing other visualization techniques to better understand the behavior and performance of the trained model.