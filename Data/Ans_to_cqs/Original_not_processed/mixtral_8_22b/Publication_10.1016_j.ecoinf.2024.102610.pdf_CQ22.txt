Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Keshavamurthy, R., Dixon, S., Pazdernik, K.T., Charles, L.E., 2022. Predicting infectious 
disease for biopreparedness and response: a systematic review of machine learning 
and deep learning approaches. One Health 15, 100439. https://doi.org/10.1016/J. 
ONEHLT.2022.100439. 

Khun, M., 2022. Classification and Regression Training: Package caret. Available at: http 
s://cran.r-project.org/web/packages/caret/caret.pdf (Accessed: 26 January 2023).  
Laaksonen, M., Sajanti, E., Sormunen, J.J., Penttinen, R., H¨anninen, J., Ruohom¨aki, K., 
et al., 2017. Crowdsourcing-based nationwide tick collection reveals the distribution 
of Ixodes ricinus and I. persulcatus and associated pathogens in Finland. Emerg. 
Microb. Infect. 6 (5) https://doi.org/10.1038/EMI.2017.17.

The  model  performance  was  assessed  based  on  the  final  trained 
model  (average  of  the  six  models)  “out-of-bag”  R2  and  RMSE  values, 
which  is  an  indication of  how  well  the  model generalizes  the  unseen 
data.  Variable  importance  was  determined  using  the  permutation 
method, where variables are ranked according to how much the model’s 
performance  degrades  when  the  values  of  specific  variables  are 
randomly  shuffled  (Breiman,  2001).  We  used  the  ‘pdp’  package 
(Greenwell, 2022) to generate partial dependence plots, which show the 
impact of each predictor on the response variable while maintaining all 
other predictors constant.

The attained performance of the trained models (R2  values ranging 
from 0.38 to 0.41) demonstrates the potential for predicting tsetse fly 
relative numbers using machine learning methodologies. Our analysis 
indicates that using environmental and weather data near the period of 
tsetse monitoring yields more accurate predictions compared to longer- 
term averages. When extrapolating tsetse number predictions based on 
different  sets  of  predictors,  significant  disparities  emerge.  VSURF- 
retained variables of 2021 reveal pronounced tsetse hotspots (>6 FTD) 
within  known  tsetse  belts  (McCord  et  al.,  2012).  On  the  other  hand, 
predictions based on RFE-retained variables did not identify prominent 
hotspots,  and  most  of  these  predictions  fell  outside  the  range  of  the 
environmental and weather data used for model training. Notably, for 
RFE-retained variables and VSURF long-term variables, extrapolations

abundance  of  Aedes  aegypti  female  mosquitoes  in  Thailand.  For  tick 
abundance in Southern Scandinavia, Jung Kjær et al. (2019) employed 
Boosted  Regression  Trees  (BRT)  with  gridded  environmental  and 
weather  variables.  Their  approach  yielded  higher  accuracy  for  tick 
larvae and nymphs (R2 of 0.69) but less accurate results for adult ticks 
(R2 of 0.1). Ceia-Hasse et al. (2023) demonstrated an improved perfor-
mance  of  deep  learning  over  classical  machine  learning  (area  under 
curve values 0.83 and 0.75 respectively) in predicting the abundance of 
yellow  fever  mosquitoes  in  Madeira,  Portugal.  These  findings  collec-
tively  highlight  the  promising  potential  of  various  machine  learning 
techniques in developing high-performing models for assessing disease 
vector abundance.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The performance of the deep learning model is evaluated using two primary metrics: out-of-bag R^2 and root mean square error (RMSE). Out-of-bag R^2 measures the proportion of variance explained by the model, while RMSE quantifies the average difference between predicted and actual values. These metrics provide insights into how well the model can generalize to unseen data. Additionally, variable importance is determined through the permutation method, ranking variables based on their impact on model performance when randomly shuffled. Partial dependence plots generated using the 'pdp' package further illustrate the influence of individual predictors on the response variable.