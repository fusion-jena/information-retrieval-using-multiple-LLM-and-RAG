Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2. Training dataset and testing dataset

d
e
s
i

m
o
t
s
u
C

g
n
i
n
r
a
e
L

r
e
f
s
n
a
r
T

1
≥
R
N
S

y
r
a
r
b
i
L

i
p
d

e
z
i
s
w
o
d
n
i
W

size of 32. The most suitable architecture was chosen based on the best 
validation accuracy (proportion of all correct predictions) and precision 
(number of true positives divided by true positives and false positives) 
obtained during training. The model training and prediction procedures 
were  executed  on  Microsoft  Azure  using  instance  NV12s  v3  with  12 
vCPUs and 112 GB RAM. The CNNs were implemented using Tensor-
Flow (Abadi et al., 2016) and Python 3. The Ubuntu 20.04 operating 
system was used and obtained via the Ubuntu 20.04 Data Science Virtual 
Machine  on  Microsoft  Azure.  The  algorithm  scripts  are  available  in 
Supporting Information B. 

2.5. Inference and post-processing

To test the efficacy of our models, we created several segments by 
using  the  same  sliding  window  approach.  Namely,  we used  the  same 
window size that was used in training, and thus multiple segments were 
created  across  the  entire  testing  file  by  moving  the  window  by  one 
second  in  the  moored  recording.  We  converted  each  of  these  testing 
segments into spectrograms (FFT length = 1024; hop size = 128; Hann 
window) which were used as input for subsequent model prediction. All 
generated spectrogram images were created as 5 × 5 in. but varied in 
their dpi configuration, ranging from 200 × 200 (40 dpi) to 500 × 500 
(100 dpi) samples. The number of images used per class was constrained 
by our computational resources, and we used the maximum number of 
images possible in each case. We attempted a number of experiments 
and varied the number of classes. The largest dataset built comprised 
80,000 images when combining three seconds window size and 40 dpi

)

%

(

9
.
7
6

.

1
6
6

.

7
0
8

.

8
4
5

.

0
9
5

.

7
4
5

.

1
6
5

.

7
4
4

s
n
e
S

)

%

(

3
.
6
7

.

6
8
4

.

6
8
3

.

6
2
5

.

5
2
5

.

4
1
2

.

2
7
3

.

4
0
5

2
≥
R
N
S

c
e
p
S

)

%

(

3
.
2
9

.

7
4
9

.

0
8
9

.

7
0
9

.

2
2
9

.

2
6
9

.

8
3
9

.

7
6
8

e
r
o
c
s

1
F

)

%

(

9
.
8
6

.

3
7
5

.

5
2
4

.

3
7
5

.

5
2
5

.

0
3
2

.

0
6
3

.

3
5
4

u
c
c
A

)

%

(

4
.
4
8

.

5
1
8

.

6
7
7

.

8
9
7

.

1
8
7

.

3
1
7

.

1
3
7

.

0
4
7

c
e
r
P

)

%

(

6
.
7
8

.

2
6
9

.

2
8
9

.

4
0
8

.

4
7
7

.

6
2
6

.

1
5
6

.

9
2
6

s
n
e
S

)

%

(

7
.
6
5

.

7
0
4

.

1
7
2

.

5
4
4

.

7
9
3

.

1
4
1

.

9
4
2

.

4
5
3

c
e
p
S

)

%

(

4
.
6
9

.

3
9
9

.

7
9
9

.

2
5
9

.

9
4
9

.

3
6
9

.

1
4
9

.

8
0
9

e
z
i
s

k

k

k

k

k

k

4
2

4
2

2
1

0
2

0
8

0
8

k

9
3

.

k

6
2

0
7

0
8

0
9

0
0
1

0
4

0
4

0
9

0
4

)
s
(

2

3

7

2

3

e
r
u
t
c
e
t
i
h
c
r
a

d
e
s
i

m
o
t
s
u
C

g
n
i
n
r
a
e
L

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly state the specific criteria used to determine when training is complete. However, it mentions that the most suitable architecture was chosen based on the best validation accuracy and precision obtained during training. This suggests that the authors likely monitored both metrics throughout the training process and stopped training once they observed no further improvement or reached a predefined threshold. Additionally, the use of early stopping could have been employed to prevent overfitting and halt training if performance on the validation set began to degrade. Therefore, while the exact criteria are not specified, it can be inferred that validation accuracy, precision, and possibly early stopping were considered to decide when training should conclude.