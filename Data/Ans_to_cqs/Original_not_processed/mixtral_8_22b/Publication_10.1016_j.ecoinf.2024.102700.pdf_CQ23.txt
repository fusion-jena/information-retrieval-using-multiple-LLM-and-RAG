Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

for model validation, either in addition to internal validation strategies
(n = 22), or as the sole validation method (n = 17). Notably, a consid-
erable number of studies did not use an explicit validation method to
measure model performance or did not clearly state this in the text (n =
94, 32%) (category “not provided” in Fig. 10).

employed in its collection?

iii. What kind of (correlative) modelling approaches have been

applied?

iv. Which environmental variables have been used as candidates in

the models?

v. What temporal and spatial resolution was chosen for the model?
vi. Which validation method was used and which metrics were

vii. What

the main output

for which these models were

selected?
is
implemented?

viii. What are the strengths, weaknesses and opportunities of each

modelling approach?

Based on these research questions, related eligibility criteria were
then developed using the standard approach for research questions
definition (i.e., Population, Intervention, Comparator - PIC framework,
CEE, 2022, Table 1).

EcologicalInformatics82(2024)1027002E. Pasanisi et al.

Table 1
Eligibility criteria concerning question key elements following the PIC
framework.

Question key elements

Eligibility criteria

Population (P):

● Point location/occurrence data of
Cetacean and/or Sea turtle species

4.4. The “best” modelling approach

model according to specific needs and available information, incorpo-
rating “features classes” and a “regularisation multiplier” to find a
proper trade-off between flexibility and overfitting (Muscarella et al.,
2014). The advantages of Maxent accounts for its widespread use,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study does not provide explicit details about the measures taken to ensure the generalizability of the deep learning model. However, it is mentioned that some studies employed internal validation strategies (n=22) and external validation methods (n=17) for model validation. Additionally, there were cases where no explicit validation method was stated (n=94, 32%). Therefore, based on the given context, we cannot determine the exact measures taken to ensure the generalizability of the deep learning model.

Answer:::

Based on the provided context, it appears that various validation methods were used to measure the performance of the models. These include internal validation strategies and external validation methods. However, there isn't any direct mention of specific techniques such as diverse datasets, cross-validation, or stratified splitting being used to ensure the generalizability of the deep learning model. It should be noted that nearly one-third of the studies did not explicitly state their validation methods. Therefore, while it can be assumed that some form of validation was likely performed, the specifics regarding ensuring the generalizability of the deep learning model remain unclear from the provided context.