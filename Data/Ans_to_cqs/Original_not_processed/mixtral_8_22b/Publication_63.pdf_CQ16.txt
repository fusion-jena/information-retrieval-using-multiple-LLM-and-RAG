Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

For the training process, a batch size of 20 images and an RMSprop optimiser with a learning rate of 0.001 and 
a learning rate decay of 0.0001 was used. The chosen loss function was mean squared error, while the prediction 
accuracy was quantified by the MAE of the respective dataset. The MAE of the validation dataset was computed 
after each epoch. Models were trained until the validation MAE did not further improve compared to the preced-
ing epochs and diverged from the training MAE (’overfit’). The trained model was then applied to the test dataset.
All CNN were implemented using the Keras API version (2.3.0.0)54 and the TensorFlow backend (version 
2.2.0)55 in R (version 3.6.3)23. Model training was undergone on a workstation with two CUDA-compatible 
NVIDIA GPUs (GeForce RTX 2080 Ti, CUDA version 11.0).

extracted a random sample of 10% of the dataset of each trait before model training. This ‘test dataset’ was not 
involved in the training process and exclusively served for the independent evaluation of the trained models. 
The remaining data was split into ’training dataset’ and ’validation dataset’ by a ratio of 4:1 (Table 1). The train-
ing dataset was employed to train the weights of the CNN model, whereas the validation dataset indicated the 
training progress after each full training cycle (’epoch’).

,

(1)

target denoting the log10-transformed target value, and mintrain and maxtrain being the minimum and maximum 
of the log10-transformed training dataset. Note that the minimum and maximum values used for normalising the 
targets were derived from the training dataset exclusively, preventing a leakage of information of the validation 
and test datasets to the training process. As a result, the final target values ranged exactly (for validation and test 
datasets: approximately) between 0 and 1. The same normalisation scheme was undergone for the bioclimatic 
variables.

We clipped the images to be quadratic by removing the spare margins and down-sampled the resulting image 
to a resolution of 512 × 512 pixels. Further pre-processing included log10-transformation of the reference trait 
data (‘targets’) due to skewed distributions and removing outliers exceeding three standard deviations above or 
below the mean. Afterwards, we normalised all targets (training, validation and test datasets) by the minimum 
and maximum values of the training dataset according to

targetnorm = target − mintrain
maxtrain − mintrain

,

(1)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: Training is considered complete when the validation Mean Absolute Error (MAE) does not show any improvement compared to previous epochs and starts to diverge from the training MAE. In other words, the training process stops once the model begins to overfit the training data, which is determined by monitoring the performance on the validation set.