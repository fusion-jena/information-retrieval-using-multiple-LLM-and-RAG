Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

10 

20/40/60/80 

20/40/60 

11 

20/40/60/80 

20/40/60 

128 
128 
128 
128 
128 
128 
64 
256 
512 
64/256/ 
512 
64/256/ 
512 

1024 
1024 
1024 
1024 
1024 
1024 
1024 
1024 
1024 

512 

2048  

Table 3 
Combination  of  the  convolutional  neural  network  deep  learning  model 
parameters.  

No 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 

Model 

Optimizer 

Learning Rate 

Without Dropout 

With Dropout 

RMSProp 

Adam 

SGD 

RMSProp 

Adam 

SGD 

0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01  

EcologicalInformatics80(2024)1024958E. Joelianto et al.                                                                                                                                                                                                                               

Fig. 8. Performance test of each configuration.  

Table 4 
The standard deviation values for each performance metric.  

Configurations 

Accuracy 
(%) 

Precision 
(%)

Fig. 2. Model of deep learning layer.  

EcologicalInformatics80(2024)1024954E. Joelianto et al.                                                                                                                                                                                                                               

In a CNN, a convolution layer performs convolution operations be-
tween the pixels on the input and several kernels or filters. The math-
ematical equation of the convolution process is as follows, where f is the 
input data and h is the kernel size. 

G[m, n] = (f *h)[m, n] =

h[j, k]f [m (cid:0)

j, n (cid:0) k]

(6) 

∑

∑

j

k

Fig. 9. Model optimization results.  

EcologicalInformatics80(2024)1024959E. Joelianto et al.                                                                                                                                                                                                                               

Fig. 10. The performance of Model 1 In each Running Fold of the model training for binary classification.  

Fig. 11. Scatterplot of the Model 1’s performance on each Running Fold for binary classification.  

Table 5 
Confusion matrix of the binary classification test.   

Aedes aegypti 

Culex quinquefasciatus 

Table 6 
Model performance on the binary classification test.  

Aedes aegypti 
Culex quinquefasciatus 

84 
1 

13 
72  

Accuracy (%) 

Precision (%) 

Recall (%) 

91.76 

86.59 

98.82 

F1-Score 

0.9230

Figs. 10 and 11 illustrate the performance of Model 1 in each running 
fold  of  model  training.  The  first  and  tenth  running  fold  models  per-
formed well. Compared with the first running fold, the tenth running 
fold  model  had  greater  Recall  and  F1-Scores  (96.46%  and  0.9497, 
respectively). We chose Model 1 in the tenth running fold as the best 
model  for  evaluating  ovitraps  in  binary  classification.  Subsequently, 
mosquito audio data from the recordings were used to test the optimal 
binary classification model. Table 5 presents the confusion matrix of the 
prediction results from the best model on 85 audio recordings for each 
mosquito class or type. From the results in the table, the performance 
measure can be remade with the formula of accuracy, precision, Recall, 
F1-Score, weighted accuracy, and micro F1 (Grandini et al., 2020) to 
determine  how  well  the  model  works  on  audio  data  recorded  by

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, there are several postprocessing steps involved depending on the specific requirements of the task. Some common postprocessing steps include metrics calculation, confusion matrix generation, saliency map creation, and model evaluation.

Metrics calculation involves computing various performance measures such as accuracy, precision, recall, F1 score, etc., to evaluate the effectiveness of the trained model. These metrics help in understanding the strengths and weaknesses of the model and provide insights into its generalization capabilities.

Confusion matrix generation is another important step in postprocessing. It provides a visual representation of the predicted vs actual classes, which helps in identifying any biases or imbalances in the dataset. A confusion matrix also enables the computation of additional performance measures like sensitivity, specificity, positive predictive value, negative predictive value, etc.

Saliency maps are often generated to understand the importance of different features in making predictions. They highlight the regions in the input image that contribute most towards the final prediction. This information can be useful in debugging the model and improving its interpretability.

Finally, model evaluation is performed using techniques like cross-validation, bootstrapping, etc., to ensure that the model has not overfit or underfit the training data. This step ensures that the model will perform well on unseen data and is robust to variations in the input distribution.

Therefore, postprocessing steps play a crucial role in validating the trained model and ensuring its reliability for real-world applications.