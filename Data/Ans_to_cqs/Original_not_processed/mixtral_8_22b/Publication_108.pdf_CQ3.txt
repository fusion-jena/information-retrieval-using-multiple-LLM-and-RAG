Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

encoding and decoding blocks and are summarized in Table 1. These experiments were monitored
using TensorBoard and validated on the validation portion of the dataset.

In general, the limitations of deep learning in comparison to other machine learning methods
are the requirement of large and high-quality training data, as well as hardware limitations related to
GPU computing power. The most notable advantage of deep learning is the grade of automatization
and a high potential to generalize when using large amounts of representative training data, which
might, however, not always be available; especially with respect to ground-truth labels that might be
scarce or not exist at all.. Furthermore, the black-box nature makes these algorithms a good choice for
classiﬁcation as suggested in this study, but a challenge for modeling physical properties, as is often
the case in forestry. This case study relied on high-resolution orthophotos with 20-cm spatial resolution
obtained from an aerial survey. The great advantage of these data is that many details can be detected.

The overall workﬂow of preprocessing, network design, and prediction are shown in Figure 2.
Due to the size of the orthophotos and due to memory limitations when doing computations, it is
intuitive to process the orthophotos into relatively small labeled tiles (or rather small image cubes) and
feed them into the CNN. Each orthophoto of size 10,000 × 10,000 pixels was divided into 1525 tiles of
256 × 256 pixels. The data (orthophoto and corresponding labels) were then split into three datasets:
training (80%), validation (20%), and test (two full images of 10,000 × 10,000 pixels). The training
data were used for optimizing the neural network, while the validation dataset was used to assess the
performance during the training process. The test dataset was used to assess the performance of the
ﬁnal optimized neural network. The training and validation images were read into arrays with the

Remote Sens. 2019, 11, 1976

12 of 14

greater than 0.5 ha. As these results also required choosing optimal parameters, the transferability of
the method was somewhat more complex compared to the pretrained U-Net architecture, which can be
applied without tuning additional parameters speciﬁc to the area of interest. An in-depth investigation
of the performance of the proposed architecture on further datasets would be an interesting future
project, especially with respect to the power of generalization, which can be increased by different data
augmentation techniques.

4.2. Limitations of This Study

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't explicit information about the specific data annotation techniques used in the deep learning pipeline. However, we can infer some aspects based on the mentioned processes.

Firstly, the text mentions that each orthophoto was divided into smaller tiles of 256 x 256 pixels. This implies that the labeling was likely done at the tile level, meaning that each tile had its own set of labels.

Secondly, the mention of 'labels' suggests that semantic segmentation could have been used as a data annotation technique. Semantic segmentation involves assigning a class label to every pixel in an image, thus providing detailed information about the objects present in the scene.

Lastly, the use of a Convolutional Neural Network (CNN) for processing the tiles indicates that the input data was likely in the form of multi-dimensional arrays, such as those produced by semantic segmentation.

However, without explicit information about the type of labels used (e.g., whether they indicate object boundaries, object classes, etc.), it's impossible to definitively state what kind of data annotation techniques were used. Therefore, based on the provided context, we can only suggest that semantic segmentation may have been used, but further confirmation would be needed to confirm this.