Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

IUC-NN all features
not threatened
possibly threatened

Spatial
cleaning

full
full
medium
medium
raw
raw

full
full

full
full

full
full

full
full

IUCN designation

not
threatened

possibly
threatened

Method type∗

75.1
38.8
75.1
36.4
73.8
35.3

68.3
32.5

68.5
32.4

78.9
11.8

81.6
29.4

24.9
61.2
24.9
63.6
26.2
64.7

31.7
67.5

31.5
67.6

21.1
88.2

18.4
70.6

index
index
index
index
index
index

index
index

index
index

prediction
prediction

prediction
prediction

∗For index-based methods, the results are for all species with digitally available occurrence records (n = 866). For prediction-based methods
(IUC-NN), results are from the test data set (n = 89).

We trained IUC-NN on all species with an IUCN RL as-
sessment and available occurrence records. Prior to the
training, we randomly split the data set into a training
set (90% of the entries) and a test set (10%). We used
20% of the training set for validation. Because the size
of the data set was comparatively small, we performed
cross-validation by shifting the validation set 5 times to
quantify the average validation cross-entropy loss and ac-
curacy. We then used the neural network with the lowest
cross-entropy loss across a range of models with differ-
ent numbers of hidden layers and subsets of features to
predict the conservation status of all orchid species at
2 levels: binary (possibly threatened vs. not threatened)
and detailed (CR, EN, VU, NT, and LC). See Supporting
Information for details on the network architecture and
training. We combined the IUC-NN assessments with dis-
tribution data from WCSP to show the number and pro-

generally high for CR, EN, and LC classes and low for
the intermediate VU and NT classes (Supporting Infor-
mation). Accuracy was highest for species the IUCN con-
sidered threatened by natural systems modification and
energy production and mining and lowest for species
threatened by human intrusion and disturbance and pol-
lution (Supporting Information). Relative to the IUCN
RL, the accuracy of index-based methods to identify pos-
sibly threatened and not threatened species was higher
with IUCN15 (69.9%, n = 359) and ThreatSearch (78.6%,
n = 14), similar with IUCN2008 (64.4%, n = 810), and
lower with SRLI (57.1%, n = 261) (Supporting Informa-
tion).

Conservation Biology
Volume 35, No. 3, 2021

preliminary assessments (Schmidt et al. 2017; Cosiaux
et al. 2018; Zizka et al. 2020b). Prediction-based meth-
ods combine existing IUCN RL assessments with species
traits to predict the conservation status of not evalu-
ated or data-deficient species (Bland et al. 2015; Pelletier
et al. 2018; González-del-Pliego et al. 2019; Lughadha
et al. 2019) and include machine learning algorithms.
Prediction-based methods may be based on the same
indices on species’ ranges as index-based methods, but
they also incorporate additional traits, such as climatic
niche, biomes, human footprint index, geographic re-
gion, or traits related to species morphology or physi-
ology (Bland et al. 2015; Di Marco & Santini 2015).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about the specific criteria used to determine when training is complete. However, it mentions that the model with the lowest cross-entropy loss across a range of models with different numbers of hidden layers and subsets of features was selected to predict the conservation status of orchid species. This suggests that the training process might have been stopped once the validation loss reached its minimum value, which is a common practice in machine learning. Additionally, the use of cross-validation by shifting the validation set five times indicates that the performance of the model was evaluated multiple times during training to ensure stability and prevent overfitting.