Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The prediction power with machine learning algorithms was tested 
with the package “sdm”  (Naimi and Araújo, 2016), “dismo”  (Hijmans 
et al., 2015), “bioclim” (Booth et al., 2014), and the ensemble modeling 
approach  implemented  in  “biomod2”  (Thuiller  et  al.,  2009;  2014). 
Model mean performances for AUC, ROC, TSS, KAPPA, and COR values 
were extracted using “shiny” packages (Chang et al., 2023) in RStudio 
(RStudio Team, 2020). 

2.10. Statistical analysis

2.6. Model selection 

Since  performance,  accuracy,  key  parameters,  and  sensitivity  for 
prediction vary depending on which method that is used (Diniz-Filho 
et al., 2009; Elith et al., 2006; Qiao et al., 2015), we tested eight different 
machine  learning  algorithms  to  generate  our  predictive  models.  The 
included  algorithms  were:  Generalized  Linear  Model  (GLM),  Support 
Vector  Machine  (SVM),  Multivariate  Adaptive  Regression  Spline 
(MARS),  Random  Forest  (RF),  Flexible  Discriminant  Analysis  (FDA), 
Classification  and  Regression  Trees  (CART),  Generalized  Boosting 
regression Model (GBM) and Maximum-Entropy learning (MAXENT) for 
habitat suitability prediction (Table S5). 

2.7. Ensemble modeling approach

EcologicalInformatics78(2023)1023465M. Abdelgadir et al.                                                                                                                                                                                                                            

importance,  and  regularized  training  gain  for  each  variable.  Here,  a 
variable  with  highest  regularized  training  gain  is  indicating  that  this 
variable  has  the  most  useful  information  on  its  own  when  used  in 
isolation. Model sensitivity and accuracy for habitat suitability were also 
checked  with  the  AUC  values.  Graphical  representation  of  MAXENT 
models were produced in QGIS Desktop v 3.24.2 (QGIS Development 
Team, 2022).

To verify the model’s validity, 30% of each taxon’s data records were 
utilized as testing data, while the remaining 70% were used as training 
data.  After  10  K-fold  cross-validation  and  10-fold  bootstrapping,  all 
models  were  assessed  based  on  the  mean  values  for  Area  Under  the 
Curve AUC (Hanley and McNeil, 1982), True Skill Statistics TSS (Mon-
serud  and  Leemans,  1992),  Cohen’s  KAPPA  (Allouche  et  al.,  2006), 
point-biserial correlation COR (Elith et al., 2010), and Receiver Oper-
ator Characteristics ROC (Hanley and McNeil, 1982). Bootstrapping was 
used  to  provide  unbiased  predictive  accuracy  with  a  sufficiently  low 
variance  (Harrell  et  al.,  2005;  Lima  et  al.,  2019).  For  the  model 
threshold,  the  sensitivity-specificity  sum  maximization  technique  was 
employed  (Liu  et  al.,  2005).  According  to  this  evaluation  criterion, 
species distribution can be accurately predicted (Liu et al., 2005). For

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors employed two strategies to ensure the validity and reliability of their models. Firstly, they utilized 30% of each taxon's data records as testing data, while the remaining 70% served as training data. This allowed them to evaluate how well the trained models could generalize to new, unseen data. Secondly, after conducting 10 K-fold cross-validation and 10-fold bootstrapping, the authors evaluated the models based on several metrics such as Area Under the Curve (AUC), True Skill Statistics (TSS), Cohen's Kappa (KAPPA), point-biserial correlation (COR), and Receiver Operator Characteristics (ROC). These evaluations helped determine the overall performance of the models during training. Additionally, bootstrapping was used to provide unbiased predictive accuracy with a sufficiently low variance. Lastly, for the model threshold, the sensitivity-specificity sum maximization technique was employed, ensuring accurate species distribution predictions.