Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.4. Sampling Method

The SPOT6 satellite data for our ﬁve study areas were preprocessed to be fed into the
different Deep Learning architectures and the XGBoost model. First, the data were split
into three mutually exclusive parts: a learning set, a validation set and a test set totally
independent of the two previous ones.

Four of the ﬁve areas were used for learning and validation. The last, isolated scene
was then used as the test set. It contained all the classes for the two nomenclatures, the ﬁve
LC classes, and the 12 LU classes. In addition, this image contained all the environments
representing the New Caledonian landscape: urban, mining, mountainous and forest
environment with variations from the coastline to the inland mountain areas. It is on this
entire scene that the ﬁnal confusion matrix and quality metrics were computed.

40.32%
35.97%
46.56%
50.21%
38.75%
50.40%
48.38%

For the LU detection task, all deep learning techniques except AlexNet outperformed
XGBoost. Differences were signiﬁcant, with up to 15 percent points in OA. As in the
previous section, the best performing “single-pixel” architecture is DenseNet and the best
“semantic labeling” network is DeepLab. Interestingly, DenseNet reached the best PA,
although DeepLab dominated the remaining metrics.

For the remainder of this study, the best performing “single-pixel” and “semantic
labeling” were selected. There was little difference between the architectures, so the
architectures with the best F1-score for the LU classiﬁcation were chosen arbitrarily.

4.3. Inﬂuence of Neo-Channels and Land Cover as Input on the Learning

conv1
conv2
conv3
conv4
conv5
maxpool

Conv

11 × 11
5 × 5
3 × 3
3 × 3
3 × 3
2 × 2

Kernels

Stride

Pad

96
256
384
384
256
Na

4
1
1
1
1
2

0
2
1
1
1
0

ResNet (Deep Residual Network, [43]) is a Deep Learning architecture with many
layers that use skip connections, as illustrated in Figure 4. These skip connections allow
the bypassing of layers and add their activations to those of the skipped layers further
down the sequence. The dotted arrows in Figure 4 denote skip connections through a linear
projection to adapt to the channel depth.

By skipping layers and thus shortening the back-propagation path, the problem of the
“vanishing gradient” can be mitigated. Figure 4 represents a 34-layer ResNet architecture.
The ﬁrst layer uses 7 × 7 convolutions, the remaining ones 3 × 3.

Remote Sens. 2021, 13, 2257

9 of 22

Figure 4.
architecture. The number of kernels is indicated at the bottom of each convolution layer.

Remote Sens. 2021, 13, 2257

13 of 22

between 12 land type classes for the classiﬁcation, as described in the nomenclature in
Table 4. Table 8 presents the results of the LU classiﬁcation on the test area and Table A2, in
the Appendix, presents the results of the LU classiﬁcation on the four training areas.

Table 8. Results of Deep Learning architecture and XGBoost for the LU detection task with RGBNIR
as input.

Architectures

XGboost
AlexNet
ResNet
DenseNet
SegNet
DeepLab
FCN

OA

51.56%
45.79%
55.96%
59.59%
58.36
61.45%
56.07%

PA

42.61%
33.93%
43.89%
46.18%
37.16
49.77%
49.59%

UA

38.27%
38.26%
49.58%
55.00%
40.48
51.04%
47.22%

F1-Score

40.32%
35.97%
46.56%
50.21%
38.75%
50.40%
48.38%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention or reference to any specific data repository link for the deep learning pipeline used in this study. Therefore, I cannot provide the requested information.