Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

configuration of optimizer and learning rate which has been considered 
for the training of the framework. The EMViT-Net framework achieves 
prominent results as compared to other deep learning models and per-
forms better with an augmented set of EMDS-6 datasets.

To further validate the performance of the proposed model EMViT- 
Net,  the  acquired  findings  were  compared  with  other  state-of-the-art 
models. The performance measures used to compare the performance 
of  EMViT-Net  with  other  deep  learning  models  are  evaluated  on  the 
validation set and test set of the considered dataset EMDS-6. The com-
parison of the classification results achieved by other pre-trained deep 
learning models is given in Table 4 and Table 5 which illustrates the 
finding on each set validation set and test set respectively by calculating 
the  average  value  of  precision,  recall  and  f1-score  for  all  categories 
which are named as Avg_Precision, Avg_Recall and Avg_F1-score. The 
detailed analysis of the proposed network EMViT-Net and other deep 
learning models with specific configurations on unseen test sets is out-
lined  here  which  shows  that  the  EMViT-Net  outperforms  precision,

3.3. Experimental setup 

The system configuration used for training and experiments of the 
proposed model is given in Table 2. The proposed model EMViT-Net uses 
a kernel of size 3 and strides with size 1 for feature extraction from the 
convolutional  layer  and  generates  enriched  feature  spaces. To  reduce 
the size of extracted feature space max-pooling and average pooling are 
applied to look up the maximum and average value of generated feature 
spaces. To illustrate the point-wise and depth-wise combination of local 
convolutional  features  a  separable  convolutional  parameter-sharing 
attention block is added and batch normalization is applied to ensure 
the stable training and faster convergence of the proposed model. 

3.4. Performance evaluation

Table 6 
Performance comparison of EMViT Net with different deep learning models on EMDS-6 test set.  

Model 

Original dataset 

After Augmentation 

Avg. Precision 

Avg. Recall 

Avg. F1-score 

Accuracy 

Avg. Precision 

Avg. Recall 

Avg. F1-score 

Accuracy 

DenseNet121 
Alex Net 
ViT 
ResNet50 
Xception Net 
VGG19 
Inception V3 
VGG16 
EMViT-Net 

39.20% 
32.53% 
34.92% 
41.96% 
44.25% 
41.20% 
50.78% 
38.21% 
57.31% 

33.01% 
31.90% 
33.24% 
37.14% 
39.37% 
31.43% 
43.97% 
37.47% 
53.71% 

33.79% 
29.32%` 
32.63% 
36.93% 
39.07% 
29.97% 
43.41% 
36.80% 
53.45% 

33.02% 
31.91% 
33.23% 
37.14% 
39.37% 
31.43% 
43.97% 
37.46% 
53.71% 

34.92% 
38.19% 
43.55% 
46.57% 
50.87% 
52.40% 
51.91% 
50.86% 
69.53% 

33.77% 
35.87% 
37.65% 
41.58% 
44.76% 
48.57% 
48.88% 
50.15% 
67.62% 

32.45% 
35.35% 
37.92% 
42.06% 
43.03% 
47.67% 
48.10% 
50.64% 
66.89% 

33.77% 
35.87% 
37.65% 
41.58% 
44.76% 
48.57% 
48.88% 
50.15% 
67.62%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the provided context does not explicitly mention the exact hyperparameters such as learning rate or optimizer used in the deep learning model called EMViT-Net. However, it can be inferred that some form of optimization was performed during the training process since the text mentions that the model performs well with an augmented set of EMDS-6 datasets. Additionally, the use of a kernel of size 3 and strides with size 1 suggests that these parameters were chosen for feature extraction within the convolutional layers of the model. Furthermore, the application of max-pooling and average pooling techniques indicates that the dimensionality of the extracted feature space was reduced. Lastly, the inclusion of a separable convolutional parameter-sharing attention block and batch normalization implies that these methods were employed to improve the stability and speed of the model's training process.