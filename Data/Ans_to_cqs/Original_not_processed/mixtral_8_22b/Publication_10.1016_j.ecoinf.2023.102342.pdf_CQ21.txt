Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.1. Operational workflow 

The whole process of data acquisition and processing, reported in the 
following  section,  is  called  Knowledge  Discovery  in  Databases  (KDD) 
(Kotu and Deshpande, 2015); it is a process of identifying patterns or 
relationships  within  a  dataset  useful  to  make  important  decisions 
(Hammad and AbouRizk, 2014). This process does not involve applying 
data-mining  techniques  but  requires  more  actions  to  reach  the  final 
result. 

The KDD sequence applied in our case study included the following 

steps:  

• identification of the aim for a specific study area;  
• pre-selection of useful data to achieve the objective;  
• analytical determinations for the detection of PPPs in Puglia surface 

water bodies;  

• optimisation and elaboration of the obtained results through:

statistics;  

• Mapping and interpretation of the results: It evaluates whether the 
objective has been achieved, and if the answer is no, it proceeds with 
the reiteration (and possible modification) of the previous step and 
sometimes further steps.  

• display of results in an understandable format; 

Fig. 1. Study area and monitoring network map. Base Map tiles by Sentinel-2 cloudless 2021 by EOX IT Services GmbH.  

EcologicalInformatics78(2023)1023423C. Massarelli et al.                                                                                                                                                                                                                              

• decisions making. 

2.2. Study area

In short, data mining ensures that starting from “cryptic” information 
scattered without apparent order in a database, we arrive at knowledge 
that can be exploited for various purposes (Kotu and Deshpande, 2015). 
It is also possible to implement (Online document, 2022b) an automatic 
elaboration  workflow  with  open-source  software  without  using  an 
operator who reprocesses the data each time. Data mining can be sup-
ported  by well-known  and  widely applied  data  processing techniques 
such as verifying or interpreting results (Hamdi et al., 2022).

Gubner, J.A., 2006. Probability and Random Processes for Electrical and Computer 
Engineers. undefined 1–62. https://doi.org/10.1017/CBO9780511813610.003. 
Guo, W.W., Xue, H., 2012. An Incorporative Statistic and Neural Approach for Crop Yield 
Modelling and Forecasting STEM & International Education View Project Special 
Issue : Advances in Multiple Criteria Decision Analysis (Mathematics Journal) View 
Project an Incorporative Statist. https://doi.org/10.1007/s00521-011-0636-0. 
Guo, W.W., Xue, H., 2014. Crop yield forecasting using artificial neural networks: a 

comparison between spatial and temporal models. Math. Probl. Eng. 2014 https:// 
doi.org/10.1155/2014/857865. 

Gupta, D., Gujre, N., Singha, S., Mitra, S., 2022. Role of existing and emerging

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of postprocessing steps specifically related to machine learning model training such as saliency maps, metrics calculation, confusion matrices, etc. However, the operational workflow described in the context includes several general steps that could potentially encompass some aspects of postprocessing. These include:

* Optimization and elaboration of the obtained results through statistics: This step might involve calculating various performance metrics to evaluate the trained model.
* Mapping and interpretation of the results: This step involves assessing whether the objectives have been met, which could involve creating visualizations like confusion matrices or other types of plots to better understand the model's performance.
* Display of results in an understandable format: This step suggests presenting the results in a clear and interpretable manner, which could involve generating reports or dashboards containing relevant performance metrics and visualizations.