Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Results

We  calibrated  models  for  classification  challenges  using  different  numbers  of  training 
steps, and considered two factors to find optima for training TensorFlow (Khalighifar et al. 
2019): correct identification rate and processing time. As a result, for all challenges except 
Challenge 3, we chose 4000 training steps as an optimum number. For Challenge 3, given 
the number of species (41 species), 8000 training steps proved to be the optimum number. 
The details of results associated with each classification task are as follows:

Challenge 1

We  created  a  confusion  matrix  to  depict  TensorFlow’s  initial  results  with  20  species 
(Fig. 3). The overall correct identification rate was 94.3%. We achieved 100% correct iden-
tification rate for 11, and 90% or above for 17, species. The lowest identification rates were 
for closely-related species Platymantis isarog and P. montanus, with 70 and 75% correct

647

Model architecture

Convolutional neural networks (CNNs) are a subset of DNNs that are specialized for image 
classification  tasks  and  pattern  recognition.  One  of  the  main  advantages  of  CNNs  is  the 
ability to perform automated feature extraction, eliminating the need for hand-crafted fea-
ture  extraction.  CNN  architecture  is  built  on  three  types  of  layers:  (1)  convolutional  lay-
ers,  which  are  the  most  important  because  they  apply  hierarchical  feature  extraction  and 
decomposition  of  input  images;  (2)  pooling  layers,  which  carry  out  operations  to  reduce 
numbers of parameters and necessary computation; and (3) fully connected layers, which 
perform the actual classification at the end of the pipeline.

Across broader taxonomic scales and phylogenetic relationships (e.g., Chan and Brown 
2017), other means (biogeographic realm, ectomorph type, classification, etc.) of restrict-
ing/limiting  candidate  species  pools  may  prove  useful  for  ‘fine-tuning’  of  TensorFlow’s 
automation of species recognition. Additional caveats for future consideration include (1) 
single notes per species and (2) sample sizes, which will be limited for rare species, those 
that occur at naturally low abundances, or taxa characterized by reduced detection proba-
bilities due to cryptic microhabitat preferences, narrow activity patterns, or seasonally-lim-
ited  reproductive  cycles  (Wells  2010).  Avenues  for  future  development  of  these  methods 
in  our  immediate  plans  include  application  to  additional  taxonomic  groups  (e.g.,  insects, 
birds), and automation of call detection from environmental sound samples as a precursor 
step to automated species identification.

Funding  No funding was used for this research.

Data  availability  Data  are  publicly  available  via  Cornell  University’s  Laboratory  of  Ornithology  and 
Macaulay Library of Natural Sounds (https ://www.macau layli brary .org).

Compliance with ethical standards 

Conflict of interest  All authors declare that they have no conflicts of interest.

References

Abadi M et al. (2016) Tensorflow: a system for large-scale machine learning. Paper presented at the 12th 

USENIX Symposium on Operating Systems Design and Implementation, Savannah, USA,

1 3Biodiversity and Conservation (2021) 30:643–657 

655

Aide TM, Corrada-Bravo C, Campos-Cerqueira M, Milan C, Vega G, Alvarez R (2013) Real-time bioacous-

tics monitoring and automated species identification. PeerJ 1:e103

Araya-Salas M, Smith-Vidaurre G (2017) warbleR: an R package to streamline analysis of animal acoustic 

signals. Methods Ecol Evol 8:184–191

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the provided context does not explicitly mention the specific criteria used to split the data for deep learning model training into train, test, and validation sets. However, it can be inferred that the researchers likely followed common practices in machine learning, such as randomly splitting the dataset into training, testing, and validation subsets. Typically, the training set is used to fit the model, while the validation set is employed to tune hyperparameters during the training process. Lastly, the testing set serves to evaluate the final performance of the trained model. In this case, the researchers mentioned using different numbers of training steps to optimize their TensorFlow models for various classification challenges. They also reported achieving high correct identification rates across multiple species, indicating successful model training and evaluation processes.