Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The duration of audio ﬁles in CLO-43DS data is different,
which cannot be directly used as the input to the CNN. The
ﬁrst method for dealing with the multi-variate varying length
audio data is that the signal is repeated from the beginning to
force the ﬁxed duration of 2s, which has been used in [30].
The second method is to directly resize the audio image to a
ﬁxed size.

D. DEEP LEARNING ARCHITECTURE
The feature learning part of our proposed model follows a
VGG style network [24], which has been previously used
for classifying acoustic scenes [5]. The overall architec-
ture is illustrated in Table 1. This network is trained using
Adam optimizer with a learning rate of 10−4. The cate-
gorical cross entropy is utilized as the loss function. The
batch size is 64 samples and the network is trained with
200 epochs.

TABLE 3. Classification performance of different methods using single
CNN-based model. Here, Mel-CNN, Harm-CNN, and Perc-CNN denote that
the input to those CNNs are Mel-spectrogram, harmonic-component
based spectrogram, and percussive-component based spectrogram.
Subnet-CNN denotes that a SubSpectralNet architecture is used with the
Mel-spectrogram as the input.

[21] Y.
by
divisions,’’
Available:
classiﬁcation-results-a

‘‘Acoustic
based

Sakashita
ensemble

adaptive
2018.

scene

on

[22] J. Salamon, J. P. Bello, A. Farnsworth, and S. Kelling, ‘‘Fusing shallow
and deep learning for bioacoustic bird species classiﬁcation,’’ in Proc.
IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), Mar. 2017,
pp. 141–145.

[23] J. Salamon, J. P. Bello, A. Farnsworth, M. Robbins, S. Keen, H. Klinck,
and S. Kelling, ‘‘Towards the automatic classiﬁcation of avian ﬂight
calls for bioacoustic monitoring,’’ PLoS ONE, vol. 11, no. 11, pp. 1–26,
Nov. 2016.

[24] K. Simonyan and A. Zisserman, ‘‘Very deep convolutional networks for
large-scale image recognition,’’ in Proc. 3rd Int. Conf. Learn. Repre-
sentations, (ICLR), San Diego, CA, USA, 2015. [Online]. Available:
http://arxiv.org/abs/1409.1556

The classiﬁcation results using different fusion strategies
are shown in Table 4. From the table, we can have following
observations: (1) the fusion of different CNN-based models
often leads to the performance improvement; (2) the fusion
of more CNN-based models architecture does not always
achieve better performance than fewer CNN-based models;
(3) different CNN architectures might have better discrim-
inability in recognizing bird calls than different inputs to
CNNs.

The best classiﬁcation balanced accuracy and F1-score
using a class-based late fusion of different inputs to the
same CNNs are 84.76% and 92.26%, which is higher than
83.27% and 91.42%. Here, the improvement is mainly due
to the discriminability of different inputs to the CNNs. The
classiﬁcation F1-score of each bird species is shown in Fig. 5.
It is found that the classiﬁcation performance of WIWA is the
worst, which is in accordance with [23].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention or discussion about addressing data bias during preprocessing of the deep learning pipeline. However, some common techniques used to handle data bias include stratified splitting, oversampling, undersampling, and diverse data collection. These techniques help ensure that the dataset is representative and balanced, reducing potential biases that could affect the performance of the deep learning model.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes or labels in both sets. Oversampling increases the number of instances in minority classes by duplicating existing examples or generating synthetic ones. Undersampling reduces the number of instances in majority classes by randomly removing examples. Lastly, diverse data collection aims to gather a wide range of data points representing various scenarios, conditions, and populations to improve the generalizability of the model.

In summary, although the given context doesn't discuss specific techniques for handling data bias, commonly employed methods include stratified splitting, oversampling, undersampling, and diverse data collection.