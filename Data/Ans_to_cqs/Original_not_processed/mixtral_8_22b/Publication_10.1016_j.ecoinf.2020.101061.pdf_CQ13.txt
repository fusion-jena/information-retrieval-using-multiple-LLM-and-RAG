Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Collecting a suﬃcient number of training samples will often be a
bottleneck in developing supervised methods in airborne imagery. It is
therefore useful to test the number of local training samples needed to
achieve maximum performance. We performed a sensitivity study by
training models using diﬀerent proportions of training data. We se-
lected 5%, 25%, 50% and 75% of the total hand-annotations to com-
pare to the full dataset for the within-site results for each site. We reran
this experiment ﬁve times to account for the random subsampling of
annotations. In addition, we ran the evaluation plots for the pretraining
model only (i.e. 0% hand-annotated data) to assess whether the addi-
tion of hand-annotated data improved the within-site pretraining.

3. Results

Tesla K80 GPU for 5 epochs. To align these unsupervised classiﬁcations
with the ImageNet pretraining weights, we normalized the RGB chan-
nels by subtracting the ImageNet mean from each channel. We then
retrained the network using the hand-annotated data for 40 epochs. For
more details of this approach see Weinstein et al. (2019). Data aug-
mentation of random ﬂips and translations was tested and found to
have little eﬀect on the ﬁnal score.

Using the evaluation plots, we chose two metrics to assess model
performance. For comparison with the existing LiDAR-only im-
plementations, we used precision and recall statistics with a bounding
box marked as true positive if it had an intersection-over-union (IoU) of
greater than 0.5. Intersection-over-union is the ratio of the area of
bounding box overlap to the area of bounding box union between the
predicted tree crown and the visually annotated crowns in the eva-
luation data. For each bounding box prediction, the deep learning
model reports a conﬁdence score between 0 and 1. To transform these
scores into precision and recall statistics, we need to deﬁne a threshold
of box scores to accept. As we lower the threshold for acceptance, a
greater number of trees will be captured, but at the expense of de-
creased precision. To highlight this relationship, we showed the per-
formance of the deep learning approach across all bounding box

20%. Given that the sites were selected to be as diﬀerent as possible,
and encompass a range of tree canopy conditions, this result under-
scores the ability of convolutional neural networks to learn ﬂexible
deep features. We expect that as more sites are included, the universal
model will continue to improve. This means that a way forward is to
combine pretraining from as many sites as possible. Given that each
NEON site has millions of trees, and there are dozens of sites with trees
collected annually, there is a possibility of pretraining on continental
scale. Because NEON sites are intended to represent all of the major
biogeographic regions in the United States, this broad scale pre-training
(in combination with existing local training data) has the potential to
reduce the need for new local training data by giving the model the
potential to learn the general suite of features characterizing trees (at
least those within the United States).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide information about the specific hyperparameters such as learning rate or optimizer used in the deep learning model. However, it mentions that the model was trained for 40 epochs after retraining with hand-annotated data. Additionally, data augmentation techniques like random flips and translations were tested but did not significantly impact the final score.