Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

III. 

MATERIALS AND METHODS 

In  this  section  the  dataset  used  in  the  study  is  presented 
along with the modelling approach taken and the evaluation 
metrics used to evaluate the trained model. The section also 
discusses data pre-processing using the Librosa library. Keras 
and TensorFlow 2.2 are utilised as the backend and an Nvidia 
2070 super GPU with 8GB of memory is utilised to accelerate 
model training. In addition, the proposed inferencing pipeline 
is discussed along with the associated technologies. 
A.  Data Collection and Description

CNN  approaches  require  a  large  corpus  of  high-quality 
annotated  data  that  can  be  used  to  train  the  network.  Given 
that there is limited availability of publicly available data that 
satisfy this requirement there are currently no viable models 
capable of classifying within species animal types.  Another 
major challenge to overcome is the deployment and automated 
inference  of  acoustic  sensors.  Individually,  sensors  may 
generate  reasonable  amounts  of  data,  but  collectively  the 
amount  of  data  that  needs  to  be  processed  will  increase 
exponentially based on the number of sensors deployed. The 
first challenge relates directly to how the data is obtained. The 
second  is  the  cost  of  compute  needed  to  process  the  data. 
Deploying  trained  models  on  edge  devices  for  real-time 
inferencing will take some consideration which has not been 
sufficiently  reported  in  the  literature.  Centralising  inference

true  positive  rate  while 

the 

The  trained  model  is  hosted  using  TensorFlow  2.2  and 
served  through  a  public  facing  website  developed  by  the 
authors 2 .  CUDA  11  and  cuDNN  7.6.5  enables  the  GPU 
accelerated learning aspect of the pipeline. A Samsung S10 is 
used  to  record  garden  birds  and  automatically  upload  the 
acquired audio to the platform using the Simple Mail Transfer 
Protocol (SMTP) for classification. Figure 6 shows the end-
to-end inferencing pipeline starting with the sensor and ending 
with the public facing conservationAI site as shown in Figure 
7.  Due  to  the  use  of  standard  protocols,  the  system  can 
interface  with  a  variety  of  sensors  for  real-time  inference. 
Where in field communication is unavailable, audio files can 
be batch uploaded through the website for offline inferencing. 

Figure 6. End-to-end Inferencing Pipeline 

Figure 7. ConservationAI Platform 

Inferencing

(UBMK) (pp. 625-629). IEEE 
[16] Kahl, S., Wilhelm-Stein, T., Hussein, H., Klinck, H., Kowerko, 
D.,  Ritter,  M.  and  Eibl,  M.,  2017,  September.  Large-Scale  Bird 
Sound  Classification  using  Convolutional  Neural  Networks.  In 
CLEF (Working Notes) 
[17]  Lasseck,  M.,  2018,  September.  Audio-based  Bird  Species 
Identification with Deep Convolutional Neural Networks. In CLEF 
(Working Notes) 
[18]  Muda,  L.,  Begam,  M.  and  Elamvazuthi,  I.,  2010.  Voice 
recognition  algorithms  using  mel  frequency  cepstral  coefficient 
(MFCC)  and  dynamic  time  warping  (DTW)  techniques.  arXiv 
preprint arXiv:1003.4083 
[19] S. Kanai, Y. Fujiwara, and S. Iwamura, “Preventing gradient 
explosions in gated recurrent units,” in Advances in neural 
information processing systems, 2017, pp. 435–444. 
[20] J. Ba and B. Frey, “Adaptive dropout for training deep neural 
networks,” in Advances in Neural Information Processing Systems, 
2013, pp. 3084–3092.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The text does not explicitly mention the specific cloud platform used to host the trained model. However, it mentions that the trained model is served through a public-facing website developed by the authors. This suggests that they might have used their own custom web server or hosting service rather than a popular cloud provider like AWS, Azure, or Google Cloud Platform. Therefore, without further information, we cannot definitively determine which platform was used to deploy the deep learning model.