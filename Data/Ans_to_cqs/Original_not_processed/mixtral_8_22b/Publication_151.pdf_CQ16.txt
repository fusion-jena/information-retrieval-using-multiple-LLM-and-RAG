Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

by a running average of its recent magnitude to speed
up training (Tieleman and Hinton 2012). The batch size
is ﬁxed to 32. We check the training loss every 50 epochs
and stop the training when the value of the loss function
fails to decrease in two consecutive checks. The model
with the optimal objective function value is chosen.

{

=

=

n
i

n
i

Di}
{

DR
i }

1 and

−

Our choices of hyperparameters such as k and the
training parameters such as the stopping criterion were
based on preselected values that were not ﬁne-tuned
on any data set. In extensive simulations, this simple
procedure was necessary due to computational reasons.
When applying in practice on real data, it is possible to
ﬁne-tune all the hyperparameters using a validation set.
We can ﬁrst randomly select a subset of the reference
species as the validation set, use these as testing data
to tune the parameters for the given data set, and then
train one last time with all the data with the ﬁne-tuned
parameters. Note that such a procedure will require
repeated training and can be slow, and our preliminary
results (Table S2 of the Supplementary material available
on Dryad) show that the gain in accuracy obtained can
be small.

Evaluation on Simulated Data Sets
DEPP training and parameter sensitivity.—We start by
evaluating DEPP on simulated data sets, testing the
ability to train the CNN model in reasonable times. As
the training epochs advance, the loss function (1) drops
rapidly and stabilizes after around 500 epochs in a typical
case (Fig. S1 of the Supplementary material available on
Dryad). Here, training, which is a one-time process for
each reference tree, ﬁnished in around 20 min for the 200-
taxon data set and 260 minutes for 10,000-taxon data set,
on a machine with one 2080Ti NVIDIA GPU and 8 CPU
cores. Placement of 1000 queries took 4 seconds for the
200-taxon and 30 s for the 10,000-taxon data sets using a
single CPU core. On the small 200-taxon data set, EPA-ng
has an advantage in terms of running time. However, in
the larger HGT data set (10,000-taxon), DEPP placements
are faster than the alternatives with half the running time
of EPA-ng. In terms of the memory usage, APPLES+JC

in the training set; however, high error examples have
higher variance. The high variance can be attributed to
a lack of signal: two identical sequences in the gene
may belong to different parts of the species tree, a
problem that the model cannot overcome. At the time
of testing (e.g., for a query), distances are systematically
overestimated in cases with high error, and a large range
of values are estimated for pairs with equal ML distances.
In some cases, DEPP assigns small distances to some
reference species that have high distances to the query
(Fig. 3; bottom left).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The training process is stopped when the value of the loss function fails to decrease in two consecutive checks. These checks are performed every 50 epochs. This means that if the loss function does not improve over two consecutive checks (which occur every 50 epochs), the training process is halted. The model with the optimal objective function value is then selected. It should be noted that the choices of hyperparameters and training parameters were based on preselected values that were not fine-tuned on any dataset. Instead, they were chosen due to computational reasons during extensive simulations. When applying this methodology in practice on real data, it is possible to fine-tune all the hyperparameters using a validation set.