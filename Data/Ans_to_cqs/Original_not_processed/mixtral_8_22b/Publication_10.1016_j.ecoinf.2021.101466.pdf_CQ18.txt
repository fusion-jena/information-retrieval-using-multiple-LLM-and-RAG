Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

these methods. By applying random erasing to the training dataset of the 
EfficientNet, performance was also moderately improved (Table 6).

4. Discussion 

Table 3 
Detection results using only the YOLOv4 with/without Random Erasing (R. E.).   

YOLOv4 w/ R. E. 
YOLOv4 w/o R. E. 

Precision 

0.55 
0.49 

Recall 

0.42 
0.41 

F-measure 

0.48 
0.45  

Table 4 
Comparison of performance among the EfficientNet and Xception models.   

Precision 

Recall 

F-measure 

EfficientNet-B0 
EfficientNet-B1 
EfficientNet-B2 
EfficientNet-B3 
Xception 

0.86 
0.89 
0.89 
0.91 
0.84 

0.38 
0.41 
0.40 
0.39 
0.35 

0.53 
0.56 
0.55 
0.55 
0.49  

Table 5 
Confusion matrices of the two-stage detection using the EfficientNet-B1 with (a) 
or without (b) random erasing. The rows and columns correspond to the ground 
truth and prediction, respectively.   

P. striolata 

P. atra 

Background 

(a) With random erasing 
P. striolata 
P. atra 
Background 

170 
2 
15 

(b) Without random erasing 
P. striolata 
P. atra 
Background 

164 
5 
20 

3 
90 
11 

4 
84 
15 

2 
7 
189  

7 
10 
180

Khoshgoftaar, 2019), is essential to create effective variation in training 
data with the cost to collect actual photographs kept minimum.

To train the EfficientNet, we prepared 4000 images for each category 
using the data augmentation method proposed above. We used 80% of 
the 4000 images for training and the remaining 20% for validation. The 
EfficientNet was trained by the Adagrad in 100 epochs. The dropout rate 
for each task was set at 0.5. The batch size was set at 20. 

All evaluations were performed on the NVIDIA GeForce RTX 2080Ti 
GPU with 11G memory, and the software was Windows 10, Python 3.7, 
CUDA 10.2. Keras 2.4.3 were used to build all models. 

To compare model results with the test video, we used IoU as the 
threshold  for  positives  or  negatives  based  on  the  object  confidence 
scores estimated by the object detector. IoU was defined as the inter-
section  over  the  union  of  the  two  bounding  boxes,  which  were  the 
ground-truth  bounding  box  and  the  predicted  bounding  box.  In  this 
paper, we set the threshold of IoU at 0.3 to consider correct or incorrect 
detection results.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The strategy implemented to monitor the model performance during training involves setting aside a portion of the dataset for validation purposes. Specifically, 80% of the 4000 images for each category are used for training, while the remaining 20% are reserved for validation. This allows for continuous monitoring of the model's performance throughout the training process. Additionally, the evaluation metrics such as precision, recall, and F-measure are likely being tracked to assess the model's effectiveness. Furthermore, the use of IoU (Intersection over Union) as a threshold for determining positive or negative detections indicates that the model's ability to accurately localize objects within the image is also being monitored.