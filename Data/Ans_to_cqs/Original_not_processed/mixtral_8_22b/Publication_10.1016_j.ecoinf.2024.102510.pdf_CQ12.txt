Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

64, 128, 256, 512 

64, 128, 256, 512 

EcologicalInformatics80(2024)1025107S.V.S. Kumar and H.K. Kondaveeti                                                                                                                                                                                                         

Table 8 
Performance comparison of the selected models evaluated using a 60:40 split of training and testing data.   

Validation accuracy 

Precision 

Recall 

F1-score 

Model name 

Feature extractor 

Fine tuner 

Feature extractor 

Fine tuner 

Feature extractor 

Fine tuner 

Feature extractor 

Fine tuner 

MobileNetV2 
EfficientNetB0 
GoogleNet 
DenseNet201 
InceptionV3 
ResNet18 
InceptionResNetV2 
NASNetMobile 

91.21% 
94.47% 
88.47% 
92.41% 
92.99% 
87.81% 
93.04% 
92.83% 

93.16% 
96.56% 
90.16% 
94.21% 
94.56% 
89.33% 
95.44% 
94.68% 

92.54% 
94.99% 
89.98% 
93.22% 
93.86% 
89.38% 
93.73% 
93.41% 

94.11% 
95.31% 
90.97% 
95.02% 
95.12% 
91.25% 
95.13% 
95.44%

Proposed pre-trained 
models in this work    
MobileNetV2    
a. Feature extractor 
b. Fine tunner 
EfficientNetB0    
a. Feature extractor 
b. Fine tunner 
GoogleNet    
a. Feature extractor 
b. Fine tunner 
DenseNet201    
a. Feature extractor 
b. Fine tunner 
InceptionV3    
a. Feature extractor 
b. Fine tunner 
ResNet18    
a. Feature extractor 
b. Fine tunner 
InceptionResNetV2    
a. Feature extractor 
b. Fine tunner 
NASNetMobile    
a. Feature extractor 
b. Fine tunner 

96.38%   
98.25%   

97.52%   
99.12%   

94.62%   
96.13%   

96.47%   
98.54%   

96.25%   
97.34%   

91.47%   
93.24%   

95.83%   
97.12%   

96.62%   
98.54%

search  tests  various combinations of  the hyperparameters  identified in  manual  search and  trains the selected 
models to achieve the maximum possible accuracy through multiple iterations. Experimental analysis revealed 
that the Fine-tuned EfficientNetB0 model exhibited superior performance, achieving an accuracy of 99.12%. In 
contrast, the performance of the ResNet18 model was disappointing with an accuracy of 93.24%, while other 
models outperformed it.

for  implementation,  accessing  pre-trained  weights  from  the  Deep 
Learning Toolbox. Table 2 presents the details of the pre-trained models 
used in this study. 

The  objective  of  this  work  is  to  generate  multiple  variants  of  the 
selected CNN models using transfer learning with HHOS and to identify 
the best-performing model for bird species recognition. The following 
sub-sections  provide  a  detailed  explanation  of  the  methodology  fol-
lowed in this study. 

2.1. Dataset description

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The pipeline uses Convolutional Neural Networks (CNN) as the deep learning model. This can be seen from the table where different types of CNN architectures are listed such as MobileNetV2, EfficientNetB0, GoogleNet, DenseNet201, InceptionV3, ResNet18, InceptionResNetV2, and NASNetMobile. These are all popular CNN architectures used for image classification tasks.