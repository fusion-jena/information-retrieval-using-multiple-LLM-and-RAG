Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 5. Model predicted vs observed AGB (a) Random Forest, (b) Artificial Neural Network, (c) Support vector machine of Sentinel-1 and Sentinel-2.

The  model  initially  included  all  variables,  acknowledging  the  sig-
nificance  of  identifying  and  selecting  pertinent  variables  for  model 
development. Variable importance measures were employed to evaluate 
their significance, which helped identify the most influential variables 
for  predicting  AGB.  However,  it  is  recognised  that  assessing  model 
performance is essential, particularly when dealing with less important 
variables. A stratified sampling method was applied to all AGB obser-
vations for this evaluation. This technique randomly allocated 70% of 
the samples to the training dataset and the remaining 30% to the vali-
dation  dataset.  Three  error  statistics,  specifically  R2,  mean  absolute 
error  (MAE),  and  RMSE  (as  indicated  in  Eqs.  8,  9,  and  10),  were 
employed to compare the accuracies of the models. The generated ma-
chine learning models were then extrapolated for the entire region. This

3.5.3. Artificial neural network 

ANNs are used for modelling complex phenomena and developing 
nonlinear regression (Haykin and Lippmann, 1994). It consists of three 
different  layers:  input,  hidden,  and  output  (Ingram  et  al., 2005).  The 
ANN uses calibration parameters, such as the learning rate and weight, 
to improve the results. The weights were randomly initialized using the 
Nguyen–Widrow method (Zhou et al., 2016). An ANN fitted with CARET 
is a single hidden-layer neural network with two hyperparameters: size 
and decay. The number of units in the hidden layer (size) and regular-
isation parameter to avoid overfitting (decay) were passed as arrays of 
1–20  and  0.025–1,  respectively.  The  Transfer/Activation  function  for 
the  model was  selected  as  the  logistic  function.  The  optimum  combi-
nation of parameters for the best model fit was based on accuracy. 

3.6. Model fitting and evaluation

R.K.  Singh:  Conceptualization,  Data  curation,  Formal  analysis, 
Methodology,  Writing  –  original  draft.  C.M.  Biradar:  Conceptualiza-
tion, Funding  acquisition, Investigation, Methodology,  Project admin-
istration, Resources, Supervision, Writing – original draft. M.D. Behera: 
Conceptualization, Investigation, Methodology, Resources, Supervision, 
Writing  –  review  &  editing.  A.J.  Prakash:  Methodology,  Software, 
Writing  –  original  draft.  P.  Das:  Investigation,  Methodology,  Visuali-
zation,  Writing  –  original  draft,  Writing  –  review  &  editing.  M.R. 
Mohanta:  Data  curation,  Formal  analysis,  Software.  G.  Krishna: 
Investigation, Project administration, Visualization, Writing –  original 
draft.  A.  Dogra:  Funding  acquisition,  Project  administration,  Visuali-
zation, Writing – review & editing. S.K. Dhyani: Funding acquisition, 
Visualization, Writing – review & editing. J. Rizvi: Project administra-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available in the given context to provide a detailed explanation about how the trained deep learning model was deployed. However, we can infer from the text that the researchers used various machine learning techniques like Random Forest, Artificial Neural Network, and Support Vector Machine to develop their models. They also mentioned using a stratified sampling method to allocate 70% of the samples to the training dataset and the remaining 30% to the validation dataset.

To evaluate the performance of these models, they utilized three error statistics - R², Mean Absolute Error (MAE), and Root Mean Square Error (RMSE). After evaluating the models, they were likely extrapolated for the entire region. However, the specific details regarding the deployment process, including model serialization or platform selection, are not explicitly stated in the provided context. Therefore, I cannot provide a more precise answer without additional information.