Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3. Fish classification by species 

A classifier based on deep neural networks was also used for this task. 
In this case, the chosen architecture is a residual neural network, whose 
main characteristic is that it can skip some of its layers (He et al., 2016). 
In particular, the implementation of ResNet50V2 model in TensorFlow 
and  pre-trained  with  the  ImageNet  dataset  (training  parameters  in 
Table  2).  A  problem  encountered  in  initial  tests  related  to  species 

EcologicalInformatics67(2022)1014954X. Lekunberri et al.

(b) Computing infrastructure used to train both neural networks 

Infrastructure 
Search strategy 
Training duration 
(best assignment) 

Nvidia Tesla V100 (16GB) 
Manual tuning  
Segmentation 
Classification 

4 h 6 min 24 s 
9 h 22 min 34 s

Trained model 

-  Manually: 275 

segments  

-  Automatically: 
6921 segments  

-  Data 

augmentation: 
x12 

-  14,896 images  
-  Two trained 

models 

22 of the 30 
fishing sets 
(unannotated) 

Data of the 22 
fishing sets   

-  Annotations  
-  Species 

prediction  

-  Size 

distribution 
Comparison  

Ground truth 

validation (sec. 
2.5) 

Data from 4 fishing 
sets  

-  Official sources  
-  Estimations

obtained through a port sampling program. This sampling strategy for 
estimating the composition of catches by species and sizes in the purse 
seine tropical tuna fisheries was established in 1998, and although it has 
been  slightly  adapted,  it  is  still  used  today  by  European  scientists 
(Duparc et al., 2019). When a tuna vessel arrives at port, sampling be-
gins with the selection of the well to be sampled. Although some wells 
may contain catches from different sets, those that store catches from a 
single  set  are  prioritized.  For  each  well  selected,  a  sample  of  500  in-
dividuals  is  randomly  selected  and  sampled  (i.e.,  species  id  and  size 
measurement). Sampling is conducted during the routine fish landing 
process in two batches while it is still frozen: 300 individuals first and 
200 individuals one hour after the first batch. The measurements taken 
at port are made either to FL if the fish is small or to LD1 otherwise.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, there are common practices in machine learning and deep learning pipelines to manage randomness. These include setting fixed seeds for reproducibility, using techniques like cross-validation to reduce variance due to random data splits, and employing ensemble methods to average out the effects of random initialization. In the given context, the authors mention using manual tuning and data augmentation, which could potentially help mitigate the impact of randomness. Nonetheless, without specific details regarding how they handled randomness, we cannot definitively state their approach.