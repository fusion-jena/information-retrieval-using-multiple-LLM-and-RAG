Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

function to ignore a certain class. These annotations are made manually, 
using special software, and consume large amounts of time. For model 
development  there  are  many  well  established  collections  of  image 
datasets for the training and evaluation of the models, such as ImageNet

Neural  networks  can  be  trained  in  a  supervised,  semi-supervised 
(Chen  et  al.,  2021;  Zhao  et  al.,  2020)  or  unsupervised  (Harb  and 
Kn¨obelreiter, 2021; Ji et al., 2019) way. When it comes to supervised 
learning (Deng et al., 2009; Minaee et al., 2021), the models are typi-
cally  trained with a  huge amount of  training data. This  training  data 
consist of input and target image pairs, where the input image describes 
the image that is supposed to be classified and the target image describes 
the  corresponding  classes  (labels).  For  semantic  image  segmentation, 
the  target  image  consists  of  a  fully  labeled  image,  which  means  that 
every single pixel of the training image is assigned to a certain class. In 
some cases, parts of the image that have no influence on the specific task 
can  be  ignore  by  the  model  (overexposed,  underexposed  or  blurred 
parts, unimportant parts etc.). This can be done by adjusting the loss

Australas. J. Inf. Syst. 22 https://doi.org/10.3127/ajis.v22i0.1538. 

Grathwohl, W., Wang, K.-C., Jacobsen, J.-H., Duvenaud, D., Norouzi, M., Swersky, K., 

2020. Your classifier is secretly an energy based model and you should treat it like 
one. In: Presented at the 8th International Conference on Learning Representations. 
https://doi.org/10.48550/arXiv.1912.03263. 

EcologicalInformatics79(2024)10241715S. Herdy et al.                                                                                                                                                                                                                                   

Harb, R., Kn¨obelreiter, P., 2021. InfoSeg: unsupervised semantic image segmentation 
with mutual information maximization. In: Bauckhage, C., Gall, J., Schwing, A. 
(Eds.), Pattern Recognition. Springer International Publishing, Cham, pp. 18–32. 
https://doi.org/10.1007/978-3-030-92659-5_2.

model allowed to benefit from unlabeled data during the training pro-
cess,  which  helped  us  to  reduce  the  time  needed  for  manual  data 
labelling.  In  addition,  existing  Joint  Energy-Based  models  have  the 
problem that the training is very unstable due to an exploding genera-
tive loss (Grathwohl et al., 2020), whereas the training of JESS was very 
stable.  In  contrast  to  the  basic  model,  the  JEM  image  classification 
additionally allows out of distribution detection as well as better cali-
bration of the model. In this respect, the JEM image classification works 
better than our model. The big improvement for our application was, 
that  JESS  can  be  very  useful  to  perform  a  domain  adaption  between 
similar biocrust datasets and therefore increase the transferability of the 
segmentation models.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit details about the strategies used to monitor the model performance during training. However, it mentions that neural networks can be trained using supervised, semi-supervised, or unsupervised methods. Supervised learning typically involves training models with a large amount of training data consisting of input and target image pairs. Semi-supervised learning allows models to benefit from unlabeled data during training, reducing the need for manual data labeling. Unsupervised learning focuses on finding patterns within the dataset without any prior knowledge of labels.

To evaluate the performance of these models, various metrics can be employed depending on the specific task. For instance, accuracy, precision, recall, F1 score, and area under the curve (AUC) are commonly used for classification tasks. For semantic image segmentation, mean Intersection over Union (mIoU) and pixel accuracy are often utilized. Additionally, loss functions play a crucial role in monitoring model performance during training. Cross-entropy loss is frequently used for multi-class classification problems, while binary cross-entropy loss is suitable for binary classification tasks.

However, the given context does not explicitly mention the use of these techniques or other strategies to monitor the model performance during training. Therefore, further information would be required to provide a more precise response.