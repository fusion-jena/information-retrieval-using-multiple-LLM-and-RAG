Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

by class sample size. We used the SGD (stochastic gradient descent) optimizer with an initial learning rate of 
0.01 for all models except MansNet, which was initially set at 0.1. The learning rate was reduced by a factor of 
10 after steps of 30 epochs. We used batch normalization and models were trained for 150 epochs using Nvidia 
Tesla K80 or P100 GPUs.

Scientific Reports |         (2021) 11:7580  | 

https://doi.org/10.1038/s41598-021-87210-1

4

Vol:.(1234567890)www.nature.com/scientificreports/Model

#Params 
(million)

Model speed 
(ms)

Top-1 accuracy Top-2 accuracy Top-3 accuracy Top-4 accuracy Top-5 accuracy Macro recall

Wide-ResNet101 124.9

InceptionV3

ResNet101

MnasNet-A1

24.0

42.6

1.0

5.46

3.34

3.33

3.28

0.9171

0.9162

0.9133

0.8579

0.9627

0.9610

0.9633

0.9335

0.9782

0.9767

0.9787

0.9609

0.9850

0.9834

0.9852

0.9730

0.9897

0.9882

0.9892

0.9814

0.8552

0.8519

0.8499

0.7689

Macro 
precision

0.8831

0.8881

0.8740

0.8250

Model training.  To speed up the training process, we used models pre-trained on the ImagNet  database32 
and then retrained them for bumble bee species classification using our image data set. We divided our full data 
set into training (80%) and test (20%) groups. After randomly shuffling images in each class (species) we split 
the images within species along the 80:20 ratio to maintain their proportional representations in the training 
and test groups. For each model, cropped images were resampled to a standard size for model input. Following 
the original implementation of these models, we used images of 224 × 224 pixels for ResNet, Wide-Resnet, and 
MnasNet, and 299 × 299 pixels for InceptionV3. We used an image augmentation strategy that included random 
rotation (≤ 100°), crop (≤ 10%), sheer (≤ 30%) and horizontal flip to help reduce overfitting and improve the 
generality of our  models33. To help account for the class imbalance in our data set, predictions were weighted

Gathering more images, especially of species with higher error rates, would likely improve the classification 
accuracy of our model and reduce species-specific error rates. This would allow us to capture a greater range 
of the heterogeneity in each species as well as reduce the imbalance among classes. For example, species with 
at least 4,500 images (3,600 train + 900 test) all had error rates lower than 10% (Fig. 3, Table S1). This suggests 
that, for species with error rates greater than 10%, obtaining at least 4,500 images would be an important goal 
for improving model performance. A challenge, however, is that the species with low training sample sizes are 
generally rarer in nature and/or have a restricted range. This rarity reduces their occurrence in databases such 
as Bumble Bee Watch because these species are not frequently encountered by volunteers. Some images can be

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors implemented several strategies to monitor the model performance during training. Firstly, they used models pre-trained on the ImageNet database and then retrained them for bumblebee species classification using their own image dataset. They divided their full dataset into training (80%) and test (20%) groups while maintaining the proportional representation of images within species in both groups. Secondly, they used an image augmentation strategy that included random rotation, crop, shear, and horizontal flip to help reduce overfitting and improve the generality of their models. Lastly, they used prediction weights to help account for the class imbalance in their dataset. These strategies helped ensure that the models performed well during training and generalized well to new data.