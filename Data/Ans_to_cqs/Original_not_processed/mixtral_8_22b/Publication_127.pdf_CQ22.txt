Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

S
E
C
N
E
I
C
S
R
E
T
U
P
M
O
C

Y
G
O
L
O
C
E

ABCDownloaded from https://www.pnas.org by THUERINGER UNIVERSITAETS UND LANDESBIBLIOTHEK JENA on August 28, 2024 from IP address 141.35.40.48.Table 1. Performance of different deep learning architectures

Architecture

No. of layers

Short description

AlexNet

NiN

VGG

GoogLeNet

8

16

22

32

ResNet

18, 34, 50, 101, 152

Table 2. Accuracy of different models on task I: Detecting
images that contain animals

Architecture

AlexNet
NiN
VGG
GoogLeNet
ResNet-18
ResNet-34
ResNet-50
ResNet-101
ResNet-152
Ensemble of models

Top-1 accuracy, %

95.8
96.0
96.8
96.3
96.3
96.2
96.3
96.1
96.1
96.6

The bold font indicates the top-performing architecture.

E5720 | www.pnas.org/cgi/doi/10.1073/pnas.1719367115

Norouzzadeh et al.

8

16

22

32

ResNet

18, 34, 50, 101, 152

A landmark architecture for deep learning winning ILSVRC
2012 challenge (31).
Network in Network (NiN) is one of the ﬁrst architectures
harnessing innovative 1 × 1 convolutions (49) to provide
more combinational power to the features of a convolutional
layers (49).
An architecture that is deeper (i.e., has more layers of
neurons) and obtains better performance than AlexNet
by using effective 3 × 3 convolutional ﬁlters (26).
This architecture is designed to be computationally efﬁcient
(using 12 times fewer parameters than AlexNet) while offering
high accuracy (50).
The winning architecture of the 2016 ImageNet competition
(25). The number of layers for the ResNet architecture can be
different. In this work, we try 18, 34, 50, 101, and 152 layers.

25% (757,000) nonempty images and randomly selected 757,000
empty images. This dataset was then split into training and
test sets.

A well-known method for further improving classiﬁcation
accuracy is to use an ensemble of models at the same time
and average their predictions. After training all of the nine
models for each stage, we formed an ensemble of the trained
models by averaging their predictions (SI Appendix, Prediction
Averaging). More details about the architectures, training meth-
ods, preprocessing steps, and the hyperparameters are in SI
Appendix, Preprocessing and Training. To enable other groups
to replicate our ﬁndings and harness this technology for their
own projects, we are publishing the software required to run
our experiments as freely available, open-source code. We are
also publishing the ﬁnal DNNs trained on SS so that others
can use them as is or for transfer learning. Both the code and
the models can be accessed at https://github.com/Evolving-AI-
Lab/deep learning for camera trap images.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In Table 2, the metric used to evaluate the performance of the deep learning models is Top-1 accuracy. Top-1 accuracy measures the percentage of correct predictions where the predicted label matches exactly with the true label. It does not consider any partial credit for close guesses. Other common evaluation metrics include precision, recall, F1 score, and area under the receiver operating characteristic curve (AUROC), but these were not mentioned in the given context.