Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

III. Model Development

i. All the datasets were divided randomly into two: 80 % for
training the RF and SVR models, and 20 % for testing the
model, although the training set was further randomly
sampled to select training and validation set to obtain opti-
mized model hyperparameters.

EcologicalInformatics82(2024)1027355I. Busari et al.

Table 3
Description of models developed in the study.

Model abbreviation

Description

RF_with_Sensor

RF_w/o_Sensor

SVR_with_Sensor

SVR_w/oSensor

RF_with_Sensor_cont

RF_w/o_Sensor_cont

SVR_with_Sensor_cont

SVR_w/o_Sensor_cont

Data-driven models have evolved as effective decision-support tools
for HABs monitoring and prediction. These models are essential for
using patterns between water quality parameters and ecosystem vari-
ables to predict algal-related parameters such as chlorophyll-a, phyco-
cyanin, algal cells, and toxins (Busari et al., 2023; Kimambo et al.,
2019). Machine learning (ML) models such as random forest (RF),
Multilayer perceptron (MLP), long-short term memory (LSTM), and
support vector regression (SVR) have been used successfully to predict
different algal-related parameters and help identify drivers of HABs (Liu
et al., 2019; Qian et al., 2023; Zhang et al., 2015, Busari et al., 2023).
Model predictions are, however, influenced by varying degrees of un-
certainty (Gawlikowski et al., 2023). According to Guzman et al. (2015),
uncertainty refers to the variation between the actual state of a variable
and its theoretical assessment at a particular time. These prediction

C and 27

◦

◦

3. Methodology

To provide clarity, this section begins with a brief overview of the
methodology which includes each objective and the sequential steps
undertaken to achieve them, followed by a detailed explanation of the
methods employed for each objective.

3.1. Overview of methodology

Objective 1
This objective involves the development of multiple machine-
learning models using randomized subsets of training data to estimate

Fig. 2. Flowchart of adopted methodology.

effect of measurement uncertainties on chlorophyll-a predictions.

While the overall methodology is shown in the flowchart in Fig. 2,
this section provides the general outline of the methodology adopted to
address objective 1.

I. Data Acquisition

i. High frequency (e.g., 15 min) continuous surface water
quality data (e.g., pH, turbidity) were acquired from water
quality sensors-YSI profiler deployed in Boyd Millpond by the
Land Development Division of Greenville County, SC.

enhance learning of peak values as compared to that of the manually
sampled data.

4.2. Hyperparameter tuning

For tuning purposes, the model structures were same as described in
Table 3, with the manually sampled chlorophyll-a as output for the
manually sampled scenarios and the continuous regression derived
laboratory chlorophyll-a was the output for the high frequency data
scenario. Using different random training datasets to develop the models
enabled the realization of optimized parameters using the Optuna
package. The multi-modal nature of some of the distribution of the pa-
rameters indicates several peaks that provide a good trade-off between
performance and computational cost. The distribution of the parameters
slightly varies with each modeling scenario. For RF_w/o_Sensor, the
modal n_estimators observed was 20, which increases to 50 in the RF_w/
o_Sensor_cont. This shows the need for more regression trees to be

EcologicalInformatics82(2024)1027359I. Busari et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors implemented a strategy to monitor the model performance during training by dividing all datasets randomly into two sets: 80% for training the Random Forest (RF) and Support Vector Regression (SVR) models, and 20% for testing the model. Furthermore, the training set was also randomly sampled to select training and validation sets to obtain optimized model hyperparameters. This approach allowed the researchers to evaluate the performance of their models during training and fine-tune them accordingly.

Reference(s):
[I. Busari et al.]

Answer:::
Answer: The strategy implemented to monitor the model performance during training involved dividing all datasets randomly into two sets: 80% for training the Random Forest (RF) and Support Vector Regression (SVR) models, and 20% for testing the model. Additionally, the training set was further randomly sampled to select training and validation sets to obtain optimized model hyperparameters. This approach enabled the evaluation of the performance of the models during training and the fine-tuning of the models accordingly.

Reference(s):
[I. Busari et al.]