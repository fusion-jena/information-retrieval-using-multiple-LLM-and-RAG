Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Three models (Models 4, 5, and 6) were trained using our own data 
(clusters of extracted numbers), as described above, as input for training, 
whereas the other three models (Models 1, 2, and 3) were trained with 
the modified National Institute of Standards and Technology (MNIST) 
dataset of handwritten digits, which can be used to train classification 
models (Deng, 2012).

split  data  with  the  highest  mAP50  (0.987)  for  the  prediction  of  our 
model.

Li, X., Wang, W., Wu, L., Chen, S., Hu, X., Li, J., Tang, J., Yang, J., 2020b. Generalized 
Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object 
Detection. Vancouver. 

Li, Y., Fan, Q., Huang, H., Han, Z., Gu, Q., 2023. A modified YOLOv8 detection network 

for UAV aerial image recognition. Drones 7. https://doi.org/10.3390/ 
drones7050304. 

Liang, X., Kankare, V., Hyypp¨a, J., Wang, Y., Kukko, A., Haggr´en, H., Yu, X., 

Kaartinen, H., Jaakkola, A., Guan, F., Holopainen, M., Vastaranta, M., 2016. 
Terrestrial laser scanning in forest inventories. ISPRS J. Photogramm. Remote Sens. 
115, 63–77. https://doi.org/10.1016/j.isprsjprs.2016.01.006. 

Luo, Y., Duraiswami, R., 2008. Canny edge detection on NVIDIA CUDA. In: In: 2008 IEEE 

Computer Society Conference on Computer Vision and Pattern Recognition 
Workshops. IEEE, Anchorage, pp. 1–8. https://doi.org/10.1109/ 
CVPRW.2008.4563088.

Using this ideal split, a test was conducted using unprocessed data. 
This indicates that the test dataset appeared to be similar to the training 
data  because  it  consisted  of  images  of  the  extracted  clusters  without 
further processing. 

The  dataset  used  in  this  study  included  single-tree  point  clouds, 
images of single-trees, and *. csv containing the attributes used to pro-
duce the images, reference data, clusters of numbers (in two different 
point-thickness settings), labeled numbers, preprocessed images of the 
numbers, numbers from the best split, and tables containing the results 
of  our  digit  recognition  are  freely  available  under:  Doi:  https://doi. 
org/10.5281/zenodo.10663114. 

3. Results 

3.1. Classification accuracy

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The dataset used in this study, including single-tree point clouds, images of single-trees, and.csv files containing the attributes used to produce the images, reference data, clusters of numbers, labeled numbers, preprocessed images of the numbers, numbers from the best split, and tables containing the results of their digit recognition, is freely available under the DOI: <https://doi.org/10.5281/zenodo.10663114>. This suggests that the data repository of the deep learning pipeline is available on Zenodo.