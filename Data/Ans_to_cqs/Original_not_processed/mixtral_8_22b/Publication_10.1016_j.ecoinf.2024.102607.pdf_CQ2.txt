Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Davidson, A., Fisette, T., Rollin, P., Brisco, B., et al., 2020. Application of Google 
Earth engine cloud computing platform, sentinel imagery, and neural networks for 
crop mapping in Canada. Remote Sens. 12, 3561–3578. 
Breiman, L., 2001. Random forests. Mach. Learn. 45, 5–32. 
Cai, S., Liu, D., 2013. A comparison of object-based and contextual pixel-based 

classifications using high and medium spatial resolution images. Remote Sens. Lett. 
4, 998–1007. 

Campos, J.C., Brito, J.C., 2018. Mapping underrepresented land cover heterogeneity in 
arid regions: the Sahara-Sahel example. ISPRS J. Photogramm. Remote Sens. 146, 
211–220. 

Chen, J., Chen, J., Liao, A., Cao, X., Chen, L., Chen, X., He, C., Han, G., Peng, S., Lu, M., 
et al., 2015. Global land cover mapping at 30m resolution: a POK-based operational 
approach. ISPRS J. Photogramm. Remote Sens. 103, 7–27. 

Chen, B., Huang, B., Xu, B., 2017. Multi-source remotely sensed data fusion for

In addition to selecting the RS imagery and representative training 
samples, the choice of machine learning (ML) algorithm directly affects 
the accuracy of the classification results. Currently, a wide range of ML 
algorithms are extensively employed in LULC mapping, including sup-
port vector machines (SVMs) (Adugna et al., 2022; Silva et al., 2017), 
random forests (RFs) (Svoboda et al., 2022), decision trees (DTs) (Shih 
et al., 2018), and artificial neural networks (ANNs) (Amani et al., 2020; 
Hu et al., 2021). Researchers have frequently compared the accuracies 
of LULC maps derived from different classifiers (Shih et al., 2021). The 
RF  classifier  outperformed  the  other  ML  classifiers,  as  confirmed  by 
LULC (Shih et al., 2018; Yuh et al., 2023) and crop mapping (Inglada 
et al., 2015). RF has lower sensitivity to tuning parameters and stronger 
robustness against noise (Wa´sniewski et al., 2022). Furthermore, RF can

2.2.1. Satellite data 

Landsat-8 satellite data were obtained from the GEE platform (htt 
ps://developers.google.com/earth-engine/datasets/catalog/LANDSAT_ 
LC08_C02_T1_L2).  Detailed  statistical  information  of  these  images  is 
presented in Table 1. For LULC classification, we selected only six bands: 
blue, green, red, near-infrared, and two shortwave infrared bands. The 
quality assurance (QA) band was pivotal for identifying and removing 
clouds and shadows. 

2.2.2.

Image preprocessing

image presegmentation. This retains the benefits of object-based clas-
sification  while  eliminating  time-consuming  parameter  adjustments 
required by traditional segmentation methods. Furthermore, it is worth 
highlighting that the proposed method is deployed on the GEE platform. 
This indicates that it can be easily applied to other regions or different 
study years, making it a versatile and accessible tool for RS and LULC 
classification tasks. In future studies, the sample and vegetation index 
feature datasets should be continuously optimised. Furthermore, we will 
incorporate CNN and DNN deep-learning algorithms into the study of 
LULC mapping in arid zones.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The research primarily focuses on remote sensing (RS) imagery for land use and land cover (LULC) mapping. Specifically, they utilize Landsat-8 satellite data obtained from the Google Earth Engine (GEE) platform. They select six bands from this data: blue, green, red, near-infrared, and two shortwave infrared bands. Additionally, they employ the quality assurance (QA) band to identify and remove clouds and shadows. Therefore, the primary data format used in their deep learning pipeline is RS imagery. However, there is also mention of incorporating Convolutional Neural Networks (CNN) and Deep Neural Networks (DNN) in future studies, which typically work with image data. There is no explicit mention of other data formats such as audio, video, or CSV files being used in their current or planned deep learning pipelines.