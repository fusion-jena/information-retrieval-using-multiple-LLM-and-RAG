Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The duration of audio ﬁles in CLO-43DS data is different,
which cannot be directly used as the input to the CNN. The
ﬁrst method for dealing with the multi-variate varying length
audio data is that the signal is repeated from the beginning to
force the ﬁxed duration of 2s, which has been used in [30].
The second method is to directly resize the audio image to a
ﬁxed size.

D. DEEP LEARNING ARCHITECTURE
The feature learning part of our proposed model follows a
VGG style network [24], which has been previously used
for classifying acoustic scenes [5]. The overall architec-
ture is illustrated in Table 1. This network is trained using
Adam optimizer with a learning rate of 10−4. The cate-
gorical cross entropy is utilized as the loss function. The
batch size is 64 samples and the network is trained with
200 epochs.

trogram. In addition to different TFRs, a different deep learning architecture, SubSpectralNet, is employed
to classify bird sounds. Experimental results on classifying 43 bird species show that fusing selected deep
learning models can effectively increase the classiﬁcation performance. Our best fused model can achieve a
balanced accuracy of 86.31% and a weighted F1-score of 93.31%.

TABLE 3. Classification performance of different methods using single
CNN-based model. Here, Mel-CNN, Harm-CNN, and Perc-CNN denote that
the input to those CNNs are Mel-spectrogram, harmonic-component
based spectrogram, and percussive-component based spectrogram.
Subnet-CNN denotes that a SubSpectralNet architecture is used with the
Mel-spectrogram as the input.

To further improve the classiﬁcation performance, we not
only fuse CNN-based models with different input features,
but also fuse another CNN-based model with a different
architecture (see Table 2). The best classiﬁcation F1-score
can be up to 93.31%. Different from the VGG style network,
the SubSpectralNet can be regarded as a ﬁlter with different

VOLUME 7, 2019

175359

J. Xie et al.: Investigation of Different CNN-Based Models for Improved Bird Sound Classification

[5] M. Dorfer, B. Lehner, H. Eghbal-Zadeh, H. Christop, P. Fabian, and
W. Gerhard, ‘‘Acoustic scene classiﬁcation with fully convolutional
in Proc. DCASE Challenge,
neural
Sep. 2018. [Online]. Available: http://dcase.community/challenge2018/task-
acoustic-scene-classiﬁcation-results-a

I-vectors,’’

networks

and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

From the given context, it appears that the authors have focused on improving the classification performance by employing various techniques such as using different time-frequency representations (TFRs), fusing multiple deep learning models, and utilizing a different deep learning architecture called SubSpectralNet. However, there is no explicit mention of specific measures taken to ensure the generalizability of their deep learning model.

Generalizability refers to how well a machine learning or deep learning model performs when applied to new, unseen data. To ensure good generalization, one might use diverse datasets, perform cross-validation, or apply stratified splitting during training and testing phases. These techniques help prevent overfitting and allow the model to better handle novel inputs.

In this case, while the authors do discuss using different types of spectrograms as input features and combining several models to enhance performance, they do not explicitly state any particular steps taken to guarantee the robustness and applicability of their approach across varied scenarios. Therefore, without additional information, it remains uncertain whether these aspects were considered during the development and evaluation of their deep learning model.