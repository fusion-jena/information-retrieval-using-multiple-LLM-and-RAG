Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

diversify  the  training  data,  and  the  3-s  window  length  enables  the 
implementation of this data augmentation method.

Here  we  present  a  new  algorithm,  called  BirdNET,  that  builds  on 
these previous successes using CNNs and spectrogram data to classify 
984  bird  species.  We  discuss  the  necessary  steps  required  to  develop 
such a system and provide insights into our training and testing work-
flow of a deep artificial neural network. Finally, we give an outlook on 
how  this  technology  can  support  ornithologists  and  conservation  bi-
ologists in their work to identify and address the environmental chal-
lenges of our time. 

2. Methods

followed  the  original  Wide  ResNet  design.  Our  downsampling  blocks 
employed the changes suggested in (Xie et al., 2018). The third and final 
component, the classification block, was derived from (Schlüter, 2018) 
and resulted in probability predictions for all 987 classes per second (i. 
e., three predictions per 3-s input spectrogram) followed by global log- 
mean-exponential  pooling  and  sigmoid  activation.  Most  convolutions 
use 3 × 3 kernels with padding and are succeeded by batch normali-
zation  (Ioffe  and  Szegedy,  2015)  and  ReLU  activation  (if  not  noted 
differently).  Because  we  treated  spectrograms  as  monochrome  input 
images, the input was a single channel mel spectrogram of size 64 × 384, 
visualizing three seconds of audio at a sampling rate of 48 kHz. 

2.5. Training

2. Methods 

Our overall workflow for training a deep neural network consisted of 
the acquisition of large amounts of audio data, the pre-processing of this 
data to generate visual representations of sound, the augmentation of 
these visualizations, and, finally, the training of a complex model ar-
chitecture with ~27 million trainable parameters. We ran inference on 
independent validation and test splits of the acquired data and applied 
our model to continuous soundscape recordings, which are part of an 
ongoing monitoring project in Ithaca, NY, USA. 

2.1. Data acquisition

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not contain any information about the data repository link of the deep learning pipeline. Therefore, it is not possible to provide an accurate response based solely on the provided context.