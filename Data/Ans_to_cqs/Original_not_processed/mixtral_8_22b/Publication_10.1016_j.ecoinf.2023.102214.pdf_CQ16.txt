Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Models were trained and tested by tuning the number of required 
epochs and then inspecting the model outputs and error outcomes for 
signs of overfitting. If the model focuses excessively on data fitting, it 
may imitate insignificant noise rather than the broad properties of in-
terest, resulting in overfitting.

converged to its most accurate state, assessing each image only 10–30 
times  (in  machine  learning  terms,  after  10–30  “training  epochs”), 
whereas the typical duration is between 70 and 250 epochs. Subsequent 
training had no effect or decreased the algorithm’s performance on held- 
out test data, indicating that its long-term behavior resembled memo-
rizing  its  training  set  rather  than  learning  a  generalized  matching 
strategy (this is the machine learning definition of “overfitting”).

2.8.2.

Image classification 

To assess the efficacy of the various techniques, we compute the top- 
k accuracy on a test set, where k = 1, 5, and 10 represents the position of 
the correct match (i.e., an annotation of the same individual represented 
by a query annotation) within a list of proposed matches. Consequently, 
a top-1 rank is an accurate result supplied by the algorithm as the most 
probable match for a candidate annotation. A top-5 rating indicates that 
the correct answer might be any of the top-5 values among the returned 
options, and so on. 

EcologicalInformatics77(2023)1022145E. Bohnett et al.                                                                                                                                                                                                                                 

3. Results 

3.1. Detection algorithm

Declaration of Competing Interest 

The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper. 

Data availability 

Research-related  requests  for  annotations  and  data  used  for  ML 
training in this paper can be requested in COCO format (Lin et al., 2020) 
via the corresponding author and must be expressly and independently 
permitted by author Eve Bohnett or through an established collabora-
tion on Whiskerbook.org. Data can also be reviewed and shared via a 
collaboration request to user Eve Bohnett inside the Whiskerbook.org 
system. 

Acknowledgements

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Training completion is determined based on several factors, including signs of overfitting and the convergence of the model to its most accurate state. Overfitting occurs when the model focuses too much on data fitting, leading it to mimic insignificant noise instead of the broader properties of interest. To avoid overfitting, models are trained and tested by adjusting the number of required epochs and examining the model outputs and error outcomes. In this study, the model converged to its most accurate state after 10--30 training epochs, while the typical range is between 70 and 250 epochs. Further training did not improve or even worsened the algorithm's performance on held-out test data, suggesting that its long-term behavior was more like memorizing the training set rather than learning a generalized matching strategy. This phenomenon is referred to as overfitting in machine learning. Therefore, the criteria used to determine when training is complete include monitoring the model's performance on both training and testing datasets, looking for signs of overfitting, and ensuring that the model has reached its most accurate state without excessive data fitting.