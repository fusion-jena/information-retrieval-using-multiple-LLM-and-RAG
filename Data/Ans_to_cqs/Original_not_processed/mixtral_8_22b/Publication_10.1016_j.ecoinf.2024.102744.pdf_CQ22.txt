Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

VnPollenBee dataset. The best metrics values are shown in bold font. 

Method 

Evaluation metrics 

Journal Pre-proof

Our proposed methods 

Baseline methods 

0.12  0.004 

0.15  0.009 

0.086  0.03 

0.99 

0.99 

0.58 

0.96 

0.41 

0.91 

0.85 

0.88 

0.88 

MR 

Yolov5 + classification  0.11 

Yolov5 + focal loss 

Yolov5 [39] 

Faster RCNN [40] 

0.91 

0.93 

0.70 

0.93 

FAR  Precision  Recall  F1-score 

Faster RCNN 

+ Overlap Sampler 

0.07 

0.01 

0.99 

0.93 

0.95 

Figure 14: Evaluation metrics of the pollen-bearing bee detection results. 

Figure 15: Detection results of the proposed improvement: (above) YOLOv5 + focal loss, (below) 

Faster  RCNN  +  Overlap  sampler.  The  green  and  red  boxes  indicate  pollen-bearing  and 

 
 
Journal Pre-proof

non-pollen-bearing bees, respectively. Values indicate the confidence score. 

Furthermore,  Fig.  15  depicts  some  detection  outcomes  of  the  second  proposed

image for each model in our experiments are computed and shown in Table 6. 

Table 6: Comparison of the number of parameters, GFLOPs, and inference time of models in our 

experiments. 

Method 

Evaluation metrics 

 
 
Journal Pre-proof

Parameters (M)  GFLOPs  Time (ms) 

Baseline methods 

Yolov5 [39] 

86.18 

203.8 

Faster RCNN [40] 

41.20 

446.7 

52.9 

60.0 

Other state-of-the-art methods 

EfficientDet [43] 

6.55 

2.8 

322.0 

698.0 

79.4 

22.0 

52.3 

110.0 

Yolov5 + classification 

RetinaNet [41] 

DETR [44] 

Yolov5 + focal loss 

Faster RCNN 

+ Overlap Sampler 

47.8 

97.1 

86.35 

41.30 

204.2 

86.18 

37.96 

203.8 

Our proposed methods 

Journal Pre-proof

1097.9 

41.30 

5.4. Application to the problem of counting pollen-bearing bees 

Counting the number of pollen-bearing bees entering the hive enables beekeepers to monitor the 

hive’s food status and promptly replenish it if necessary. Recognizing this benefit, we integrated

(DETR),  our  proposed  model’s  FAR,  Precision,  and  F1  score  are  higher  by  3%,  4%,  and  1%, 

respectively. Although the MR measurement of our proposed model is higher than that of DETR, 

the difference is not significant. 

Table  5:  Comparison  of  experimental  results  between  the  proposed  method  and  recent 

state-of-the-art models  on the VnPollenBee dataset.  The best  metrics  values are shown in  bold 

font, while the second-highest values are shown in underline font. 

MR  FAR  Precision  Recall  F1-score 

Method 

Evaluation metrics 

Journal Pre-proof

Other state-of-the-art methods 

Our proposed method 

0.062  0.04 

0.078  0.13 

0.078  0.13 

0.01 

0.87 

0.99 

0.93 

0.93 

0.92 

0.87 

0.92 

0.95 

0.07 

EfficientDet [43] 

RetinaNet [41] 

DETR [44] 

+ Overlap Sampler 

Faster RCNN 

0.89 

0.89 

0.94 

0.95 

Additionally,  the  number  of  parameters,  GFLOPs,  and  the  average  inference  time  per

and false positives,  we incorporate two additional  measures:  Miss  Rate (MR) and False Alarm 

Rate (FAR). These metrics are computed using the following formulas: 

(1) 

(2) 

(3) 

(4) 

where  TP,  TN,  FP,  and  FN  stand  for  True  Positive,  True  Negative,  False  Positive,  and  False 

Negative respectively. 

In addition, we use the F1 score to be able to  gauge the balance between Precision and 

Recall. The F1 score is determined as follows: 

=TPPrecisionTPFP=TPRecallTPFN=FNMRFNTP=FPFARTPFP 
 
 
 
 
 
 
 
 
 
Journal Pre-proof

(5) 

4.  Proposed  methods 

for  pollen-bearing  bee  detection  and 

classification 

4.1. Baseline models 

as the second baseline method due to its higher detection accuracy. 

We  have  selected  two  widely  recognized  object  detection  models,  YOLOv5  [39]  and  Faster 

RCNN [40], as baseline methods for pollen-bearing bee detection. YOLOv5 is a one-stage object

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The evaluation metrics used to assess the performance of the deep learning models include Miss Rate (MR), False Alarm Rate (FAR), Precision, Recall, and F1-score. The MR and FAR measure the proportion of missed detections and false alarms, respectively. Precision indicates the ratio of correctly detected positive instances out of all predicted positive instances, while Recall represents the fraction of relevant instances that were retrieved. Lastly, the F1-score combines both Precision and Recall into a single metric, providing a balanced assessment of the model's performance.