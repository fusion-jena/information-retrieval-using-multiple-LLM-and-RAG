Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The implementation of the CNN classiﬁer was done in Python
programming language (https://www.python.org/), using the
Keras high level deep learning library (https://keras.io/), and Ten-
sorFlow with graphical processing unit (GPU) execution as the
back-end engine (https://www.tensorﬂow.org/). The regions of
the images most informative for the decision making process in
the deep learning model were visualized using Gradient-
weighted Class Activation Mapping (Grad-CAM; (Selvaraju et al.,
2017)). As an output, heatmaps were generated that indicated
important aspects of the each head capsule used to determine
the taxonomic decision-making process of the model.

3. Results

3.1. Classiﬁcation results

Fig. 2. Architecture of the proposed CNN model, where input images of 512x512
pixels with 3 colour channels are transformed into a 2048 feature vector that is
subject to classiﬁcation using the fully connected layer. A normalized exponential
function (softmax) then takes the input vector and normalizes it into a probability
distribution to determine the probability for each class.

CNN, while the remaining 20% were used for validation of the
model. The 80:20 split of the image data was carried out per cate-
gory (chironomid taxa), where each ﬁfth image was chosen for the
validation dataset (Table 1).

4. Discussion

factors: network architecture, protocol type of image acquisition
(Martineau et al., 2017), and robustness of input matrix (number
of entities and replicates). Our choice to use a ResNet-50 network
architecture, in combination with transfer learning, data augmen-
tation, and dropout proved appropriate for the current number of
taxa in our demonstration dataset. ResNet-50 network architecture
represents a midsize solution in the ResNet palette (18, 34, 50, 101,
152 layers) that combines both representation power and lower
complexity that allows relatively fast training of the models. How-
ever, the protocol for image acquisition inﬂuences the complexity
of features, which will be processed by CNNs. Controlled object
position during the collection of images can also govern the level
of feature variability. Our dataset was constructed under the lab-
based protocol of image acquisition with fully controlled position
of the larvae (ventral point of view). This was not the case in pre-

ImageNet) (Russakovsky et al., 2015). Since 2012, there has been
signiﬁcant improvement in deep learning CNN architectures that
have led to better classiﬁcation results in the ImageNet challenge.
Here lies an opportunity to use a similar structure and approach
for targeted application in biomonitoring studies that could incor-
porate high-resolution information from the Chironomidae in
inferences of ecosystem integrity.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: Based on the given context, the data format used in the deep learning pipeline is images. Specifically, the input images have dimensions of 512x512 pixels with three color channels. These images are fed into a Convolutional Neural Network (CNN) for classification purposes. Additionally, the context mentions the use of Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps that highlight important aspects of each head capsule used in the taxonomic decision-making process of the model. Therefore, we can conclude that the primary data format used in this deep learning pipeline is images.