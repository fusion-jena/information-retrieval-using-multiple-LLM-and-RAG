Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

This  experiment  used  both  learnable  frontends  with  80  filters  of 
length  512  (16 ms)  that were  initialized  by  mel-filterbanks.  Gaussian 
pooling  was  removed,  and  downsampling  happened  in  the  filtering 
convolution layer by a stride of 320 (10 ms). Then, the outputs were log- 
compressed  without  normalization.  These  plain  frontends  are  called 
LEAF-P and SincNet-P, and Table 4 shows their test results.

datasets.  They  are  not  flexible  enough  to  address  current  open  chal-
lenges unless used purposefully on a narrow task.

Recent years have seen impressive progress in bird species recogni-
tion and related tasks (Stowell, 2022; Xie et al., 2023). It was foreseeable 
that  deep  learning  would  emerge  as  the  most  successful  method  for 
large-scale  bioacoustics  analysis  (Kahl  et  al.,  2021;  Stowell,  2022; 
Stowell et al., 2019; Tang et al., 2023; Xie et al., 2023; Zsebok et al., 
2019). The main advantage of neural networks is to avoid many brittle 
and  difficult  choices  in  designing  manual  features  for  the  underlying 
task. For example, Xie et al. (Xie and Zhu, 2019) compared three types of 
features  for  bird  species  classification  consisting  of  hand-crafted 
acoustic features, including features from Mel Frequency Cepstral Co-
efficient (MFCC), visual features extracted from the Constant-Q Trans-
form (CQT) time-frequency representation, and training a convolutional 
network directly on the CQT. They also tested the fusion of classifiers

The experiments were conducted on a server with 64 Intel Xeon Gold 
6226R CPUs, 192 GiB RAM, and one NVIDIA RTX A-6000 GPU with 48 
GiB RAM. The training time varied based on the experiment, with the 
lowest for static frontends being around 1.5 hours and for LEAF around 
5 h. SincNet+ is slightly faster than LEAF since the latter has complex 
valued filters. The project used the following Python packages: PyTorch 
(Paszke et al., 2019), TorchAudio (Yang et al., 2021), TorchVision (T. 
maintainers  and  contributors,  2016),  Scikit-learn  (Pedregosa  et  al., 
2011), NumPy (Harris et al., 2020), Matplotlib (Hunter, 2007), Pandas 
(T. Pandas Development Team, 2023), and tqdm (da Costa-Luis et al., 
2023). 

3.1. Main results

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning models in this study were built using the PyTorch framework. This can be inferred from the mention of PyTorch in the list of Python packages used in the project. Other packages mentioned include TorchAudio, TorchVision, Scikit-learn, NumPy, Matplotlib, Pandas, and tqdm. However, none of these are direct competitors or alternatives to PyTorch when it comes to building deep learning models. Therefore, we can confidently state that PyTorch was the primary framework used for developing the deep learning models in this research.