Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

YFT 

BET 

FAL 

F 

SUS 

Predictor 

F 

SUS 

Predictor 

F 

SUS 

Predictor 

F 

SUS 

SKJ 

Predictor 

SST 

Temperature at 50 m 
Month 
Temperature gradient at 

200 m 

Chlorophyll concentration 

integrated at 20 m 

Nitrate at 50 m 

Phosphate at 50 m 

10 

10 
10 

10 

10 

10 

10 

0.0078 

0.0078 
0.0075 

Oxygen concentration 
integrated at 10 m 
Temperature at 50 m 
Nitrate at 50 m 

0.0071 

Surface phosphate 

0.0069  Month 

0.0067 

Nitrate at 20 m 

0.0064 

SST 

10 

10 
10 

10 

10 

10 

10 

0.0080 

Silicate at 150 m 

0.0079 
0.0078 

Salinity at 50 m 
Temperature at 50 m 

0.0075 

SST 

0.0069 

Nitrate at 100 m 

0.0056 

0.0055 

Salinity at 200 m 
Oxygen concentration 
integrated at 50 m 
Oxygen concentration 
integrated at 175 m 

Nitrate at 20 m 

10 

0.0064 

Temperature at 150 m 

10 

0.0051 

Temperature gradient at 

150 m 

10 

0.0061 

Phosphate at 175 m 

10 

0.0050 

Phosphate at 10 m 

Sea level anomaly 

10 

0.0061 

Longitude

10 

10 

10 

10 

9 

9 

9 

8 

8 

7 

6 

0.0080 

0.0066 
0.0052 

0.0037 

0.0029 

0.0026 

0.0025 

0.0040 

0.0026 

0.0026 

0.0023 

0.0021 

0.0033 

0.0029 

Silicate at 50 m 

10 

0.0047 

Oxygen concentration 
integrated at 50 m 

Salinity at 50 m 

Thermocline intensity 
Surface oxygen 
concentration 

Temperature at 100 m 
Silicate at 100 m 
Chlorophyll fronts 

Chlorophyll concentration 
integrated at 50 m 
Oxygen concentration 
integrated at 50 m 
Oxygen concentration 
integrated at 125 m 
Sea level anomaly 

10 

0.0042 

10 

10 

0.0038 

0.0028 

9 

9 
9 
7 

0.0059 

Thermocline intensity 

0.0051          
0.0051          
0.0034           

9 

9 

9 

8 

7 

0.0069       

0.0055       

0.0046       

0.0056       

0.0019       

Table 4 
Mean  accuracies  and  their  standard  deviations  after  the  5  × 10-fold  cross- 
validation of each model.   

Random Forest 

SMO 

Multilayer 

Perceptron 
Naïve Bayes 

SKJ 

YFT 

BET 

FAL

Honarmand Ebrahimi, S., Ossewaarde, M., Need, A., 2021. Smart fishery: a systematic 
review and research agenda for sustainable fisheries in the age of AI. Sustainability 
13 (11), 6037. https://doi.org/10.3390/su13116037. 

Watson, R.A., 2018. Fuel use and greenhouse gas emissions of world fisheries. Nat. 
Clim. Chang. 8 (4), 333–337. 

Platt, J., 1998. Fast training of support vector machines using sequential minimal 

optimization. In: Schoelkopf, B., Burges, C., Smola, A. (Eds.), Advances in Kernel 
Methods - Support Vector Learning. 

R Core Team, 2021. R: A Language and Environment for Statistical Computing. R 

Foundation for Statistical Computing, Vienna, Austria. URL. https://www.R-project. 
org/.  

Reilly, S.B., Fiedler, P.C., 1994. Interannual variability of dolphin habitats in the eastern 
tropical Pacific. I: Research vessel surveys, 1986-1990. Fish. B.-NOAA 92 (2), 
434–450.

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

Machine-learning aiding sustainable Indian Ocean tuna purse seine fishery 

Nerea Goikoetxea a, *, Izaro Goienetxea b, Jose A. Fernandes-Salvador a, Nicolas Go˜ni c, 
Igor Granado b, I˜naki Quincoces a, Leire Ibaibarriaga a, Jon Ruiz a, Hilario Murua d, 
Ainhoa Caballero b 
a AZTI, Marine Research, Basque Research and Technology Alliance (BRTA), Txatxarramendi Ugartea z/g, 48395 Sukarrieta, Spain 
b AZTI, Marine Research, Basque Research and Technology Alliance (BRTA), Herrera kaia, Portualdea z/g, 20110 Pasaia, Spain 
c LUKE, Natural Resources Institute Finland, It¨ainen Pitk¨akatu 4A, FI-20520 Turku, Finland 
d International Sustainable Seafood Foundation, Pittsburgh, PA 15201, United States   

A R T I C L E  I N F O    

A B S T R A C T

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: Before training a deep learning model, several preprocessing steps can be taken to improve its performance. These may include data cleaning, where missing or inconsistent values are removed or corrected; normalization, which scales numeric variables to a common range such as [0, 1] or [-1, 1]; and feature engineering, where new features are created from existing ones to better capture patterns in the data. Additionally, it is often helpful to split the dataset into separate training, validation, and testing sets to evaluate the model's ability to generalize to unseen data. The specific preprocessing steps used will depend on the nature of the data and the requirements of the particular deep learning algorithm being employed.