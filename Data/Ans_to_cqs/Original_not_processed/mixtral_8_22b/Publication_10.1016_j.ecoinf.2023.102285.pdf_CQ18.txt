Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The rest of this document is structured as follows: The methodology 
is revealed in Section 2. The datasets on which the methodology is built 
and tested are explored in Section 3. A summary of the findings is pro-
vided in Section 4. Discussions are outlined in Section 5. Section 6 draws 
a conclusion as well as future potential works. Finally, the limitations of

Kuru, K., Girgin, S., Arda, K., Bozlar, U., 2013. A novel report generation approach for 
medical applications: the sisds methodology and its applications. Int. J. Med. Inform. 
82 (5), 435–447. http://dx.doi.org/10.1016/j.ijmedinf.2012.05.019. 

Kuru, K., Clough, S., Ansell, D., McCarthy, J., McGovern, S., 2023. Wildetect: an 

intelligent platform to perform airborne wildlife census automatically in the marine 
ecosystem using an ensemble of learning techniques and computer vision. Expert 
Syst. Appl. 231, 120574 http://dx.doi.org/10.1016/j.eswa.2023.120574. 

Leira, F.S., Johansen, T.A., Fossen, T.I., 2015. Automatic detection, classification and 

tracking of objects in the ocean surface from uavs using a thermal camera. In: 2015 
IEEE Aerospace Conference, pp. 1–10. http://dx.doi.org/10.1109/ 
AERO.2015.7119238.

EcologicalInformatics78(2023)1022858K. Kuru et al.                                                                                                                                                                                                                                    

Fig. 12. Stationary example 2: man-made object detection.  

overfitting, and finally iii) let field experts evaluate the model with a 
completely new dataset independent from the first and second datasets. 
The model can be deployed if it passes these three phases successfully. 
These phases are outlined in Fig. 3. The obtained results as well as their 
evaluation  are  provided  in  the  following  section.  The  experimental 
design of data utilisation and data processing phases with their targeted 
objectives are outlined in Table 3 regarding the APEM‘s database. The 
viability of the methodology was ensured in 4 phases.

Phase III. Evaluation using recent surveys (Fig. 3 III): A dataset 
was  prepared  to  evaluate  the  eligibility  of  the  methodology.  This  set 
consists of 57 images with ISMMMOs and 5000 images with no ISMM-
MOs. This set is not included in the dataset used for the establishment of 

the  methodology  to  observe  if  the  methodology  works  as  desired  for 
other independent datasets. The test results are displayed in Table 10 B. 
We moved to the next phase to verify the system with field experts using 
other  independent  datasets  after  the  satisfactory  results  (Se,  Sp,  PPV, 
NPV, and ACC > 0.95) obtained in this phase. 

Phase  IV.  Validation  by  field  experts  using  the  most  recent 
surveys (Fig. 3 IV): Furthermore, in an independent verification dataset,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the reliability and robustness of the proposed methodology, a four-phase evaluation process was established. Phase I involved initial testing using historical datasets, while Phase II focused on preventing overfitting through cross-validation. In Phase III, the methodology was evaluated using recent surveys, consisting of 57 images with ISMMMOs and 5000 images without them. This dataset was separate from those used in establishing the methodology to assess its effectiveness on other independent datasets. Satisfactory results (Se, Sp, PPV, NPV, and ACC > 0.95) were achieved in this phase. Lastly, Phase IV entailed validation by field experts using the most recent surveys. However, the specific strategy to monitor the model performance during training is not explicitly mentioned in the given context.