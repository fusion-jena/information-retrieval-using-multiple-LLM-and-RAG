Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics82(2024)1027346or mel-frequency cepstral coefficients (MFCC) can be represented as a
single-channel images. We evaluate a commonly applied pre-trained
ResNet-50 architecture (He et al., 2016). Dufourq et al. (Dufourq
et al., 2022) also demonstrates strong classification performance and
low data requirements of ResNet-50 when comparing alternative pre-
trained CNN-based models. With the rapid development of transformer-
based models we also evaluate two transformer models Audio Spectro-
gram Transformer (AST) (Gong et al., 2021) which, like ResNet, oper-
ates on the spectrogram. We also evaluate HuBERT (Hsu et al., 2021)
which operates directly on the 1-D waveform. We evaluate the models
using the same feature extractor fθ and user model Uϕ pipeline presented
in Fig. 1 using a two-class binary output. Hence Uϕ is a two layer {100,2}
fully connected network.

query set are negative. Liu et al. (Liu et al., 2019) propose transductive
propagation that iteratively propagates labels from labelled instances to
unlabelled instances according to the graph structure of the embeddings.
Other semi-supervised learning techniques have been applied such as
active learning. Wang et al. (Wang et al., 2022) combines a few-shot

samples (red line) compared to randomly ordered samples, no active
learning (blue line), and active learning using high-certainty samples
(yellow line). The baseline accuracy is calculated using a 2-shot, 2-way
test accuracy without fine-tuning (81.4%). The AST feature extraction
model is fine-tuned on a subset of 500 training samples. Model perfor-
mance is re-evaluated on the test set at 10 sample increments using each
of the three sample orderings. Low certainty refers to queries with a
similar Euclidean distance to prototypical embeddings and therefore lie
along decision boundaries. For high-certainty samples, the order is
reversed with query embedding in close proximity to prototypical em-
beddings being prioritised for model fine-tuning.

2.1. State of the art

Machine learning tasks designed for low-data contexts are referred to
as few-shot learning tasks. Within the context of bioacoustic applications,

EcologicalInformatics82(2024)1027342B. McEwen et al.

the field of computational bioacoustics (Stowell, 2021) has experienced
significant development over the last few years, in part due to public
challenges such as the Detection and Classification of Acoustic Scenes
and Events (DCASE) (Nolasco et al., 2023).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about specific datasets used in the deep learning pipeline. However, it mentions that the authors evaluated their models using a two-class binary output and a fully connected network with layers {100,2}. They also discuss applying transductive propagation and other semi-supervised learning techniques, but do not specify any particular dataset names. Therefore, I cannot provide a helpful answer regarding the datasets used in this study.