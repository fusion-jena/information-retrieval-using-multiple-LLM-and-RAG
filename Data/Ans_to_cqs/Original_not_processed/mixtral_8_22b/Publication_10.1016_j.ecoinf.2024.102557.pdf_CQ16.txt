Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

analytical  methods and  modeling tools  are needed to  deal with  these 
challenges (Tan et al., 2006). Over the past years, the field of artificial 
intelligence and machine learning has enabled significant advances in

Morera, A., et al., 2021. Performance of statistical and machine learning-based methods 
for predicting biogeographical patterns of fungal productivity in forest ecosystems. 
For. Ecosyst. 8 (1) https://doi.org/10.1186/s40663-021-00297-w. 

Morera, A., et al., 2022. Historical and future spatially-explicit climate change impacts 
on mycorrhizal and saprotrophic macrofungal productivity in Mediterranean pine 
forests. Agric. For. Meteorol. 319, 108918 https://doi.org/10.1016/j. 
agrformet.2022.108918. 

Moss, D., Wyatt, B.K., 1994. The CORINE biotopes project: a database for conservation of 
nature and wildlife in the European community. Appl. Geogr. 14 (4), 327–349. 
https://doi.org/10.1016/0143-6228(94)90026-4. 

Novak, M., Wootton, J.T., Doak, D.F., Emmerson, M., Estes, J.A., Tinker, M.T., 2011. 

Predicting community responses to perturbations in the face of imperfect knowledge 
and network complexity. Ecology 92 (4), 836–846. https://doi.org/10.1890/10- 
1354.1.

We evaluated trained models according to their predictive accuracy 
and ecological interpretation of their predictors. Environmental cross- 
validation with ten folds was performed to represent the new environ-
ment’s  predictive  error  accurately.  Using  Partial  Dependence  Plots 
(PDPs), we uncovered patterns between model predictors and species- 
specific productivity. The resulting PDPs were evaluated using existing 
scientific  knowledge  to  determine  whether  the  patterns  found  were 
ecologically consistent. 

2.3. Estimating biogeographic patterns of current fungal productivity

Model hyperparameters were tuned for each species-specific model 
using Bayesian optimization focused on reducing the root mean squared 
error (RMSE) of the predictions based on environmental cross-validation 
(Roberts et al., 2017) with ten folds, as implemented in the R package 
“mlr3mbo” (Kotlarski et al., 2014). The search space of optimal hyper-
parameters was defined by the ranges of “mtry”  (number of variables 
randomly sampled as candidates at each split), “min.node.size”  (mini-
mum size of terminal nodes), and “num.trees” (number of trees to grow) 
shown  in  Table  S3  (the  abbreviations  of  the  hyperparameters  used 
correspond to the terminology used in the R package “ranger”).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly state the specific criteria used to determine when training is complete. However, it mentions that model hyperparameters were tuned for each species-specific model using Bayesian optimization focused on reducing the root mean squared error (RMSE) of the predictions based on environmental cross-validation with ten folds. This suggests that the training process may have been considered complete once the RMSE reached a satisfactory level or stopped improving significantly. Additionally, the use of Bayesian optimization implies that the training process might have continued until the most promising set of hyperparameters was identified.