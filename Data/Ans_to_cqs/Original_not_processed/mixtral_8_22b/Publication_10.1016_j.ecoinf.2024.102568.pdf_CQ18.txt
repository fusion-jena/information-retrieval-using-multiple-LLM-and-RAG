Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 5 
Exp.1 results. 

of RMSE and MAE higher than 20 and in green the values lower than 8; 
while  the  values  of  MRE  are  in  green  if  lower  than  0.4  and  in  red  if 
higher than 1. In the end, we used green for accuracy higher than 0.9 
and red for values lower than 0.75. In addition, the number of obser-
vations in the training set is reported in the column “train size”, while 
the column “% out of range” shows the number of observations in the 
test set with the value of at least one of the two channels out of the range 
between the minimum and the maximum values of the training set. 

6.1. Exp.1

Table 7 
Results of Exp.3. 

the distribution of values in the training is more similar to the one of the 
test period. However, when LSTM is performing better than VR + SVR, 
the gain in performance is more significant. 

In  terms  of  bias,  the  results  are  good  for  both  NO  and  NO2.  The 
precision of sensors 4005, 4007, 4009, and 4012 is very low for both NO 
and NO2. Sensor 4006 shows a high precision error only for NO. The 
other sensors have very good performances, even reaching the regula-
tory  monitoring  required  performances.  This  is  an  important  result, 
considering that the mean value of the NO concentrations during the test 
period  (17.22  μg/m3)  was  beyond  the  noise  limit  of  the  cell  (18.75 
μg/m3). The mean concentration of NO is low because the test periods 
are during the co-location near the background station which is located 
in a green area far away from the most relevant source of pollution, such 
as road traffic.

7.1. Performance 

Comparing the results of VR + SVR and LSTM, we can observe that, 
even if in some cases VR + SVR is performing better than LSTM, the 
increase in performance is usually less significant. Instead, in most cases 
where LSTM shows better results it significantly increases accuracy and 
reduces RMSE, MAE and MRE. Nevertheless, in cases where the size of 
the training dataset is restricted, the performance of LSTM models may 
prove to be inadequate. In these cases, the VR + SVR can provide better 
performance than the LSTM. From our experiments, we observed that a 
training period with <4000 observations generates a model unable to 
achieve satisfactory performance levels.

The LSTM model is trained using the mean squared error (MSE) as 
loss function and the ADAM optimization (Kingma and Ba (2015)). To 
avoid overfitting, a dropout layer is added. The dropout layer, described 
¨
by 
Ozgür  and  Nar  (2020),  is  a  regularization  method  that  randomly 
excludes some inputs from activation and weight updates while training 
a network. Inputs not set to zero are scaled up by 1/(1 (cid:0) rate) such that 
the  sum  over  all  inputs  remains  the  same.  The  training  set  is  pre-
processed using a MinMaxScaler that transforms each feature by scaling 
it  to  a  [0–1]  range.  The  dimension  of  the  temporal  window  must  be 
selected  dynamically  considering  the  performance  obtained  with 
different values on the available dataset. 

In  the  specific  case  of  Modena,  an  Italian  city  spanning  183  km2, 

there are two legal AQ stations denoted by red dots in Fig. 6.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To monitor the model performance during training, several strategies were employed. Firstly, the loss function used for training the Long Short-Term Memory (LSTM) model was Mean Squared Error (MSE). By tracking the changes in MSE during training, it was possible to assess how well the model was learning to predict the target variable. Secondly, to prevent overfitting, a dropout layer was incorporated into the model architecture. Dropout is a regularization technique that randomly excludes certain inputs from activation and weight updates during training. This helps ensure that the model does not become too specialized to the training data and maintains its ability to generalize to new data. Lastly, the input features were transformed using a MinMaxScaler, which scales each feature to a range between 0 and 1. This standardizes the input data and makes it easier for the model to learn patterns within the data. Overall, these strategies helped maintain the balance between model complexity and performance, ensuring that the final model could accurately predict air quality measurements without being excessively complex or prone to overfitting.