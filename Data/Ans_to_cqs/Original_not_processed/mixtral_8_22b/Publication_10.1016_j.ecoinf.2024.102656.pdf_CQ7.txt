Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Soofi, M., Qashqaei, A.T., Trei, J.-N., Shokri, S., Selyari, J., Ghasemi, B., Sepahvand, P., 
Egli, L., Nezami, B., Zamani, N., Yusefi, G.H., Kiabi, B.H., Balkenhol, N., Royle, A., 
Pavey, C.R., Redpath, S.M., Waltert, M., 2022. A novel application of hierarchical 
modelling to decouple sampling artifacts from socio-ecological effects on poaching 
intensity. Biol. Conserv. 267, 109488 https://doi.org/10.1016/j. 
biocon.2022.109488. 

Su, X., Liu, S., Dong, S., Zhang, Y., Wu, X., Zhao, H., Zhao, Z., Sha, W., 2015. Effects of 
potential mining activities on migration corridors of Chiru (Pantholops hodgsonii) in 
the Altun National Nature Reserve, China. J. Nat. Conserv. 28, 119–126. https://doi. 
org/10.1016/j.jnc.2015.09.008. 

Teitelbaum, C.S., Mueller, T., 2019. Beyond migration: causes and consequences of 

nomadic animal movements. Trends Ecol. Evol. 34 (6), 569–581. https://doi.org/ 
10.1016/j.tree.2019.02.005.

available in Supplementary text S1). This methodology enhances pre-
dictive  accuracy  by  combining  forecasts  from  multiple  statistical 
models, mitigating the uncertainties and biases inherent in relying on a 
single modelling method (Araújo and New, 2007; Hysen et al., 2022). 
Five  statistical  models  were  used  in  this  ensemble  framework, 
including  generalized  linear  models  (GLM),  maximum  entropy  (Max-
Ent),  random  forest  (RF),  generalized  boosting  model  (GBM),  and 
multivariate  adaptive  regression  lines  (MARS).  To  facilitate  model 
training, we employed a 3:1 train-test split for the occurrence points. 
Additionally, following Barbet-Massin et al. (2012), we generated 1000 
random  pseudo-absence  points  (five  times  the  number  of  occurrence 
points per species) across the study area. These pseudo-absence points 
are crucial for model execution and provide a reference for areas that are 
unlikely to be inhabited by the target species.

Area of core 
habitats (km2) 

% of protected 
core habitats 

Length of roads 
intersecting core habitats 
(km) 

wild goat 
50 km 
70 km 
100 km 

Urial 
50 km 
70 km 
100 km 

310.15 
398.36 
443.25 

950.60 
1100.21 
1200.81 

Jebeer gazelle 
50 km 
70 km 
100 km 

930.56 
1050.30 
1232.81 

85.32 
81.20 
80.30 

83.30 
82.15 
78.20 

88.30 
86.32 
84.29 

4 
5.5 
6.5  

16 
19 
23  

18 
20 
23

Vogeler, J.C., Cohen, W.B., 2016. A review of the role of active remote sensing and data 
fusion for characterizing forest in wildlife habitat models. Rev. Teledetec. 45, 1–14. 
https://doi.org/10.4995/raet.2016.3981. 

Wan, H.Y., Cushman, S.A., Ganey, J.L., 2019. Improving habitat and connectivity model 
predictions with multi-scale resource selection functions from two geographic areas. 
Landsc. Ecol. 34 (3), 503–519. https://doi.org/10.1007/s10980-019-00788-w. 

Ward, J.V., Malard, F., Tockner, K., 2002. Landscape ecology: a framework for 
integrating pattern and process in river corridors. Landsc. Ecol. 17, 35–45. 

Westley, F., Miller, P.S. (Eds.), 2013. Experiments in Consilience: Integrating Social and 

Scientific Responses to Save Endangered Species. Island Press.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The context does not explicitly state the specific criteria used to split the data for deep learning model training. However, it mentions that a 3:1 train-test split was employed for the occurrence points. This means that the dataset was divided into four parts, three of which were used for training the model and one part was used for testing its performance. It is common practice in machine learning to use such a split ratio when there is enough data available. The validation set is often created by further splitting the training set or using techniques like cross-validation. In this case, no explicit mention of a separate validation set is made, but it can be assumed that some form of validation was performed during the modeling process.