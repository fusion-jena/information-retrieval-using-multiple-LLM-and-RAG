Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

hyperparameter  automatically.  However,  given  their  capability  to 
assemble 40 models in one simulation, we are leveraging this advantage 
to narrow down the selection of machine learning models. Subsequently, 
based on the suggestions of the Lazy Predict algorithm, ML models were 
further fine-tuned using hyperparameter tuning techniques. This process 
led to the development of robust ML models for each SWQP one after 
another. These ML models were optimized for each water quality mea-
sure. XGB, RF, and ET were chosen to build a stacking-based ANN meta 
ML  model  based  on  their  best  performance  and  the  entire  autoML 
model’s results.

maximum depth, minimum sample split, and learning rate (Bolick et al., 
2023). These refined hyperparameters are selected to enhance the ac-
curacy and predictive capabilities of the models, rendering them suit-
able for effective utilization in academic research and publications.

Table  2  lists  nine  grid  search  ML  models  with  fivefold  cross- 
validation for four WQPs and hyperparameters. Model evaluation and 
hyperparameter selection use cross-validation resampling. The dataset is 
split  into  five  equal-sized  folds  using  fivefold  cross-validation.  Five 
times, one of each fold, the training and assessment process is validated. 
A  more  complete  model  performance  analysis  is  possible.  Averaging 
coefficient of determination (R2) or RMSE across five iterations with five 
folds  improves  model  performance  and  hyperparameter  tuning  effi-
ciency estimation. The Python library’s randint command picks integers 
within a range for hyperparameters like n_estimators and max_depth. We 
use  the  uniform  command  for  discrete  or  continuous  values  inside  a 
range,  like  the  min_samples_split  hyperparameter.  These  commands 
examined  multiple  hyperparameter  value  ranges  to  establish  model

1)  Identifying  the  most  appropriate  model  for  each  specific  water 
quality parameter from numerous ML models is complex and iterative. 
2) Developing several models to predict each and individual water 

quality factor is time-consuming and iterative. 

To solve the first problem, the top models were selected based on 
their R2  score for a specified number of iterations using training data 
alone.  To  solve  the  second  problem,  the  Lazypredict  Python  library’s 
auto ML approach is used. The best 40 models for each parameter will 
result. After comprehensive simulations for each of the four parameters 
with autoML, five to six ML models were chosen based on performance. 
Based on these detailed simulations, XGB, RF, and ET were chosen to 
build a stacking ANN meta model. Additionally, the stacked ANN meta

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about which specific deep learning framework was used to build the model. It mentions the use of Python libraries such as Lazypredict and possibly Scikit-learn for hyperparameter tuning, but it does not specify whether TensorFlow, PyTorch, or any other deep learning framework was employed. Therefore, I cannot determine which framework was used to build the deep learning model based on the provided context.