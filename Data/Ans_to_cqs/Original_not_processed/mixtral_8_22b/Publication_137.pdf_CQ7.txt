Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Model training: We process data with a deep neural
network and adjust the training epoch, batch size, and
volume size to output a classiﬁer for prediction.
3. Result output: The point cloud test set is segmented,
and we can obtain the ﬁnal segmentation results. The
output ﬁles include point cloud geometric partition
graphs, SPGs, and segmentation results.

Results and Discussion

123

2170

Journal of the Indian Society of Remote Sensing (September 2021) 49(9):2163–2172

training, we set the learning decay rate to 0.7 so that the
learning rate gradually decays as the training progresses.
Table 1 shows the experimental results in which we ﬁxed
the voxel size and batch size and adjusted the regulariza-
tion strength, from which we can be told that result is better
while regularization strength is 0.2.

overall accuracy (OA) as metrics. We adjusted three
parameters (voxel size is the voxelization subsampling
size, the regularization strength inﬂuences the coarseness
of the minimal partition, and batch size means the batch
number of point cloud samples in training). We used the
hold-out method to distinguish the test set and the training
set at a ratio of 3:7 for preprocessing the original data. We
further adjust the parameters of networks to explore the

inﬂuence of parameters on experimental results, and we
discuss the selection of the frame parameters.

Selection of the Frame Parameters

We investigated the effects of several parameters in our
framework, such as the regularization strength, voxel size
for the minimal partition, and training batch size. In

123

Journal of the Indian Society of Remote Sensing (September 2021) 49(9):2163–2172

2169

Fig. 5 Part of segmentation experimental results. a Geometric features, b Geometric partition, c SPG, and d Segmentation result

123

Hu, X., & Yuan, Y. (2016). Deep-learning-based classiﬁcation for
DTM extraction from ALS point cloud. Remote Sensing, 8(9),
730.

Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating
deep network training by reducing internal covariate shift. Paper
presented in International Conference on Machine Learning,
Lille, pp. 448–456.

Landrieu, L., & Boussaha, M. (2019). Point cloud oversegmentation
with graph-structured deep metric learning. Paper presented at

123

2172

Journal of the Indian Society of Remote Sensing (September 2021) 49(9):2163–2172

the 2019 The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR).

Landrieu, L., & Obozinski, G. (2017). Cut pursuit: Fast algorithms to
learn piecewise constant functions. Siam Journal on Imaging
Sciences, 10(4), 1724–1766.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors used the hold-out method to divide the dataset into training and testing sets at a ratio of 3:7. This means that they allocated 70% of their data for training purposes and reserved the remaining 30% for testing. They did not explicitly mention using a separate validation set; however, it is common practice in machine learning to use a portion of the training data as a validation set during the training phase to tune hyperparameters and prevent overfitting.

Reference(s):
[1] Hu, X., & Yuan, Y. (2016). Deep-learning-based classiﬁcation for DTM extraction from ALS point cloud. Remote Sensing, 8(9), 730.
[2] Landrieu, L., & Boussaha, M. (2019). Point cloud oversegmentation with graph-structured deep metric learning. Paper presented at the 2019 The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).