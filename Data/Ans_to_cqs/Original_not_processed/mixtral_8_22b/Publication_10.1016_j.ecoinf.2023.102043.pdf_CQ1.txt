Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Farm 

A 
B 
C 
D 
Total 

# Annotated Events 

# Audio Files 

Duration (h) 

1046 
791 
961 
2171 
4969 

3,468,415 
2,939,211 
1,662,819 
1,920,752 
9,991,197 

~ 10,527.82 
~ 12,519.97 
~ 5036.06 
~ 6172.18 
~ 34,256.03  

Therefore, the recording campaign was planned to last an entire year so 
as  to  capture  the  variations  that  goat  vocalizations  demonstrate 
throughout  the  year.  Overall,  we  have  collected  approximately  10  M 
sound  events  lasting  more  than  34,000  h.  Fig.  7  illustrates  the  data 
distribution per farm in terms of number of audio files, annotations and 
durations.

model for extracting the embeddings. 

These are pulled from YAMNet and then fed as input to a sequential 
and  a  reduce  mean  layer  mapping  to  the  classes  mentioned  above 
(Ntalampiras et al., 2021). At this point, the final layers of the network 
map the YAMNet embeddings to the available labels as shown in Fig. 5. 

3.3. Results on goat vocalization detection 

The  dataset  presented  in  Section  3.2  was  divided  into  70%  for 
training, 10% for validation, and 20% for testing purposes. The division 
was  kept  the  same  when  experimenting  with  RF  and  YAMNet-based 

3  The 

librosa  python  package  available  at  https://librosa. 

org/doc/latest/index.html was employed at this stage 

Fig. 3. A close-up picture of a Sensortile.

3.2.2. Transfer learning based on YAMNet 

The second algorithm exploits the representation extracted from a 
deep neural network, i.e. YAMNet, which is pre-trained on data coming 
from 521 classes. Interestingly, YAMNet follows the MobileV1 convo-
lution architecture and is trained on the AudioSet-YouTube corpus (Shor 
et  al.,  2020).  Towards  using  YAMNet,  the  audio  data  is  processed  as 
follows:  

1.  The audio is converted to a monophonic channel and resampled at 

16 kHz.  

2.  The spectrogram is extracted and created using STFT magnitudes of 

25 ms overlapped by 15 ms.  

3.  The Mel spectrogram is calculated by mapping to 64 bins of the Mel 

scale within the range of 125â€“7500 Hz.  

4.  Finally, the algorithm is applied and its outcome is passed to YAMNet 

model for extracting the embeddings.

This would open new opportunities to develop up-to-date real-time 
automatic monitoring and management systems of goat farms based on 
vocalization analysis, which would increase the range of already avail-
able PLF tools. 

The project is divided into four partially overlapping phases:  

1.  collection  of  basic  data  through  a  one-year-long  data  harvesting 
campaign,  using  dedicated  devices  (cameras  and  microphones)  in 
the partner farms;  

2.  manual  labeling  of  the  most  relevant  events  by  a  team  of  animal 

scientists, so as to complete our ground truth;  

3.  training and testing the models upon the aforesaid dataset;  
4.  implementation and testing in real conditions of a prototype of the 

proposed system. 

1  https://vocapra.lim.di.unimi.it/index.php 

At the time of writing, phase 1 is complete, phases 2 and 3 are at a 

final stage, and phase 4 is starting. 

2. The goat farms

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, it appears that the method used for collecting raw data in the deep learning pipeline involves a one-year-long data harvesting campaign using dedicated devices such as cameras and microphones placed in partner farms. This is part of Phase 1 of the project, which has been completed. It can be assumed that these devices collect audio and visual data related to goats and their environment. However, there is no explicit mention of specific types or brands of sensors used for data collection. Additionally, there is no information about any use of surveys or public datasets for gathering data. Therefore, based on the provided context, the only known method for collecting raw data in the deep learning pipeline is through the use of dedicated devices like cameras and microphones installed in partner farms.