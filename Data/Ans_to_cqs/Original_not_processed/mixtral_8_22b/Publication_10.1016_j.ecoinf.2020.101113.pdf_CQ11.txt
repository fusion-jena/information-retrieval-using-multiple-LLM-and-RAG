Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The manual effort in training data creation was reduced to template 
creation and validation of template-based detections in a graphical user 
interface (Fig. 3). This addresses an important need for more accessible 
training  data  from  study  sites  to  leverage  deep  learning  for  acoustic 
monitoring.  Our  evaluation  demonstrates  that  strong  classification 
performance  can  be  achieved  using  data  collected  from  the  study  re-
gion,  without  relying  on  crowd-sourced  public  datasets.  The  pipeline 
thus  increases  the  potential  for  region-optimized  acoustic  monitoring 
systems.  Furthermore,  the  training  data  collection  pipeline  could  ac-
celerate the collection of data for rare species. 

Our  training  scheme  allowed  for  multi-label  learning  from  single- 
label  training  data  by  defining  a  custom  training  loss  and  including

2.3.  Model training 

2.3.1.  Training data preprocessing 

The  CNN  model  used  in  this  study  requires  equally  sized  input 
images. We chose a time-frequency input window size of 2 s as it is near 
the mean and median template duration across target call types (Fig. 2). 
Most  call  types  have  a  duration  below  1  s,  and  for  those  above  2  s,

To  expand  this  approach  to  the  broader  community,  we  have 
identified three important challenges for future research. First, future 
developments  should  account  for  the  large  variability  in  the  size  of 
target  calls  (i.e.  templates).  Introducing  recurrent  connections  in  the 
CNN, or other architecture modifications could potentially reduce the 
negative  effects  of  window  size.  Second,  previous  studies  have  found 
data  augmentation  to  significantly  improve  performance  (Kahl  et  al., 
2019).  In  these  cases,  training  data  was  mainly  based  on  monodirec-
tional  recordings  of  single  species,  and  data  augmentation  (i.e.  noise 
addition)  apparently  helped  to  emulate  the  conditions  of  soundscape 
recordings.  The  effect  may  be  reduced  for  training  data  collected  di-
rectly from soundscapes, as in this study. Still, data augmentation may

be  necessary  to  increase  the  training  data  size  for  rare  species.  Thus, 
future  efforts  should  investigate  optimal  data  augmentation  methods 
for  bioacoustic  recognition.  Third,  an  important  challenge  will  be  to 
maintain  high  accuracy  while  increasing  the  efficiency  of  prediction. 
This  will  require  increasing  the  prediction  speed  and  decreasing  the 
memory  footprint  of  the  model by  investigating  other  network archi-
tectures and reducing the number of parameters.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: Unfortunately, there isn't enough information in the given context to provide the exact data repository link of the deep learning pipeline. However, I can tell you that the authors mention their use of a custom training loss function and a Convolutional Neural Network (CNN) model with equal-sized input images. They also discuss the importance of addressing challenges such as handling variable sizes of target calls, optimizing data augmentation methods, and maintaining high accuracy while improving prediction efficiency.