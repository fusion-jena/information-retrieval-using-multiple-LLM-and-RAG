Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

sample with its corresponding remote sensing sequence of data. Finally, 70% of the data were used for training 
the algorithms whereas the remaining 30% were used only for validation.

125,161

84,491

71,623

49,829

33,408

29,859

28,754

11,437

10,104

4252

TOTAL

2,398,326

Table 2.   Number of pixels identified in the in situ visits. Of those, 70% were used for training and the 
remaining 30% for validation.

unit reads the input xt , and the previous hidden state ht−1 . Their combination is modulated by an hyperbolic 
tangent as:

˜ct = tanh(Wcxt + Ucht−1 + bc),
(1)
where Wc , Uc , and bc are the input weights, the recurrent weights, and the bias, respectively. The input gate 
determines which information is stored in the memory cell by means of a sigmoid function:

it = σ (Wixt + Uiht−1 + bi),

and similarly, the forget gate decides which content of the existing memory cell is forgotten:

ft = σ (Wf xt + Uf ht−1 + bf ).

(2)

(3)

The information is updated into the memory cell by adding the information coming from both the input and 
forget gates, i.e., adding new information from ct , and rules out part of the current memory information:

non-cloudy Sentinel-2 images for crop classification. It is worth mentioning that a procedure used for improv-
ing the performance of RNNs is the attention mechanism (AM). AM implements a coding-decoding model for 
identifying network key  features43,44. AM has been applied in different topics such as time travel  prediction45 or 
text  classification46. In remote sensing and image processing AM has been used for improving classification in 
very high-resolution  images47,48 as well as to capture the spatial and channel  dependencies49. In this context, this 
work aims at evaluating the interpretability of a DL algorithm based on a 2-layer bi-directional Long Short-Term 
Memory network (2-BiLSTM) for land use classification over the province of València (Spain) in the framework 
of CAP activities (Fig. 1 shows an scheme of the process). Sentinel-2 time series during the 2017/2018 agronomic

https://doi.org/10.1038/s41598-020-74215-5

9

Vol.:(0123456789)www.nature.com/scientificreports/Figure 8.   Architecture of the 2-BiLSMT network (left), and LSTM unit components (right). In our case, 14 
features along 30 time steps were used as predictor variables.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the specific requirements of the project. However, some common postprocessing steps include:

1. Model Evaluation: This involves calculating various metrics such as accuracy, precision, recall, F1 score, etc., to evaluate the performance of the trained model. These metrics help in understanding how well the model has learned to classify the given dataset.

2. Confusion Matrix: A confusion matrix is a table that summarizes the predictions made by the model against the actual values. It provides insights into the types of errors made by the model and helps in identifying any patterns or trends in the misclassifications.

3. Saliency Maps: Saliency maps are visualizations that highlight the regions of an input image that contribute most significantly to the output prediction. They provide insights into the decision-making process of the model and help in interpreting the results.

In the context of the given problem statement, it is not explicitly mentioned what postprocessing steps were taken after the model training. However, considering the nature of the task, it can be assumed that some form of evaluation metrics would have been calculated to assess the performance of the trained model. Additionally, saliency maps could also have been generated to understand the important features contributing to the final classification result.