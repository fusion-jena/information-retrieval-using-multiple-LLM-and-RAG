Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The fundamental concept behind the ResNet model is to use shortcut links to bypass
blocks of convolutional layers (bottleneck). The CONV layers each have a 3 × 3 ﬁlter
and are designed according to two rules: (1) the layers have the same number of ﬁlters
with the same output feature map size and (2) the number of ﬁlters is multiplied if the
feature map size is halved. The convolutional layers conduct the downsampling with
a stride of 2. The network ends with an average POOL layer and 1000 FC layers with
a SoftMax activation function. The default input size is 224 × 224 × 3 [24].
Xception: The Xception model’s architecture was proposed by Chollet (2017). This
model is a CNN-based architecture also trained on the ImageNet dataset. The Xception
architecture comprises 36 CONV layers with a 3 × 3 ﬁlter and stride of 2. These CONV
layers are structured into 14 modules, all of which have the ReLu activation function

VGG16: Simonyan and Zisserman (2014) proposed the architecture of the VGG16
model. VGG16 is a CNN model that consists of 16 hidden layers, including a total with
convolutional, max pooling and fully connected layers. VGG16 was trained on the
ImageNet dataset, which consists of 1,000,000 images. VGG16 is constructed of ﬁve
blocks of convolutional layers with a 3 × 3 ﬁlter and stride of 1. After each convolution,
an activation function (ReLU) is executed, followed by a max-pooling process with
a 2 × 2 max ﬁlter and stride of 2. At the end of the ﬁve blocks, three FC layers are
added: the ﬁrst two layers with 4096 neurons and an ReLU activation function each,
and the third layer with 1000 neurons and a SoftMax activation function [21]. The
default input size is 224 × 224 × 3 [22].
ResNet-50: The ResNet model’s architecture was proposed in 2015 by He et al. ResNet-
50 is a 50 convolutional neural network layers pre-trained on the ImageNet dataset [23].

Abstract: Satellite images have drawn increasing interest from a wide variety of users, including
business and government, ever since their increased usage in important ﬁelds ranging from weather,
forestry and agriculture to surface changes and biodiversity monitoring. Recent updates in the ﬁeld
have also introduced various deep learning (DL) architectures to satellite imagery as a means of
extracting useful information. However, this new approach comes with its own issues, including
the fact that many users utilize ready-made cloud services (both public and private) in order to
take advantage of built-in DL algorithms and thus avoid the complexity of developing their own
DL architectures. However, this presents new challenges to protecting data against unauthorized
access, mining and usage of sensitive information extracted from that data. Therefore, new privacy
concerns regarding sensitive data in satellite images have arisen. This research proposes an efﬁcient

Execution Time

All runtimes reported in this section were measured on the Google Colab repository
with a CPU running at 2.30GHz. Table 10 presents a detail of the runtime for each CNN
model. The training runtime for VGG16, Xception, and ResNet50 is 22.27, 21.26, and
30.8 min, respectively. Additionally, the prediction runtime for these models is 0.803,
0.827, and 1.835 s, respectively. The training runtime for DenceNet121 and the proposed
model is 18.34 and 16.43 min, and the prediction runtime is 4.134 and 0.976 s, respectively.
Accordingly, the computation overhead varies from one model to another. However,
PHE data are signiﬁcantly fast during both training and prediction and therefore the
computation overhead of the proposed encryption schema is low.

Remote Sens. 2021, 13, 2221

21 of 26

Figure 9. Training accuracy of different CNN models.

Table 10. CNN models’ run-time.

CNN Models

Training Run-Time

Prediction Run-Time

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there is no explicit mention or reference to any specific code repository link for the deep learning pipeline used in this study. It would be best to refer back to the original source or contact the authors directly for more detailed information about the code repository link.