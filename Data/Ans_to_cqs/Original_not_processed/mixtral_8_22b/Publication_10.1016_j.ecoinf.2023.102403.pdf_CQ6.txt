Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Data will be made available on request.  

EcologicalInformatics79(2024)1024038V. Pizarro et al.                                                                                                                                                                                                                                 

Appendix A. The database 

Table A.1 below shows the data loss for each criterion that we have used to clean our database. We downloaded 71,670,596 records from GBIF and 

OBIS. Only 820,004 records were useful for our analyses.  

Table A.1 
Criteria for filtering occurrence data from GBIF and OBIS using bioregions.  

Database state 

Number of records 

Origial records from GBIF and OBIS 
Data curation (following Zizka et al. (2020)) 
Taxonomically filtered data 
Deletion of data outside the native range 

71,670,596 
5,380,439 
5,007,322 
820,004

scales associated with data collection (Zizka et al., 2020). Due to these 
disparities,  scholars  recommend  a  thorough  examination  and  refine-
ment  of  these  data  repositories  (Bonnet-Lebrunm  et  al.,  2023).  To 
enhance the quality and reliability of the information, a comprehensive 
series  of  filters  has  been  systematically  applied  to  our  analysis.  To 
minimize errors associated with the public usage of GBIF and OBIS re-
positories,  we  curated  the  dataset  following  Zizka  et  al.  (2020)  and 
filtered the dataset by the columns labeled “scientific name”, “family”, 
“year”, “longitude” and “latitude”. We retained all taxonomic informa-
tion down to the species level and removed records with NA in these 
columns. We also removed all duplicate records with identical latitude

workflow. J. Open Source Softw. 1, 54. https://doi.org/10.21105/joss.00054. 
Guisande, C., Lobo, J., 2019. Discriminating well surveyed spatial units from exhaustive 
biodiversity databases. R package version. 2.0. URL: http://cran.r-project.org/web/ 
packages/KnowBR. 

Heberling, J.M., Miller, J.T., Noesgaard, D., Weingart, S.B., Schigel, D., 2021. Data 
integration enables global biodiversity synthesis. Proc. Natl. Acad. Sci. 118, 
e2018093118 https://doi.org/10.1073/pnas.2018093118. 

Hollowed, A.B., Barange, M., Beamish, R.J., Brander, K., Cochrane, K., Drinkwater, K., 
Foreman, M.G., Hare, J.A., Holt, J., Ito, S.I., et al., 2013. Projected impacts of climate 
change on marine fish and fisheries. ICES J. Mar. Sci. 70, 1023–1037. https://doi. 
org/10.1093/icesjms/fst081.

◦
and ∼10

9 

10 

1 
2 
3 
4 
5 
6 
7 
8 

Inner Baltic Sea 
Black Sea 
NE Atlantic 
Norwegian Sea 
Mediterranean 
Arctic Seas 
North Pacific 
North American 
Boreal 
Mid-Tropical N 
Pacific Ocean 
South-East 
Pacific 
The Caribbean 
and the Gulf of 
Mexico 
Gulf of California 
Indo-Pacific Seas 
and Indian Ocean 
Gulfs of Aqaba, 
Aden, Suez, Red 
Sea 
Tasman Sea 
15 
16 
Coral Sea 
17  Mid South 

12 
13 

11 

14 

Tropical Pacific 
Offshore and NW 
North Atlantic 
Offshore Indian 
Ocean 
Offshore W 
Pacific 
Offshore S 
Atlantic 
Offshore Mid-E 
Pacific 
Gulf of Guinea 
Argentina 
Chile 
Southern 
Australia 
Southern Africa 
New Zealand 
North West 
Pacific 
Southern Ocean 

18 

19 

20 

21 

22 

23 
24 
25 
26 

27 
28 
29 

30 

415 
537 
2053 
1132 
2859 
10,276 
12,974 
8001 

8902 
102 
87,377 
3046 
12,532 
2506 
78,070 
9709 

72 
37 
310 
93 
372 
114 
839 
162 

30 
22 
104 
35 
101 
23 
156 
48 

2.46 
3.21 
3.90 
2.16 
3.39 
3.90 
4.50 
2.99 

32,685 

9310 

615

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, several preprocessing steps can be taken to improve its performance. These include:

1. Normalization or standardization: This involves transforming the input features so they fall within a specific range, such as between 0 and 1 or having a mean of 0 and a standard deviation of 1. This helps prevent any single feature from dominating the others during training.

2. Scaling: Similar to normalization, this step scales the values of input features to ensure they are on a similar scale. For example, if one feature ranges from 0 to 100 while another ranges from 0 to 1, scaling would adjust the latter feature to match the former's scale.

3. Cleaning: This process removes noise and outliers from the dataset, which could negatively impact the model's performance. It may involve removing missing values, correcting inconsistencies, or eliminating irrelevant data points.

4. Feature engineering: This step involves creating new features based on existing ones to better capture patterns in the data. Examples include combining multiple features into one or extracting relevant components from complex features like images or text.

5. Encoding categorical variables: Deep learning models typically require numerical inputs, so categorical variables must be converted into numeric form. Techniques like one-hot encoding or label encoding can be employed for this purpose.

These preprocessing steps help prepare the data for optimal use in deep learning models, improving their accuracy and efficiency. However, it is essential to note that not all datasets require every step; some might only need minimal preprocessing, depending on their characteristics and the problem being addressed.