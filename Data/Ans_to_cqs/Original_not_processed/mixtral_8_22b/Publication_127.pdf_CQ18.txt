Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A well-known method for further improving classiﬁcation
accuracy is to use an ensemble of models at the same time
and average their predictions. After training all of the nine
models for each stage, we formed an ensemble of the trained
models by averaging their predictions (SI Appendix, Prediction
Averaging). More details about the architectures, training meth-
ods, preprocessing steps, and the hyperparameters are in SI
Appendix, Preprocessing and Training. To enable other groups
to replicate our ﬁndings and harness this technology for their
own projects, we are publishing the software required to run
our experiments as freely available, open-source code. We are
also publishing the ﬁnal DNNs trained on SS so that others
can use them as is or for transfer learning. Both the code and
the models can be accessed at https://github.com/Evolving-AI-
Lab/deep learning for camera trap images.

The training set contained 1.4 million images, and the test set
contained 105,000 images. Since the SS dataset contains labels
for only capture events (not individual images), we assigned the
label of each capture event to all of the images in that event. All
of the architectures achieved a classiﬁcation accuracy of >95.8%
on this task. The VGG model achieved the best accuracy of
96.8% (Table 2). To show the difﬁculty of the task and where the
models currently fail, several examples for the best model (VGG)
are shown in SI Appendix, Results on the Volunteer-Labeled Test
Set, and SI Appendix, Fig. S10 shows the best model’s confusion
matrix.

Table 2. Accuracy of different models on task I: Detecting
images that contain animals

Architecture

AlexNet
NiN
VGG
GoogLeNet
ResNet-18
ResNet-34
ResNet-50
ResNet-101
ResNet-152
Ensemble of models

Top-1 accuracy, %

95.8
96.0
96.8
96.3
96.3
96.2
96.3
96.1
96.1
96.6

The bold font indicates the top-performing architecture.

E5720 | www.pnas.org/cgi/doi/10.1073/pnas.1719367115

Norouzzadeh et al.

23. Sutskever I, Vinyals O, Le QV (2014) Sequence to sequence learning with neural
networks. 2014 Advances in Neural Information Processing Systems (NIPS) (Neural
Information Processing Systems Foundation, La Jolla, CA).

24. Cho K, et al. (2014) Learning phrase representations using RNN encoder-decoder for

statistical machine translation. arXiv:1406.1078.

25. He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition.
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (IEEE, New
York).

yellow-billed oxpeckers roosting on their large mammalian hosts. Afr J Ecol.

26. Simonyan K, Zisserman A (2014) Very deep convolutional networks for large-scale

13. Goodfellow I, Bengio Y, Courville A (2016) Deep Learning (MIT Press, Cambridge,

image recognition. arXiv:1409.1556.

MA).

27. Mnih V, et al. (2015) Human-level control through deep reinforcement learning.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information in the given context to determine the specific strategy used to monitor the model performance during training. However, it does mention that after training all nine models for each stage, they formed an ensemble of the trained models by averaging their predictions. This implies that some form of evaluation was conducted post-training to assess the performance of these models. Additionally, it states that all architectures achieved a classification accuracy of over 95.8%, with the VGG model achieving the highest accuracy of 96.8%. These results suggest that the performance of the models was monitored throughout the training process, but the exact methods used aren't explicitly mentioned.