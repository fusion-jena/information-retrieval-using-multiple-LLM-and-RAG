Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

LeCun,  Y.,  Bottou,  L.,  Bengio,  Y.  & 
Haffner,  P.  1998.  Gradient-based 
learning 
document 
recognition.  Proc.  IEEE  6  (11),  227-
2324. 

applied 

to 

Loffe,  S.  &  Szegedy,  C,  2015.  Batch 
Nomalization: 
deep 
network training by reducing internal 
covariate 
preprint: 
1502.03167. 

accelerating 

arXiv 

shift. 

Purohit  S.,  Viroja  R.  &  Gandhi  S.  2016. 
Automatic  plant  species  recognition 
learning 
technique  using  machine 
approaches. 
International 
IEEE 
Conference on Computing & Network 
Communications. 

Sermanet,  P.,  Eigen,  D.,  Zhang,  X., 
Mathieu, M., Fergus, R. & LeCun, Y., 
Intergrated 
2014. 
recognition, 
and 
Detection 
convolution 
using 
networks. In: International conference 
on learning Representations. 

Localization 

Overfeat: 

Simonyan, K. & Zisserman, A., 2014. Very 
for 
deep  convolutional  networks 

103

propagation  of  the  tensors  along  the  skip 
connections.  The  proposed  network  learnt 
around 100K parameters to  detect  the type 
of leaf image and if it belongs to  a  certain 
class,  which  is  comparatively  less  than  the 
existing  deep  learning  approaches  reported 
in  the  literature.  Because  of  this  least 
number  of  parameters,  we  performed  data 
augmentation to allow for in deep features to 
be  extracted  and 
to 
accurately  identify  the  classes.  We  also 
performed  benchmark  experiment  with  the 
three  state-of-the-art  approaches  of  plant 
species  recognition.  The  empirical  results 
indicate that the proposed CNN-LSTM was 
able to  classify the particular class  of each 
image  with  an  accuracy  of  95%  far  better 
than all the three combatants. This indicates 
that the proposed system could be expanded 
to  support  an  integrated  plant  species 
identification  system  to  operate  in  real 
ecosystem services.

appear  in  controlled  backlit  and  front-lit 
versions,  with  several  samples  per  species. 
They vary considerably in sharpness, noise, 
illumination patterns, and shadows. Since the 
dataset is not large enough for deep learning 
to overcome the problem of overfitting, data 
augmentation was used to enlarge the dataset 
training  and  overcoming 
for  network 
overfitting. The dataset used in this work can 
be  downloaded  at  UCI  Machine  Learning 
Repository:  One-hundred  plant  species 
leaves  data  set  Data  Set  database.  Figure  5 
shows sample of image data of 24 species in 
grey  scale  from  UCI  Machine  learning 
repository. 

Figure 4: Feature extraction from a plant leaf. 

Figure 5: A sample plant species image from UCI repository. 

97 

 
Tanzania Journal of Forestry and Nature Conservation, Vol 90, No. 3 (2021) Special Issue: 
Embracing Science and Technology in Nature Conservation. pp 93-103 

Identification of leaf pattern 

indicate

93 

Keywords: Biodiversity - Computer vision - 
Convolutional  neural  networks  -  Plant 
species - Deep learning. 

INTRODUCTION 

science,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data repository link of the deep learning pipeline is not explicitly mentioned in the given context. However, there is a reference to the UCI Machine Learning Repository where the dataset used in this work can be downloaded. Unfortunately, no specific link or identifier is provided for the dataset within the UCI Machine Learning Repository. To find the exact dataset, one would need to search for the "One-hundred plant species leaves data set" within the UCI Machine Learning Repository.