Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.5. Model selection 

CNNs are sensitive to overfitting (Domingos, 2012). Throughout the 
training process, the algorithm goes through cycles of training on the 
training set - evaluating performance on the validation set – adjusting 
CNN node weights – before repeating the entire cycle. These cycles are 
referred to as epochs or iterations when the training dataset is too large 
to  be  processed  in  one  stroke  and  needs  to  be  subdivided  in  several 
smaller batches as is the case in this study. There is an optimum number 
of iterations before the performance on the validation and training sets 
(independent data that the CNN has not seen) start to diverge as the CNN 
overfits  and  becomes  more  specialized  at  predicting  the  training  set 
while becoming less able to predict the validation set (generalization).

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ‘Imagenet classification with deep 
convolutional neural networks’, in. Adv. Neural Inf. Proces. Syst. 1097–1105. 
Langenk¨amper, D., et al., 2017. BIIGLE 2.0 - browsing and annotating large marine 

image collections. Front. Mar. Sci. 4 (83) https://doi.org/10.3389/ 
fmars.2017.00083. 

LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. nature 521 (7553), 436. 
Levin, L.A., 1991. Interaction between metazoans and large, agglutinating protozoans: 
implications for the community structure of deep-sea benthos. Am. Zool. 31, 
886–900. 

Levin, L.A., Gooday, A.J., 1992. Possible roles for Xenophyophores in deep-sea carbon 
cycling. In: Rowe, G.T., Pariente, V. (Eds.), Deep-Sea Food Chains and the Global 
Carbon Cycle. Kluwer, Netherlands, pp. 93–104. 

Levin, L.A., et al., 2019. Global observing needs in the Deep Ocean. Front. Mar. Sci. 6 

(241) https://doi.org/10.3389/fmars.2019.00241.

2.4. Model evaluation 

The testing dataset was composed of 500 manually annotated images 
from  the  same  transect  and  was  only  used  to  calculate  performances 
outside  the  Darknet  framework  by  comparing  CNN  predictions  with 
manual annotations. 

Predictions  come  as  a  .JSON  file  containing  the  coordinate  of  the 
bounding box of each tentative annotation as well as a confidence score 
ranging from 0.05 at minimum (lower confidence scores introduced too 
much  noise  and  therefore  were  not  recorded)  to  1  at  maximum.  Pre-
dictions made on the testing set were compared to the manual annota-
tion of the same images.

Some model parameters were modified from the default configura-
tion to balance use of resources and training speed. We retained a res-
olution of 704 × 704, batch size 64, 32 subdivisions and trained up to 
6000 iterations. Other parameters were kept to default or set according 
to guidance by the developers (https://github.com/AlexeyAB/darknet). 
Manual annotations were used to generate training, validation and 
testing  datasets.  Biigle  annotations  (label  name,  centre  x,  center  y, 

EcologicalInformatics71(2022)1017863N. Piechaud and K.L. Howell

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no information available regarding the specific data augmentation techniques applied in the deep learning pipeline mentioned in the given context. The text does mention that Convolutional Neural Networks (CNNs) are prone to overfitting, which can be mitigated using various data augmentation techniques such as flipping, rotating, scaling, cropping, etc. However, it does not provide any details about the exact methods employed in this particular study. Therefore, based on the given context, we cannot determine what data augmentation techniques have been applied in the deep learning pipeline.