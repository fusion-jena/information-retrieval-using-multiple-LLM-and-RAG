Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

imaging procedure. An algorithm for domain adaptation, domain adversarial training of neural

networks (DANN), significantly improved the prediction performance of models trained by

non-standardized, low-quality images. Our findings demonstrate that existing databases can

be used to train models and successfully classify images from unexplored biota, but the imag-

ing conditions and classification algorithms need careful consideration.

K E Y W O R D S
biodiversity assessment, bulk sample, coleoptera, convolutional neural network, domain adaptation,
image classification, machine learning

I N T R O D U C T I O N

Biological

identifications

increasingly rely on machine learning

algorithms that use photographic images to place unidentified speci-

Tomochika Fujisawa and Víctor Noguerales contributed equally to this study.

mens into a taxonomic classification. As these methods are proving to

LeCun, Y., Bengio, Y. & Hinton, G. (2015) Deep learning. Nature, 521(7553),
436–444. Available from: https://doi.org/10.1038/nature14539
Mukhoti, J., Kulharia, V., Sanyal, A., Golodetz, S., Torr, P.H.S. & Dokania, P.
K. (2020) Calibrating deep neural networks using focal loss. Advances
in Neural Information Processing Systems, 33, 15288–15299. Available
from:
https://proceedings.neurips.cc/paper/2020/hash/aeb7b30ef
1d024a76f21a1d40e30c302-Abstract.html

Noguerales, V., Meramveliotakis, E., Castro-Insua, A., Andújar, C.,
Arribas, P., Creedy, T.J. et al.
(2021) Community metabarcoding
reveals the relative role of environmental filtering and spatial pro-
cesses in metacommunity dynamics of soil microarthropods across a
mosaic of montane forests. Molecular Ecology in press. Available
from: https://doi.org/10.1111/mec.16275

Local low quality (LL) dataset

of 0.6. The neural network was trained with the stochastic gradient

descent algorithm with the softmax cross-entropy loss for 300 epochs.

We used a batch size of 10 and a fixed learning rate of 0.01, and the

convergence of loss was visually assessed. The numbers of units in the

A subset of single specimens (taken from the bulk samples) were indi-

two FC layers (512 and 256 for the first and second FC layers, respec-

vidually photographed using a conventional stereoscope NIKON

tively) and the dropout rate were determined by five-fold cross-

SMZ1270i equipped with a NIKON DS-Fi3 Microscope Camera (5.9

megapixels) controlled by the NIKON DS-L4 v.1.5.0.3 control unit.

These images were denoted Local Low Quality (LL) dataset. These pho-
tographs were intended to represent a more realistic scenario of local

401

diversity estimation using deep learning for computer vision.
Methods in Ecology and Evolution, 13(2), 346–357. Available from:
https://doi.org/10.1111/2041-210X.13769

Schwartz, S.T. & Alfaro, M.E. (2021) Sashimi: a toolkit for facilitating high-
throughput organismal
image segmentation using deep learning.
Methods in Ecology and Evolution, 12(12), 2341–2354. Available from:
https://doi.org/10.1111/2041-210X.13712

Stork, N.E. & Grimbacher, P.S.

(2006) Beetle assemblages from an
Australian tropical rainforest show that the canopy and the ground
data contribute equally to biodiversity. Proceedings of the Royal Soci-
ety B, 273(1596), 1969–1975. Available from: https://doi.org/10.
1098/rspb.2006.3521

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention or reference to the location of the code repository for the deep learning pipeline used in this study. It would be best to contact the authors directly or check their personal websites or other publications for any potential links to the relevant code repositories.