Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.2. Faster R-CNN approach

The Faster R-CNN presents recent advancement of both Fast
R-CNN and R-CNN by Ren et al. [16]. It merges a Region
Proposal Network (RPN) as object bounds predictor and Fast
R-CNN for target detection in processed images. The role of
RPN module is to serve as the ‘‘attention” mechanism of this
uniﬁed Faster R-CNN, as depicted in Fig. 2. Three basic com-
ponents of the Faster R-CNN can be described as follow.
First, the feature extractor network to generate feature maps

[34]. Second,

[34]. Second,

from the input image (see Fig. 2). It can be a pre-trained
CNN architecture such as Inception [32], Residual Neural Net-
work (Resnet) [33], and Dense Convolutional Network (Den-
senet)
the RPN module proposes object
locations of the feature maps. Third, a regressor and classiﬁer
are trained using the loss function L in (1) for the CNN detec-
tion network to adjust these proposed locations and to predict
single or multi-object classes with the corresponding bounding
box area in the resulted image, as shown in Fig. 2.

Lð pif g;

tif gÞ ¼

1
Ncls

X

i

Lclsðpi

i Þ þ k 1
; p(cid:3)
Nreg

X

i

i Lregðti; t(cid:3)
p(cid:3)

i Þ: ð1Þ

IoU ¼

A \ B
A [ B

ð2Þ

Next, the Region of Interest (RoI) pooling layer takes the
region corresponding to a proposal from the backbone feature
map and dividing it into sub-windows. The maximum pooling
is performed over these sub-windows to give the output of RoI
pooling layer, which has a size of (N, 7, 7, 512), and N is the
number of generated region proposals by the RPN mechanism,
as shown in Fig. 2. After passing through two fully connected
layers (FCs), the features are fed into the classiﬁer and regres-
sor branches as follow. The classiﬁcation layer calculates the
probability of the region proposal contains an object such that
the probability Pi of each element in the feature map i contains
the target object using softmax function. The regions with the
top score of 300 Pi in the total rankings present the detected
target object. In addition, the regressor provides the IoU index

A new mobile application of agricultural pests recognition

4427

Fig. 3

performance utilization of
the RPN module with the
bounding box regression, as depicted in Fig. 2. Moreover,
the computational time of this deep learning approach is not
a problem in this study, because the detection and classiﬁca-
tion procedures of agricultural insect pests can be executed
in a few seconds in the cloud computing system, saving all
required hardware resources.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The purpose of the deep learning model used in this case is object detection and classification. This is evident from the use of the Faster R-CNN approach, which is a type of convolutional neural network designed specifically for object detection tasks. The Faster R-CNN model uses a Region Proposal Network (RPN) to propose potential object locations within the input image, and then applies a classifier and regressor to refine these location predictions and assign class labels to them. The goal of this process is to accurately detect and identify specific objects - in this case, agricultural insect pests - within the input images.