Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

higher  MS is needed to better capture the index response to wildfire. 
Compared to the default parameters, the overall accuracy and kappa of 
optimized  parameters  can  improve  by  up  to  8.4%  and  36.8%, 
respectively.

parameters (Figs. A2–A4 and Fig. 4). Among these, the kappa coefficient 
is  selected  to  comprehensively  evaluate  the  detection  accuracy  for 
different  indices  and  parameter  sets.  Although  overall  accuracy  can 
quantify  the  absolute  accuracy  of  detection,  it  is  not  well-suited  for 
evaluating  the  performance  of  various  indices  for  LTR,  which  uses  a 
binary classification system of ‘burned’ and ‘unburned’ values. As can be 
seen from Figs. A2 and A3, the user's accuracy is always higher than the 
producer's  accuracy  for  any  study  area  and  indices  with  the  same 
parameter setting. That means LTR tends to have a larger omission error 
than commission error. In other words, unburned pixels are less likely to 
be mistakenly identified as burned. In most cases, although the LTR does 
not  effectively  identify  the  burned  pixels,  the  overall  accuracy  still 
maintains at a high level because the unburned pixels can be accurately

Model Proportion for best fitting. Runge et al. (2022) optimized the LTR

EcologicalInformatics78(2023)10230412W. Liu et al.                                                                                                                                                                                                                                      

XGBoost  offer  a  quantitative  measure  of  the  influence  of  each  input 
feature on the model's predictive accuracy. Specifically, Random Forest 
determines  feature  importance  by  assessing  the  reduction  in  the  Gini 
impurity each time the feature is used for splitting across all trees in the 
ensemble.  XGBoost  computes  feature  importance  based  on  the  gain, 
which indicates the improvement in accuracy brought by a feature to the 
branches which it is on.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model is evaluated using several metrics such as overall accuracy, kappa coefficient, user's accuracy, producer's accuracy, and feature importance. The overall accuracy measures the absolute accuracy of detection, while the kappa coefficient provides a comprehensive evaluation of the detection accuracy for different indices and parameter sets. User's accuracy refers to the proportion of correctly classified positive instances out of all predicted positives, whereas producer's accuracy represents the proportion of correctly classified positive instances out of all actual positives. Feature importance is determined by assessing the reduction in the Gini impurity or the improvement in accuracy brought by a feature to the branches it is on. In this case, the kappa coefficient was chosen to evaluate the detection accuracy due to its suitability for binary classification systems like 'burned' and 'unburned' values. Additionally, the use of Random Forest and XGBoost algorithms allowed for the computation of feature importance based on the reduction in the Gini impurity and the gain, respectively.