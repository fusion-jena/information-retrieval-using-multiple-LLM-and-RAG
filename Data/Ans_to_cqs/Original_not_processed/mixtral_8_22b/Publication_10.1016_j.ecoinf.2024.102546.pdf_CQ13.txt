Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

different modules of I3Net.  Unlike training the YOLO models without 
domain adaptation, a different learning rate scheme was implemented to 
train the I3Net modules. Considering the embedded noise in unpaired 
target  domain  images  may  adversely  affect  early-stage  training,  the 
initial  learning  rate  was  set  to  0.001  for  training  the  I3Net  modules, 
which  aimed  to  ensure  the  effective  learning  of  source-domain  infor-
mation, being less disturbed by the target domain images, and thereafter 
the learning rate was reinitialized to 0.01 to enhance feature adaptation 
to  the  target  domain.  Other  hyperparameter  settings  remained  as 
described in Table 2. 

4. Results 

4.1. In-season and cross-season weed detection

6  https://github.com/ultralytics/ultralytics/issues/189 

EcologicalInformatics81(2024)1025466B. Deng et al.                                                                                                                                                                                                                                    

Fig. 3. Flowchart of our cross-season weed detection.  

Table 2 
Primary hyperparameter settings of the three detection models.  

Hyperparameters 

Detection models 

Initial learning 

rate 

Learning rate 
schedule 
NMS threshold 
Confidence 
threshold 
Weight decay 
Image size 
Batch size 

Optimizer 

YOLOX 

YOLOv8 

0.01 

0.01 

Warm up +
cosine decay 
0.45 

Warm up + cosine 
decay 
0.7 

0.25 

0.0005 
800 
8 

SGD 

0.25 

0.0005 
800 
8 

SGD 

Classification loss 

BCE 

Location loss 

IoU 

Data augmentation 

Color jitter 
+ mosaic 

VFL (Zhang et al., 
2021) 
DFL (Li et al., 2020) 
+ CIoU (Zheng et al., 
2021)

Abbeel, Pieter, 2017. Domain randomization for transferring deep neural networks 
from simulation to the real world. In: Paper Presented at the 2017 IEEE/RSJ 
International Conference on Intelligent Robots and Systems (IROS). 

Wang, Pei, Tang, Yin, Luo, Fan, Wang, Lihong, Li, Chengsong, Niu, Qi, Li, Hui, 2022. 
Weed25: a deep learning dataset for weed identification. Front. Plant Sci. 13, 
1053329. 

Wang, Su, Saharia, Chitwan, Montgomery, Ceslee, Pont-Tuset, Jordi, Noy, Shai, 

Pellegrini, Stefano, Onoe, Yasumasa, Laszlo, Sarah, Fleet, David J., Soricut, Radu, 
2023. Imagen editor and editbench: Advancing and evaluating text-guided image 
inpainting. In: Paper presented at the Proceedings of the IEEE/CVF Conference on 
Computer Vision and Pattern Recognition. 

Weyler, Jan, L¨abe, Thomas, Magistri, Federico, Behley, Jens, Stachniss, Cyrill, 2023. 
Towards domain generalization in crop and weed segmentation for precision 
farming robots. IEEE Robot. Automat. Lett. 8 (6), 3310–3317.

which  contained  385  hyperspectral  images  with  237  bands  in  the 
wavelength range of 420–979 nm, stored as NumPy arrays. There are 
pixel-wise annotations for each instance of plants.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The primary hyperparameters used in the deep learning models include initial learning rate, learning rate schedule, Non-Maximum Suppression (NMS) threshold, confidence threshold, weight decay, image size, batch size, classification loss, location loss, data augmentation techniques, and optimizers. For both YOLOX and YOLOv8 models, the initial learning rate is set to 0.01, while the learning rate schedule uses warm-up and cosine decay. The NMS threshold is 0.45 for YOLOX and 0.7 for YOLOv8, with a confidence threshold of 0.25 for both models. Weight decay is set to 0.0005, and the image size is 800 pixels. Both models use Stochastic Gradient Descent (SGD) as their optimizer. Classification loss is calculated using Binary Cross Entropy (BCE), and location loss is determined using Intersection over Union (IoU). Data augmentation techniques employed include color jitter and mosaic for YOLOX, and VFL, DFL, and CIoU for YOLOv8.