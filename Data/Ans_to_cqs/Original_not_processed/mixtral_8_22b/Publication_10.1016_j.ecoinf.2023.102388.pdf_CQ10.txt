Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The architecture of VGG16, as depicted in Fig. 5, consists of five sets 
of  convolutional  layers  alternating  with  five  max-pooling  layers,  fol-
lowed by two fully connected layers and an output layer. The initial two 
blocks comprise two convolutional layers each, employing respectively 
64  and  128  filters.  The  subsequent  two  blocks  encompass  three  con-
volutional  layers  with  respectively  256,  512  and  512  filters.  All  con-
volutional filters have a size of 3 × 3 and the max-pooling layers utilize a 
2 × 2 pool size with a stride of 2. During the SNN training process, we 
fine-tuned VGG16 by unfreezing the last two blocks (block 4 and block 
5), ensuring that their weights are updated in each epoch. Finally, ad-
justments were made to the final dense layer in each CNN to account for 
the specific number of classes representing beluga individuals in each 
dataset.  Fine-tuning  of  these  deep  models  was  conducted  using  Sto-

6.4. Biodiversity challenges 

In a recent article, Villon and collaborators (Villon et al., 2022) have 
delved  into  challenges that extend  beyond dataset limitations,  with a 
particular focus on biodiversity and its impact on deep learning-based 
automated  monitoring  of  marine  mammals  and  fish  habitats  through 
computer  vision.  More  specifically,  they  explored  the  implications  of 
three  fundamental  rules  of  biodiversity,  namely  the  distribution  of 
species  abundance,  species  rarity  and  ecosystem  openness.  They  also 
proposed promising solutions to these problems,  some of which  were 
previously briefly discussed in Section 2.

Nepovinnykh, Eerola and Kalviainen (Nepovinnykh et al., 2020) have 
employed SNNs for ringed seal re-identification, developing a complete 
framework  that  includes  CNN-based  animal  segmentation,  patch  cor-
respondence detection as well as the ranking of images in the database 
based on similarity to the query image. The dataset for evaluating the re- 
identification  framework  had  2000  images  of  46  distinct  seals  in-
dividuals,  each  manually  identified  by  a  biologist.  It  was  split  into  a 
gallery set (composed of 500 images, around 10 images per individual) 
and  a  query  set  (1500  images  from  28  unknown  individuals  and  18 
known  individuals,  varying  from  5  to  120  images  per  individual),for 
which the approach achieved a top-1 score of 67.8% and a top-5 score of 
88.6% in re-identification.

4.3. Target and attack models 

We adopted two popular neural network architectures as our target 
model:  ResNet50  (He  et  al.,  2016b)  and  DenseNet121  (Huang  et  al., 
2017).  

• ResNet50. The ResNet50 architecture contains 50 layers and uses a 
stack of three layers with 1 × 1, 3 × 3 and 1 × 1 convolutions as the 

Fig.  7. Distribution  of  the  dataset  for  the  experimental  setting.  The  main 
dataset is split in 1
3 of individuals (e.g., 60 individuals in each subset: target set, 
attack set and evaluation set for GREMM dataset). The arrows indicate that the 
same individuals and pictures were re-used from one dataset to another.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention or reference to any code repository links related to the deep learning pipelines used in the research papers mentioned. Therefore, I cannot provide the requested information.