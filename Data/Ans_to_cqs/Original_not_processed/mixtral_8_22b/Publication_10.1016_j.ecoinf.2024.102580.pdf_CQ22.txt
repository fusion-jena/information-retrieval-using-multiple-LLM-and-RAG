Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.1. Success of deep learning models 

The  semantic  segmentation  model  used  to  identify  the  substrate 
types  achieved  an  accuracy  of  92%.  The  precision  for  the  vegetation 
class was 0.90, for the bare class was 0.96, and for the ‘other’ class was 
0.50 when evaluating the model against the test dataset. The recall of 
the model (the number of instances in which the model correctly iden-
tified the pixels out of the total number of pixels in that class) reached 
0.97 for vegetation, 0.87 for bare substrate and the ‘other’ class reached 
a recall of 0.53.

EcologicalInformatics81(2024)1025802R.K. James et al.                                                                                                                                                                                                                                

Fig. 1. Workflow used to (a) select a deep learning model, (b) develop a ground-truth imagery dataset, (c) train the deep learning models, (d & e) evaluate model 
performance and (f & g) obtain the data and analyse it to quantify the spatial patterns and resilience of the ecosystem. 

2.3. Deep learning models 

2.3.1. Semantic segmentation for vegetation mapping

Data availability 

The deep learning and post-processing scripts along with the 2012 
aerial  imagery  and  data  output  used  in  this  study  can  be  found  at 
https://git.wur. 
nl/deep-learning-tools-for-marine-ecosystem-monitoring. 

Acknowledgments

training, which helped to reduce human error. Similar to the seagrass 
semantic  segmentation  model,  the  resolution  of  the  images  in  the 
ground-truth dataset was reduced to 1000 × 1333, and the three colour 
channels of the images were normalised by subtracting the means and 
dividing  by  the  standard  deviations  per  channel.  The  colour  channel 
means and standard deviations were based on the ImageNet dataset used 
in the training of the (pre-trained) RestNet-50 (the used mean values 
were [0.485, 0.456, 0.406], and the standard deviations were [0.229, 
0.224, 0.225]). The DETR model’s object queries parameter was set to 
100, allowing for the detection of up to 100 turtles in an image, which 
was sufficient for all case-study images.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To evaluate the performance of the deep learning model, several metrics were employed. These include accuracy, precision, and recall. Specifically, the semantic segmentation model used to identify substrate types achieved an accuracy of 92%. Precision was also calculated for each class; the precision for the vegetation class was 0.90, for the bare class was 0.96, and for the 'other' class was 0.50. Recall, or the proportion of true positive predictions out of the actual positives, was also measured. The recall of the model reached 0.97 for vegetation, 0.87 for bare substrate, and the 'other' class reached a recall of 0.53.