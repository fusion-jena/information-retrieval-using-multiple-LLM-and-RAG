Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics78(2023)1023346H. Gong et al.                                                                                                                                                                                                                                    

Table 1 
Machine configuration information table.  

Projects 

Content 

Central Processing Unit 
Memory 
Video card 
Operating System 
CUDA 
Data Processing 

Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz 
32G 
NVIDIA GeForce GTX TITAN Xp 
Ubuntu 5.4.0-6ubuntu1 ~ 16.04.5 
Cuda8.0 with cudnn 
python2.7, OpenCV, TensorFlow  

12. Experimental parameter settings

Under the condition of unchanged training methods and parameters, 
the results of each model listed in Table 3 were obtained. As compared to 
the  accuracy of  the  model in  this  work, the  VGG  model's recognition 
accuracy  was  too  low.  Although  the  traditional  DenseNet  has  fewer 
parameters  and  a  greater  identification  accuracy  than  ResNet,  its 
recognition rate is lower than that of the model in this work. Due to its 
sliding window design, the Swin Transformer is somewhat more accu-
rate than the other models. Nevertheless, the number of parameters and 
model size are excessive, consuming too many memory resources. On 
top  of  that,  the  proposed  model  exhibited  the  greatest  identification 
accuracy  but  needs  some  improvement,  in  terms  of  the  number  of 
parameters.

learning. In: Proceedings of the IEEE Interna-tional Conference on Innovations in 
Intelligent Systems and Applications Conference (ASYU). 31 October–2 November. 
Chen, R., Little, R., Mihaylova, L., Delahay, R., Cox, R., 2019. Wildlife surveillance using 

deep learning methods. Ecol. Evol. 9 (17), 9453–9466. 

Corkery, G.P., Gonzales-Barron, U.A., Butler, F., Mc Donnell, K., Ward, S., 2007. 

A preliminary investigation on face recognition as a biometric identifier of sheep. 
Trans. ASABE 50, 313–320. 

Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., 

et al., 2021. An image is worth 16x16 words: transformers for image recognition at 
scale. In: International Conference on Learning Representations. 2,3,7. 

García, R., Aguilar, J., Toro, M., Pinto, A., Rodríguez, P., 2020. A systematic literature 
review on the use of machine learning in precision livestock farming. Comput. 
Electron. Agric. 179, 105826.

Model 

DenseNet 
Block 

ResNet 
Block 

Accuracy 
(%) 

Parameter size 
(MB) 

Flops 

14. Results and discussion 

Module1 and 
bulk of ViT 

The entire 
model 

√ 
×
√ 

×
√ 
×

92.58 
88.31 
97.68 

61.96 
80.81 
108.26 

1.57G 
2.51G 
2.60G  

The aim of this work was to investigate the use of computer vision 
techniques in the field of facial recognition of sika deer. Through the 
combined use of deep learning and Transformer, facial recognition of 

EcologicalInformatics78(2023)1023347H. Gong et al.                                                                                                                                                                                                                                    

Fig. 5. Overall model diagram based on ViT.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The hardware resources used for training the deep learning model include Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz, NVIDIA GeForce GTX TITAN Xp GPU, and 32GB RAM. Additionally, the operating system used is Ubuntu 5.4.0-6ubuntu1 ~ 16.04.5, along with Cuda8.0 with cudnn and python2.7, OpenCV, TensorFlow libraries.