Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

model 

Accuracy 

DenseNet201 
efficientNetB0 
efficientNetB3 
Inceptionresnetv2 
ResNet50v2 
ensemble of EfficientNetB0, Inceptionresnetv2, resnet50v2 
ensemble of EfficientNetB0, DesNet201 
ensemble of EfficientNetB0, Desnet201, ResNet50V2 
ensemble of EfficientNetB0, EfficientNetB3 
ensemble of EffieicntNetB0, EffieicntNetB3, 
inceptionresnetv2, Desnet201, ResNet50V2 
ensemble of EfficientNetB0, inceptionresnetv2, Desnet201 
ensemble of EfficientNetB0, inceptionresnetv2, 
Desnet201, EfficientNetB3 
ensemble of EfficientNetB0, inceptionresnetv2,Desnet201, 
ResNet50V2 
ensemble of EfficientNetB0, inceptionresnetv2, 
EfficientNetB3 
ensemble of inceptionresnetv2 + Desnet201 + ResNet50V2 

F1- 
score 

0.9948 
0.9979 
0.9979 
0.9948 
0.9917 
0.9979 
0.9979 
0.9979 
0.9990 
0.9990 

0.9929 
0.9964 
0.9952 
0.9972 
0.9764 
0.9978 
0.9977 
0.9981 
0.9986 
0.9986 

0.9986 
0.9989 

0.9990 
0.9990 

0.9987 

0.9990 

0.9987 

0.9979 

0.9978 

0.9990

3.7. Performance metrics 

In this work, we measure the accuracy of the deep-learning models 

by using the following metrics:  

• Accuracy 

accuracy which is a simple metric for deep-learning classification 
models. This metric measures the overall percentage of correct pre-
dictions. However, accuracy does not take into account the different 
types  of  errors.  That  is  the  reason  we  employ  other  metrics  for 
measuring the efficiency of deep learning models. 

Accuracy =

TP + TN
TP + TN + FP + FN

• Precision 

(1)    

Precision  is  a  metric  that  measures  the  number  of  positive  pre-
dictions  that  are  actually  correct  viz.  a  viz.  correct  and  incorrect 
positive predictions. 

recall is a metric that measures the number of positive predictions 
that are actually correct viz. a viz. correct positive predictions and 
incorrect negative predictions. Recall measures how many positive 
predictions were correctly spotted by the model. 

Recall = TP

TP + FN

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

An ensemble of deep learning architectures for accurate plant 
disease classification 

Ali Hussein Ali a, Ayman Youssef b, Mahmoud Abdelal c, Muhammad Adil Raja d,* 
a Basra University, Department of Computer Science, Iraq 
b Electronics Research Institute (ERI), Department of Computers and Systems, Cairo, Egypt 
c Benha University, artificial intelligence department and Mechatronics Engineering department, Cairo, Egypt 
d Regulated Software Research Centre (RSRC), Dundalk Institute of Technology (DkIT), Dundalk, Ireland   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Plant leaf disease 
Agriculture 
Ensemble deep learning models

3.4. Deep learning models 

In this work, we propose deep-learning architectures to classify plant 

EcologicalInformatics81(2024)1026185A.H. Ali et al.                                                                                                                                                                                                                                    

diseases. We also propose using different ensembles to increase classi-
fication accuracy. To this end, five different deep-learning models are 
proposed to classify plant diseases. The chosen models are:  

Precision = TP

TP + FP

• DenseNet201 

• Recall 

(2)    

DenseNet is a network proposed by (Huang et al., 2017). In this 
network,  each  Layer  has  a  connection  with  subsequent  Layers. 
Densenet201 is a CNN that has 201 deep layers.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context provided does not explicitly mention the criteria used to split the data for deep learning model training. However, typically, datasets are divided into three subsets: training set, validation set, and testing set. The training set is used to fit the model, while the validation set is used to tune hyperparameters and prevent overfitting during training. Finally, the testing set is used to evaluate the final performance of the trained model on unseen data. Common splitting ratios include 60% for training, 20% for validation, and 20% for testing or 70% for training, 15% for validation, and 15% for testing. Other methods such as k-fold cross-validation can be employed to ensure robustness and generalization of the model.