Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Cspnet: A new backbone that can enhance learning capability of cnn. In: Proceedings 
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 
Workshops, pp. 390–391. 

Waycott, M., Duarte, C.M., Carruthers, T.J.B., Orth, R.J., Dennison, W.C., Olyarnik, S., 

Calladine, A., Fourqurean, J.W., Heck, K.L., Hughes, A.R., Kendrick, G.A., 
Kenworthy, W.J., Short, F.T., Williams, S.L., 2009. Accelerating loss of seagrasses 
across the globe threatens coastal ecosystems. Proc. Natl. Acad. Sci. 106 (30), 
12377–12381. 

Weidmann, F., Jager, J., Reus, G., Schultz, S.T., Kruschel, C., Wolff, V., Fricke- 

Neuderth, K., 2019. A closer look at seagrass meadows: Semantic segmentation for 
visual coverage estimation. In: OCEANS 2019 Marseille, 1–6. 

Xu, R., Lin, H., Lu, K., Cao, L., Liu, Y., 2021. A forest fire detection system based on 

ensemble learning. Forests 12 (2), 217. 

EcologicalInformatics76(2023)10204713

Our proposed detector-2 was based on EfficientDet-B7. EfficientDet 
frameworks are well optimised with the input image sizes of 512, 640, 
768,  896,  1024,  1280,  1280,  and  1536  for  the  family  network 
EfficientDet-D0 to EfficientDetD7, respectively. These optimised image 
sizes achieved the highest accuracy on the ImageNet dataset. We set up 
the model config file with a class number 1, image size of 1536 × 1536, 
batch size of 16, initial learning rate of 2e3, momentum optimiser value 
of 0.5 and step number of 400,000. We also monitored the validation 
loss  using  early  stopping  during  training  for  every  epoch.  We 
consciously monitored the validation accuracy to stop overfitting and 
overtraining  with  a  patience  of  20.  We  have  used  TensorFlow  object 
detection  API.  First,  we  downloaded  the  pre-trained  EfficientDet-D7 
model weight from the TensorFlow-2 object detection model zoo page.

Fig. 2. YOLOv5 Architecture.  

EcologicalInformatics76(2023)1020474M.K. Noman et al.                                                                                                                                                                                                                              

Fig. 3. EfficientDet architecture (adopted from (Tan et al., 2020)).  

output feature. Each input layer is given an additional weight, which 
allows the network to learn the important features. Three weight fusion 
approaches are considered:  

(

w

Pout
6 = Conv

′

1.Pin

′

′

2.Ptd
6 + w
1 + w′
w′

6 + w
2 + w′

3.Resize
3 + ϵ

(cid:0)

)

Pout
5

(5) 

1.  Unbounded fusion 

∑

O =

wi.Ii

(1) 

i

Recently,  attention  has  focused  on  machine  learning  and  deep- 
learning algorithms to achieve these goals. Deep learning is a branch 
of machine learning and uses algorithms inspired by the function and 
structure of neural networks in the human brain (LeCun et al., 2015). An 
important  part  of  machine  learning  is  feature  engineering,  which  in-
creases  accuracy  and  requires  expertise  in  the  specific  domain  of  the 
problem. The deep learning approaches can perform feature engineering 
independently  by  itself  (Goodfellow  et  al.,  2016;  Jalali  et  al.,  2022). 
Deep-learning are providing state-of-the-art performances of computer 
vision tasks such as classification, detection or segmentation (Kamilaris 
and Prenafeta-Boldu, 2018; Pouyanfar et al., 2018).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention the type of hardware resources used for training the deep learning models. Therefore, it is not possible to determine whether GPUs, TPUs, or other types of hardware were used for training the models mentioned in the context.