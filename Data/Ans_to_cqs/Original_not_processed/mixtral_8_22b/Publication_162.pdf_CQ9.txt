Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

he 

is 

fauna and flora using deep learning.

Dimitri Korsch is a Research Associ-
ate in the Computer Vision Group at
Friedrich  Schiller  University  Jena,
Germany.  He received his BSc and
MSc  degree  in  IT-Systems  Engi-
neering from University of Potsdam
in  2013  and  2016,  respectively.  His
research  interests  include  unsuper-
vised  machine  learning,  reinforce-
ment learning as well as fine-grained
visual categorization.

results in an unchanged expected activation in the fol-
lowing  convolutional  layers.  Furthermore,  we  nor-
malize all input channels (red, green, blue, and depth)
by subtracting the respective mean and dividing by the
respective standard deviation over the whole dataset.
We also introduce a feature fusion module to combine
the extracted features from both backbones using one
3 × 3 convolution per FPN scale and reduce the num-
ber of channels from 2 × 256 to 256. This allows us to
use weights pre-trained on the Microsoft COCO data-
set [24] for the region proposal network (RPN) classi-
fier and mask head. Fig. 4 illustrates the general archi-
tecture of the resulting D-Mask R-CNN architecture.
We  restrict  our  evaluation  of  D-Mask  R-CNN  to
instances of deers as it is the most common species in our
RGB-D dataset. We quantify the results of D-Mask R-
CNN using the average precision (AP), AP50, and AP75
metrics as defined by the Microsoft COCO dataset [24].

32. M. Simon, E. Rodner, and J. Denzler, “Part detector
discovery  in  deep  convolutional  neural  networks,”  in
Asian  Conference  on  Computer  Vision  (ACCV)  (2014),
pp. 162–177.

33. Van G. Horn, O. Mac Aodha, Y. Song, Y. Cui, C. Sun,
A.  Shepard,  H.  Adam,  P.  Perona,  and  S.  Belongie,
“The iNaturalist Species Classification and Detection
Dataset,” in IEEE Conference on Computer Vision and
Pattern Recognition (CVPR) (2018), pp. 8769–8778.
34. G. Yang and D. Ramanan, “Upgrading optical flow to
3D scene flow through optical expansion,” in Proceed-
ings  of  the  IEEE/CVF  Conference  on  Computer  Vision
and Pattern Recognition (CVPR) (2020), pp. 1334–1343.

PATTERN RECOGNITION AND IMAGE ANALYSIS 

 Vol. 31 

 No. 3 

 2021

488

RADIG  et  al.

5. G. Brehm, “New LED lamp for the collection of noctur-
nal Lepidoptera and a spectral comparison of light-trap-
ping lamps,” Nota Lepidopterol. 40, 87–108 (2017).
6. J. Böhlke, D. Korsch, P. Bodesheim, and J. Denzler,
“Lightweight  filtering  of  noisy  web  data:  Augmenting
fine-grained datasets with selected internet images,” in
International Conference on Computer Vision Theory and
Applications (VISAPP) (2021), pp. 466–477.

7. S. T. Buckland et al., Distance Sampling: Methods and

Applications (Springer, New York, NY, 2015).

8. T.  Chambert,  D.  A.  W.  Miller,  and  J.  D.  Nichols,
“Modeling  false  positive  detections  in  species  occur-
rence data under different study designs,” Ecology 96
(2), 332–339 (2015).

9. R. B. Chandler and J. D. Clark, “Spatially explicit inte-
grated population models,” Methods Ecol. Evol. 5 (12),
1351–1360 (2014).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no direct mention or reference to where the data repository of the deep learning pipeline used by Dimitri Korsch is available. The sources cited do not provide this specific detail either. Therefore, without additional context or resources, it is not possible to determine where the data repository of the deep learning pipeline is located.