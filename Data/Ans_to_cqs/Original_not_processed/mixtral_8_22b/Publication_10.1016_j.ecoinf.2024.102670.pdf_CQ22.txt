Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

An  issue  with  deep  learning  methods  is  that  it  can  be  difficult  to 
obtain enough ground truth data. Sharma et al. (2017) utilized crowd-
sourcing, involving non-expert users for obtaining manual annotation, 
and demonstrated the efficacy of their method on karyotyping images of 
chromosomes.

Following the methodology described in Section 2.5.1, we computed 
the  average  precision,  recall,  F1-measure,  and  MMC  for  the  three 
different sets of fungal images. Results are shown in Table 2. In all cases, 
the 2nd-order Gaussian filter was applied with the set of angles θ having a 
◦
step  size  of  15
.  The  datasets  contained  diverse  organisms  and  were 
acquired with diverse resolutions. Therefore, the standard deviation σ 
and  the  minimum  branch  length  were  varied.  In  the  image  set  from 
(Cardini et al., 2020), all images were acquired at the same scale and 
represented the same organism. Therefore, the σ and minimum branch 
length  parameters  were  the  same  for  all  images  (i.e.,  σ = 4  pixels  or 
4.4μm and minimum branch length = 22 μm.). For the image set from 
(Vidal-Diez  de  Ulzurrun  et  al.,  2019),  the  image  scales  vary  between 
samples, and the σ-parameter was varied (σ = [2.5, 3.5] pixels, step size

(4)  

(5)  

(6)  

(7) 

In case (b), the goal was to assess the strength of agreement between 
the gold standard method (manual tracing) and the proposed automated 
method measuring the mycelium length. Lin’s Concordance Coefficient 
(ρc
) (McBride,  2005) is  a commonly  adopted method  to assess  agree-
ment  strength.  Since  the  relation  between  our  measurement  and  the 
manual  one can be  regarded  as  a  statistical population  of  continuous 
random  variables,  following  the  guidelines  by  McBride  (2005),  we 
considered  the  one-sided  95%  confidence  limit  of  ρc  which  was 
computed using the software provided in (Mathew, 2018). CIlow95%(ρc) <
0.9 as poor, 0.9 < CIlow95%(ρc) < 0.95 as moderate, 0.95 < CIlow95%(ρc) <
0.99  as  substantial,  and  CIlow95%(ρc)  > 0.99  as  almost  perfect, 

2.5.2. Validation of separation of filaments

3.1. Scale bar reading 

We found that the automatic method provides a highly precise esti-
mation of the pixel-millimeter ratio, with only a couple of cases where 
one  or  two  fewer  or  additional  pixels  were  counted  to  the  scale  bar. 
Manually tracing the scale bar may lead to a less exact estimate. Fig. 10 
shows  boxplots  of  the  mm/pixel  ratios  obtained  considering  1)  an 
automated  segmentation  and  reading  of  the  scale  bar  and  2)  manual 
tracing.  The  results  show  that  manual  tracing  is  very  accurate  in  the 
median case. However, the lower quartile represents an underestimation 
of 9%, and the lower whisker represents an underestimation of 21%. 

3.2. Mycelium detection performance

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper uses several metrics to evaluate the performance of the deep learning model. These include average precision, recall, F1-measure, and Matthews Correlation Coefficient (MMC). Additionally, Lin's Concordance Coefficient (ρc) is used to measure the strength of agreement between the gold standard method (manual tracing) and the proposed automated method for measuring mycelium length.