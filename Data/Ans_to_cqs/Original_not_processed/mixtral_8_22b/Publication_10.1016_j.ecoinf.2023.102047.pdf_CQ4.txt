Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

H. ovalis) with a max stride of 32. It is worth noting that data augmen-
tation is a well-proven and common technique to avoid overfitting and 
to render a model generalised. We applied random cropping, horizontal/ 
vertical flipping, image rotation, image translation, zooming, brightness 
adjustment,  contrast  adjustment,  hue  and  saturation  adjustment, 
gaussian  noise,  random  erasing  both  of  our  models  training,  which 
helped increase the size and variability of our dataset.

Recently,  attention  has  focused  on  machine  learning  and  deep- 
learning algorithms to achieve these goals. Deep learning is a branch 
of machine learning and uses algorithms inspired by the function and 
structure of neural networks in the human brain (LeCun et al., 2015). An 
important  part  of  machine  learning  is  feature  engineering,  which  in-
creases  accuracy  and  requires  expertise  in  the  specific  domain  of  the 
problem. The deep learning approaches can perform feature engineering 
independently  by  itself  (Goodfellow  et  al.,  2016;  Jalali  et  al.,  2022). 
Deep-learning are providing state-of-the-art performances of computer 
vision tasks such as classification, detection or segmentation (Kamilaris 
and Prenafeta-Boldu, 2018; Pouyanfar et al., 2018).

A deep-learning model trained using a dataset from one location does 
not  generalise  to  other  locations  owing  to  the  data  distribution  shift 
problem. Some researchers have mitigated the issue of data distribution 
shifts in different locations. For example, Islam et al. (Islam et al., 2019), 
developed a domain adaptation model by utilising a generative adver-
sarial network that aligns marginal data distribution between the target 

and source domains.

bottom-up  path,  which  improves  low-level  feature  propagation.  By 
linking the feature grid with all feature levels, adaptive feature pooling 
is used to propagate useful information directly between feature levels. 
PANet uses more accurate localisation signals in lower layers of the 
network, which enhances the location accuracy of objects. Finally, the 
head section generates three different sizes (18 × 18,36 × 36,72 × 72) of 
feature maps to enable multiscale prediction and help the model handle 
small, medium and large objects. The CSPDarknet backbone extracts the 
feature from the input data, and then these feature maps are fed into the 
PANet for feature fusion. Finally, the head layer predicts the class, score 
and location of the objects (Xu et al., 2021). 

2.3. EfficientDet architecture

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors applied several data augmentation techniques to their deep learning pipeline to prevent overfitting and improve the model's generalization capabilities. These techniques include random cropping, horizontal and vertical flipping, image rotation, image translation, zooming, brightness adjustment, contrast adjustment, hue and saturation adjustment, gaussian noise, and random erasing. All these methods helped increase the size and variability of the dataset, allowing the model to learn better representations and improving its performance on unseen data.