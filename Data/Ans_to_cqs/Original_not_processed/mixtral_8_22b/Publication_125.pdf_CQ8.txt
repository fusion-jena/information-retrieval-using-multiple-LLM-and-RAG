Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5.2. Experimental Set-Up

The hardware conﬁguration and software used for the encryption process are:

Graphics processing unit: Intel Core i5-3210M (2.50 GHZ).

•
• Memory: 4 GB.
• Operating system: Windows 10 Professional.
•

Visual Studio Code with Python 3.9 extension.

These CNN experiments are conducted using the Google Colab repository, which
allowed us to execute Python code through the browser and also provided access to
NVIDIA graphics processing unit (GPUs). The libraries used to conduct these experiments
are the Keras DL library and TensorFlow backend, a DL platform. The proposed model
was trained using Stochastic Gradient Descent (SGD) optimizer with a learning rate of
0.001, 32 batch size and 100 epochs.

5.3. Experimental Results
5.3.1. Images Encryption

This section presents the results of image encryption we obtained using the Paillier
scheme, or PHE. In addition, it also evaluates the efﬁciency of the encryption in terms of
its reliability.

VGG16: Simonyan and Zisserman (2014) proposed the architecture of the VGG16
model. VGG16 is a CNN model that consists of 16 hidden layers, including a total with
convolutional, max pooling and fully connected layers. VGG16 was trained on the
ImageNet dataset, which consists of 1,000,000 images. VGG16 is constructed of ﬁve
blocks of convolutional layers with a 3 × 3 ﬁlter and stride of 1. After each convolution,
an activation function (ReLU) is executed, followed by a max-pooling process with
a 2 × 2 max ﬁlter and stride of 2. At the end of the ﬁve blocks, three FC layers are
added: the ﬁrst two layers with 4096 neurons and an ReLU activation function each,
and the third layer with 1000 neurons and a SoftMax activation function [21]. The
default input size is 224 × 224 × 3 [22].
ResNet-50: The ResNet model’s architecture was proposed in 2015 by He et al. ResNet-
50 is a 50 convolutional neural network layers pre-trained on the ImageNet dataset [23].

Execution Time

All runtimes reported in this section were measured on the Google Colab repository
with a CPU running at 2.30GHz. Table 10 presents a detail of the runtime for each CNN
model. The training runtime for VGG16, Xception, and ResNet50 is 22.27, 21.26, and
30.8 min, respectively. Additionally, the prediction runtime for these models is 0.803,
0.827, and 1.835 s, respectively. The training runtime for DenceNet121 and the proposed
model is 18.34 and 16.43 min, and the prediction runtime is 4.134 and 0.976 s, respectively.
Accordingly, the computation overhead varies from one model to another. However,
PHE data are signiﬁcantly fast during both training and prediction and therefore the
computation overhead of the proposed encryption schema is low.

Remote Sens. 2021, 13, 2221

21 of 26

Figure 9. Training accuracy of different CNN models.

Table 10. CNN models’ run-time.

CNN Models

Training Run-Time

Prediction Run-Time

Table 3. CNN Architecture.

No.

Layers

Output Shape

Parameters

Dropout Rate

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Dropout
Flatten
Fully Connected
Activation (ReLu)
Fully Connected
Activation (softmax)

128 × 128 × 3
128 × 128 × 32
—
64 × 64 × 32
64 × 64 × 32
—
32 × 32 × 32
32 × 32 × 64
—
16 × 16 × 64
16 × 16 × 64
16,384
64
—
4
—

—
896
—
—
9248
—
—
18,496
—
—
—
—
1,048,640
—
—
260

—
—
—
—
—
—
—
—
—
—
0.4
—
—
—
—
—

4.2.1. Data Augmentation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of where the code repository of the deep learning pipeline is available. It only mentions that the experiments are conducted using the Google Colab repository, but it does not provide any specific link or reference to a publicly accessible code repository such as GitHub, GitLab, or BitBucket. Therefore, I cannot determine where the code repository of the deep learning pipeline is available.