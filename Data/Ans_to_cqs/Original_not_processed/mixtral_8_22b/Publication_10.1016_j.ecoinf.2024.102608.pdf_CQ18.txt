Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

exploring the parameter space using randomized grid search methods 
(Bergstra and Bengio, 2012). This approach helps strike a balance be-
tween model complexity and the dataset, reducing the risk of overfitting. 
This studyâ€™s main research objectives are as follows: to demonstrate

we selected the set of hyperparameter values that resulted in the mini-
mum  MAE  and  RMSE,  as  well  as  the  highest  R2,  for  each  machine 
learning model. Table 1 presents the resulting hyperparameter values 
for the four machine learning models.

randomly selecting a subset of the parameter grid to explore (Bergstra 
and  Bengio,  2012).  Instead  of  exhaustively  searching  through  all 
possible combinations of hyperparameters, which can be computation-
ally  expensive  and  time-consuming,  randomized  grid  search  offers 
several  advantages, like,  reduces computational cost, especially when 
dealing with a large number of hyperparameters, and it has been shown 
to find equally or more optimal solutions than an exhaustive grid search, 
particularly  when  some  hyperparameters  are  more  influential  than 
others (Bergstra and Bengio, 2012; Lee et al., 2022). We then generated 
various  cases  by  combining  hyperparameter  values  extracted  from  a 
uniform distribution and evaluated their performance. Table S4 in the 
supplementary file summarizes the hyperparameters, their ranges, and 
the intervals used in the grid search. After the randomized grid search,

50 
110 
Sqrt 
6 
4 
True 
9 
Distance 
Kd_tree 
1 
50 
0.01 
Linear 
(100,100) 
Logistic 
Lbfgs 
0.01 
Adaptive 

20 
110 
Sqrt 
6 
4 
True 
9 
Distance 
Brute 
1 
100 
0.1 
Exponential 
(50, 50) 
Tanh 
Lbfgs 
0.01 
Constant 

50 
60 
Sqrt 
6 
4 
True 
9 
Distance 
Brute 
1 
50 
0.01 
Linear 
(50, 50) 
Relu 
Lbfgs 
0.001 
Constant 

20 
90 
Sqrt 
6 
3 
True 
9 
Distance 
Brute 
1 
100 
0.01 
Square 
(50, 50) 
Logistic 
Lbfgs 
0.001 
Adaptive 

50 
70 
Sqrt 
6 
3 
True 
9 
Distance 
Brute 
1 
100 
0.05 
Linear 
(50, 50) 
Logistic 
Lbfgs 
0.0001 
Adaptive 

100 
60 
Sqrt 
10 
4 
True 
9 
Distance 
Brute 
1 
50 
0.01 
Linear 
(50, 50) 
Tanh 
Adam 
0.001 
Adaptive

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information on the strategy implemented to monitor the model performance during training. However, based on the given context, we can infer that the researchers employed a randomized grid search method to optimize the hyperparameters of various machine learning models. They aimed to minimize Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and maximize R^2 score. The table presented in the text likely contains the best performing hyperparameters found after conducting this optimization process. Unfortunately, without additional details about the specific metrics monitored during training or any validation techniques applied, I cannot provide a definitive answer regarding the monitoring strategy.