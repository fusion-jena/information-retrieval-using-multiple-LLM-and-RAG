Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

III. 

MATERIALS AND METHODS 

In  this  section  the  dataset  used  in  the  study  is  presented 
along with the modelling approach taken and the evaluation 
metrics used to evaluate the trained model. The section also 
discusses data pre-processing using the Librosa library. Keras 
and TensorFlow 2.2 are utilised as the backend and an Nvidia 
2070 super GPU with 8GB of memory is utilised to accelerate 
model training. In addition, the proposed inferencing pipeline 
is discussed along with the associated technologies. 
A.  Data Collection and Description

While  a  limited  range  of  species  have  been  used  in  this 
study,  future  work  will  significantly  expand  the  number  of 
classes  in  the  model.  The  inclusion  of  additional  data  will 
enable us to compare the approach outlined in this paper with 
more  advanced  network  architectures  such  as  1D  CNNâ€™s. 

Figure 12. Bird Classification Using Visual Data 

By using a combination of both vision and acoustic based 
data  we  can  extend  the  reach  of  the  platform  into  habitats 
where  visual  monitoring  is  not  feasible.  By  studying  both 
image and acoustic data the system can analyse and provide a 
more holistic overview of the habitat. 

References

Directly  relating  to  the  approach  posited  in  this  paper, 
several  deep  learning  approaches  have  been  reported  in  the 
literature  [16]  and  [17].  In  these  studies,  features  extracted 
from visual spectrogram representations of foreground species 
recordings were used to train CNNs and achieve 0.605 MAP 
in  BirdCLEF2017.  While  [10]  combined  hand-crafted 
features with deep learning in an attempt to classify fourteen 
different  bird  species  using  three  different  feature  types 
(acoustic features, visual features, and those generated using 
deep-learning). They reported that an F1-score equal to 95.95 
was possible when all three approaches were combined in an 
ensemble configuration. 
B.  Limitations

CNN  approaches  require  a  large  corpus  of  high-quality 
annotated  data  that  can  be  used  to  train  the  network.  Given 
that there is limited availability of publicly available data that 
satisfy this requirement there are currently no viable models 
capable of classifying within species animal types.  Another 
major challenge to overcome is the deployment and automated 
inference  of  acoustic  sensors.  Individually,  sensors  may 
generate  reasonable  amounts  of  data,  but  collectively  the 
amount  of  data  that  needs  to  be  processed  will  increase 
exponentially based on the number of sensors deployed. The 
first challenge relates directly to how the data is obtained. The 
second  is  the  cost  of  compute  needed  to  process  the  data. 
Deploying  trained  models  on  edge  devices  for  real-time 
inferencing will take some consideration which has not been 
sufficiently  reported  in  the  literature.  Centralising  inference

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The specific datasets used in the deep learning pipeline are not explicitly mentioned in the given context. However, it does mention that the study uses a combination of both vision and acoustic-based data for bird classification. It also mentions that the approach outlined in this paper was compared with more advanced network architectures such as 1D CNN's using features extracted from visual spectrogram representations of foreground species recordings. Additionally, it discusses combining hand-crafted features with deep learning to classify fourteen different bird species using three different feature types (acoustic features, visual features, and those generated using deep-learning). Therefore, while the exact datasets used are not specified, it can be inferred that the study likely used custom datasets containing both image and audio data related to various bird species.