Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

mAP =

1
k

∑k

i=1

APi

(3) 

We  also  consider  Params  and  FLOPs  to  evaluate  the  model.  The 
“Params”  metric  in  a  neural  network  model  refers  to  the  number  of 
learned variables used for making predictions. It is an essential metric 
for  evaluating  the  model's  complexity  and  computational  efficiency. 
Models  with  more  parameters  generally  require  more  resources  for

On the positive side, a smaller model might generalize better on data 
from previously unseen domains or categories, with a reduced capacity 
to  memorize  training  data;  the  model  may  focus  on  learning  more 
generic  features  that  can  be  useful  across  different  datasets  (Seema-
kurthy et al., 2022). As we will see later, this is a goal we seek in our 
model. 

A reduction in the number of filters can lead to faster inference times. 
Using  smartphone  applications,  the  model  may  process  images  more 
quickly, making it suitable for real-time applications or scenarios that 
demand rapid detection, such as NBSB detection and counting (Diwan 
et al., 2023). However, care must be taken, as if the number of filters is 
decreased,  the  model  might  become  more  prone  to  overfitting  the

During  the  preprocessing  phase,  techniques  like  auto-orientation, 
resizing,  tiling,  and  filtering  were  utilized  to  standardize  and  enrich 
the dataset. These steps ensured that the images were consistently ori-
ented,  had  a  uniform  size  of  640  × 640  pixels,  and  contained  a  sub-
stantial  amount  of  annotated  data,  meeting  the  90%  annotation 

threshold. Augmentation played a crucial role in further diversifying the 
dataset. By introducing random saturation adjustments to each training 
example, the number of outputs per example was increased to two. This 
augmentation  strategy 
intensity, 
contributing to a more comprehensive and robust training dataset. 

introduced  variations 

in  color

This study approached the problem of detecting and counting NBSB 
through  images  and  videos  acquired with  drones.  The state-of-the-art 
methods  nowadays  are  based  on  deep  learning  algorithms,  and  we 
have developed an improved YOLOv8 model with architecture modifi-
cations  that  have  allowed  a  good  compromise  between  accuracy  and 
speed of processing after it has been trained. We tested the model with a 
public image dataset of NBSB in soybean fields and added a novel one 
with more images. The results have shown that the system can truly help 
automate this task, which will allow better pest management control, 
and it can be extended to other pests and crops in the future. Fig. 1 brings 
general schematics of the proposal, where the model receives images or 
videos from real field conditions and produces detection and counting of 
NBSB. 

This research addresses those main issues with the following high-

lights as contributions:

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific methods used for collecting raw data in the deep learning pipeline. However, it mentions that the study approaches the problem of detecting and counting NBSB through images and videos acquired with drones. Additionally, it states that they tested the model with a public image dataset of NBSB in soybean fields and added a novel one with more images. Therefore, it can be inferred that the researchers collected raw data using drones and utilized both publicly available datasets and their own custom dataset for training and testing purposes.