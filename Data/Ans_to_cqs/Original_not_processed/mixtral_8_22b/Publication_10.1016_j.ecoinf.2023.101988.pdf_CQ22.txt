Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

century: where do unmanned aircraft fit in? J. Unmanned Vehicle Syst. 3, 137–155. 
https://doi.org/10.1139/juvs-2015-0021. 

Chalmers, C., Fergus, P., Wich, S., Longmore, S.N., 2021. Modelling animal biodiversity 

using acoustic monitoring and deep learning. In: ’Proceedings of the 2021 
International Joint Conference on Neural Networks (IJCNN), pp. 1–7. https://doi. 
org/10.1109/IJCNN52387.2021.9534195. 

Christie, K.S., Gilbert, S.L., Brown, C.L., Hatfield, M., Hanson, L., 2016. Unmanned 
aircraft systems in wildlife research: current and future applications of a 
transformative technology. Front. Ecol. Environ. 14, 241–251. https://doi.org/ 
10.1002/fee.1281. 

Civil Aviation Safety Authority, 2019. Advisory Circular AC 101–01 v3.0. Australian 

Government, Canberra, Australia.  

Corcoran, E., Denman, S., Hamilton, G., 2021. Evaluating new technology for 

biodiversity monitoring: are drone surveys biased? Ecol. Evol. 11, 6649–6656. 
https://doi.org/10.1111/2041-210X.13581.

0.169  

(cid:0) 4.625 

1.988 

(cid:0) 2.327  

(cid:0) 2.750 
(cid:0) 9.750 
(cid:0) 2.500 
(cid:0) 2.500 
(cid:0) 8.750 
(cid:0) 3.500 
(cid:0) 5.000 
(cid:0) 9.000 
(cid:0) 4.750 

6.000 
2.125 
3.375 

(cid:0) 3.000 
(cid:0) 2.375 
(cid:0) 2.625 

6.375 
(cid:0) 2.000 
(cid:0) 3.875 

(cid:0) 3.375 
(cid:0) 1.500 
(cid:0) 2.125 

5.212 
5.212 
5.212 
5.212 
5.212 
5.212 
5.212 
5.212 
5.212 

2.738 
2.738 
2.738 

4.019 
4.019 
4.019 

2.219 
2.219 
2.219 

3.938 
3.938 
3.938 

(cid:0) 0.528  
(cid:0) 1.871  
(cid:0) 0.480  
(cid:0) 0.480  
(cid:0) 1.679  
(cid:0) 0.672  
(cid:0) 0.959  
(cid:0) 1.727  
(cid:0) 0.911  

2.192  
0.776  
1.233  

(cid:0) 0.746  
(cid:0) 0.591  
(cid:0) 0.653  

2.873  
(cid:0) 0.901  
(cid:0) 1.746  

(cid:0) 0.857  
(cid:0) 0.381  
(cid:0) 0.540  

0.09 

0.088 

<0.001 

0.866 

0.02 

0.797 

0.170 

0.877 

<0.001 

0.859

X 
√ 

X 
√ 
√ 

(continued on next page) 

EcologicalInformatics74(2023)1019888S. Fischer et al.                                                                                                                                                                                                                                  

(continued ) 

Species name 

Location habitat 

Survey type & method

Table 3 
Percentage of species identified by observer and audio for each habitat (species 
numbers in brackets).  

Method 

Habitat 

Established 
streetscape 

Native 
vegetation 

New 
streetscape 

Parklands 

Observer total 

89.6% (43) 

72.9% (51) 

85.7% (42) 

Observer only 

20.8% (10) 

12.9% (9) 

24.5% (12) 

Audio total 

79.2% (38) 

87.1% (61) 

75.5% (37) 

Audio only 

10.4% (5) 

27.1% (19) 

14.3% (7) 

Total number of 

48 

70 

49 

73.9% 
(51) 
17.4% 
(12) 
81.2% 
(56) 
24.6% 
(17) 
69  

species 
identified 

Transition 1 
Transition 2 
Wet 
Habitat    

Native vegetation 
New streetscape 
Parkland 
Survey type    
Point-count 
Survey method    

Observer 

Survey type x Survey method    

Point-count & observer 

Season x Habitat

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers cited in this context do not provide specific information about the evaluation metrics used for their respective deep learning models. However, common metrics used to evaluate the performance of deep learning models include accuracy, precision, recall, and F1 score. Accuracy measures the proportion of correct predictions out of all predictions made. Precision is the ratio of true positive predictions to the sum of true positives and false positives. Recall, also known as sensitivity or true positive rate, is the ratio of true positive predictions to the sum of true positives and false negatives. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both factors. Other possible metrics include area under the receiver operating characteristic curve (AUROC), Cohen's kappa coefficient, and Matthews correlation coefficient (MCC). Without further details from the authors regarding their chosen evaluation metrics, it cannot be determined which ones were specifically employed in these studies.