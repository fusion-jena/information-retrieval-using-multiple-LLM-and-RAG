Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Our  deep-learning  models  used  NASnet  architecture  (Zoph  et  al., 
2017) with a Faster-rcnn backbone (Ren et al., 2015) implemented in 
Tensorflow2. The parameters of the model can be found on TensorFlow 
model zoo1 under the name “faster_rcnn_nas”. All images were resized to 
1333 × 800 pixels to match with the pre-training data (COCO dataset 
(Lin et al., 2014)) used to prepare the first layers of our model and save 
computing time during the training phase). We used a learning rate of 
0.008 with a cosine learning rate decay. For each K-fold, the model was 
trained on its own version of Trainingclips  through 200,000 iterations, 
with a batch size of 16 images per iteration. The training was completed 
in 96 h  per model using a GPU-cluster equipped with 4 RTX8000. In 
order  to  evaluate  the  performance  of  our  deep-learning  models,  we 
computed the recall, precision, and F-measure for each model. Briefly, a

2. Methods 

2.1. Deep learning model 

To assess the robustness of our method, we performed a 5-fold cross- 
validation.  For  each  fold,  we  randomly  selected  80%  of  our  dataset 
Videoclips  to  train  our  model,  and  20%  to  test  it.  We  could  not  split 
directly images from the frame dataset as images from the same videos 
were very alike which can lead to a model with a low generalization 
capacity.  Using  a  80%  training/20%  testing  random  split  on  videos 
rather  than images  ensured  full independency  between  images of  the 
training set and testing set.

85 

80 
10,474 
2570 
900 
783 
454 

346 

267 
223 

132 

107 

36 

32 
14 

10 

4214 

822 

162 

229 
190 
112 

37 

80 
4621 
1640 
615 
430 
322 

103 

168 
77 

80 

78 

30 

18 
1 

8 

65 

40 

32 

7 
4 
4 

3 

4 
90 
62 
16 
35 
28 

10 

13 
11 

35 

9 

5 

4 
1 

1  

EcologicalInformatics80(2024)1024992S. Villon et al.                                                                                                                                                                                                                                   

For each fold, the frames from Trainingclips  were used to train the 
models. The Testingclips were used to assess the robustness of our method 
on short sequences centered around the presence of fish presence. The 
Testingstations, common to all k-fold were used to assess the robustness of 
the method on 1-h videos, corresponding to the real use-case scenarios 
of ecological studies (Supp. Fig. 1). 

2. Methods

mechanisms  (Vaswani  et  al.,  2017).  Moreover,  recent  technological 
strides in time series processing offer promising avenues for refinement. 
Techniques such as contrastive representation distillation (Tian et al., 
2020), federated distillation learning (Xing et al., 2021), long short-term 
memory (Sepp and Jurgen, 1997), and temporal feature network (Xiao 
et  al.,  2021)  are  among  the  innovative  approaches  in  this  domain. 
Methodologies such as few-shot/one shot learning and adaptative losses 
may also improve the models. Such methods may be explored to effi-
ciently discriminate fish with few training data, such as the tiger shark 
Galeocerdo cuvier or the silvertip shark Carcharhinus albimarginatus. The 
integration of these methodologies carries the potential to enhance ac-
curacy metrics and better exploit the temporal dimension of videos.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, there is mention of a 5-fold cross-validation process, which is a technique used to reduce overfitting by evaluating the model's performance on different subsets of the data. Additionally, the authors note that they used a cosine learning rate decay, which can help prevent overfitting by gradually reducing the learning rate during training.