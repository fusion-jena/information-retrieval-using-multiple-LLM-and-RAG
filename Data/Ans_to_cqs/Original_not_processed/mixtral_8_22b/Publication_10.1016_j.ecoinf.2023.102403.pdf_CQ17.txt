Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

R5 (∼ 5

◦

) 

R10 (∼ 10

◦

) 

L 

2.89 
1.38 
0.83 
2.41 
0.70 
2.13 
2.84 
0.20 

M 

H 

NR 

IR 

L 

M 

H 

NR 

IR 

24.41 
13.53 
5.37 
22.41 
8.07 
17.67 
26.81 
1.97 

6.04 
4.13 
0.83 
7.22 
14.04 
11.19 
8.52 
0.59 

25.93 
25.93 
52.63 
27.27 
27.78 
30.19 
15.00 
69.45 

0.00 
7.41 
10.53 
12.12 
16.67 
7.55 
10.00 
11.02 

14.81 
3.70 
0.00 
0.00 
0.00 
1.89 
5.00 
1.00 

51.85 
51.85 
21.05 
30.30 
22.22 
30.19 
40.00 
10.52 

7.41 
11.11 
15.79 
30.30 
33.33 
30.19 
30.00 
8.01 

0.00 
20.00 
42.86 
16.67 
7.69 
30.00 
12.50 
42.29 

18.18 
10.00 
0.00 
0.00 
7.69 
10.00 
12.50 
16.57 

L 

0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
0.00 
2.86 

M 

H 

36.36 
50.00 
28.57 
33.33 
23.08 
25.00 
37.50 
22.29 

45.45 
20.00 
28.57 
50.00 
61.54 
35.00 
37.50 
16.00

scales associated with data collection (Zizka et al., 2020). Due to these 
disparities,  scholars  recommend  a  thorough  examination  and  refine-
ment  of  these  data  repositories  (Bonnet-Lebrunm  et  al.,  2023).  To 
enhance the quality and reliability of the information, a comprehensive 
series  of  filters  has  been  systematically  applied  to  our  analysis.  To 
minimize errors associated with the public usage of GBIF and OBIS re-
positories,  we  curated  the  dataset  following  Zizka  et  al.  (2020)  and 
filtered the dataset by the columns labeled “scientific name”, “family”, 
“year”, “longitude” and “latitude”. We retained all taxonomic informa-
tion down to the species level and removed records with NA in these 
columns. We also removed all duplicate records with identical latitude

Data will be made available on request.  

EcologicalInformatics79(2024)1024038V. Pizarro et al.                                                                                                                                                                                                                                 

Appendix A. The database 

Table A.1 below shows the data loss for each criterion that we have used to clean our database. We downloaded 71,670,596 records from GBIF and 

OBIS. Only 820,004 records were useful for our analyses.  

Table A.1 
Criteria for filtering occurrence data from GBIF and OBIS using bioregions.  

Database state 

Number of records 

Origial records from GBIF and OBIS 
Data curation (following Zizka et al. (2020)) 
Taxonomically filtered data 
Deletion of data outside the native range 

71,670,596 
5,380,439 
5,007,322 
820,004

◦
and ∼10

9 

10 

1 
2 
3 
4 
5 
6 
7 
8 

Inner Baltic Sea 
Black Sea 
NE Atlantic 
Norwegian Sea 
Mediterranean 
Arctic Seas 
North Pacific 
North American 
Boreal 
Mid-Tropical N 
Pacific Ocean 
South-East 
Pacific 
The Caribbean 
and the Gulf of 
Mexico 
Gulf of California 
Indo-Pacific Seas 
and Indian Ocean 
Gulfs of Aqaba, 
Aden, Suez, Red 
Sea 
Tasman Sea 
15 
16 
Coral Sea 
17  Mid South 

12 
13 

11 

14 

Tropical Pacific 
Offshore and NW 
North Atlantic 
Offshore Indian 
Ocean 
Offshore W 
Pacific 
Offshore S 
Atlantic 
Offshore Mid-E 
Pacific 
Gulf of Guinea 
Argentina 
Chile 
Southern 
Australia 
Southern Africa 
New Zealand 
North West 
Pacific 
Southern Ocean 

18 

19 

20 

21 

22 

23 
24 
25 
26 

27 
28 
29 

30 

415 
537 
2053 
1132 
2859 
10,276 
12,974 
8001 

8902 
102 
87,377 
3046 
12,532 
2506 
78,070 
9709 

72 
37 
310 
93 
372 
114 
839 
162 

30 
22 
104 
35 
101 
23 
156 
48 

2.46 
3.21 
3.90 
2.16 
3.39 
3.90 
4.50 
2.99 

32,685 

9310 

615

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Regularization is a technique used in machine learning and deep learning models to prevent overfitting. Overfitting occurs when a model learns the training data too well, resulting in poor generalization performance on unseen data. Regularization helps to reduce this problem by adding a penalty term to the loss function during optimization. This encourages simpler models with smaller weights, which can improve their ability to generalize to new data. Two common types of regularization used in deep learning pipelines are Dropout and L2 regularization.

Dropout is a regularization method where randomly selected neurons are ignored or "dropped out" during training. This means they do not contribute to the forward pass or participate in backpropagation. By doing so, it prevents complex co-adaptations between neurons, reducing the risk of overfitting. During testing, no neurons are dropped out, but their outputs are scaled down proportionally to the dropout rate used during training.

L2 regularization, also known as weight decay, adds a penalty term proportional to the square of the magnitude of the weights to the loss function. This discourages large weights, promoting simpler models that are more likely to generalize better. In practice, L2 regularization often leads to smoother decision boundaries and improved overall performance compared to models without regularization.

Other forms of regularization include L1 regularization, which uses the absolute value of the weights instead of squaring them, and early stopping, where training is halted once validation error starts increasing. These techniques can be combined or used independently depending on the specific requirements of the task and the characteristics of the data.