Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

hyperparameters.  The  hyperparameters  with  the  current  results  are 
saved until better accuracy is achieved. The termination criterion of the 
proposed approach is the maximum number of iterations to be executed. 
After the completion of the iterations, the proposed approach provides 
us with the best hyperparameters, thus evolving the near-optimal CNN. 
The  overall  complexity  is  dominated  by  the  iterations,  “TC”,  and 
within  each  iteration,  the  operations  depend  on  the  population  size 
“NP”.  Therefore,  the  total  complexity  can  be  approximated  as 
O(TC*NP).

The results obtained from the experiments provide insights into the 
performance  of  the  algorithm  and  its  effectiveness  in  optimizing  the 
hyperparameters  of  the  CNN  model.  The  accuracy  of  the  CNN  model 
trained  using  the  optimized  hyperparameters  improved  significantly 
compared  to  that  of  models  trained  with  random-tuned  hyper-
parameters. The accuracy metric, precision, recall, and F1 score were 
calculated  to  assess  the  classification  performance  of  the  proposed 
approach. The results demonstrated a substantial increase in classifica-
tion accuracy, indicating the effectiveness of the hybrid nature-inspired 
algorithm  in  finding  optimal  hyperparameters  for  plant  leaf  image 
classification, as depicted in Table 7. 

For performance analysis, we used 2278 and 3000 plant leaf images 
from the Mendeley and CVIP100 datasets, respectively. The datasets are 
divided into training (80%) and testing (20%) datasets.

Table 8 
Performance  comparison  of  the  proposed  HPB3C-3PGA-based  approach  with 
existing machine learning approaches.  

Table 10 
Parameter  comparison  of  the  HPB3C-3PGA-based  CNN  configuration  with 
existing transfer learning approaches.  

Model  

Accuracy 

Precision 

Recall 

F1-score 

Models 

Trainable Param 

Non-Trainable Param 

SVM 

KNN 

Decision Tree 

Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Proposed Approach  Mendeley 
CVIP100 

Random Forest 

CNN 

82.32% 
84.52% 
75.53% 
77.43% 
78.20% 
80.25% 
82.54% 
84.78% 
90.52% 
92.43% 
98.96% 
98.97% 

82.42% 
84.52% 
75.55% 
77.55% 
78.54% 
80.47% 
82.32% 
84.42% 
90.32% 
92.46% 
99.22% 
99.28% 

82.82% 
83.87% 
75.42% 
77.32% 
78.88% 
80.25% 
82.81% 
84.51% 
90.02% 
92.42% 
98.18% 
99.48% 

82.54% 
83.58% 
75.75% 
77.83% 
78.45% 
80.25% 
82.79% 
84.59% 
90.52% 
92.42% 
97.71% 
98.98%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study uses a Convolutional Neural Network (CNN) model for plant leaf image classification. The search space of CNN hyperparameters includes convolution layers, filters, filter size, number of neurons, batch size, epochs, and CNN model optimizers. The range of values considered for these hyperparameters is listed below:

- Convolution Layers: Lower limit = 1 and Upper limit = 10
- Filters: Lower limit = 1 and Upper limit = 64
- Filter Size: Lower limit = 1 and Upper limit = 10
- Number of Neuron: Lower limit = 32 and Upper limit = 1024
- Batch Size: Lower limit = 8 and Upper limit = 512
- Epochs: Lower limit = 1 and Upper limit = 25
- CNN Model Optimizer: ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

These hyperparameters are tuned using a hybrid nature-inspired algorithm called HPB3C-3PGA. The proposed approach aims to find the best combination of hyperparameters that result in the highest accuracy for plant leaf image classification. After completing the iterations, the proposed approach provides us with the best hyperparameters, thus evolving the near-optimal CNN.