Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(3)  As a contextual constraint, bioclimatic data (see above) was fed into the CNN with the same model and 
data configuration including Plasticity in a mixed data approach (‘Worldclim’ in Fig. 2, setup 3 in Fig. 1). 
4) We tested an Ensemble approach, in which two more state-of-the-art model architectures, namely 
 Xception51 and MobileNetV2, the latter with halved number of trainable  parameters52, were trained on the 
configuration of setup 3, and their predictions were subsequently averaged (’Ensemble’ in Fig. 2, setup 4 in 
Fig. 1). These models differed strongly in their number of trainable weights, resulting in a different depth. 
The final model performance was assessed using a 3-fold cross-validation, with three different training, 
validation and test splits. To enable a comparison of model performance across traits, the resulting mean 
absolute error (MAE) was normalised by division over the range of the target values of the respective test

Conclusion and outlook
Following the urgently needed transition of ecology towards a data-sharing scientific  discipline15,44 and the call for 
integration of powerful datasets in  ecology44, we built upon this revolution of Big Data provided by professional 
and citizen science alike. Therefore, we exploited the potential of Convolutional Neural  Networks44 to produce 
generic models generalising across all biomes and regions around the globe to extract a set of plant functional 
traits from simple RGB photographs. Thus, the burden of limited geographical coverage of trait databases might 
be lifted by the worldwide coverage of the iNaturalist plant photograph database. The traits referring to the models 
with the highest predictive performance cover the primary axes of plant form and function 13, which are plant and 
organ size (GH, LA) as well as the leaf economics spectrum (SLA). Despite of the disputable model performance

Vol.:(0123456789)www.nature.com/scientificreports/Discussion
Our results suggest that certain plant functional traits can be retrieved from simple RGB photographs. The key 
for this trait retrieval are deep learning-based Convolutional Neural Networks in concert with Big Data derived 
from open and citizen science projects. Although these models are subject to some noise, there is a wealth of 
applications for this approach, such as global trait maps, monitoring of trait shifts in time and the identification 
of large-scale ecological gradients. This way, the problem of limited data that still impedes us to picture global 
 gradients7 could be alleviated by harnessing the exponentially growing iNaturalist  database16. The performance 
of the CNN models across traits varied strongly, but revealed a clear trend: As expected, the more a trait referred 
to morphological features, the more accurate the predictions were. The models of the Baseline setup explained a

Nevertheless,  the  benefit  of  including  climate  information  on  temperature,  precipitation  and  their 
 seasonality8,20,21,26 on predicting trait expressions was confirmed for all traits in this study, which underlines 
the value of contextual constraints in CNN  models10 (see below for a discussion of the relevance of climate vs. 
image data). This also highlights the general flexibility of deep learning frameworks in adapting to variable input 
data from different scales and  sensors10, which makes them a promising tool for ecological research. Our results 
particularly revealed this effect for SSD, SLA and LA, whereas it was smaller for GH, LNC and SM (Fig. 2). For 
the latter traits, other physical constraints such as  disturbance33,34, seasonal  variation35,36 and soil  conditions6,26,28 
come into consideration. As the focus of the Worldclim setup was to show that contextual cues can improve the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, the authors discuss the use of Convolutional Neural Networks (CNN) for extracting plant functional traits from simple RGB photographs. They mention feeding bioclimatic data into the CNN along with the images. Additionally, they experiment with an ensemble approach using two more state-of-the-art model architectures, namely Xception and MobileNetV2. From this information, we can infer that the main data format used in their deep learning pipeline is image data (RGB photographs), while additional contextual data includes bioclimatic data. However, the specific file format or structure of these data sources is not explicitly mentioned in the provided context.