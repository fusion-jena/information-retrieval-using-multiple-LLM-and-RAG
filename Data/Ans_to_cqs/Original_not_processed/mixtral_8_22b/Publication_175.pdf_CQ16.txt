Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

There are two ways to tackle this problem of lack of data. The first 
one  consists  of  directly  addressing  the  data  itself,  through  data 
augmentation (Van Dyk and Meng, 2012; Wang and Perez, 2017; Wong 
et al., 2016). The second option is to change the classification algorithm. 
Few-shots learning (FSL) algorithms (Fei-fei et al., 2006; Fink, 2005) are 
designed to compute a classification task (query, noted Q) with only a 
few  thumbnails  to  train  (Support  Sets,  noted  SS),  and  it  has  been 
increasingly studied since 2017 (Finn et al., 2017). Few-shots learning 
methods are divided into three main approaches. Metric-based methods 
are embedding both queries (Q) and support sets (Ss), before assigning to 
the query a class, according to distances computed between Q and Ss 
(Sung et al., 2018; Victor and Bruna, 2018; Yanbin et al., 2019). The 
second approach consists of 1) training a model on a large database, and

a new task with a very limited dataset, usually only 1â€“5 thumbnails per 
class.

5 shots 

30 shots 

70.9 
28.8 
61.01 
32.55 
35.18 
51.18 
43.17 
51.07 
68.28 
55.44 
39.16 
41.35 
45.85 
58.08 
33.71 
65.44 
86.21 
45.7 
40.82 
50.69 
50.23 
14.75 

86.35 
42.66 
72.02 
40.64 
53.20 
79.29 
63.51 
70.63 
81.50 
67.22 
54.22 
58.87 
59.13 
61.00 
44.36 
84.86 
90.00 
70.60 
62.72 
55.70 
64.92 
14.55  

ResNet  DL  model  trained  on  smaller  AT1  (315  natural  thumbnails  in 
average  per  species)  during  the  second  experiment  showed  highly 
degraded  performance  with  a  mean  accuracy  of  only  42.21%  (SD  =
24.95%).  Among  species  variation  ranged  with  this  model  from  only 
3.49% (Chaetodon trifascialis) to 85.86% (Chaetodon auriga).

where very few images per classes are at disposal. Therefore, the dataset

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about the criteria used to determine when training is complete for either data augmentation or few-shot learning methods. However, based on general machine learning practices, some common criteria include reaching a predefined number of epochs, achieving a desired level of performance on a validation set, observing a plateau in the validation loss, or meeting other user-specified conditions. In the case of few-shot learning, where only a small amount of labeled data is available, monitoring the performance on a separate validation set might be more challenging due to the limited data. Instead, one could rely on early stopping techniques or use cross-validation strategies to ensure robustness and prevent overfitting. Nonetheless, without specific details regarding the implementation of these methods in the given context, we cannot definitively state which criteria were employed.