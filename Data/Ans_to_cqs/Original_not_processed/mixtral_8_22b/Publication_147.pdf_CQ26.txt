Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Keywords: wetlands; Sentinel-1; Sentinel-2; Google Earth Engine; remote sensing; Alberta;
segmentation convolutional neural nets; XGBoost; land cover; SAR; machine learning

1. Introduction

Machine learning—a method where a computer discovers rules to execute a data processing
task, given training examples—can generally be divided into two categories: Shallow learning and
deep learning methods [1]. Deep learning uses many successive layered representations of data
(i.e., hundreds of convolutions/ﬁlters), while shallow learning typically uses one or two layered
representations of the data [1]. Deep learning has shown great promise for tackling many tasks such as
image recognition, natural language processing, speech recognition, superhuman Go playing, and
autonomous driving [1–3].

Remote Sens. 2020, 12, 2; doi:10.3390/rs12010002

www.mdpi.com/journal/remotesensing

The shallow learning classiﬁcation model was done with the XGBoost algorithm [75]. XGBoost
was used since it has been shown to be one of the better performing shallow learning models in
machine learning competitions [1], although it has limited use in remote sensing literature. It has been
the most popular shallow learning algorithm in Kaggle competitions since 2014 [1]. Early work on this
project showed XGB models slightly out performing random forest and boosted regression tree models.
We used the xgboost package [75] in R Statistical software [76]. The inputs into the XGBoost model
were: Anthocyanin Reﬂectance Index (ARI), delta Normalized Diﬀerence Vegetation Index fall–spring
(dNDVI), POLr, Red Edge Inﬂection Point (REIP), Topographic Position Index (TPI), Topographic
Wetness Index (TWI), Multi Resolution Index of Valley Bottom Flatness (VBF), VH, dVH (Table 1).
These inputs were the indices shown to be important for wetland class mapping, while also having low

5. Conclusions

The goal of this study was to compare shallow learning (XGB) and deep learning (CNN) methods
for the production of a large-scale spatial wetland classiﬁcation. We encourage readers to view both
products via this link: https://abmigc.users.earthengine.app/view/cnn-xgb, and one of the products
can be downloaded via this link: https://bit.ly/2X3Ao6N. A comparison of the two products to
photo-interpreted validation data showed that CNN products outperform the shallow learning (XGB)
product in terms of accuracy by about 5–8%. The CNN product achieved an average overall accuracy
of 80.8% with a mean F1-score of 0.58. When compared to a small data set (n = 22) of ﬁeld data, the
results were inconclusive and both data sets showed little ability to distinguish between fen and bogs.
This ﬁnding could just be due to the small, spatially constrained data or it could highlight the mismatch
between on the ground conditions and large-scale landcover classiﬁcations.

Remote Sens. 2020, 12, 2

4 of 20

data sets: Two generated from photo interpretation and one ﬁeld validation data set. These results
will guide future large-scale spatial wetland inventory eﬀorts in Canada. If deep learning techniques
are found to generate better products, new wetland inventories projects should adopt deep learning
workﬂows. If shallow learning methods still produce comparable results, they should continue to
be used in wetland inventory workﬂow; however, deep learning architectures should still remain an
active area of research with regard to methods for wetland mapping.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In the given context, there is no explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on general practices in machine learning and deep learning, some common techniques can be mentioned.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes in each subset. This helps prevent any imbalance in the target variable from affecting the performance of the model.

Oversampling and undersampling involve adjusting the number of samples in the minority and majority classes, respectively. Oversampling increases the number of instances in the minority class, while undersampling reduces the number of instances in the majority class. Both techniques aim to balance the dataset and reduce bias towards the majority class.

Diverse data collection refers to collecting a wide range of data samples representing different scenarios, environments, and conditions. This ensures that the model learns from diverse data points and becomes more robust and accurate.

While these techniques are not explicitly discussed in the given context, they are commonly employed in addressing data bias during preprocessing of deep learning pipelines.