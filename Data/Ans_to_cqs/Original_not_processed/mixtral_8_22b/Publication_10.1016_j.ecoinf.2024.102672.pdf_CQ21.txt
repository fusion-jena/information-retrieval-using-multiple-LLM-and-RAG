Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The result of this process was added to the dataset as a new cate-
gorical binary variable that stored the existence of stratification or not 
(took the value of 0 when the reservoir was not stratified and 1 when it 
was stratified). 

2.5.3. Forecasting ML models 

A classification model was designed in order to detect if there existed 

Table 1 
Initial hyperparameters space.  

Initial hyperparameters space 

Hyperparameters 

Values 

Layers 

Number of neurons of the dense layer 
Dropout rate of the dropout layer 
Learning rate 
Batch size 

1 dense layer, 1 dense layer +1 dropout 
layer 
32, 64 
0.2, 0.4 
(cid:0) 3, 10
10
32, 64  

(cid:0) 4

Predicted classes   

Training  

Not-stratified  

True classes 

Not-stratified 
Stratified 

549  
53  

Stratified  

31  
681  

Testing   

Not-stratified  

115  
2  

Stratified 

7 
166  

Fig. 6. Real and predicted values of thermocline presence with the optimal classification model. The points at the left of the dashed line belong to the training set 
while those at the right belongs to the test set. 

Table 4 
Results from the training and testing of the selected regression model for each set of variables.   

Hyperparameters 

Variables 

Topology* 

Learning rate 

Batch size 

Epochs 

t 
+ t-1 
+ t-2 
þ t-3 
+ t-4 
+ t-5 

32(0.4)16(0.2)8 
32(0.4) 
32(0.2)4(0.2) 
32(0.2)4(0.2) 
32(0.2)4(0.2) 
32(0.4)16(0.2) 

(cid:0) 3 

(cid:0) 3 

(cid:0) 3 

¡3 

(cid:0) 3 

(cid:0) 3 

10
10
10
10
10
10

32 
32 
32 
32 
32 
32 

500 
80 
250 
280 
280 
240 

Training 

MAE 

2.42 
2.70 
2.44 
1.94 
1.83 
1.83 

Percentile 

67.6 
66.9 
70.4 
70.3 
70.0 
70.6 

P50

loss curves during the training. As optimizer, the Adam algorithm was 
used, which is a stochastic gradient descent method. Then, one of the 
hyperparameters was modified iteratively following the direction that

(cid:0) 4 

thermal stratification in the reservoir or, on the contrary, it was mixed; 
while in order to calculate the depth of the thermocline, a regression 
model was designed. Among the variety of available ML algorithms to 
perform classification and regression tasks, ANN were chosen to address 
the  problem  presented  in  this  work.  They  are  supervised  ML  models, 
which means that both, the independent and dependent variables, are 
shown to the model to learn from them.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the specific requirements of the project. Based on the given context, here are some possible postprocessing steps:

1. Model Evaluation: After training the model, evaluating its performance using appropriate metrics is essential. In this case, Mean Absolute Error (MAE), Percentile P50 loss curves, and confusion matrices have been used to evaluate the performance of the classification and regression models.

2. Hyperparameter Tuning: To improve the model's performance further, hyperparameters such as learning rate, batch size, number of layers, and neurons can be tuned. This involves selecting different combinations of hyperparameters and observing their impact on the model's performance.

3. Visualization: Visualizing the results of the trained model can help understand how well it performs. For example, Fig. 6 shows real and predicted values of thermocline presence with the optimal classification model. Similarly, other visualizations like saliency maps can also be generated to highlight important features contributing to the model's predictions.

4. Interpretation: Once the model has been evaluated and validated, interpreting its results is crucial. It helps explain why certain decisions were made by the model and provides insights into the underlying patterns in the data.

In summary, postprocessing steps after model training include evaluating the model's performance using relevant metrics, fine-tuning hyperparameters, generating visualizations, and interpreting the results. These steps ensure that the model meets the desired objectives and provides valuable insights into the problem being addressed.