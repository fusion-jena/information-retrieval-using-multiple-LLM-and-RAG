Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

71.17% 

98.7% 

Ganguly et al., 2022b) 

DDYOLOv5 and ResNet-50 (Hu et al., 

Pine tree classification 

98.71% 

2022) 

Deep Attention Dense CNN model ( 

Pandey and Jain, 2022b) 

Dense convolutional neural networks 

Plant leaf disease 
classification 
Plant disease classification 

97.33% 

99.1% 

() 

Proposed Approach 

Plant leaf classification 

98.97  

6.1.2. CVIP100 dataset

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ImageNet classification with deep 

convolutional neural networks. Commun. ACM 60, 84–90. https://doi.org/10.1145/ 
3065386. 

Kumar, S., Singh, A., Walia, S., 2018. parallel big bang–big crunch global optimization 
algorithm: performance and its applications to routing in WMNs. Wirel. Pers. 
Commun. 100, 1601–1618. https://doi.org/10.1007/s11277-018-5656-y. 

EcologicalInformatics81(2024)10258115S. Ghosh et al.                                                                                                                                                                                                                                   

Liu, Z., Reynolds, A.C., 2020. A sequential-quadratic-programming-filter algorithm with 
a modified stochastic gradient for robust life-cycle optimization problems with 
nonlinear state constraints. SPE J. 25, 1938–1963. https://doi.org/10.2118/193925- 
pa.

Data augmentation was used to collect all possible cases. For data 
augmentation,  we  implemented  Kera’s  flow_from_directory  method 
during the learning phase of the CNN. The applied data augmentation 
techniques used for plant image classification include random rotation, 
random cropping, random flipping, random color jittering, and random 
noise addition. This ensures that we have covered all the possible cases 
that might occur in the real world. 

6.2. Experiment setup

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information on the specific data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, it mentions that data augmentation techniques were employed during the learning phase of the Convolutional Neural Network (CNN). These techniques included random rotation, random cropping, random flipping, random color jittering, and random noise addition. Data augmentation is a strategy used to increase the amount of training data by applying various transformations to existing images, which can help improve the generalization capabilities of the model.