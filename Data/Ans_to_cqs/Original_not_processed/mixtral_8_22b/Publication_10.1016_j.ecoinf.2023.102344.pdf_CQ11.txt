Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

the  shortcut  connections  within  the  network  that  makes  the  training 
faster; bottleneck architecture which consists of a 1 × 1 convolutional 
layer  for  dimension  reduction,  3  × 3  convolution  layer  for  feature 
extraction, and another 1 × 1 convolutional layer for dimension resto-
ration;  shortcut  connections  which  allows  gradients  to  flow  directly 
through  the  network  due  to  the  input  added  directly  to  the  output; 
global  average  pooling  (GAP)  which  computes  spatial  average  of  the 
feature  maps  at  the  end  section  of  the  convolutional  layer;  and  skip 
connections which bypass multiple residual blocks. On the other hand, 
InceptionV3 is a 48-layer 24 CNN containing 24 × 106 parameters with 
enhancement using label smoothing and factorized convolutional layers 
in order to easily propagate the information from the input to the output 
section. For all image-based pre-trained networks, the purpose of CNN

Algorithm 

Accuracy 
(%) 

Reference 

CNN models (VGG19, 
InceptionV3, and 
Resnet50) 

91.14% 

U-Net architecture CNN 

High (na)1 

Cephalopod species 
identification 

Quantification of sheet 
nacre morphogenesis 

In Situ Sea Cucumber 

Detection 

Micro-CT scanning 
image analysis of 
fossil and shelly 
invertebrates 
Assess bivalve 
phylogeny 

Species identification 
using shell image 
analysis 

Common cockle harvest 

origin 

1 Non-available. 

Tree-structured support 
vector machines (SVM) 

U-Net 

CNN 

SVM trained on 
pretrained VGG16 
features 
Deep and shallow neural 
networks with emphasis 
to spectral, texture, and 
geometric features 
selection using PCA-NCA 
and sequence layers of 
GRU-LSTM-BiLSTM 
(BivalveNet) 

(Tan et al., 
2021) 

(Beliaev 
et al., 2020) 
(Xia et al., 
2018) 

(Edie et al., 
2023) 

97.6% 

97.0% 

77.0% 

(Kiel, 2021) 

96.0% 

(Wijaya and 
Town, 
2022) 

96.91% 

This work

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

BivalveNet: A hybrid deep neural network for common cockle 
(Cerastoderma edule) geographical traceability based on shell image analysis

intelligence-based hybrid deep learning models for image classification: the first 
narrative review. Comput. Biol. Med. 137, 104803 https://doi.org/10.1016/j. 
compbiomed.2021.104803. 

Kiel, S., 2021. Assessing bivalve phylogeny using Deep Learning and Computer Vision 

Approaches. https://doi.org/10.1101/2021.04.08.438943. 

Lauguico, S., Concepcion, R., Tobias, R.R., Alejandrino, J., De Guia, J., Guillermo, M., 

Sybingco, E., Dadios, E., 2020. Machine Vision-Based Prediction of Lettuce 
Phytomorphological Descriptors using Deep Learning Networks, in: 2020 IEEE 12th 
International Conference on Humanoid, Nanotechnology, Information Technology, 
Communication and Control, Environment, and Management (HNICEM). In: 
Presented at the 2020 IEEE 12th International Conference on Humanoid, 
Nanotechnology, Information Technology, Communication and Control, 
Environment, and Management (HNICEM), pp. 1–6. https://doi.org/10.1109/ 
HNICEM51456.2020.9400103.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough context to provide a direct link to the data repository of the deep learning pipeline mentioned in the given text. The references provided do not contain any specific links to such repositories either. It would be best to refer back to the original sources or contact the authors for more detailed information about their datasets and pipelines.