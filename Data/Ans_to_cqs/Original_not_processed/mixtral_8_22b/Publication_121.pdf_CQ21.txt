Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

D. Model Training

Feature Extraction: The hardware to train the model included
a Lenovo laptop equipped with an 8265U CPU at 1.80 GHz
of Intel Core i5, 8 GB of RAM running on a Windows 10 64-
bit system. The software tools included Annaconda3 Jupyter
Notebook with Python 3.8, where the Tensorﬂow, OpenCV-
python3 [37] and Keras [38] libraries were used. The dataset
was divided in a ratio of 75:25 into a training set of 5789
images and a test set of 1930 images. To obtain the pre-
trained weight parameters, we built the base models from the
MobileNetV2, MobileNetV3-Large and MobileNetV3-Small

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on August 29,2024 at 05:51:17 UTC from IEEE Xplore.  Restrictions apply.

models, pre-trained on 1.4M images from 1000 classes. First,
the intermediate layer of all the models was selected to use
for feature extraction. For this purpose, the output of the last
layer (bottleneck layer) is commonly used prior to the ﬂatten
operation. The reason is that all the fully connected layers
are specialized to the task network was trained on; thus, the
features learned by these layers will not be useful for the new
task. The bottleneck features are more generic. Therefore, the
base models were frozen, loaded with weights trained on the
ImageNet dataset and used as a feature extractor. We added
a dropout layer with a dropout rate of 0.2 to reduce the
overﬁtting of the model. Finally, the top classiﬁer softmax
layer was added for predicting the class for an input image.
The model with the base model of MobileNetV2 was compiled
and optimized with Adam optimizer. The other with the base
model of MobileNetV3 were optimized with Gradient descent

optimizer (SGD) with a learning rate of 0.5 and momentum
of 0.9. All models were trained on a training set within 10
and 100 epochs (iterations).
Fine-Tuning: We un-froze the base models and trained the
weights of the top layers of these models along with the
classiﬁer layer added in the previous step. The models were
trained in 10 iterations to force the weights to be tuned from
generic feature maps to feature associated with the leaf dataset.
For a fair comparison, both V2 and V3 models were trained
with the same dataset and training parameters, i.e. 235,704.
The models were ﬁne-tuned and re-evaluated. The models
were saved in the machine with all the class labels.

IV. RESULTS AND DISCUSSION

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, several postprocessing steps can be performed depending on the specific requirements of the project or study. However, based on the given context, there isn't any explicit mention of postprocessing steps such as generating saliency maps, calculating metrics, or creating confusion matrices. Nevertheless, some common postprocessing steps often employed include:

1. Evaluation Metrics Calculation: After training the model, it is essential to evaluate its performance using various evaluation metrics like accuracy, precision, recall, F1 score, ROC curves, etc. These metrics help assess how well the model has been trained and if it needs further fine-tuning.

2. Confusion Matrix Generation: A confusion matrix is another valuable tool for evaluating the performance of a classification model. It provides insights into the types of errors made by the model during prediction. By analyzing the confusion matrix, one can identify which classes are being misclassified frequently and work towards improving the model accordingly.

3. Visualizing Results: Postprocessing may also involve visualizing results through techniques like saliency maps or heatmaps. These visualizations highlight important regions in the input data that contribute significantly to the model's predictions. They aid in understanding the decision-making process of the model and identifying potential biases or weaknesses.

In conclusion, while the given context does not explicitly state any postprocessing steps, typical practices include calculating evaluation metrics, generating confusion matrices, and visualizing results using methods like saliency maps.