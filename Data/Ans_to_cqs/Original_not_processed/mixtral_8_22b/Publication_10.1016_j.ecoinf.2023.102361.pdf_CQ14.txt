Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2. Split the datasets 

In this research, the datasets were randomly divided into three parts 
for training, validation and testing. Here, 60% of the data was used to 
train the deep learning models, and 20% of them was kept to validate the 
models. The remaining 20% data was used to evaluate the performance 
of the models. Table 1 show the number of data in the dataset and how 
they are separated for training, testing and validation. 

2.3. Deep learning models

average 
)/
n. 

+ … + Pf n
(cid:0)

, Pf 2

, …, Pf n

and Pv in (Pv1, Pv2, …, Pvn) do. 

7: Calculate average of the variance APv = (Pv1 + Pv2 + … + Pvn)/n. 
)
Pf 1
8: for each Pf  in 
if Pf > APf  and Pv > APv then 
9:
10: Add the patch to selected set SP 
11: end if 
12: end for. 
Fig.  3  illustrates  the  patch  selection  process  with  an  example.  An 
image was divided into 16 patches. Then the mean frequency (in FFT) 
and the variance (in the Laplacian method) of each patch were calcu-
lated. We then calculated the average of the mean frequency and the 
variance separately. This average value was used as a threshold for that 

Fig. 2. The workflow for enhancing and resizing the images.

2.6.4. Model training with selected patches 

We trained the same deep learning models as mentioned in Section 
2.5. For training, we resized all the patches of images to a resolution of 
256 × 256 pixels. Although after dividing the image into patches, there 
were images with lower resolution, i.e., 64 × 64 and 128 × 128 pixels, 
they were converted into a uniform size. 

2.6.5. Evaluation of the models 

An image was divided into patches first to predict its class label. Then 
the important patches were selected using the approach mentioned in 
Section 2.6.3. After that, the model predicted the class label for each 
patch. The weighted majority voting technique was used to predict the 
class label of the image from the predicted labels. 

2.7. Experimental setup

Khotimah, W.N., Bennamoun, M., Boussaid, F., Xu, L., Edwards, D., Sohel, F., 2023. Mce- 
st: classifying crop stress using hyperspectral data with a multiscale conformer 
encoder and spectral-based tokens. Int. J. Appl. Earth Obs. Geoinf. 118, 103286 
https://doi.org/10.1016/j.jag.2023.103286. 

Kirk, K., Andersen, H.J., Thomsen, A.G., Jørgensen, J.R., Jørgensen, R.N., 2009. 

Estimation of leaf area index in cereal crops using red–green images. Biosyst. Eng. 
104, 308–317. https://doi.org/10.1016/j.compag.2008.03.009. 

Kounalakis, T., Malinowski, M.J., Chelini, L., Triantafyllidis, G.A., Nalpantidis, L., 2018.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide information on how the hyperparameters of the model were optimized. Therefore, it is unknown whether techniques such as grid search or random search were employed.