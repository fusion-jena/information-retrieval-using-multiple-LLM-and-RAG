Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

As three of our models are based on the YOLO structure, we would 
expect the results to be relatively similar, and the results demonstrate 
the success on small training data quantities compared to larger model 
complexity. Intuitively, it would be expected that a smaller model can 
successfully learn from fewer data to represent less complex problems, 
whereas larger more complex models may require more data to repre-
sent more complexity within the object to detect. The results indicated 
that YOLOv5s, as the smallest model, performs best in terms of preci-
sion. The TPH-YOLOv5, which is an extension of the YOLOv5s model is a 
slightly more complex model, and further pre-training on RPAS specific 
imagery. The results indicated that detection of Pacific oysters does not 
demand  the  complexity  of  the  larger  YOLOv5m  model  and  using  the 
TPH-YOLOv5 model pre-trained with RPAS data, is not beneficial in this 
instance.

Minimum 

Maximum 

– 

0 
(cid:0) 25% 
(cid:0) 20% 
◦
(cid:0) 90

– 

10% 
+50% 
20% 
◦
+90

2.4. Deep learning models 

Two  widely  used  object  detection  models  were  selected  for  com-
parison, YOLOv5 (Jocher et al., 2021) and Faster R-CNN (FR-CNN) (Ren 
et al., 2015). YOLO is a lightweight approach where objects are identi-
fied directly through as single pass, whereas the FR-CNN is a multi-stage 
network approach based on identifying potential regions and then cat-
egorising and discarding some inappropriate regions (Ren et al., 2015). 
For the YOLOv5 model, we also tested three variants, YOLOv5 small, 
YOLOv5  medium  and  TPH-YOLOv5  (Zhu  et  al.,  2021b),  which  is  a 
modified variant of YOLO with a Transformer Prediction Head (TPH) 
(Yang et al., 2019).

The  authors  recognize  several  other  limitations  that  could  be 
addressed in follow up projects. First, only two types of neural network 
architectures  were  used,  whereas  additional  benchmarking  could  be 
performed  with  other  types  of  ResNets,  DenseNets  and  transformer 
based models. Secondly, this study does not address the individual in-
sights from the trained models, and the pros and cons of architectures 
and hyperparameters in recognizing specific features of Pacific oysters 
across  mudflats  and  rocky  shore  imagery.  Thirdly,  ablations  studies 
should  be  performed,  showcasing  the  possibilities  for  reducing  the 
complexities of neural network layers and speeding up the computation 
times. And fourthly, if left unmanaged, Pacific oysters can create oyster 
reefs and very dense clusters where younger oysters grow on top of the 
older. In such cases, no gaps are found in the cluster and only the oysters

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Pacific oysters 
Invasive species 
Convolutional neural networks 
Deep learning 
Drone 
Remote sensing 
Ecological management

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The text does not provide explicit information about the preprocessing steps involved before training the deep learning models. However, common practices in preparing datasets for deep learning include normalization, scaling, and cleaning. Normalization involves rescaling the input features so they have zero mean and unit variance. Scaling adjusts the range of pixel values to improve contrast or brightness. Cleaning removes noise, irrelevant data, or outliers that might negatively impact the performance of the model. These techniques help ensure that the dataset is suitable for training deep learning models effectively.