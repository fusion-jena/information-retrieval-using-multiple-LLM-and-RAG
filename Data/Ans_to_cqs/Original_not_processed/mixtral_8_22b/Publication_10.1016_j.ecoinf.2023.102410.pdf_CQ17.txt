Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Data analysis

Table 1 
Number of tracked vocalisations of each song structure as a proportion of the 
whole data set.  

Song Variant / Pattern 

Number of Tracks  % Tracking Sample  % Detections 

P3 
P2 
P1 
P3A 
P2A 
P3B 
Total 
Alternating P3A to P3 

190 
162 
10 
17 
2 
2 
383 
4 

49.6 
42.3 
2.5 
4.4 
0.5 
0.5 
100 
0.1 

42.1 
30.8 
3.2 
4.3 
0.5 
0.3 
81.1 
n/a

sation are outlined in Gavrilov et al. (2012).

inaccurate localisation (White et al., 2006; Wiggins et al., 2013). The 
accuracy  of  sound  speed  profiles  is  important  for  localising  sound 
sources, with the speed of sound transmission underlying the accuracy

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The table and text provided do not contain information about regularization methods used to prevent overfitting in the deep learning pipeline such as dropout or L2 regularization. Regularization methods are techniques used to prevent overfitting by adding a penalty term to the loss function during training. Dropout is a technique where randomly selected neurons are ignored during training which helps to make the model more robust and prevents overfitting. L2 regularization adds a penalty equal to the sum of squares of all the weights in the network to the loss function, this encourages smaller weight values and makes the model simpler and less likely to overfit. Other popular regularization methods include L1 regularization, early stopping, and data augmentation.