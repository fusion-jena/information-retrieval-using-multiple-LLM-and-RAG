Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3. Materials and methods 

3.1. Dataset curation

6  https://github.com/ultralytics/ultralytics/issues/189 

EcologicalInformatics81(2024)1025466B. Deng et al.                                                                                                                                                                                                                                    

Fig. 3. Flowchart of our cross-season weed detection.  

Table 2 
Primary hyperparameter settings of the three detection models.  

Hyperparameters 

Detection models 

Initial learning 

rate 

Learning rate 
schedule 
NMS threshold 
Confidence 
threshold 
Weight decay 
Image size 
Batch size 

Optimizer 

YOLOX 

YOLOv8 

0.01 

0.01 

Warm up +
cosine decay 
0.45 

Warm up + cosine 
decay 
0.7 

0.25 

0.0005 
800 
8 

SGD 

0.25 

0.0005 
800 
8 

SGD 

Classification loss 

BCE 

Location loss 

IoU 

Data augmentation 

Color jitter 
+ mosaic 

VFL (Zhang et al., 
2021) 
DFL (Li et al., 2020) 
+ CIoU (Zheng et al., 
2021)

5648 
385 
5510 
2568 
>10,000 
848 
3975 
8034 
2872 
8000 
5187 
9324 
201 
6428 
1147 
>10,000 
1901 
462 
>10,000 
500 
150 
4402 
>10,000 
7950 
1118 
>10,000 
1321 
>10,000 
9372 
>10,000 
8878 
>10,000 
407 
39 
465 
60 

12 
16 (including crops) 
2 
18 (10 weeds) 
2 (1 weed) 
3 
5 
74 (58 weeds) 
5 (1 weed) 
2 (1 weed) 
15 
15 (14 weeds) 
3 
37 (9 weeds) 
2 
25 
2 
4 
14 (including crops) 
3 (1 weed) 
3 (1 weed) 
2 (1 weed) 
4 (1 weed) 
47 (including crops) 
14 (8 weeds) 
8 
2 (1 weed) 
3 (1 weed) 
18 (weeds) 
10 (9 weeds) 
3 (1 weed) 
4 (2 weed) 
12 (including crops) 
3 (1 weed) 
3 (1 weed) 
2 (1 weed) 

RGB 
HSI 
RGB 
RGB-D 
RGB 
RGB 
RGB 
RGB 
RGB 
RGB 
RGB 
RGB 
RGB 
Multimodal 
RGB 
RGB 
RGB-D 
RGB 
RGB 
MSI 
RGB 
RGB 
Multimodal 
RGB 
RGB 
RGB 
RGB 
MSI 
RGB 
RGB-NIR 
RGB 
RGB 
RGB 
RGB 
MSI 
MSI

Fig. 6. Example predictions by YOLOv8 trained on the Year 2021 data and tested the images from the same season (in-season) and trained on the Year 2022 data and 
tested on the Year 2022 data (cross-season). The percentage and label attached to each bounding box indicate the detection confidence and the predicted weed class, 
respectively. 

Fig. 7. Weed detection accuracies of YOLOX and YOLOv8 with and without I3Net-based domain adaptation (DA). In-season and cross-season metrics refer to the 
accuracies of models trained and tested on the data from the same and different seasons, respectively, and the error bar indicates the standard error over three 
modeling replications.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The primary hyperparameter settings for both YOLOX and YOLOv8 include a warm-up period followed by a cosine decay schedule for the learning rate. However, the specific details regarding the stopping criterion or convergence thresholds for determining when training is complete are not explicitly mentioned in this context. Typically, common practices involve monitoring the performance on a separate validation set during training and using various criteria such as early stopping based on validation loss plateaus, minimum validation loss, maximum validation accuracy, or a predefined number of epochs. Without additional information, it cannot be definitively stated what exact criteria were employed to decide when training was completed for these particular models.