Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 4 
Average performance (Avg) and standard deviation (SD) for five trained models. Average precision, recall and F1-score for trained ResNet50 and EfficientNetB3 
(EffNetB3) models modified for multitask learning (MTL) with transfer learning using pre-trained weights from ImageNet. The models are trained and validated on the 
TLm  dataset. The models ResNet50, EfficientNetB3 are trained without MTL.  

Model 

Level 

ResNet50MTL 
EffNetB3MTL 

ResNet50MTL 
EffNetB3MTL 

ResNet50MTL 
EffNetB3MTL 

ResNet50 
EffNetB3 

L1 Order 
L1 Order 

L2 Family 
L2 Family 

L3 Species 
L3 Species 

Species 
Species 

Avg 

0.990 
0.986 

0.987 
0.984 

0.955 
0.948 

0.955 
0.953 

Precision 

SD (10

(cid:0) 3) 

(1.0) 
(4.4) 

(0.8) 
(3.1) 

(4.3) 
(5.2) 

(3.3) 
(2.5) 

Avg 

0.991 
0.993 

0.986 
0.988 

0.961 
0.966 

0.957 
0.966 

Recall 

SD (10

(cid:0) 3) 

(1.1) 
(0.5) 

(0.9) 
(0.7) 

(9.8) 
(5.1) 

(7.3) 
(2.5) 

Avg 

0.991 
0.989 

0.987 
0.986 

0.957 
0.956 

0.955 
0.959

Appendix C. The training of the models 

The best model with transfer learning was chosen based on the minimum total loss after nine epochs, as seen in Fig. C.5. Note that we observe 
overfitting after nine epochs, where the validation loss starts to increase, although the bias is still very low. The increase is indicated by a higher 
difference between training and validation loss and bias is the loss evaluated on the training dataset. 

Note that the largest variation is 0.6%, which is very similar to the variation of 0.8% when training with different values of α in Fig. B.4. This 

indicates a minimal impact on the change of accuracy for different choices of α. 

References 

An, G., Akiba, M., Omodaka, K., Nakazawa, T., Yokota, H., 2021. Hierarchical deep 

learning models using transfer learning for disease detection and classification based 
on small number of medical images. Scient. Rep. 11 (1) https://doi.org/10.1038/ 
s41598-021-83503-7.

bounding boxes, in the training dataset, are within this size. Examples of 
full resolution TL images and cropped images of insects may be found in 
A.

EcologicalInformatics77(2023)1022782K. Bjerge et al.                                                                                                                                                                                                                                   

Table 1 
The nine different species of insects in the TLm  and GBIFm  datasets ordered by taxonomy used for training and validation. The splitting of the GBIFm  dataset is 
approximately 20% for validation and 80% for training. The splitting of the TLm  dataset is approximately 16% for validation and 84% for training.  

Order 

Family 

Species 

TLm 

GBIFm    

Training 

Validation 

Training 

Validation 

Coleoptera 
Diptera 
Diptera 
Diptera 
Hymenoptera 
Hymenoptera 
Hymenoptera 
Hymenoptera 
Lepidoptera 

Coccinellidae 
Syrphidae 
Syrphidae 
Syrphidae 
Apidae 
Apidae 
Apidae 
Vespidae 
Nymphalidae

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The table titled "Table 1" provides information about how the data was split for deep learning model training. For both the TLm and GBIFm datasets, the data was divided into two parts - one for training and another for validation. In the case of the TLm dataset, approximately 84% of the data was allocated for training while the remaining 16% was reserved for validation. Similarly, for the GBIFm dataset, around 80% of the data was utilized for training purposes, whereas the rest 20% was set aside for validation. However, there is no mention of any specific criterion or methodology employed for dividing the data into these subsets.