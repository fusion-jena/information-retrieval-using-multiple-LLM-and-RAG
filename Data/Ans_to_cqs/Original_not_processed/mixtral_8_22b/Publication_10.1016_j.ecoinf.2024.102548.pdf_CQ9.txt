Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Transfer learning is an efficient technique in deep learning that le-
verages  pre-trained  models  to  address  data  scarcity  and  accelerate 
model  training.  Our  study  employed  several  well-known  pre-trained 
models,  namely  MobileNet,  VGG-19,  EfficientNet,  ResNet-50,  Incep-
tionV3, and InceptionResNetV2, to harness their learned representations 
and adapt them to our specific classification task. These models have 
been extensively trained on large-scale datasets, allowing them to cap-
ture general features that are useful across various domains (Weiss et al., 
2016).  Transfer  learning  involves  two  main  phases:  fine-tuning  and 
feature extraction. In the feature extraction phase, the pre-trained model 
is used as a fixed feature extractor. The input image is passed through 
the modelâ€™s convolutional layers, and the output features are obtained. 
These features capture meaningful information from the image, forming

4.2. Data augmentation 

Data augmentation is a pivotal technique used to enhance the per-
formance  and  generalization  capability  of  deep  learning  models  by 
augmenting  the  training  dataset  with  artificially  generated  variations 
(Wu et al., 2017). Therefore, there are many augmentation techniques in 
the  literature  applied  especially  for  the  diagnosis  of  several  diseases 

EcologicalInformatics81(2024)1025485T. Chawla et al.                                                                                                                                                                                                                                 

Fig. 2. Okra Leaves: The top row shows diseased okra leaves, while the bottom row shows healthy okra leaves.  

Table 1 
Dataset split for Okra Leaves.  

Dataset 

Diseased Okra Leaves 

Healthy Okra Leaves 

Training Set 
Testing Set 
Validation Set 

885 
69 
143 

703 
69 
131

3.2.4. ResNet-50 

ResNet-50 is a widely used deep residual neural network architecture 
that addresses the challenges of training very deep networks. It employs 
residual blocks with skip connections to enable the flow of gradients and 
facilitate the training of deeper models. ResNet-50 has been pre-trained 
on  large-scale  datasets,  allowing  it  to  capture  complex  patterns  and 
achieve strong performance. 

3.2.5.

InceptionV3 

InceptionV3 is an advanced CNN architecture that incorporates the 
concept of inception modules. These modules utilize parallel convolu-
tions  of  different  kernel  sizes  to  capture  multi-scale  features.  Incep-
tionV3  has  been  pre-trained  on 
large-scale  datasets  and  has 
demonstrated  excellent  performance  in  various  image  classification 
tasks. 

3.2.6.

InceptionResNetV2

1.1. Organization 

The subsequent sections of this article follow the following structure: 
In Section 2, a thorough exploration of the related work in the field is 
presented. Section 3 outlines the Deep Learning Techniques employed in 
the study. The Materials and Methods used are detailed in Section 4. A 
comprehensive  comparison  of  the  performance  of  different  models  is 
discussed in Section 5.2. The obtained results and subsequent discussion 
are provided in Section 5. Finally, Section 6 concludes the study. 

2. Related work

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, I cannot provide a direct answer regarding where the data repository of the deep learning pipeline is available. There is no mention or reference to any specific data repositories such as Zenodo, Figshare, Dryad, or GBIF in the provided text. To find the relevant information, please refer to the original source or contact the authors directly.