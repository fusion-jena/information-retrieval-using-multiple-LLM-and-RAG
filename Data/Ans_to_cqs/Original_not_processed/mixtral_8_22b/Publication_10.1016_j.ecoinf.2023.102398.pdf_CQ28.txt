Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5.2. Deployment of the model 

The trained model is hosted and run in a cloud-based system. Cloud 
resident  camera  is  placed  in  the  Kohora  range  of  KNP.  The  images 
captured  by  the  camera  are  fed  into  the  model.  The  following  cloud 
computing infrastructure is used for the deployment of the system  

• Processor: Equivalent to intel core i9 7980XE @ 2.60 GHz  
• GPU: Tesla T4 GPU  
• Bandwidth: 1Gbps  
• Storage: 100GB  

• Latency: Maximum 50 ms  
• Secured wireless connectivity: WPA3  
• Cloud features: Scalable, resource pooling, secured, economic, etc.

next  section,  there  are  proven  approaches  based  on  CNN  models  for 
controlling  human-elephant  conflicts  and  saving  other  wild  animals’ 
lives  from  fatal  road  accidents.  To  train  a  CNN-based  model,  large 
datasets are required. Various groups of people are maintaining large 
datasets  of  wild  animals  that  can  be  used  for  training  a  specially 
configured CNN model to obtain better performance (Zhou et al., 2022). 
However, computation time and local resources required to train such 
approaches  are  high,  which  appears  to  be  a  major  limitation  of  such 
approaches. Hence, ample opportunities exist to design and configure 
fast cloud resident-modified CNN-based DL models with multiple cam-
era inputs for deployment around the critical infrastructure, including 
highways passing through important biological hotspots (like the NH-37 
passing through the KNP).

In  order  to  determine  more  accurate  training  results  and  also  to 
explore the effect of epoch upon training result, apart from 150 epochs, 
the model with attention layer is trained with epoch values 100, 200, 
and  250  under  a  uniform  training  environment  and  with  the  same 
dataset.  The  training  summary  for  each  of  these  epochs  is  shown  in 
Tables 5, 6 and 7 for epochs 100, 200, and 250, respectively. The trends 
of mAP values with increasing epochs are shown in Figs. 14 and Fig. 15. 
The size of the dataset used for custom training is sufficiently large. 
Further, the DL model used in this work is tuned with optimized hyper 
parameters  for  which  overfitting  and  under  fitting  situations  are  pre-
vented from occurring. As mentioned above, the effort to over-train the 
model has been avoided and graded MSE convergence (Figs. 7 to 11) has 
been  adopted  to  fine-tune  the  model.  Results  obtained  for  different

The training is done from scratch using GPU (Tesla T4) and CUDA 
Version-12.0 in Google Colab with the parameters (i) Input image size =
416, (ii) Batch size  = 16,  (iii) Epochs = 100, 150, 200  and 250, (iv) 
Weights  = Default  to yolov5.pt., (v) Data = custom data set  and (vi) 
Cache = True. 

EcologicalInformatics79(2024)10239811B. Bhagabati et al.                                                                                                                                                                                                                              

Fig. 11. Training Plots for the proposed model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, it is not explicitly stated which specific cloud computing platform or service provider (such as Amazon Web Services [AWS], Microsoft Azure, or Google Cloud Platform) was used to host and run the deep learning model. However, we do know that the model was deployed in a cloud-based system with certain hardware and network specifications, including an Intel Core i9 processor equivalent to the 7980XE running at 2.60 GHz, a Tesla T4 GPU, 1Gbps bandwidth, 100GB storage, maximum latency of 50ms, secure wireless connectivity via WPA3, and various cloud features like scalability, resource pooling, security, and cost-effectiveness. Additionally, the training process took place in Google Colab using a Tesla T4 GPU and CUDA Version-12.0. Nevertheless, without explicit mention of the cloud platform used for deployment, one cannot definitively state whether AWS, Azure, Google Cloud Platform, or another service provider was utilized.