Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.4. Sampling Method

The SPOT6 satellite data for our ﬁve study areas were preprocessed to be fed into the
different Deep Learning architectures and the XGBoost model. First, the data were split
into three mutually exclusive parts: a learning set, a validation set and a test set totally
independent of the two previous ones.

Four of the ﬁve areas were used for learning and validation. The last, isolated scene
was then used as the test set. It contained all the classes for the two nomenclatures, the ﬁve
LC classes, and the 12 LU classes. In addition, this image contained all the environments
representing the New Caledonian landscape: urban, mining, mountainous and forest
environment with variations from the coastline to the inland mountain areas. It is on this
entire scene that the ﬁnal confusion matrix and quality metrics were computed.

Remote Sens. 2021, 13, 2257

13 of 22

between 12 land type classes for the classiﬁcation, as described in the nomenclature in
Table 4. Table 8 presents the results of the LU classiﬁcation on the test area and Table A2, in
the Appendix, presents the results of the LU classiﬁcation on the four training areas.

Table 8. Results of Deep Learning architecture and XGBoost for the LU detection task with RGBNIR
as input.

Architectures

XGboost
AlexNet
ResNet
DenseNet
SegNet
DeepLab
FCN

OA

51.56%
45.79%
55.96%
59.59%
58.36
61.45%
56.07%

PA

42.61%
33.93%
43.89%
46.18%
37.16
49.77%
49.59%

UA

38.27%
38.26%
49.58%
55.00%
40.48
51.04%
47.22%

F1-Score

40.32%
35.97%
46.56%
50.21%
38.75%
50.40%
48.38%

All architectures were trained with stochastic gradient descent using a similar protocol,
with a momentum of 0.9 and starting from an initial learning rate of 10−2. Every 20 epochs,
the learning rate is divided by 10 until reaching 10−6.

Neural networks do not perform well when trained with unbalanced data sets [41]. In
the case of “central-pixel labeling” architectures it is possible to make balanced data sets
with the initial pixels selection used for the learning. In the case of “semantic labeling” the
composition of the images makes it more difﬁcult to precisely control the number of pixels
per class. We tried several methods, but found negligible differences in performance. All
reported experiments use the median frequency balancing method.

3.3.1. Central-Pixel Labeling

4.4. Confusion Matrix of the Best Deep Learning Model for LULC Classiﬁcation

The results of the best performing architecture for the LULC classiﬁcation task,
DeepLab, is detailed with two confusion matrices. Table 10 shows The LC classiﬁca-
tion task with the raw channels as input, and the LU classiﬁcation task with the LCE in
addition to the raw channels, is in Table 11. The resulting maps of the LU labelling task are
shown in Figure 9.

Table 10. Land cover confusion matrix of DeepLab.

Predicted

Buildings

Bare Soil

Forest

Low-Density Vegetation

Water Surfaces

Buildings
Bare soil
Forest
Low-density vegetation
Water surfaces

0.43
0.24
0.18
0.15
0

0
0.84
0.02
0.14
0

0
0.02
0.78
0.19
0.01

0
0.04
0.12
0.84
0

Table 11. Land use confusion matrix of DeepLab + LCM.

Predicted

s
a
e
r
A

l
a
i
r
t
s
u
d
n
I

0.32
0.43

0

0.18
0.01
0.03

0.02

s
a
e
r

A
n
a
b
r

U

0.72
0.03

0

0.05
0.01
0.06

0.09

0.04

0.01

0
0
0
0

0
0
0
0

d
n
a

s
e
t
i
s
k
r
o
W

s
e
n
i
M

0
0

0.86

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The data was split into three mutually exclusive parts: a learning set, a validation set, and a test set. Four of the five areas were used for learning and validation, while the remaining isolated scene was used as the test set. This independent test set contained all the classes for both nomenclatures and represented various environments such as urban, mining, mountainous, and forest landscapes. The final confusion matrix and quality metrics were computed based on this entire scene.