Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

12.282, and 13.897 for the validation (Fig. 5a-f). Table 3 lists the mean 
and standard deviation values of the NSE and RMSE driven by the 10- 
fold  cross-validation  of  the  deep  learning  models.  The  CNN  model 
with  the  autoencoder  showed  better  estimation  performance  for  TDI, 
BMI, and FAI than the CNN model estimation without the autoencoder

To  determine  the  optimal  data-driven  model,  the  conventional 
model performances were compared with the estimation performances 
of the CNN and the CNN with the autoencoder. The ANN model uses 
hidden nodes in hidden layers with learnable weights to extract input 
data. The principles of feature extraction and model training are similar 
to those of the autoencoder and CNN models. Six hidden layers were 
designed  with  128,  128,  256,  256,  512,  and  512  nodes.  The  output 
layers with three nodes estimated the three indices. The loss function 
and optimizer were set as the mean squared error and Adam optimizer, 
respectively, at a learning rate of 0.001. The SVM regression model was 
designed to estimate TDI, BMI, and FAI. The kernel function, C-param-
eter, and gamma of the SVM were set to radial basis functions of 100 and 
0.1, respectively. The SVM was unable to estimate the indices simulta-
neously. The RF uses an ensemble regressor by applying multiple deci-

2.4.2. Convolutional neural network 

CNN is a type of deep learning algorithm primarily used for image 
recognition and processing tasks (Chauhan et al., 2018). It’s composed 
of multiple layers, including convolutional layers that apply kernels to 
extract  features  from  input  images,  followed  by  pooling  layers  that 
reduce  the  spatial  dimensions  of  the  features.  CNNs  are  designed  to 
automatically learn hierarchical representations of data, making them 
highly effective for tasks like object detection, image classification, and 
even natural language processing (Khan et al., 2020). That is, the CNN 
architecture  was  designed  to  efficiently  process  complex  datasets 
(Alshehhi et al., 2017). Convolutional layers adopt internal kernel op-
erations that calculate nonlinear features using trainable weights and

Badrinarayanan, V., Kendall, A., Cipolla, R., 2017. Segnet: a deep convolutional encoder- 
decoder architecture for image segmentation. IEEE Trans. Pattern Anal. Mach. Intell. 
39 (12), 2481–2495. 

Baker, R.E., Pena, J.M., Jayamohan, J., J´erusalem, A., 2018. Mechanistic models versus 
machine learning, a fight worth fighting for the biological community? Biol. Lett. 14 
(5), 20170660. 

Bank, D., Koenigstein, N., Giryes, R., 2020. Autoencoders. arXiv preprint arXiv: 

2003.05991.  

Barzegar, R., Aalami, M.T., Adamowski, J., 2020. Short-term water quality variable 

prediction using a hybrid CNN–LSTM deep learning model. Stoch. Env. Res. Risk A. 
34 (2), 415–433. 

Beissinger, M., 2018. Deep generative networks for sequence prediction. arXiv preprint 

arXiv:1804.06546.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about which specific frameworks were used to build the deep learning models mentioned. However, it can be inferred that popular deep learning libraries such as TensorFlow or PyTorch could have been utilized due to their widespread use in building and implementing deep learning architectures like Convolutional Neural Networks (CNNs) and Autoencoders. These libraries offer essential tools and functionalities required for creating and training deep learning models, including support for various types of layers, optimization algorithms, and activation functions. Nonetheless, without concrete evidence from the given context, one cannot definitively state which particular frameworks were employed.