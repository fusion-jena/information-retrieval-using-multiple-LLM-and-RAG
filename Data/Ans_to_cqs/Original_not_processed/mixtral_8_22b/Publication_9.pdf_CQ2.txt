Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectifiers: 
Surpassing human- level performance on ImageNet classification. In 
2015 IEEE International Conference on Computer Vision (ICCV). IEEE.

He,  K.,  Zhang,  X.,  Ren,  S.,  &  Sun,  J.  (2016).  Deep  residual  learning  for 
image recognition. In Proceedings of the IEEE conference on computer 
vision and pattern recognition (pp. 770– 778).

Hubel,  D.  H.,  &  Wiesel,  T.  N.  (1962).  Receptive  fields,  binocular  inter-
action  and  functional  architecture  in  the  cat's  visual  cortex.  The 
Journal of Physiology, 160, 106– 154. https://doi.org/10.1113/jphys 
iol.1962.sp006837

Joly,  A.,  Bonnet,  P.,  Goëau,  H.,  Barbe,  J.,  Selmi,  S.,  Champ,  J.,  Dufour- 
Kowalski,  S.,  Affouard,  A.,  Carré,  J.,  Molino,  J.- F.,  Boujemaa,  N., 
&  Barthélémy,  D.  (2016).  A  look  inside  the  Pl@ntNet  experience. 
Multimedia  Systems,  22,  751– 766.  https://doi.org/10.1007/s0053 
0- 015- 0462- 9

Christin, S., Hervet, É., & Lecomte, N. (2019). Applications for deep learn-
ing  in  ecology.  Methods  in  Ecology  and  Evolution,  10,  1632– 1644. 
https://doi.org/10.1111/2041- 210X.13256

Deng, J., Dong, W., Socher, R., Li, L.- J., Li, K., & Fei- Fei, L. (2009). Imagenet: 
A large- scale hierarchical image database. In 2009 IEEE conference 
on computer vision and pattern recognition (pp. 248– 255). IEEE.
Dutta, A., Gupta, A., & Zissermann, A. (2016). VGG image annotator (VIA). 
Retrieved from http://www.robots.ox.ac.uk/~vgg/softw are/via
Felleman, D. J., & Van Essen, D. C. (1991). Distributed hierarchical pro-
cessing  in  the  primate  cerebral  cortex.  Cerebral  Cortex  (New  York, 
NY: 1991), 1(1), 1– 47.

Firestone,  C.  (2020).  Performance  vs.  competence  in  human– machine 
comparisons.  Proceedings  of  the  National  Academy  of  Sciences 
of  the  United  States  of  America,  117,  26562– 26571.  https://doi.
org/10.1073/pnas.19053 34117

lack  of  readily  available  image  datasets  with  high- resolution  image 

We then discuss the strengths and limitations of our approach for 

segmentation mask annotations limits how biologists can accessibly 

processing fish images and consider how this approach can be ex-

engage with deep learning applications to rapidly process images for 

tended to other branches of the tree of life.

SCHWARTZ And ALFARO 2041210x, 2021, 12, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13712 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License2344  |    Methods in Ecology and Evolu(cid:13)on

2 |  M ATE R I A L S A N D M E TH O DS

gamut of fish images— similar to the Gray et al. (2019) implementa-

overarching  goal  of  training  a  neural  network  is  to  iteratively  min-

tional  training.  The  utility  of  pre- trained  CNNs  out- of- the- box  is 

imize the error between model output and expected output by op-

constrained by how relevant the novel input data are to the data the 

timally  adjusting  model  weights  and  reaching  model  convergence, 

CNN  was  originally  trained  on.  For  instance,  ImageNet  comprises 

such that the trained neural network generalizes well to novel input 

more  than  14  million  high- resolution  images  across  nearly  22,000 

data. Model weights are adjusted to minimize error on each subse-

categories and is often used as a starting point for recognition tasks 

quent run using an algorithm called stochastic gradient descent with 

with deep learning (Deng et al., 2009; Krizhevsky et al., 2017). Using 

backpropagation  (LeCun  et  al.,  1989;  Rumelhart  et  al.,  1995).  This

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not explicitly mention the specific data formats used in the deep learning pipeline. However, it can be inferred that one of the primary data formats used is high-resolution images, as mentioned in several sources such as He et al. (2015, 2016), Deng et al. (2009), and Firestone (2020). Additionally, the context mentions the use of ImageNet, which is a dataset containing millions of labeled images. Therefore, we can conclude that high-resolution images are a significant data format used in the deep learning pipeline discussed in the given context.