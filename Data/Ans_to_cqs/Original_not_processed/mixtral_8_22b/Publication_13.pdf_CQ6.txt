Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

LeCun, Y., Bengio, Y. & Hinton, G. (2015) Deep learning. Nature, 521(7553),
436–444. Available from: https://doi.org/10.1038/nature14539
Mukhoti, J., Kulharia, V., Sanyal, A., Golodetz, S., Torr, P.H.S. & Dokania, P.
K. (2020) Calibrating deep neural networks using focal loss. Advances
in Neural Information Processing Systems, 33, 15288–15299. Available
from:
https://proceedings.neurips.cc/paper/2020/hash/aeb7b30ef
1d024a76f21a1d40e30c302-Abstract.html

Noguerales, V., Meramveliotakis, E., Castro-Insua, A., Andújar, C.,
Arribas, P., Creedy, T.J. et al.
(2021) Community metabarcoding
reveals the relative role of environmental filtering and spatial pro-
cesses in metacommunity dynamics of soil microarthropods across a
mosaic of montane forests. Molecular Ecology in press. Available
from: https://doi.org/10.1111/mec.16275

imaging procedure. An algorithm for domain adaptation, domain adversarial training of neural

networks (DANN), significantly improved the prediction performance of models trained by

non-standardized, low-quality images. Our findings demonstrate that existing databases can

be used to train models and successfully classify images from unexplored biota, but the imag-

ing conditions and classification algorithms need careful consideration.

K E Y W O R D S
biodiversity assessment, bulk sample, coleoptera, convolutional neural network, domain adaptation,
image classification, machine learning

I N T R O D U C T I O N

Biological

identifications

increasingly rely on machine learning

algorithms that use photographic images to place unidentified speci-

Tomochika Fujisawa and Víctor Noguerales contributed equally to this study.

mens into a taxonomic classification. As these methods are proving to

training was done using taxon labels from the source images and data-

training images on prediction accuracy, whereby the CNN model was

trained with N images randomly selected from the dataset and predicted

the class (family label) of n test images randomly selected from the rest.

N ranged between 100 and 700 for LH (with intervals of 100 images),
between 50 and 250 for LL (with intervals of 50 images) and between
100 and 900 for GH (with intervals of 100 images). The number of test
images n was set to 200 for LH and GH, and 50 for LL due to the small
size of the dataset. To evaluate the consistency of prediction accuracy,

Local low quality (LL) dataset

of 0.6. The neural network was trained with the stochastic gradient

descent algorithm with the softmax cross-entropy loss for 300 epochs.

We used a batch size of 10 and a fixed learning rate of 0.01, and the

convergence of loss was visually assessed. The numbers of units in the

A subset of single specimens (taken from the bulk samples) were indi-

two FC layers (512 and 256 for the first and second FC layers, respec-

vidually photographed using a conventional stereoscope NIKON

tively) and the dropout rate were determined by five-fold cross-

SMZ1270i equipped with a NIKON DS-Fi3 Microscope Camera (5.9

megapixels) controlled by the NIKON DS-L4 v.1.5.0.3 control unit.

These images were denoted Local Low Quality (LL) dataset. These pho-
tographs were intended to represent a more realistic scenario of local

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention any specific preprocessing steps taken before training the deep learning model. However, it is common practice in deep learning applications to perform various preprocessing techniques such as image resizing, normalization, augmentation, or noise reduction depending on the nature of the input data. In this case, since the datasets consist of images, some possible preprocessing steps could include converting color images to grayscale, rescaling pixel values to a certain range (like [0, 1] or [-1, 1]), applying histogram equalization, or performing geometric transformations like rotation, flipping, or cropping. Additionally, if there are missing or corrupted images in the dataset, they may be removed or replaced with alternative data points. It should also be noted that the choice of preprocessing technique depends on factors such as computational resources available, desired level of complexity, and the characteristics of the target task.