Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To address the problem of unbalanced training data, scholars have 
explored  various  sampling  techniques,  including  major  category

92.50 
100.00 
96.10 
52.50 
72.41 
60.87 
70.00 
96.55 
81.16 
75.00 
93.75 
83.33 

89.08 
92.98 
90.99 
66.39 
88.76 
75.96 
37.82 
88.24 
52.94 
76.47 
96.81 
85.45 

87.04 
93.07 
89.95 
60.19 
61.32 
60.75 
50.93 
68.75 
58.51 
52.78 
91.94 
67.06  

90.67 

88.51 

62.00 

52.45 

64.33 

55.10 

73.83 

67.21 

Fig. 10. Spatial comparison of land categories between classification results from EXP5, CNLUCC-2020, CLCD-2020 and Globeland30–2020. 
Note: EXP5: SSA-TPRF model based on SSA; CNLUCC-2020: LULC of CNLUCC in 2020; CLCD-2020: LULC of CLCD in 2020; Globeland30–2020: LULC of Globeland30 
in 2020.

5.5. Limitations 

Similar to other research endeavours, this study encountered various 

constraints. Suggestions for subsequent studies are also provided.

Fig.  7. Comparison  between  classification  results  from  EXP1,  EXP2,  EXP3, 
EXP4 and EXP5 by OA and Kappa. 
Note:  EXP1:  Overall  model  based  on  PBA;  EXP2:  Tile  model  based  on  PBA; 
EXP3:  Overall  model  + Multiple  probabilistic  classification  model  based  on 
PBA; EXP4: Tile model + Multiple probabilistic classification model based on 
PBA; EXP5: SSA-TPRF model based on SSA. 

presented in Section 4.2, the OA of EXP3 (85.19%), based on the mul-
tiple  probabilistic  classification  model,  surpassed  that  of  EXP1 
(84.99%),  based  on  the  single-image  hard-classification  model.  Our 
research reaffirms the efficacy of the multiple probabilistic classification 
model for enhancing the LULC classification mapping accuracy. Similar 

Fig. 9. Comparison between classification results from six types of tile size by 
OA and Kappa. 

Fig. 8. Spatial comparison of land categories between classification results from EXP1, EXP2, EXP3, EXP4 and EXP5.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide information about the specific criteria used to determine when training is completed. However, common criteria include reaching a certain number of epochs or iterations, achieving a desired level of performance on a validation set, observing a plateau in the validation loss, or meeting some predefined threshold for a metric such as accuracy or F1 score. These criteria can vary depending on the specific machine learning task and dataset being used.

The context mentions several experiments (EXP1 through EXP5) using different models and methods for Land Use/Land Cover (LULC) classification mapping. It also includes figures comparing the results of these experiments using metrics like overall accuracy (OA) and Kappa coefficient. However, it does not explicitly state what criteria were used to determine when each experiment was considered complete. Therefore, I cannot provide a definitive answer to the query based solely on the given context.