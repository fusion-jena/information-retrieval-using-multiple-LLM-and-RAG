Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

kernel to expand without increasing the number of parameters [39]. This expansion of the
window is controlled by the dilation rate and it enables the network to capture information
from a larger receptive ﬁeld of view with the same parameters and computational complex-
ity as the normal convolution. The combination of spatial pyramid pooling with Atrous
convolutions resulted in an efﬁcient multi-scale processing module called Atrous spatial
pyramid pooling (ASPP). In the earlier version (DeepLabV3) [40], the last ResNet block of
the modiﬁed ResNet-101 uses different Atrous convolutions with different dilation rates.
ASPP, together with bilinear up sampling, is also used on top of the modiﬁed ResNet block.
DeepLabv3+ is an improvement in the previous version by adding an effective decoder
module to improve the boundaries of the segmentation results [41]. Furthermore, apart
from ResNet-101, an Xception model can be used as a feature extractor while applying a

as a feature [13]. As the study showed, they require a large training sample to maintain a
good performance of their approach.

Training procedure—We adapted a pre-trained VGG16 network that is a CNN trained
on the ImageNet dataset and used for transfer learning on our dataset [51]. We froze
earlier layers of the base version of the network to make them non-trainable and added an
extra max-pooling layer before the fully connected layers to reduce the dimension of the
previous layer. The feature vector of the fully connected layer was reduced from 2048 units
of the original VGG16 to 128 units, which helped in reducing the computational complexity
without sacriﬁcing much on performance. The model was implemented using Keras with
TensorFlow backend [52].

good and (not so) bad sources of morphological data. Methods Ecol. Evol. 2020, 11, 1296–1308. [CrossRef]

24. White, A.E.; Dikow, R.B.; Baugh, M.; Jenkins, A.; Frandsen, P.B. Generating segmentation masks of herbarium specimens and a

data set for training segmentation models using deep learning. Appl. Plant Sci. 2020, 8, e11352. [CrossRef]

25. Wu, P.; Li, W.; Song, W. Segmentation of Leaf Images Based on the Active Contours. Int. J. e-Serv. Sci. Technol. 2015, 8, 63–70.

[CrossRef]

26. Coussement, J.R.; Steppe, K.; Lootens, P.; Roldan-Ruiz, I.; de Swaef, T. A ﬂexible geometric model for leaf shape descriptions with

high accuracy. Silva Fenn. 2018, 52, 1–14. [CrossRef]
Janwale, A.P.; Lonte, S.S.A. Plant Leaves Image Segmentation Techniques: A Review. Int. J. Comput. Sci. Eng. 2017, 5, 147–150.

27.
28. Corney, D.P.A.; Clark, J.Y.; Tang, H.L.; Wilkin, P.; Tang, H.L.; Wilkin, P.; Tang, H.L.; Wilkin, P. Automatic extraction of leaf

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, some general approaches to handling data imbalance or bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets such that each subset maintains the class distribution of the overall dataset. Oversampling increases the size of minority classes by duplicating samples, while undersampling reduces the size of majority classes by removing samples. These methods help balance the dataset and prevent the model from being biased towards the majority class.

Diverse data collection aims to gather a wide range of examples representing various scenarios, conditions, and variations within the target domain. By collecting diverse data, the model can learn more robust features and become less sensitive to noise or outliers.

In summary, although the given text does not mention any specific technique used to handle data bias, common strategies include stratified splitting, oversampling, undersampling, and diverse data collection.