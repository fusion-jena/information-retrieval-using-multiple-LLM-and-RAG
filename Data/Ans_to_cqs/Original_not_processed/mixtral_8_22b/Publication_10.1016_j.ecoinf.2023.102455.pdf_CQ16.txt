Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

MVMD-KELM 

MVMD-CNN-BiRNN 

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

MVMD-CNN-BiGRU 

MVMD-RVFL 

MVMD-KELM 

MVMD-CNN-BiRNN 

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

Phase 

Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 

R 

0.985 
0.955 
0.918 
0.944 
0.904 
0.928 
0.998 
0.943 
0.903 
0.811 
0.844 
0.783 
0.845 
0.803 
0.895 
0.815 
0.998 
0.924 
0.907 
0.921 
0.904 
0.887 
0.998 
0.911 
0.778 
0.545 
0.623 
0.509 
0.682 
0.525 
0.839 
0.496 

RMSE 

MAPE 

0.179 
0.247 
0.364 
0.257 
0.395 
0.289 
0.072 
0.289 
0.398 
0.432 
0.492 
0.497 
0.491 
0.459 
0.410 
0.429 
0.022 
0.330 
0.386 
0.296 
0.397 
0.387 
0.070 
0.320 
0.619 
0.706 
0.717 
0.654 
0.671 
0.639 
0.511 
0.629

CNN-BiGRU 

RVFL 

KELM 

CNN-BiRNN 

Phase 

Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 
Training 
Testing 

R 

0.985 
0.960 
0.960 
0.949 
0.972 
0.930 
0.999 
0.955 
0.921 
0.698 
0.865 
0.662 
0.843 
0.668 
0.873 
0.689 
0.998 
0.933 
0.952 
0.930 
0.964 
0.928 
0.997 
0.929 
0.792 
0.603 
0.826 
0.594 
0.783 
0.591 
0.801 
0.598 

RMSE 

0.072 
0.098 
0.117 
0.113 
0.100 
0.130 
0.024 
0.105 
0.164 
0.253 
0.210 
0.266 
0.225 
0.263 
0.205 
0.256 
0.010 
0.130 
0.128 
0.130 
0.112 
0.133 
0.024 
0.141 
0.256 
0.284 
0.236 
0.287 
0.261 
0.287 
0.251 
0.285 

MAPE

3.3. Machine learning tuning

2.9. Statistical criteria 

This section introduces six expert statistical criteria to evaluate the 
merit  of  the  forecasting  model  mathematically.  The  aforementioned 
metrics  include  the  coefficient  (R),  root  mean  square  error  (RMSE), 
Kling-Gupta efficiency (KGE) (Gupta et al., 2009), Reliability, Squared 
Chi-square  Distance  (SquD),  and  mean  absolute  percentage  error 
(MAPE).  The  following  are  the  mathematical  formulations  of  metrics 
(Jamei et al., 2021): 

MAPE =

∑N
i=1

1
N

⃒
⃒
⃒
⃒

Qobs,i (cid:0) Qfor,i
Qobs,i

⃒
⃒
⃒
⃒ × 100

¯

¯

Qobs  and 

where Qobs,i  and Qfor,i  are the values for the observed and forecasted Q 
values, respectively. 
Qfor  are averaged values of observed and 
forecasted  streamflow  values.  The  variable  Ki  is  the  number  of  time 
intervals  where  the  qualified  forecast’s  threshold  value  (δ)  equals  or 
exceeds the RAE value. According to Chinese law, the δ value has been 
set at 20%.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide explicit information on the specific criteria used to determine when training is completed. However, based on common machine learning practices, some possible criteria could be:

1. Validation Loss Plateau: Training can be considered complete when the validation loss stops decreasing significantly with each epoch. This indicates that the model has learned all it can from the data and further training may lead to overfitting.

2. Maximum Number of Epochs: Training can also be stopped after a certain maximum number of epochs have been reached. This prevents unnecessary computation if the model has already converged.

3. Early Stopping: This technique involves monitoring the performance of the model on a separate validation set during training. If the performance on the validation set starts to degrade, even though the training loss continues to decrease, then training is halted. This helps prevent overfitting.

4. Learning Rate Schedule: Some models use a learning rate schedule, which reduces the learning rate as training progresses. When the learning rate reaches a minimum threshold, training can be considered complete.