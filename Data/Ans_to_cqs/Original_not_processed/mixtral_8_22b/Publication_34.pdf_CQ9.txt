Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

capacity: they have accumulated around three hundred thousand ﬁnely geolocated
plant species observations just in France during last decade. Citizen programs
in biodiversity sciences are currently developing worldwide. We expect them to
reach similar volumes of observations to the sum of national museums, herbaria
and conservatories in the next few years, while still maintaining a large ﬂow of
observations for the future. With good methods for dealing with sampling bias, those
ﬁne precision and large spatial scale data will make a perfect context for reaching
the full potential of deep learning SDM methods. Thus, NN methods could be a
signiﬁcant tool to explore biodiversity data and extract new ecological knowledge
in the future.

10.3.2 Species Selection

For the genericity of our results and to make sure they are not biased by the choice
of a particular category of species, we have chosen to work with a high number of
randomly chosen species. From the 7626 initial species, we selected species with
more than 300 observations. We selected amongst those a random subset of 1000
species to constitute an ensemble E1000. Then, we randomly selected 200 species
amongst E1000 to constitute E200, and ﬁnally randomly selected 50 in E200 which

10 A Deep Learning Approach to Species Distribution Modelling

183

gave E50. E50 being the main dataset used to compare our model to the baselines, we
provide in Fig. 10.1 the list of species composing it. The full dataset with species
of E1000 contains 6,134,016 observations in total (see Table 10.1 for the detailed
informations per species).

10.3.3 Environnemental Data

=

SNN, DNN and CNN models are ﬁtted with the package mxnet: All model
0.03, 0.03), then we
parameters were initialized with a uniform distribution U (
applied a stochastic gradient descent algorithm with a momentum of 0.9, a
batch-size of 50 (batch samples are randomly chosen at each iteration), and an initial
8. The choice of initial learning rate was critical for a good
learning rate of 10−
optimization behavior. A too big learning rate can lead to training loss divergence,

−

190

C. Botella et al.

whereas when it is too small, learning can be very slow. We stopped when the
average slope of the training mean loss had an absolute difference to 0 on the last 100
3. The learning took approximately 5 min for SNN, 10 min for
epochs inferior to 10−
DNN, and 5 h for CNN (independently of the version).

10.3.5 Evaluation Metrics

25
Natural grasslands: clc
Moors: clc

∈ {
}
∈ {

188, 4672

∈ {
∈ {

27
}

∈ {
24

1, 10

∈ {

∈ {

∈ {

26

23

}

}

}

}

}

}

}

]

Resolution
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
3
30
30
30

}

30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30

(continued)

10 A Deep Learning Approach to Species Distribution Modelling

187

Table 10.2 (continued)

Name
sclero
transi_wood
no_veg
coastal_area
ocean

Description
Sclerophyllous vegetation: clc
∈ {
Transitional woodland-shrub: clc
No or few vegetation: clc
Coastal area: clc
Ocean surface: clc

∈ {

∈ {

44

31, 32

37, 38, 39, 42, 30

28
}
29
∈ {
}

}

∈ {

}

}

Nature
bool.
bool.
bool.
bool.
bool.

Values
0, 1
}
{
0, 1
}
{
0, 1
}
{
0, 1
}
{
0, 1
}
{

Resolution
30
30
30
30
30

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about where the data repository of the deep learning pipeline is available. It only mentions that the authors worked with a high number of randomly chosen species from an initial set of 7626 species, selecting species with more than 300 observations and creating subsets E1000, E200, and E50. However, there is no mention of where this data is stored or made publicly available. Therefore, I do not know where the data repository of the deep learning pipeline is available.