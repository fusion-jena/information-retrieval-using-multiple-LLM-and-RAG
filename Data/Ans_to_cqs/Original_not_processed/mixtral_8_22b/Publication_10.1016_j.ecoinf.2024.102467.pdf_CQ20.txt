Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EfficientnetV2 is an efficient, lightweight feature extraction network. 
The  EfficientNet  series  comprises  a  set  of  lightweight  convolutional 
neural networks. In the EfficientNetV1 series, Google’s focus was pre-
dominantly on optimizing the accuracy, parameter count, and compu-
tational  requirements  of  the  model  (Tan  and  Le,  2019).  The 
EfficientNetV2  series  further  reduces  the  number  of  parameters  and 
computations  while  preserving  the  accuracy  of  the  model,  leading  to 
significant  decreases  in  model  training  and  inference  duration. 
Furthermore, the EfficientNetV2 network uses an improved progressive 
learning approach that dynamically adjusts the regularization method 
based on the training image size. This method can improve the training 
speed  and  accuracy  of  the  network.  Compared  with  some  previous 
networks, the experimental results of this method show that the training

computational  complexity,  which  can  reduce  the  consumption  of 
computing  resources  during  the  training  process.  In  the  experiments 
conducted  in  this  study,  under  the  same  training  environment  and 
epoch, the algorithm was trained on an RTX 3090 for 6 h. The video 
memory usage was 12 G. The training time of the original YOLOv5 al-
gorithm was 12 h. The video memory usage was 17.1 G. Fig. 10 visually 
compares the parameter quantities and detection efficiency between the 
two models. The significant reduction in model size and inference time 
indicates that the model in this study is more suitable for deployment in 
agricultural embedded devices.

speed is increased by 11 times, and the number of parameters is reduced 
by  1/6.8  (Tan  and  Le,  2021).  Based  on  this  network,  we  designed  a 
backbone  to  improve  the  training  speed  of  the  model  while  ensuring 
detection accuracy and speed.

EfficientnetV2 utilizes fused-MBConv blocks (Tan and Le, 2021) to 
improve the training speed further. Although the computational cost of 
the  Depthwise  Conv  in  the  MBConv  block  is  theoretically  small,  in 
practice, using MBConv blocks with vast amounts of Depthwise Conv 
structures in the shallow layers of the backbone during training will lead 
to  a  decrease  in  training  speed  because  current  training  accelerators 
have not optimized this structure. In the fused-MBConv block, the 1 × 1 
Conv and Depthwise Conv3x3 used to increase the dimensionality in the 
MBConv block are replaced with a 3 × 3 Conv used for dimensionality 
increase. Fig. 2(b) shows the fused MBConv block. Testing showed that 
using  Fused-MBConv  blocks  in  the  shallow  layers  of  the  network 
significantly improved the training speed of the model. Based on this,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, it is mentioned that the algorithm was trained on an RTX 3090 GPU for 6 hours. Additionally, the video memory usage was 12 GB. Therefore, it can be concluded that the hardware resource used for training the deep learning model in this case was a GPU, specifically an NVIDIA GeForce RTX 3090 graphics card. No mention of other types of hardware resources such as TPUs or CPUs was made in the provided context.