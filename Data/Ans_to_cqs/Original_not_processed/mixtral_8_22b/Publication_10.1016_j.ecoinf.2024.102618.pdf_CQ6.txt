Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.7. Performance metrics 

In this work, we measure the accuracy of the deep-learning models 

by using the following metrics:  

• Accuracy 

accuracy which is a simple metric for deep-learning classification 
models. This metric measures the overall percentage of correct pre-
dictions. However, accuracy does not take into account the different 
types  of  errors.  That  is  the  reason  we  employ  other  metrics  for 
measuring the efficiency of deep learning models. 

Accuracy =

TP + TN
TP + TN + FP + FN

• Precision 

(1)    

Precision  is  a  metric  that  measures  the  number  of  positive  pre-
dictions  that  are  actually  correct  viz.  a  viz.  correct  and  incorrect 
positive predictions. 

recall is a metric that measures the number of positive predictions 
that are actually correct viz. a viz. correct positive predictions and 
incorrect negative predictions. Recall measures how many positive 
predictions were correctly spotted by the model. 

Recall = TP

TP + FN

3. Methodology 

The  approach  proposed  in  this  work  can  be  explained  as  follows. 
First, the dataset is balanced using the class-weighted technique. This 
step is important as the deep learning models have a bias towards classes 
with  a  large  number  of  images.  This  needs  to  be  solved  using  a  data 
balancing technique. Also, the data imbalanced in the proposed dataset 
is small hence a simple algorithm like class-weighted is proposed. Then a 
novel image pre-processing technique is proposed. A number of different 
models from the state-of-the-art deep learning models are tested. The 
results  of  the  five  best  models  are  reported.  Also,  different  ensemble 
models are tested and compared. The results show that ensemble models 
can increase the accuracy of the classification hence introducing more 
stable models. 

Table 1 
Related Work comparison.  

ref 

contribution 

disadvantages 

accuracy 

(Anandhakrishnan 
and Jaisakthi, 
2022)

Different  deep  learning  models  are  tested  to  find  the  model  with  the 
highest accuracy. The results show that EfficientNet achieves the highest 
accuracy.  A  data  augmentation  technique  is  added  to  increase  the 
number  of  images  from 55,448  to  61,486  images.  Results  of  the  pro-
posed deep learning models on the dataset with and without augmen-
tation  are  reported. This  work  augments  the  dataset using a  complex 
data augmentation technique to produce a new dataset. However, in our 
proposed work we use an augmented version of PlanVillage that can be 
used by different researchers for comparison. Also, we propose using a

NS 

1851 
1926 
1692 
2010 
2022 
1736 
1824 
1908 
1920 
1745 
1642 
1774 
1728 
2016 
1961 
1702 
1987 
1816 
1683 
1838 
1760 
1827 
1988 
1722 
1939 
1790 
1824 
2008 
1888 
1939 
1826 
1907 
1920 
1781 
1882 
1741 
1913 
1859  

provide crystal-clear images for further examination. The added image 
enhancement  technique  enabled  the  proposed  systems  to  reach  high 
accuracy values. 

This  dataset  is  used  after  these  pre-processing  steps  with  the  sug-
gested models. Table 3 presents a comparison between different trained 
deep learning models proposed in this paper. The table shows the five 
different  deep  learning  models  chosen  for  this  application  and  their 
reported  accuracy  and  F1-score.  The  table  also  shows  ten  different 

Table 3 
Comparison between different trained deep learning models proposed.  

model 

Accuracy

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, several preprocessing steps may be involved depending on the specific requirements of the task and the nature of the input data. These steps aim to prepare the data in a suitable format for efficient processing and accurate prediction. Some common preprocessing techniques include:

1. Normalization: This involves rescaling the input features so they fall within a specified range or distribution. For example, min-max normalization scales each feature to lie between 0 and 1, while z-score normalization transforms the data to have zero mean and unit variance. Normalization helps ensure that all features contribute equally to the learning process and prevents any single feature from dominating due to its scale.

2. Scaling: Similar to normalization, scaling adjusts the magnitude of input features but typically focuses on preserving relative differences rather than absolute values. Common scaling methods include logarithmic scaling, power transformation, and standardization. Scaling can help improve convergence during optimization and reduce sensitivity to initial parameter settings.

3. Cleaning: Data cleaning involves identifying and handling missing, invalid, or inconsistent entries in the dataset. Techniques such as imputation (filling gaps with estimated values), outlier detection, and noise reduction can help maintain data integrity and prevent biased or erroneous outcomes.

4. Augmentation: Data augmentation generates additional samples by applying various transformations to existing instances, such as rotation, flipping, cropping, or adding noise. Augmentation can enhance model robustness and generalization by exposing it to diverse variations of the same underlying patterns.

5. Encoding: Categorical variables need to be converted into numerical representations before being fed into most machine learning algorithms. One-hot encoding and label encoding are popular approaches for mapping discrete categories onto continuous vectors.

In the given context, the authors mention balancing the dataset using the class-weighted technique and proposing a novel image pre-processing technique. However, they do not provide explicit details about these procedures or discuss other potential preprocessing steps. Therefore, based solely on the information available, one cannot definitively determine what specific preprocessing steps are involved before training the deep learning models in this study.