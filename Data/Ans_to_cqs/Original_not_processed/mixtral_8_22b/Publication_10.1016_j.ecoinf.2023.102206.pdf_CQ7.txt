Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

are  highly  different 

each  other 

from 

Table 4 
Input Parameters.  

Feature 

Input Parameter 

1 

2 

3 

4 

CO2 emissions due to gaseous fuel consumption 
(% of total) 
CO2 emissions due to liquid fuel consumption 
(% of total) 
CO2 emissions due to solid fuel consumption 
(% of total) 
CO2 emissions (in metric tons per capita)  

2  Benchmark datasets are investigated for ML methodologies where training 
and  testing  data  are  drawn  from  same  distribution.  The  proposed  IFTL  is  a 
generic  approach  based  on  the  principle  of  transfer  learning  which  may  pri-
marily  work  in  any  real-world  application  with  training  and  testing  domains 
having different data distributions. 

Table 5 
Output Parameters.  

Feature 

Output 

Output Parameters 

GDP per capita (at current US$)  

and target domains are collected from the World Bank database of the 
EU and India (http://data.worldbank.org/).

Further  discussions  analyze  IFTL  and  FTL  for  their  abilities  to 
improve learning by restricting overconfidence (controlling hesitancy) 
during TL by considering GRNN and SVR as the TUR. Overconfidence in 
ELM,  GRNN,  or  SVR  arises  when  they  make  predictions  on  a  dataset 
(target  domain) that has a huge data distribution difference from the 
source domain data on which they are trained. In this scenario, they just 
use their training experience to make predictions during testing without 
considering the distribution divergence in the testing dataset from the 
training  dataset.  We  conclude  this  section  with  the  execution  time 
analysis of the approaches.  

a)  GDP prediction using only CO2 emission data2

This  tightly  coupled  relationship  between  CO2  emission  and  GDP 
motivated us to predict the GDP of a nation using its carbon emission. 
However,  the  available  dataset  of  some  countries  is  not  sufficient 
enough to train a machine learning (ML) model. To overcome this lim-
itation,  this  paper  proposes  a  novel  transfer  learning  methodology. 
Transfer  learning  (TL),  a  machine  learning  (ML)  technique,  utilizes 
previously learned information to resolve new tasks, more specifically, 
related tasks. In conventional ML techniques, every new task is learned 
from the scratch (Che et al., 2021), and the training and test data are 
drawn from the same distribution. However, if the data distribution is 
changed between the training and test data, the performance and reli-
ability  of  the  predicted  output  may  degrade  significantly  (Lu  et  al., 
2019). This may also lead to high computational costs and inappropriate

We have found that the proposed approach efficiently captured the 
uncertainty produced by extreme variations in data distribution or the 
predictive tasks across the source and target data. It suitably restricted 
overconfidence  for  better  learning  while  transferring  the  learned 
knowledge. IFTL outperformed FTL, where the training and testing do-
mains (including labels) have huge data distribution differences. This 
validated  the  effectiveness  of  hesitancy  in  restricting  overconfidence 
during TL. IFTL is also thoroughly analyzed for its asymptotic compu-
tational complexity and execution time. The limitation of IFTL is that it 
adds  additional  computation  by  calculating  membership,  non- 
membership,  hesitancy  margin  of  each  feature,  and  the  distance 
metric for refining the output labels predicted by other ML approaches. 
This  work  has  successfully  demonstrated  the  utility  of  ecological

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide explicit details about how the data was split for deep learning model training. However, we can infer that the data was divided into training and testing sets. According to Table 4, input parameters such as CO2 emissions due to gaseous, liquid, and solid fuel consumption were considered for the analysis. These features might be used to train the deep learning models. Furthermore, the text mentions that benchmark datasets are investigated for ML methodologies where training and testing data are drawn from the same distribution. This suggests that the data could have been randomly split into training and testing sets, maintaining the same distribution. Additionally, the context discusses the use of transfer learning, which involves utilizing previously learned information to solve new related tasks. This implies that there might be separate source and target domains, possibly requiring further splitting of the data. Nonetheless, specific criteria for splitting the data, such as percentage allocations for train, test, and validation sets, are not mentioned in the given context.