Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1. Hyperparameter ﬁne-tuning results.

Scenario Number of Blocks Number of Filters

Learning Rate Mean IoU Accuracy

1
2
3
4
5
6
7
8
9
10

3
4
5
6
4
4
4
4
4
4

64 , 64, 64
64, 64, 64, 64
64, 64, 64, 64, 64
64, 64, 64, 64, 64, 64
16, 32, 64, 128
32, 64, 128, 256
64, 128, 256, 512
16, 32, 64, 128
16, 32, 64, 128
16, 32, 64, 128

0.001
0.001
0.001
0.001
0.001
0.001
0.001
0.01
0.0005
0.00001

0.30
0.38
0.36
0.32
0.42
0.38
0.31
0.008
0.42
0.39

82%
89%
86%
86%
94%
88%
84%
71%
94%
90%

Scenario 5 was selected as the optimal solution as it had the best values for IoU and accuracy
while training on fewer epochs. The resulting architecture is shown in Figure 4 and described in
the following.

2.5.1. Encoding Path

Figure 4. U-net architecture (experimental setup with 3 encoding blocks).

Remote Sens. 2019, 11, 1976

6 of 14

Figure 5. Loss function of the model (training and validation).

2.4. Evaluation Metrics

To assess the performance of the neural network, several evaluation metrics were used. Evaluation
metrics were computed during the forward pass, and were not subject to maximization, but were
rather used as a performance indicator. This helped to optimize the hyperparameters of the model.
In this study, we used a custom implementation of the intersection over union metric. It computes the
intersection of the reference dataset and the predicted classiﬁcation and divides it by the union of the
two (Equation (1)). In addition, we calculated the overall accuracy of the model (Equation (2)).

IoU =

TP
TP + FP + FN

Accuracy =

TP + TN
TP + FN + FP + TN

(1)

(2)

where TP, TN, FP, and FN are true positive, true negative, false positive, and false negative.

Due to the fact that the feed-forward neural network outputs a probability of a class rather
than a class label, a threshold has to be set to obtain a confusion matrix and to be able to compute
the evaluation metrics. This threshold being unknown during the training, a custom metric was
implemented and operated according to the algorithm in Algorithm 1 to compute the mean intersection
over union for thresholds between 0.5 and 1.

Algorithm 1 Pseudocode for calculating a custom metric for thresholding.

1: Create an empty array to hold the intersection over union values for all thresholds IoUs
2:
3: Create array V of values between 0.5 and 1 with a step of 0.05
4:
5: Feed forward to do the pixelwise classiﬁcation prediction P(C|X, W)
6:
7: for Every element k of array V do
8:
9:
10:
11:
12:
13:
14:
15: end for
16:
17: return the mean intersection over union mIoU ← mean(IoUs)

During our study, we tested different hyperparameters to ﬁnd an optimal setting for our problem.
The different parts of our ﬁnal architecture, as well as the tested hyperparameter settings are described
in the following.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: To evaluate the performance of the deep learning model, two main metrics were used: Intersection over Union (IoU) and Overall Accuracy. The IoU metric measures the overlap between the predicted segmentation map and the ground truth, while the Overall Accuracy measures the percentage of correctly classified pixels. These metrics were computed using a custom implementation of the IoU metric and Equations (1) and (2), respectively. Additionally, a custom metric was implemented to calculate the mean IoU for thresholds between 0.5 and 1, which helped to determine the optimal threshold value for converting probabilities into class labels.