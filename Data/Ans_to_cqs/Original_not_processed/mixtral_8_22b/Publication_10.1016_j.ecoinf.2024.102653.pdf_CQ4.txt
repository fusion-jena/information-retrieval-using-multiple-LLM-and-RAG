Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Methods 

Fig. 2 summarizes a series of processes in designing a deep-learning 
architecture that acts as a toxicovigilance tool. Subsequent sections will 
provide a comprehensive description of each section. 

2.1. Data collection

2.6. Performance metrics 

Conventional  metrics  were  used  to  evaluate  the  model’s  perfor-
mance, such as confusion matrices, accuracy, recall, precision, F1-score, 
Cohen  Kappa,  and  the  area under  the  ROC curve,  some of  which  are 
defined below (Johnson and Khoshgoftaar, 2019).  

Table 1 
List of hyperparameters utilized for training the Recurrent Neural Network 
model.  

Hyperparameter 

Value 

Optimizer 
Learning rate 
Batch size 
Epochs 
Dropout rate 
Loss function 

ADAM (Kingma and Ba, 2017) 
0.003 
32 
100 
0.5 
Binary Cross Entropy  

●  Confusion Matrix

Machine learning coupled with big data technology has permeated 
agriculture  to  inform  crop,  livestock,  and  water  management  (Liakos 
et  al.,  2018).  For  example,  previous  studies  have  successfully  used 
artificial  intelligence  to  analyze  and  classify  animal  behavior  (Klean-
thous et al., 2022), and evaluate animal well-being (McLennan et al., 
2015).  Furthermore,  the  use  of  neural  networks  or  deep  learning  ar-
chitectures has significantly increased for solving entomological prob-
lems  (Marinho  et  al.,  2023;Peng  and  Wang,  2022;  Tuda  and  Luna- 
Maldonado,  2020).  For  example,  Convolutional  Neural  Networks 
(CNN)  have  been  applied  to  the  classification  of  fruit  fly  pupae  as 
parasitized or healthy (Marinho et al., 2023) and the recognition of in-
sect  pest  species  (Peng  and  Wang,  2022;  Tuda  and  Luna-Maldonado, 
2020).  Regarding  honey  bees,  recent  studies  have  proposed  deep

In the proposed architecture, the model employs dual BiLSTM layers 
in its structure. Following each BiLSTM layer, dropout regularization is 
incorporated to mitigate the risk of overfitting. Specifically, this regu-
larization method entails the random deactivation of 50% of the neural 
connections (Srivastava et al., 2014). After these first layers, the archi-
tecture introduces a densely connected layer comprised of 128 neurons. 
This  layer  utilizes  a  Rectified  Linear  Unit  (ReLU)  activation  function 
(Nair and Hinton, 2010). A mechanism was proposed to facilitate the 
classification  of  the  processed  sequences,  as  depicted  in  Fig.  3.  The 
model  harnessed  the  capabilities  of  the  NVIDIA  CUDA  Deep  Neural 
Network  (cuDNN)  library  to  enhance  computational  efficiency  and 
reduce training duration, as presented by Chetlur et al. (2014). 

2.4. Model training and hyperparameters

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information on the specific data augmentation techniques applied in the deep learning pipeline. Therefore, I cannot provide a helpful answer to this query based on the available information.