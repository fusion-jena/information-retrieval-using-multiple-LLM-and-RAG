Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4.2.1. Data Augmentation

Data augmentation is a technique for increasing the amount of data available for train-
ing the proposed CNN model without actually acquiring new data [49]. This technique is
used to expand the dataset into a larger one more appropriate for DL model training. There
are various strategies used for data augmentation, including rotation, zoom, horizontal,
and vertical shift. These techniques assist in enhancing the efﬁciency of CNNs [50].

Different data augmentation strategies have been utilized in this research. For instance,
we applied a 90-degree rotation range, a zoom and shear range of 20%, a brightness scale
between 0.2 to 1.0 and a shift range of 20% in height and width. Finally, a horizontal ﬂip
and vertical ﬂip have also been applied. Table 4 shows the detailed parameters of our data
augmentation processes

Table 4. Augmentation Parameters.

Augmentation

Rotation
Zoom
Shear
Horizontal shift
Vertical shift
Brightness
Horizontal ﬂip
Vertical ﬂip

Remote Sens. 2021, 13, 2221

18 of 26

Figure 6. Sample image data augmentation. (a) Rotation results; (b) Zoom results; (c) Shearing results; (d) Horizontal shift
results; (e) Vertical shift results; (f) brightness results; (g) Horizontal ﬂip results; (h) Vertical ﬂip results.

Remote Sens. 2021, 13, 2221

19 of 26

Figure 7. Model accuracy over plain data. (a) Training accuracy; (b) Validation accuracy.

Figure 8. Model accuracy over encrypted data. (a) Training accuracy; (b) Validation accuracy.

Data augmentation retains the features that are essential for predictions. As shown in
Figure 6g,h, the pixels are completely rearranged when ﬂipping the images horizontally
and vertically, but the features are retained.

Table 3. CNN Architecture.

No.

Layers

Output Shape

Parameters

Dropout Rate

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Dropout
Flatten
Fully Connected
Activation (ReLu)
Fully Connected
Activation (softmax)

128 × 128 × 3
128 × 128 × 32
—
64 × 64 × 32
64 × 64 × 32
—
32 × 32 × 32
32 × 32 × 64
—
16 × 16 × 64
16 × 16 × 64
16,384
64
—
4
—

—
896
—
—
9248
—
—
18,496
—
—
—
—
1,048,640
—
—
260

—
—
—
—
—
—
—
—
—
—
0.4
—
—
—
—
—

4.2.1. Data Augmentation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study employs several data augmentation techniques to enhance the efficiency of Convolutional Neural Networks (CNN). The specific techniques used include a 90-degree rotation range, a zoom and shear range of 20%, a brightness scale between 0.2 to 1.0, and a shift range of 20% in both height and width. Additionally, horizontal and vertical flips were also applied. These methods help increase the amount of data available for training the proposed CNN model without requiring additional data acquisition. Figure 6 illustrates sample image data augmentations using these techniques.