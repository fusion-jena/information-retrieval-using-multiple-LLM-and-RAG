Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

0.8280

0.7342

0.7370

0.7301

0.7001

0.7389

A slight difference indicates that DeepLabV3+ was the best classiﬁer method from
a quantitative perspective, returning the best available results for the chosen metrics. In
the recent few years, the architecture DeepLabv3+ has been regarded as state-of-the-art in
semantic segmentation. So it is no surprise that it achieved the best performance among all
tested architectures in our experiments, both in terms of absolute average accuracies as
in terms of variability for the test set. Nevertheless, it also is accurate to say by analyzing
the results presented in Table 1 that all of the ﬁve state-of-the-art networks are capable
of segmenting trees inside a Cerrado urban environment in a satisfactory way with the
proposed imagery dataset. These deep neural networks can separate tree covered-area

Remote Sens. 2021, 13, 3054

10 of 19

The most signiﬁcant variation of performance is concerning the number of parameters
and with training and inference time. Despite being the best architecture in performance,
According to Table 2, DeepLabv3+ needed more parameters than the other architectures,
about 2.75 times more parameters than the U-Net, the least requiring one. The need for a
more signiﬁcant number of parameters often implies a higher demand for training samples
that our dataset or another dataset may not have met that the methods present in this
research paper may be applied, possibly causing the DeepLabV3+ architecture to perform
below its potential.

Remote Sens. 2021, 13, 3054

11 of 19

Figure 11. Convergence of the evaluated networks.

Table 2. Number of Parameters and Processing Time of the proposed approaches. The training time
represents the results for the test set of each method. The inference time stands for the time taken by
each model to make predictions for each image.

Method

FCN

U-Net

SegNet

DeepLabV3+: The DeepLabV3+ [48] starts with three blocks composed of two convo-
lutions and one polling layer that performs the feature extraction and an initial prediction
map. These features are then processed by a particular layer, called Atrous Spatial Pyramid
Pooling (ASPP) introduced in [49]. This technique involves employing atrous convolution
in parallel to extract features at multiple scales and alleviate the loss of spatial information
due to prior pooling or convolutions with striding operations. The data is then processed
with features extracted from the ﬁrst pooling layer and reﬁned by one extra convolutional
layer. Then three convolutional layers process the concatenated segments upsampled
by a bilinear interpolation producing the ﬁnal prediction map. For more details, see
Figure 7 [48].

Figure 7. DeepLabV3+ architecture. Adapted from [43,48].

Remote Sens. 2021, 13, 3054

7 of 19

Large-Scale Machine Learning on Heterogeneous Systems. 2015. Available online: tensorﬂow.org (accessed on 16 July 2021).

52. Cohen, J. A Coefﬁcient of Agreement for Nominal Scales. Educ. Psychol. Meas. 1960, 20, 37–46. [CrossRef]
53. Wu, Z.; Gao, Y.; Li, L.; Xue, J.; Li, Y. Semantic segmentation of high-resolution remote sensing images using fully convolutional

network with adaptive threshold. Connect. Sci. 2019. [CrossRef]

54. Berman, M.; Triki, A.R.; Blaschko, M.B. The Lovasz-Softmax Loss: A Tractable Surrogate for the Optimization of the Intersection-
Over-Union Measure in Neural Networks. In Proceedings of the IEEE Computer Society Conference on Computer Vision and
Pattern Recognition, Salt Lake City, UT, USA, 18–23 June 2018. [CrossRef]

55. LeCun, Y.; Bengio, Y.; Hinton, G. Deep Learning. Nature 2015, 521, 436–444. [CrossRef] [PubMed]

Remote Sens. 2021, 13, 3054

19 of 19

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific data annotation techniques used in the deep learning pipeline. However, we can infer that semantic segmentation was employed as part of the research study. Semantic segmentation is a type of pixel-level classification task where each pixel in an image is assigned a label corresponding to the object or region it belongs to. It differs from other annotation techniques such as bounding box annotation and instance segmentation.

Bounding box annotation involves drawing rectangular boxes around objects within an image, which helps localize and identify those objects. Instance segmentation goes further by outlining individual instances of objects within an image, allowing for precise identification and differentiation between overlapping or closely situated objects.

In contrast, semantic segmentation focuses on identifying regions rather than individual instances, grouping together pixels belonging to the same category without distinguishing between separate entities. Given the focus on separating tree-covered areas in the Cerrado urban environment, it appears that semantic segmentation was the primary annotation technique utilized in this study.