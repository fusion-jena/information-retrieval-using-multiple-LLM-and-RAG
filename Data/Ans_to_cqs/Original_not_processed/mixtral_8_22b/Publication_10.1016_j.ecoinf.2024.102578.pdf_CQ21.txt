Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Workflow 

The multi-step, semi-automated workflow proposed here (Fig. 1) is 
adapted from B¨ohner et al., 2023, including pre-processing of images, 
model  training,  classification,  manual  quality  checks,  and  final  data 
formatting. Specifically, we build on the results of Rigoudy et al. (2022) 
and  Fennell  et  al.  (2022),  who  combined  MegaDetector  with  manual 
classification and custom-trained models. The workflow consists of the 
following two classification steps in addition to pre-processing of images 
and  final  manual  inspection,  quality  control,  and  data  formatting 
(Fig. 1). 

2.1. Classification 1 – Image quality and animal presence/absence

Table 4 
Definitions of model performance metrics based on “caret” R package, based on 
true positives (TP), true negatives (TN), false positives (FP), and false negatives 
(FN).  

Metric 

Equation 

Definition 

Accuracy 

Precision 

Recall 

TP + TN
TP + FP + TN + FN 
TP
TP + FP 

TP
TP + FN 

F1 

2*precision*recall
precision + recall  

Proportion of correct predictions in the whole 
data set. 
The proportion of images that a model classified 
as a specific category C that are actually category 
C. 
The proportion of images that are actually a 
specific category C that the a model classified as 
C. 
Weighted average of precision and recall.  

Table 5 
Performance of the image quality model on the test data.  

Location 

Finnmark 

Yamal 

Id 

Bad 
Good 
Bad 
Good 

Precision 

0.920 
0.986 
0.764 
0.979 

Recall 

0.910 
0.988 
0.779 
0.977 

F1 

0.915  
0.987 
0.771  
0.978

shown to reduce the processing time of image classification load by as 
much as 5× to 13× depending on the tasks (Fennell et al., 2022; Henrich

corner  etc.),  as  high-quality  training  data  are  important  for  model 
training (B¨ohner et al., 2023). In particular, images of animals at large 
distances (e.g., appearing as points on the horizon) that could be iden-
tified  by  humans  only  because they  moved  in  and  out  of  frame were 
excluded from model training. The resultant data subsets (46,491 im-
ages  for  Finnmark  and  33,889  for  Yamal;  Table  S1)  were  randomly 
divided into 92% to be used for model training, 8% for validation of the 
trained model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training step, there are several postprocessing steps involved in this workflow. These include manual quality checks, final data formatting, and a second round of classification. Manual quality checks involve inspecting the output of the initial classification step to ensure accuracy and reliability. Final data formatting involves preparing the data for further analysis or presentation. The second round of classification involves using the trained model to classify additional images, which can help improve the overall accuracy of the model. Other potential postprocessing steps not explicitly mentioned in this workflow may include generating saliency maps, calculating metrics such as precision, recall, and F1 score, and creating confusion matrices to evaluate the performance of the model. However, these steps would depend on the specific requirements and goals of the project.