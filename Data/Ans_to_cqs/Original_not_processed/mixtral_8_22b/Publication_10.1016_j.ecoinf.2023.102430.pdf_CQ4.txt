Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Methods 

2.1. Bug-picture database

2.3. Algorithm training and testing 

We trained all algorithms on a random subset of 5256 pictures (80% 

of  the  6570-picture  dataset).  To  gauge  performance  consistency,  the 
training-testing  process  was  repeated  10  times  for  each  algorithm;  in 
each of these (pseudo-)replicate runs, all five algorithms used the same 
training and testing picture subsets.

(pseudo-)replicates) to the full dataset (see Supplementary Dataset S1). 
Those 85 results are not mutually independent, and the random-effects

AN  was  implemented  in  MATLAB  (www.mathworks.com).  For 
training,  we  used  the  stochastic  gradient  descent  with  momentum 
optimizer with default settings except for the initial learning rate (which 
we set to 0.001) and the maximum number of epochs (which we set to 15 
after  preliminary  tests).  The  ‘classical’  machine-learning  algorithms 
(AB, GB, HB, and LD) were run in Python (www.python.org) using the 
scikit-learn toolbox (Pedregosa et al., 2011). We left hyperparameters at 
scikit-learn  default  values,  except  for  the  learning  rate  of  GB  and  HB 
(which we set to 0.15) and the tolerance threshold value for LD (set to 1 
× 10

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about specific data augmentation techniques applied in the deep learning pipeline. However, it mentions that the authors used a bug-picture database and trained their algorithms on a subset of this dataset. They also mention using stochastic gradient descent with momentum optimizer for training, but they do not specify any particular data augmentation techniques such as flipping, rotating, or scaling. Therefore, based on the given context, I cannot determine which data augmentation techniques were applied in the deep learning pipeline.