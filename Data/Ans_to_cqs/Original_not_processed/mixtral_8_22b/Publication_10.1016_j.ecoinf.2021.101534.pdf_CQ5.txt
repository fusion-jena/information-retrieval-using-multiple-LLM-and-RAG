Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

whole image. Thus, it may minimize the dilution effect and reduce the 
required amount of training data.

Compared with previous CNN-based approaches, the mAP of 0.83 in 
our case study is inconspicuous (Appendix S2: Table S4). However, not 
only the model itself but also the test dataset used can affect the values of 
model performance metrics. Because the SILIC aims to facilitate auto-
mated information extraction from the recordings of PAM projects, our 
test dataset was obtained from soundscape recordings, which are usually 
much noisier than focal recordings. In comparison with focal recordings, 

EcologicalInformatics68(2022)1015346S.-H. Wu et al.

The mixed audio clips are then converted into spectrograms as input 
images for model training. The clips are transformed by applying the 
short-time Fourier transform (STFT) with a window size of 1600 sam-
ples,  hop  size  of  400  samples  (75%  overlap),  and  240  mel-scale  fre-
quency bins.  Each spectrogram thus  has a height  of 438 pixels  and a 
width of 436 pixels (Appendix S1: Fig. S4a).

Zhang, X., Chen, A., Zhou, G., Zhang, Z., Huang, X., Qiang, X., 2019. Spectrogram-frame 

linear network and continuous frame sequence for bird sound classification. Ecol. 
Inform. 54, 101009. 

Garamszegi, L.Z., 2019. Automatic bird song and syllable segmentation with an 
open-source deep-learning object detection method – a case study in the Collared 
Flycatcher (Ficedulaalbicollis). Ornis Hungarica 27, 59–66. 

Zwart, M.C., Baker, A., McGowan, P.J.K., Whittingham, M.J., 2014. The use of 

automated bioacoustic recorders to replace human wildlife surveys: an example 
using Nightjars (S.G. Willis, Ed.). PLoS One 9, e102770. 

EcologicalInformatics68(2022)10153410

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific datasets such as MNIST, CIFAR, or ImageNet being used in the deep learning pipeline. Instead, the authors have mentioned using their own custom dataset derived from soundscape recordings, which are typically much noisier than focal recordings. These soundscape recordings were transformed into spectrograms as input images for model training. The transformation process involved applying short-time Fourier transform (STFT) with a window size of 1600 samples, hop size of 400 samples (75% overlap), and 240 mel-scale frequency bins. As a result, each spectrogram had a height of 438 pixels and a width of 436 pixels. Therefore, based on the available context, we cannot provide the names of standard datasets like MNIST, CIFAR, or ImageNet used in this particular deep learning pipeline.