Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2. Split the datasets 

In this research, the datasets were randomly divided into three parts 
for training, validation and testing. Here, 60% of the data was used to 
train the deep learning models, and 20% of them was kept to validate the 
models. The remaining 20% data was used to evaluate the performance 
of the models. Table 1 show the number of data in the dataset and how 
they are separated for training, testing and validation. 

2.3. Deep learning models

VGG16 and VGG19 are classical architectures that are well known 
for  simplicity  and  uniformity.  These  models  are  suitable  for  smaller 
datasets and can provide better accuracy by fine-tuning the pre-trained 
network (Sukegawa et al., 2020). The models have several drawbacks, 
such  as  vanishing  gradient  problems  and  loss  of  fine-grained  spatial 
information (Pan et al., 2020). On the other hand, ResNet-50 contains 
residual  connections,  which  can  overcome  the  vanishing  gradient 
problem and enable training very deep networks. The model performs 
well on both large and small datasets (Al-Masni et al., 2020).

3. Results 

In this section, we present the experimental results of our proposed 
approach and compare them with the traditional approach and the re-
sults achieved by the previous studies on all the datasets. 

3.1. Traditional pipeline 

We first trained the models using the original images only, without 
any  data  augmentation.  Table  2  summarises  the  accuracy,  precision, 
recall and F1 score of the ten models. There is a significant variation 
between  the  models  regarding  the  number  of  parameters  and  model 
depth.  Overall,  the  DenseNet  models  achieved  the  best  results  on  all 
datasets. DenseNet169 and DenseNet201 attained the same accuracy of 
95.01% for the DeepWeeds dataset, but the precision, recall and F1 score 
indicates that DenseNet169 is better than DenseNet201. The dataset has 
inter-class  similarity  and  intra-class  dissimilarity  issues.  That  affected 
the classification accuracy. Olsen et al. (2019) also mentioned that there

2.3. Deep learning models 

The  selection  of  the  deep  learning  models  for  image  classification 
depends  on  available  computational  resources  and  the  trade-offs  be-
tween the model complexity and performance (Druzhkov and Kustikova, 
2016;  Li  et  al.,  2018).  To  test  the  performance  of  our  technique,  we 
selected  the  following  deep  learning  models:  VGG16  (Simonyan  and 
Zisserman, 2014), VGG19 (Simonyan and Zisserman, 2014), ResNet-50 
(He  et  al.,  2016),  Inception-V3  (Szegedy  et  al.,  2016),  InceptionRes-
NetV2  (Szegedy et  al., 2017), Xception  (Chollet,  2017), DenseNet121 
(Huang et al., 2017), DenseNet169 (Huang et al., 2017), DenseNet201 
(Huang et al., 2017) and MobileNetV2 (Sandler et al., 2018). For the 
sake  of  brevity,  we  briefly  summarise  the  main  attributes  of  these 
techniques.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The text does not explicitly state what type of deep learning model is used in the pipeline. However, it mentions several specific deep learning models such as VGG16, VGG19, ResNet-50, DenseNet121, DenseNet169, DenseNet201, and MobileNetV2. All of these models are types of Convolutional Neural Networks (CNNs). Therefore, it can be inferred that the pipeline uses CNNs for image classification tasks.