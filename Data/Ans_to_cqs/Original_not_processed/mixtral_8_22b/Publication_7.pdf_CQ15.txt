Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Convolutional neural networks (CNNs) [9], also known as
deep networks, are an important class of machine learning
algorithms applicable, among others, to numerous computer
vision problems. Deep CNNs, in particular, are composed of
multiple layers of processing involving linear as well as non-
linear operators. To solve a particular task, the parameters of
networks are learned in an end-to-end manner. Image represen-
tations extracted from deep CNNs trained on a large dataset
such as ImageNet [10] have shown to produce a promising
performance for diverse classiﬁcation and recognition tasks
[11], [12], [13], [14] and [15]. Spatial pyramid pooling (SPP)
[16] and Multi-scale Orderless Pooling (MOP) [17] schemes
have made CNNs independent of the input image size and
robust for diverse classiﬁcation and recognition applications.
In this paper, we propose a computer vision and deep
learning based framework for the automatic annotation of

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

978-1-5090-1537-5/16/$31.00 ©2016 IEEEA. Classiﬁcation Process

Image representations extracted from deep neural networks,
trained on large datasets such as ImageNet [9] and ﬁne tuned
on domain speciﬁc datasets, have shown state-of-art perfor-
mance in numerous image classiﬁcation problems [14]. The
activation vectors of the ﬁrst fully connected layer of a pre-
trained VGGnet [24] are employed as feature representations
in our work. The weights of this deep network are ﬁne tuned
using the Benthoz15 dataset [23] which consists of expert-
annotated and geo-referenced marine images from Australian
seas.

[10] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
A large-scale hierarchical image database,” in IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), pp. 248–255, IEEE,
2009.

[11] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and
T. Darrell, “Decaf: A deep convolutional activation feature for generic
visual recognition,” International Conference on Machine Learning
(ICML), pp. 647–655, 2014.

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

NC
C

NC
C

(a)

(b)

(c)

Fig. 4: Mosaics and Coral Maps: (a) the 3 sites of the Abrolhos Island; (b) Site 3 Coral Map for 2010 and (c) Site 3 Coral
Map for 2013. Legend key: C is coral and NC is non-coral

hybrid feature representations,” IEEE International Conference on Image
Processing, in press.

[16] Y. Gong, L. Wang, R. Guo, and S. Lazebnik, “Multi-scale orderless
pooling of deep convolutional activation features,” in Computer Vision–
ECCV 2014, pp. 392–407, Springer, 2014.

[17] K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling in deep
convolutional networks for visual recognition,” in European Conference
on Computer Vision (ECCV), pp. 346–361, Springer, 2014.

[18] L. Edwards, “Catami classiﬁcation scheme for scoring marine biota and
substrata in underwater imagery,” CATAMI Classiﬁcation Scheme for
Scoring Marine Biota and Substrata in Underwater Imagery, pp. 1–17,
2013.

[19] M. D. Stokes and G. B. Deane, “Automated processing of coral reef
benthic images,” Limnology and Oceanography: Methods, vol. 7, no. 2,
pp. 157–168, 2009.

[20] O. Pizarro, P. Rigby, M. Johnson-Roberson, S. B. Williams, and
J. Colquhoun, “Towards image-based marine habitat classiﬁcation,” in
OCEANS 2008, pp. 1–7, IEEE, 2008.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about specific optimization techniques used in the deep learning pipeline, such as Stochastic Gradient Descent (SGD) or Adam. However, it can be assumed that some form of optimization technique was used during training of the deep neural networks mentioned, like VGGnet, since these models require parameter updates through backpropagation. Typically, popular choices include SGD with momentum, Adaptive Moment Estimation (Adam), Root Mean Square Propagation (RMSProp), and others. Without explicit mention in the text, it cannot be confirmed which optimization method was utilized in this case.