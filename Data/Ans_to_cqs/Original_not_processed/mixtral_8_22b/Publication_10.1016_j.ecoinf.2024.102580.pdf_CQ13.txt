Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025802R.K. James et al.                                                                                                                                                                                                                                

Fig. 1. Workflow used to (a) select a deep learning model, (b) develop a ground-truth imagery dataset, (c) train the deep learning models, (d & e) evaluate model 
performance and (f & g) obtain the data and analyse it to quantify the spatial patterns and resilience of the ecosystem. 

2.3. Deep learning models 

2.3.1. Semantic segmentation for vegetation mapping

Access  to  required  computing  resources  is  another  challenge. 
Training  deep  neural  networks  for  semantic  segmentation  and  object 
detection traditionally requires expensive computational resources with 
multiple high-end GPUs (e.g., available on high-performance computing 

EcologicalInformatics81(2024)10258010R.K. James et al.

training, which helped to reduce human error. Similar to the seagrass 
semantic  segmentation  model,  the  resolution  of  the  images  in  the 
ground-truth dataset was reduced to 1000 × 1333, and the three colour 
channels of the images were normalised by subtracting the means and 
dividing  by  the  standard  deviations  per  channel.  The  colour  channel 
means and standard deviations were based on the ImageNet dataset used 
in the training of the (pre-trained) RestNet-50 (the used mean values 
were [0.485, 0.456, 0.406], and the standard deviations were [0.229, 
0.224, 0.225]). The DETR model’s object queries parameter was set to 
100, allowing for the detection of up to 100 turtles in an image, which 
was sufficient for all case-study images.

3.1. Success of deep learning models 

The  semantic  segmentation  model  used  to  identify  the  substrate 
types  achieved  an  accuracy  of  92%.  The  precision  for  the  vegetation 
class was 0.90, for the bare class was 0.96, and for the ‘other’ class was 
0.50 when evaluating the model against the test dataset. The recall of 
the model (the number of instances in which the model correctly iden-
tified the pixels out of the total number of pixels in that class) reached 
0.97 for vegetation, 0.87 for bare substrate and the ‘other’ class reached 
a recall of 0.53.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the given context does not provide information about the specific hyperparameters such as learning rate or optimizer used in the deep learning model. However, we do know some details about the parameters used in the DETR model, specifically the object queries parameter being set to 100, which allows for the detection of up to 100 turtles in an image. Additionally, the color channels of the images were normalized using the means and standard deviations from the ImageNet dataset.