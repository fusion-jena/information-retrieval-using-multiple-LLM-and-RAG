Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

[18] H. Chen, A. Chen, L. Xu, H. Xie, H. Qiao, Q. Lin, K. Cai, A
deep learning CNN architecture applied in smart near-infrared
analysis of water pollution for agricultural irrigation resources,
Agric. Water Manag. 240 (2020) 106303.

[19] X. Wu, C. Zhan, Y. Lai, M. Cheng, J. Yang, IP102: A Large-
Scale Benchmark Dataset for Insect Pest Recognition, IEEE/
CVF Conference on Computer Vision and Pattern Recognition
(CVPR) 2019 (2019) 8779–8788.

[20] W. Li, P. Chen, B. Wang, C. Xie, Automatic Localization and
Count of Agricultural Crop Pests Based on an Improved Deep
Learning Pipeline, Sci. Rep. 9 (2019) 7024.

[21] A. Gutierrez, A. Ansuategi, L. Susperregi, C. Tubı´ o, I. Rankic´ ,
L. Lenzˇ a, A Benchmarking of Learning Strategies for Pest
Detection and Identiﬁcation on Tomato Plants for Autonomous
Scouting Robots Using Internal Databases, J. Sens. 2019 (2019)
5219471.

4432

M.E. Karar et al.

IoU ¼

A \ B
A [ B

ð2Þ

Next, the Region of Interest (RoI) pooling layer takes the
region corresponding to a proposal from the backbone feature
map and dividing it into sub-windows. The maximum pooling
is performed over these sub-windows to give the output of RoI
pooling layer, which has a size of (N, 7, 7, 512), and N is the
number of generated region proposals by the RPN mechanism,
as shown in Fig. 2. After passing through two fully connected
layers (FCs), the features are fed into the classiﬁer and regres-
sor branches as follow. The classiﬁcation layer calculates the
probability of the region proposal contains an object such that
the probability Pi of each element in the feature map i contains
the target object using softmax function. The regions with the
top score of 300 Pi in the total rankings present the detected
target object. In addition, the regressor provides the IoU index

A new mobile application of agricultural pests recognition

4427

Fig. 3

Alexandria Engineering Journal (2021) 60, 4423–4432

H O S T E D   BY

Alexandria University

Alexandria Engineering Journal

www.elsevier.com/locate/aej
www.sciencedirect.com

A new mobile application of agricultural pests
recognition using deep learning in cloud computing
system

Mohamed Esmail Karar a,b,*, Fahad Alsunaydi a, Sultan Albusaymi a, Sultan Alotaibi a

a College of Computing and Information Technology Shaqra University, Shaqra, Saudi Arabia
b Department of Industrial Electronics and Control Engineering, Faculty of Electronic Engineering, Menouﬁa University,
Minuf, Egypt

Received 23 September 2020; revised 6 January 2021; accepted 9 March 2021
Available online 31 March 2021

KEYWORDS

Smart agriculture;
Crop pest;
Cloud computing;
Deep learning;
Faster R-CNN

e.g. machine learning and artiﬁcial neural networks, have been
widely employed in previous studies to solve the above prob-
lems in the agricultural ﬁeld.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers cited do not provide explicit information about the method used for collecting raw data in their respective deep learning pipelines. However, some clues can be inferred based on the nature of the research. For instance, paper [18] focuses on analyzing water pollution for agricultural irrigation resources using a deep learning CNN architecture. It is likely that they collected raw data using various sensors or sampling techniques to measure water quality parameters. On the other hand, paper [19] introduces a large-scale benchmark dataset for insect pest recognition, suggesting that they might have gathered images from publicly available sources or created their own dataset using image acquisition devices like cameras. Similarly, paper [20] discusses automatic localization and count of agricultural crop pests based on an improved deep learning pipeline, implying that they could have used sensors or imagery data to collect relevant information. Lastly, paper [21] presents a benchmarking of learning strategies for pest detection and identification on tomato plants using internal databases, indicating that they may have relied on existing datasets or captured images themselves using specialized equipment. Overall, while the exact methods for gathering raw data are not explicitly stated, one can infer that the researchers likely used a combination of sensors, surveys, and public datasets depending on the specific requirements of their projects.