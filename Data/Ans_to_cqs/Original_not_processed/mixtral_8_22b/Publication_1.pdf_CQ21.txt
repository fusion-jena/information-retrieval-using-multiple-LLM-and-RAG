Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

all  based  on  the  lower  level  representations  learned  in  previous 
layers. These  models  are  completely  trainable  from  data,  usually 
in a supervised fashion, such that the learning algorithm (usually 
stochastic  gradient  decent),  is  told  what  the  desired  output  is  for 
each input data sample.

4.2.Data analysis

which  no  models  yet  exist.  A  roadmap  of  improvements  is 
envisioned  for  further  enhancing  analysts'  ability  to  explore  and 
search large volumes of sensor data, including providing a richer 
set  of  elemental  signal  attributes,  a  more  natural-language 
interface, and also the ability to search by exemplars. 

Other  exploration  tools  are  more  focused  on  visualizing  the  data 

Finally,  our  software  expedites  auditing  â€“  the  manual  review  of 
classification  model  output.  We  run  existing  DL  models  against 
our  survey  data  to  automatically  classify  and  detect  species  or 
events  of  interest  for  each  project.  These  models  output  the 
relative  probability  that  an  event  is  from  a  specific  data  class 
(usually  corresponding  to  a  species  or  event),  and  analysts  can 
sort the data accordingly. Analysts are then presented with ranked

pages  containing  a  large  number  of  panels,  where  each  panel 
contains  a  visualization  of  an  individual  data  sample.  Using 
keyboard shortcuts, the panels are efficiently labeled. For images, 
the visualization consists of image cropping around the object of 
interest, contrast enhancement, and consecutive frame differences. 
For  audio,  2D  spectrograms  of  an  appropriate  duration  (e.g.,  2 
seconds)  are  displayed  per  panel.  This  gives  a  visual 
representation  of  the  sound  clip;  distinct  sounds  have  different 
spectrograms,  enabling  analysts  to  quickly  learn  to  visually  spot 
sounds  of  interest  when  presented  with  many  sounds 
simultaneously  on  a  page. They  also  have  the  ability  to  play  the 
audio  corresponding  to  each  spectrogram,  and  view  more 
temporal  context  around  it  in  order  to  help  with  their  auditing 
decision.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about the postprocessing steps involved after the model training. However, we can infer some possible steps based on the given context. After training deep learning (DL) models using stochastic gradient descent, these models are used to classify and detect species or events of interest in the survey data. The models output the relative probability that an event belongs to a specific data class, which could be a particular species or event.

The results are then sorted according to this probability, allowing analysts to focus on the most relevant data samples first. For images, the postprocessing involves cropping around the object of interest, contrast enhancement, and displaying consecutive frame differences. For audio data, 2D spectrograms are generated to give a visual representation of the sound clips. Distinct sounds have different spectrograms, making it easier for analysts to identify sounds of interest when presented with multiple sounds simultaneously. Additionally, analysts can listen to the audio corresponding to each spectrogram and view more temporal context around it to aid in decision-making during the auditing process.

While the text does not mention saliency maps, metrics calculations, or confusion matrices explicitly, these techniques could potentially be employed as part of the postprocessing steps. Saliency maps could be used to highlight important features within the images or spectrograms that contribute to the classification decisions made by the models. Metrics calculations would involve evaluating the performance of the trained models using various evaluation metrics, such as accuracy, precision, recall, F1 score, etc. Lastly, confusion matrices could be created to visualize the performance of the models across all classes, showing true positives, false positives, true negatives, and false negatives.