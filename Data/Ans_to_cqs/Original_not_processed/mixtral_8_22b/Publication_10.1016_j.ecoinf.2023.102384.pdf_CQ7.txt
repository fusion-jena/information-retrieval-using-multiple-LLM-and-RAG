Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

we break them down into smaller patches. Specifically, in the training 
stage,  we  randomly  crop  square  patches  (experimenting  with  various 
patch sizes, namely 256, 320, 480, 640, and 800 pixels), and we apply a 
simple  augmentation  strategy,  flipping  the  patches  horizontally  and 
vertically with a 50% probability. On the other hand, during the vali-
dation phase, we divide the images of the validation split into regularly- 
spaced,  overlapping  patches,  using  the  same  size  employed  during 
training.  We  process  these  patches  individually,  reconstructing  the 
overall  output  by  combining  the  predictions  from  the  patches,  and 
subsequently, we calculate metrics over the complete image. For clarity, 
Fig.  2  provides  a  graphical  representation  of  this  procedure.  In  more 
detail,  for  the  solution  based  on  detection,  we  reconstruct  the  final 
global  output  using  non-maximum  suppression  among  the  bounding

Fig. 3. Generated ground-truth. Ground-truth required for the training phase is derived from dot labels by leveraging distinct procedures depending on the specific 
deep learning model PCθ  being employed:: (i) bounding boxes are generated by creating squares centered over the dots with a fixed side length s, (ii) density maps are 
produced by overlaying Gaussian kernels Gσ  centered at the dot positions, and (iii) segmentation maps are generated by superimposing dot-centered discs having 
radius r and splitting overlapping discs using a background ridge. The parameters s, σ, and r are constants that are established based on the standard object sizes 
prevalent in the images. Best viewed in electronic format.

Training Setup. In the training phase, we partition the training data 
into  two  subsets:  training  and  validation.  To  mitigate  potentially  un-
balanced  sets  arising  from  the  varying  insect  numbers  present  in 
different  images,  we  deviate  from  the  typical  per-image  splitting 
approach.  Rather,  we  embrace  an  alternative  strategy.  We  vertically 
divide each image into halves, alternatingly assigning one portion to the 
training subset and the other to the validation set. 

We  process  images  in  the  wild,  i.e.,  without  performing  any  pre- 
processing  operation,  such  as  segmenting  the  region  representing  the 
trap from the background. To address the challenge of large image sizes,

data collection and curation phases.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data is split into two subsets for training and validation purposes. Instead of using a per-image splitting approach, which could result in imbalanced sets due to varying insect numbers in different images, a unique strategy is adopted. Each image is vertically divided into halves, with one half assigned to the training subset and the other to the validation set. This method ensures a balanced distribution of insect numbers across both subsets. No pre-processing operations like segmenting the trap region from the background are performed on the images before processing.