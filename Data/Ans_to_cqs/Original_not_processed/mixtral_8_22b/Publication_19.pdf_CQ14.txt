Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

TABLE II.  

HYPERPARAMETERS DETERMINED USING GRID SEARCH 

Model Name 

Inception-V3 
MobileNet-V2 
ResNet-18 
DenseNet-121 

Batch 
Size 
48 
32 
32 
16 

Learning 
Rate 
0.05 
0.01 
0.005 
0.001 

Parameters 
# of 
Epochs 
75 
100 
150 
100 

Input Image Size 

299 (cid:3400) 299 (cid:3400) 3 
224 (cid:3400) 224 (cid:3400) 3 
224 (cid:3400) 224 (cid:3400) 3 
224 (cid:3400) 224 (cid:3400) 3 

C.  Results 

  As  Table  III  show  all  models  performed  reasonably  well 
with macro-F1 averages above 91%. Because the models are to 
be deployed on IoT edge devices, the size of each model is an 
important  consideration.  As  Table  III  shows 
the  best 
performing model was Inception-V3 with a macro Average F1 
score of 0.93, and the smallest size of 175 MB.   

TABLE III.  

BEST RESULTS FOR EACH NN ARCHITECTURE 

Model 

InceptionV3 
DenseNet-121 
ResNet-18 
MobileNetV2 

Model Size 
(MB) 
175 
446 
480 
507 

Accuracy 

94% 
93% 
92% 
93%

(cid:21)(cid:19)(cid:21)(cid:19)(cid:3)(cid:44)(cid:40)(cid:40)(cid:40)(cid:3)(cid:42)(cid:79)(cid:82)(cid:69)(cid:68)(cid:79)(cid:3)(cid:38)(cid:82)(cid:81)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:82)(cid:81)(cid:3)(cid:36)(cid:85)(cid:87)(cid:76)(cid:73)(cid:76)(cid:70)(cid:76)(cid:68)(cid:79)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:79)(cid:79)(cid:76)(cid:74)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:81)(cid:72)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:55)(cid:75)(cid:76)(cid:81)(cid:74)(cid:86)(cid:3)(cid:11)(cid:42)(cid:38)(cid:36)(cid:44)(cid:82)(cid:55)(cid:12)

Towards an IoT-based Deep Learning Architecture 
for Camera Trap Image Classification 

Imran A. Zualkernan  
Comp. Science and Engineering 
American University of Sharjah 
Sharjah, UAE 
izualkernan@aus.edu 

Salam Dhou 
Comp. Science and Engineering 
American University of Sharjah 
Sharjah, UAE 
sdhou@aus.edu

(cid:21)(cid:19)(cid:21)(cid:19)(cid:3)(cid:44)(cid:40)(cid:40)(cid:40)(cid:3)(cid:42)(cid:79)(cid:82)(cid:69)(cid:68)(cid:79)(cid:3)(cid:38)(cid:82)(cid:81)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:82)(cid:81)(cid:3)(cid:36)(cid:85)(cid:87)(cid:76)(cid:73)(cid:76)(cid:70)(cid:76)(cid:68)(cid:79)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:79)(cid:79)(cid:76)(cid:74)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:81)(cid:72)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:55)(cid:75)(cid:76)(cid:81)(cid:74)(cid:86)(cid:3)(cid:11)(cid:42)(cid:38)(cid:36)(cid:44)(cid:82)(cid:55)(cid:12)

stored locally while the label, timestamp and device ID are sent 
and  stored  in  the  Googleâ€™s  Cloud-hosted  Firebase  database 
(https://firebase.google.com/). 

Fig. 1.  System architecture of the proposed IoT system 

Fig. 2.  Edge-node hardware using a commercial camera and RPi

(cid:21)(cid:19)(cid:21)(cid:19)(cid:3)(cid:44)(cid:40)(cid:40)(cid:40)(cid:3)(cid:42)(cid:79)(cid:82)(cid:69)(cid:68)(cid:79)(cid:3)(cid:38)(cid:82)(cid:81)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:82)(cid:81)(cid:3)(cid:36)(cid:85)(cid:87)(cid:76)(cid:73)(cid:76)(cid:70)(cid:76)(cid:68)(cid:79)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:79)(cid:79)(cid:76)(cid:74)(cid:72)(cid:81)(cid:70)(cid:72)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:81)(cid:72)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:55)(cid:75)(cid:76)(cid:81)(cid:74)(cid:86)(cid:3)(cid:11)(cid:42)(cid:38)(cid:36)(cid:44)(cid:82)(cid:55)(cid:12)

other animals like foxes appeared individually. Out of the 231 
sheep images used for Testing (see Table I), 134 (58%) images 
depicted a herd rather than an individual sheep.  

TABLE IV.  

CONFUSION MATRIX FOR INCEPTION-V3 MODEL  

Donkey 
Fox 
Goat 
Sheep 
Ghost 
Other 

Donkey 
369 
3 
0 
0 
7 
2

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The hyperparameters of the model were determined using Grid Search. This can be seen from TABLE II which lists the Hyperparameters Determined Using Grid Search. These include Batch Size, Learning Rate, Parameters # of Epochs, and Input Image Size for various models such as Inception-V3, MobileNet-V2, ResNet-18, and DenseNet-121.