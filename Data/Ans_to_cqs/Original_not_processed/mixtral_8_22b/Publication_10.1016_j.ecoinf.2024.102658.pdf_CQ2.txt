Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics82(2024)102658Availableonline5June20241574-9541/©2024TheAuthors.PublishedbyElsevierB.V.ThisisanopenaccessarticleundertheCCBYlicense(http://creativecommons.org/licenses/by/4.0/).R. Noda et al.                                                                                                                                                                                                                                    

amount  of  data,  distribution  data  for  machine  learning  models  and 
physiological data for process-based models. For both types of models, 
the  data  is  difficult  and  costly  to  collect.  This  poses  a  bottleneck  for 
building SDMs for practical use.

3.2. Climate datasets 

The  climate  data  used  in  this  study  comprises  the  27  climate  ex-
tremes indices defined by the Expert Team on Climate Change Detection 
and Indices (ETCCDI), and the 19 bioclimatic variables from WorldClim 
(Hijmans  et  al.,  2005).  For  both  sets  of  climatic  variables,  we  chose 
observational and simulation data averaged for the years 1950–2000 to 
represent the present-day climate, and simulation data averaged for the 
years  2061–2080  to  represent  the  expected  climate  in  approximately 
2070. 

We use present-day and future ETCCDI indices derived from results 
of the Community Climate System Model version 4 (CCSM4) (Gent et al., 
2011),  one  of  a  number  of  Coupled  Model  Intercomparison  Project 
Phase  5  (CMIP5)  global  climate  models  for  which  these  indices  were

Following this, forward feature selection (FFS) was performed. FFS is 
a  common  stepwise  selection  procedure  (Hastie  et  al.,  2020),  which 
begins with an empty model, and iteratively selects the next feature from 
the initial set which most improves model performance. Candidate lo-
gistic  regression  and  random  forest  models  were  evaluated  via  (1) 
random cross-validation (CV) and (2) spatial CV (Roberts et al., 2017), 
in which the full training dataset was partitioned into spatial blocks like 
those shown in Fig. 2. 

Because model performance estimated via spatial CV is dependent on 
the spatial configuration of the CV folds, the procedure was repeated 
over 100 random blocking configurations; those features selected most 

Fig.  2. One  spatial-CV  fold  pattern  used  in  feature  selection.  This  particular 
fold was also utilized when calculating numerical scores for the models.

3. The study area and data

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, it appears that the study uses two main types of data: distribution data for machine learning models and physiological data for process-based models. However, there is no explicit mention of specific data formats such as images, audio, video, or CSV files. Therefore, I cannot provide a definitive answer regarding the exact data format used in their deep learning pipeline.