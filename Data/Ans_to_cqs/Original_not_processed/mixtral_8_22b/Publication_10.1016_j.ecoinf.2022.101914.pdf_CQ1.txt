Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.7. Subsetting background points 

We  made  three  random  selections  of  background  points  from  the 
training dataset for use during model construction. First, we made the 
“1×” selection, which selected the same number of background points as 
presences in the training dataset. Second, we made the “10×” selection, 
which selected a number of background points equal to ten times the 
number of presences in the training dataset. Third, we made the “10 K” 
selection, which selected 10,000 background points from the training 
dataset.  We  used  this  approach  to  maintain  consistency  across  back-
ground  points  used  to  train  each  model  so  there  was  no  variation  in 
model results due to variation in the response variable. 

2.8. Training individual models

points. Then, to obtain presences and background points to use during 
external evaluation, we set aside one fold. We then used the remaining 
four folds for internal cross-validation during model training.

To separate data into training and testing datasets, we used a spatial 
blocking technique, in which we divided our study area into 25 equally 
sized  blocks,  each  approximately  41  km  × 41  km  in  size,  using  the 
blockCV package in the R programming language (Valavi et al., 2019). 
We determined the size of our spatial blocks using the spatialAutoRange 
function in the blockCV package, which returns a block size equal to the 
median  range  of  spatial  autocorrelation  in  independent  covariates 
(Valavi  et  al.,  2019).  This  attempts  to  ensure  data  within  a  block  is 
relatively independent of data outside of that block. We then divided 
these blocks among five folds in which the numbers of presences and 
background points were roughly equal. We used five folds because, due 
to the spatial arrangement of our presence data, using more would cause 
folds to have drastically differing numbers of presences and background

4.2. Ensemble models

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide information on the methods used for collecting raw data in the deep learning pipeline such as surveys, sensors, or public datasets. Therefore, I cannot provide an accurate answer based on the given context.