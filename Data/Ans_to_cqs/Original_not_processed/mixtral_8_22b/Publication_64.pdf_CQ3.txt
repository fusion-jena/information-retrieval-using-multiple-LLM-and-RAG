Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Finally for the ResNet50 evaluation we use random ten
crop testing with smaller data augmentation parameters than
those used during training.

4.1 The datasets

4.1.1 Google Search Image. For this dataset we select the
3680 labels (around 60% of all labels) with more than 12
images in our training dataset. For each one of these labels

1Code is available at github.com/IgnacioHeredia/plant classification

Table 1: Accuracy results of the two algorithms for
all three test datasets.

Datasets

Google Image Search
Portuguese Flora
iNaturalist

Accuracy %
ResNet50 (paper) PlantNet (usual)
Top1
40
29
33

Top5
63
47
49

Top1
18
15
18

Top5
37
29
30

we automatically retrieve the 10 ﬁrst images returned by the
Google Image Search engine. As this is done in an automated
fashion some minor mislabeled or corrupt examples might
appear in the dataset. By choosing only the most popular
labels and retrieving the top results, we expect to minimize
the presence of mislabeled images.

[3] Alex Krizhevsky, Ilya Sutskever, and Geo↵rey E Hinton. Ima-
genet classiﬁcation with deep convolutional neural networks. In
F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger,
editors, Advances in Neural Information Processing Systems 25,
pages 1097–1105. Curran Associates, Inc., 2012.

[4] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delv-
ing deep into rectiﬁers: Surpassing human-level performance on
imagenet classiﬁcation, 2015.

[5] Sue Han Lee, Chee Seng Chan, Paul Wilkin, and Paolo Remagnino.
Deep-plant: Plant identiﬁcation with convolutional neural net-
works, 2015.

[6] Mads Dyrmann, Henrik Karstoft, and Henrik Skov Midtiby. Plant
species classiﬁcation using deep convolutional neural network.
Biosystems Engineering, 151:72–80, 2016.

[7] M-E. Nilsback and A. Zisserman. Automated ﬂower classiﬁcation
over a large number of classes. In Proceedings of the Indian Con-
ference on Computer Vision, Graphics and Image Processing,
Dec 2008.

As deep learning framework we use the Lasagne [11] module
built on top of Theano [12, 13]. We initialize the weights of
the model with the pretrained weights on the ImageNet
dataset provided in the Lasagne Model Zoo. We train the
model for 100 epochs on a GTX 1080 for 6 days using Adam
[14] as learning rule. During training we apply standard data
augmentation (as sheer, translation, mirror, etc) so that the
network never sees the same image. We do not apply rotation
or upside down mirroring to the images tagged as ’habit’, as it
does not make much sense to have a tree or a landscape upside
down. After applying the transformations we downscale the
image to the ResNet standard 224

224 input size. 1

⇥

259CF’17, May 15-17, 2017, Siena, Italy

Ignacio Heredia

3 THE MODEL
As plant classiﬁcation is not very di↵erent from general object
classiﬁcation, we expect that top performing architectures
in the ImageNet Large Scale Visual Recognition Challenge
(ILSVRC) would perform well in this task. Therefore we
use as convolutional neural network architecture the ResNet
model [10] who won the ILSVRC’15. This architecture con-
sists of a stack of similar (so-called residual) blocks, each
block being in turn a stack of convolutional layers. The inno-
vation is that the output of a block is also connected with its
own input through an identity mapping path. This alleviates
the vanishing gradient problem, improving the gradient back-
ward ﬂow in the network and allowing to train much deeper
networks. We choose our model to have 50 convolutional
layers (aka. ResNet50).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about the specific data annotation techniques used in their deep learning pipeline. However, based on common practices in deep learning pipelines, especially those involving image recognition tasks like plant classification, we can infer that they likely employed some form of labeling or categorization technique.

In the case of the Google Search Image dataset mentioned, the authors selected 3680 labels with more than 12 images in their training dataset. These labels could be considered as categories or classes under which the corresponding images were grouped. Each image was then assigned a label, effectively 'annotating' it with its respective category.

While the text does not explicitly mention bounding box annotation or instance segmentation, these techniques are typically used when dealing with multiple objects within an image or when precise localization of objects is required. Given that the paper focuses on plant classification, where the goal is to identify the type of plant rather than locate individual plants within an image, such detailed annotations may not have been necessary.

Therefore, while the exact data annotation techniques used in this particular study remain unclear due to lack of explicit information, it is reasonable to assume that basic labeling or categorization was employed.