Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

However,  the  rise  of  cheap  and  powerful  sensors  has  created  an 
ever-increasing data glut.  To be effective, these new tools must be 
coupled  with  new  automated  approaches  to  processing  and 
analyzing wildlife data streams. 

Here we describe examples of how we are leveraging advances in 
the areas of big data and deep learning to help researchers extract 
meaningful  information  from  the  torrent  of  new  sensor  data,  and 
improve the adaptive management of natural systems. 

4. DEEP LEARNING FOR 

BIODIVERSITY  
4.1.Big data infrastructure

!
 
The specific subfield of ML that we have invested in is known as 
Deep  Learning  (DL)  [31].  DL  is  a  quickly  growing  and  vibrant 
field;  here  we  summarize  our  use  of  DL  and  postulate  how 
biodiversity monitoring can be improved using various properties 
of DL algorithms.

See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/282290618

Deep Learning for Large Scale Biodiversity Monitoring

Conference Paper · September 2015

DOI: 10.13140/RG.2.1.1051.7201

CITATIONS
26

3 authors:

David J Klein

45 PUBLICATIONS   2,299 CITATIONS   

SEE PROFILE

Bernie Tershy

University of California, Santa Cruz

162 PUBLICATIONS   10,146 CITATIONS   

SEE PROFILE

READS
1,677

Matthew Mckown

Conservation Metrics, Inc.

19 PUBLICATIONS   545 CITATIONS   

SEE PROFILE

All content following this page was uploaded by Bernie Tershy on 29 September 2015.

The user has requested enhancement of the downloaded file.

Boomberg data for good 2015 http://first.bloomberglp.com/documents/d4gx/Environment.zip

Deep Learning for Large Scale Biodiversity Monitoring

David J. Klein

Matthew W. McKown

Bernie R. Tershy

Conservation Metrics, Inc. 
100 Shaffer Rd. 
Santa Cruz, CA 95060

We  see  a  long  and  exciting  roadmap  of  DL-based  improvements 
applied  to  biodiversity  monitoring,  leveraging  various  desirable 
properties of DL algorithms. This includes the property of transfer 
learning  [33],  in  which,  for  example,  models  trained  for  a  given 
species  might  be  used  to  improve  the  results  on  other  related 
species that might have less training data available for it. Also, the 
concept of a joint embedding space [34] might be used to improve 
the natural language interface to our auditing and exploration UI, 
as  well  as  to  combine  multiple  types  of  sensors  (e.g.,  audio  and 
image)  into  a  single  model  that  outperforms  each  individual

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough context to provide a direct link to the data repository of the deep learning pipeline mentioned in the paper. The Bloomberg Data for Good 2015 link provided does not seem to contain any relevant information regarding the deep learning pipeline or its associated data repositories. It would be best to refer directly to the original research paper titled "Deep Learning for Large Scale Biodiversity Monitoring" published in September 2015 by David J. Klein, Matthew W. McKown, and Bernie R. Tershy. However, without access to the full text of the article, I cannot confirm if they have shared their dataset or code in a public repository such as Zenodo, Figshare, Dryad, or GBIF.