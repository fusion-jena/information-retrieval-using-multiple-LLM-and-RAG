Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

et al., 2021; Stowell et al., 2019). Some of the state-of-the-art techniques 
for  handling  big  datasets,  such  as  deep  learning  and  convolutional 
neural networks (Stowell, 2022; Stowell et al., 2019), can be difficult to 
run for ornithologists, managers, and researchers without bioacoustics 
or  engineering  backgrounds.  However,  user-friendly  and  ready-to-use 
machine  learning  approaches  have  recently  been  developed  and  are 
increasingly accessible to respond to real-life monitoring challenges and 
the general public (Cole et al., 2022). Among these approaches is Bird-
NET, a research project between The Cornell Lab of Ornithology and the 
Chemnitz University of Technology. BirdNET facilitates the automated 
detection and classification of bird vocalizations, through a developed 
deep neural network, from sound recordings (Kahl et al., 2021). Bird-
NET is able to identify over 3000 bird species (Wood et al., 2021) and is

EcologicalInformatics72(2022)1019107R. Manzano-Rubio et al.                                                                                                                                                                                                                      

Tolkova, I., Chu, B., Hedman, M., Kahl, S., Klinck, H., 2021. Parsing birdsong with deep 

audio embeddings. arXiv preprint (arXiv:2108.09203).  

Towsey, M., Znidersic, E., Broken-Brow, J., Indraswari, K., Watson, D.M., Phillips, Y., 
Street, G., 2018. Long-duration, false-colour spectrograms for detecting species in 
large audio data-sets. J. Ecoacoust. 2 (1). 

Turgeon, P., Van Wilgenburg, S., Drake, K., 2017. Microphone variability and 

degradation: implications for monitoring programs employing autonomous 
recording units. Avian Conserv. Ecol. 12 (1). 

Van Rossum, G., Drake Jr., F.L., 1995. Python tutorial, (Vol. 620).. Centrum voor 

Wiskunde en Informatica, Amsterdam, The Netherlands.

2.4. Automated recognition software comparison

as  the  validation  dataset  to  assess  the  performance  of  BirdNET  and 
Kaleidoscope  Pro.  The  software  performance  was  evaluated  by 
comparing the recall rate and the percentage of occurrences detected 
using each software when compared to the ones obtained in the vali-
dation dataset. The recall rate is an index commonly used in bioacoustics

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning pipeline mentioned in the given context uses audio data format. This is evident from the fact that BirdNET, which employs a deep neural network, is designed to automatically detect and classify bird vocalizations from sound recordings. Additionally, the paper titled "Parsing birdsong with deep audio embeddings" further supports this claim. Therefore, it can be concluded that the deep learning pipeline discussed here primarily utilizes audio data format.