Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We used a GoogLeNet architecture as it was the winner of the 2015
competition imageNet (Szegedy et al., 2015), an identiﬁcation chal-
lenge on 1000 diﬀerent classes. This CNN is composed of 22 layers. It
uses inception modules. Inception modules allow the network to use
convolutions of diﬀerent sizes (1*1, 3*3 and 5*5 pixels) and to weight
each of these convolutions. This network could thus account more or
less strongly for the context of each pixel, which increases the range of
possibilities to improve its performance during the training.

A link to a depository with architecture details is given at the end of
references. We stopped the network training after 70 epochs (i.e. a
complete scope of the dataset where each image is used only once), to
−5, an exponential
prevent overﬁtting. We used a learning rate of 10
learning decay with a Gamma of 0.95, a dropout of 50% and an Adam
Solver type as learning parameters. Those are classic hyper-parameters
for a fast convergence of the network without over-ﬁtting (Srivastava
et al., 2014). The weight initialization is also classic with a random
Gaussian initialization. The training lasted 8 days on our conﬁguration;
we trained and ran our code on a computer with 64GB of RAM, an i7
3.50GHz CPU and a Titan X GPU card for 900,000 images.

We used at least 2200 thumbnails per ﬁsh species class, and batches

240

S. Villon et al.

Ecological Informatics 48 (2018) 238–244

Ecological Informatics 48 (2018) 238–244

of 16 images to train our network. We ran this architecture on Caﬀe (Jia
et al., 2014). To focus on the impact of the training data, we used the
same CNN architecture for our training and test procedures.

2.3. Building the training datasets

Using the raw training dataset of 20 ﬁsh species (Table S1) we built
4 diﬀerent datasets to assess the inﬂuence of the dataset building on
classiﬁcation results (Table S2).

The ﬁrst training dataset T1 contained raw ﬁsh thumbnails (T0) and

their respective mirror images.

More precisely, we doubled the number of thumbnails per ﬁsh in-
dividual by ﬂipping each thumbnail with respect to the vertical axis.
Such a procedure homogenizes the proportion of left-oriented and
right-oriented individuals in the database and we hypothesize it could
improve the average identiﬁcation rate since ﬁsh individuals are seen in
all positions.

The fourth training dataset T4 contained thumbnails from T3 minus
the “part of ﬁsh”, which is replaced by 20 classes “part of species”
obtained by splitting thumbnails from each species. The diﬀerence
between T3 and T4 was that T3 contained only one global class “part of
ﬁsh” whereas T4 contained as many “part of species” classes as there
were “ﬁsh” species.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The deep learning model was trained using a computer with 64GB of RAM, an i7 3.50GHz CPU, and a Titan X GPU card. No mention of TPUs was made in the provided context.