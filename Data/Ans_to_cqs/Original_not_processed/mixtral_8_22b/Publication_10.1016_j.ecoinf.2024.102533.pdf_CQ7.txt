Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.6. Step 5: Clustering the freshness data using six body parts parameters 

The  most  suitable  number  of  clusters  from  the  previous  stage  be-
comes the standard for the proposed number of freshness classes. Each 
species  attains  several  freshness classes  based  on  its  freshness strong-
hold. We group the data using the clustering method to automatically 
determine freshness class based on the dataset. Intuitively, the clustering 
method partitions data where similar data are grouped in one cluster, 
while dissimilar data are separated into other clusters. The partitioning 
occurs automatically according to the clustering algorithm. 

2.7. Step 6: Evaluating the clustering results

Therefore, the data normalization stage is unnecessary.

beling  is  explaned  in  the  following  sub-section.  Meanwhile,  species 
divided into three classes were labeled according to the three available 
classes.

2.7. Step 6: Evaluating the clustering results 

Clustering divides data into groups based on inherent characteristics; 
not requiring external information, such as, classes which become data 
labels. Therefore, the created groups align naturally with the data con-
ditions  and  the  clustering  algorithm.  As  a  result,  the  evaluation  of 
clustering results is conducted internally, using Silhouette and Calinski- 
Harabasz.  High  evaluation  scores  on  both  methods  indicate  that  the 
clustering results obtained by the clustering method is the best outcome. 

2.8. Elbow method

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it does not provide explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, typically, the data is divided into three sets: training set, validation set, and testing set. The training set is used to fit the model, while the validation set is used to tune hyperparameters and prevent overfitting. Lastly, the testing set is used to evaluate the final performance of the trained model. The division ratio can vary depending on the size of the dataset but commonly ranges between 60-80% for training, 10-20% for validation, and 10-20% for testing.