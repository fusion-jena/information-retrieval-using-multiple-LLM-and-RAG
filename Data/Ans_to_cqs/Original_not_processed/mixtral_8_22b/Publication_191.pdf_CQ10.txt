Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

deeper, its optimization capability can be further improved. How- 
ever, deep CNN networks require very large amounts of training 
data. Table 6 shows examples of existing well-known datasets and 
their size as quantity of images. The biggest plant database that 
we  have  found  is  the  PlantClef2015  dataset  [6]  which  has  only 
around 113,205 number of images. This is still far from matching 
the scale and variety of existing general major datasets for images 
[51,52,55] , videos [53] or languages [54] . In addition, we can see 
that the PlantClef2015 dataset [6] has one of the largest number 
of object categories but the least number of images. For example, 
compared to the ILSVRC 2010 dataset [55] , it has less than 10% of 
their total images but the same number of categories. Hence, to

Based on all the facts that support the eﬃciency of leaf fea- 
tures learned using CNN for species identiﬁcation, it now appears 
undeniable  that  CNN  is  a  key  tool  to  assist  researchers  to  dis- 
cover which the leaf features are most effective for plant species 
identiﬁcation. Nevertheless, we come up against a common ques- 
tion that is often arises in the ﬁeld of deep learning: how many 
convolutional layers are required in CNN to achieve the best opti- 
mization ability in modeling plant data? Is using only the AlexNet 
model suﬃcient? Based on numerous publications on object clas- 
siﬁcation  benchmarks,  we  observe  a  dramatic  increase  in  depth 
for CNN in achieving the state-of-the-art result. For example: from 
5 convolutional layers in AlexNet [32] to 16 in VGGNet [48] , 21 
in GoogleNet [49] , and then to 164 in ResNet [50] . This conveys 
the important message that when the network goes deeper and

[54] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, 
L.-J. Li, D.A. Shamma, et al., Visual genome: connecting language and vision 
using crowdsourced dense image annotations, arXiv: 1602.07332 (2016). 
[55] A. Berg, J. Deng, L. Fei-Fei, Large scale visual recognition challenge 2010, 2010, 

S.H. Lee et al. / Pattern Recognition 71 (2017) 1–13 

13 

Sue Han Lee received Master degree in Electrical and Electronics Engineering from Shinshu University, Japan in 2014. She is currently pursuing the Ph.D. degree at the 
Faculty of Computer Science and Information Technology, University of Malaya, Malaysia. Her research interest is computer vision, with main focus on plant recognition.

In Section 4 , using the V1 strategy on Malayakew dataset, we 
analysed the global response of ﬁlters in each convolution layer. 
In this section, in order to gain insights into CNN, we further ex- 
plore the local responses of individual ﬁlters in each convolution 
layer. We randomly subsample some of the feature maps/channels 
in each layer and reconstruct them back to image pixels to reveal 
the structures within each patch that stimulated a particular fea- 
ture map using the DN approach [36] . We also run through all the 
training samples, and subsequently discover which portions of the 
training images caused the ﬁring of neurons. By doing this, we can 
improve our understanding of the transformation of the features 
learned in each layer and realise the characteristic of each layer in 
the CNN. Fig. 4 shows the feature visualisation of layer 1. We can 
see that some of the ﬁlters learned are similar to a set of Gabor-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there is no information about the code repository link of the deep learning pipeline used by Sue Han Lee and her team. Therefore, I cannot provide the requested information.