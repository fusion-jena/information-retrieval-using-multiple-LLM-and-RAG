Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

−

Our choices of hyperparameters such as k and the
training parameters such as the stopping criterion were
based on preselected values that were not ﬁne-tuned
on any data set. In extensive simulations, this simple
procedure was necessary due to computational reasons.
When applying in practice on real data, it is possible to
ﬁne-tune all the hyperparameters using a validation set.
We can ﬁrst randomly select a subset of the reference
species as the validation set, use these as testing data
to tune the parameters for the given data set, and then
train one last time with all the data with the ﬁne-tuned
parameters. Note that such a procedure will require
repeated training and can be slow, and our preliminary
results (Table S2 of the Supplementary material available
on Dryad) show that the gain in accuracy obtained can
be small.

is placed independently, and the result is compared
against the full reference tree before pruning the query
(i.e., the true tree for simulations and the ASTRAL tree
for WoL). The error metric we report is the number of

the gene tree and eq,n is the number of branches between queries and species i on species tree.

DEPP implementation details.—We implemented DEPP
using PyTorch and treeswift python packages (Moshiri
2020) and trained the models on 2080Ti NVIDIA GPUs.
The embedding size k is set to 128 for data sets with 200
taxon and 512 for larger data sets (including the real web-
of-life [WoL] data set). Other hyperparameters are ﬁxed
to their defaults (Table S2 of the Supplementary material
available on Dryad) unless otherwise speciﬁed. DEPP
is trained on the reference tree and is used to compute
distances that are then fed to APPLES-II (Balaban
et al. 2022), used identically to APPLES-II+JC (see
below). Branch lengths of the backbone tree provided
to DEPP are re-estimated using RAxML-8 (Stamatakis
2014) under the GTR+CAT model. Given more than one
gene, DEPP has two options: concatenating genes or
computing a summary of distances. For each query, we
can compute the distance between a query and backbone
species j according to each of the N genes, obtaining

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
According to the provided context, the hyperparameters of the model, including 'k' and the training parameters like the stopping criterion, were based on preselected values that were not fine-tuned on any dataset. This approach was adopted due to computational limitations during extensive simulations. However, when applying the method in practice on real data, it is suggested that all the hyperparameters could be fine-tuned using a validation set. This process involves selecting a subset of the reference species as the validation set, tuning the parameters using these data, and finally retraining the model with all the data using the fine-tuned parameters. It is noted that this procedure may be computationally intensive and slow, and the gains in accuracy might be minimal. Unfortunately, the context does not provide specific information about the optimization methods used, such as grid search or random search. Therefore, while it suggests that hyperparameter optimization is possible, it does not specify which optimization techniques are employed.