Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

dataset is being used to obtain the pretraining weights for our proposed
model. After augmenting the dataset, the number of images increased to
185,431 with 38 classes.

3.3. Dhan-Shomadhan dataset

individual extraction of features. Such techniques acquire characteris-
tics directly from the unprocessed data,
improving accuracy and
robustness (Archana and Jeevaraj, 2024; Mumuni and Mumuni, 2024;
Yang et al., 2023a). In addition, deep learning effectively manages
extensive datasets, enhancing the ability to apply knowledge across
many scenarios in agricultural settings.

promotes

ensures

and

3.1. Data acquisition

To completely validate the network presented in this study, two
types of public datasets are being utilized. The first is the Plant Village
(Hughes and Salathe, 2016) dataset, which is used to pre-train the net-
work’s weights. The second is the Dhan-Shomadhan dataset (Hossain,
2023), which is applied to train the final model for diagnosing rice leaf
diseases in the field.

3.2. PlantVillage dataset

For our experimental setup of training the BEiT model, we employed
an NVIDIA RTX 3060 Ti GPU coupled with an AMD Ryzen 9 5900X CPU
and 32 GB of RAM to ensure robust processing capabilities necessary for
handling large datasets and complex model architectures. Our model is
developed using TensorFlow within a Jupyter Notebook environment,
facilitating an interactive setup that supports real-time adjustments and
visual feedback. Each image is standardized to 224 × 224 pixels for
training and subjected to various data augmentation techniques like
random rotations and color adjustments to enhance model robustness.
The training parameters mainly consist of using the Adam optimizer
(cid:0) 5 and adopting categorical cross-entropy
with a learning rate of 1 × 10
as the loss function, specifically designed for optimizing multi-class
classification tasks. To improve the effectiveness of training and the
performance of
such as Reduc-
the model, various callbacks

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there isn't any explicit mention of where the data repositories of the deep learning pipeline are available. The mentioned datasets - Plant Village and Dhan-Shomadhan - can be found through their respective citations or sources, but it does not specify if they have been uploaded to specific data repositories such as Zenodo, Figshare, Dryad, or GBIF. Therefore, I cannot provide a definitive answer regarding the availability of these datasets in those particular data repositories.