Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 3. CNN Architecture.

No.

Layers

Output Shape

Parameters

Dropout Rate

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Dropout
Flatten
Fully Connected
Activation (ReLu)
Fully Connected
Activation (softmax)

128 × 128 × 3
128 × 128 × 32
—
64 × 64 × 32
64 × 64 × 32
—
32 × 32 × 32
32 × 32 × 64
—
16 × 16 × 64
16 × 16 × 64
16,384
64
—
4
—

—
896
—
—
9248
—
—
18,496
—
—
—
—
1,048,640
—
—
260

—
—
—
—
—
—
—
—
—
—
0.4
—
—
—
—
—

4.2.1. Data Augmentation

Execution Time

All runtimes reported in this section were measured on the Google Colab repository
with a CPU running at 2.30GHz. Table 10 presents a detail of the runtime for each CNN
model. The training runtime for VGG16, Xception, and ResNet50 is 22.27, 21.26, and
30.8 min, respectively. Additionally, the prediction runtime for these models is 0.803,
0.827, and 1.835 s, respectively. The training runtime for DenceNet121 and the proposed
model is 18.34 and 16.43 min, and the prediction runtime is 4.134 and 0.976 s, respectively.
Accordingly, the computation overhead varies from one model to another. However,
PHE data are signiﬁcantly fast during both training and prediction and therefore the
computation overhead of the proposed encryption schema is low.

Remote Sens. 2021, 13, 2221

21 of 26

Figure 9. Training accuracy of different CNN models.

Table 10. CNN models’ run-time.

CNN Models

Training Run-Time

Prediction Run-Time

Training Run-Time

Prediction Run-Time

VGG16
Xception
ResNet50
DenseNet121
The proposed model

22 min 27 s
21 min 26 s
30 min 8 s
18 min 34 s
16 min 43 s

0.803 s
0.827 s
1.835 s
4.134 s
0.976 s

5.5. Discussion

Recent years have seen increasing concerns about protecting the privacy of conﬁdential
information when processing data using models. This leads to the need for cryptographic
techniques to solve privacy concerns in data-driven models. Several PPDL techniques have
been proposed in the literature to solve these concerns. This research is, to the best of our
knowledge, the ﬁrst work that investigates PPDL for satellite image classiﬁcation.

VGG16: Simonyan and Zisserman (2014) proposed the architecture of the VGG16
model. VGG16 is a CNN model that consists of 16 hidden layers, including a total with
convolutional, max pooling and fully connected layers. VGG16 was trained on the
ImageNet dataset, which consists of 1,000,000 images. VGG16 is constructed of ﬁve
blocks of convolutional layers with a 3 × 3 ﬁlter and stride of 1. After each convolution,
an activation function (ReLU) is executed, followed by a max-pooling process with
a 2 × 2 max ﬁlter and stride of 2. At the end of the ﬁve blocks, three FC layers are
added: the ﬁrst two layers with 4096 neurons and an ReLU activation function each,
and the third layer with 1000 neurons and a SoftMax activation function [21]. The
default input size is 224 × 224 × 3 [22].
ResNet-50: The ResNet model’s architecture was proposed in 2015 by He et al. ResNet-
50 is a 50 convolutional neural network layers pre-trained on the ImageNet dataset [23].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there isn't any specific mention or details regarding the deployment process of the trained deep learning model. Therefore, it cannot be determined what process was followed to deploy the trained deep learning model, such as whether model serialization or platform selection took place.