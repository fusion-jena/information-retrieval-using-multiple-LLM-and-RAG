Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

18. Chu, Y.; Yue, X.; Yu, L.; Sergei, M.; Wang, Z. Automatic image captioning based on ResNet50 and LSTM with soft attention. Wirel.

Commun. Mob. Comput. 2020, 2020, 8909458. [CrossRef]

19. Wazirali, R.; Intrusion detection system using fknn and improved PSO. Comput. Mater. Contin. 2021, 67, 1429–1445. [CrossRef]
20. Alsharman, N.; Jawarneh, I. Googlenet cnn neural network towards chest ct coronavirus medical image classiﬁcation. J. Comput.

21.

Sci. 2020, 16, 620–625. [CrossRef]
Joshi, K.; Tripathi, V.; Bose, C.; Bhardwaj, C. Robust sports image classiﬁcation using inceptionv3 and neural networks. Procedia
Comput. Sci. 2020, 167, 2374–2381. [CrossRef]

22. Bennett, M.K.; Younes, N.; Joyce, K. Automating Drone Image Processing to Map Coral Reef Substrates Using Google Earth

Engine. Drones 2020, 4, 50. [CrossRef]

23. Raphael, A.; Dubinsky, Z.; Iluz, D.; Netanyahu, N.S. Neural Network Recognition of Marine Benthos and Corals. Diversity 2020,

12, 29. [CrossRef]

SVM ClassifierLinear KernelBleached or unbleached coral12345678910abbbb12345678910Input ImageConvolutional Layer 1Convolutional Layer 2Convolutional Layer 3Convolutional Layer 4Convolutional Layer 5Fully Connected Layer 6 Fully Connected Layer 7ClassifierOutputDescriptionStride sizeab4 x 41 x 1227 x 227 x 355 x 55 x 9627 x 27 x 25613 x 13 x 38413 x 13 x 38413 x 13 x 25640964096Big Data Cogn. Comput. 2021, 5, 53

7 of 15

Algorithm 1: k-means Clustering Algorithm.

Input: Features as data points
Let features F = {F1, F2, F2, ..., Fn} is set of data points and C = {C1, C2, C3, ..., Co}
is set of centers.

Figure 3. The proposed framework steps visual representation.

3.1. Explanation of Steps

Initially, an image is taken with the help of an underwater drone. In the next step,
the image is segmentized and divided into small patches. Features are extracted from
each patch with the help of handcrafted descriptors and D-CNNs. A visual vocabulary

Big Data Cogn. Comput. 2021, 5, 53

5 of 15

(VV) is created, as shown in Figure 4, this visual vocabulary is the features extracted
from these features, and the training features are passed to classiﬁer i.e., SVM, which
classiﬁes whether the VV-features are of bleached coral or healthy coral. We used different
handcrafted features as well as different D-CNN’s but AlexNet shows the highest accuracy.
We used different classiﬁers i.e., SVM, kNN, and decision tree, but SVM outperforms all
other classiﬁers.

Figure 4. Visual Vocabulary of features.

3.2. Feature Extraction

Similarly, in [8] hyper-spectral bottom index imagery is used for bottom-type classiﬁca-
tion in coral reef areas. The drawback of this technique is the need for an enormous number
of samples in the dataset for achieving higher accuracy. In [9], they proposed a method
of deep convolutional neural network VGG-19 for corresponding coral classiﬁcation that
needs a massive dataset for better accuracy.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the code repository link of the deep learning pipeline. Therefore, it is not possible to determine the specific link to GitHub, GitLab, BitBucket, or any other code repository platform. It would be necessary to have additional information or access to the relevant resources to locate the desired code repository link.