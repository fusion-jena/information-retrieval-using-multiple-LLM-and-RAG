Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Index  Terms- Convolutional  neural  networks,  bioacoustics, 

flight calls, deep learning, data augmentation. 

1.  INTRODUCTION

The  automated  classification  of  migrating  birds'  ftight  calls  has 
the  potential  to  yield  new  biologieal  insights  and  conservation  ap 
plications  for  birds  that  vocalize  during  migration.  In  this  paper 
we  explored  two  state-of-the-art classification  techniques  for large 
vocabulary  bird  species  classification  from  flight  calls:  a  "shallow 
learning" unsupervised dietionary learning  method and  a deep con 
volutional  neural  network  combined  with  data  augmentation.  The 
models  were evaluated on a dataset of 5428  ftight  calls from 43  dif 
ferent  species, and  were  compared  against  a  baseline  model  based 
on  MFCCs.  We  showed  that  the  two  models  perform  comparably, 
yielding  a  mean  classification  accuracy  of 0.94  and  significantly 
outperforming  the  MFCC  baseline  (0.85).  We  also  compared  the 
performance of the CNN model  with  and  without augmentation and

The  methods  compared  in  this  study  are  evaluated  in  terms  of 
classification  accuracy.  We  divide  the  CLO-43SD  dataset  into  5 
folds  and  perform 5-fold cross  validation,  and  report the  results  as 
a  box-plot  generated  from  the  per-fold  accuracies.  For  identfying 
the best training epoch for the CNN model we use  1 of the 4 training 
folds  as  a validation set, and train on the remaining 3 folds. 

4.  RESULTS AND DISCUSSION 

The results for the MFCC baseline, SKM and CNN models are pro 
vided  in  Figure  1  (left  of the  dashed  line).  Mean  accuracies  are 
indicated  by  the  red  squares.  We  see  that  both  models  based  on 

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:58:01 UTC from IEEE Xplore.  Restrictions apply. 

142 

1.00 

0.98 

0.96 

,., 
~ 0.94 
:; 
8  0.92 
<l: 
ยง  0.90 
~ '"'  0.88 
. ~ 
.!l!  0.86 
ร 

0.84 

0.82 

0.80 

MFCC 

SKM 

CNN 

FUSION

Automated c1assification of organisms to  species based on  their vo 
calizations  would  contribute  tremendously  to  abilities  to  monitor 
biodiversity, with a wide range of applications in the field of ecology. 
In  particular, automated c1assification of migrating birds'  flight calls 
could yield new biological insights and conservation applications for 
birds that vocalize during  migration.  In this paper we explore state 
of-the-art c1assification techniques for large-vocabulary bird species 
c1assification  from  flight  calls.  In  particular, we contrast a "shallow 
learning"  approach  based on  unsupervised dictionary  learning with 
a deep convolutional  neural network combined with data augmenta 
tion.  We show that the two models perform comparably on a dataset 
of 5428  flight  calls spanning 43  different species, with  both  signifi 
cantly  outperforming an  MFCC  baseline.  Finally, we  show  that  by

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the dataset used was diverse, consisting of 5428 flight calls from 43 different species. This diversity helps prevent overfitting and improves the model's ability to generalize to unseen data. Secondly, the models were evaluated using 5-fold cross-validation. Cross-validation is a technique used to assess how well a statistical model will generalize to an independent dataset. It involves reserving a portion of the available data for testing the model and using the rest of the data for training. This process is repeated multiple times, each time with a different portion of the data being used for testing. The results are then averaged across the runs. Lastly, stratified splitting was not explicitly mentioned but can be assumed given the nature of the task. Stratified sampling ensures that each fold in the cross-validation contains approximately the same percentage of samples of each target class as the complete set. This is particularly important when dealing with imbalanced datasets, which is often the case in real-world scenarios.