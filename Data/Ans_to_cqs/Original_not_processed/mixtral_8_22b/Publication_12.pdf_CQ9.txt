Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Biological Conservation 241 (2020) 108269

Contents lists available at ScienceDirect

Biological Conservation

journal homepage: www.elsevier.com/locate/biocon

Automatic standardized processing and identification of tropical bat calls
using deep learning approaches

T

Xing Chena,1, Jun Zhaob,1, Yan-hua Chena, Wei Zhoub,*, Alice C. Hughesa,*
a Center for Integrative Conservation, Xishuangbanna Tropical Botanical Garden, Chinese Academy of Sciences, Menglun 666303, China
b Software School, Yunnan University, Kunming 650500, China

A R T I C L E I N F O

A B S T R A C T

Keywords:
Bats
Bioacoustics
Automated monitoring
Algorithms
Deep learning
Neural network
Automatic processing
Biodiversity metrics
Machine learning
Calls
Echolocation
Monitoring protocol

Fig. 1. Schematic diagram of pipeline. We first built model
and then test the model. There are three python scripts used to
for
Coverting_image.py,
including
Making_database.py, and Training.py in a self-developed open
source software Waveman. Tested process using both filtered
images and unfiltered audio-files.

modelling,

2

X. Chen, et al.

Biological Conservation 241 (2020) 108269

Table 1
Taxa summary of the 36 species and itscall information.

Family

Species

Individual number**

No. of images***

Location

Release type

In this study, we demonstrate that our model has high enough ac-
curacy to identify the 36 tropical bat species for both filtered and un-
filtered datasets. For the selected data BatNet outperforms CNNFULL by
increasing the overall accuracy rate from 77% to 91% using the vali-
dated dataset, and shows greatest improvement for the 12 vesperti-
lionid species. This improvement indicates the complicated architecture
of BatNet is more suitable for the application of unfiltered audio-files
recorded in tropical regions than simple networks (i.e., CNNFULL).
Secondly, the unfiltered data collected from different environments,
including nature habitats (i.e., CE (cave entrance) and DF (densely
forested) where bats usually emerge) and human living areas (i.e., AU
(Auditorium) is relatively wide open). The audio-files not only con-
tained no call regions, but only contained signal regions full of echos,
background noises, and high intra-species acoustic variation (such as

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., et al., 2011.
Scikit-learn: machine learning in python. J. Mach. Learn. Res. 12, 2825–2830.
Pennell, M.W., Eastman, J.M., Slater, G.J., Brown, J.W., Uyeda, J.C., FitzJohn, R.G., et al.,
2014. Geiger v2. 0: an expanded suite of methods for fitting macroevolutionary
models to phylogenetic trees. Bioinformatics 30, 2216–2218.

Proença, V., Martin, L.J., Pereira, H.M., Fernandez, M., McRae, L., Belnap, J., et al., 2017.
Global biodiversity monitoring: from data sources to essential biodiversity variables.
Biol. Conserv. 213, 256–263.

Rich, L.N., Davis, C.L., Farris, Z.J., Miller, D.A., Tucker, J.M., Hamel, S., et al., 2017.
Assessing global patterns in mammalian carnivore occupancy and richness by in-
tegrating local camera trap surveys. Glob. Ecol. Biogeogr. 26, 918–929.

Russo, D., Jones, G., 2002. Identification of twenty-two bat species (Mammalia: chir-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The article does not provide specific information about the availability or location of the data repository for the deep learning pipeline. It mentions the use of a self-developed open source software called Waveman, which includes three Python scripts: Converting\_image.py, Making\_database.py, and Training.py. However, there is no mention of any publicly accessible repositories such as Zenodo, Figshare, Dryad, or GBIF. To find the exact location of the data repository, one would need to contact the authors directly or search for additional resources related to their work.