Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.5.1. Model selection and parametrization 

For  the  classification  task,  before  the  implementation  of  deep 
learning models, all images were resized to the same resolution (227Ã—
197  pixels)  by  considering  the  mean  dimensions  of  the  set,  and  then 
normalized to the [0,1] range (Na and Fox, 2020). Then, six open source 
CNNs  were  selected:  VGG16  (Simonyan  and  Zisserman,  2015), 
ResNet50,  ResNet101  (He  et  al.,  2016),  Inception-v3  (Szegedy  et  al., 
2016), DenseNet201 (Huang et al., 2017) and EfficientNetB0 (Tan and 
Le,  2019).  These  algorithms  were  selected  because  of  their  ease  for 
transfer  learning and  high  performance  on  similar classification  tasks 
(Arun  and  Viknesh,  2022;  Vallabhajosyula  et  al.,  2022).  For  model 
optimization, we used the Adam optimizer algorithm (Kingma and Ba, 
2015), a batch size of 10 and 100 epochs. The learning rates were chosen 
(cid:0) 6 showing 
from empirical trials over 100 epochs, with and 10

The last decade has also seen enormous technological advances in 
our  ability to  identify,  access,  and  analyse online  digital  data  (Farley 
et  al.,  2018;  Hampton  et  al.,  2013;  Runting  et  al.,  2020).  The  use  of 
artificial  intelligence,  and  specifically  of  machine  learning  and  deep 
learning  algorithms,  such  as  Convolutional  Neural  Networks  (CNNs), 
have led to significant progress in environmental monitoring from on-
line  digital  images,  including,  for  instance,  the  recognition  and  sur-
veillance of plant diseases (e.g., Abade et al., 2021), the classification of 
land cover (ElQadi et al., 2020; Xu et al., 2017) or the detection and 
classification of animals in camera traps (Tan et al., 2022), requiring a 
low degree of human supervision (Lusch et al., 2018).

EcologicalInformatics81(2024)1026029Faster R-CNN ResNet101 iNaturalistFaster R-CNN ResNet101 MS COCOFaster R-CNN ResNet50 iNaturalistFaster R-CNN ResNet50 MS COCOFaster R-CNN Inception-v2 MS COCOAverage inference time per image (ms)3951063668958mAP@0.50IOU76.8579.2374.9380.8081.71Total loss2.241.142.241.201.08A.S. Cardoso et al.                                                                                                                                                                                                                              

with other plant species. Moreover, there are no other plant species in 
Portugal (our study area) with the same features as C. selloana. Both of 
these particularities may be the source of the high results observed in 
this study. 

4.4. Monitoring the invasive alien Cortaderia selloana from online digital 
images

of data for some contexts, particularly if the aim is informing manage-
ment activities. Furthermore, there is no guarantee that the quality and 
resolution of publicly available images will enable precise identification 
of the species. Incorporating other forms of online data, such as textual 
information (e.g., tags, captions, comments) may further improve the 
generalization of deep learning tools for invasive alien species detection, 
mapping, and monitoring (Jeawak et al., 2018; Tateosian et al., 2023; 
Terry et al., 2020). Lastly, the spatial concentration bias of social media 
images, particularly the prevalence of photo captures in some areas at 
the  expense  of  other  areas  (e.g.,  due  to  accessibility  limitations, 
appealing attributes, among others; Di Minin et al., 2015), may also lead 
to limitations in the detection of invasive plants (and other species or 
natural assets).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it can be inferred that the primary data format used in the deep learning pipeline is images. This is evident from several mentions of using images throughout the process, such as resizing and normalizing them for input into various CNN architectures like VGG16, ResNet50, ResNet101, Inception-v3, DenseNet201, and EfficientNetB0. Additionally, the context discusses applications of deep learning in processing online digital images for ecological purposes, such as recognizing plant diseases, classifying land cover, and detecting animals in camera traps. However, there is no explicit mention of any other data formats being utilized in this specific deep learning pipeline.