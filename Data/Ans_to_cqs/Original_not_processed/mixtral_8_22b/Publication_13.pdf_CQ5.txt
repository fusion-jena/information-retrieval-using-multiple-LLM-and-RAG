Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

and TensorFlow 2.5.0 (https://www.tensorflow.org) libraries, and all

statistical analyses were conducted with R 4.1.0 (R Core Team, 2021).

Between-datasets classification

For the between-dataset prediction, the CNN model was trained with

RE SU LT S

a source dataset to predict images from a different target dataset. The

NN was trained with N images randomly selected from the source

Performance of within-dataset classification

dataset, which was then used to predict all images of the target data-
set and AccT and ΔAcc were measured. We ran the above procedures
for three source–target pairs (training dataset!predicted dataset),
GH!LH, GH!LL and LL!LH. These settings simulate two alternative
scenarios: (i) a global image database is used to predict local samples
(GH!LH and GH!LL) and (ii) conventional

images, as

those

Effects of datasets and the number of images

The accuracy of within-dataset classification and the effect of the

offering high numbers of images per taxon, which is more difficult to

200 images in each of the three datasets used here. However, the

obtain locally, although it is critical for increasing the performance of

degree of accuracy is greatly affected by the image quality and the

the CNN-based classification (Figure 2; Donahue et al., 2013; Valan

complexity of the dataset: both the LL (low image quality) and in

et al., 2019, 2021).

(a)

(b)

F I G U R E 6

Prediction probabilities for the successful, failed and out-of-distribution predictions at a 0.95 threshold (horizontal line). (a) Intra-
dataset predictions of LH images using 400 randomly selected images for training. (b) Predictions of LH images using 800 GH images for training.

representing single-specimen photographs by local taxonomists, are
used to predict local high-resolution images (LL!LH).

Between-datasets classification with domain adversarial
training

In addition to the standard CNN setups described above, we employed

large reduction of accuracy, hence difficulty in transfer.

the domain adversarial training of neural networks (DANN, Ganin

Divergence between the source and target datasets was mea-

et al., 2016) which incorporates a certain portion of the unknown tar-

sured with a dataset classification error. A linear support vector

gets in the model. The DANN model jointly predicts the class (family

machine (SVM) was trained to classify images to the source or target

label) of the source images and the dataset (domain) of all input images

dataset with the features of 200 randomly selected images from both

(as in the previous section) by adding layers for the dataset classifica-

Local low quality (LL) dataset

of 0.6. The neural network was trained with the stochastic gradient

descent algorithm with the softmax cross-entropy loss for 300 epochs.

We used a batch size of 10 and a fixed learning rate of 0.01, and the

convergence of loss was visually assessed. The numbers of units in the

A subset of single specimens (taken from the bulk samples) were indi-

two FC layers (512 and 256 for the first and second FC layers, respec-

vidually photographed using a conventional stereoscope NIKON

tively) and the dropout rate were determined by five-fold cross-

SMZ1270i equipped with a NIKON DS-Fi3 Microscope Camera (5.9

megapixels) controlled by the NIKON DS-L4 v.1.5.0.3 control unit.

These images were denoted Local Low Quality (LL) dataset. These pho-
tographs were intended to represent a more realistic scenario of local

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Three main datasets were used in this study: Global High Quality (GH), Local High Quality (LH), and Local Low Quality (LL). The GH dataset consists of high-quality images obtained from various sources such as museum collections and online databases. The LH dataset contains high-quality images taken by professional photographers specifically for this project. Lastly, the LL dataset includes lower-quality images captured using a conventional stereoscope microscope camera.

The purpose of these datasets is to evaluate the performance of the Convolutional Neural Network (CNN) model under different scenarios. For instance, one scenario involves using a global image database (GH) to predict local samples (LH and LL), while another scenario focuses on predicting local high-resolution images (LL) based on single-specimen photographs taken by local taxonomists (LH). Additionally, the study employs Domain Adversarial Training of Neural Networks (DANN) to incorporate some unknown targets into the model, aiming to reduce the large accuracy gap between source and target datasets.