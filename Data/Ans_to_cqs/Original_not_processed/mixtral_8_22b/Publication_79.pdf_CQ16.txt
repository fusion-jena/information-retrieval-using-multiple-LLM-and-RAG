Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Theresultingnetworkwasthentestedintheremainingregion(e.g.,C).Thisexperimentwasrepeatedthreetimes,i.e.,untilthethreeregionshadasemanticsegmentationresultingfromthecross-validationapproach.Table2showsthenumberofsamplesusedineachexperiment.Forthetrainingandvalidationsets,thosenumbersincludesamplesgeneratedthroughadataaugmentationprocedure.Duringtraining,theearlystoppingcriterion(alsoknownas“patience”inKeras)wassetto50,i.e.,ifafter50epochsthevalidationaccuracydidnotincrease,thetrainingprocesswashaltedFig.5RegionsA,B,andCusedtogeneratesamplepatchesinthespectralinputdataanalysis,accordingtoTable2.Table2Regionsandnumberofsamplesusedfortraining,validation,andtestingproceduresineachcross-validationexperiment.ExperimentTrainingregionsValidationregionsTestingregion1A+B:70%(5439samples)A+B:30%(2331samples)C(645samples)2B+C:70%(6951samples)B+C:30%(2982samples)A(336samples)3A+C:70%(4802samples)A+C:30%(2065samples)B(774samples)Nevesetal.:HierarchicalmappingofBrazilianSavanna(Cerrado)physiognomiesbase

physiognomyoccurs.Similartothepreviousexperiment(Sec.2.4),allsamplesthatcontainanyno-datavaluewereexcluded.Thus,thesixdataaugmentationtechniquesmentionedbeforewereappliedfortheremainingtrainingandvalidationsamples.Thecompletesamplessetwasrandomlysplit:70%and30%wereassignedfortrainingandvalidation,respectively.Theslidingwindowapproachwasalsoemployedtocreatetheresults.Tousethesamesamplegenerationapproachintheentirehierarchicalprocess,thesemanticsegmentationwasrepeatedforthefirstlevel(forest,grassland,andsavanna).Subsequently,thesemanticsegmentationapproachwasemployedforeachresultingsavannaandgrasslandmaps.ThefinalCerradophysiognomiesmap(andtherespectiveaccuracymetrics)iscomposedoftheforestmap(galleryforest),thesavannamap(shrubsavanna,typicalsavanna,woodlandsavanna,Rupestriansavanna,andVereda),andthegrasslandmap(opengrassland,shrubgrassland,Rupestriangrassland,andhumidopengrassland).Theselasttwoweregeneratedinthesecondlevelofclassification.ThesemethodologicalstepsarerepresentedinFigs.1(b

trainingsstoppedbefore100epochs,andstabilizationoccurredbetweenepochs5and93.Ingeneral,allaccuracyvalueswerehigherthan87.5%.ThehighestaccuraciesintrainingwerereachedusingtheRGB+NIR1+NIR2+RedEdgedatasetinexperiments1and3,whereas,inexperiment2,thehighestaccuracywasobtainedforRGB+EVI2.Inthevalidationstep,thehighestaccuraciesforexperiments1and2werereachedusingRGB+EVI2,whereasthehighestaccuracyinexperiment3wasobservedwiththeRGB+NIR1+NIR2+RedEdgedataset.Fortheteststep,theOAsandF1-scoreperclassarepresentedinTable4.TheOAvariedfrom87.4%,usingRGB+LSMM,to89.3%withtheRGB+EVI2dataset.Itcouldbeexpectedthattheeightbanddatasetwouldachievethehighestperformance,sinceitcontainsmorebandsand,consequently,mostofspectralinformation.However,itobtainedthesecondworstOAvalueof87.6%.DespitepresentingthelowestOA,theRGB+LSMMdatasethadthehighestF1-score(0.91)fortheforestclass.Thisisalsoreflectedintheclassdelineationinthemappingresult.Forsavannaandgrassland,thehighestF1-scores(0.92and0.84,respectively)wereachievedwit

Table5Confusionmatrix(innumberofpixels),precision,recall,andF1-score(highlightedinbold)forthefirstlevelofclassification,usingtheRGB+EVI2dataset.OA=92.8%.PredictedReferenceGrasslandSavannaForestTotalPrecisionGrassland5,906,317315,6738,0846,230,0740.95Savanna697,3947,788,06593,3078,578,7660.91Forest36,92996,4232,441,1112,574,4630.95Total6,640,6408,200,1612,542,502——Recall0.890.950.96——F1-score0.920.930.95——Fig.8Patchesof:(a)theWorldView-2image;(b)thereferencedata;(c)resultingthematicmapusingRGB+EVI2dataset;and(d)resultingthematicmapusingRGB+LSMMdatasets.G×Sarethemisclassifiedareasbetweengrasslandandsavanna;S×F,betweensavannaandforest;andG×F,betweengrasslandandforest.Nevesetal.:HierarchicalmappingofBrazilianSavanna(Cerrado)physiognomiesbasedondeeplearningJournalofAppliedRemoteSensing044504-13Oct–Dec2021(cid:129)Vol.15(4)Downloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Applied-Remote-Sensing on 16 Nov 2023

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The early stopping criterion, also known as "patience" in Keras, was set to 50 during training. This means that if after 50 epochs the validation accuracy did not increase, the training process would be halted. In other words, the training stopped before reaching 100 epochs and stabilized between epochs 5 and 93. All accuracy values were higher than 87.5%. The highest accuracies in training were reached using the RGB+NIR1+NIR2+RedEdge dataset in experiments 1 and 3, while in experiment 2, the highest accuracy was obtained for RGB+EVI2. In the validation step, the highest accuracies for experiments 1 and 2 were reached using RGB+EVI2, whereas the highest accuracy in experiment 3 was observed with the RGB+NIR1+NIR2+RedEdge dataset. For the test step, the OAs and F1-score per class are presented in Table 4. The OA varied from 87.4%, using RGB+LSMM, to 89.3% with the RGB+EVI2 dataset. It could be expected that the eight band dataset would achieve the highest performance since it contains more bands and consequently most of spectral information. However, it obtained the second worst OA value of 87.6%. Despite presenting the lowest OA, the RGB+LSMM data set had the highest F1-score (0.91) for the forest class. This is also reflected in the class delineation in the mapping result. For savanna and grassland, the highest F1-scores (0.92 and 0.84, respectively) were achieved with the RGB+NIR1+NIR2+RedEdge dataset.