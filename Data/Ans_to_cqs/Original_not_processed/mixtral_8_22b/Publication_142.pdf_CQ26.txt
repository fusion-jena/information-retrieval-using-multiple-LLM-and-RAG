Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Biases in our data arise in part from differences between the
aims of the original data collectors (i.e., the photographers)
and our aims as biodiversity researchers and ecologists. For
example, the spatial distribution of our images was biased to-
ward areas where extensive managed gardens or other displays
exhibited large collections of ﬂowering plants (Figure 2). These
biases could be addressed by choosing alternative sources,
changing the search terms used, or pre-ﬁltering images. For
example, choosing to collect images from social media targeted
at outdoor enthusiasts (e.g., hikers), such as specialist Facebook
groups or ‘‘subreddits,’’ would be less likely to return images
from formal gardens. Images may also be biased taxonomically

tions of the training data, and the gap between these and the test
data on which the developed algorithms will be evaluated.28

network training by reducing internal covariate shift. arXiv, 1502.03167.

Fourth Edition (Springer-Verlag).

10 Patterns 1, 100116, October 9, 2020

For any given research question, ecologists and data scien-
tists should carefully consider the steps that might be required
to ensure the relevance and accuracy of AI-generated data for
any given research question. To aid this we have summarized
our experience into an eight-point list of questions which we
recommend researchers ask themselves when using AI classiﬁer
naturalists:

1. Does the spatial distribution of images ﬁt your needs? Im-
ages from social media are often aggregated in areas of
high population density or tourist hotspots. If the distribu-
tion is biased in some way, could this be accounted for in
subsequent analyses?

2. Can you ﬁlter images before classiﬁcation? For example,
ﬁltering can be done by carefully selecting your source

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. One common approach is stratified splitting, which involves dividing the dataset into subsets based on specific criteria, ensuring each subset has a representative sample of the overall dataset. This technique helps maintain the balance of classes within the dataset, preventing overfitting or underfitting due to imbalanced data.

Oversampling and undersampling are additional methods used to handle class imbalance. Oversampling increases the number of instances in the minority class by duplicating existing samples or generating synthetic examples. Undersampling reduces the majority class size by randomly removing instances or employing more sophisticated techniques like NearMiss or Tomek Links. Both approaches aim to achieve a balanced dataset, improving model performance and generalization.

Diverse data collection is another strategy to mitigate data bias. By collecting data from various sources, demographics, or environments, it becomes possible to capture a broader range of features and patterns, leading to better representation and reduced bias. In the context provided, one suggestion is to gather images from social media platforms targeting outdoor enthusiasts instead of formal gardens, thereby minimizing potential biases related to plant species or locations.

Lastly, filtering images before classification can help eliminate irrelevant or misleading information. Researchers can apply filters based on metadata, image quality, or content, ensuring only relevant and high-quality data enters the deep learning pipeline. This step contributes to improved model performance and reliability.