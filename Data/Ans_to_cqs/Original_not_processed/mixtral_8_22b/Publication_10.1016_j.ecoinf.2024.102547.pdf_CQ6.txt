Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

RMSE_Train 

MAE_Train 

RMSE_Test 

MAE_Test 

10.96 
6.67 
8.99 
6.44 
6.22 
4.75 
5.81 
5.50 
6.02 
4.95 
5.52 
4.02 
6.17 
4.44 
6.49 
4.24 

7.80 
4.62 
6.56 
4.65 
4.30 
3.42 
3.80 
3.78 
3.93 
3.12 
3.93 
2.81 
4.03 
2.98 
4.52 
2.72 

13.41 
7.16 
12.12 
8.23 
9.96 
8.24 
11.90 
10.38 
6.94 
5.70 
7.62 
5.51 
11.25 
6.25 
7.33 
4.93 

9.19 
5.02 
8.99 
6.05 
6.02 
4.97 
7.30 
6.45 
4.11 
3.35 
5.16 
3.38 
6.29 
3.96 
5.48 
3.60  

remotely the marine organism acoustically and then better understand 
the underlying mechanisms driving the observed effects. 

5. Conclusion 

In  this  study,  we  analyzed  a  multifrequency  acoustics  dataset  ac-
quired  from  scientific  echosounders  in  the  West  African  waters  using 
FDA,  both  with  and  without  the  incorporation  of  spatial  dimensions.

examining  data  characterised  by  functional  attributes  distributed  across  a  spatial  domain.  This  analysis  en-
compasses dimension reduction techniques, as well as supervised and unsupervised methods, which take into 
consideration spatial dependencies within extensive datasets.

EcologicalInformatics81(2024)10254713Depth(m)Y. Kande et al.

1.  Dimension reduction by principal component analysis (PCA) 
The first step is to express raw data to functions using 

Xj
s(t) = Xs(t) =

∑P

m=1

cs,j,mbm(t)

(4)  

where b1(t), ….., bP(t) represents the collection of first P basis functions 
(Fourier, Spline, etc). 

Let us recall some FDA notions useful for PCA. The empirical func-

2.2.1. Aggregated data modeling 

To compare with the benchmark work Diogoul et al. (2020), we first 
modeled the layer descriptors by the environmental data, aggregating 
them through the mean. The aggregated variables are: 

tional mean of Xj

s(.) is: 

Xj,n(t) =

1
n

∑

Xj
s(t)

s∈(s1,…,sn)

Xj
s =

1
Ds

∑Ds

p=1

(cid:0)

)

,

tp

Xj
s

(1)  

and the empirical covariance function: 
∑

)(cid:0)

(cid:0)

̂cj,n(t, u) =

1
n (cid:0) 1

s∈(s1,…,sn)

Xj
s(t) (cid:0) Xj,n(t)

Xj
s(u) (cid:0) Xj,n(u)

(5)  

(6) 

)
.

where  Ds  is  the  number  of  depth  where  data  are  available  and 
s ∈ (s1, …, sn).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, several preprocessing steps can be applied to improve its performance and efficiency. These may include:

1. Data Cleaning: Removing or correcting erroneous, missing, or irrelevant data points. In the given context, it might involve removing outliers or handling missing values in the acoustic dataset.

2. Normalization/Scaling: Scaling input features to have similar magnitudes to prevent any feature dominating the others during training. Common techniques include Min-Max scaling, Z-score normalization, or log transformation. For instance, the RMSE and MAE scores could benefit from such transformations if they vary significantly in scale.

3. Feature Engineering: Creating new features from existing ones to help the model learn more effectively. In the case of functional data analysis, this could entail extracting relevant features from the time series data, like frequency components or trends.

4. Dimensionality Reduction: Reducing the dimensionality of the input space to avoid overfitting and improve computational efficiency. Principal Component Analysis (PCA) was mentioned in the context as one possible technique for achieving this.

5. Data Augmentation: Generating additional synthetic samples to increase the size of the training set artificially. While not explicitly stated in the context, this could potentially apply to the acoustic dataset by creating modified versions of the original signals.