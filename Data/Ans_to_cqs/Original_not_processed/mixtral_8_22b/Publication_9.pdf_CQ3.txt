Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

specific segmentation models. The full instructions and options are 

cluded in model training are shown in Figure 1.

provided on the GitHub repository.

2.3 | Model training procedure

2.5 | Sashimi online model repository

We first used the VGG Image Annotator Version 1.0.6 (https://www.

We constructed a website to serve as a repository for the fish seg-

robots.ox.ac.uk/~vgg/softw are/via/via- 1.0.6.html;  Dutta  et  al., 
2016) to manually annotate pixel coordinates to create precise po-

mentation model (presented here) and future, community generated 

organismal  segmentation  models  (https://sashi mi.shawn tyler schwa 

lygonal mask contours directly around the fish body boundary (i.e. 

rtz.com). We aim to inspire other biologists interested in automated 

where the foreground pixels of the target fish body meet those of 

segmentation to create pre- trained models for their organism(s) of 

the background). We intentionally assigned all segmentation masks

lack  of  readily  available  image  datasets  with  high- resolution  image 

We then discuss the strengths and limitations of our approach for 

segmentation mask annotations limits how biologists can accessibly 

processing fish images and consider how this approach can be ex-

engage with deep learning applications to rapidly process images for 

tended to other branches of the tree of life.

SCHWARTZ And ALFARO 2041210x, 2021, 12, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13712 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License2344  |    Methods in Ecology and Evolu(cid:13)on

2 |  M ATE R I A L S A N D M E TH O DS

gamut of fish images— similar to the Gray et al. (2019) implementa-

have  revealed  promising  utility  for  automating  data  collection  ap-

data  collection  increase.  Computer  vision  techniques  provide  one 

proaches for studies in ecology and evolutionary biology at substan-

means  for  accurate  and  scalable  image  pre- processing  in  biology 

tially greater speeds than manual approaches (Christin et al., 2019; 

(Lürig et al., 2021; Muñoz & Price, 2019; Porto & Voje, 2020).

Lürig et al., 2021; Norouzzadeh et al., 2018; Schneider et al., 2019). To 

Machine learning, and especially deep learning algorithms, which 

illustrate, deep learning with CNNs has been successful for ecologi-

permit  the  identification  and  classification  of  complex  patterns  in 

cal applications, including the automated identification of sea turtles 

noisy environments (Carranza- Rojas et al., 2017; Cheng et al., 2017; 

(Gray et al., 2018) and segmentation of cetaceans (Gray et al., 2019)

biodiversity  across  the  tree  of  life  directly  out- of- the- box  without 

when  no  prior  task  experience  is  supplied  (Gray  et  al.,  2019).  We 

additional training.

use transfer learning with pre- trained COCO weights to successfully 

High- fidelity  image  segmentation  is  a  unique  problem  in  com-

automate  image  segmentation  of  fishes  currently  unrepresented 

puter vision and is further constrained by the taxonomic imbalance 

within COCO out- of- the- box.

of biodiversity in readily accessible, annotated datasets for training 

Here, we present Sashimi, a user- friendly toolkit that facilitates 

neural networks to perform segmentation. For image segmentation 

the  rapid  execution  of  accurate,  high- throughput  image  segmen-

to  work,  the  neural  network  must  not  only  successfully  recognize 

tation  of  digitized  organisms— requiring  no  extensive  program-

the presence or absence of a target in an image but also must isolate

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text mentions that the VGG Image Annotator was used to manually annotate pixel coordinates to create precise polygonal mask contours directly around the fish body boundary. This suggests that the technique used for data annotation in this case is instance segmentation, where each individual object (fish body) is outlined precisely within the image. Bounding box annotation, on the other hand, involves drawing a rectangle around the object rather than outlining its exact shape. Instance segmentation provides more detailed information about the location and shape of objects in an image compared to bounding box annotation.