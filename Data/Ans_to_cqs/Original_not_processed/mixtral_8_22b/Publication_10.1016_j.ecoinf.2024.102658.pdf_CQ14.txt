Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  iterative  model  exploration  in  this  work  roughly  follows  the 
Bayesian workflow described by Gelman et al. (Gelman et al., 2020). The 
Bayesian and non-Bayesian model pairs are chosen so that one repre-
sents  a  less  flexible  model  in  terms  of  possible  shapes  of  its  decision 
boundary (Bayesian logistic regression and MLE logistic regression) and 
one  represents  a  more  flexible  model  (Bayesian  GAM  and  random 
forest).

Our process of finding the best model roughly follows the Bayesian 
workflow described by Gelman et al. (Gelman et al., 2020). This is an 
iterative modeling process in which one systemically repeats the cycle of 
inspecting the outputs of a model, analyzing the effects of the model and 
its  configurations,  and  adjusting  the  configurations  or  switching  to 
another model type according to the observations. The cycle is repeated 
multiple times while recording the observations and results.

4.2.1. Baseline model: random forest 

Random forest (Breiman, 2001) utilizes an ensemble of classification 
or regression trees; each tree is grown from a bootstrap sample of the 
training dataset, and represents a series of sequential decisions, in which 
each node of the tree is a binary split made on a predictive feature (e.g., 
whether  the  mean  annual  temperature  is  above  25 
C).  Further,  a 
random subset of features is considered when finding the optimal split at 
each node (we use a value of sqrt(n), n being the number of potential 
predictors, for the size of this subset). When used for classification, the 
outputs from the component trees are put through a majority vote to 
create a single output. This is known to be a simple but powerful method 
of retaining the complex non-linearity of decision trees while avoiding 
overfitting. 

â—¦

The  final  settings  restricted  the  non-linearity  enough  to  make  the 
models fit on random-CV features resemble the results from Bayesian 
and  MLE  logistic  regression.  The  models  fit  on  spatial-CV  features, 
however, still gave very unrealistic predictions for the future, in which 
every area on Earth is a suitable habitat for Elephas maximus. It seemed 
that restricting the priors and the basis dimension of the model has only 
a limited effect that varied depending on the feature set used to fit the 
models. 

6.2.2. Random forest

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The text does not provide explicit information about how the hyperparameters of the model were optimized. However, it mentions that the final settings restricted the non-linearity enough to make the models fit on random-CV features resemble the results from Bayesian and MLE logistic regression. This suggests that some form of optimization was performed to find these final settings. Unfortunately, without further details, we cannot determine whether grid search, random search, or another method was used for hyperparameter optimization.