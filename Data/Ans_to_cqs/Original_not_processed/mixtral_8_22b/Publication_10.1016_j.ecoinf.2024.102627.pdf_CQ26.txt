Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(cid:0)

̂ηs(x) = exp
exp

∑

j

)

θ(x)
f s
(
f j
θ(x)

)

where θ is the set of parameters of the neural network to be optimised by 
minimizing the loss function of Eq. (2). 

Using this very common deep learning framework, it is possible to 
show that the species assemblage predictor Sλ(x) of Eq. (1) is consistent 
λ(x) when  the 
(Lorieul,  2020),  i.e.  it  tends  towards  the  optimal  set  S*
number  of  training  samples  increases.  In  other  words,  our  species 
assemblage predictor is as simple as training a deep neural network with 
a cross-entropy loss function on the presence-only samples and thresh-
olding  the  output  softmax  probabilities  to  get  the  assemblage  of  pre-
dicted species. 

◦

Our species assemblage predictor has theoretical guarantees that we 
have validated on a previously unseen observation set (see Section 3.1). 
However, some bias in the input data could prejudice its predictions. 
Unlike some methods, it has the advantage of not being biased by the 
heterogeneous  sampling  effort.  Indeed,  it  depends  only  on  the  condi-
tional probability ℙX,Y(Y = k|X = x) and not on the marginal distribu-
tion ℙX. Nonetheless, it is impacted by species detection bias, i.e. by the 
fact that some species might be observed more than others conditionally 
to  a  given  x.  Largely  under-observed  species,  in  particular,  may  be 
excluded  from  the  predicted  assemblage.  Conversely,  some  over- 
observed  species  could  be  predicted  at  locations  where  they  are  not 
present. In future work, it would be interesting to study the impact of 
this type of bias on the assemblage-level indicators introduced in this

(IDRIS). A full description of the model architecture, dataset spatial split 
and training procedure can be found in supplementary information (SI) 
Box A. Finally, the settings of our species assemblage model are sum-
marised in the Fig. 1.

2.2.1. Definition 

The objective is to optimise a model returning likely species assem-
blages worldwide while being learned on a set of presence-only obser-
vations. To do so, we optimise a deep species distribution model (Botella 
et  al.,  2018b)  and  further  calibrate  it  to  return  species  assemblages 
including the initial species observed with very high confidence. This 
method is derived from what is called set-valued prediction (or set-valued 
classification) in the machine learning community (Chzhen et al., 2021; 
Mortier et al., 2021). The model is trained on presence-only data, all 
species combined (multi-species SDM), and is then used to predict a set 
of  labels  by  thresholding  the  SDM  output  categorical  probabilities 
associated to species.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The text does not provide explicit details about specific techniques used for addressing data bias during preprocessing of the deep learning pipeline. However, it mentions that the species assemblage predictor is impacted by species detection bias, which means that some species might be observed more or less frequently than others, leading to potential exclusion or false inclusion in the predicted assemblage.

To mitigate such issues, one could consider using various techniques like stratified splitting, oversampling, undersampling, or diverse data collection. Stratified splitting involves dividing the dataset into subsets based on certain criteria, ensuring each subset maintains the same class proportions as the original dataset. Oversampling and undersampling involve increasing or decreasing the number of instances in minority or majority classes, respectively, to balance the dataset. Lastly, collecting diverse data helps ensure that different species are represented equally in the dataset.

While these techniques are not explicitly mentioned in the provided context, they could potentially help address the species detection bias issue discussed.