Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

mask. (3) Training set: grid with neighborhood features of six years (1986, 2005, 2008, 2010, and 2013). The features include the LU type, soil, topography, elevation, slope, aspect, distance to settlements, distance to roads, distance to rivers in this grid unit, and the 4 neighborhood grid units. (4) Constraint Factors: The statistical data and the quantity simulated by the backtracking of the Markov model are combined, and the numbers of different LU types in 2000 after modification by the simulation numbers are as follows (Table 1): 2.4.2. Deep Learning Module Probability maps (Figure 9): Water and settlements are constraint factors and can be determined by manual interpretation, and thus, no simulation is needed.  Figure 9. Probability maps. Remote Sens. 2020, 12, 3314

Traditional means and algorithms lack the ability to quantitatively analyze the drivers and
mechanisms of LUCC, and the accumulation of massive data over the years provides the possibility of
using deep learning models for related explorations. The probability of the LU distribution can be
determined by a deep learning model. The LU probability cannot determine whether a certain LU
type exists at that time; its function is to determine the distribution probability of a variety of LU types
in a spatial unit, and the probability is the basis for the SM.

Figure 4 introduces the adopted DM. In the DM, the grid with the neighborhood features includes
the LU type, soil, topography, elevation, slope, aspect, and distance-based variables, and all grid
units are input into the DM in series. The deep learning method can model complex spatiotemporal
dependencies, ﬁt the drivers and mechanisms of the LUCC, derive the probability maps needed for the
SM, and perform further LU simulations.

Remote Sens. 2020, 12, x FOR PEER REVIEW 6 of 22  (1) PM: The PM is a process of information collection and collation and data preprocessing. It is the foundation and preparation stage of LUCC reconstruction. (2) DM: A deep learning algorithm is assembled to calculate the probability of each LU type in each grid unit. Through the analysis of the relationships between the LU distribution and various natural environmental and socioeconomic conditions, the evaluation maps of LU suitability, i.e., probability maps are drawn to show the possible spatial distribution of the land cover. (3) SM: According to certain principles or methods, the quantity of each LU in the geographical locations and spatially analytical outcomes is distributed. Then, the backward projection of the historical LU is realized. For the specific spatial allocation, under the control of the total land cover area and other distribution factors, the allocation can be performed in descending order based on the probability

mainly driven by socioeconomic factors over short periods, such as several years or decades. Political factors have a macro-control role in LU and its changes [35–38]. Traditional means and algorithms lack the ability to quantitatively analyze the drivers and mechanisms of LUCC, and the accumulation of massive data over the years provides the possibility of using deep learning models for related explorations. The probability of the LU distribution can be determined by a deep learning model. The LU probability cannot determine whether a certain LU type exists at that time; its function is to determine the distribution probability of a variety of LU types in a spatial unit, and the probability is the basis for the SM. Figure 4 introduces the adopted DM. In the DM, the grid with the neighborhood features includes the LU type, soil, topography, elevation, slope, aspect, and distance-based variables, and all grid units are input into the DM in series. The deep learning method can model

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide any information about the data repository link of the deep learning pipeline. Therefore, I am unable to provide the requested information.