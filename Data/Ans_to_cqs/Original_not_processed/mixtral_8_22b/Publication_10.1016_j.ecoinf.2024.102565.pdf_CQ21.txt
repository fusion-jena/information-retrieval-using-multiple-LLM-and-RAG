Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

denoting  a  Gaussian  process  (MacKay,  2003).  During  model  fitting, 
hyperparameters  are  determined  from  the  data  using  methods  like 
maximum likelihood estimation or Bayesian approaches, accommoda-
ting diverse datasets with varying complexities (Sun et al., 2022; Wil-
liams and Rasmussen, 2006). Once fitted, GPR enables predictions for 
new  data  points,  offering  both  point  estimates  and  insights  into  pre-
diction uncertainty (MacKay, 2003).

2.4. Research methods

During the validation phase of the machine learning algorithms, a K- 
fold cross-validation technique was implemented. Additionally, a four- 
fold  cross-validation  was  conducted  on  the  training  dataset,  as  illus-
trated in Fig. 4. The dataset was initially extracted, and the feature set 
was randomly divided into four mutually exclusive folds through strat-
ified sampling (Guo et al., 2021; Psychalas et al., 2023). Each fold served 
as  the  validation  set,  while  the  remaining  three  folds  constituted  the 
training set for model training. To address imbalances, random under 
sampling (RUS) was applied to the training set, while the validation set 
remained unchanged. The model underwent training using the balanced 
three-fold  training  dataset  for  a  specified  number  of  epochs  and  was 
subsequently  tested  on  the  validation  fold to  generate  predictions for 
that specific fold. This process iterated four times with distinct valida-

Type 

Training Phase 

Validation Phase 

Linear Regression 
Regression Trees 
Support Vector Machines 
Gaussian Process Regression 
Neural Network 

R2 

0.796 
0.771 
0.797 
0.798 
0.882 

RMSE [g m(cid:0) 3] 

2.580 
2.752 
2.571 
2.562 
1.970 

MAE 

1.870 
2.070 
1.860 
1.890 
1.333 

MBE 

0.034 
0.067 
0.101 
0.002 
0.003 

R2 

0.790 
0.659 
0.780 
0.765 
0.840 

RMSE [g m(cid:0) 3] 

2.621 
3.342 
2.661 
2.777 
2.010 

MAE 

1.900 
2.423 
1.932 
1.994 
1.457 

MBE 

0.091 
0.317 
0.077 
0.232 
0.034  

EcologicalInformatics81(2024)10256511A. Noori et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the type of problem being solved and the desired output. Here are some common postprocessing steps:

1. Model Evaluation: After training, it is essential to evaluate the performance of the model using various metrics such as accuracy, precision, recall, F1 score, ROC AUC, etc. These metrics help assess how well the model has learned from the training data and its ability to generalize to new data. In this study, the authors used R2, RMSE, MAE, and MBE as evaluation metrics.

2. Prediction Generation: Once the model is trained and evaluated, it can be used to generate predictions for new data. For example, in this study, the models were used to predict soil moisture content based on input features such as temperature, humidity, precipitation, etc.

3. Uncertainty Quantification: Some models provide not only point estimates but also insights into prediction uncertainty. For instance, Gaussian Process Regression (GPR), which was one of the models used in this study, provides a measure of uncertainty along with each prediction. This information can be useful in decision-making processes where uncertainty needs to be taken into account.

4. Visualization: Postprocessing may involve visualizing the results of the model in different ways. For example, saliency maps can be generated to highlight important regions in the input data that contribute most to the predicted outcome. Similarly, confusion matrices can be created to visualize the performance of classification models. However, these techniques do not seem to have been employed in this particular study.