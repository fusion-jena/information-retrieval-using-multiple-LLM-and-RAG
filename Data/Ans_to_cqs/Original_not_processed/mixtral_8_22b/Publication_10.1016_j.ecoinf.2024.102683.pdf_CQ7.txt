Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 7. Data splitting in the proposed model.  

different  plants  with  99.78%  accuracy,  demonstrating  the  excellent 
performance of the proposed model in focusing and quickly extracting 
important  features  and  a  high  recognition  rate.  Also,  the  SCAM-Herb 
model based on gated-CA module was able to achieve a high accuracy 
of 99.52% with 90% of training data (Fig. 8b). Moreover, the SCAM- 
herb model based on mixed-CA and GAP-CA modules with 50% of the 
training data achieved accuracies of 94.15% and 93. 23%, respectively, 
which performed relatively poorly compared to the two aforementioned 
models (Fig. 8c and d). However, with increasing the training data, the 
accuracy of the two models increased to 99.38% and 99.43%, respec-
tively. Notably, when more than 80% of the data were used to train the 
models, the accuracy of the models was nearly constant or less variable. 
Therefore, 80% of the total data was sufficient for training the models,

Ms2(F) = W Ã— F

(7)  

where W shows the weight obtained by the SA module, and F is the input 
feature map. Therefore, the presented model extracts various features 
based on local and global information, which facilitates the interpreta-
tion of the original image and increases the classification accuracy. 

2.4. Data split 

How to split the data for training and testing of the proposed models 

is reported in Table 1. 

2.5. Evaluation of classifiers

Deep learning (DL) has become an advanced method in the field of 
computer science, but despite their high learning capacity, models based 
on DL often face a challenge called overfitting. To overcome the over-
fitting problem, deep neural networks must be supported by a significant 
amount of labeled data. Data augmentation (DA) technique is used as a 
basic  method  to  quantitatively  increase  and  diversify  training  data 
(Momeny et al., 2021; Momeny et al., 2023). DA is a technique in which 
the training set is artificially increased by creating modified copies of a 
dataset using the existing data. Using a designed set of DAs instead of 
simple  random  transformations  during  data  training  can  significantly 
improve  the  generalization  ability  of  the  network  (Hsia  et  al.,  2022; 
Jahanbakhshi et al., 2021a; Momeny et al., 2022). As the name suggests, 
automatic DA methods work automatically, and help us avoid the per-

As Fig. 3 shows, the data are first divided into five equal folds in the 
proposed  FAA-based approach.  After that,  policies will  augment each 
fold without repetition. Then, the CNN model starts to process the folds. 
In  the  next  step,  the  optimal  augment  policies  are  evaluated  and 
recognized. The output of each CNN is controlled by a Bayesian opti-
mizer. Weak policies are then removed by the controller and strong ones 
are selected. The process continues to find the optimal policies for data 
augmentation. 

2.3. The proposed approach (SCAM-Herb model) 

CNN-based methods have better performance in identifying plants, 
but still, based on data analysis and some previous research (Wang et al., 
2020, Azadnia et al., 2023), texture characteristics are very important. 
Therefore, more attention should be paid to the modules that consider 

Fig. 2. Images of three different classes of plants.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The table mentioned in the given context (Table 1) provides the details about how the data was split for training and testing of the proposed models. Unfortunately, the specific percentages or numbers used for this division are not explicitly stated in the provided text. However, it does mention that the data was divided into five equal folds in the proposed FAA-based approach. This implies that the dataset might have been divided into five parts, where four parts could have been used for training and one part for testing. Additionally, the text mentions that the optimal augment policies are evaluated and recognized after processing the folds. This indicates that there may also have been a separate validation set used for tuning hyperparameters and selecting the best performing model. In summary, while the exact proportions used for dividing the data are not specified, the context suggests that the data was likely divided into training, testing, and possibly validation sets.