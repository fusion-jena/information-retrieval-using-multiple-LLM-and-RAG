Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

In  our  study,  we  utilized  data  from  the  third  and  fourth  natural 
environment surveys, incorporating various environmental variables, to 
assess  the  impact  of  urban  development  on  species  distribution.  To 
achieve  this,  we  employed  seven  different  machine  learning  models, 
extracting the Area Under the Curve (AUC) values for each model both 
before and after urban development (Fig. 3). The AUC value, a critical 
measure of model performance, indicated that the Generalized Linear 
Model  (GLM)  and  Random  Forest  (RF)  models  had  the  highest  AUC 
value  of  0.85,  while  the  Classification  and  Regression  Tree  (CART) 
model  had  the  lowest  at  0.79.  On  average,  the  models  demonstrated 
robust performance with an average AUC value of 0.84, underscoring 
their overall effectiveness in species distribution modeling. Despite the 
methodological similarities among the models, their distinct character-

Song, W., Kim, E., 2012. A comparison of machine learning species distribution methods 
for habitat analysis of the Korea water deer (Hydropotes inermis argyropus). Korean 
J. Remote Sens. 28 (1), 171–180. https://doi.org/10.7780/kjrs.2012.28.1.171. 
Srivathsa, A., Karanth, K.U., Kumar, N.S., Oli, M.K., 2019. Insights from distribution 
dynamics inform strategies to conserve a dhole Cuon alpinus metapopulation in 
India. Sci. Rep. 9 (1), 3081. https://doi.org/10.1038/s41598-019-39293-0. 
Tarabon, S., Berg`es, L., Dutoit, T., Isselin-Nondedeu, F., 2019. Environmental impact 

assessment of development projects improved by merging species distribution and 
habitat connectivity modelling. J. Environ. Manag. 241, 439–449. https://doi.org/ 
10.1016/j.jenvman.2019.02.031.

Fig. 3. Receiver operating characteristics (ROC) curves of seven machine learning models. The true positive rate (sensitivity) of the vertical line and the false positive 
rate (1-specificity) of the horizontal line quantify the proportion of correctly and incorrectly classified samples, respectively. The red and blue curves represent the 
mean area under the curve (AUC) of training and test data, respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to 
the web version of this article.) 

EcologicalInformatics80(2024)1024645E.S. Kim et al.

1. Introduction 

Habitat  loss  due  to  increased  urban  development  has  led  to  a 
decrease  in  biodiversity.  Thus,  since  regulating  sustainable  urban 
development  is  rather  challenging,  an  integrative  strategy  that  takes 
urban  development  and  biodiversity  issues  into  consideration  is 
required (Cooke et al., 2019; Srivathsa et al., 2019). An essential strat-
egy in urban planning is to assess habitats before development ensues, 
focusing on habitat protection or conversion of the surrounding land-
scape into suitable habitat (Cooke et al., 2019). For this, it is necessary to 

quantitatively analyze how urban development fragments habitats and 
how  this  fragmentation  affects  communities  of  species  and  their 
extinction risk over time.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about addressing data bias during preprocessing of the deep learning pipeline. However, some common techniques used to address data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets based on specific criteria such as class labels, ensuring that each subset maintains the same proportions of classes as the original dataset. This technique helps prevent imbalanced datasets and ensures that all classes are represented equally during training and testing phases.

Oversampling is a method used to increase the number of instances in minority classes by duplicating existing examples or creating synthetic ones using interpolation techniques like SMOTE (Synthetic Minority Over-sampling Technique). This approach aims to balance the dataset and improve the model's ability to learn patterns within the minority classes.

Undersampling, conversely, reduces the size of majority classes by randomly removing instances or selecting only those closest to the decision boundary between classes. By reducing the dominance of majority classes, undersampling can help mitigate bias towards them and improve overall classification accuracy.

Diverse data collection focuses on gathering more representative samples across various demographics, geographical locations, or other relevant factors. Collecting diverse data enables models to generalize better and perform well when applied to new, unseen scenarios.

These techniques should be carefully considered depending on the nature of the problem being addressed and the available resources. It is also important to note that no single technique guarantees optimal results, so experimentation and validation through cross-validation or holdout sets may be required to determine which combination works best for a particular application.