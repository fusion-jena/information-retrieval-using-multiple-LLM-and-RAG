Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

kernel range). The threshold used was the 10th percentile training presence. For each metric the best model is highlighted in bold where higher was better for AUC, TPR, TSS and Kappa and lower better for Omission.

0.875 
0.024 
0.977 
0.635 
0.750 

a) Training set (75% random)                       
AUC 
Omission 
TPR 
k 
TSS 
b) Test set #1 (25% random)                       
0.662 
cAUC 
0.083 
Omission 
0.917 
TPR 
0.094 
k 
0.522 
TSS 
c) Test set #2 (Irish records only)                       
0.621 
cAUC 
1.000 
Omission 
0.000 
TPR 
(cid:0) 0.003 
k 
(cid:0) 0.394 
TSS 

0.701 
1.000 
0.000 
0.000 
(cid:0) 0.585 

0.687 
1.000 
0.000 
(cid:0) 0.003 
(cid:0) 0.228 

0.780 
0.014 
0.986 
0.210 
0.758 

0.753 
0.014 
0.986 
0.166 
0.704 

0.785  
0.181  
0.819  
0.485  
0.571  

0.691  
0.172  
0.828  
0.144  
0.580  

0.849 
0.042 
0.958 
0.459 
0.698 

0.757 
0.028 
0.972 
0.104 
0.713 

0.824 
0.041 
0.959 
0.393 
0.647 

0.729 
0.033 
0.967 
0.080 
0.655 

0.727 
0.122 
0.878 
0.242 
0.454 

0.584 
0.211 
0.789 
0.211 
0.365 

0.708  
0.330  
0.670  
0.275  
0.415  

0.599  
0.350  
0.650  
0.052  
0.396  

0.783 
0.167 
0.833 
0.553 
0.566 

0.691 
0.152 
0.848 
0.226 
0.581

Each of the iSDMs at the four different spatial extents were further 
subject to five treatments to test the impact of potential biases and error: 
a) Random backgrounds where 100% of training records were used, and 
background points were selected at random from the full extent of the 
model.  b)  Spatial  filtering  input  data  to  reduce  problems  of  spatial 
autocorrelation, where all species records were thinned using the soft-
ware OccurrenceThinner (Verbruggen et al., 2013), in a manner to filter 
out a greater proportion of sightings where the density of records was 
highest  based  on  their  kernel  density  (Fig.  1c;  with  densities  per  cell 
rescaled  to  an  index  from  0  to  1).  Species  records  were  selected  for 
deletion randomly from those cells with a kernel density index between 
0.5 and 1.0 giving an increased chance of removing records from the 
highest density areas. Over 10 cross-validated model runs, an average of

Table 1 
iSDM evaluation metrics for a) the training sets representing 75% of presence data selected at random, b) Test dataset #1 representing 25% of presence data selected at random and c) Test dataset #2 representing presence 
data from Ireland only for four spatial extents with five model treatments with i) random background points, ii) filtered (pre-thinned) input records adjusted for presence record density using OccurrenceThinner, iii) 
targeted selection of background points drawn from only those 1 km squares with a deer record, iv) filtered (pre-thinned) and targeted background point selection and v) weighted background points based on an estimated 
proxy for likely survey effort derived from a bias grid, throughout Great Britain and Ireland (GB & Ireland), Great Britain or restricted to the area currently colonised by muntjac (95% kernel range) or its core range (50%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about any specific deep learning pipeline or data augmentation techniques such as flipping, rotation, scaling, etc. Therefore, I cannot provide a helpful answer regarding this topic based solely on the provided context.