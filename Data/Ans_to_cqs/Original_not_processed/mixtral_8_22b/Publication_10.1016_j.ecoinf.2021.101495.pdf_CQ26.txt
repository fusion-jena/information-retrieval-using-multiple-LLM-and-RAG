Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(b) Computing infrastructure used to train both neural networks 

Infrastructure 
Search strategy 
Training duration 
(best assignment) 

Nvidia Tesla V100 (16GB) 
Manual tuning  
Segmentation 
Classification 

4 h 6 min 24 s 
9 h 22 min 34 s

Murua, J., Moreno, G., Itano, D., Hall, M., Dagorn, L., Restrepo, V., 2020c. ISSF Skippers 
Workshops. Technical Report Round 9. URL: https://iss-foundation. 
org/knowledge-tools/reports/technical-reports/. 

Qiao, M., Wang, D., Tuck, G.N., Little, L.R., Punt, A.E., Gerner, M., 2020. Deep learning 
methods applied to electronic monitoring data: automated catch event detection for 
longline fishing. ICES J. Mar. Sci. fsaa158 https://doi.org/10.1093/icesjms/fsaa158. 

Rathi, D., Jain, S., Indu, S., 2017. Underwater fish species classification using 

convolutional neural network and deep learning. In: 2017 Ninth International 

EcologicalInformatics67(2022)10149513X. Lekunberri et al.

Trained model 

-  Manually: 275 

segments  

-  Automatically: 
6921 segments  

-  Data 

augmentation: 
x12 

-  14,896 images  
-  Two trained 

models 

22 of the 30 
fishing sets 
(unannotated) 

Data of the 22 
fishing sets   

-  Annotations  
-  Species 

prediction  

-  Size 

distribution 
Comparison  

Ground truth 

validation (sec. 
2.5) 

Data from 4 fishing 
sets  

-  Official sources  
-  Estimations

Fig. 3. Example of individual fishes once the segmentation is done. These fishes belong to a monospecific set of YFT.  

Table 2 
Computing  infrastructure,  search  space  and  best  assignments  of  hyper-
parameters of the neural networks.  

(a) Hyperparameters used for the training of each neural network. The base models 
have been obtained from TensorFlow Object Detection API (segmentation) and the 
base implementation of TensorFlow (classification) 

Hyperparameter  Module 

Search space 

Best assignment 

Epochs 

Batch size 

Learning rate 

Activation 

Train/test split 

Segmentation 
Classification 
Segmentation 
Classification 
Segmentation 
Classification 
Segmentation 
Classification 
Segmentation 
Classification 

[1000(cid:0) 20,000] 
[500–5000] 
[2(cid:0) 32] 
[2–128] 
[0.0001–0.01] 
[0.0001–0.01] 
Softmax 
Softmax 
[0.9/0.1–0.8/0.2] 
[0.9/0.1–0.8/0.2] 

15,000 
500 
4 
128 
0.008 
0.0001 
Softmax 
Softmax 
0.9/0.1 
0.8/0.2

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide specific information on techniques used to address data bias during preprocessing of the deep learning pipeline. However, common techniques used to mitigate data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subgroups based on certain characteristics or labels, ensuring that these subgroups are proportionally represented in both the training and testing datasets. This helps maintain the balance between different classes or categories within the dataset.

Oversampling and undersampling are techniques used to handle class imbalance in datasets. Oversampling increases the number of instances in the minority class by duplicating existing samples or generating synthetic ones, while undersampling reduces the number of instances in the majority class by randomly removing some samples. Both methods aim to achieve a more balanced distribution of classes in the dataset.

Diverse data collection focuses on gathering data from various sources, demographics, or environments to ensure that the dataset represents a wide range of scenarios and conditions. This can help reduce biases introduced by relying solely on data from limited sources or populations.

While the given context does not explicitly mention any of these techniques, they are commonly employed to tackle data bias during preprocessing in deep learning pipelines.