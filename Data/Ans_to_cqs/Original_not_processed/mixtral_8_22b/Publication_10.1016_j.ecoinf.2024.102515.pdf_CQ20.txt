Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(INDITIC Consortium, 2023). This kind of initiatives would benefit of 
the implementation of the current methodology to reduce human effort. 
Although the usefulness of this methodology has been proven, there 
are still certain limitations that cannot be ignored. The main one cor-
responds to the nature of the tweets themselves, with a low number of 
words  accompanying  the  messages,  not  always  well  written,  which 
makes  it  difficult  to  obtain  useful  information.  This  leads  to  a  high 
number of tweets being lost in the filtering process. Furthermore, using 
exclusively textual information from tweets to obtain a training dataset 
would  only  lead  to  the  creation  of  a  deficient  model.  In  addition, 
biodiversity observations only make sense when accompanied by their 
location, allowing, among other applications, to alert about the presence 
of  invasive  species  or  reuse  the  information  in  species  distribution

In this study we have used the ‘Full-archive search endpoint’ to ac-
cess  the  entire  dataset  published  on  Twitter  from  its  beginning  in 
2006–2007 until the end of 2022. To handle the data in JSON format 
returned  by  the  Twitter  API,  we  used  the  twarc2  library  (https:// 
twarc-project.readthedocs.io/).  This  library  simplifies  the  handling  of 
the quota limits imposed by the Twitter API, as well as the pagination 
resulting from a single query. 

The API works by searching for words, hashtags or combinations of 
both  in  the  text  of  tweets,  much  like  the  Twitter  Advanced  Search 
interface  (https://twitter.com/search-advanced?).  To  find  out  how  to 
run the search, in an initial phase of the study, some public tweets with 
observations  were  provided  by  the  social  media  manager  of  the

geographical area and therefore the number of potential tweets is also 
limited,  which  prevents  us  from  making  major  efforts  in  training  an 
image recognition model (e.g. deep learning), something that would be 
very useful if this methodology were extended to larger areas and/or 
more languages, with the subsequent increase in the volume of data.

DIVERSIMAR project (@diversimar). This helped us to understand how 
users expressed themselves in this social network. Although many of the 
tweets turned out to be very specific, it was possible to identify three 
fairly common ways of expressing that something interesting had been 
found. Therefore, we decided to perform the tweet search through the 
API  with  three  different  criteria:  (i)  tweets  in  which  users  ask  “who 
knows” or if “anyone knows” what they have found (query 1), (ii) tweets 
that directly ask “what is this” that they have found (query 2) and (iii) 
tweets  from  users  claiming  to  have  found  something,  with  textual 
expression as “I/we have found” (query 3). Different verb tenses were 
also used in each of the expressions, as well as the use of first person in 
both  singular  and  plural.  In  addition,  the  different  criteria  must  be 
accompanied by one of the following words to ensure that they refer to

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there isn't enough information to determine which hardware resources are used for training the deep learning model. The context mentions the possibility of using image recognition models (e.g., deep learning) but does not provide any details regarding the hardware resources employed for training these models.