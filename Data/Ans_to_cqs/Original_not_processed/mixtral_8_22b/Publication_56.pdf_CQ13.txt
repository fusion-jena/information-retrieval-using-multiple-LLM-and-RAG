Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

https://doi.org/10.1038/s41598-020-74215-5

10

Vol:.(1234567890)www.nature.com/scientificreports/ 15.  Chen, Y., Lin, Z., Zhao, X., Wang, G. & Gu, Y. Deep learning-based classification of hyperspectral data. IEEE J. Sel. Top. Appl. Earth 

Observ. Remote Sens. 7, 2094–2107 (2014).

 16.  Li, W., Fu, H., Yu, L. & Cracknell, A. Deep learning based oil palm tree detection and counting for high-resolution remote sensing 

images. Remote Sens. 9, 22 (2017).

 17.  Hu, F., Xia, G.-S., Hu, J. & Zhang, L. Transferring deep convolutional neural networks for the scene classification of high-resolution 

remote sensing imagery. Remote Sens. 7, 14680–14707 (2015).

 18.  Liang, H. & Li, Q. Hyperspectral imagery classification using sparse representations of convolutional neural network features. 

Remote Sens. 8, 99 (2016).

 19.  Zhang, L., Zhang, L. & Du, B. Deep learning for remote sensing data: A technical tutorial on the state of the art. IEEE Geosci. 

Remote Sens.Mag. 4, 22–40 (2016).

Recently, some approaches have been proposed to evaluate the interpretability of deep learning  models33,34 
including methods based on model decomposition, sensitivity analysis, and feature visualisation. The relevance of 
network inputs can for example be obtained by the gradient-based sensitivity analysis (GBSA), which computes 
the prediction function squared partial derivatives with a standard gradient  backpropagation35. The Layer-wise 
Relevance Propagation (LRP)36 propagates the prediction backward in the neural network using propagation 
rules until the input features are reached. Arras et al.37 proposed a LRP for LSTM networks that provided better 
results than the GBSA on a five-class prediction task. Class activation maps were used to point out the most 
discriminative regions used by a CNN to identify a  class38.

sample with its corresponding remote sensing sequence of data. Finally, 70% of the data were used for training 
the algorithms whereas the remaining 30% were used only for validation.

125,161

84,491

71,623

49,829

33,408

29,859

28,754

11,437

10,104

4252

TOTAL

2,398,326

Table 2.   Number of pixels identified in the in situ visits. Of those, 70% were used for training and the 
remaining 30% for validation.

unit reads the input xt , and the previous hidden state ht−1 . Their combination is modulated by an hyperbolic 
tangent as:

˜ct = tanh(Wcxt + Ucht−1 + bc),
(1)
where Wc , Uc , and bc are the input weights, the recurrent weights, and the bias, respectively. The input gate 
determines which information is stored in the memory cell by means of a sigmoid function:

it = σ (Wixt + Uiht−1 + bi),

and similarly, the forget gate decides which content of the existing memory cell is forgotten:

ft = σ (Wf xt + Uf ht−1 + bf ).

(2)

(3)

The information is updated into the memory cell by adding the information coming from both the input and 
forget gates, i.e., adding new information from ct , and rules out part of the current memory information:

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available in the given context to determine the specific hyperparameters used in the deep learning model, such as the learning rate or the type of optimizer employed. It would require more details about the implementation of the model to provide this information accurately.