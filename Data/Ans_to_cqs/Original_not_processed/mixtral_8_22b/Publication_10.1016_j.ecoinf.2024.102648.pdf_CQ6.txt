Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

â—¦

Fig.  1. Illustration  of  major  deep  learning  (DL)  methods  for  prediction  of 
CLCuD in upland cotton. 

EcologicalInformatics81(2024)1026484S.K. Sain et al.                                                                                                                                                                                                                                  

Fig. 2. SMW-wise percent CLCuD percent incidence in the four locations of the north-western Zone. A. Faridkot, b. Sriganganagar, c. Sirsa, d. Hisar.  

3.5. Multi-layer perceptron (MLP): artificial neural network 

training  = 0.80 and R2

2.2. Machine learning and deep learning tools 

In the present study machine learning (bootstrap forest, boosted tree) 
and deep learning (artificial neural network) models were employed to 
forecast  the  percent  disease  incidence  of  CLCuD  under  the  prevailing 
weather data on minimum, maximum and average temperature, stan-
dard meteorological week (SMW)-wise growing degree days (henceforth 
mentioned  as  GDD),  minimum  relative  humidity  (RHmini.),  maximum 
relative humidity (RHmax.), average relative humidity (RHave.), cumu-
lative rainfall (mm) and whitefly per three leaves. The weather param-
eters recorded from 2011 to 2019 at weather stations based at all four 
locations  were  used  for  calculating  the  GDD  as  per  the  following 
equations.

and DL models to detect different types of disease symptoms in cotton. 
Rumpf et al. (2010) have utilized ML and DL models for early diagnosis 
and classification of diseases in sugar beet based on spectral plant in-
dexes using a Support Vector Machine (SVM). EfficientNet deep learning 
architecture is reported to be more accurate than DL models for preci-
sion  for  plant  disease  classification  (Atila  et  al.,  2021).  Furthermore, 
ANN  techniques  and  regression  models  have  recently  been  used  to 
predict the bark thickness of ash (Fraxinus excelsior) plants and hypericin 
content  in  Hypericum  perforatum  with  80%  accuracy  (Mosaffaei  and 
Jahani, 2021; Saffariha et al., 2021). Saleem et al. (2021) have devel-
oped an insect pest prediction system (IPPS) using the Internet of Things

2.7. Early stopping 

It is the process that stops growing additional trees/layers/split when 
further addition of more trees/layers/split does  not improve  the vali-
dation statistic in the case of bootstrap forest and boosted tree methods. 
The  validation  statistic  included  the  (R2)  value  for  a  continuous 
response. In the case of the entire machine learning model early stop-
ping  was  enabled  so  that  the  model  would  not  overfit  the  predicted 
percent CLCuD. To address the inclination of neural networks to overfit 
data, the penalty method was employed within the framework of ANN 
models. 

3. Results 

3.1. Multiyear SMW-wise percent CLCuD incidence in the four locations

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it doesn't provide specific information about the preprocessing steps involved before training a deep learning model such as normalization, scaling, or cleaning. However, generally speaking, these are common preprocessing steps taken before training any machine learning or deep learning model. Normalization involves rescaling the input features to a standard range, typically between 0 and 1, which helps prevent certain features from dominating others due to their scale. Scaling refers to transforming the feature values to have zero mean and unit variance, which can help stabilize the learning process. Cleaning involves removing noise, outliers, or missing values from the dataset to ensure the quality of the data being fed into the model. These preprocessing steps are crucial to improving the performance and efficiency of the model during training.