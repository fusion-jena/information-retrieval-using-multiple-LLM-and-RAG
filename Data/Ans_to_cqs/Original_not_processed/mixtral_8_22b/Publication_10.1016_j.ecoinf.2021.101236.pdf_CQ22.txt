Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

overall process mostly followed current best practices in deep learning 
which are well summarized in (Chollet, 2017).

followed  the  original  Wide  ResNet  design.  Our  downsampling  blocks 
employed the changes suggested in (Xie et al., 2018). The third and final 
component, the classification block, was derived from (Schlüter, 2018) 
and resulted in probability predictions for all 987 classes per second (i. 
e., three predictions per 3-s input spectrogram) followed by global log- 
mean-exponential  pooling  and  sigmoid  activation.  Most  convolutions 
use 3 × 3 kernels with padding and are succeeded by batch normali-
zation  (Ioffe  and  Szegedy,  2015)  and  ReLU  activation  (if  not  noted 
differently).  Because  we  treated  spectrograms  as  monochrome  input 
images, the input was a single channel mel spectrogram of size 64 × 384, 
visualizing three seconds of audio at a sampling rate of 48 kHz. 

2.5. Training

For comparability reasons, we evaluated our system using sample- 
wise  (mAP)  and  class-wise  mean  average  precision  (cmAP)  metrics. 
Both metrics were used in past editions of BirdCLEF and worked well for 
multi-label classification scenarios (Kahl et al., 2019). As for the training 
dataset,  test  samples  were  unevenly  distributed  across  classes.  While 
sample-wise  evaluation  benefited  from  this  imbalance  by  assigning 
common species a higher rank, it also reasonably represented real-world 
use  cases  as  common  species  are  much  more  likely  to  occur  in  a 
recording.  A  class-wise  evaluation  provided  a  balanced  measure  in 
which the true positive rate for each species contributed equally to the 
score.  This  better  reflected  the  need  for  precise  primary  predictions. 
Additionally, we used several complementary metrics like top-1 accu-
racy,  F0.5  score,  and  area  under  the  ROC  curve  (AUC)  to  assess  the

Here  we  present  a  new  algorithm,  called  BirdNET,  that  builds  on 
these previous successes using CNNs and spectrogram data to classify 
984  bird  species.  We  discuss  the  necessary  steps  required  to  develop 
such a system and provide insights into our training and testing work-
flow of a deep artificial neural network. Finally, we give an outlook on 
how  this  technology  can  support  ornithologists  and  conservation  bi-
ologists in their work to identify and address the environmental chal-
lenges of our time. 

2. Methods

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model is evaluated using both sample-wise (mAP) and class-wise mean average precision (cmAP) metrics. These metrics have been used in past editions of BirdCLEF and are suitable for multi-label classification scenarios. Additionally, other complementary metrics such as top-1 accuracy, F0.5 score, and area under the ROC curve (AUC) are employed to further assess the model's performance.