Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Machine learning, and particularly deep learning, has evolved into
the most commonly used approaches for the automatic classiﬁcation of
digital images (LeCun et al., 2015). The major advantage of deep
learning is that the time-consuming and complex step of previous fea-
ture extraction becomes unnecessary. Instead, the model learns and
extracts the relevant features itself during the training process. The
major drawback of deep learning is that large amounts of labeled
training data are required (Kamilaris and Prenafeta-Boldú, 2018).
Among the deep learning architectures, convolutional neural networks
(CNN) are particularly suitable for image analysis due to their ability to
extract spatial features. CNNs have proven to be quite powerful in
performing diﬀerent tasks such as object detection (Everingham et al.,
2010; Tompson et al., 2014), classiﬁcation (Traore et al., 2018, Xu
et al., 2017, Amara et al., 2017, Lu et al., 2017, Han et al., 2018) and

Ecological Informatics 50 (2019) 220–233

classiﬁcation of woody vegetation might reach a level where it is able to
provide acceptable results in shorter time. Possible improvements may
be achieved by further increasing the sample size, using more photo-
graphs with high quality or by testing alternative CNN-architectures.
Another possibility poses transfer learning, meaning that knowledge
gained from one classiﬁcation task is reused for another similar task
(Weiss et al., 2016). While training time and computing requirements
are considerably reduced, ﬁne tuning a pre-trained model to ﬁt the new
task can be time-consuming, in particular when the input data are
diﬀerent. Nevertheless, for many classiﬁcation tasks, pretrained models
such as VGG16 (Simonyan and Zisserman, 2014) or ResNet50 (He et al.,
2015) have proven to be beneﬁcial, particularly in cases where only a
small amount of training data is available.

CNNveg are shown in Fig. 7.

Although the use of pre-trained models has proven to be advanta-
geous for many image recognition tasks (Weiss et al., 2016), we decided
to train the model from scratch. We recognized that our speciﬁc clas-
siﬁcation problem was too diﬀerent from the pre-trained networks.
Moreover, we considered the number of labeled samples available
(nearly 30,000 per class) as large enough for training our own network.

We trained the CNN using ReLU activation for the convolutional layers
and an exponential linear unit (ELU) activation on the fully connected
layer (Clevert et al., 2015). As optimizer we chose the adaptive ADAM
(Adaptive Moment Estimation) with a learning rate of lr = 0.0001.
Training was performed with a batch size of 256 over 16,290 iterations
(= 90 epochs).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the data repository link of the deep learning pipeline. Therefore, I cannot provide the requested information.