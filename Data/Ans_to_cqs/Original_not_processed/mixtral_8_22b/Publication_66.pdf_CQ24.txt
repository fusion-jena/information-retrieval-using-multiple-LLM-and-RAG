Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Therefore,	 models	 including	 all	 variables	 used	 200	 input	 neurons,	
those	with	three	variables	used	150	input	neurons	and	so	on.	 ̄x and ̄y 
were	calculated	as	xi	minus	the	mean	of	xi	to	xi+w	(from	i	to	i	plus	the	
window	length,	w)	of	interpolated	data,	where	i	is	the	value	of	X or Y 

(Aiello,	 Kraljevic,	 &	 Maj,	 2015),	 an	 open-	source	 platform,	 was	 used	

at	a	given	point.

in  r	to	construct	 an	artificial	 neural	network	and	perform	 predictive	

̄xi = xi − μ (xi:x

(i+w))

modelling.	A	random	hyperparameter	search	was	conducted	to	deter-

Importantly,	the	variables	used	in	the	input	layer	were	only	those	

mine	the	optimum	model	structure.	The	number	of	layers	and	hidden	

collected	by	the	GPS	logger—TDR	data	were	subsequently	used	to	val-

nodes	per	layer	were	varied,	from	one	to	four	layers	and	from	20	hid-

idate	predictions.	Models	were	trained	on	species	individually,	with	all	

den	nodes	to	1,000.	The	hyperparameter	search	was	allowed	to	run

produced	 poorer	 behavioural	 predictions,	 further	 demonstrating	 the	

structed	the	deep	learning	models	in	r	using	H2O	and	conducted	the	

BROWNING et al. 2041210x, 2018, 3, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12926 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons Licensecomparative	modelling.	E.B.	and	R.F	wrote	the	manuscript.	All	authors	

contributed	to	editing	of	the	manuscript.	R.F.	and	M.B.	supervised	this	

work.

DATA ACC ESSI BILITY

GPS	track	data	used	in	the	analysis	are	available	at	(http://seabirdtrack-

ing.org/mapper/contributor.php?contributor_id=950).	Other	data		used	

within	 the	 analysis	 (GPS	 &	 dive	 data,	 and	 associated	 matrices	 used

each	species.	The	models	were	then	used	to	predict	the	diving	loca-

tions	of	birds	monitored	with	only	GPS	devices.

2.4 | Alternative prediction methods

To	 compare	 predictions	 obtained	 from	 deep	 learning	 models	 with	

methods	 used	 in	 previous	 studies	 classifying	 foraging	 behaviour	 in	

seabirds	HMMs,	a	naïve	Bayes	classifier	and	speed	and	tortuosity	pre-

dictions	were	implemented	on	the	data	(see	Appendix	S8,	supporting	

information	for	details	of	the	latter).	The	Naïve	Bayes	classification,	a	

supervised	 learning	 method,	 was	 implemented	 in	 r	 using	 the	 e1071	

package	 (Meyer,	 Dimitriadou,	 Hornik,	 Weingessel,	 &	 Leisch,	 2015).	

The	inputs	were	the	same	as	used	in	the	H2O	model,	and	the	depend-

ent	 variable	 (variable	 to	 be	 predicted)	 was	 the	 binary	 dive/not	 dive	

column.

HMMs	 are	 an	 unsupervised	 learning	 method	 that	 identifies	 dis-

crete	 states	within	 time-	series	 data	 and	 have	 been	 used	 extensively

Received:	30	June	2017  |  Accepted:	13	October	2017
DOI:	10.1111/2041-210X.12926

R E S E A R C H   A R T I C L E

Predicting animal behaviour using deep learning: GPS data 
alone accurately predict diving in seabirds

Ella Browning1,2  | Mark Bolton3 | Ellie Owen4 | Akiko Shoji5 | Tim Guilford5 |  
Robin Freeman2

1Centre	for	Biodiversity	and	Environment	
Research,	University	College	London,	London,	
UK

2Institute	of	Zoology,	Zoological	Society	of	
London,	London,	UK

3RSPB	Centre	for	Conservation	Science,	
Sandy,	Bedfordshire,	UK

4RSPB	Centre	for	Conservation	Science,	
Inverness,	UK

5Department	of	Zoology,	Oxford	University,	
Oxford,	UK

Correspondence
Ella	Browning
Email:	ella.browning.14@ucl.ac.uk 
and
Robin Freeman
Email:	robin.freeman@ioz.ac.uk

Funding information
Natural	Environment	Research	Council,	Grant/
Award	Number:	NE/L002485/1

Abstract

1.	 To	 prevent	 further	 global	 declines	 in	 biodiversity,	 identifying	 and	 understanding	 key

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer:::
One strategy employed to handle randomness in the deep learning pipeline is a random hyperparameter search. This technique involves varying different aspects of the model structure, such as the number of layers and hidden nodes per layer, to determine the optimal configuration. In this case, the authors varied the number of layers from one to four and the number of hidden nodes from 20 to 1,000. Additionally, they allowed the hyperparameter search to run until it found the optimum model structure. Another approach mentioned in the text is the use of supervised and unsupervised learning methods, such as Naïve Bayes classification and Hidden Markov Models (HMMs), respectively. These techniques can help improve the accuracy of behavioral predictions made by the deep learning models. However, the specific details regarding how these methods address randomness within the deep learning pipeline are not explicitly stated in the given context.
Answer:::