Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

high-resolution CHM of the Earth (hereafter “Lang10m”) at 10 m reso-
lution  using  Sentinel-2  optical  images  and  a  deep  learning  approach 
(convolutional neural networks).

Heumann, B.W., Hackett, R.A., Monfils, A.K., 2015. Testing the spectral diversity 

hypothesis using spectroscopy data in a simulated wetland community. Ecol. Inform. 
25, 29–34. 

Hoffr´en, R., Lamelas, M.T., de la Riva, J., Domingo, D., Montealegre, A.L., García- 

Martín, A., Revilla, S., 2023. Assessing gedi-nasa system for forest fuels classification 
using machine learning techniques. Int. J. Appl. Earth Obs. Geoinf. 116, 103175. 
Huang, H., Gong, P., Cheng, X., Clinton, N., Li, Z., 2009. Improving measurement of 

forest structural parameters by co-registering of high resolution aerial imagery and 
low density lidar data. Sensors 9 (3), 1541–1558. 

Kacic, P., Hirner, A., Da Ponte, E., 2021. Fusing sentinel-1 and-2 to model gedi-derived 
vegetation structure characteristics in gee for the paraguayan chaco. Remote Sens. 
13 (24), 5105. 

Kacic, P., Kuenzer, C., 2022. Forest biodiversity monitoring based on remotely sensed

2022),  biomass  density  (Duncanson  et  al.,  2022),  forest  fuels  classifi-
cation (Hoffr´en et al., 2023) and surface elevation (Quir´os et al., 2021) 
which are key components for a global monitoring of forest ecosystems. 
Limitations at local scale arise because of the generalized footprint and 
the  sparse  sampling  design  (Liu  et  al.,  2022).  To  extrapolate  GEDI 
samples  for  continuous  information  on  vegetation  structure,  multiple 
approaches  have  been  developed  fusing  GEDI  samples  with  passive 
optical images in machine learning models (Liu et al., 2022; Rishmawi 
et al., 2021; Kacic et al., 2021). At global scale, Potapov et al. (2021) 
made use of machine learning algorithms to compute and derive a global 
forest  canopy  height  map  (hereafter  “Potapov30m”)  at  30  m  spatial 
resolution fusing GEDI and phenology metrics based on Landsat 8 OLI 
imagery. More recently Lang et al. (2022), Lang et al. (2022), produced a

2.3. LiDAR data 

2.3.1. GEDI LiDAR data 

We estimated the HH using the recently published and freely avail-
able LiDAR GEDI CHMs Lang10m (Lang et al., 2022; Lang et al., 2022) 
(downloaded  here:  https://langnico.github.io/globalcanopyheight/) 
and Potapov30m (Potapov et al., 2021) (downloaded here: https://glad. 
umd.edu/dataset/gedi/). 

EcologicalInformatics76(2023)1020823M. Torresani et al.                                                                                                                                                                                                                              

Fig. 2. In white, the center of the 30 plots situated in the 2 forested areas of San Genesio/Jenesien and Monticolo/Montiggl in South Tyrol (Italy). Background image 
used: Google Image at February 21th 2023. Coordinates in WGS 84/ UTM zone 32 N (EPSG:32632).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The query asks about the availability of the deep learning pipeline used in the study. However, none of the provided sources mention any specific data repositories such as Zenodo, Figshare, Dryad, or GBIF where this pipeline might be accessible. Therefore, it seems that the required information is not present within the given context. It would be best to consult other resources or contact the authors directly to find out more details regarding the accessibility of their deep learning pipeline.