Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

However,  although  research  on  the  urban  AE  gained  traction  in 
recent years, sophisticated methods to quantify its complex properties 
on  a  larger  scale  are  still  scarce.  This  is  especially  true  for  big  audio 
datasets, which are so extensive that listening to the files becomes no 
longer  feasible.  To  date,  few  approaches  have  been  used  to  quantify 
large datasets of the urban AE. Classical approaches reach their limits 
when  it  comes  to  analyzing  longer  recording  periods  (e.g.  several 
months) (Gage et al., 2017). In recent years, sound event classification 
using  machine  learning  approaches  became  more  popular  (Phillips 
et al., 2018; Sethi et al., 2022; Stowell et al., 2019; Ulloa et al., 2018), 
but is still not ready to be deployed unconfined (Alcocer et al., 2022). In 
psychoacoustics, mostly smaller field studies have been conducted (Hall 
et  al.,  2013;  Ma  et  al.,  2021;  Montoya-Belmonte  and  Navarro,  2020;

two examples for the LUTs “Main Street” and “Urban Forest”, depicting 
every step from the FCM, to thresholding, to the adjacency matrix and its 
respective network representation.

All analyses were performed using Python 3.8.5 and corresponding 
packages.  A  list  of  packages  and  their  versions,  python  code  for  our 
analyses as well as a demo dataset with functions and documentation to 
apply FCM-based complex networks for any kind of power spectra from 
the urban AE is provided on GitHub (https://github.com/THaselhoff/Co 
mplex-networks-for-analyzing-the-urban-acoustic-environment). 

4. Results 

4.1. Diel cycle of average shortest path length

(continued on next page) 

EcologicalInformatics78(2023)10232611T. Haselhoff et al.                                                                                                                                                                                                                               

Table B1 (continued ) 

AAD_ID 

Land use type 

23 
24 

Commercial Area 
Urban Forest 

R2-Threshold 

0.75 
0.71 

ASPL 

2.76 
2.21 

STD 

0.18 
0.34  

Appendix C

Fig. C1. 95% Bootstrap intervals of the average shortest path length (ASPL) for each hour by device. For each hour per device, 100 Bootstrap samples were build and 
the 97.5 and 2.5 quantiles of the ASPL values were calculated.  

EcologicalInformatics78(2023)10232612T. Haselhoff et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about specific datasets used in a deep learning pipeline such as MNIST, CIFAR, or ImageNet. However, it mentions that the study focuses on large audio datasets related to the urban acoustic environment (AE). These datasets are described as being too extensive for manual listening, indicating they likely contain numerous recordings. The analysis involves applying Fourier Complexity Measures (FCMs) and converting them into complex networks. Additionally, the study uses psychoacoustic data from smaller field studies. Unfortunately, there is no explicit mention of the exact names or sources of these datasets.

Answer:::