Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3. Training

3. Results

3.1. Training Evaluation

The model was trained for 350 epochs and evaluated using the scores precision, recall, F1, GIoU,
and mAP, as seen in Table 2. The scores are calculated from model validation data, consisting of
321 image tiles. The F1 score and mAP score are seen to follow each other closely, given indications on
the training at diﬀerent stages, the model quickly reached F1 and mAP scores of ~0.4, whereafter they
continue to increase but at a slower rate. At the end of the training, the model achieved the accuracy
scores of F1 = 0.530 and mAP = 0.557. The GIoU is steadily decreasing, indicating that the model is
becoming better at correctly locating targets.

Table 2. Training metrics at diﬀerent iteration stages.

Epoch

Precision Recall

F1 Score

GIoU

100
200
300
350

0.656
0.583
0.493
0.476

0.321
0.549
0.610
0.600

0.430
0.541
0.534
0.530

2.14
1.58
1.29
1.16

mAP

0.407
0.542
0.548
0.557

to keep these values. There is some variance in proposed learning rate settings, but studies applying
Yolo to aerial imagery have succeeded with a learning rate of 0.001 [12] and have proven that this value
produces higher precision [20]. The model was trained for a total of 350 epochs, resulting in a total
training time of 27 h. Due to limitations in computer memory, the batch size was set at 4.

schema. (Source: European Space Agency “Sentinel High Level Operations Plan (HLOP)”). ISPRS Int. J. Geo-Inf. 2020, 9, x FOR PEER REVIEW 12 of 15  Figure 10 shows an example of iceberg training data used in the model and is a good indicator of a complex situation where data are to be labelled. It could be argued that too many objects are not labelled, leaving them out of training, but in opposition to this, one could say that too many small objects are included, and these are not of great importance. In Figure 11, training objects are also seen to be located within the large piece of floating ice in the right side of the image, this also raises the question of icebergs being present in other types of ice, such as in this study [23], or if such large pieces of floating ice should be in a class of their own or maybe not be included at all.  Figure 10. Example of icebergs detected with an adaptive thresholding algorithm in Sentinel-1 data. Since ships are clearly defined objects,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the provided context, it appears that the model was trained for a fixed number of epochs rather than using specific criteria to determine when training is complete. The model was trained for a total of 350 epochs, which resulted in a total training time of 27 hours. However, there is no mention of any specific criteria used to determine when training should stop, such as a validation loss plateau or reaching a certain level of performance on a validation dataset. Therefore, based on the information provided, it seems that the decision to train for 350 epochs was made beforehand and not based on any particular stopping criterion.