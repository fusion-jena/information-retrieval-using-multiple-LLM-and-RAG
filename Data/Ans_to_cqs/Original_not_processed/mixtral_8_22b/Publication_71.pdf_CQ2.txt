Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1. Training parameters used in DeepLabV3+.

Training Parameter

Value

Learning policy
Base learning rate
Learning rate decay factor
Learning rate decay step
Learning power
Training number of steps
Momentum
Train batch size
Weight decay
Train crop size
Last layer gradient multiplier
Upsample logits
Drop path keep prob
tf_initial_checkpoint
initialize_last_layer
last_layers_contain_logits_only
slow_start_step
slow_start_learning_rate
ﬁne_tune_batch_norm
min_scale_factor
max_scale_factor
scale_factor_step_size
atrous_rates
output_stride

Poly
0.0001
0.1
2000
0.9
≥100,000
0.9
2
0.00004
‘513,513’
1
True
1
deeplabv3_pascal_train_aug
False
True
0
1 × 10
False
0.5
2
0.25
[6,12,18]
16

−4

14 of 23

including a NIR band in addition to the RGB bands. This is because in order to build a satisfactory
model, not only a lot of training data are needed that include the NIR band in addition to RGB color
images but also signiﬁcant GPU power that can conduct a proper training with batch sizes larger than 16.
This is because, for eﬃcient model training, larger batch sizes are recommended in DeepLabV3+ [49].
Moreover, the DeepLabV3+ architecture, which is originally designed for three input channels, RGB,
needs to be adjusted accordingly to accommodate four-channel input images. With four-channel input
images, the existing pre-trained models, which are for RGB, cannot be used directly and there is a need
for training a model from scratch or at least modifying the DeepLabV3+ architecture such that only the
weights for the newly added image bands can be learned and the weights of RGB input channels can
be initialized by pre-trained model weights via transfer learning [41].

Remote Sens. 2020, 12, x FOR PEER REVIEW 14 of 23 images but also significant GPU power that can conduct a proper training with batch sizes larger than 16. This is because, for efficient model training, larger batch sizes are recommended in DeepLabV3+ [49]. Moreover, the DeepLabV3+ architecture, which is originally designed for three input channels, RGB, needs to be adjusted accordingly to accommodate four-channel input images. With four-channel input images, the existing pre-trained models, which are for RGB, cannot be used directly and there is a need for training a model from scratch or at least modifying the DeepLabV3+ architecture such that only the weights for the newly added image bands can be learned and the weights of RGB input channels can be initialized by pre-trained model weights via transfer learning [41]. In this work, we used the default DeepLabV3+ architecture and considered using more than three input channels with DeepLabV3+ as future work. However, we conducted an

when more than three channels are aimed to be used. Even if these modifications are done properly, the training will have to start from scratch since there are no pre-trained DeepLabV3+ models other than RGB input channels. Moreover, one needs to find a significant number of training images that contain all these additional input channels. This may not be practical since the existing RGB pre-trained model utilized thousands, if not millions, of RGB images in the training process. Our customized CNN method, on the other hand, can handle more than three channels; however, the training needs to start from scratch since there are no pre-trained models available for the NIR band. One other challenge with deep learning methods is when the dataset is imbalanced. With heavily imbalanced datasets, the error from the overrepresented classes contributes much more to the loss value than the error contribution from the underrepresented classes. This makes the deep learning method’s loss function

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not explicitly mention the specific data format used in the deep learning pipeline. However, it does provide some clues about the type of data being processed. The text refers to RGB color images and Near-Infrared (NIR) bands, suggesting that the data format used in the deep learning pipeline is likely related to image processing. Furthermore, the discussion revolves around adjusting the DeepLabV3+ architecture, which is a convolutional neural network (CNN) primarily used for semantic segmentation tasks involving images. Therefore, based on the information provided, it can be inferred that the data format used in the deep learning pipeline is most likely image data.