Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

was analysed using various evaluation matrices. During model training, 
the input image size was set to 512 × 512 and the maximum batch size 
was limited to 4. To prevent underfitting, all models were ensured to 
follow back-propagation after accumulating the batch size 32 times. The 
models were trained using a stochastic gradient descent (SGD) optimizer 
with an initial learning rate of 0.01 and a cycle learning rate of 0.2, with 

EcologicalInformatics82(2024)1026917S. Kaukab et al.

The input part of YOLOv5 uses self-adaptive anchor box computa-
tion, mosaic data augmentation, and image scaling. Input images were 
scaled down to a fixed size (512 × 512) with normalization using self- 
adaptive  image  scaling.  A  high-performance  classifier  is  used  by  the 
backbone benchmark network in YOLOv5 to extract features. The focus 
structure was used as the backbone of architecture to resize the input 
image by using slice operation and fuse it in the channel. This results in 
lowering  the  number of  FLOPs and  parameters. 6 × 6 sized  convolu-
tional layers are more effective on GPUs to use as focus structures in 
YOLOv5.  In  YOLOv5  architecture,  the  neck  part  oversees  boosting 
feature variety and creating useful feature outputs. The head serves as 
both  a  classifier  and  a  regressor,  predicting  of  class  and  position  of 
targets. Three feature layers are created in the head by applying 1 × 1

learning rate decay occurring after specific iterations. A total of 1000 
sets of aligned RGB images and depth images were manually labelled 
and divided into training (80% images), validation (10% images), and 
test sets (10% images). Data augmentation techniques such as scaling, 
panning, rotation, colour transformation, and mosaic were employed to 
increase  the  number of  training samples and  improve  model general-
ization ability. Pretrained weights were loaded to evaluate their impact 
on detection results. Models were trained for 300 epochs and evaluated 
on the validation set after each epoch. 

A computer system running on a Windows 10 64-bit system with an 
Intel i7 eight-core CPU (3.0 GHz), an Nvidia RTX 2060 12 GB Graphics 
Processing Unit (GPU) (2176 CUDA cores), and 8 GB of memory were 
used during the study. Further, CUDA 8.1, CUDNN 7.5, Python 3.8, and 
Microsoft Visual Studio 9.0 software were utilized to attain the aim of 
this study. 

3.2. Model evaluation

using pre-trained vgg16 with rgb and nir information fusion. IEEE Access 8 (1), 
2327–2336. 

Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Guo, B., 2021. Swin transformer: 

Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/ 
CVF international conference on computer vision 10012–10022. 

Mzoughi, O., Yahiaoui, I., 2023. Deep learning-based segmentation for disease 

identification. Eco. Inform. 75. 

Nguyen, T., Vandevoorde, K., Wouters, N., Kayacan, E., Baerde-maeker, D.J.G., 

Saeys, W., 2016. Detection of red and bicoloured apples on tree with an rgb- 
d camera. Biosyst. Eng. 146, 33–44. https://doi.org/10.1016/j. 
biosystemseng.2016.01.007. 

Qixin, S., Xiujuan, C., Zhikang, Z., Guomin, Z., Tan, S., 2022. Noise-tolerant rgb-d feature 

fusion network for outdoor fruit detection. Comput. Electron. Agric. 198, 107034 
https://doi.org/10.1007/s11119-020-09709-3.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, the deep learning pipeline primarily utilizes image data format. Specifically, the input images are scaled down to a fixed size (512 × 512) with normalization using self-adaptive image scaling. Additionally, the context mentions the use of RGB images and depth images, which are also types of image data formats. There is no mention of other data formats like audio, video, or CSV being used in this particular deep learning pipeline.