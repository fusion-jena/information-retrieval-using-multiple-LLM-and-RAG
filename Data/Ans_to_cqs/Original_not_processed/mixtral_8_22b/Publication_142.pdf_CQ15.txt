Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

tions of the training data, and the gap between these and the test
data on which the developed algorithms will be evaluated.28

Access to the Pl@ntNet classiﬁcation tool is provided through a dedicated
API available at my.plantnet.org. The main feature of this API is a RESTful
JSON-based web service that can accept one to ﬁve images of a plant and re-
turns a list of likely species. The species are associated with classiﬁcation
scores (the softmax output of the CNN), as well as a list of matching images
retrieved from the database. To facilitate the implementation of future studies
based on the methodology of this paper, we have developed the ‘‘plantnet’’51
R-package allowing users to query the Pl@ntNet API. The package is available
online at https://github.com/BiologicalRecordsCentre/plantnet.

the Pl@ntNet user community (currently 1.8 million user accounts). At the time
of writing, the CNN architecture used is the inception model49 extended with
batch normalization.50 The network is pre-trained on the commonly used Im-
ageNet dataset and ﬁne-tuned on Pl@ntNet data. Pl@ntNet currently covers
30,261 species illustrated by more than 2.9 million images. The taxonomic
coverage of our study is therefore one to three orders of magnitude larger
than previously published studies making use of automated species identiﬁca-
tion for ecological research. The training of Pl@ntNet CNN requires the mobi-
lization of a high-performance computing infrastructure and expertise in deep,
distributed, and large-scale learning. Thus, the resulting classiﬁcation tool is in
itself a major advance in biodiversity data science.

AI naturalists, just like their human counterparts, may have
their own biases which must be fully understood if the informa-
tion that they generate is to be trusted and suitably utilized. For
example, most AI systems can only detect or recognize already
seen (or learned) objects or concepts. Benchmark datasets of
images can be organized to precisely assess the limits of AI sys-
tems’ ability, highlighting where human expertise is still required.
Deep learning models (some of the most advanced AI algo-
rithms) are developed with training datasets that allow them to
capture discriminant visual patterns. Their performances are
then strongly correlated to the quality and completeness of the
datasets on which they are trained. Unbalanced, biased, or
otherwise poor-quality training datasets will lead to underper-
forming algorithms in real conditions.27 During the learning
phases, particular attention must be given to any relevant limita-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention the specific optimization techniques applied in the deep learning pipeline such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). However, it does provide some information about the deep learning process used in developing the Pl@ntNet classification tool.

The text mentions that the Convolutional Neural Network (CNN) used in Pl@ntNet is based on the Inception model, which is then fine-tuned using Pl@ntNet data after being pre-trained on the ImageNet dataset. This suggests that transfer learning, a common optimization technique in deep learning, might be employed here. Transfer learning involves leveraging knowledge gained from solving one problem and applying it to another related problem.

Moreover, the text also highlights the importance of having high-quality and balanced training datasets for achieving good performance in real conditions. This implies that strategies for handling unbalanced or biased datasets could potentially be part of the optimization techniques used in the deep learning pipeline.

However, without explicit mention of optimization techniques such as SGD or Adam in the provided context, I cannot definitively state what optimization techniques are applied in the deep learning pipeline.