Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

647

Model architecture

Convolutional neural networks (CNNs) are a subset of DNNs that are specialized for image 
classification  tasks  and  pattern  recognition.  One  of  the  main  advantages  of  CNNs  is  the 
ability to perform automated feature extraction, eliminating the need for hand-crafted fea-
ture  extraction.  CNN  architecture  is  built  on  three  types  of  layers:  (1)  convolutional  lay-
ers,  which  are  the  most  important  because  they  apply  hierarchical  feature  extraction  and 
decomposition  of  input  images;  (2)  pooling  layers,  which  carry  out  operations  to  reduce 
numbers of parameters and necessary computation; and (3) fully connected layers, which 
perform the actual classification at the end of the pipeline.

Funding  No funding was used for this research.

Data  availability  Data  are  publicly  available  via  Cornell  University’s  Laboratory  of  Ornithology  and 
Macaulay Library of Natural Sounds (https ://www.macau layli brary .org).

Compliance with ethical standards 

Conflict of interest  All authors declare that they have no conflicts of interest.

References

Abadi M et al. (2016) Tensorflow: a system for large-scale machine learning. Paper presented at the 12th 

USENIX Symposium on Operating Systems Design and Implementation, Savannah, USA,

1 3Biodiversity and Conservation (2021) 30:643–657 

655

Aide TM, Corrada-Bravo C, Campos-Cerqueira M, Milan C, Vega G, Alvarez R (2013) Real-time bioacous-

tics monitoring and automated species identification. PeerJ 1:e103

Araya-Salas M, Smith-Vidaurre G (2017) warbleR: an R package to streamline analysis of animal acoustic 

signals. Methods Ecol Evol 8:184–191

Biodiversity and Conservation (2021) 30:643–657

(2) how does TensorFlow perform when it encounters species that do not exist in its 
reference library? To answer these questions, we generated 20 spectrograms per spe-
cies for this new dataset, resulting in a total of 440 spectrograms, to be subjected to 
identification using the CNN developed in Challenge 1.

3.  Challenging TensorFlow to identify all 41 species for which recordings are available 
We increased the number of species in the TensorFlow reference library to 41 by add-
ing 21 new, undescribed species (one species in the new dataset was already present 
in reference library, owing to a recent taxonomic change; Brown et al. 2015b). Then, 
we followed the same procedure as in Challenge 1, to test performance on a reference 
library that is twice as large as the original (i.e., 41 classes).

Across broader taxonomic scales and phylogenetic relationships (e.g., Chan and Brown 
2017), other means (biogeographic realm, ectomorph type, classification, etc.) of restrict-
ing/limiting  candidate  species  pools  may  prove  useful  for  ‘fine-tuning’  of  TensorFlow’s 
automation of species recognition. Additional caveats for future consideration include (1) 
single notes per species and (2) sample sizes, which will be limited for rare species, those 
that occur at naturally low abundances, or taxa characterized by reduced detection proba-
bilities due to cryptic microhabitat preferences, narrow activity patterns, or seasonally-lim-
ited  reproductive  cycles  (Wells  2010).  Avenues  for  future  development  of  these  methods 
in  our  immediate  plans  include  application  to  additional  taxonomic  groups  (e.g.,  insects, 
birds), and automation of call detection from environmental sound samples as a precursor 
step to automated species identification.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific datasets used in the deep learning pipeline. However, it mentions that data were obtained from Cornell University’s Laboratory of Ornithology and Macaulay Library of Natural Sounds. The researchers generated 20 spectrograms per species for their new dataset, resulting in a total of 440 spectrograms. They also added 21 new, undescribed species to increase the number of species in the TensorFlow reference library to 41. Therefore, it can be inferred that the datasets used in the deep learning pipeline consist of audio recordings of various bird species, represented as spectrograms.