Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

As it has been proven, ELMs are an important approach for handling and analysing Big
Data as they require the minimum training time relative to the corresponding engineering
learning algorithms. Moreover ELMs do not require ﬁne manipulations to determine their
operating parameters and ﬁnally they can determine the appropriate output weights
towards the most eﬀective resolution of a problem. What is most important, they have
in contrast to corresponding methods which adjust their
the potential to generalize,

508

K. DEMERTZIS ET AL.

performance based solely on their training data set. It is obvious that the emerging use of
ELM in Big Data analysis as well as DELE creates serious prerequisites for complex systems’
development by low-cost machines.

8. Future research

ELMs use the SLFFNN’s general methodology, with the speciﬁcity that the Hidden Layer
(feature mapping) is not required to work in a coordinated fashion. All hidden-layer par-
ameters are independent from the activation functions and from the training data.

ELMs can randomly create hidden nodes or hidden level parameters, before seeing the
training data, while it is remarkable that they can handle non-diﬀerential activation
equations and they do not address known NN problems such as stopping criterion, learn-
ing rate and learning epochs (Cambria & Guang-Bin, 2013; Huang, 2014, 2015).

A mathematical basis has been provided for the understanding of ELM (Equations

(1)–(9)) (Cambria & Guang-Bin, 2013; Huang, 2014, 2015).

For an ELM using SLFFNN and random representation of hidden neurons, input data is
mapped to a random L-dimensional space with a discrete training set N, where
(xi,ti), i [ 1, N with xi [ Rd and ti [ Rc. The speciﬁcation output of the network is the
following:

Before introducing our proposed algorithm, it would be essential to discuss the existing basic
theoretical framework. The question of whether a small Neural Network architecture can
learn a lot, even from huge training data sets, was answered in the aﬃrmative by ELM. An
ELM (Cambria & Guang-Bin, 2013) is a Single-Hidden Layer Feed Forward Neural Network
(SLFFNN) with N hidden neurons, randomly selected input weights and random values of
bias in the hidden layer, while the weights at its output are calculated with a single multipli-
cation of vector matrices. SLFFNNs are used in ELMs because of their ability to approach any
continuous function and to classify any discontinuous areas. An ELM can accurately learn N
samples, and its learning speed can be even thousands of times greater than the speed of
conventional Back Propagation Feed Forward Neural Networks (BP_FFNN).

The implementation of this proposed framework was based on the DELE philosophy.
An important aspect of the framework is the usage of ELM which has proven to be
capable, of solving a multidimensional and complex IT problem. The Deep ELM simulates
the functioning of biological brain cells in a most realistic mode. This creates the potential
for a fully automated conﬁguration of the model with high accuracy classiﬁcation. An inno-
vative aspect of this work is the development of this model using Online Sequential Multi-
layer algorithm plus a Graph Regularized Extreme Learning Machine Autoencoder that
aims to optimize the choice of the input layer weights and bias. This has been done in
order to achieve a higher level of generalization. This method combines two highly
eﬀective machine learning algorithms, for solving a multidimensional and complex
machine hearing problem. Another interesting point is the performance of feature extrac-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't specific information about the hyperparameters used in the deep learning model, such as learning rate or optimizer. However, we can infer some details about the model's structure and components.

The text mentions that the deep learning model uses a Single-Hidden Layer Feed Forward Neural Network (SLFFNN) with N hidden neurons. The input weights and biases in the hidden layer are randomly selected, while the output weights are calculated through a single multiplication of vector matrices.

Additionally, the model incorporates an Online Sequential Multilayer algorithm and a Graph Regularized Extreme Learning Machine Autoencoder. These elements aim to optimize the choice of input layer weights and bias, ultimately improving the model's generalization capabilities.

However, without explicit mention of the learning rate, optimizer, or other common hyperparameters, it is difficult to provide a definitive list of those used in this particular deep learning model.