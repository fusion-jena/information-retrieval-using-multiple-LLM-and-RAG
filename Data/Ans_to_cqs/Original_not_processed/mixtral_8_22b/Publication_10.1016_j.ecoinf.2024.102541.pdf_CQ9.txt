Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Lee, S., Agrawal, A., Balaprakash, P., Choudhary, A., Liao, W., 2018b. Communication- 
efficient parallelization strategy for deep convolutional neural network training. In: 
Proceedings of MLHPC 2018 : Machine Learning in HPC Environments. 

Lin, T.-Y., et al., May 2014. Microsoft COCO: common objects in context. In: 13th 

European Conference in Computer Vision (ECCV), pp. 740–755 [Online]. Available: 
http://arxiv.org/abs/1405.0312. 

Liu, W., et al., 2016. SSD: single shot MultiBox detector. Europ. Conf. Comp. Vision 1, 

852–869. https://doi.org/10.1007/978-3-319-46448-0. 

Dong, X., Yan, S., Duan, C., Aug. 2022. A lightweight vehicles detection network model 

Liu, J., Zhang, L., Li, Y., Liu, H., 2023a. Deep residual convolutional neural network 

based on YOLOv5. Eng. Appl. Artif. Intell. 113 https://doi.org/10.1016/j. 
engappai.2022.104914.

ground-truth annotations, with a histogram in the top-left showing class 
distribution  and  additional  visualizations  including  label,  mask,  and 
heat maps, offering comprehensive insights into the dataset’s structure 
and diversity.

3.1.1. Backbone network 

The YOLOv5s model, a standout in computer vision, excels in various 
applications with its convolutional layer backbone, adept at extracting 
high-level image features. This backbone, based on CSPDarknet53 and 
shown in Fig. 2(a), improves upon Darknet53 from YOLOv3 (Redmon 
and Farhadi, 2018) to ensure efficient information processing. This led 
to the reengineering of the YOLOv5s backbone (Fig. 2(b)), enhancing its 
efficiency and reducing computational demands. The modified model is 
both  versatile  and  lightweight,  blending  the  precision  of  computer 
vision with ecological research needs. Subsequent subsections detail the 

EcologicalInformatics80(2024)1025413S.R. Bakana et al.                                                                                                                                                                                                                              

Fig. 1. Mosaic Data Enhancement sample.

Sibusiso  R.  Bakana:  Conceptualization,  Data  curation,  Formal 
analysis, Investigation, Methodology, Project administration, Resources, 
Validation, Visualization, Writing –  original draft, Writing –  review & 
editing,  Funding  acquisition.  Yongfei  Zhang:  Conceptualization, 
Funding  acquisition,  Supervision,  Validation,  Visualization,  Writing  – 
review & editing. Bhekisipho Twala: Supervision, Validation, Visuali-
zation, Writing – review & editing. 

Declaration of competing interest 

There are no conflicts to declare. 

Data availability 

Our  dataset  is  publicly  available  here  https://data.mendeley. 
com/datasets/vhmvfbgvxj/2 and the code can be shared as per request. 

References 

Adarsh, P., Rathi, P., Kumar, M., Mar. 2020. YOLO v3-tiny: Object detection and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
According to the given context, the data repository of the deep learning pipeline is available at <https://data.mendeley.com/datasets/vhmvfbgvxj/2>. However, it does not explicitly mention if this link leads to any specific data repository such as Zenodo, Figshare, Dryad, or GBIF. Therefore, I cannot provide a more precise answer regarding which specific data repository hosts the mentioned dataset.