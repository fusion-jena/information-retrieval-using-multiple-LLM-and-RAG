Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

size of 256*256 pixels were converted to 64*64 pixels to save training
time and reduce high memory graphics use. The size-reduced images
packaged into two datasets: training dataset with 85% of images
(111,244/130,858) and validation dataset with 15% (19,614/130,858)
using a Python script Making_dataset.py in Waveman. To balance the
image number for all the species, we provided an upper limit for when a
species had too much data (Supplementary information 1, S1). We also
developed a method to increase the number of images for the rare
species (S2), in which signals were rescaled exponentially, and we
shifted the window slightly either side of the call to change background
noise. Both these measures ensure rare species with small image num-
bers will not be under-represented and under-classified relative to
common species (S1), as though we cannot incorporate the same level
as call variation as in common species this measure rebalances the

We further improved Waveman by modifying BatNet and opti-
mizing parameter setting of batch size. We add new kind of BNorm
layers behind the 22 convolutional layers to prevent overfitting when
we trained models using BatNet (Fig. 2C). Therefore the model
“learned” to generalize from a trend in both “known” and “unknown”
datasets rather than to maximize the performance on the “known”
datasets (usually called training datasets, Ioffe and Szegedy, 2015).
Computers can only train with small volumes of images at once as they
have too little Random Access Memory or Graphic memory. Batch size
was set to limit the image number. In this study, we set a large batch
size equal to 128, which means training with 128 images for each
iteration.

rate equaled 1e-3 (only a network called ResNet_v2 was set to 1e-5). We
trained a model using the training dataset (incl. 111,244 images) for
50–60 times using Graphic Processing Unit (GPU, Nvidia 1080ti, US)
for two hours and 10 min. After training the model contained refined
parameters and a graph which were saved for the downstream analysis.

2.2. Testing and further refinements of Waveman

We used filtered data (i.e., validation dataset in which 19,614
images were selected) to test different model and taxon bias. Then we
collected audio-files from a corridor for the 15 species to test how to
lower the misidentification and false positives. Finally, we optimized
the BatNet and collected audio from different human and natural
conditions to test the generalization of the model by recording the same
species under different conditions these audio-files are unfiltered and
were directly imported into Waveman.

2.2.1. Comparison of BatNet and other three networks

Biological Conservation 241 (2020) 108269

Contents lists available at ScienceDirect

Biological Conservation

journal homepage: www.elsevier.com/locate/biocon

Automatic standardized processing and identification of tropical bat calls
using deep learning approaches

T

Xing Chena,1, Jun Zhaob,1, Yan-hua Chena, Wei Zhoub,*, Alice C. Hughesa,*
a Center for Integrative Conservation, Xishuangbanna Tropical Botanical Garden, Chinese Academy of Sciences, Menglun 666303, China
b Software School, Yunnan University, Kunming 650500, China

A R T I C L E I N F O

A B S T R A C T

Keywords:
Bats
Bioacoustics
Automated monitoring
Algorithms
Deep learning
Neural network
Automatic processing
Biodiversity metrics
Machine learning
Calls
Echolocation
Monitoring protocol

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The strategy implemented to monitor the model performance during training involves several steps. Firstly, the images were reduced in size from 256*256 pixels to 64*64 pixels to save training time and reduce high memory graphics use. These size-reduced images were then packaged into two datasets: a training dataset with 85% of the images and a validation dataset with 15%. This was done using a Python script Making_dataset.py in Waveman.

To balance the image number for all the species, an upper limit was provided for when a species had too much data. Additionally, a method was developed to increase the number of images for the rare species, where signals were rescaled exponentially, and the window was shifted slightly either side of the call to change background noise.

Waveman was further improved by modifying BatNet and optimizing parameter settings of batch size. New kinds of BNorm layers were added behind the 22 convolutional layers to prevent overfitting when training models using BatNet. The model was trained using the training dataset for 50–60 times using GPU for two hours and 10 minutes. After training, the model contained refined parameters and a graph which were saved for downstream analysis.

The testing and further refinement of Waveman involved using filtered data (validation dataset) to test different models and taxon bias. Audio files from a corridor for the 15 species were collected to lower misidentification and false positives. The model was optimized, and audio from different human and natural conditions was recorded to test the generalization of the model.

However, the specific strategy to monitor the model performance during training is not explicitly mentioned in the given context. It could involve techniques such as tracking loss and accuracy metrics during training, visualizing the model's predictions, or using tools like TensorBoard for real-time monitoring. But without explicit mention in the context, it remains uncertain what exact methods were employed.