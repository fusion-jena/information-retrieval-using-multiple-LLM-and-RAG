Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

These  spectrogram images  are  input  into  the  ResNet-50  deep  (50- 
layer) convolutional neural network (CNN), which was developed and 
pre-trained using millions of label images in over 1000 categories (He 
et  al.,  2015).  Although  ResNet-50  was  not  explicitly  trained  on  spec-
trograms, many studies have shown that CNNs pre-trained for one task 
can  extract  meaningful  features  distant  from  the  original  training 
dataset  (e.g.,  Almabdy  and  Elrefaei,  2019;  Bousetouane  and  Morris, 
2015; Copiaco et al., 2019; Razavian et al., 2014). A suite of features is

similarities. It is widely used to visualize high-dimensional data (van der 
Maaten  and Hinton, 2008). Here the  method has been applied to the 
fc1000 activation vectors returned by ResNet-50. 

4.2. Classifier model 

The labeled dataset was split 70/30 into training and testing data-
sets.  For  model  selection  and  parameter  optimization  50%  of  the 
training data were held-out for validation (see Supporting Information). 
The final classification model, a SVM with a cubic polynomial kernel, 
was trained using the ResNet-50 fc1000 activations of the full training 
dataset. A 10-fold cross-validation was then used to define the score-to- 
posterior-probability transformation function (Platt, 2000), which pro-
vides a basis for estimating the posterior probability for new observa-
tions. Fig. 9 shows a confusion matrix for the test data not seen during 
training.

EcologicalInformatics77(2023)1022686D.R. Bohnenstiehl                                                                                                                                                                                                                               

Fig.  6. Feature  extraction  and  classification  work-
flows as applied to the same data segments in Fig. 5. 
An  850-ms  long  data  segment  (boxes)  is  extracted 
from the unfiltered waveform around each detection 
to  form  a  frequency-reassigned  spectrogram  image. 
These  images  are  fed  into  ResNet-50  CNN,  and  acti-
vations  from  the  fully  connected  layer  (fc1000)  are 
used as a feature vector for each detected signal. The 
SVM  classifier  is  used  to  classify  the  candidate  de-
tections based on the layer activations. Signals in the 
‘other’  class  represent  false  alarms  identified  by 
detection stage.

Acknowledgments 

Hydrophone deployment and recovery were facilitated by O. Caretti, 
with  assistance  from  R.  Patrick  Lyon,  E.  Voigt,  and  K.  Simmons.  The 
members of the Jones Bay Club generously provided use of their boat 
ramp  for  instrument  deployment  and  recovery.  This  work  benefited 
from discussions with S. Ricci and D. Eggleston, as well as from early 
testing and critical conversations with O. Caretti and R. Van Hoeck. 

References 

Almabdy, S., Elrefaei, L., 2019. Deep convolutional neural network-based approaches for 
face recognition. Appl. Sci. 9 (20), 4397. https://doi.org/10.3390/app9204397. 

Amorim, M.C.P., 2006. Diversity of sound production. In: Ladich, F., Collin, S.P., 
Moller, P., Kapoor, B.G. (Eds.), Communication in Fishes. Science Publishers, 
Enfield, NH, pp. 69–103.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the study does not directly discuss specific techniques to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some general practices can be observed in this research.

Firstly, the labeled dataset was divided into training and testing datasets with a 70/30 split. While this division is mentioned, there is no explicit mention of whether this split was performed randomly or if any particular technique like stratification was employed to maintain class balance.

Secondly, within the training dataset, half of the data was set aside for validation purposes. Again, it is not specified how this subset was selected - whether it was done randomly or through a more sophisticated approach like stratified sampling.

Lastly, the paper mentions that the final classification model, a support vector machine (SVM) with a cubic polynomial kernel, was trained using the ResNet-50 fc1000 activations of the full training dataset. Afterward, a 10-fold cross-validation was utilized to establish the score-to-posterior-probability transformation function. Cross-validation is a common practice to ensure robustness against overfitting and underrepresentation of certain classes but does not necessarily tackle data imbalance issues head-on.

Therefore, while the study employs several good practices for handling data in a deep learning pipeline, it does not provide direct evidence of employing specific techniques to address data bias during preprocessing.