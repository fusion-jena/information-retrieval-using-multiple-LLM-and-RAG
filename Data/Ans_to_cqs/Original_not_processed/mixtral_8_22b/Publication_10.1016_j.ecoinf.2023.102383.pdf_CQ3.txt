Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 10. An example of deer annotation. There are 72 deer in the left image. The 72 deer are annotated by ImageLab as shown in the right image.

discarded.  This  verification  process  aims  to  prevent  subjective  biases 
and ensure the accuracy and reliability of the annotations. As a result, a 
comprehensive dataset consisting of 2278 thermal images and 13,509 
deer  instance  annotations  was  constructed.  The  entire  process  took 
approximately seven days, with the two scientists and two students each 
dedicating four hours each day to complete the task.

compressed,  reducing  to  only  a  few  pixels  in  deeper  CNN  layers.  For 
instance, an object with dimensions of 15 × 15 pixels in a UAV thermal 
image might be represented by just 1 pixel in the feature map from Layer 
4 of ResNet152 (refer to Fig. 4). The limited spatial resolution can lead to 
loss of fine details, making it difficult for the model to distinguish small 
objects from the background. Through FPN, different feature maps from 
different layers can complement each other, and deeper feature map can 
receive some spatial information from shallower layers. However, still 
certain  spatial  features  might  have  been  lost  during  the  process  of 
convolution operations. Consequently, the models of FRC_ResNet18FPN 
and FRC_ResNet34FPN can obtain higher AP for medium and large ob-
jects than the remaining models because they have less CNN layers than 
others.  Notably,  the  FRC_ResNet152FPN  obtains  the  best  detection

For deep learning-based object detection, two fundamental elements, 
feature  maps  and  anchor  boxes,  play  critical  roles.  Feature  maps  are 
extracted from original images and utilized to identify potential objects 
of  interest  and  locate  their  rough  positions  within  an  image.  Subse-
quently, anchor boxes come into play for generating regions of interest 
(RoIs)  and  facilitating  bounding  box  regression,  which  enables  the 
refinement of RoIs to better match the bounding box of the objects of 
interest. In the general definition of CNNs, the CNN layers that are closer 
to the input layer are called shallower layers, while deeper layers are 
those more distant  from the  input  layer. In the  architecture of  object 
detection,  various  CNNs—such  as  ResNet18,  ResNet34,  ResNet50, 
ResNet101, and ResNet152—differ in the overall depth of their layers. 
These CNNs are used to extract feature maps from the original imagery.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific data annotation technique used in the deep learning pipeline. However, based on the given context, we can infer that the method employed is bounding box annotation. This is evident from Figure 10, where the instances of deer are enclosed within rectangular bounding boxes. Bounding box annotation is a popular technique used in object detection tasks, where the objective is to draw a rectangle around the target object in an image.

In this case, the goal was to create a comprehensive dataset comprising 2278 thermal images and 13,509 deer instance annotations. To achieve this, a team of two scientists and two students dedicated four hours each day over seven days to manually annotate the images. A rigorous verification process was also implemented to eliminate any subjective biases and maintain the accuracy and reliability of the annotations.

While the text does not discuss other data annotation techniques such as semantic segmentation or instance segmentation, these methods could potentially be applied to similar datasets depending on the specific requirements of the project. Semantic segmentation involves assigning a class label to every pixel in an image, whereas instance segmentation focuses on identifying individual instances of objects belonging to the same class.