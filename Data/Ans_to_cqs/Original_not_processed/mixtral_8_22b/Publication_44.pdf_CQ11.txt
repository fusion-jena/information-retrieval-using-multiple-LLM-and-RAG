Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Herbarium sheet images are usually of high resolution to capture the ﬁne-grain details
of the specimens. As a standard procedure for training deep learning models, all input
images together with their annotation were resized to a 512 × 512 resolution to reduce
the computational cost during training. Rotation, ﬂipping, and brightness adjustments
were applied as augmentation techniques for better network generalization. We used
DeepLabv3+ as the segmentation model with ResNet-101 as the feature extractor. This
model was pre-trained on the ImageNet dataset and ﬁne-tuned on the dataset. This is
useful as earlier layers of the network tend to learn generic features and therefore become
useful for other computer vision tasks [49]. We applied an Adam optimizer with a learning
rate of 1 × 10−4 and a batch size of 3. The model was trained for 100 epochs with a binary
cross-entropy loss function as we had a binary class problem (leaf or background).

In this phase, we adapted DeepLabv3+ architecture, which follows the same encoder-
decoder architecture. This was based on the performance of the DeepLabv3+ model on
our previous work related to the segmentation of the whole herbarium specimen [7]. The
model has also being widely adapted for herbarium-related studies [36]. Apart from that,
DeepLabv3+ has been the state-of-the-art in different benchmarking datasets for semantic
segmentation tasks [37]. Deeplabv3+ follows the same encoder-decoder architecture. In
the encoder phase, DeepLabv3+ uses pre-trained CNNs that have been trained for image
classiﬁcation tasks such as ResNet or VGG16. DeepLab families uses spatial pyramid
pooling to process input images at multiple scales in order to capture multi-scale features
and later fuse the output to produce a feature map [38]. To improve its efﬁciency, an Atrous
convolution operation was introduced. This operation enables the window size of the

classification that has the same size as an input image.  In this phase, we adapted DeepLabv3+ architecture, which follows the same encoder-decoder architecture. This was based on the performance of the DeepLabv3+ model on our previous work related to the segmentation of the whole herbarium specimen [7]. The model has also being widely adapted for herbarium-related studies [36]. Apart from that, DeepLabv3+ has been the state-of-the-art in different benchmarking datasets for semantic segmentation tasks [37]. Deeplabv3+ follows the same encoder-decoder architecture. In the encoder phase, DeepLabv3+ uses pre-trained CNNs that have been trained for image classification tasks such as ResNet or VGG16. DeepLab families uses spatial pyramid pooling to process input images at multiple scales in order to capture multi-scale features Sensors 2021, 21, 4549

7. Hussein, B.R.; Malik, O.A.; Ong, W.-H.H.; Slik, J.W.F. Semantic Segmentation of Herbarium Specimens Using Deep Learning
Techniques. In Computational Science and Technology, Proceedings of the 6th ICCST 2019, Kota Kinabalu, Malaysia, 29–30 August 2019;
Springer: Berlin/Heidelberg, Germany, 2020; pp. 321–330. [CrossRef]
Carranza-Rojas, J.; Goeau, H.; Bonnet, P.; Mata-Montero, E.; Joly, A. Going deeper in the automated identiﬁcation of Herbarium
specimens. BMC Evol. Biol. 2017, 17, 181. [CrossRef]
Lang, P.L.M.; Willems, F.M.; Scheepens, J.F.; Burbano, H.A.; Bossdorf, O. Using herbaria to study global environmental change.
New Phytol. 2019, 221, 110–122. [CrossRef]

8.

9.

10. Hussein, B.R.; Malik, O.A.; Ong, W.-H.; Slik, J.W.F. Reconstruction of damaged herbarium leaves using deep learning techniques

11.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not provide information about the data repository link of the deep learning pipeline. Therefore, it is not possible to determine the specific link to resources like Zenodo, Figshare, Dryad, or GBIF.