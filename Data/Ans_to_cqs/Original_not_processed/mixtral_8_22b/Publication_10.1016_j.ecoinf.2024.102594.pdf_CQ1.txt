Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

During the DeepLabV3+ model training process, feeding large-size 
images directly to the network may lead to memory overflow. There-
fore, it is necessary to cut all remote sensing images and semantic labels 
of land cover classes into a series of regular image blocks for input. To 
maximize the sample size and maintain consistency with the cropping 
approach in the model prediction stage, we set the cropping size to 32 ×
32  pixels  with  a  redundancy  rate  of  0.5.  In  continuing,  70%  of  the 
dataset  was  used  for  training  and  the  remaining  for  validation.  The 
training set was enhanced by: (i) Flipping the images and labels along 
the X or Y axis; (ii) Exchanging between multiple image channels while 
the  labels remain unchanged; (iii)  Randomly rotating  the images and 
◦
labels by 90
; and (iv) randomly adding noise to the 
images  while  maintaining  the  labels  unchanged  (Ye  et  al.,  2022).

3.1. DeepLabV3+ algorithm 

DeepLabV3+ is a CNN algorithm for semantic segmentation, which 
is the latest version of the DeepLab algorithms family (Scepanovic et al., 
2021).  In  the  encoding  stage,  DeepLabV3+ introduces  dilated  convo-
lutions,  which expands  the  receptive field  without losing information 
(Fig.  3).  The  Atrous  spatial  pyramid  pooling  module  with  dilated 
convolution  has  been  mainly  designed  to  appropriately  incorporate 
multi-scale information. During decoding, it is capable of enhancing the 
accuracy  of  segmentation  boundaries  by  further  integrating  low-level 
features with high-level features (Liu et al., 2021a).

Enhancing Land Cover/Land Use (LCLU) classification through a comparative 
analysis of hyperparameters optimization approaches for deep neural network 
(DNN). Ecol. Inform. 78, 102333 https://doi.org/10.1016/j.ecoinf.2023.102333. 
Ba, J., Gao, F., Peng, C., Li, J., 2022. Characteristics of nitrate and heavy metals pollution 
in Huixian Wetland and its health risk assessment. Alex. Eng. J. 61, 9031–9042. 
https://doi.org/10.1016/j.aej.2022.02.045. 

Berra, E.F., Gaulton, R., Barr, S., 2019. Assessing spring phenology of a temperate 

woodland: a multiscale comparison of ground, unmanned aerial vehicle and Landsat 
satellite observations. Remote Sens. Environ. 223, 229–242. https://doi.org/ 
10.1016/j.rse.2019.01.010. 

Buchsteiner, C., Baur, P.A., Glatzel, S., 2023. Spatial analysis of intra-annual reed 

ecosystem dynamics at Lake Neusiedl using RGB drone imagery and deep learning. 
Remote Sens. 15, 1–22. https://doi.org/10.3390/rs15163961.

EcologicalInformatics81(2024)1025944Z. Chen et al.                                                                                                                                                                                                                                    

Fig. 2. Flowchart of the processing steps of the proposed approach.  

Fig. 3. Structure of the DeepLabV3+ algorithm.  

EcologicalInformatics81(2024)1025945Z. Chen et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit details about the methods used for collecting raw data in the deep learning pipeline. However, based on general practices in deep learning applications, various methods can be employed for gathering raw data. These include but are not limited to:

1. Surveys: Data collection through surveys involves gathering information from individuals via questionnaires or interviews. This method is often used when human insights are required for specific tasks such as sentiment analysis or emotion recognition.

2. Sensors: Sensor data collection involves utilizing devices equipped with sensors like cameras, microphones, GPS, accelerometers, etc., to gather real-world data. For instance, in environmental studies, sensor data might be collected from weather stations, water quality monitors, or air pollution detectors.

3. Public Datasets: Utilizing publicly available datasets is another common practice in deep learning research. These datasets could have been gathered from various sources, including online platforms, government databases, or scientific research projects. Examples of popular public datasets include ImageNet for computer vision tasks, MNIST for handwritten digit recognition, and COCO for object detection and segmentation.

Based on the context provided, it appears that the study focuses on applying the DeepLabV3+ algorithm for semantic segmentation tasks related to land cover/land use (LCLU) classification. While the exact source of the dataset isn't mentioned, one can infer that the researchers likely used satellite or aerial imagery data due to their relevance to the task at hand. Nonetheless, without more specific information regarding the data collection process, it remains uncertain whether the data were obtained through direct acquisition, public datasets, or other means.