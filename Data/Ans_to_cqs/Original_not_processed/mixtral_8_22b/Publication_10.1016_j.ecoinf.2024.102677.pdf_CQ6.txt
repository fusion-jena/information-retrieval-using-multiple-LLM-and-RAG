Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

discriminant rules are illustrated in Fig. 3. Finally, we employed deep 
learning techniques to predict the types of landscapes in the case study 
area. The classification process based on deep learning encompasses the 
following stages.

4.2. Landscape type classification 

The  five  network  models  were  evaluated  using  the  performance 
metrics  of  the  validation  and  test  sets.  The  model  accuracy  was 
continuously assessed using the validation set during training, and the 
performance of the testing set guided the final decision. Fig. 6 illustrates 
the  learning  curves,  indicating  a  reduction  in  training  losses  as  the 
number  of  epochs  increases  and  convergence  within  500  epochs. 
Inceptionv3  converges  by  400  epochs,  while  the  other  networks 
converge  within  150  epochs.  The  ResNet  architecture,  especially 
ResNet50 and ResNet101, outperforms the others.

To ensure the stability of the proposed models, we randomly divided 
the  dataset  into  three  parts:  training  (60%),  validation  (20%),  and 
testing  (20%)  (Meng  et  al.,  2022).  This  division  was  performed  in  a 
stratified manner to maintain class proportions across all of the parts. 
The dataset was randomly divided into a training set (2880 images), a 
validation set (961 images), and a testing set (958 images). The models 
were trained on an NVIDIA 3090 GPU with a 256 Ã— 256 image input 
size. After parameter tuning, the learning rate, batch size, and number of 
epochs were set to 0.0001, 8, and 30, respectively.  

(2)  Model selection

(2)  Model selection 

In recent years, deep learning has made rapid progress in the field of 
image  recognition,  thus  greatly  improving  computer  processing. Con-
volutional neural network (CNN) is a popular deep learning architecture 
applied to image classification with good performance in the extraction 
of underlying abstract features (Meng et al., 2022). Convolution layers, 
pooling layers, fully connected layers, and nonlinear operations consti-
tute the CNN model (Attri et al., 2023). We fine-tuned several state-of- 
the-art  CNN  architectures,  including  the  Visual  Geometry  Group 
(VGG)  (Simonyan  and  Zisserman,  2014),  Inception  (Szegedy  et  al., 
2016), and residual network (ResNet) (He et al., 2016) CNNs, using the 
training dataset, and we evaluated their respective  performances. We 
selected from these networks the most effective model to create the rural

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it does not explicitly mention any specific preprocessing steps taken before training the deep learning models for landscape type classification. However, some common preprocessing steps often used in deep learning include data normalization, scaling, cleaning, and augmentation. These steps help improve the quality and consistency of the input data, which can lead to better model performance.

Data normalization involves adjusting values measured on different scales to a common scale, such as rescaling numerical inputs between 0 and 1 or applying z-score normalization. Scaling may also be necessary if certain features have significantly larger magnitudes compared to others, potentially affecting the model's ability to learn effectively.

Cleaning the data refers to handling missing or inconsistent entries, removing noise, and addressing outliers. Properly cleaned datasets contribute to more accurate predictions and improved overall model performance.

Data augmentation is another technique frequently applied in deep learning tasks involving images. It generates new samples by applying transformations like rotation, flipping, zooming, cropping, or shifting to existing images. Data augmentation helps increase the diversity of the training dataset and reduces overfitting.

Although the context does not provide explicit information about the preprocessing steps used, it mentions that the models were trained on an NVIDIA 3090 GPU with a 256 x 256 image input size. This suggests that some form of image resizing or rescaling might have been implemented as part of the preprocessing stage.