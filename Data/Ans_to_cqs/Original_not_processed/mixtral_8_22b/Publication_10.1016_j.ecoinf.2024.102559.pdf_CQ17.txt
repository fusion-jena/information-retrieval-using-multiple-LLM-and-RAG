Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., 
Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, ´E., 2011. Scikit-learn: machine 
learning in Python. J. Mach. Learn. Res. 12, 2825–2830. 

Petty, A.M., Setterfield, S.A., Ferdinands, K.B., Barrow, P., 2012. Inferring habitat 

suitability and spread patterns from large-scale distributions of an exotic invasive 
pasture grass in North Australia. J. Appl. Ecol. 49 (3), 742–752. https://doi.org/ 
10.1111/j.1365-2664.2012.02128.x. 

Prasai, R., Schwertner, T.W., Mainali, K., Mathewson, H., Kafley, H., Thapa, S., 

Adhikari, D., Medley, P., Drake, J., 2021. Application of Google earth engine python 
API and NAIP imagery for land use and land cover classification: A case study in 
Florida, USA. Eco. Inform. 66, 101474 https://doi.org/10.1016/j. 
ecoinf.2021.101474.

structures (e.g., roads and buildings) and water from slowing down the 
classification processing. This step reduced the average number of pixels 
per scene the classification model had to analyze to 3,757,323 and took, 
on average, 18 s per scene.

6. Conclusion 

Preserve, where The Nature Conservancy is actively working to priori-
tize its iceplant removal efforts. This machine learning application opens 
the door to scale methods across space and over time efficiently. While 
some steps require manual input (for example, creating a training set for 
a  minority  class  in  the  landscape),  the  emphasis  on  creating  a  repro-
ducible data analysis and validation workflow makes it possible for the 
methods presented to be adapted and applied across California and to all 
the other Mediterranean climatic regions in the world, plus over time to 
understand the spread and mitigation of iceplant invasions. 

Funding 

This work was supported by a gift from Microsoft (funding code 8- 

448755-17211-EC417) and NASA grant #80NSSC23K1561. 

CRediT authorship contribution statement

Despite its invasive nature, iceplant remains a minority land cover 
class  in  most  NAIP  scenes  in  this  region  compared  to  non-iceplant 
vegetation. Generating training and test data by sampling designs such 
as  random  sampling  or  allocating  samples  in  proportion  to  expected 
class  areas  would  therefore  result  in  a  highly  unbalanced  dataset. 
Training machine learning models with unbalanced sets poses a chal-
lenge to accurately predicting the minority class, often leading to under- 
predicting  it,  and  multiple  methods  exist in  the  literature  to  improve 
balance  in  a  dataset  (He  and  Garcia,  2009).  Due  to  the  high  spatial 
resolution of NAIP and the expanse of the study region, data availability 
for both classes allowed us to create a reasonably balanced final training 
dataset  having  38%  iceplant  points  and  62%  other  vegetation  points 
without having to discard, repeat, or create synthetic data points.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers cited do not directly discuss the specific regularization methods used to prevent overfitting in their deep learning pipelines. However, some common regularization techniques used in deep learning include dropout and L2 regularization. Dropout involves randomly setting a fraction of input units to 0 during training, which helps prevent overfitting by making the network more robust to small changes in the inputs. L2 regularization adds a penalty term to the loss function, encouraging smaller weights and thus reducing the complexity of the model. Other regularization techniques include early stopping, weight decay, and batch normalization. It is important to note that the choice of regularization method depends on the specific problem and architecture being used.