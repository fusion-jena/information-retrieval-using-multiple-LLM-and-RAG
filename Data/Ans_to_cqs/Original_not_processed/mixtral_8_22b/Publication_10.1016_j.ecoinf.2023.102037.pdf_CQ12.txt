Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

• Aperture: F/10  
• ISO: 160  
• Shutter speed: 1/15 s  
• Focal Length: 55 mm  
• White balance: “Incandescent” 

2.3. Data splitting and image tiling

ofmineervlieg/. Accessed: 1 June 2022.  

Wang, R.J., et al., 2017. A crop pests image classification algorithm based on deep 

convolutional neural network. Telkomnika (Telecommun. Comput. Electron. Contr.) 
15 (3), 1239–1246. Available at: 10.12928/TELKOMNIKA.v15i3.5382. 

Wang, C.Y., et al., 2020a. CSPNet: A new backbone that can enhance learning capability 
of CNN. In: IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition Workshops, 2020-June, pp. 1571–1580. Available at: https://doi.org/ 
10.1109/CVPRW50498.2020.00203. 

Wang, J., et al., 2020b. Common pests image recognition based on deep convolutional 

neural network. Comput. Electron. Agric. 179 (June), 105834. Available at: https 
://doi.org/10.1016/j.compag.2020.105834.

detection  and  classification  accuracy  in  the  popular  object  detection 
benchmarking dataset, known as COCO (Lin et al., 2015), on which it 
was originally trained. In this version of the model, a Cross Stage Partial 
Network (CSPNet) (Wang et al., 2020a) with a Spatial Pyramid Pooling 
(SPP)  layer  is  used  as  the  model  back-bone  and  a  path  aggregation 
network (PANet) as neck to boost information flow. The head in YOLOv5 
achieves multi scale prediction by generating different output feature 
maps. 

2.5. Training, inference and evaluation 

The  insect  detection  model  was  trained  and  tested  using  Ubuntu 
20.04.4 LTS on an HP® Zbook 17 G6 with an Intel®Xeon® E-2286M (16 

EcologicalInformatics75(2023)1020374I. Kalfas et al.

2021a; Wang et al., 2020c). Wang et al. (2020a, 2020b, 2020c) obtained 
a mean Average Precision (mAP) score of 63.54% using YOLOv3 (Red-
mon  and  Farhadi,  2018)  while  detecting  and  classifying  pest  species 
from  the  images  in  their  “Pest24”  dataset.  The  dataset  consisted  of 
25,378  annotated  images  coming  from  24  pest  species  that  were  all 
collected by an automatic imaging trap. Rustia et al. (2021) designed a 
multi-stage deep learning method including object detection, insect vs. 
non-insect  separation  and  a  multi-class  insect  classification  for  insect 
identification. Data were acquired by multiple wireless imaging devices 
installed  in  greenhouses  –  under  varying  lighting environments  -  and 
their classification model reached average F1-scores of up to 0.92. Hong 
et  al.  (2021)  developed  an  AI-based  pest  counting  method  for  moni-
toring  the  black  pine  bast  scale  (M.  thungergianae)  which  reached  a

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The pipeline uses a deep learning model called YOLOv5, which stands for You Only Look Once version 5. This model is a single-stage detector built upon the concept of anchor boxes and is primarily used for object detection tasks. It belongs to the family of Convolutional Neural Networks (CNNs) and is specifically designed for real-time processing. YOLOv5 has several improvements over its predecessors, such as a more efficient architecture, better performance, and support for transfer learning. It also includes features like mosaic data augmentation, adaptive image filling, and auto-learning bounding box anchors.