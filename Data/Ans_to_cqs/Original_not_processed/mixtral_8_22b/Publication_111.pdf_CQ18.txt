Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

train than LSTM [16].

Practically, over/underﬁtting diﬃculties in neural net-
work models are caused by the neural network model’s
excessive/insuﬃcient training epochs [43]. As a result, one
possible solution to the DL-based model’s over/underﬁtting
concerns is to apply the early stopping strategy [44], which is
used to cease training when generalisation performance
starts to degrade for a number of epochs. To track the
generalisation performance,
in the proposed model, the
training data is separated into training and validation
groups.

+e dropout approach [45] is another way to deal with
the overﬁtting problem. Dropout is a regularisation strategy
that allows you to train neural networks with alternative
topologies in parallel by randomly dropping out a certain
proportion of layer neurons. Dropout is indicated by the
black neurons in the fully connected layers, as seen in
Figure 3.

Table 2: +e hyperparameters values of the ML models.

Best parameter
Criterion
max_depth
max_features
min_samples_split

Bootstrap
max_depth
max_features
min_samples_leaf
min_samples_split
n_estimators

C
Degree
Gamma
Epsilon
Kernel

Decision tree

Signiﬁcant wave height Water temperature

Mae
7
Auto
4
Random forest
True
100
3
5
8
200
SVR
100
1
Auto
Default
Poly

Mae
10
Log2
Default

True
90
2
5
12
200

1
1
Default
0.2
Poly

decomposing one sample (i.e., minimum of wave height-
series of ocean marine necessary parameters). We used the
seasonaldecompose function from the statsmodels library in

the optimal conﬁguration of hyperparameter values for a
predictive model has a direct eﬀect on the models’ per-
formance and the tested dataset. While hyperparameter
tuning is a crucial step in the model training process to
ensure a successful ML application, it is a compute-in-
tensive procedure. +is is because of the large number of
possible combinations to test and the computational re-
sources required [18, 19].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The strategy implemented to monitor the model performance during training is the use of the early stopping strategy. This strategy involves separating the training data into training and validation groups. Training is then stopped when the generalization performance starts to degrade for a number of epochs. Additionally, the dropout approach was also employed to address the issue of overfitting. Dropout is a regularization technique that trains neural networks with alternate topologies in parallel by randomly dropping out a certain proportion of layer neurons.