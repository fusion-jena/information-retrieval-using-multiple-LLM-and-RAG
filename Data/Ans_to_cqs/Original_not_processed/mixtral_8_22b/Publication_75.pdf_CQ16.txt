Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(8)  

where  dim is  the dimension  of the  feature vectors,  Ft(τ) is the τth  the 
element of the feature vector of the query image t and FDBs (τ) is the τth 
element of the feature vector of the sth  image in the database DB. 

ComputersandElectronicsinAgriculture187(2021)1062696A. Loddo et al.                                                                                                                                                                                                                                  

Metrics. Four performance measures, namely average retrieval pre-
cision, ARP, average retrieval rate, ARR, Fscore  and mean average preci-
sion, mAP, have been used to compare the retrieval performances. The 
mathematical  formulation  for  each  of  these  performance  measures  is 
given as follows: 

ARP =

number of relevant images retrieved
total number of images retrieved (η)

=

100
ω

∑ω

i=1

r(DBi)
η

(9)  

ARR =

22 
30 
77 
118 
32 
24 
15 
55 
103 
160 
4  

ComputersandElectronicsinAgriculture187(2021)1062697A. Loddo et al.                                                                                                                                                                                                                                  

Table 5 
Summary of the experimentation results on the local dataset (StD is the deviation standard of Acc value and Time is the training time in minutes).  

Network 

AlexNet 
ResNet18 
ResNet50 
ResNet101 
GoogLeNet 
ShuffleNet 
SqueezeNet 
MobileNetV2 
InceptionV3 
VGG16 
SeedNet 

Acc 

93.43 
97.47 
96.46 
96.97 
95.45 
96.46 
95.96 
93.94 
96.46 
95.96 
97.47 

Spec 

91.08 
96.63 
94.44 
96.61 
95.06 
95.90 
95.75 
93.16 
95.99 
94.82 
99.88 

Sen 

91.36 
95.50 
94.98 
94.66 
93.47 
94.37 
94.71 
91.51 
94.81 
94.86 
96.81 

MAvG 

90.15 
96.11 
96.15 
96.34 
94.67 
95.57 
95.13 
92.67 
95.74 
94.22 
96.60 

MFM

5. Authors contribution 

Conceptualization, A.L. and C.D.R.; methodology, A.L. and C.D.R.; 
software, A.L. and M.L.; validation, A.L., M.L. and C.D.R.; formal anal-
ysis, A.L. and C.D.R.; investigation, A.L., M.L. and C.D.R.; resources, A. 
L.,  M.L.  and  C.D.R.;  data  curation,  A.L.,  M.L.  and  C.D.R.;  wri-
ting—original draft preparation, A.L. and C.D.R.; writing—review and 
editing, A.L., M.L. and C.D.R.; supervision, C.D.R.. All authors have read 
and agreed to the published version of the manuscript. 

6. Funding 

The  Regione  Autonoma  della  Sardegna  partially  supported  the 
research in this paper with the research project “Algorithms and Models 
for  Imaging  Science  [AMIS]”  (finanziato  con  risorse  FSC  2014–2020 
Patto per lo Sviluppo della Regione Sardegna). 

7. Abbreviations 

The following abbreviations are used in this manuscript:  

DPI 

CNN 
JPEG 
HC 
Acc 
Spe 
Sen 
MAvG 
MFM 
MAvA 
Std 
ARP 
ARR 
mAP 
SVM 
KNN 
RF 
GLCM 
AUC 
TP 
FP 
TN 
FN

3.2.2. Retrieval results 

The retrieval experiments ensued the following strategy: every image 
is used as a query image and is matched with every remaining image in 
the database. Tables 6 and 7 present the retrieval performances of all the 
networks in terms of the four considered measures by choosing the top 
100 matches, i.e. η = 100, and the two chosen similarity distances. 

3.3. Deep learning vs traditional machine learning comparison 

A comparison of deep learning approaches with traditional machine

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about the specific criteria used to determine when training is complete. However, common criteria include reaching a certain number of epochs or iterations, achieving a desired level of accuracy or loss on the validation set, or observing a plateau in the validation loss.