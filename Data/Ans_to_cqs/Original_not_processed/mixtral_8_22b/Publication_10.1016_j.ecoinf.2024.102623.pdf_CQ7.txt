Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

vancements in deep learning to enhance performance. Specifically, our 
MLP architecture consists of four layers, each containing 512 neurons 
and connected with residual connections (He et al., 2016). We employ 
batch normalization (Ioffe and Szegedy, 2015) and the Rectified Linear 
Unit (ReLU) activation function in all layers except the final one, where 
instead a sigmoid function is used to enable multi-label classification. 
The model is trained with a batch size of 256 for 30 epochs using the 
AdamW optimizer (Loshchilov and Hutter, 2017). Both the weight decay 
and learning rate are set to 0.0001. Additionally, we employ a learning 
rate scheduler with exponential decay of 0.95, and introduce dropout

determined through cross-validation, involving the partitioning of the 
training  data  and  designating  a  portion  as  the  validation  set.  The  se-
lection  of hyperparameter values, or equivalently the selection of the 
model, is then based on the performance on this validation set. However, 
constructing  an  effective  validation  set  with  presence-only  data  is 
challenging, as evaluating model performance with such data may lead 
to  choosing  a  model  that  makes  biased  predictions  (El-Gabbas  and 
Dormann, 2018). To alleviate this issue, we employ spatial block cross- 
validation  (Roberts  et  al.,  2017;  Valavi  et  al.,  2023),  which  involves 
spatially splitting the presence observations into training and validation 
sets. This approach makes it difficult for the model to perform well on 
the  validation  set,  favoring  models  capable  of  generalizing  to  unseen 
areas (Smith et al., 2021). This is particularly important since presence-

diverse datasets. This includes addressing issues such as class imbalance 
and sampling bias.

Hence, we perform k-fold block cross-validation, dividing the region 
of interest into 5 Ã— 5 geospatial blocks and assigning them to k distinct 
folds, such that each fold contains approximately the same number of 
presence  observations.  We  choose  k = 5,  resulting  in  that  for  each 
partition, the model is trained on 80% of the presences and validated on 
the remaining 20%. This procedure is equivalent to the spatial blocks 
based on rows and columns of Valavi et al. (2018), and is illustrated in 
Fig.  3.  The  model  is  then  evaluated  on  each  fold  and  the  results  are 
averaged. The model with the best performance, determined here by the 
mean AUC (Area Under the receiver operating characteristic Curve) over 
all the species, is selected. The target-group background points are used 
as pseudo-absences to compute the AUC on the validation set, similarly 
to Valavi et al. (2023). 

3.3. Model and training details

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The authors use spatial block cross-validation to divide their dataset into training and validation sets. They first divide the region of interest into 5x5 geospatial blocks and assign these blocks to five folds, ensuring each fold has roughly the same number of presence observations. For each partition, the model is trained on 80% of the presences and validated on the remaining 20%. This process is repeated for each fold, and the results are averaged. The model with the highest mean Area Under the Receiver Operating Characteristic Curve (AUC) across all species is chosen. Target-group background points are employed as pseudo-absences to calculate the AUC on the validation set.