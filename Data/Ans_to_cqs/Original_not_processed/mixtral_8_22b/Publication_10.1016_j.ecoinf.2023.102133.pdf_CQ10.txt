Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(cid:0) 3, 10

(cid:0) 4;  

The following configuration optimized the performance of the model 
and was accordingly adopted for analysis: Adam solver (Kingma and Ba, 
(cid:0) 4,  constant  learning 
2014),  10 neurons  per  hidden  layer, alpha  = 10
rate, and rectifier activation function, also called Rectified Linear Unit 
(ReLU) activation function, defined as: 

(

)

{

ReLU

k

=

k, if k > 0;
0, if k⩽0.

(14) 

In the case of the RF, the hyperparameters include the number of 
decision trees in the forest, the maximum depth of the decision tree, the 
number of features considered by each tree when splitting a node, etc. 
This  set  of  hyperparameters  was  tested  using  the  grid  configuration 
shown below:  

1.  Number of decision trees: from 100 to 1000 (in steps of 100);  
2.  Number of features to consider at every split (max features): auto,

sqrt, log2, None;  

3.  Maximum number of levels in decision tree: None, or from 10 to 100 

(in steps of 10);

M5P, BAGGING, RF, SVR 
ANN 
ENN 
RF, LSTM 
LSTM 

Mosre et al. (2021) 

LR - EFS 

Granata et al. (2020) 
Zhang et al. (2021) 
Wang et al. (2023) 
Izadifar et al. (2010) 
Hao et al. (2022) 

RF, MLP, kNN, ARDS 
RF 
RF 
ANN, GP, SAS/STAT 
BMA 

Pastures grass 
Different land cover 
Green peppers 
Corn, soybeans, potatoes 
Grassland, Forest,  
Alpine meadow 
Grassland,  
Open shrubland,  
Barren vegetation 
Sawgrass 
Grassland 
Different land cover 
Spontaneous flora 
Grassland,  
Cropland,  
Forest 

1825 
11713 
800 
6208 
300–500 

4017 

2069 
Datasets of various sizes 
Datasets of various sizes 
150 
Datasets of various sizes 

Present work (2023) 

RF, MLP 

Citrus orchard 

576 

3–6 
2–5 
10 
5–16 
4–8 

5–18 

3–7 
21 
7 
5–9 
7 

4–10 

RMSE[mmd

(cid:0) 1] 

R2 

0.18–0.40 
0.39–0.78 
0.35–0.61 
0.40–1.30 
0.21–1.06 

0.93–0.98 
0.98–0.99 
0.86–0.97 
0.42–0.70 
0.16–0.80 

0.42–1.81 

0.15–0.82 

0.42–1.06 
0.28–0.73 
0.99–2.18 
0.06–0.10 
0.32–0.67

EcologicalInformatics76(2023)10213312A. Pagano et al.                                                                                                                                                                                                                                 

Table 5 
Results and model comparison.  

Predictor 

Model name 

Nr. of input features 

Input features 

Multi Layer Perceptron (MLP) 

Random Forest (RF) 

MLP1 
MLP2 
MLP3 
MLP4 
MLP5 
MLP6 
MLP7 
MLP8 
MLP9 
MLP10 
MLP11 
MLP12 

RF1 
RF2 
RF3 
RF4 
RF5 
RF6 
RF7 
RF8 
RF9 
RF10 
RF11 
RF12 

10 
9 
8 
7 
6 
5 
4 
6 
5 
4 
5 
4 

10 
9 
8 
7 
6 
5 
4 
6 
5 
4 
5 
4

2020 

2021 

Instruments 

Variable 

Units 

Drill and Drop 
WatchDog 2000 
EC Tower 
Sentinel-2 

SWC 
ETo 
ETa 
Images 

(cid:0) 3] 
(cid:0) 1] 
(cid:0) 1] 

[cm3cm
[mm d
[mm d
[–] 

365 

355 
363 
– 

44 

365 

344 
365 
193 
75 

366 

355 
366 
120 
74 

334 

320 
333 
263 
58  

EcologicalInformatics76(2023)1021335A. Pagano et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention of any specific code repository links related to the deep learning pipeline used in this study. Therefore, I cannot provide the requested information.