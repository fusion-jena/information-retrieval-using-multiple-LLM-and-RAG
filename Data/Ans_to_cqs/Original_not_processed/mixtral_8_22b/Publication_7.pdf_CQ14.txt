Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

119,273
63,600
55,050

1,377
1,272
1,101

TABLE I: WA subset of Benthoz15 in numbers.

labels in this dataset which make it quite challenging. Table. I
details some statistics of the Western Australia (WA) subset of
this dataset. We have used a subset of this dataset containing
images from Western Australia (WA) to train our classiﬁer.
This subset consists of 4,750 images with 237,500 expert-
annotated points collected over a span of 3 years (2011 to
2013).

B. Pre-processing

We applied color channel stretch on each image in the
dataset. We calculated the 1% and 99% intensity percentiles
for each color channel. The lower intensity was subtracted
from all the intensities in each respective channel and the
negative values were set to zero. These intensities were then
divided by the upper percentile. The resulting intensities
achieved a better performance compared to the original ones.

C. Classiﬁcation Experiments and Results

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

978-1-5090-1537-5/16/$31.00 ©2016 IEEEA. Classiﬁcation Process

Image representations extracted from deep neural networks,
trained on large datasets such as ImageNet [9] and ﬁne tuned
on domain speciﬁc datasets, have shown state-of-art perfor-
mance in numerous image classiﬁcation problems [14]. The
activation vectors of the ﬁrst fully connected layer of a pre-
trained VGGnet [24] are employed as feature representations
in our work. The weights of this deep network are ﬁne tuned
using the Benthoz15 dataset [23] which consists of expert-
annotated and geo-referenced marine images from Australian
seas.

C. Classiﬁcation Experiments and Results

Selecting patch sizes that give the best classiﬁcation ac-
curacy is an important step. We trained our classiﬁer using
multiple patches at different scales and achieved the best
performance when these three patch sizes were used: 28 × 28,
224 × 224, and 448 × 448. These correspond to small, medium
and large scales. Feature extraction at different sizes insures an
efﬁcient encoding of coral species independently of their size.

28x28

224x
224

448x
448

l

a
i
t
a
p
S

i

d
m
a
r
y
P

t
e
n
G
G
V

g
n

i
l

o
o
p
-
x
a
M

P
L
M

r
e
y
a
L
2

Coral

Non-
Coral

Fig. 3: Block diagram of the proposed classiﬁcation method.

We conducted three experiments to evaluate our classiﬁer:
(i) the classiﬁer was trained on two-thirds of the images from
the year 2011 and tested on the remaining images from the
same year,
(ii) the images from year 2011 were used for
training and the images from 2012 and 2013 constitute the
test set, (iii) the training set consisted of two-thirds of the
images from the years 2011, 2012 and 2013, whereas the test
set consists of all the remaining images from the same years.
Table. II shows the details and reports the preliminary results

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

 
 
 
Experiment

# of Training Samples

# of Test Samples

Accuracy

Exp 1: Train and test
on 2011
Exp 2: Train on 2011 and
test on 2012 and 2013
Exp 3: Train and test on
2011,2012 and 2013

108,000

108,000

157,173

53,000

130,000

80,750

97.00%

92.45%

95.33%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about how the hyperparameters of the model are optimized. Therefore, we cannot determine if they used methods like grid search or random search.

Based on the given context, there is no mention of any specific optimization techniques used for selecting the optimal hyperparameters for the model. It only discusses the process of fine-tuning the weights of a pre-trained VGGnet using the Benthoz15 dataset and extracting activation vectors from the first fully connected layer as feature representations. Additionally, it mentions the selection of patch sizes for achieving the best classification accuracy but does not specify the methodology behind choosing those particular patch sizes.