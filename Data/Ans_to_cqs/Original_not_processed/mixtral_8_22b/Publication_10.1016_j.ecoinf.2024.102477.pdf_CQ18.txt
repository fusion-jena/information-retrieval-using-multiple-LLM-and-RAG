Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

SVR is a machine learning method known for its superior accuracy 
compared  with  other  machine  learning  methods  and  its  ability  to 
simplify parameters, achieve global optimization, and handle nonlinear 
problems  (Chen  et  al., 2017;  Ji et  al.,  2021). In  this  study, the  expo-
(cid:0) 8–21,  σ  =
nential  parameters  were  set  as  follows:  C  = 20–210,  ε  = 2
(cid:0) 8–21 (Yang et al., 2022). Table 2 presents the training results for the 
2
hyperparameter-optimized  SVR  model.  Parameter  C  controls  error 
tolerance during training and determines the maximum deviation that 
the model permits for any individual training example. A higher C value 
allows for a larger error, which makes the model more likely to fit the 
training  data  but  also  increases  the  risk  of  overfitting.  Conversely,  a 
smaller  C  value  imposes  stricter  constraints  on  the  model,  thereby 
increasing  the  difficultly  of  fitting  the  training  data  but  potentially

regularization parameter used to control model complexity and prevent 
overfitting  by  constraining  the  loss  function  during  training.  The 
parameter ε  controls the model's fault tolerance, that is, the degree of 
tolerance for differences between predicted and actual values of training 
samples. The term σ represents a parameter of a Gaussian kernel or the 
width parameter of a radial basis function kernel. This parameter con-
trols the relationship between support vectors and hyperplanes and af-
fects model complexity and generalization ability. SVR is formulated as 
follows: 

f (x) = ωT φ(x) + b

R =

1
2

‖ω‖2 + C

)

ξi + ξ*
i

∑N
(cid:0)

i=1

(5)  

(6)  

where ω is a weight vector, φ(x), b is a bias term, C is the regularization 
constant, and ξi and ξ*
i  are slack variables that quantify how far data can 
exist from the ε tube. 

3.4. Deep learning 

3.4.1. SLSTM method

concentration of atmospheric CO. This model was compared with four 
statistical  models  (ARIMA,  SARIMA,  ETS,  and  HWETS),  one  machine 
learning model (SVR), and one deep learning model (SLSTM) in terms of 
its predictive performance. Model performance was evaluated using the 
MAPE and RMSE metrics. Table 3 presents the average values of these 
metrics for the aforementioned models. The MAPE values of the SGRU 
model were lower than those of the ARIMA, SARIMA, ETS, HWETS, SVR, 
and SLSTM models by 67.60%, 55.98%, 79.85%, 55.72%, 42.43%, and 
20.44%,  respectively,  indicating  that  the  accuracy  of  prediction  was 
significantly higher for the SGRU model than for the other models. As 
presented in Fig. 2, the CO values predicted by the SGRU model were 
close to the actual values. Fig. 3 shows scatter plots of the actual CO 
values and those predicted by the ARIMA, SARIMA, ETS, HWETS, SVR, 
SLSTM, and SGRU models. Compared with the other models, the deep

Oper. Res. 9, 673–685. 

Chen, J., Chen, H., Huo, Y., Gao, W., 2017. Application of SVR models in stock index 
forecast based on different parameter search methods. Open J. Stat. 7, 194. 

Chen, J., Jing, H., Chang, Y., Liu, Q., 2019. Gated recurrent unit based recurrent neural 
network for remaining useful life prediction of nonlinear deterioration process. 
Reliab. Eng. Syst. Saf. 185, 372–382. 

Chen, J., Chen, K., Ding, C., Wang, G., Liu, Q., Liu, X., 2020. An adaptive Kalman filtering 

approach to sensing and predicting air quality index values. IEEE Access 8, 
4265–4272. 

Chen, H., Zhang, Y., Cao, Y., Xie, J., 2021. Security issues and defensive approaches in 

deep learning frameworks. Tsinghua Sci. Technol. 26, 894–905. 

Choi, K., Yi, J., Park, C., Yoon, S., 2021. Deep learning for anomaly detection in time- 
series data: review, analysis, and guidelines. IEEE Access 9, 120043–120065.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The strategy implemented to monitor the model performance during training involves setting specific exponential parameters such as C and ε. These parameters play crucial roles in controlling error tolerance during training and determining the maximum deviation that the model permits for any individual training example. For instance, a higher C value allows for a larger error, making the model more likely to fit the training data but also increasing the risk of overfitting. On the contrary, a smaller C value imposes stricter constraints on the model, thereby increasing the difficulty of fitting the training data but potentially preventing overfitting. Additionally, the parameter ε controls the model's fault tolerance, i.e., the degree of tolerance for differences between predicted and actual values of training samples. Furthermore, the term σ represents a parameter of a Gaussian kernel or the width parameter of a radial basis function kernel, affecting model complexity and generalization ability. Overall, these strategies help ensure optimal model performance during training while minimizing potential errors and overfitting.