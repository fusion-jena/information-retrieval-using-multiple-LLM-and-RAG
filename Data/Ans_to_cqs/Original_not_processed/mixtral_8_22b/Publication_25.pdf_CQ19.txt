Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

combined with labeled data in a semi-supervised framework (sensu [14]), which may improve deep
learning on limited training data by providing neural networks the opportunity to learn generalized
features on a wider array of training examples, followed by retraining on a smaller number of high
quality annotations [16]. It is unknown whether moderate to low quality annotations can be used
to generate trees for initial model training, given the imperfect nature of existing unsupervised tree
delimitation approaches.

The challenge for applying deep learning to natural systems is the need for large training datasets.
A lack of training data is a pervasive problem in remote sensing due to the cost of data collection
and annotation [13]. In addition, the spatial extent of training data often prohibits the ﬁeld-based
veriﬁcation of annotated objects. For tree detection, the high variation in tree crown appearance, due
to taxonomy, health status, and human management, increases the risk of overﬁtting when using small
amounts of training data [10]. One approach to addressing the data limitation in deep learning is
“self-supervised learning” (sensus [14]), which uses unsupervised methods to generate training data
that is used to train supervised models [15]. This approach has recently been applied to remote sensing
for hyperspectral image classiﬁcation [9]. Self-supervision, which only relies on unlabeled data, can be

Remote Sens. 2019, 11, 1309

3 of 13

of thousands of noisy labels will yield improved performance, even though these labeled data are
imperfect due to the limitations of the generative algorithm [17].

Figure 1. A conceptual ﬁgure of the proposed semi-supervised pipeline. A Light Detection and
Ranging (LIDAR)-based unsupervised detection generates initial training data for a self-supervised
(red, green, blue (RGB) deep learning model. The model is then retrained based on a small number of
hand-annotated trees to create the full model.

2.1. Study Site and Field Data

We used data from the National Ecological Observatory Network (NEON) site at the San Joaquin
Experimental Range in California to assess our proposed approach (Figure 2). The site contains an open
woodland of live oak (Quercus agrifolia), blue oak (Quercus douglasii), and foothill pine (Pinus sabiniana)
forest. The majority of the site is a single-story canopy with mixed understory of herbaceous vegetation.

6 of 13

for learning both bounding boxes and image classes. Retinanet diﬀers from other object detection
frameworks, such as RCNN, by combining object detection and classiﬁcation into a single network.
This allows for faster training and it decreases the sensitivity to the number of box proposals among
the images [25]. We used a resnet-50 classiﬁcation backbone that was pretrained on the ImageNet
dataset [27]. We experimented with deeper architectures (resnet-101 and resnet-152), but found no
improvement where oﬀset increased the training time.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention which specific deep learning frameworks were used to build the deep learning model. However, it mentions that RetinaNet was used as the object detection framework, which combines object detection and classification into a single network. RetinaNet is compatible with popular deep learning libraries like TensorFlow and PyTorch, but without explicit information, we cannot definitively state which one was used in this case.