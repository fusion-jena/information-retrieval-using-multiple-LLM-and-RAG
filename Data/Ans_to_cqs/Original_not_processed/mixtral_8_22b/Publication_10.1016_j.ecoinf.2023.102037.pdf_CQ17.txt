Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ofmineervlieg/. Accessed: 1 June 2022.  

Wang, R.J., et al., 2017. A crop pests image classification algorithm based on deep 

convolutional neural network. Telkomnika (Telecommun. Comput. Electron. Contr.) 
15 (3), 1239–1246. Available at: 10.12928/TELKOMNIKA.v15i3.5382. 

Wang, C.Y., et al., 2020a. CSPNet: A new backbone that can enhance learning capability 
of CNN. In: IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition Workshops, 2020-June, pp. 1571–1580. Available at: https://doi.org/ 
10.1109/CVPRW50498.2020.00203. 

Wang, J., et al., 2020b. Common pests image recognition based on deep convolutional 

neural network. Comput. Electron. Agric. 179 (June), 105834. Available at: https 
://doi.org/10.1016/j.compag.2020.105834.

ayanan, 2022). In our previous research (Kalfas et al., 2021; Kalfas et al., 
2022), we showed that model performance can be highly overestimated 
when weak validation procedures – like random data splitting- are fol-
lowed.  Despite  taking  the  above  limitations  into  consideration,  other 
studies  still  only  focused  on  datasets  where  insect  classes  were  quite 
broad – insect order or family level, quite dissimilar and thus, relatively 
easy to classify (Rustia et al., 2021b; Wang et al., 2020c).

From a model-centric view misclassifications are often explained by 
the model complexity, its hyperparameters and the training procedure 
efficiency.  Hence,  many  researchers  employ  a  variety  of  models  and 
training  procedure  optimizations  until  they  find  the  “best”  result. 
Moreover, as we have already shown in our previous research (Kalfas 
et al., 2021; Kalfas et al., 2022), several studies on insect recognition 
don’t  apply  any  strict  validation  procedure  to  evaluate  their  models, 
which often leads to over-optimistic or unrealistic performance. 

From a data-centric approach, wrong detections are assumed to be 
caused by either intra- or inter-class variability (Fig. 2 and Fig. 3), class 
imbalance (Fig. 4) or labelling errors. 

2.2. Imaging setup

• Aperture: F/10  
• ISO: 160  
• Shutter speed: 1/15 s  
• Focal Length: 55 mm  
• White balance: “Incandescent” 

2.3. Data splitting and image tiling

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers referenced do not explicitly mention specific regularization methods used to prevent overfitting in the deep learning pipelines. However, it is common practice in deep learning to use various techniques such as dropout and L2 regularization to mitigate overfitting. Dropout is a technique where randomly selected neurons are ignored during training, which helps prevent complex co-adaptations on training data. On the other hand, L2 regularization adds a penalty term to the loss function, discouraging large weights and promoting simpler models. Other popular regularization methods include early stopping, weight decay, and batch normalization. It should also be noted that proper dataset preparation, including appropriate data augmentation and balancing, contributes significantly to preventing overfitting.