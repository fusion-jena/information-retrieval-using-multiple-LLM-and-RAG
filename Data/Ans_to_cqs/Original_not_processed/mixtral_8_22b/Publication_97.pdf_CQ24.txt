Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Remote Sens. 2020, 12, 1145

6 of 17

Training data were generated as batches of size (m, 256, 256, 3), where m is the batch size (m =
20 in our experiments). The batches consisted of sub-images of size 256 × 256 that were randomly
cropped out from the original satellite images presented in Table 1. We had a stream (internally, a
Python generator) of almost never repeated sub-images; these sub-images were combined into batches
and used for the neural network training. Satellite images for sites #1, #3, #5, #7–10 were used for
training and #2, #4, #6 for validation. Corresponding batches of mask data had shape (20, 256, 256, 1).
The network training assessment was performed on sub-images generated from image #2 (Table 1).
Images #4 and #6 were used for visualization and demonstration of the algorithm eﬃcacy.

case for further investigations for the appliance of deep learning approaches in vegetation science.

science and forestry, the deep learning approach has high potential and is only at the beginning of its
development [37,38]. In the case of the problem in recognition of forest disturbances, there are only a
few works discovering peculiarities of solving problems using deep learning methods [39–41].

58. Yu, L.C.; Sung, W.K. Understanding geometry of encoder-decoder CNNs. arXiv 2019, arXiv:1901.07647v2.
Ioﬀe, S.; Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate
59.
shift. arXiv 2015, arXiv:1502.03167v3.
Srivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; Salakhutdinov, R. Dropout: A simple way to prevent
neural networks from overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958.

60.

61. Evaluation of the CNN Design Choices Performance on ImageNet-2012. Available online: https://github.

com/ducha-aiki/caﬀenet-benchmark (accessed on 24 March 2020).

62. Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G.S.; Davis, A.; Dean, J.;
Devin, M.; et al. TensorFlow: Large-scale machine learning on heterogeneous systems. arXiv 2016,
arXiv:1603.04467v2.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the authors employ several strategies to handle randomness in their deep learning pipeline. One such strategy is the use of random cropping of sub-images from the original satellite images during the generation of training data. This technique introduces variability in the input data, which can help improve the model's ability to generalize to new, unseen data. Additionally, the authors mention using a Python generator to create a stream of almost never repeated sub-images, which also contributes to introducing randomness in the training process.

Regarding handling randomness related to the initialization of weights or other parameters in the deep learning models, the authors do not explicitly discuss this aspect in the provided context. However, common practices in the field include setting a fixed random seed value before running any code involving random processes, such as weight initialization or data shuffling. This ensures reproducibility of results across different runs of the same experiment. Another popular method to reduce the impact of random initializations is to perform multiple runs with different seeds and average the results.

Furthermore, techniques like dropout regularization, mentioned in reference [59], can be used to mitigate the effects of randomness in the training process. Dropout involves randomly dropping out neurons during training, which helps prevent overfitting and improves the model's performance on unseen data. Lastly, batch normalization, discussed in reference [58], is another technique that can help stabilize the learning process by normalizing layer inputs and reducing internal covariate shift.