Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.2. Process flow 

This study has two perspectives, model training and development on 
a high-end computer, and the model deployment to an edge device, as 
shown in Fig. 3. The training dataset could be pre-processed, such as 
denoising,  contrast  enhancement,  and  image  resizing.  We  only  used 
image re-sizing to make the images suitable for the input image reso-
lution required for the selected models. 

After a model has been trained, it needs to be validated and tested to 
confirm that it has achieved the desired performance. The performance 
might  be  measured  using  different  metrics,  such  as  classification 

Table 2 
The class distribution in the Extinction dataset.  

Class 

Number of images

3.5. Hyperparameter optimization 

The model training process determines the values for the trainable 
parameters  of  a  model,  e.g.,  Table  4 shows  the  size  of  the  model pa-
rameters. In addition, a DNN model also has other parameters that need 
to be selected, e.g., batch size, that determines the model performance. 
The  model  parameters  define  the  model  and  are  termed  as  hyper-
parameters. Each hyperparameter has a range of values, from which an 
optimum  selection  can  improve  the  model  performance.  The  model 
hyperparameters could be in hundreds, presenting a very large search 
space, but these differ in their relative importance. The common ones for 
a DNN are learning rate, batch size, and dropout.

5.3. Study uncertainties and limitations 

The model evaluation was performed on two datasets which are in 
comparison  much  smaller  to  the  ImageNet  dataset  used  for  the  pre- 
trained  models.  Hence  the  proposed  techniques  of  fine  tuning  have 
not been applied to the large datasets. However, the general rules pro-
vided  in  section  3.3  for  selecting  a  particular  transfer  learning  (just 
replacing the classification head vs. fine-tuning by training few or all 
layers) can guide the implementation choice. The selection of an opti-
mum model however  would  also  be governed by  experimentation, to 
resolve uncertainty in the process.

further model performance improvement, some or all the layers in the 
pre-trained model can be re-trained. Therefore, there is a need for some 
adaptation  of  a  pre-trained  model  to  achieve  better  performance,  as 
described in the sections 3.3.2 and 3.3.3.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: After a model has been trained, it needs to be validated and tested to confirm that it has achieved the desired performance. The performance might be measured using different metrics, such as classification accuracy, precision, recall, F1 score, etc. These metrics help evaluate how well the model performs on unseen data. A confusion matrix can also be generated to visualize the performance of the model. It provides information about actual and predicted classifications done by a classification system. Additionally, saliency maps can be used to understand what parts of the input data were most important for the model's predictions. This can provide insights into the decision-making process of the model.