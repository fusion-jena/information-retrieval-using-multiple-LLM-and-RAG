Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Hyperparameter optimisation 

Hyperparameter  optimization  searches  for  the  best  set  of  hyper-
parameters  for  a  machine  learning  model  that  can  perform  best  on  a 
given  task.  In  many  packages,  random  or  grid  search  is  the  default 
method  for  selecting  optimal  hyperparameters  (Snoek  et  al.,  2012). 
There are many studies on the selections of optimization algorithms for 
theoretical  problems  or  engineering  applications,  in  which  various 
versions  of  Bayesian  optimizers  and  Swarm-based  algorithms  were 
compared (Stenger et al., 2019; Stenger and Dirk, 2022).

The training dataset, including 268 sample plots with 39 features in a 
tabulated format, was used as input during the training process (opti-
mizing  hyper-parameters  and  fitting  models  with  these  data).  The 
training data set was divided into two parts, in which 80% was used for 
training/validation, and the remaining 20% was kept as unseen data for 
testing. To eliminate bias, 10-fold cross-validation was used during the 
training  process,  and  mean  RMSE  was  used  as  the  objective  function 
(lost function). Table 4 shows RMSE, MAE, and R2  using different op-
timizers. In addition, we tested the differences between the RMSEs in 
Table 4 using the Wilcoxon Signed-Rank test with paired samples. The 
differences between (XGBoost-BO vs. XGBoost-TDO, XGBoost-BOHB vs. 
XGBoost-TDO) or (LightGBM-BO vs. LightGBM-TDO, LightGBM-BOHB 
vs.  LightGBM-TDO)  are  significant.  However,  the  performance  of 
XGBoost-TDO  versus  LightGBM-TDO  appears  to  be  the  same (Fig.  3),

Parameter to control 

minimum loss reduction 
Amount of weight required 
for a tree to produce a 
child 

Parameter to control the 

step size at each iteration 

Maximum-depth trees can 

grow 

number of boosting 

iterations 

Minimal number of data in 

one leaf.  

‘reg_alpha’: (0.0, 0.1), 

‘lambda_l1’: (0.0, 0.1), 

‘reg_lambda’: (0.0, 0.1), 

‘lambda_l2’: (0.0, 0.1), 

‘num_leaves’: (25, 5000), 

“gamma”: (0,10)  

‘min_child_weight’: 
(1,10), 

‘min_child_samples’: (50, 
10,000), 

Learning_rate: (0, 0.1) 

Learning_rate: (0, 0.1) 

‘max_depth’: (5, 50), 

‘max_depth’: (5, 50), 

‘num_boost_round’: 
(100,2000), 

‘num_boost_round’: (100, 
2000), 
‘min_data_in_leaf’: (100, 
2000), 

Random seed for bagging 

“seed”: (0,200),   

performance comparisons. 

3. Results and discussions 

3.1. AGB estimation

As  machine  learning  models  have  been  increasingly  deployed  in 
critical applications, there may be a growing demand for interpretable 
and explainable hyperparameter optimization techniques. Methods that 
provide transparency and explainability in the hyperparameter tuning 
process  could  gain  importance  to  ensure  fairness,  accountability,  and 
transparency in developing machine learning models. Machine learning 
algorithms are considered robust classification and regression methods 
in which models are trained and learned from input data to improve the 
prediction of unseen data. However, the internal process is not under-
standable, as  it is  considered a  black-box stage. To  better understand 
interactions  between  features,  we  evaluated  several  performance  in-
dicators,  such  as  feature  importance,  feature  interactions,  and  contri-
butions of all features. The Shapley values provide a way to distribute

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, while specific regularization methods used in the deep learning pipeline are not explicitly mentioned, some hyperparameters related to regularization can be identified. Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function, discouraging complex models.

Two types of regularization methods are implicitly referenced in the context: L1 regularization and L2 regularization. These are also known as Lasso and Ridge regularizations, respectively. L1 regularization adds an absolute value of the magnitude of coefficients as penalty to the loss function, whereas L2 regularization adds the squared magnitude of coefficients.

In the context,'reg_alpha', 'lambda_l1','reg_lambda', and 'lambda_l2' are hyperparameters associated with regularization. Specifically,'reg_alpha' and'reg_lambda' correspond to L1 and L2 regularization terms, respectively. Similarly, 'lambda_l1' and 'lambda_l2' represent the weights assigned to the L1 and L2 regularization terms, controlling their influence on the overall loss function.

However, other common regularization methods like Dropout and Early Stopping are not directly discussed in the provided context. Dropout randomly sets a fraction rate of input units to 0 at each update during training time, helping to prevent overfitting. On the other hand, Early Stopping monitors the validation error and stops training when the error starts increasing, indicating that the model might be starting to overfit.