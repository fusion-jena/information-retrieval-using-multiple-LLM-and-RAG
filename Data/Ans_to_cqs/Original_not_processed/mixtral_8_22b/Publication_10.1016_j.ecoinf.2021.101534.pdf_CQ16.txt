Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.2. Training and validation dataset 

The recordings for training were obtained from the Macaulay Library 
and  xeno-canto.  They  were  labeled  by  experts  on  the  sound-labeling 
platform  of  the  SILIC  and  transformed  to  3-s  spectrogram  clips 
following the steps mentioned in the section 2.4.1. To avoid an imbal-
anced dataset, we randomly selected 11 labels (20% of the labels for the 
class with the fewest labels) for each class for the validation and used the 
rest for training. To ensure the independence of the validation dataset 
from the training dataset, no labels from the same recording were used 
in both datasets. In total, we prepared 720 labels from 92 recordings for 
training and 66 labels from 21 recordings for validation (Appendix S2: 
Table S1). 

3.3. Soundscape recordings

4. Results 

4.1. Data preparation and model training 

We spent around one hour to label training and validation data for 
each  of  the  six  classes  on  our  sound-labeling  platform  and  about  six 
hours for initial model training. The validation loss of the model reached 
a plateau at the 42nd epoch, and the parameters were saved for infer-
ence.  It  took  around  68  h  to  apply  the  trained  model  on  the  4128-h 
soundscape  recordings  obtained  from  the  five  PAM  sites,  and  the 
model identified 459,518 inferred sounds with a confidence score larger 
than  or  equal  to  0.10.  As  the  test  dataset,  we  sampled  4748  inferred 
sounds, with 739â€“819 for each class. After the manual review of the test 
dataset,  we  obtained  2201  ground-truth  positives  and  2547  ground- 
truth negatives for testing the model.

whole image. Thus, it may minimize the dilution effect and reduce the 
required amount of training data.

curves for each class to examine the class-specific performance and its 
changes with threshold scores (see Appendix S3). All the metrics were 
calculated using the scikit-learn package (https://scikit-learn.org/). 

owlet  S-01  to  0.91  for  the  northern  boobook  S-01.  Except  for  the 
northern  boobook  S-01,  whose  AP  value  was  0.49,  the  AP  values  for 
other classes were between 0.76 and 0.96 (Table 1). 

3.5. Reinforcement model

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer:::
The training process is considered complete when the validation loss of the model reaches a plateau. In this case, the validation loss reached a plateau at the 42nd epoch, indicating that further training would not significantly improve the model's performance. At this point, the model's parameters were saved for inference.
Answer:::