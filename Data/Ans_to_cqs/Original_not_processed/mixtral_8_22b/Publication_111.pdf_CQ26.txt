Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Data CollectionPre-Processing&ConstructionLagHyperparam- OptiDatapreprocessingHyperparametertuningTraining &ValidationModelValidationModelpredection &deploymentModeltrainingKOREA HYDROGRAPHIC ANDOCEANOGRAPHIC AGENCY 8483, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8551167 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [28/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseComputational Intelligence and Neuroscience

7

Figure 3: Stacked GRU-DNN model.

Table 1: +e search space of the GRU-DNN model hyperparameters.

Hyperparameters
No. of GRU cells
No. of FC layers
No. of FC layers’ units
Hidden layers activation
Batch size
Droupout rate of FC layers

Value
[4, 8, 16]
[1, 2]
[4, 8, 16]
[Relu, Linear]
[4, 8, 16]
[0.0, 0.1, 0.2]

Practically, over/underﬁtting diﬃculties in neural net-
work models are caused by the neural network model’s
excessive/insuﬃcient training epochs [43]. As a result, one
possible solution to the DL-based model’s over/underﬁtting
concerns is to apply the early stopping strategy [44], which is
used to cease training when generalisation performance
starts to degrade for a number of epochs. To track the
generalisation performance,
in the proposed model, the
training data is separated into training and validation
groups.

+e dropout approach [45] is another way to deal with
the overﬁtting problem. Dropout is a regularisation strategy
that allows you to train neural networks with alternative
topologies in parallel by randomly dropping out a certain
proportion of layer neurons. Dropout is indicated by the
black neurons in the fully connected layers, as seen in
Figure 3.

13

[45] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and
R. Salakhutdinov, “Dropout: a simple way to prevent neural
networks from overﬁtting,” Ee Journal of Machine Learning
Research, vol. 15, pp. 1929–1958, 2014.

[46] D. P. Kingma and J. Ba, “Adam: a method for stochastic

optimization,” 2014, https://arxiv.org/abs/1412.6980.

[47] J. Bergstra, D. Yamins, and D. D. Cox, “Hyperopt: a python
library for optimizing the hyperparameters of machine
learning algorithms,” in Proceedings of the 12th Python in
Science Conference, p. 20, Austin, TX, USA, 2013.

[48] M. Abadi, P. Barham, J. Chen et al., “Tensorﬂow: a system for
large-scale machine learning,” in Proceedings of the 12th
${$USENIX$}$ Symposium on Operating Systems Design and
Implementation (${$OSDI$}$ 16), pp. 265–283, Savannah,
GA, USA, November 2016.

deep learning, and machine learning models for predicting the SSTand SWH on a real dataset obtained from the Korea Hydrographic
and Oceanographic Agency. +en, we proposed comparing these three predictive approaches on four diﬀerent evaluation metrics.
Experimental results have revealed that the deep learning model slightly outperformed the machine learning models for overall
performance, and both of these approaches greatly outperformed the statistical predictive model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it mentions two methods used to tackle overfitting concerns in the proposed deep learning model: early stopping strategy and dropout approach. The early stopping strategy involves separating the training data into training and validation groups to monitor the generalization performance. On the other hand, the dropout approach is a regularization technique that trains neural networks with alternate topologies in parallel by randomly dropping out a certain proportion of layer neurons. These methods help improve the model's ability to generalize better and avoid overfitting but do not directly address data bias issues.