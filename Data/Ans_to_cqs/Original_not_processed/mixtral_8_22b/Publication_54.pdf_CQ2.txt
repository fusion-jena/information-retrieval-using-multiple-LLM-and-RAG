Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

102976

VOLUME 9, 2021

Y.-P. Huang, H. Basanta: Recognition of Endemic Bird Species Using Deep Learning Models

IV. EXPERIMENTAL SETTINGS
To extract the relevant features of birds, we randomly split
the endemic bird data into 3,132 images for training and
760 images for testing. To allow the deep networks to con-
verge and improve the ability of the model to generalize
adeptly, we augmented the training dataset 10 times, resulting
in a total of 31,320 images. Then, 25,056 (80%) images were
used for training and 6,264 (20%) were used for validation.
The Inception-ResNet-v2 model was trained using the mini-
batch gradient descent algorithm with the batch size set to
32 and the learning rate maintained at 0.0001. The Adam
optimizer was used to ﬁne-tune the model with the following
parameters:

• Exponential decay rate of ﬁrst-moment estimation

of 0.9.

The structure of this paper is organized as follows.
Section II describes data acquisition and preprocessing of
acquired dataset to overcome imbalanced and data overﬁt-
ting. Section III focuses on the deep learning models and
enhancement of ﬁne grained feature extraction accuracy by
swapping the misclassiﬁed data between the training and
validation datasets. Section IV illustrates the experimental
setting and the hardware requirements. Section V endorses
the proof of concept and validation of the purposed method-
ology. Section VI emphasizes the signiﬁcances of endemic
birds and its habitation. Finally, Section VII summarizes the
impact of the purposed model and presents directions for
future study.

The following procedures are used in the approach devel-

oped in this study.

102978

VOLUME 9, 2021

Y.-P. Huang, H. Basanta: Recognition of Endemic Bird Species Using Deep Learning Models

the holdout validation dataset. The presented work was imple-
mented using the TensorFlow libraries on a GPU workstation
with an Intel Xeon 8 CPU, 32 GB of memory, and an Nvidia
GeForce 11 GB GRX 2080 Ti graphics card.

V. PROOF OF CONCEPT
In this experiment, 760 images, which were excluded from
the training and validation datasets, were used for testing.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it can be inferred that the data format used in the deep learning pipeline is images. This is evident from several statements throughout the text, such as "randomly split the endemic bird data into 3,132 images," "augmented the training dataset 10 times, resulting in a total of 31,320 images," and "760 images...were used for testing." These references clearly indicate that the input data for the deep learning models consists of images. Therefore, the data format used in the deep learning pipeline is images.