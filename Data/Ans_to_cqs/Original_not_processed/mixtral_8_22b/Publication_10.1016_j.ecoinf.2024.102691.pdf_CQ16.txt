Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

was analysed using various evaluation matrices. During model training, 
the input image size was set to 512 × 512 and the maximum batch size 
was limited to 4. To prevent underfitting, all models were ensured to 
follow back-propagation after accumulating the batch size 32 times. The 
models were trained using a stochastic gradient descent (SGD) optimizer 
with an initial learning rate of 0.01 and a cycle learning rate of 0.2, with 

EcologicalInformatics82(2024)1026917S. Kaukab et al.

3.2. Model evaluation 

Matrices  such  as  precision,  recall,  and  average  precision  (AP)  at 
various Intersections Over Union (IoU) thresholds were used to evaluate 
the performance of the models using Eqs. (4–6). The AP0.5, indicating 
average precision at 50% IoU, provided a more balanced reflection of 
the global detection performance of the model. The evaluation metrics 
for each model on the validation set were calculated after 300 epochs. 

Precision(P) =

True Positive
True Positive + False Positive

Recall(R) =

True Positive
True Positive + False Negative

Average Precision(AP) =

∫

x=1

x=0

Precision(Recall)d(Recall)

3.3. Performance on the test data 

(4)  

(5)  

(6)

learning rate decay occurring after specific iterations. A total of 1000 
sets of aligned RGB images and depth images were manually labelled 
and divided into training (80% images), validation (10% images), and 
test sets (10% images). Data augmentation techniques such as scaling, 
panning, rotation, colour transformation, and mosaic were employed to 
increase  the  number of  training samples and  improve  model general-
ization ability. Pretrained weights were loaded to evaluate their impact 
on detection results. Models were trained for 300 epochs and evaluated 
on the validation set after each epoch. 

A computer system running on a Windows 10 64-bit system with an 
Intel i7 eight-core CPU (3.0 GHz), an Nvidia RTX 2060 12 GB Graphics 
Processing Unit (GPU) (2176 CUDA cores), and 8 GB of memory were 
used during the study. Further, CUDA 8.1, CUDNN 7.5, Python 3.8, and 
Microsoft Visual Studio 9.0 software were utilized to attain the aim of 
this study. 

3.2. Model evaluation

E 

0.931 
0.910 
0.919 
0.915 
39 

Note: The abbreviations denote: A (baseline detector-1); B (baseline detector-2); 
C (baseline detector-3); D (NBR-DF-YOLOv5); and E (NT-FFN).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly state the criteria used to determine when training is complete. However, it can be inferred from the information given that the models were trained for a fixed number of epochs (300) and then evaluated on the validation set after each epoch. This suggests that the completion of training may have been determined by reaching this predefined number of epochs rather than by observing a validation loss plateau or other similar metric.