Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

threshold during training for 3000 iterations. At the end of the training process, the best
performing model based on the validation loss was saved and used as the Faster R-CNN
model with a NMS threshold of 0.7 during testing.

as a feature [13]. As the study showed, they require a large training sample to maintain a
good performance of their approach.

0.0232

extent
ﬁlled_area
major_axis_length
minor_axis_length
perimeter
solidity
diameter
aspect_ratio
rectangularity
compactness
circularity
narrow_factor
per_dia_ratio
per_length_ratio
per_length_
width_ratio

MAE

Faster
R-CNN

0.0123
461.2895
2.8865
1.4556
21.1247
0.0077
1.6507
0.0330
0.0035
1.0373
0.0289
0.0049
0.0986
0.0637

0.0415

Table 9. Cont.

MSE

YOLOv5s

0.0174
1300.0921
5.6320
3.3250
33.1226
0.0081
3.9047
0.0288
0.0046
1.2096
0.0352
0.0045
0.1163
0.0768

0.0507

Proposed
Method

0.0002
164,526.7895
6.1220
1.5845
258.5453
0.0000
1.9746
0.0008
0.0000
0.6377
0.0007
0.0000
0.0062
0.0021

Faster R-CNN

YOLOv5s

0.0003
383,162.7632
40.6365
6.0962
1608.1119
0.0005
5.6350
0.0080
0.0002
5.2750
0.0025
0.0001
0.0410
0.0212

0.0005
27,113,134.6711
349.0719
130.0219
4932.9094
0.0004
205.8782
0.0042
0.0002
4.9619
0.0027
0.0001
0.0402
0.0218

0.0011

0.0075

0.0078

Proposed
Method

0.0143
405.6190
2.4743
1.2588
16.0793
0.0068
1.4052
0.0288
0.0030
0.7985
0.0258
0.0052
0.0787
0.0463

9 of 23

Table 1. Dataset summary used for training the single-leaf classiﬁer.

Datasets

UBDH dataset
Flavia dataset

Total

Single Leaves
(Positive Samples)

Non-Single Leaves
(Negative Samples)

798
83

881

1015
0

1015

Figure 4. Negative samples manually extracted from the segmentation model results for training the single-leaf classiﬁer.
The dataset consisted of 881 intact individual leaves as positive training samples and 1015 negative samples.

4.2. Pre-Processing and Training of Semantic Segmentation Model

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not explicitly state the specific criteria used to determine when training is completed. However, it mentions that the best performing model based on the validation loss was saved after 3000 iterations. This suggests that the training might have been stopped once the validation loss reached its minimum or started to increase again, indicating overfitting. Therefore, one possible criterion could be reaching a validation loss plateau or observing signs of overfitting. Another possibility is simply stopping the training after a fixed number of iterations, such as 3000 iterations in this case. Without further information, we cannot definitively confirm which criteria were used.