Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics78(2023)1023346H. Gong et al.                                                                                                                                                                                                                                    

Table 1 
Machine configuration information table.  

Projects 

Content 

Central Processing Unit 
Memory 
Video card 
Operating System 
CUDA 
Data Processing 

Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz 
32G 
NVIDIA GeForce GTX TITAN Xp 
Ubuntu 5.4.0-6ubuntu1 ~ 16.04.5 
Cuda8.0 with cudnn 
python2.7, OpenCV, TensorFlow  

12. Experimental parameter settings

∑C

j=1,j∕=yi

es(cosθj +m/2)

(3) 

In the above formula, the number of samples in a batch, the number 
of sample classes, the cosine factor, the cosine interval, the angle be-
tween the feature and the target weight, the angle between the feature, 
and the non-target weight are all denoted by the letters n, C, s, m, θyi , 
and θj, respectively. The network can concentrate its expressive power to 

Fig. 3. DenseNet structure used in module 1.  

EcologicalInformatics78(2023)1023345H. Gong et al.                                                                                                                                                                                                                                    

Fig. 4. Module 2 model diagram.

6.1. Vision transformer 

Transformer (Vaswani et al., 2017), which is a deep neural network 
first created for natural language processing (NLP), was built on a self- 
attention mechanism that makes it possible for noticeably huge recep-
tive  fields.  The Transformer  has become  a  de facto industry  standard 
procedure in NLP because of its remarkable efficiency, and it has also 
motivated  researchers  in  the  field  of  computer  vision  to  investigate 
applications  by  utilizing  the  long-term  relationships  between  pixels 
(Khan et al., 2022).

ViT  is the  first significant effort to employ  a  pure Transformer on 
pictures directly, showing that it can totally replace the conventional 
convolution processes with SOTA performance. The training of the va-
nilla ViT model, however, necessitates high computing costs, according 
to  the  experimental  findings.  As  a  result,  the  utilization  of  a  hybrid 
design  that  couples  the  Transformer  with  a  CNN  backbone  (such  as 
ResNet)  is  advocated  here.  The  Transformer  may  concentrate  on 
modelling global attention using the feature that ResNet extracted. Ac-
cording to the experimental findings, the hybrid approach can deliver 
better performance with comparatively less computing work. The main 
objective of this work was to create a model that accurately identifies 
sika deer using the idea.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model described in the given context uses Python2.7 along with several libraries such as OpenCV and TensorFlow. Therefore, we can infer that TensorFlow is one of the frameworks used to build the deep learning model. However, there is no mention of other popular deep learning frameworks like PyTorch or Keras.