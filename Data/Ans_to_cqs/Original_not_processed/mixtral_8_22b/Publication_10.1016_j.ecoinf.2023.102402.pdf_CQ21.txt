Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

et  al., 2014). Further details on how to  get our  presence data can be 
found in the Data Availability section. The questionnaire included also 
details  on  sightingh  sites  such  as  habitat  features  and  number  of 
encountered  specimens,  and  percentages  on  the  total  number  of  re-
sponses were computed for each of these values.

2.4. Model validation 

The model's performance was  evaluated using the Area Under the 
receiver-operator  Curve  (AUC).  The  AUC  values  range  from  0  to  1, 
where values closer to 1 indicate a higher accuracy of model prediction 
(Fielding and Bell, 1997). In addition to the AUC, the True Skill Statistics 
(TSS) was calculated. TSS values range between (cid:0) 1 and + 1. A TSS value 
of +1 means complete agreement between observed and predicted dis-
tributions, whereas values of ≤0 denote no better than random perfor-
mance  (Allouche  et  al.,  2006).  AUC  and  TSS  are  the  methods  most 
commonly used to assess the model performance in species distribution 
model studies (e.g., Gaier and Resasco, 2023; Mondanaro et al., 2023; 
Song and Estes, 2023).

Investigation, Methodology, Supervision, Visualization, Writing – orig-
inal draft, Writing – review & editing. Sonia Smeraldo: Formal analysis, 
Investigation,  Methodology,  Visualization,  Writing  –  original  draft, 
Writing – review & editing. Maria Luisa Chiusano: Writing – original 
draft,  Writing  –  review  &  editing.  Francesca  Raffini:  Supervision, 
Visualization,  Writing  –  original  draft,  Writing  –  review  &  editing. 
Daniele  Canestrelli:  Supervision,  Visualization,  Writing  –  original 
draft, Writing – review & editing. Luigi Musco: Conceptualization, Data 
curation,  Investigation,  Supervision,  Visualization,  Writing  –  original 
draft, Writing – review & editing. Claudia Gili: Conceptualization, Su-
pervision,  Visualization,  Writing  –  original  draft,  Writing  –  review  & 
editing. 

Declaration of Competing Interest 

The authors have no conflicts of interest to declare. 

Data availability

(0–0.335),  medium 
formance  classes  were  considered:  poor 
(0.336–0.665), and good (0.666–1).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, several postprocessing steps can be performed depending on the specific requirements of the study or project. Based on the given context, it appears that the researchers focused on evaluating their model's performance using two main metrics: Area Under the receiver-operator Curve (AUC) and True Skill Statistics (TSS). These metrics help determine the accuracy and reliability of the model predictions.

To calculate these metrics, one must first gather the necessary information from the trained model. For instance, when calculating the AUC, the true positive rate (TPR) and false positive rate (FPR) need to be determined based on the model's output. Similarly, computing the TSS requires knowing the true positives, true negatives, false positives, and false negatives obtained from the model's results.

Additionally, visualizing the model's performance through tools like saliency maps could provide valuable insights into which input features contribute significantly to the final outcome. However, this is not explicitly mentioned in the provided context.

Lastly, creating a confusion matrix might also be helpful during the postprocessing stage. This tool allows researchers to compare actual versus predicted outcomes, providing a clearer understanding of the model's strengths and weaknesses. Again, while not directly stated in the context, generating a confusion matrix is often part of the postprocessing steps in many machine learning projects.