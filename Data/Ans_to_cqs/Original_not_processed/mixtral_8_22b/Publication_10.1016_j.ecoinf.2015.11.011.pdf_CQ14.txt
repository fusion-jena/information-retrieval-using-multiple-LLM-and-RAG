Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4.2. Opportunities of the modeling approach

Segmentation and classiﬁcation strategies in eCognition are still
rapidly evolving; methods and rule sets for automatically selecting
segmentation parameters are under development (Dragut et al.,
2010, 2014; Martha et al., 2012), but there is not yet consensus on
best practices. Better classiﬁcations, which could then better capture
the process of interest, may be possible as these tools develop fur-
ther. Machine learning techniques are being brought together with

M.V. Eitzel et al. / Ecological Informatics 31 (2016) 100–111

109

segmentation to more automatically classify images (Nancy Thomas,
personal communication). This set of approaches with historical im-
agery could become more powerful as new methods are developed.
We do caution that even with machine learning, some supervision
and validation using aerial photo interpretation techniques or
other data sources are still necessary (Sexton et al., 2015).

(Mixed GAM Computation Vehicle; Wood, 2006). The GAM was ideal
for these data for two reasons: 1) a Markovian random ﬁeld (MRF)
basis was available for the smoothing function, which is designed for
use with polygons with potentially irregular sizes (which some of the
cells have after applying the forest-only analysis mask); and 2) mgcv
had extensions for non-normal response variables. The quasi-binomial
family was an appropriate choice, as it allowed for overdispersion. The
response variable was then framed as a number of 1-m by 1-m cells
within the 20-m by 20-m cell of the DEM which were classiﬁed as
‘woody cover’ as binomial successes, and those classiﬁed as ‘herbaceous
cover’ as binomial failures.

; Eastingi

þ β

loc:cont:xloc:cont:
Þ

i

ð1Þ

and f() was a smooth function using the MRF basis. We ﬁt models at
all scales for all four sites independently, and corrected for multiple
comparisons using the ‘false discovery rate’ method in the R function
“p.adjust” (which uses the method of Benjamini and Yekutieli, 2001).
See Supplementary data for R code to ﬁt these models. To illustrate
the workﬂow associated with the processing and classiﬁcation of the
imagery, gridding at the scale of the DEM, scaling up, and ﬁtting
GAMs, see Fig. 3.

3. Results

3.1. Preprocessing, classiﬁcation, and model diagnostics

Table 1
Site characteristics.

Distance from coast (km)
Average elevation (m)
Latitude (°N)
Longitude (°W)
Total annual rainfall (mm)
July–August mean temperature (°C)

Bald
Hills

18.8
585
41.17
123.89
2782
19.3

Blake
Mountain

62.7
1180
40.51
123.53
1588
20.9

Iaqua
Buttes

26.5
775
40.71
123.90
1837
18.6

Willow
Creek

39.4
375
40.95
123.66
1458
23.9

M.V. Eitzel et al. / Ecological Informatics 31 (2016) 100–111

103

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about how the hyperparameters of the model were optimized. However, based on common practices in machine learning, one can infer that either grid search or random search might have been used. Grid search involves trying out different combinations of hyperparameter values within a predefined range, while random search randomly selects combinations of hyperparameter values within a given range. Both methods aim to find the optimal combination of hyperparameters that minimize error or maximize performance. Without specific details mentioned in the text, we cannot definitively state whether grid search or random search was employed.