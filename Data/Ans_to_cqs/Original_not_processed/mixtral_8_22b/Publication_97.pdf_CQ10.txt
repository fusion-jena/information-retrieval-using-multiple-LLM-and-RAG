Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

case for further investigations for the appliance of deep learning approaches in vegetation science.

58. Yu, L.C.; Sung, W.K. Understanding geometry of encoder-decoder CNNs. arXiv 2019, arXiv:1901.07647v2.
Ioﬀe, S.; Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate
59.
shift. arXiv 2015, arXiv:1502.03167v3.
Srivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; Salakhutdinov, R. Dropout: A simple way to prevent
neural networks from overﬁtting. J. Mach. Learn. Res. 2014, 15, 1929–1958.

60.

61. Evaluation of the CNN Design Choices Performance on ImageNet-2012. Available online: https://github.

com/ducha-aiki/caﬀenet-benchmark (accessed on 24 March 2020).

62. Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G.S.; Davis, A.; Dean, J.;
Devin, M.; et al. TensorFlow: Large-scale machine learning on heterogeneous systems. arXiv 2016,
arXiv:1603.04467v2.

Remote Sens. 2020, 12, 1145

6 of 17

Training data were generated as batches of size (m, 256, 256, 3), where m is the batch size (m =
20 in our experiments). The batches consisted of sub-images of size 256 × 256 that were randomly
cropped out from the original satellite images presented in Table 1. We had a stream (internally, a
Python generator) of almost never repeated sub-images; these sub-images were combined into batches
and used for the neural network training. Satellite images for sites #1, #3, #5, #7–10 were used for
training and #2, #4, #6 for validation. Corresponding batches of mask data had shape (20, 256, 256, 1).
The network training assessment was performed on sub-images generated from image #2 (Table 1).
Images #4 and #6 were used for visualization and demonstration of the algorithm eﬃcacy.

40. Rammer, W.; Rupert, S. Harnessing deep learning in ecology: An example predicting bark beetle outbreaks.

Front. Plant Sci. 2019, 10, 1327. [CrossRef]

41. Wagner, F.H.; Sanchez, A.; Tarabalka, Y.; Lotte, R.G.; Ferreira, M.P.; Aidar, M.P.; Gloor, E.; Phillips, O.L.;
Aragão, L.E.O.C. Using the U-Net convolutional network to map forest types and disturbance in the Atlantic
rainforest with very high resolution images. Remote Sens. Ecol. Conserv. 2019, 5, 360–375. [CrossRef]
42. Ronneberger, O.; Fischer, P.; Brox, T. U-Net: Convolutional networks for biomedical image segmentation.

arXiv 2015, arXiv:1505.04597.

43. Zhang, Z.; Liu, Q.; Wang, Y. Road extraction by deep residual U-Net. IEEE Geosci. Remote Sen. Lett. 2018, 15,

749–753. [CrossRef]

44. Çiçek, Ö.; Abdulkadir, A.; Lienkamp, S.S.; Brox, T.; Ronneberger, O. 3D U-Net: Learning dense volumetric

segmentation from sparse annotation. arXiv 2015, arXiv:1606.06650.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there isn't any direct mention or reference to a specific code repository link for the deep learning pipeline used in this study. Therefore, it's not possible to provide the exact link to the GitHub, GitLab, or BitBucket repository containing the source code for their implementation. However, one can infer that they might have used popular deep learning libraries such as TensorFlow (reference 62) and possibly other open-source tools like PyTorch or Keras during their research. To find more details about the code used in this work, it would be best to contact the authors directly or look for additional resources related to their project.