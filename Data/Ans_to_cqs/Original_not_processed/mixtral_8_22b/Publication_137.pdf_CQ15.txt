Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Model training: We process data with a deep neural
network and adjust the training epoch, batch size, and
volume size to output a classiﬁer for prediction.
3. Result output: The point cloud test set is segmented,
and we can obtain the ﬁnal segmentation results. The
output ﬁles include point cloud geometric partition
graphs, SPGs, and segmentation results.

Results and Discussion

123

2170

Journal of the Indian Society of Remote Sensing (September 2021) 49(9):2163–2172

training, we set the learning decay rate to 0.7 so that the
learning rate gradually decays as the training progresses.
Table 1 shows the experimental results in which we ﬁxed
the voxel size and batch size and adjusted the regulariza-
tion strength, from which we can be told that result is better
while regularization strength is 0.2.

2165

Fig. 1 The pipeline of the SPG framework. a Represents the original
input data (taking a tree and a pole as examples). b Is a hand-crafted
point cloud partition, c each partition is converted into a superpoint of

the SPG, and d is the network for superpoint embedding and
segmentation based on PointNet and GRU. The black lines represent
the superedges

with K ¼ P3
adjacency:

i¼1 ki,

E ¼ (cid:3)

3
X

i¼1

ki
K

log

(cid:2) (cid:3)
ki
K

in accordance with the optimal

ð1Þ

The linearity, planarity, and scattering are derived by the

following terms:

linearity ¼

planrity ¼

scattering ¼

k1 (cid:3) k2
k1
k2 (cid:3) k3
k1

k3
k1

ð2Þ

The linearity describes how elongated the adjacency is,
the planarity assesses how plane the adjacency is, the high-
scattering values are used to represent an isotropic and
spherical adjacency. We describe these three point features
as geometric features.

According to the pipeline of our framework, ﬁrst, we
compute the geometric partition. Then, each geometric
partition is converted into a superpoint. Next, we input the
superpoints in the SPG to a PointNet network for super-
point embedding. The ﬁnal operation is to segment the
point clouds based on context with a graph convolution
network. Therefore, the results of geometric partition have
a great impact on the semantic segmentation due to dif-
ferent superpoint caused by varying partition result.

We will discuss the regularization parameter l which
inﬂuences the coarseness of the partition. In formula (3),
the former term describes the ﬁdelity, and the latter is the
smoothness. The varying regularization parameter l causes
different partition results. Then, when we convert
the
partition to a superpoint, it will construct varied superpoint
graph, which is actually the neural network input.

The Structure of the SPG

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there isn't any explicit mention of specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) being used in the deep learning pipeline. However, it does state that they use a deep neural network for processing data and adjust the training epoch, batch size, and volume size to output a classifier for prediction. This implies that some form of optimization technique would likely be employed during this process, but without further details, it cannot be definitively stated which one was used.