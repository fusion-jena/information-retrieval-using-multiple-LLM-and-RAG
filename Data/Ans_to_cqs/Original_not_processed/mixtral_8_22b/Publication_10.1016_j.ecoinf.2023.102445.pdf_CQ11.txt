Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

input into the model network for training.

2.2. Methods 

To better show the workflow of the method in this paper, Fig. 4 is 

drawn. 

EcologicalInformatics79(2024)1024453M. Wei and W. Zhan                                                                                                                                                                                                                          

Fig. 3. YOLOv8 network structure.  

2.2.1. Video processing

designs  the  C2flite  module  to  integrate  more  deep  features  into  the 
network.  Thus,  the  number  of  model  parameters  can  be  significantly 
reduced while maintaining high accuracy and speed. Concurrently, we 
conducted  ablation  experiments  and  compared  YOLO_MRC's  perfor-
mance with that of improved models such as YOLOv5s-ECA (She et al., 
2022),  Fast-RCNN  (Mobilenetv2)  (Shen  et  al.,  2018),  YOLOv5Ghost 
(Zhang et al., 2022), and YOLOv7Tiny (Wang et al., 2023) to explore the 
performance advantages of YOLO_MRC on our Bactrocera cucurbitae pest 
dataset. In addition, on the public dataset Pest_24_640, YOLO_MRC is 
used  to  conduct  benchmark  experiments  with  several  other  excellent 
SOTA  models  to  explore  its  performance  on  multiclass  pest  detection 
tasks. 

2. Materials and methods 

2.1. Materials 

2.1.1. Experimental equipment and environment

3.4. Benchmark experiments 

To  further  explore  the  performance  of  YOLO_MRC  in  multiclass 

EcologicalInformatics79(2024)1024459M. Wei and W. Zhan                                                                                                                                                                                                                          

Fig. 11. Convergence of P, R, and mAP50 during training and loss of cls_loss during validation for the four experimental models (Experiments 1,2,7, and 10).  

Table 4 
Comparative Experiment 1.  

Models 

Time (ms) 

YOLOv5s-ECA 
Faster-RCNN(Mobilenetv2) 
YOLOv5Ghost 
YOLOv7Tiny 
YOLO_MRC 

6.6 
65 
9.5 
11.8 
5.6 

R (%) 

99.4 
69.0 
99.5 
97.2 
99.5 

mAP@0.5 

mAP@0.5:0.95 

Model size (MB) 

99.6 
97.7 
99.3 
98.8 
99.3 

71.5 
63.4 
72.5 
66.1 
73.4 

14.4 
628.5 
7.8 
12.3 
2.4  

Table 5 
Comparison Experiment 2.  

Models 

Video1 

Video2 

Video3 

Average accuracy 
(%)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The article does not provide information about a specific data repository link for the deep learning pipeline used in their research. Therefore, I cannot provide a direct link to any data repositories like Zenodo, Figshare, Dryad, or GBIF related to their study.