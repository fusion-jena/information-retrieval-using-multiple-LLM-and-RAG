Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

References 

Abu, A., Diamant, R., 2022. Feature set for classification of man-made underwater 

objects in optical and sas data. IEEE Sensors J. 22 (6), 6027–6041. http://dx.doi.org/ 
10.1109/JSEN.2022.3148530. 

Bibby, C., Jones, M., Marsden, S., 1998. Expedition Field Techniques: Bird Surveys. Royal 

Geographical Society, London.  

Çalıs¸kan, A., 2023. Detecting human activity types from 3d posture data using deep 
learning models. Biomed. Signal Process. Control 81, 104479. http://dx.doi.org/ 
10.1016/j.bspc.2022.104479. 

Clements, N., Robinson, W., 2022. A re-survey of winter bird communities in the Oregon 
coast range, USA, initially surveyed in 1968-1970. Biodiers. Data J. http://dx.doi. 
org/10.3897/arphapreprints.e91575. Aug.  

Davis, K.L., Silverman, E.D., Sussman, A.L., Wilson, R.R., Zipkin, E.F., 2022. Errors in 

aerial survey count data: identifying pitfalls and solutions. Ecol. Evol. 12 (3), e8733 
http://dx.doi.org/10.1002/ece3.8733.

Fig. 1. Overall methodology. The images as they stream are automatically placed in the queue array to be processed in an automated way.  

EcologicalInformatics78(2023)1022853K. Kuru et al.                                                                                                                                                                                                                                    

Fig. 2. User interfaces. Left: the main platform developed for multi purpose environmental applications. Right: man-made object detection and splitting interface 
that can be opened from the main platform.

UCLAN 
UCLAN 
APEM 
Average 

✓ 
✓✓ 
✓✓✓ 
✓✓✓✓  

varies from 7 s to 16 s, depending on the image size and the number of 
objects in the image and their sizes, which is a very fast processing time 
for  high-pixels-per-image  (HPP)  images  up  to  50  MB  based  on  the 
camera system that is explained in Section 3. The overall computational 
complexity of the developed algorithms is O(n log n). It is important to 
point out that the supervised DL and ML approaches, designed by us in 
our previous work in (Kuru et al., 2023), that runs on similar images in 
the same surveys, can detect specific marine small natural objects (e.g., 
birds) in a few seconds (i.e., between 2 and 4 s). In this sense, we can 
conclude that DL and ML techniques slightly outperform the proposed 
non-supervised technique developed in this study considering the pro-
cessing time.

EcologicalInformatics78(2023)10228512K. Kuru et al.                                                                                                                                                                                                                                    

Fig. 16. Examples for blank images with no man-made objects.  

EcologicalInformatics78(2023)10228513K. Kuru et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The information provided does not explicitly state what type of data format is used in the deep learning pipeline. However, there are some clues that suggest it might involve image data. For instance, Fig. 1 mentions "images" being placed in a queue array for processing. Additionally, the mention of "high-pixels-per-image (HPP)" also suggests that the input data could be images. Furthermore, the paper discusses the use of deep learning and machine learning techniques for detecting specific marine small natural objects such as birds, which implies that visual data like images or videos may be involved. Therefore, while it cannot be definitively stated without more explicit evidence, it seems likely that the deep learning pipeline uses image data.