Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

119,273
63,600
55,050

1,377
1,272
1,101

TABLE I: WA subset of Benthoz15 in numbers.

labels in this dataset which make it quite challenging. Table. I
details some statistics of the Western Australia (WA) subset of
this dataset. We have used a subset of this dataset containing
images from Western Australia (WA) to train our classiﬁer.
This subset consists of 4,750 images with 237,500 expert-
annotated points collected over a span of 3 years (2011 to
2013).

B. Pre-processing

We applied color channel stretch on each image in the
dataset. We calculated the 1% and 99% intensity percentiles
for each color channel. The lower intensity was subtracted
from all the intensities in each respective channel and the
negative values were set to zero. These intensities were then
divided by the upper percentile. The resulting intensities
achieved a better performance compared to the original ones.

C. Classiﬁcation Experiments and Results

We conducted three experiments to evaluate our classiﬁer:
(i) the classiﬁer was trained on two-thirds of the images from
the year 2011 and tested on the remaining images from the
same year,
(ii) the images from year 2011 were used for
training and the images from 2012 and 2013 constitute the
test set, (iii) the training set consisted of two-thirds of the
images from the years 2011, 2012 and 2013, whereas the test
set consists of all the remaining images from the same years.
Table. II shows the details and reports the preliminary results

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

 
 
 
Experiment

# of Training Samples

# of Test Samples

Accuracy

Exp 1: Train and test
on 2011
Exp 2: Train on 2011 and
test on 2012 and 2013
Exp 3: Train and test on
2011,2012 and 2013

108,000

108,000

157,173

53,000

130,000

80,750

97.00%

92.45%

95.33%

C. Classiﬁcation Experiments and Results

Selecting patch sizes that give the best classiﬁcation ac-
curacy is an important step. We trained our classiﬁer using
multiple patches at different scales and achieved the best
performance when these three patch sizes were used: 28 × 28,
224 × 224, and 448 × 448. These correspond to small, medium
and large scales. Feature extraction at different sizes insures an
efﬁcient encoding of coral species independently of their size.

28x28

224x
224

448x
448

l

a
i
t
a
p
S

i

d
m
a
r
y
P

t
e
n
G
G
V

g
n

i
l

o
o
p
-
x
a
M

P
L
M

r
e
y
a
L
2

Coral

Non-
Coral

Fig. 3: Block diagram of the proposed classiﬁcation method.

TABLE III: Coral coverage of three sites of the Abrolhos
Islands for years 2010 and 2013.

ACKNOWLEDGMENT

of coral classiﬁcation on Benthoz15 dataset. We achieved a
classiﬁcation accuracy greater than 90% in all of our experi-
ments.

The best performance is achieved when the training and
testing sets contain images from the same year. The per-
formance dropped when the experiments were done across
multiple years. This illustrates the difﬁculty encountered when
the training and test set have images from different years.
The main reason being the changes occurring in the coral
reefs with time. The major causes of misclassiﬁcation were:
the ambiguous boundaries between corals and non-corals,
dead corals (non-coral species start covering corals) and the
abundance of non-coral labels in the dataset.

D. Coral Population Analysis

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there isn't any explicit mention of specific criteria used to determine when training is complete. However, common practices in machine learning include monitoring metrics such as validation loss or accuracy during training. When these metrics reach a plateau or stop improving significantly, it can be considered as an indication that further training may not yield substantial improvements. In the context of the provided information, one could infer that similar criteria might have been employed, but without concrete evidence, it remains speculative.