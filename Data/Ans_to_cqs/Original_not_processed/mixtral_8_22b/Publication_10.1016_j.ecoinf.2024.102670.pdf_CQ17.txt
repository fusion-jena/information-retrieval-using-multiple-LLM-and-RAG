Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

An  issue  with  deep  learning  methods  is  that  it  can  be  difficult  to 
obtain enough ground truth data. Sharma et al. (2017) utilized crowd-
sourcing, involving non-expert users for obtaining manual annotation, 
and demonstrated the efficacy of their method on karyotyping images of 
chromosomes.

Future  perspectives  for  a  more  versatile  removal  of  these  compo-
nents might include adding a user interface for easily marking desired 
components  or  the  development  of  a  more  specific  detector.  Deep 
learning is a paradigm that has been shown to outperform other methods 
in several domains. Indeed, (Xu et al., 2021) developed a Convolutional 
Neural  Network-based  segmentation  model  and  compared  its  perfor-
mance against other methods, including the PCT method developed in 
(Obara et al., 2012), finding a substantial improvement. 

EcologicalInformatics82(2024)10267014O. Sten et al.                                                                                                                                                                                                                                     

Table 7 
Identification of branches and crossing, without the matching algorithm.   

True 
Positive 

False 
Positive 

False 
Negative 

Precision

sectioned brain microvasculature: learning aids completion of vascular graphs by 
connecting gaps and deleting open-ended segments. Med. Image Anal. 16 (6), 
1241–1258. URL https://linkinghub.elsevier.com/retrieve/pii/ 
S1361841512000850.  

Lasser, J., Katifori, E., Dec. 2017. NET: a new framework for the vectorization and 

examination of network data. Source Code Biol. Med. 12 (1), 4. URL http://scfbm. 
biomedcentral.com/articles/10.1186/s13029-017-0064-3.  

Ledoux, C., Chapeland-Leclerc, F., Ruprich-Robert, G., Bob´ee, C., Lalanne, C., 

Herbert, R., David, P., Jul. 2022. Prediction and experimental evidence of the 
optimisation of the angular branching process in the thallus growth of Podospora 
anserina. Sci. Rep. 12 (1), 12351. URL https://www.nature.com/articles/s41598- 
022-16245-9.

As  mentioned  in  Section  4.1,  performances  may  be  improved  by 
exploiting machine learning. Specifically, (Guo et al., 2021) extracted 
spherical patches around points of interest in the 3D volumetric images 
and used a deep learning-based model to classify the point of interest: if 
the point of interest was a cross-over point/overlap, the incoming fila-
ments were separated. With respect to the approach proposed in (Guo 
et  al.,  2021),  our  approach  is  similar  for  hierarchically  starting  by 
creating an overview and then locally analyzing the points of interest. 
Meanwhile, (Guo et al., 2021) analyzes all potential points of interest by 
considering a patch with a fixed radius, which may be advantageous in 
3D thanks to the volumetric information. We locally analyze the points 
of  interest  considering  their  respective  filament  angles  in  order  to  be 
able to identify overlaps with geometrical branch points far from each

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the regularization methods used to prevent overfitting in the deep learning pipeline. However, based on general knowledge, some common regularization techniques used in deep learning models include Dropout, L1 Regularization, and L2 Regularization. Dropout is a technique where randomly selected neurons are ignored during training, which helps prevent overfitting. L1 Regularization adds an absolute value of the magnitude of coefficients as penalty term to the loss function, while L2 Regularization adds a squared magnitude of the coefficient as penalty term to the loss function. These techniques help in reducing overfitting by introducing a cost to complexity of the model.