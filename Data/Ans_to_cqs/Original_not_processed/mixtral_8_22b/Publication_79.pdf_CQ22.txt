Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table5Confusionmatrix(innumberofpixels),precision,recall,andF1-score(highlightedinbold)forthefirstlevelofclassification,usingtheRGB+EVI2dataset.OA=92.8%.PredictedReferenceGrasslandSavannaForestTotalPrecisionGrassland5,906,317315,6738,0846,230,0740.95Savanna697,3947,788,06593,3078,578,7660.91Forest36,92996,4232,441,1112,574,4630.95Total6,640,6408,200,1612,542,502——Recall0.890.950.96——F1-score0.920.930.95——Fig.8Patchesof:(a)theWorldView-2image;(b)thereferencedata;(c)resultingthematicmapusingRGB+EVI2dataset;and(d)resultingthematicmapusingRGB+LSMMdatasets.G×Sarethemisclassifiedareasbetweengrasslandandsavanna;S×F,betweensavannaandforest;andG×F,betweengrasslandandforest.Nevesetal.:HierarchicalmappingofBrazilianSavanna(Cerrado)physiognomiesbasedondeeplearningJournalofAppliedRemoteSensing044504-13Oct–Dec2021(cid:129)Vol.15(4)Downloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Applied-Remote-Sensing on 16 Nov 2023

physiognomyoccurs.Similartothepreviousexperiment(Sec.2.4),allsamplesthatcontainanyno-datavaluewereexcluded.Thus,thesixdataaugmentationtechniquesmentionedbeforewereappliedfortheremainingtrainingandvalidationsamples.Thecompletesamplessetwasrandomlysplit:70%and30%wereassignedfortrainingandvalidation,respectively.Theslidingwindowapproachwasalsoemployedtocreatetheresults.Tousethesamesamplegenerationapproachintheentirehierarchicalprocess,thesemanticsegmentationwasrepeatedforthefirstlevel(forest,grassland,andsavanna).Subsequently,thesemanticsegmentationapproachwasemployedforeachresultingsavannaandgrasslandmaps.ThefinalCerradophysiognomiesmap(andtherespectiveaccuracymetrics)iscomposedoftheforestmap(galleryforest),thesavannamap(shrubsavanna,typicalsavanna,woodlandsavanna,Rupestriansavanna,andVereda),andthegrasslandmap(opengrassland,shrubgrassland,Rupestriangrassland,andhumidopengrassland).Theselasttwoweregeneratedinthesecondlevelofclassification.ThesemethodologicalstepsarerepresentedinFigs.1(b

NB,Brasília,DF–Brazil,p.44(2017).21.Y.LeCun,Y.Bengio,andG.Hinton,“Deeplearning,”Nature521(7553),436–444(2015).22.E.Guiradoetal.,“Deep-learningversusObiaforscatteredshrubdetectionwithGoogleearthimagery:Ziziphuslotusascasestudy,”RemoteSens.9(12),1220(2017).23.M.Brandtetal.,“AnunexpectedlylargecountoftreesinthewestAfricanSaharaandSahel,”Nature587(7832),78–82(2020).24.D.Torresetal.,“SemanticsegmentationofendangeredtreespeciesinBraziliansavannausingdeeplabv3+variants,”inIEEELatinAm.GRSS&ISPRSRemoteSens.Conf.,IEEE,pp.515–520(2020).25.K.Nogueiraetal.,“Towardsvegetationspeciesdiscriminationbyusingdata-drivendescrip-tors,”in9thIAPRWorkshopPatternRecognit.RemoteSens.,IEEE,pp.1–6(2016).Nevesetal.:HierarchicalmappingofBrazilianSavanna(Cerrado)physiognomiesbasedondeeplearningJournalofAppliedRemoteSensing044504-20Oct–Dec2021(cid:129)Vol.15(4)Downloaded

utionandincreasesthenumberoffiltersperkernelandamultilayerconvolutionaldecoder,whichupscalesthefeaturestotheoriginalspatialresolution.Theyfurtheruseskip-connectionsbetweenencoderanddecoderlayers,ofthesamespatialres-olution,topreservelow-leveldetails,requiredfortheprecisepredictionofobjectboundaries.Indeeplearningmethods,originallydevelopedinthecomputervisionfield,theanalysisofthecontributionofdifferentspectralbandstoimprovethenetworkaccuracyisnotyetwellexplored.Thespectralbehaviorofthephysiognomiesandtheirrespectivemajorgroupsrelyontheinformationcontainedindifferentwavelengths,representedherebysatellitespectralbands.However,themajorityofworkswithdeeplearningapproachesusedonlyred,green,andbluechannels22,32orincludedthenear-infrared(NIR)one.25,33Inaddition,veryfewinitia-tiveshaveappliedsomehierarchicalbehaviorinclassificationtasks.34,35Therefore,theobjectiveofthisworkisthreefold:(1)tohierarchicallyclassifytheBrazilianSavannaphysiognomiesbasedondeeplearningtechniquesaccordingtotheclassifi

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model is evaluated using several metrics such as overall accuracy (OA), precision, recall, and F1-score. The table titled 'Table5 Confusion matrix (in number of pixels)' presents these metrics for the first level of classification using the RGB + EVI2 dataset. In this case, OA = 92.8%, which indicates a high degree of correctness in classifying the entire image into three classes - grassland, savanna, and forest. Precision measures the proportion of true positive predictions out of all positive predictions made by the model. For example, the precision for the grassland class is 0.95, meaning that 95% of the predicted grassland pixels were actually grassland. Recall measures the proportion of true positives out of all actual positives in the data. For instance, the recall for the savanna class is 0.95, indicating that 95% of the actual savanna pixels were correctly identified as savanna. The F1-score combines both precision and recall into a single metric, providing a more balanced evaluation of the model's performance. It is calculated as the harmonic mean of precision and recall. In this study, the F1-scores for the grassland, savanna, and forest classes are 0.92, 0.93, and 0.95, respectively. These results suggest that the deep learning model performs well in accurately identifying each class.