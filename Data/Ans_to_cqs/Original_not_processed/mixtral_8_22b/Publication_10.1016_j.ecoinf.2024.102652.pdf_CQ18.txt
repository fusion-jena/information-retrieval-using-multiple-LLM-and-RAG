Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.6.3. Training process 

To fit into the network, the training set must have its data normalized 
and standardized. For the training network, the batch size was set to 32. 
The purposes for selecting 32 were to not exceed the memory limit and 
to make full use of computer resources. The optimizer used Adam pro-
cessing, and the learning ratio varied with group based on the cosine 
function’s law, often in the range between 0.0 and 1.0. The 100 epochs 
are used with an early stopping function to halt the learning process if 
there is no improvement in accuracy after 20 epochs. The loss function 
used is the cross-entropy loss function (Abd-Ellah et al., 2024). 

Lce(H, ̂

H) = Hlog

(

)

H
̂
H

+ (1 (cid:0) H)log

)

(

1 (cid:0) H
1 (cid:0) ̂
H

(4)  

where H is the desired output, Lce(H, ̂
is the predicted output. 

H) is the cross-entropy error, and 

̂
H 

Fig. 5. The experimental design flow chart.

on Gabor wavelet and Teager Kaiser energy operator. In: Hassanien, A., Azar, A., 
Gaber, T., Bhatnagar, R., Tolba, F., M. (Eds.), The International Conference on 
Advanced Machine Learning Technologies and Applications (AMLTA2019). AMLTA 
2019. Advances in Intelligent Systems and Computing, vol. 921. Springer, Cham. 
https://doi.org/10.1007/978-3-030-14118-9_75.  

Ramezan, C.A., Warner, T.E., Maxwell, A., 2019. Evaluation of sampling and cross- 

validation tuning strategies for regional-scale machine learning classification. 
Remote Sens. 11, 185. https://doi.org/10.3390/rs11020185. 

Rashed, H.S.A., 2016. Change detection in land degradation and environmental hazards 
sensitivity in some soils of Siwa Oasis. Egypt. J. Soil Sci. 56 (3), 433–451. https:// 
doi.org/10.21608/EJSS.2016.3135.

EcologicalInformatics81(2024)10265213(a)(b)0102030405060708090100POI AC0102030405060708090100POIACM. El-Rawy et al.                                                                                                                                                                                                                               

Bhattacharya, B., Solomatine, D.P., 2006. Machine learning in soil classification. Neural 

networks 19 (2), 186–195. https://doi.org/10.1016/j.neunet.2006.01.005. 

Cheng, G., Han, J., 2016. A survey on object detection in optical remote sensing images. 
ISPRS J. Photogramm. Remote Sens. 117, 11–28. https://doi.org/10.1016/j. 
isprsjprs.2016.03.014. 

Cooke, U., Brunsden, D., Doornkamp, J.C., Jones, D.K.C., 1982. Urban geomorphology in 
drylands (book review). Third World Plann. Rev. 5, 395. Available on: https://ia601 
506.us.archive.org/30/items/in.ernet.dli.2015.131892/2015.131892.Urban-Geomo 
rphology-In-Drylands_text.pdf.

85.99 
86.26 

74.09 

85.12 

78.5 

86.17  

is  built  solely  on  the  suggested  RUb  blocks,  in  contrast  to  the  SOD 
(salient  object  detection)  models  built  upon  existing  backbones.  This 
enables it to be set up with varying model sizes based on the restrictions 
of the target environment and trained from scratch. This suggests that 
model  training  does  not  require  sophisticated  technology  and  that 
adequate results can be obtained even in the absence of pretraining.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: During the training process, a strategy called early stopping is employed to monitor the model performance. Early stopping is designed to prevent overfitting by halting the learning process when there is no further improvement in accuracy after a certain number of epochs. Specifically, in this case, the learning process will stop if there is no improvement in accuracy after 20 epochs out of the total 100 epochs used for training. Additionally, the cross-entropy loss function is utilized to measure the difference between the actual and predicted outputs, providing another metric to evaluate the model's performance.