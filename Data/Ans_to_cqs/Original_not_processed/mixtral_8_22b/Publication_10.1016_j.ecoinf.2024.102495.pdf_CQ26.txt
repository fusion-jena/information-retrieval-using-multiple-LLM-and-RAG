Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2.3. Deep learning 

Once transformed into a matrix or vector, the results of voice feature 
extraction serve as the input for a deep learning algorithm. This algo-
rithm discerns patterns within the data, enabling it to make predictions 
based on these learned patterns, all without the need for explicit pro-
gramming (Fran√ßa et al., 2021; Navamani, 2019). A critical distinction 
between deep learning and traditional machine learning is the feature- 
extraction  process  during  classification.  Feature  extraction  from  data 
typically requires manual or human intervention in traditional machine 
learning.  Contrastingly,  deep  learning  models  are  designed  to  auto-
matically perform feature extraction.

In the CNN, feature extraction is automatically performed through a 
convolution process that applies a convolution kernel to the input data 
and pooling, which progressively reduces the spatial size of data rep-
resentation (Fernandes et al., 2021). Using convolution layers, pooling, 
and the parameter-sharing feature also makes CNN effective and effi-
cient  in  classifying  data,  such  as  images  and  sound  recordings  (Kim 
et al., 2018). When processing voice-recorded data, a visual represen-
tation of the sound in the form of a spectrogram is generated (Thakur 
and Kumar, 2021). Therefore, as with image data, a CNN can be used to 
map  patterns  from  a  given  sound  recording  data  (a  mosquito  voice 
recording in this case). Additionally, it can produce considerably higher 
accuracy than other deep learning algorithms. 

2.3. Implementation of the Mel spectrogram feature extraction

10 

20/40/60/80 

20/40/60 

11 

20/40/60/80 

20/40/60 

128 
128 
128 
128 
128 
128 
64 
256 
512 
64/256/ 
512 
64/256/ 
512 

1024 
1024 
1024 
1024 
1024 
1024 
1024 
1024 
1024 

512 

2048  

Table 3 
Combination  of  the  convolutional  neural  network  deep  learning  model 
parameters.  

No 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 

Model 

Optimizer 

Learning Rate 

Without Dropout 

With Dropout 

RMSProp 

Adam 

SGD 

RMSProp 

Adam 

SGD 

0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01 
0.001 
0.01  

EcologicalInformatics80(2024)1024958E. Joelianto et al.                                                                                                                                                                                                                               

Fig. 8. Performance test of each configuration.  

Table 4 
The standard deviation values for each performance metric.  

Configurations 

Accuracy 
(%) 

Precision 
(%)

The standard deviation values for each performance indicator were 
compared  to  determine  the  optimal  configuration  (Table  4).  Configu-
ration 8 was determined as the ideal parameter (number of bands: 60, 
number of frames: 40, hop length: 256, and length of the FFT window: 
1024)  owing  to  its  reduced  standard  deviation  value.  The  feature 
extraction parameters that yielded the best performance were employed 
during the feature extraction phase in the optimization process of the 
CNN  deep  learning  model.  The  model  optimization  outcomes  were 
derived  using  performance  criteria  identical  to  those  employed  to 
optimize  feature  extraction  parameters.  Fig.  9  illustrates  the  perfor-
mance evaluation of each model. Additionally, Model 1 exhibited the 
most favorable average performance outcome, with an 89.43% accuracy 
rate, 91.38% precision, 95.52% recall, and 0.816 F1-Score. The obtained

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, common methods include stratified splitting, oversampling, undersampling, and diverse data collection. Stratified splitting ensures that each subset of data maintains the same distribution of classes as the original dataset. Oversampling increases the number of instances in the minority class by duplicating existing samples, while undersampling decreases the number of instances in the majority class by randomly removing some samples. Diverse data collection involves gathering data from various sources to ensure that the dataset represents different populations and scenarios accurately. These techniques help mitigate data bias and improve the overall performance of deep learning models.