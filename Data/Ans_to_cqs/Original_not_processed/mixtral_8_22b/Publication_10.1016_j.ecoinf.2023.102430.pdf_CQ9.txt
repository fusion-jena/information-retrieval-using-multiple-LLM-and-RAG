Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

AN  was  implemented  in  MATLAB  (www.mathworks.com).  For 
training,  we  used  the  stochastic  gradient  descent  with  momentum 
optimizer with default settings except for the initial learning rate (which 
we set to 0.001) and the maximum number of epochs (which we set to 15 
after  preliminary  tests).  The  ‘classical’  machine-learning  algorithms 
(AB, GB, HB, and LD) were run in Python (www.python.org) using the 
scikit-learn toolbox (Pedregosa et al., 2011). We left hyperparameters at 
scikit-learn  default  values,  except  for  the  learning  rate  of  GB  and  HB 
(which we set to 0.15) and the tolerance threshold value for LD (set to 1 
× 10

specimens,  our  species-level  coverage  was  still  limited;  therefore,  we 
focus on algorithm performance at the genus level, for which we were 
able  to  gather  large  enough  samples  of  specimens  and  pictures.  We 
follow  the  currently  accepted  systematic  arrangement  for  the  Tri-
atominae (Monteiro et al., 2018), with all our bugs falling into one of the 
three genera to which the main vectors of human Chagas disease, from 
the USA to Argentina, all belong – Triatoma, Panstrongylus, and Rhodnius 
(WHO,  2002).  Our  assessment  shows  that  convolutional  neural  net-
works can identify these major triatomine genera with very high accu-
racy  using  low-resolution  pictures  taken  with  ordinary  cellphone 
cameras, irrespective of the angles or positions at which the bugs were 
photographed.  This  result  paves  the  way  for  ‘hybrid’  entomological 
surveillance systems  combining  human  taxonomic expertise  with  ma-

2.3. Algorithm training and testing 

We trained all algorithms on a random subset of 5256 pictures (80% 

of  the  6570-picture  dataset).  To  gauge  performance  consistency,  the 
training-testing  process  was  repeated  10  times  for  each  algorithm;  in 
each of these (pseudo-)replicate runs, all five algorithms used the same 
training and testing picture subsets.

2. Methods 

2.1. Bug-picture database

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about where the data repository of the deep learning pipeline is available. It only mentions that the AN model was implemented in MATLAB and the 'classical' machine-learning algorithms were run in Python using the scikit-learn toolbox. However, it does not specify any details regarding the availability of the data repository. Therefore, I do not have the necessary information to answer this query accurately.