Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

reproducibility, and we evaluated multiple seeds to select the one that 
provides  the  most  stable  and  reliable  results.  To  carry  out  the  grid 
search, we defined a range of potential values for each parameter based 
on  prior  knowledge  and  literature  review.  The  grid  search  then 
exhaustively tested all possible combinations of these values and eval-
uated the model’s  performance using cross-validation techniques. For 
each  combination,  we  utilized  the  RMSE  as  the  evaluation  metric, 
aiming to minimize the RMSE to achieve the most accurate predictions. 
By employing the grid search method, we aimed to optimize the model’s 
hyperparameters and enhance its ability to generalize well to new, un-
seen data, making it a robust and effective tool for our regression task. 
The  winning  parameters  are  as  follows:  numberOfTrees:  150,  min-
LeafPopulation: 3, bagFraction: 1, and seed: 123.

parameters of our machine learning model. Specifically, we focused on 
tuning  several  critical  parameters,  namely  ‘numberOfTrees’,  ‘min-
LeafPopulation’, ‘bagFraction’, and ‘seed’. The ‘numberOfTrees’ repre-
sents the number of decision trees in the ensemble, and through the grid 
search, we explored different values to determine the ideal number of 
trees  that  balances  model  complexity  and  predictive  performance. 
Similarly, ‘minLeafPopulation’  refers to the minimum number of sam-
ples required to form a leaf node in each tree. We experimented with 
various values to find the optimal setting that prevents overfitting while 
capturing meaningful patterns in the data. The ‘bagFraction’  indicates 
the proportion of the training dataset used to train each individual tree, 
and  we  searched  for  the  best  value  to  enhance  model  diversity  and 
generalization. Lastly, ‘seed’  is a random number seed used to ensure

30 m CHM were validated against the independent test samples of GEDI 
footprints (that were not participated in the training phase) and accu-
racy  metrics  of  mean  bias  error  (MBE)  and  root  mean  square  error 
(RMSE) as well as R2 were calculated. Table 1 lists the mean bias error 
(MBE), root mean square error (RMSE), and R2  of both CHM maps for 
the year 2019. The MBE for the 10 m CHM was (cid:0) 0.05 m, indicating that 
the  predicted  values  were  slightly  more  than  the  observed  values  on 
average (a sign of a slight overestimation). The RMSE for the 10 m CHM 
was 4.40 m, indicating the average difference between the predicted and 
observed values was 4.40 m. The R2 value for the 10 m CHM was 0.74, 
indicating a moderate correlation between the predicted and observed 
values.  On  the  other  hand,  the  MBE  for  the  30  m  CHM  was  1.05  m, 
indicating  that  the  predicted  values  were  higher  than  the  observed

Adeli, Sarina, Brisco, Brian, 2020. Google earth engine for geo-big data applications: 
a meta-analysis and systematic review. ISPRS J. Photogramm. Remote Sens. 164, 
152–170. 

Tamiminia, Haifa, Salehi, Bahram, Mahdianpari, Masoud, Beier, Colin M., 

Klimkowski, Daniel J., Volk, Timothy A., 2021. Comparison of machine and deep 
learning methods to estimate shrub willow biomass from UAS imagery. Can. J. 
Remote. Sens. 47 (2), 209–227. 

Tamiminia, Haifa, Salehi, Bahram, Mahdianpari, Masoud, Beier, Colin M., 

Johnson, Lucas, Phoenix, Daniel B., 2021a. A comparison of decision tree-based 
models for forest above-ground biomass estimation using a combination of airborne 
lidar and landsat data. In: ISPRS Annals of Photogrammetry, Remote Sensing & 
Spatial Information Sciences, 3. 

Tamiminia, Haifa, Salehi, Bahram, Mahdianpari, Masoud, Beier, Colin M.,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To evaluate the performance of their deep learning model, the authors used three main metrics: Mean Bias Error (MBE), Root Mean Square Error (RMSE), and R². These metrics are commonly used in regression tasks like this one.

Mean Bias Error (MBE) measures the average difference between the predicted and actual values. It provides information about whether the model tends to underestimate or overestimate the target variable. In this case, the MBE for the 10 m CHM was 0.05 m, which means that the predicted values were slightly more than the observed values on average, indicating a slight overestimation.

Root Mean Square Error (RMSE) measures the average magnitude of the errors made by the model. It gives us an idea of how far off the predictions are from the actual values. Here, the RMSE for the 10 m CHM was 4.40 m, meaning that the average difference between the predicted and observed values was 4.40 meters.

R², also known as the coefficient of determination, shows the proportion of variance in the dependent variable that can be explained by the independent variables. An R² value close to 1 suggests that the model explains most of the variability in the response data around its mean. In this study, the R² value for the 10 m CHM was 0.74, indicating a moderate correlation between the predicted and observed values.