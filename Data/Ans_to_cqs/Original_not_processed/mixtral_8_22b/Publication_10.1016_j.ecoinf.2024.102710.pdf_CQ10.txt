Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4 https://github.com/HKathman/pam_annotation_experiments
5 https://github.com/kahst/BirdNET-Analyzer/tree/main/checkpoints/V2.4
6 https://tfhub.dev/google/vggish/1
7 https://tfhub.dev/google/yamnet/1
8 tensorflow.keras.applications.vgg16.VGG16(weights=’imagenet’).
9 tensorflow.keras.applications.resnet_v2.ResNet152V2

(weights=’imagenet’).

Fig. 4. UMAP plots for different embedding layers of different embedding
models for AnuraSet. For UMAP generation, we randomly select 5000 samples
and discard all samples that are aligned to more than one class. Colors and
shapes indicate the 10 classes with the highest occurrence frequency. Layers are
numbered according to their distance from the classification layer, e.g. ‘Bird-
Net-1’ is the last layer before the classification layer of the BirdNet model.

EcologicalInformatics82(2024)1027105H. Kath et al.

evaluation was done on focal and citizen-science datasets. Swaminathan
et al. (2024) extend the observation to attention-based architectures pre-
trained on human speech. Lauha et al. (2022) show that transfer
learning can be helpful also for small networks trained from scratch on
small, targeted datasets gathered from online resources such as Mac-
aulay Library2 (as opposed to foundation models trained on large
datasets). While the works cited above evaluate transfer learning models
based on classification performance, McGinn et al. (2023) take a
different approach and investigate the topology of fine grained, sub-
species sound events in the embedding space afforded by BirdNet;
they find that different call types of a same species (e.g., drumming
versus vocalization) form distinct clusters, and that the vicinity of each

both the target modality and the domain, yields the best performance as
a feature embedding model. Using BirdNet-1 as the embedding model,
active learning sample selection strategies significantly reduce the
required for annotation to achieve model
number of
convergence.

learning observations show that embeddings produced by BirdNet, a model trained on high signal-to-noise re-
cordings of bird vocalisations, can be effectively used for predicting anurans in PAM data: a linear classifier
constructed using these embeddings outperforms the benchmark by 21.7%. Our results indicate that active
learning is superior to random sampling, although no clear winner emerges among the strategies employed. The
proposed method holds promise for facilitating broader adoption of machine learning techniques in PAM and
advancing our understanding of biodiversity dynamics through acoustic data analysis.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The code repository link of the deep learning pipeline mentioned in the given context is <https://github.com/HKathman/pam_annotation_experiments>. This repository contains experiments related to passive acoustic monitoring (PAM) annotations using various deep learning models like VGG16, ResNet152V2, BirdNet, etc. However, it should be noted that this repository might not contain the complete implementation of the entire deep learning pipeline discussed in the paper, but only specific parts or experiments relevant to the authors' research.

Answer:::

Based on the information provided, the code repository link of the deep learning pipeline is <https://github.com/HKathman/pam_annotation_experiments>.