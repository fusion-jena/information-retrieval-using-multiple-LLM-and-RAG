Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Results

We  calibrated  models  for  classification  challenges  using  different  numbers  of  training 
steps, and considered two factors to find optima for training TensorFlow (Khalighifar et al. 
2019): correct identification rate and processing time. As a result, for all challenges except 
Challenge 3, we chose 4000 training steps as an optimum number. For Challenge 3, given 
the number of species (41 species), 8000 training steps proved to be the optimum number. 
The details of results associated with each classification task are as follows:

Challenge 1

We  created  a  confusion  matrix  to  depict  TensorFlow’s  initial  results  with  20  species 
(Fig. 3). The overall correct identification rate was 94.3%. We achieved 100% correct iden-
tification rate for 11, and 90% or above for 17, species. The lowest identification rates were 
for closely-related species Platymantis isarog and P. montanus, with 70 and 75% correct

647

Model architecture

Convolutional neural networks (CNNs) are a subset of DNNs that are specialized for image 
classification  tasks  and  pattern  recognition.  One  of  the  main  advantages  of  CNNs  is  the 
ability to perform automated feature extraction, eliminating the need for hand-crafted fea-
ture  extraction.  CNN  architecture  is  built  on  three  types  of  layers:  (1)  convolutional  lay-
ers,  which  are  the  most  important  because  they  apply  hierarchical  feature  extraction  and 
decomposition  of  input  images;  (2)  pooling  layers,  which  carry  out  operations  to  reduce 
numbers of parameters and necessary computation; and (3) fully connected layers, which 
perform the actual classification at the end of the pipeline.

Deep neural networks

TensorFlow’s flexible architecture allows easy adaptation and deployment on different plat-
forms  including  desktops,  clusters  of  servers,  edge  devices,  and  mobile  phones  (https ://

1 3Biodiversity and Conservation (2021) 30:643–657 

653

www.tenso rflow .org/). Inception v3 is a sophisticated network given the number of layers 
(48), and is already trained on more than a million images.

Funding  No funding was used for this research.

Data  availability  Data  are  publicly  available  via  Cornell  University’s  Laboratory  of  Ornithology  and 
Macaulay Library of Natural Sounds (https ://www.macau layli brary .org).

Compliance with ethical standards 

Conflict of interest  All authors declare that they have no conflicts of interest.

References

Abadi M et al. (2016) Tensorflow: a system for large-scale machine learning. Paper presented at the 12th 

USENIX Symposium on Operating Systems Design and Implementation, Savannah, USA,

1 3Biodiversity and Conservation (2021) 30:643–657 

655

Aide TM, Corrada-Bravo C, Campos-Cerqueira M, Milan C, Vega G, Alvarez R (2013) Real-time bioacous-

tics monitoring and automated species identification. PeerJ 1:e103

Araya-Salas M, Smith-Vidaurre G (2017) warbleR: an R package to streamline analysis of animal acoustic 

signals. Methods Ecol Evol 8:184–191

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no information provided about the specific hardware resources used for training the deep learning model in the given context. Therefore, it cannot be determined whether GPUs, TPUs, or other hardware resources were utilized during the training process.