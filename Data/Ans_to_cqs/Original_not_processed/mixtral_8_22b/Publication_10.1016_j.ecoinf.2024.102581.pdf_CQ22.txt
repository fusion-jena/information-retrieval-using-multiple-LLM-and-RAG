Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

hyperparameters.  The  hyperparameters  with  the  current  results  are 
saved until better accuracy is achieved. The termination criterion of the 
proposed approach is the maximum number of iterations to be executed. 
After the completion of the iterations, the proposed approach provides 
us with the best hyperparameters, thus evolving the near-optimal CNN. 
The  overall  complexity  is  dominated  by  the  iterations,  “TC”,  and 
within  each  iteration,  the  operations  depend  on  the  population  size 
“NP”.  Therefore,  the  total  complexity  can  be  approximated  as 
O(TC*NP).

Reference 

Accuracy (%) 

Methodology 

Pandey and Jain (Pandey and Jain, 2022a) 
Ganguly et al. (Ganguly et al., 2022a) 
Tiwari et al. (Tiwari et al., 2021) 
Kolhar and Jagtap (Kolhar and Jagtap, 2021) 
Atila et al. (Atila et al., 2021) 
Anurag et al. (Saikia et al., 2021) 
Too et al. (Too et al., 2018) 

97.33 
Moderate accuracy 
99.199 
97.97 
98.42 
Moderate accuracy 
Demonstrated effectiveness 

Attention Dense Learning (ADL) for real-time plant leaf disease identification. 
BLeafNet with Bonferroni Fusion Learning, outperforming existing approaches. 
Dense Convolutional Neural Network architecture for plant disease classification. 
3-D CNN, CNN with ConvLSTM, Vision Transformer for plant image classification. 
EfficientNet deep-learning architecture for plant leaf disease classification. 
Traditional approach using color histograms and texture features. 
Fine-tuning pretrained CNN models for plant disease classification.

EcologicalInformatics81(2024)10258111S. Ghosh et al.                                                                                                                                                                                                                                   

Table 5 
Best  accuracies  from  the  respective  generations  for  the  HPB3C-3PGA-based 
CNNs on the Mendeley dataset.  

Table 7 
Classification of the HPB3C-3PGA-based CNN approach on the Mendeley and 
CVIP100 datasets.  

No of conv2d layers 

Best Accuracy Generation 

Best Accuracy 

Dataset 

Accuracy 

Precision 

Recall 

F1-Score 

1 
2 
3 
4 

70 
83 
88 
93 

85.23% 
88.45% 
92.30% 
98.96%  

Table 6 
Best accuracies from the respective generations for the HPB3C-3PGA-based CNN 
on the CVIP100 dataset.  

No of conv2d layers 

Best Accuracy Generation 

Best Accuracy 

1 
2 
3 
4 

68 
85 
86 
90 

88.52% 
91.25% 
92.88% 
98.97%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To evaluate the performance of a deep learning model, several metrics can be used. In this case, we have information about two tables (Tables 5 and 7) which provide details regarding the evaluation of the HPB3C-3PGA-based CNN approach on both the Mendeley and CVIP100 datasets. From these tables, it appears that the authors use four main metrics to assess their model's performance: accuracy, precision, recall, and F1-score.

Accuracy measures how often the classifier makes correct predictions. It is calculated as the ratio between the correctly predicted instances and the total number of instances. Precision, also known as positive predictive value, calculates the proportion of true positives among all the instances classified as positive. Recall, or sensitivity, computes the fraction of relevant instances that were retrieved. Lastly, the F1-score is the harmonic mean of precision and recall, providing a single metric that balances both factors.

Based on Tables 5 and 7, we see that the authors report the best accuracies obtained across different generations of their HPB3C-3PGA-based CNN approach. For example, Table 5 shows that the highest accuracy achieved on the Mendeley dataset was 98.96%, while Table 6 indicates that the top accuracy reached on the CVIP100 dataset was 98.97%. Additionally, Tables 5 and 7 present the corresponding values for precision, recall, and F1-scores, allowing us to understand the model's performance more comprehensively.