Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

detection system can be established. 

4. Experiments and results 

4.1. Experimental setup 

The  suggested  model's  training  procedure  is  carried  out  using  the 
PyTorch framework and the Windows operating system. The program 
environment consists of Python 3.7 and CUDA 11. 7. The datasets were 
trained using a GeForce RTX 3060 12G GPU and an Intel(R) Xeon(R) 
E5–1620 v3 CPU @ 3.50 GHz. The SGD optimizer is used to optimize the 
model, with the batch size set to 8. The momentum is 0.937, and the 
training epoch is 300. 

4.2. Performance evaluation

To extract the input information, the SRC3 block employs a parallel 
analysis  of  the  input  feature  map  using  two  convolution  kernels.  In 
contrast to the C3 block, the SRC3 block incorporates two convolution 
kernels prior to the input of the bottleneck block. One of the kernels is 
responsible  for  halving  the  dimension  of  the  feature  map,  while  the 
other  maintains  the  dimension  unchanged.  This  approach  allows  for 
more  comprehensive  processing  of  the  input  features,  enabling  the 
model  to  capture  both  high-level  semantic  information  and  preserve 
relevant details during the feature extraction process. The convolution 
kernel size utilized is 3 × 3, which leads to a broader receptive field of 
information and richer characteristics compared to the 1 × 1 convolu-
tion kernel. The output semantic information can be augmented by the 
action of two convolution kernels. The information output from the first

3.1. The backbone of YWnet 

The  feature  extraction  phase  is  considered  crucial  in  the  training 
process,  as  it  plays  a  significant  role  in  enhancing  detection  perfor-
mance. The objective of this work is to improve detection accuracy by 
designing  a  feature  extraction  mechanism  that  incorporates  rich  se-
mantic  information  and  integrates  features  from  multiple  scales.  By 
leveraging these strategies, the aim is to capture and utilize a compre-
hensive range of relevant features, thereby enhancing the overall per-
formance of the detection system. As a result, a CBAM is added to the 
network's  backbone  to  improve  feature  extraction  from  the  incoming 
semantic information. Simultaneously, a novel feature extraction mod-
ule called SRC3 is provided to extract rich semantic information from 
the complicated undersea environment. 

3.1.1. Adding the attention module

specific steps are outlined: 

Step 1: Select appropriate water downloading gear and sensors for 
data collection. Pre-processing of the acquired data, such as denoising, 
image enhancement, and correction. In order to train and evaluate un-
derwater target detection models, the dataset needs to be labeled. Then 
separate underwater images collected from the underwater environment 
into training and test images. 

Step 2: Prepare hardware servers capable of training deep learning 
models to deploy the YWnet network. This allows learning weights to 
recognize  underwater  organisms.  Tune  the  hyperparameters  of  the 
model such as learning rate, batch size and network depth to achieve the 
best performance of the model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The deep learning model is trained using a GeForce RTX 3060 12G GPU and an Intel(R) Xeon(R) E5–1620 v3 CPU @ 3.50 GHz. The PyTorch framework and the Windows operating system are employed for the training procedure. Additionally, the programming environment includes Python 3.7 and CUDA 11.7.