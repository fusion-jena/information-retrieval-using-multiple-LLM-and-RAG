Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

shown to reduce the processing time of image classification load by as 
much as 5× to 13× depending on the tasks (Fennell et al., 2022; Henrich

Separate  two-class  models  were  trained  for  Finnmark  and  Yamal 
using  the  keras  package  in  R  (Allaire  and  Chollet,  2023)  with  a  Ten-
sorFlow  backend (Allaire  and Tang,  2023).  Preliminary trials  showed 
that region-specific models performed better. The ResNet-50 architec-
ture, a convolutional neural network that is 50 layers deep (He et al., 
2015), was used to train the models with 55 epochs (number of times the 
algorithm goes through the entire training data set) and a batch size of 
64  (number  of  samples  to  work  through  before  updating  model  pa-
rameters)  with  a  one-cycle  learning  rate  (hyperparameter  controlling 
model  response  to  estimated  error  each  time  the  model  weights  are 
updated) policy with a minimum of 0.000001 and a maximum of 0.001 
(Smith, 2018).

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Arctic wildlife monitoring 
Deep learning 
ResNet-50 
MegaDetector 
Time-lapse camera

3.2. Image quality classification: Training dataset and model training 

Using the manual classifications, we randomly selected images from 
each site, camera, and year, to obtain ~15,000 images of Bad quality 
and  ~  57,000  images  of  Good  quality  for  each  location  (Finnmark 
2016–2018 and 2020–2021 and Yamal 2017–2021). These images were 
then  reexamined  by  GC  and  DE,  and  any  misclassified  images  were 
removed or reclassified. We also excluded marginal images (e.g., partly 
blurred images, images where an animal is only visible with a tail in a 

Table 2 
Total number of images per classification group as assessed manually in Finn-
mark  and  Yamal  (N),  together  with  median  and  mean  (standard  deviation) 
percentage of images for each individual camera trap per year. The total dataset 
(workflow development and independent validation) comprised 36 cameras at 5 
sites for 6 years in Finnmark and 9 or 10 cameras for 6 years in Yamal.  

Location 

Class ID

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The datasets used in this deep learning pipeline are not explicitly mentioned as being well-known datasets such as MNIST, CIFAR, or ImageNet. Instead, the authors have created their own custom datasets using images collected from time-lapse cameras deployed in Finnmark and Yamal regions. They have manually classified these images into 'Good' and 'Bad' categories based on their quality. For training purposes, they have randomly selected approximately 15,000 'Bad' quality images and around 57,000 'Good' quality images from each location. These images were then further examined and corrected if necessary. Therefore, the datasets used in this study are specific to Arctic wildlife monitoring and are not standard machine learning benchmarks like MNIST, CIFAR, or ImageNet.