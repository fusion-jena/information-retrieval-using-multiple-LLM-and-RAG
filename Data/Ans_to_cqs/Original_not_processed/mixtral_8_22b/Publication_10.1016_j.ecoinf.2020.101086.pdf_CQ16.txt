Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Wisz, M.S., Hijmans, R.J., Li, J., Peterson, A.T., Graham, C.H., Guisan, A., 2008. NCEAS
predicting species distributions working group. Eﬀects of sample size on the perfor-
mance of species distribution models. Divers. Distrib. 14 (5), 763–773.

10

Consent to publish

Not applicable (the study does not include details, images, or videos

relating to any individual).

Availability of data and materials

The simulated datasets generated during the current study are

available from the corresponding author upon reasonable request.

Funding

Numerous SDM approaches are proposed in the literature, e.g.,
generalized linear model (GLM, Guisan et al., 2002), generalized ad-
ditive model (GAM, Guisan et al., 2002), artiﬁcial neural networks
(Pearson et al., 2002), support vector machine (Guo et al., 2005),
HABITAT (Walker and Cocks, 1991), genetic algorithms for rule-set
production (GARP, Stockwell, 1999), and Maxent (Phillips et al., 2006).
Some of them require both presence and absence data, whereas others –
and presence-pseudoabsence
presence-only, presence-background,

models – require only species presence information and oﬀer a sig-
niﬁcant advantage because of the diﬃculty to obtain reliable absence
information (Hirzel et al., 2002; Peterson et al., 2011).

The mean relative rank of each method for each performance index
is shown in Fig. 6. The ranking varied by correction type and the
number of presence sites. Concerning ΔDenv, Fenv was the best method,
followed by BGenv when the amount of presences sites was 20. When

k = 50, BGenv appeared to provide the best results in terms of ΔDenv
and ΔDgeo, even if this result does not appear to be signiﬁcant con-
sidering the dispersed values.

When the number of presence sites increased, BGgeo was ranked the
best in terms of ΔAUC, BGgeo, and Fenv in terms of ΔDenv, and Fgeo in
terms of ΔDgeo.

4. Discussion

This study aimed to present a new sampling bias eﬀect correction
method in the framework of species distribution modeling and to
compare it with other representative approaches of the literature.

4.1. Absolute evaluation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't enough information to directly address the query about what criteria are used to determine when training is complete. However, generally speaking, common criteria used to determine when training is complete in machine learning models can include reaching a certain number of epochs, achieving a desired level of accuracy or loss, or observing no significant improvement in validation loss over several epochs (validation loss plateau). These criteria may vary depending on the specific model and dataset being used. In the context of species distribution models, similar criteria could potentially apply, such as monitoring changes in performance indices like ΔAUC, ΔDenv, and ΔDgeo, and stopping training when these metrics reach a satisfactory level or show minimal improvement over multiple iterations.