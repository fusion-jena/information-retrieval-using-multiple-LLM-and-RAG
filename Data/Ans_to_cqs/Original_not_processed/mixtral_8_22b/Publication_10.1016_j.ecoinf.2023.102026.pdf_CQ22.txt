Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

At  each  of  the  aforementioned  scales,  we  calculated  biologically 
informative metrics by using FRAGSTATS (McGarigal et al., 2012) for 
discrete raster layers and ArcMap v10.6.1 (ESRI, 2018) for continuous 
raster layers: in FRAGSTATS, we implemented percentage of landscape 
(PLAND) metric, while in ArcMap we calculated focal mean (FM). Both 
the functions average the pixel values of the covariates' raw raster layers 
to  obtain  a  smoothened  version  of  the  original  layer.  Additionally, 
PLAND function calculates the percentage of the focal covariate within 
the  circular  buffer,  and  this  is  why  it  has  been  preferred  for  discrete 
layers.  Finally,  we  removed  poorly  sampled  covariates  occurring  at 
<10% of camera trap stations. 

2.3. Modelling framework 

2.3.1. Generalised linear model – scale optimisation and covariates 
selection

EcologicalInformatics75(2023)1020262L. Chiaverini et al.                                                                                                                                                                                                                              

1000 m, 2000 m, 4000 m, 6000 m, 8000 m and 10,000 m (Chiaverini 
et al., 2022; Macdonald et al., 2020).

We  evaluated  the  performances  of  the  non-bootstrapped  GLM  by 
calculating  the  Area  Under  the  ROC  Curve  (AUC),  Percent  Correctly 
Classified  (PCC),  sensitivity,  specificity  and  True  Skill  Statistic  (TSS) 
using the 20% camera traps retained from the training dataset. 

To evaluate the bootstrapped GLM, for each of the 100 iterations, we 
calculated  AUC,  PCC,  sensitivity,  specificity  and  TSS  using  the  data 
retained from the model training, composed of 80% of the presence and 
of the absence locations. We obtained the final metrics by averaging the 
results  of  100  validation  iterations.  We  implemented  this  framework 
independently  for  each  felid.  Validation  metrics  were  calculated  in  R 
v3.5.1  (R  Core  Team,  2018)  using  the  package  PresenceAbsence 
(Freeman and Moisen, 2007). 

2.4. Random forest – scale optimisation and covariates selection

To produce accurate SDMs, not just the effects of different algorithms 
should be investigated, but also the effects of resampling techniques on 
model's  training  data  (Efron,  1982;  Freedman,  1981).  Specifically, 
bootstrapping (i.e., random subsampling with replacement) the training 
data  has  been  shown  to  increase  models'  precision  by  providing  a 
combination of models, which reduces stochastic errors in estimation (e. 
g., Vaughan and Ormerod (2005); Hefley et al. (2014); Xu and Goodacre 
(2018)).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not mention any deep learning models or their evaluation metrics. However, it discusses the use of several metrics to evaluate the performance of generalized linear models (GLMs): Area Under the ROC Curve (AUC), Percent Correctly Classified (PCC), sensitivity, specificity, and True Skill Statistic (TSS). These metrics are calculated using the 20% camera traps retained from the training dataset for the non-bootstrapped GLM, and the data retained from the model training (composed of 80% of the presence and absence locations) for the bootstrapped GLM. The results of 100 validation iterations are then averaged to obtain the final metrics. This process is independently implemented for each felid species.