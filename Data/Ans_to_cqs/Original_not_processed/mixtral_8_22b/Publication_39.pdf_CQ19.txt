Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

All programs use Python 3 and PyTorch (Paszke et al. (2019)) for 
building  and  training  the  networks.  The  Mask  R-CNN  model  is  built 
around  the  PyTorch  detection  model  of  Mask  R-CNN.  For  the  imple-
mentation of FGFA we use the PyTorch models for the backbone, the 
RPN and the head of the implementation of Mask R-CNN model. The 
three ResNet variations are also based on PyTorch detection models. We 
always use the pretrained versions of the detection models. The Mask R- 
CNN  is  pretrained  on  COCO  2017train  dataset.  The  ResNets  are  pre-
trained on Kinetics-400 dataset. We use these PyTorch models because 
they allow more flexibility than other implementations. They are better 
adjusted  to  the  PyTorch  training  functions  and  are  well-arranged. 
Moreover,  the  PyTorch  detection  models  do  not  have  other  de-
pendencies (e.g. special libraries) unlike other implementations. 

4.3. Object detection

4.4. Action recognition 

The three ResNet variants are trained for 40 epochs starting with an 
initial learning rate of 0.001. The learning rate is decreased every 10 
epochs by multiplying it with a γ = 0.1. For optimization we utilize the 
Stochastic  Gradient  Descent  (SGD)  with  a  momentum  of  0.9  and  a 

EcologicalInformatics61(2021)1012158F. Schindler and V. Steinhage

We use a pretrained backbone for FGFA. The backbone is extracted 
from  a  Mask  R-CNN  network  trained  on  the  segmentation  dataset. 
During the training process FGFA trains only the head and the RPN. We 
implement  the  flow  network  in  the  FGFA  architecture  with  a  SPyNet 
(Ranjan and Black (2017)). Other popular choices are FlowNet (Doso-
vitskiy et al. (2015)) and FlowNet 2.0 (Ilg et al. (2017)). SPyNet is more 
lightweight than the FlowNets. It uses 96% less parameters than Flow-
Net. Therefore it is more efficient in an embedded environment like our 
FGFA architecture. Moreover, the results of SPyNet are more accurate 
than the results of the FlowNets. 

4.3.1. Data augmentation for segmentation and detection

3.2.2. SlowFast architecture 

In this section we follow Feichtenhofer et al. (2019). The key idea of 
SlowFast  networks  is  using  two  pathways  for  the  video  input,  a  Slow 
pathway and a Fast pathway. The Slow pathway works on a low frame 
rate  and  low  temporal  resolution  for detecting  spatial  semantics. The 
Fast pathway uses a high frame rate to capture motion and the temporal 
aspects  in  the  video.  Simultaneously  the  Fast  pathway  reduces  its 
channel capacity so it becomes lightweight, but is still able to learn the 
temporal information of the video. The backbone for the pathways can 
be implemented by different networks. The best results achieve ResNets. 
SlowFast  is  a  single-stream  architecture  that  works  on  two  different 
frame rates. 

The Slow pathway uses a large temporal stride τ on the input frames. 

The pathway considers one out of τ frames from the video.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
All programs use Python 3 and PyTorch for building and training the networks. The Mask R-CNN model is built around the PyTorch detection model of Mask R-CNN. For the implementation of FGFA, the PyTorch models for the backbone, the RPN, and the head of the implementation of Mask R-CNN model are used. The three ResNet variations are also based on PyTorch detection models. These PyTorch models are chosen due to their flexibility, better adjustment to PyTorch training functions, lack of dependencies, and being well-organized.