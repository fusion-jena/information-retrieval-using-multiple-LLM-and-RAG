Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Using supervised classification, BirdNET returned the highest accu-
racy of 98.2% ± 0.85 SD at 0 m. MFCCs and BirdNET performed simi-
larly at closer distances while MFCCs returned the highest classification 
accuracies at farther distances (> 150 m) with a minimum classification 
accuracy  of  39.8%  ± 4.3  SD  at  300  m.  In  comparison  with  BirdNET, 
VGGish and Wav2Vec 2.0 performed less well with VGGish and Wav2-
Vec 2.0 returning maximum accuracies of respectively 76.4% ± 2.3 SD 
and 52.7% ± 3 SD at 0 m. Acoustic indices performed the least well with 
classification accuracies ranging between 17.1% ± 2.8 SD and 37.9% ±
2.5  SD.  The  classification  accuracies  decrease  across  distance  for  all 
feature extraction methods (Fig. 4).

Fig. 4. Mean and 95% confidence intervals of classification accuracy over 20 random iterations for each of the five feature types as a function of distance. Feature 
embeddings  from  the  BirdNET  algorithm  performed  comparably  to  MFCCs  for  calls  recorded  at  closer  distances,  whereas  embeddings  from  the  VGGish  model, 
Wav2Vec2 model, and the acoustic indices performed worse. The lack of visible confidence intervals for some points indicates a very narrow confidence interval. 

Fig. 5. Mean and 95% confidence intervals of Normalized Mutual Information (NMI) for the five feature types as a function of distance for affinity propagation 
clustering (A) and HDBSCAN (B). The lack of visible confidence intervals for some points indicates a very narrow confidence interval. 

Successful clustering was obtained through the use of MFCCs as a feature 
extraction technique, and HDBSCAN for unsupervised classification at 
distances ≤150 m (Fig. 6).

of length 2048. Model and code was run in Python version 3.10 based on 
the code and methods presented in: https://github.com/kahst/BirdNET 
-Analyzer.

We expected higher performance of the embeddings, but a possible 
limitation to our study may be the use of pre-trained CNNs. This may 
have limited the potential performance of using embedding from neural 
networks.  Interestingly,  higher  classification  accuracy was  seen  when 
using  BirdNET,  a  CNN  trained  on  audio  data  of  bird  vocalizations  in 
comparison  with  VGGish  and  Wav2Vec  2.0,  two  models  trained 
respectively on a vast Youtube audio dataset and a human speech audio 
dataset. This suggests that training a model with data input of gibbon 
vocalizations might result in an even better performance of neural net-
works for individual gibbon discrimination. However, such data training 
requires a large dataset and is very computationally costly, hence why 
we chose to test pre-trained CNNs.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The primary metric used to evaluate the performance of the deep learning models in this context is classification accuracy. Classification accuracy is calculated by dividing the number of correct predictions made by the total number of predictions made. For instance, BirdNET achieved the highest classification accuracy of 98.2% ± 0.85 SD at 0 meters. Similarly, other models like MFCCs, VGGish, and Wav2Vec 2.0 were also evaluated based on their respective classification accuracies. Additionally, Normalized Mutual Information (NMI) was used as another evaluation metric for assessing the performance of different feature types as a function of distance for affinity propagation clustering and HDBSCAN.