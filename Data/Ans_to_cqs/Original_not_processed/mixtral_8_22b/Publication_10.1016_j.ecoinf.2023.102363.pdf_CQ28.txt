Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Models on Google Cloud Platform. Apress, Berkeley, CA.  

Matwin, S., 2023. Adapting deep learning models to new acoustic environments-A 
case study on the North Atlantic right whale upcall. Ecol. Informa. 77, 102169. 

Pijanowski, B.C., Villanueva-Rivera, L.J., Dumyahn, S.L., Farina, A., Krause, B.L., 

Napoletano, B.M., Gage, S.H., Pieretti, N., 2011. Soundscape ecology: the science of 
sound in the landscape. BioScience 61 (3), 203–216. 

Roch, M.A., Soldevilla, M.S., Hoenigman, R., Wiggins, S.M., Hildebrand, J.A., 2008. 

Comparison of machine learning techniques for the classification of echolocation 
clicks from three species of odontocetes. Can. Acoust. 36 (1), 41–47. 

Roch, M.A., Klinck, H., Baumann-Pickering, S., Mellinger, D.K., Qui, S., Soldevilla, M.S., 
Hildebrand, J.A., 2011. Classification of echolocation clicks from odontocetes in the 
Southern California bight. J. Acoust. Soc. Am. 129 (1), 467–475.

The model is constructed using the EfficientNet B0 network (Tan and 
Le, 2019) which had been trained for generic image classification. The 
EfficientNet feature extraction layers are frozen (transfer learning) with 
only the weights of the final dense classification layers updated during 
training.  Training  was  conducted  within  the  Google  Collaboratory 
‘Colab’  platform  (Bisong,  2019),  using  the  Tesla  K80  GPU,  accessed 
through  cloud  computing.  An  Adam  optimizer  was  used  to  control 
gradient descent during training (Kingma and Ba, 2014), with parame-
ters set to: learning rate of 0.001, decay factor of 0.75 and a step size of 

EcologicalInformatics78(2023)1023632E.L. White et al.

2.2. Model fine-tuning 

To  fine-tune  the  base  model  with  Gulf  of  Mexico  data  the  feature 
extractor remains frozen. Models are trained with the same parameters 
as the base model but we use a cyclical learning rate of 0.0004 and is set 
to run for 50 epochs, with early stopping set to deploy if the validation 
loss does not improve within 10 epochs. A dropout rate of 0.2 is used 
during  fine-tuning,  and  DropConnect  is  employed.  Drop  out  layers 
randomly  discard  the  output  of  the  hidden  nodes  during  training, 
DropConnect randomly discards the input of the hidden layer (Sun et al., 
2022). 

2.2.1. Data acquisition

Padovese, B., Kirsebom, O.S., Frazao, F., Evers, C.H., Beslin, W.A., Theriault, J., 

automated marine big data analysis. In: 2018 IEEE 30th International Conference on 
Tools with Artificial Intelligence (ICTAI). IEEE, pp. 130–136. 

Bergler, C., Schr¨oter, H., Cheng, R.X., Barth, V., Weber, M., N¨oth, E., Hofer, H., Maier, A., 
2019. ORCA-SPOT: an automatic killer whale sound detection toolkit using deep 
learning. Sci. Rep. 9 (1), 1–17. 

Bermant, P.C., Bronstein, M.M., Wood, R.J., Gero, S., Gruber, D.F., 2019. Deep machine 
learning techniques for the detection and classification of sperm whale bioacoustics. 
Sci. Rep. 9 (1), 1–10. 

Best, P., Ferrari, M., Poupard, M., Paris, S., Marxer, R., Symonds, H., Spong, P., 

Glotin, H., 2020, July. Deep learning and domain transfer for orca vocalization 
detection. In: 2020 International Joint Conference on Neural Networks (IJCNN). 
IEEE, pp. 1–7. 

Bisong, E., 2019. Google colaboratory. In: Building Machine Learning and Deep Learning

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model was deployed using the Google Colaboratory 'Colab' platform, which provides access to a Tesla K80 GPU through cloud computing. This information can be found in the second paragraph under section 2.1. Model construction.