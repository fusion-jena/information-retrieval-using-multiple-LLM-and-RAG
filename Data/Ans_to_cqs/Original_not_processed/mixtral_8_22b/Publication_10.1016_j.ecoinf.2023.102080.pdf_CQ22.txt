Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Measuring predictive accuracy with metrics such as AUC’, maxTSS, 
or  CBI  was  helpful to  quantitatively compare  and rank  model perfor-
mances. However, these metrics may capture only a partial picture of 
the quality of the model. Depending on the focus of the SDM study (e.g., 
conservation,  climate  change,  biological  invasions,  ecological  niche 
modelling,  etc.),  other  model  outputs,  such  as  response  curves  and 
mapped predictions, should also be checked (Araujo et al., 2019; Zurell 
et al., 2012; Zurell et al., 2020). In addition, if the covariate selection is a 
key  feature  of  the  SDM  process,  all  the  other  important  steps  with  a 
potential  influence  on  the  predictions,  including  the  complexity  and 
tuning of model parameters, should also be carefully evaluated (Brun 
et al., 2020; Merow et al., 2014; Moreno-Amat et al., 2015).

windows of 100-m, 500-m, or 1-km radii), (ii) the category level (e.g.: 
within thematic covariate categories), and (iii) using all remainders.

We compared the average computation time needed for (i) running 
the overall covariate selection procedure and model fitting steps under 
each of the three main procedures, and (ii) model fitting only. Analyses 
were run using a 10-core central processing unit strategy with AMD® 
EPYC 7402 on the University of Lausanne HPC cluster. 

EcologicalInformatics75(2023)1020804A. Adde et al.

3.4.3. Computation time 

The overall average computation time for running both the covariate 
selection procedure and model fitting steps was ~1.5 time higher with 
the embedded procedure compared to the two alternatives (Fig. 4.A), 
which is the same order of magnitude as the gain in model accuracy. 
However, models from the embedded procedure were faster to fit (Fig. 4. 
B), presumably because the more relevant the covariate set, the faster 
the algorithms converged. 

4. Conclusion

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The authors do not explicitly mention any specific deep learning model evaluation metrics like accuracy, precision, or recall. Instead, they discuss evaluating Species Distribution Models (SDMs) using metrics such as Area Under Curve (AUC'), Maximum True Skill Statistic (maxTSS), and Continuous Boyce Index (CBI). These metrics help quantify and compare model performances. However, it is essential to note that these metrics might only provide a partial view of the model's quality. Other aspects, such as response curves and mapped predictions, should also be considered based on the focus of the SDM study. Additionally, factors influencing predictions, like covariate selection, model complexity, and parameter tuning, must be thoroughly examined. The paper does not directly address deep learning model evaluation metrics but focuses on assessing SDMs through various methods.