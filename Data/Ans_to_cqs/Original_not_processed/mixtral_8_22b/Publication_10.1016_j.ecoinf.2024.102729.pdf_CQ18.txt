Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

study,  the  dataset  was  randomly  divided  into  two  subsets,  the  first  one  was  used  as  a  training 

dataset  to  learn  the  optimal  model  structure  and  the  second  as  a  validation  dataset  to  test  its 

performance;  75%  of  the  data  were  devoted  to  model  training  and  25%  to  testing.  Given  the 

well-documented robustness of RF algorithms to randomly receive training data from subsets and 

establish models with high predictive capacity, we opted for random (instead of cluster) sampling 

with  one  major  condition  to  maintain  the  covariance  structure  among  the  predictor  variables 

relatively intact between the training and testing datasets. 

,(),,,(,)maxlogmin(,)xyBnIXYxyMICXYxy),,,(*yxYXI 
Journal Pre-proof

RF  modeling  can  generally  be  resilient  to  preprocessing  burdens  (e.g.,  no  feature  scaling, 

robustness  to  outliers),  flexible  with  multi-dimensional  data,  sensitive  in  elucidating  complex

with  the  testing  dataset  (Fig.  5  and Table S2). The RF  model  with  25  trees  as  hyper-parameters 

Journal Pre-proof

achieved the highest accuracy. In autumn, the optimized RF model included three input variables: 

EC, TN, and WZ. It displayed excellent performance with adj_R2 = 0.992, RMSE = 1.505, MAE = 

0.859, and KGE = 0.972 for the training data, and adj_R2 = 0.863, RMSE = 7.182, MAE = 3.598, 

and KGE = 0.824 for the testing data (Fig. 5 and Table S2). The winter RF model was optimized 

with two variables: WZ and WT. It demonstrated good performance with adj_R2 = 0.977, RMSE = 

0.620,  MAE  =  0.432,  and  KGE  =  0.938  for  training  data,  and  adj_R2 =  0.840,  RMSE  =  1.567, 

3.4. Relative Importance of Model Features 

season, the RF model with 25 trees as hyper-parameters achieved the highest accuracy. 

The selected predictor variables exerted different control (described as “Feature Importance”)

the Nanji wetland of Poyang Lake.   

Fig.  3:  Maximal  Information  Coefficient  values  between  the  nine  environmental  covariates  and 

chlorophyll  a  concentrations  for  (a)  the entire  study  period,  using  eleven  time  lags  (0-10  days), 

and (b) each of the four seasons.     

Fig.  4:  Random  forest  performance,  as  measured  by  adj_R2,  RMSE,  MAE,  and  KGE,  with  the 

training and testing/validation datasets for different time lags. The gray columns and orange line 

represent  the  adj_R2  and  KGE  values,  while  the  blue  solid  and  dashed  lines  correspond  to  the 

RMSE and MAE values, respectively.   

Fig. 5: Predictions of Chl a concentrations by the optimal RF model per season. 

Fig. 6: Relative importance of the predictor variables included in the optimal random forest model 

Journal Pre-proof

Fig. 7: GAM analysis: Non-linear relationships between the two key influential factors and Chl a

optimized RF model results at t = 5 days showed that COD, WZ, and WT were the most important 

predictors.  The  RF  model  at  t  =  5  days  with  50  trees  as  hyper-parameters  showed  the  highest 

Journal Pre-proof

The  optimized  RF  model  results  for  the  spring  season  indicated  that  the  most  important 

predictors  were  DO  and  NTU.  The  model  showed  good  performance  with  an  adj_R2 =  0.968, 

RMSE = 4.906, MAE = 2.496, and KGE = 0.942 against the training dataset, and adj_R2 = 0.878, 

RMSE = 8.606, MAE = 5.360, and KGE = 0.941 against the testing dataset (Fig. 5 and Table S2). 

Among the hyper-parameters tested, the RF model with 5 trees achieved the highest accuracy. For 

the summer, the optimized RF model identified three important predictors: WZ, TP, and COD. The 

model performed well showing adj_R2 = 0.980, RMSE = 0.596, MAE = 0.424, and KGE = 0.933 

with the training dataset, and adj_R2    = 0.933, RMSE = 1.016, MAE = 0.865, and KGE = 0.912

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the dataset was randomly divided into two subsets - a training dataset and a validation dataset. The training dataset comprised 75% of the total data and was used to train the model and determine the optimal model structure. On the other hand, the remaining 25% of the data served as the validation dataset to evaluate the model's performance. To ensure the robustness of the Random Forest (RF) algorithm, which is known to perform well even when trained on randomly sampled subsets of data, random sampling was employed instead of clustering. However, it was crucial to preserve the covariance structure among the predictor variables relatively intact between the training and testing datasets. This approach allowed for monitoring the model performance during training without compromising the integrity of the data or introducing bias.