Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.1. Operational workflow 

The whole process of data acquisition and processing, reported in the 
following  section,  is  called  Knowledge  Discovery  in  Databases  (KDD) 
(Kotu and Deshpande, 2015); it is a process of identifying patterns or 
relationships  within  a  dataset  useful  to  make  important  decisions 
(Hammad and AbouRizk, 2014). This process does not involve applying 
data-mining  techniques  but  requires  more  actions  to  reach  the  final 
result. 

The KDD sequence applied in our case study included the following 

steps:  

• identification of the aim for a specific study area;  
• pre-selection of useful data to achieve the objective;  
• analytical determinations for the detection of PPPs in Puglia surface 

water bodies;  

• optimisation and elaboration of the obtained results through:

in Fig. 2. 

The  numerical  values  of  some  parameters  (Tan  et  al.,  2019)  were 
calculated and provided as measures of the association values to explain 
the data mining results. The support parameter measures the abundance 
or  frequency  (often  interpreted  as  important)  of  a  set  of  items  in  a 
database. The value of the support parameter is given by the ratio be-
tween  the  number  of  times  an  item  appears  and  the  total  number  of 
items. We refer to a set of molecules as a “set of frequent molecules” if 
support  exceeds  a  specified  minimum  threshold  we  can  identify.  In 
general, the threshold depends on the size of the dataset.

The  user  must  decide  the  minimum  support  threshold  useful  for 
solving the assumed problem and apply the join and prune steps to the 
itemsets. In our case study, an itemset is represented by every sample's 
analytical  results,  whereas  a  k-itemset  represents  a  sample  subset  of 
various PPPs. Therefore, for each sample, there may be many k itemsets 
(with k ranging  from 1 to  n, where n  is the  number of analytical de-
terminations for a single sample). For these k-itemsets, we applied the 
Apriori algorithm to identify recurring patterns in the association rules. 
Frequent itemsets refer to itemsets whose relative frequency exceeds the 
pre-established minimum threshold the operator identifies according to 
the problem to be solved. The simplified procedures performed by the 
algorithm are as follows:

In short, data mining ensures that starting from “cryptic” information 
scattered without apparent order in a database, we arrive at knowledge 
that can be exploited for various purposes (Kotu and Deshpande, 2015). 
It is also possible to implement (Online document, 2022b) an automatic 
elaboration  workflow  with  open-source  software  without  using  an 
operator who reprocesses the data each time. Data mining can be sup-
ported  by well-known  and  widely applied  data  processing techniques 
such as verifying or interpreting results (Hamdi et al., 2022).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, there isn't any direct mention of the criteria used to determine when training is complete, such as a validation loss plateau. However, the text discusses the concept of data mining and its application in the form of the Apriori algorithm.

Data mining involves extracting valuable insights from large datasets, which often includes machine learning models. When training these models, one common criterion to determine when training should stop is indeed the validation loss plateau. A validation loss plateau occurs when the model's performance on the validation dataset stops improving significantly over several epochs. At this point, further training might lead to overfitting, causing the model to perform poorly on unseen data.

However, since the context doesn't explicitly state the use of machine learning models or provide details about their training, I cannot definitively confirm that a validation loss plateau is used as a stopping criterion in this particular scenario.