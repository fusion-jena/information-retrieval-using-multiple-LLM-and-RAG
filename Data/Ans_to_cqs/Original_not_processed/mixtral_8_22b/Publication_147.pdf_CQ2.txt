Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1. List of input variables in the XGBoost model (XGB) and convolutional neural network
(CNN) models. Each variable lists its respective data source, equation, description, and, if needed,
citation. For information on Sentinel-2 band information not listed in the table, see:
[66] and
https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial.

Variable

Data Source

Model

ARI

Sentinel-2

XGB/CNN

Band 2
Band 3
Band 4
DEM

NDVI

dNDVI

NDWI

POLr

PSRI

Sentinel-2
Sentinel-2
Sentinel-2
ALOS

Sentinel-2

Sentinel-2

Sentinel-2

Sentinel-1

Sentinel-2

CNN
CNN
CNN
CNN

CNN

XGB

CNN

XGB

CNN

REIP

Sentinel-2

XGB/CNN

Equation
(cid:17)
(cid:16) B8
(cid:16) B8
B3
B2

–

(cid:17)

-
-
-
-
(B8− B4)
(B8 + B4)

Description

Keywords: wetlands; Sentinel-1; Sentinel-2; Google Earth Engine; remote sensing; Alberta;
segmentation convolutional neural nets; XGBoost; land cover; SAR; machine learning

1. Introduction

Machine learning—a method where a computer discovers rules to execute a data processing
task, given training examples—can generally be divided into two categories: Shallow learning and
deep learning methods [1]. Deep learning uses many successive layered representations of data
(i.e., hundreds of convolutions/ﬁlters), while shallow learning typically uses one or two layered
representations of the data [1]. Deep learning has shown great promise for tackling many tasks such as
image recognition, natural language processing, speech recognition, superhuman Go playing, and
autonomous driving [1–3].

Remote Sens. 2020, 12, 2; doi:10.3390/rs12010002

www.mdpi.com/journal/remotesensing

CNNs 140 trained on a patch-level learn low- and high-level features from the remote sensing data. For example, 141 waterline edges which delineate marshes and open water may only need simple edge detection 142 convolution filters, while fens and bogs may be differentiated by subtle variations in texture or color 143 (i.e., visible flow lines in fens). Within the last couple of years, a number of studies have attempted to 144 use deep learning for wetland mapping in Canada over small areas and have achieved promising 145 results when compared to alternative shallow learning methods [20,51,52]. 146 With the current status of machine learning and the history of Canadian wetland mapping in 147 mind, we propose a simple goal for this study: To compare deep learning (CNN) classifications with 148 shallow learning (XGBoost) classifications for wetland class mapping over a large region of Alberta, 149 Canada (397,958 km2) using the most up-to-date, open source, fusion of data sources from

5. Conclusions

The goal of this study was to compare shallow learning (XGB) and deep learning (CNN) methods
for the production of a large-scale spatial wetland classiﬁcation. We encourage readers to view both
products via this link: https://abmigc.users.earthengine.app/view/cnn-xgb, and one of the products
can be downloaded via this link: https://bit.ly/2X3Ao6N. A comparison of the two products to
photo-interpreted validation data showed that CNN products outperform the shallow learning (XGB)
product in terms of accuracy by about 5–8%. The CNN product achieved an average overall accuracy
of 80.8% with a mean F1-score of 0.58. When compared to a small data set (n = 22) of ﬁeld data, the
results were inconclusive and both data sets showed little ability to distinguish between fen and bogs.
This ﬁnding could just be due to the small, spatially constrained data or it could highlight the mismatch
between on the ground conditions and large-scale landcover classiﬁcations.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it is not explicitly stated what specific data format is used in the deep learning pipeline. However, since the study focuses on comparing deep learning (Convolutional Neural Networks - CNN) and shallow learning (Extreme Gradient Boosting - XGB) methods for producing a large-scale spatial wetland classification, it can be inferred that the data format used in the deep learning pipeline is likely related to remote sensing imagery. This assumption is supported by the fact that the input variables mentioned in Table 1 include various bands from Sentinel-2 satellite imagery, Digital Elevation Model (DEM) data, Normalized Difference Vegetation Index (NDVI), and other similar remote sensing derived indices. Therefore, it can be concluded that the data format used in the deep learning pipeline is primarily based on remote sensing imagery.