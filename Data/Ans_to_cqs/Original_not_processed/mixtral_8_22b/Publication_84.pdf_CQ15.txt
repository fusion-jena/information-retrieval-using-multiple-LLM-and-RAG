Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

This is the ﬁrst study to our knowledge to investigate the pheno-
logical features in improving the performance of deep learning. As re-
vealed in our results, we have seen great potential in developing phe-
nological knowledge based deep learning methods. Recent literature
has documented the applications and beneﬁts of deep learning, a new
branch of machine learning, in various ﬁelds (LeCun et al., 2015).
However, it is still a controversial topic whether deep learning is more
suitable than traditional machine learning methods for Landsat image
classiﬁcation (Heydari and Mountrakis, 2018; Li et al., 2016). Never-
theless, this study aims to evaluate the hypotheses that applying phe-
nological knowledge as input data of deep learning can improve the
performance in the detection of invasive S. alterniﬂora. A comparison
experiment between SAE and SVM with six diﬀerent types of Landsat
images was conducted (see Table 2). The best performance was

achieved with Ppf-CM based SAE method, suggesting SAE beneﬁted
more than SVM from combining data in the two phenological stages
using Ppf-CM (Table 4). This was mainly because, compared to the
traditional machine learning method (SVM), deep learning method
(SAE) can easily capture and exploit more complex information with its
deep network structure and strong self-learning ability (Penatti et al.,
2015; Xie et al., 2015).

The parameter setting method of SVM in this study was done ac-
cording to the sensitivity analysis method in (Heydari and Mountrakis,
2018). The “kernelType” was set to “RBF” (Gaussian function). For the
“gamma” parameter in the RBF kernel, we tested values of 0.01, 0.1,
0.5, 1, 2, 5, 10, 25, 50, 100, and 300. For the “cost” parameter in SVM,
we tested values of 0.1, 0.5, 1, 2, 5, 10, 25, and 50. We randomly se-
lected 50% reference data for parameter optimization. By selecting the
highest overall accuracy achieved from diﬀerent parameter combina-
tions, this study set “gamma” and “cost” to 2 and 10 respectively.

et al., 2015; Zhang et al., 2016). A growing number of studies to date
(e.g. Heydari and Mountrakis, 2018; Ishii et al., 2015; Li et al., 2016)
have been reported on classiﬁcation of remote sensing images at
moderate spatial resolution with deep learning. For example, deep
learning method (Stacked AutoEncoder, SAE) and traditional machine
learning methods (e.g. Support Vector Machine, SVM) were compared
to map African land-cover (Li et al., 2016). It was reported that SAE
achieved a higher classiﬁcation accuracy than SVM. However, in one of
the latest developments, Heydari and Mountrakis (2018) conducted an
experiment on land cover classiﬁcation using the deep learning method
(SAE) with 26 Landsat images. Surprisingly, the results indicated that
the classiﬁcation accuracy of deep learning was not as good as tradi-
tional machine learning methods, e.g. SVM. Therefore, it is still a well-
worthy topic to investigate which kind of methods is better, deep

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the given context does not provide specific details about the optimization techniques used in the deep learning pipeline, such as Stochastic Gradient Descent (SGD) or Adam. Instead, the text focuses on comparing the performance of Stacked AutoEncoders (SAE) and Support Vector Machines (SVM) for detecting invasive Spartina alterniflora using Landsat satellite imagery.

In the context, the authors mention tuning parameters for the SVM model by testing different combinations of 'gamma' and 'cost' values. They use a sensitivity analysis method described in another paper (Heydari and Mountrakis, 2018) and select the highest overall accuracy achieved from different parameter combinations. In this case, they set 'gamma' and 'cost' to 2 and 10, respectively.

While the context does not explicitly discuss optimization techniques like SGD or Adam, these techniques are commonly used in training deep learning models like SAEs. Optimization algorithms help minimize the loss function during the training process, enabling the model to learn effectively from the input data. Without explicit mentions in the provided context, however, we cannot definitively state which optimization technique was employed in their deep learning pipeline.