Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Pytorch (Paszke et al., 2019) ML framework for deep learning (CNNs). 
These libraries also include tools for data pre-processing, model selec-
tion and evaluation. To keep our model training and analysis pipelines 
comparable, we use skorch, a scikit-learn compatible neural network li-
brary that wraps PyTorch. This allows the same scikit-learn training and 
evaluation procedure to be used for both models. Skorch is also helpful 
for end-users in CNN training, as it has a clear and simple interface. It 
only requires end-users to add the prepared datasets, model and specify 
the associated hyperparameters (Table 4). Documentation for the entire 
machine learning pipeline can be found at (PyTorch, 2023) for Pytorch 
(Paszke  et  al.,  2019;  scikit-learn,  2023)  for  scikit-learn  and  (skorch, 
2022)  for  skorch.  Commercial  restrictions  apply  to  the  availability  of 
data  used  in  this  work.  However,  links  to  public  code  examples  of

2.2.3. Model preparation 

The VGG16 network was sourced from the torch library and all layers 
frozen, preventing any further training (updates to model parameters), 
see Table 3. We then duplicated this network to provide a foundation for 
each modelling approach. For our CNN þ SVM modelling approach we 
kept the architecture up to the first FC layer (FC1), creating a feature 
extractor (Fig. 2). We then paired it with an SVM, sourced from the scikit- 
learn library. We evaluate two types of SVM: a linear SVM and a non- 
linear SVM, known as a Radial Basis Function (RBF) (Fig. 3). An RBF 
SVM is a good default choice, as it can find both a linear and non-linear 
hyperplanes at high dimensions. 

For  the  CNN  approach  however,  we  use  the  full  VGG16  network, 
leaving the feature extractor and classifier intact. In its frozen state the

2.2.5. Classification 

Each  ML  approach  requires  hyperparameters  to  classify  imagery, 
which when optimized during training can increase model performance, 
see  Table  4  for  a  hyperparameter  glossary.  Given  the  computational 
efficiency of the SVMs and the few hyperparameters required, each of 
these can be optimized simply and relatively quickly (subject to dataset 
size)  during  a  k-fold  (k = 5) cross-validated  fine  grid-search  on  the 
training  data.  For  our  CNN  þ SVM  method,  we  followed  hyper-
parameter  recommendations  by  (Hsu  et  al.,  2016),  authors  of  the 
LIBSVM library (Chang and Lin, 2011). For our non-linear RBF SVM we 
searched  hyperparameters  C = 23, 23.25, …, 27  and  γ = 2
(cid:0) 13  & 
(cid:0) 11. For the linear SVM, we used the same hyperparameter search for 
2
its sole parameter C. We also looked at the RBF and linear SVM with 

(cid:0) 15, 2

Fig. 3. A diagram of various support vector machines.

EcologicalInformatics81(2024)1026194C.A. Game et al.                                                                                                                                                                                                                                

Fig. 2. Infographic of the ML workflows (CNN & CNN þ SVM) used in this study.  

VGG16 network cannot be trained, we therefore unfroze (replaced) the 
final  FC  layers  (FC2  &  FC3)  to  re-initialize  the  weights  for  training. 
Training only these FC layers enables comparison to the CNN þ SVM 
approach in which they have been replaced with an SVM classifier. We 
also reduced the number of output nodes in FC3 from 1000 (number of 
ImageNet  classes)  to  3,  to  prepare  the  CNN  to  classify  the  3  habitat 
classes. 

2.2.4. Feature extraction & visualisation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The machine learning pipeline uses a Convolutional Neural Network (CNN) called VGG16 as the base model. The VGG16 network is sourced from the Torch library and serves as the foundation for each modeling approach. For the CNN + SVM modeling approach, the architecture is kept up to the first fully connected layer (FC1), creating a feature extractor. Then, it is paired with a Support Vector Machine (SVM) sourced from the Scikit-Learn library. Two types of SVM are evaluated: a linear SVM and a non-linear SVM, known as a Radial Basis Function (RBF). On the other hand, for the pure CNN approach, the full VGG16 network is utilized, leaving the feature extractor and classifier intact.