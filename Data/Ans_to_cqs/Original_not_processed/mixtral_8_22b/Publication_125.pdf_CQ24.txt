Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Training Run-Time

Prediction Run-Time

VGG16
Xception
ResNet50
DenseNet121
The proposed model

22 min 27 s
21 min 26 s
30 min 8 s
18 min 34 s
16 min 43 s

0.803 s
0.827 s
1.835 s
4.134 s
0.976 s

5.5. Discussion

Recent years have seen increasing concerns about protecting the privacy of conﬁdential
information when processing data using models. This leads to the need for cryptographic
techniques to solve privacy concerns in data-driven models. Several PPDL techniques have
been proposed in the literature to solve these concerns. This research is, to the best of our
knowledge, the ﬁrst work that investigates PPDL for satellite image classiﬁcation.

The motivation driving this speciﬁc research project is to link two cutting-edge re-
search topics, which are DL and privacy. Indeed, the progress of machine learning (ML)
and its subﬁeld of deep learning (DL) need not come at the expense of privacy or data
security. Therefore, this research work proposes a powerful approach based on PPDL
utilized on big satellite images in order to maintain anonymity and safeguard privacy
related to data. Our main contribution is to apply PPDL for satellite images’ data, which,
to the best of our knowledge, is an approach that has not been proposed or attempted
anywhere in the literature. In particular, the contributions of this study are:

•

•

•

2.2. Privacy-Preservation Deep Learning

Several privacy-preservation techniques focus on allowing different entities to train
DL models without revealing secure data. The existing privacy-preserving techniques

Remote Sens. 2021, 13, 2221

5 of 26

already developed in this ﬁeld, including encryption and differential privacy, are reviewed
in this section.

2.2.1. Privacy-Preservation through Encryption

Cryptographic methods could be used to conduct DL training and testing on en-
crypted data [9]. Such methods allow for privacy protection, but specialized techniques
are needed to do useful statistical analysis on encrypted data [27]. To achieve PPDL, the
most commonly used cryptographic methods are homomorphic encryption, secret sharing,
and secure multi-party computation.

Homomorphic Encryption

Keywords: privacy-preserving deep learning; deep learning; remote sensing; privacy-preservation;
convolutional neural network; homomorphic encryption; paillier scheme

Citation: Alkhelaiwi, M.; Boulila, W.;

Ahmad, J.; Koubaa, A.; Driss, M. An

Efﬁcient Approach Based on

Privacy-Preserving Deep Learning for

Satellite Image Classiﬁcation. Remote

Sens. 2021, 13, 2221. https://doi.org/

10.3390/rs13112221

Academic Editors: Do-Hyung Kim,

Anupam Anand, Joseph Bullock and

Miguel Luengo-Oroz

Received: 14 April 2021

Accepted: 3 June 2021

Published: 6 June 2021

Publisher’s Note: MDPI stays neutral

with regard to jurisdictional claims in

published maps and institutional afﬁl-

iations.

1. Introduction

Copyright: © 2021 by the authors.

Licensee MDPI, Basel, Switzerland.

This article is an open access article

distributed under

the terms and

conditions of the Creative Commons

Attribution (CC BY) license (https://

creativecommons.org/licenses/by/

4.0/).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no direct information regarding strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, it can be inferred from the context that the paper focuses on applying privacy-preserving deep learning (PPDL) techniques to satellite image classification. These techniques include encryption and differential privacy, with specific mention of homomorphic encryption, secret sharing, and secure multi-party computation. While these techniques address privacy concerns, they do not directly relate to handling randomness within the deep learning pipeline.

To manage randomness in the deep learning pipeline, common strategies include setting fixed seeds for various libraries (like NumPy, TensorFlow, PyTorch), ensuring consistent results across multiple runs. Additionally, some researchers may choose to report average performance over several runs with different initializations to account for variability due to randomness. However, these strategies are not explicitly mentioned in the provided context.