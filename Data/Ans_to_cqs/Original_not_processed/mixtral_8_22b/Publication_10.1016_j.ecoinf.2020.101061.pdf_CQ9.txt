Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2. Deep learning

We used our previously developed algorithm for RGB-based tree
identiﬁcation, which was used at a single site (Weinstein et al., 2019).

beyond the NEON sites may be useful for many applied problems. It is
currently unknown to what extent features learned from the 0.1 m re-
solution data used here can be applied to lower resolution satellite data
(Karlson et al., 2014) or higher resolution UAV data (Brieger et al.,
2019). Cross resolution training has not been fully explored in en-
vironmental remote sensing, but Li et al. (2018) recently showed that
deep learning networks can learn scale invariant land classiﬁcations
that can be matched among data sources. Given the ability to collect
virtually unlimited pretraining data using our data generation ap-
proach, NEON sites can be seen as an ideal training sources for RGB tree
models that could then be applied to other data types.

Collecting a suﬃcient number of training samples will often be a
bottleneck in developing supervised methods in airborne imagery. It is
therefore useful to test the number of local training samples needed to
achieve maximum performance. We performed a sensitivity study by
training models using diﬀerent proportions of training data. We se-
lected 5%, 25%, 50% and 75% of the total hand-annotations to com-
pare to the full dataset for the within-site results for each site. We reran
this experiment ﬁve times to account for the random subsampling of
annotations. In addition, we ran the evaluation plots for the pretraining
model only (i.e. 0% hand-annotated data) to assess whether the addi-
tion of hand-annotated data improved the within-site pretraining.

3. Results

Ecological Informatics 56 (2020) 101061

Contents lists available at ScienceDirect

Ecological Informatics

journal homepage: www.elsevier.com/locate/ecolinf

Cross-site learning in deep learning RGB tree crown detection
Ben G. Weinsteina,⁎

, Sergio Marconia, Stephanie A. Bohlmanb, Alina Zarec, Ethan P. Whitea

T

a Department of Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, USA
b School of Forest Resources and Conservation, University of Florida, Gainesville, FL, USA
c Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA

A R T I C L E I N F O

A B S T R A C T

Keywords:
Tree crown detection
RGB deep learning
Object detection
Airborne LiDAR

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The article does not provide information on where the data repository of the deep learning pipeline is available. The authors mention their previous work (Weinstein et al., 2019), but they do not specify if the data repository is accessible through platforms like Zenodo, Figshare, Dryad, or GBIF. Therefore, it is recommended to contact the corresponding author or check the supplementary materials section of the mentioned paper for more details about the availability of the data repository.