Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.7. Accuracy assessment 

The  model  with  the  best  accuracy  was  retained  after  training  the 
three main DNN models for 200 epochs. An overall accuracy measure 
was conducted to evaluate the accuracy level of our final DNN model 
using  our  validation  dataset.  A  confusion  matrix  was  produced  to 
highlight the accuracy of each class. Three quality metrics were added: 
Overall  Accuracy  (OA),  Producer  Accuracy  (PA),  and  User  Accuracy 
(UA). 

Overall accuracy is the ratio of the sum of correctly classified pixels 
to  the  total  number  of  pixels  in  the  test  dataset.  While  the  producer 
accuracy refers to the accuracy from the point of view of the mapmaker, 
the user’s accuracy represents the probability that a pixel classified in 
each  category  corresponds to  the  actual  category  on  the  ground.  The 
performance  of  our  final  DNN  model  was  evaluated  using  the  kappa 
coefficient of agreement (Landis and Koch, 1977):

A search space of the primary hyperparameters was defined. Opti-
mization  algorithms  were executed to  find  the  highest  accuracy from 
1,788,160  hyperparameter  combinations.  Our  model  was  trained  for 
200 epochs for each trial to find three DNN architectures that were used 
to  build  three  models  and  train  them  for  the  entire  dataset  for  1000 
epochs (Table 2).

3.1. DNN Architecture optimization 

The  optimization  process  considers  three  main  factors.  The  main 
factor is the model’s accuracy when tested using the validation dataset. 
Computation time and costs is the second deciding factor, as both can 
add up over time with the increasing complexity of models and datasets. 
Efficient  methods  for  hyperparameter  optimization  are  necessary  to 
obtain high-performing models while leading to more efficient utiliza-
tion of computational resources. Lastly, commonalities and differences 
between  hyperparameters  can  better  highlight  the  impact  of  each 
hyperparameter on the model’s performance.

excellent predictive capacity with an overall accuracy of 94.5% and an 
almost perfect agreement with a kappa coefficient of 93.4%. 

To better assess the performance of our DNN model for each class, 
errors of omission and commission were calculated for each LCLU class 
(Fig. 12). Errors of omission represent the proportion of reference data 
pixels that the model incorrectly classifies. In contrast, errors of com-
mission  correspond  to  the  proportion  of  model-predicted  pixels  that 
were incorrectly classified according to the reference data. These accu-
racy metrics should be considered together when evaluating the model’s 
performance. A model with high errors of omission may miss important 
observations, while a model with high errors of commission may pro-
duce many false positives. The balance between these two types of errors 
depends on the specific application and the cost of each type of error to 
each respective study.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Three metrics are used to evaluate the performance of the deep learning model: Overall Accuracy (OA), Producer Accuracy (PA), and User Accuracy (UA). Overall accuracy is the ratio of the sum of correctly classified pixels to the total number of pixels in the test dataset. Producer accuracy refers to the accuracy from the point of view of the mapmaker, while user's accuracy represents the probability that a pixel classified in each category corresponds to the actual category on the ground. Additionally, the kappa coefficient of agreement is used to evaluate the performance of the final DNN model. Furthermore, errors of omission and commission are calculated for each land cover/land use class to better assess the performance of the DNN model for each class.