Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

set 

is 

to 
1. 

2.3.3. Experimental setting 

In our experiment, a deep learning environment based on Python and 
Tensorflow – GPU as well as CUDA was constructed under the Windows 
operating system. The deep feature loss bird noise reduction network 
model was trained for 50 epochs on an RTX 2080 Ti GPU using the Adam 
(cid:0) 4. In each 
optimizer (Kingma and Ba, 2014) with a learning rate of 10
epoch, the entire training set was presented in a random order, with one 
noisy bird sound signal per iteration. 

2.4. Comparative algorithms 

Using the same test  set, we compared the  denoising results of the 
deep feature loss-based bird sound noise reduction network with several 
other  bioacoustics  noise  reduction  algorithms,  namely  SEGAN, 
WebRTC, wavelet transform (Priyadarshani et al., 2016), Wiener filter 
(Loizou, 2017), and MMSE STSA (Brown et al., 2017) algorithms.

reducing noise, and accordingly, would not be suitable for processing 
large  volumes  of  recorded  data  collected  in  the  field.  Furthermore, 
compared with the bird sound noise reduction network based on deep 
feature loss and the SEGAN algorithm, we found that the noise reduction 
efficiencies of the WebRTC and Wiener Filter algorithms were notably 
higher. This disparity in performance can be attributed to the fact that 
the deep learning model is larger in size and is thus more demanding of 
computational resources. However, it should be noted that the execution 
time of the deep learning models on CPUs is acceptable.

Abbreviations: Signal-to-noise ratio, SNR; perceptual evaluation of speech quality, PESQ; Web real-time communications, WebRTC; voice over Internet protocol, 
VoIP; minimum mean-square error short-time spectral amplitude, MMSE STSA; speech enhancement generative adversarial network, SEGAN; generative adversarial 
network, GAN; fully convolutional neural network, FCN; deep autoencoder, DAE; leaky rectified linear unit, LReLU; detection and classification of acoustic scenes 
and events, DCASE; peak signal-to-noise ratio, PSNR. 

* Corresponding author Xinghui Gao at: School of Electronics and Communication Engineering, Guangzhou University, China. 
** Corresponding author Yingying Guo at: School of Mechanical and Electrical Engineering, Guangzhou University, China. 

E-mail addresses: gaoxh@gzhu.edu.cn (X. Gao), guoyingying@gzhu.edu.cn (Y. Guo).

(2)  

∑

Λ15 =

Λ14

j × K14

j + b,

j

where b is a learned bias term. 

Fig. 4. Framework of the bird sound noise reduction network based on deep feature loss.  

EcologicalInformatics80(2024)1025174C. Zhang et al.                                                                                                                                                                                                                                   

2.3.2. Training of the bird sound noise reduction network based on deep 
feature loss

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide information about where the data repository of the deep learning pipeline is available. It only mentions that the deep feature loss bird noise reduction network model was trained for 50 epochs on an RTX 2080 Ti GPU using the Adam optimizer with a learning rate of 10. Therefore, I do not have enough information to determine where the data repository of the deep learning pipeline is available.