Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

org/10.1016/j.ecoinf.2024.102593. 

References 

Abadi, Martín, Agarwal, Ashish, Barham, Paul, Brevdo, Eugene, Chen, Zhifeng, 

Citro, Craig, Corrado, Greg S., et al., 2015. TensorFlow: Large-Scale Machine 
Learning on Heterogeneous Systems. https://www.tensorflow.org/. 

Abu-El-Haija, Sami, Kothari, Nisarg, Lee, Joonseok, Natsev, Paul, Toderici, George, 

Varadarajan, Balakrishnan, Vijayanarasimhan, Sudheendra, 2016. ‘YouTube-8M: A 
Large-Scale Video Classification Benchmark’. arXiv. http://arxiv.org/abs/1 
609.08675. 

Allen, Ann N., Harvey, Matt, Harrell, Lauren, Jansen, Aren, Merkens, Karlina P., 
Wall, Carrie C., Cattiau, Julie, Oleson, Erin M., 2021. A convolutional neural 
network for automated detection of humpback whale song in a diverse, long-term 
passive acoustic dataset. Front. Mar. Sci. 8 (March), 607321 https://doi.org/ 
10.3389/fmars.2021.607321.

outputs.  The  embeddings  obtained  using  the  BirdNET-Analyzer  v2.1 
models have 420 dimensions.

accuracy  limits  that  we  encountered  training  DNN  models  with  the 
detailed-labelled NIPS4Bplus dataset (Bravo Sanchez et al., 2021). We 
drilled down on the results using another high-quality model (BirdNET) 
and  compared  it  to  our  SincNet  trained  models.  For  that,  we  experi-
mented  with  dimensionality  reduction  of  embeddings  and  an  initial 
dimensionality reduction technique (t-SNE). We generated embeddings 
using  the  BirdNET  model  on  a  randomly  selected  40%  sample  of  the

TensorFlow Hub, 2023. 2023. https://tfhub.dev/google/vggish/1. 
Thomas, Mara, Jensen, Frants H., Averly, Baptiste, Demartsev, Vlad, Manser, Marta B., 
Sainburg, Tim, Roch, Marie A., Strandburg-Peshkin, Ariana, 2022. A practical guide 
for generating unsupervised, spectrogram-based latent space representations of 
animal vocalizations. J. Anim. Ecol. 91 (8), 1567–1581. https://doi.org/10.1111/ 
1365-2656.13754. 

Tolkova, Irina, Chu, Brian, Hedman, Marcel, Kahl, Stefan, Klinck, Holger, 2021. ‘Parsing 

Birdsong with Deep Audio Embeddings’. arXiv. http://arxiv.org/abs/2108.09203. 

Van der Maaten, Laurens, Hinton, Geoffrey, 2008. Visualizing Data Using T-SNE. 

Plotly Technologies Inc, 2015. Collaborative Data Science. Plotly Technologies Inc, 

J. Mach. Learn. Res. 9 (11). 

Montreal, QC, p. 2015. https://plot.ly. 

Van Rossum, Guido, Drake, Fred L., 2009. Python 3 Reference Manual. CreateSpace, 

Ravanelli, Mirco, Bengio, Yoshua, 2019. Interpretable Convolutional Filters with

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model is built using TensorFlow, which is a popular open-source software library for machine intelligence. It was developed by Google Brain Team and released under the Apache License 2.0. TensorFlow provides APIs for beginners and experts to develop ML-powered applications. In this study, TensorFlow is used to train the SincNet models and generate embeddings using the BirdNET model. Additionally, TensorFlow Hub is mentioned as a resource for pre-trained models. However, there is no explicit mention of other deep learning frameworks like PyTorch being used in this research.