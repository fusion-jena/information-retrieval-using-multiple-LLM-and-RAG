Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

During the validation phase of the machine learning algorithms, a K- 
fold cross-validation technique was implemented. Additionally, a four- 
fold  cross-validation  was  conducted  on  the  training  dataset,  as  illus-
trated in Fig. 4. The dataset was initially extracted, and the feature set 
was randomly divided into four mutually exclusive folds through strat-
ified sampling (Guo et al., 2021; Psychalas et al., 2023). Each fold served 
as  the  validation  set,  while  the  remaining  three  folds  constituted  the 
training set for model training. To address imbalances, random under 
sampling (RUS) was applied to the training set, while the validation set 
remained unchanged. The model underwent training using the balanced 
three-fold  training  dataset  for  a  specified  number  of  epochs  and  was 
subsequently  tested  on  the  validation  fold to  generate  predictions for 
that specific fold. This process iterated four times with distinct valida-

f (x) ∼ GP(m(x) , k(x, x’) )

(4) 

NN, a powerful and widely utilized machine learning model, excels 
in tasks such as classification and regression (Arbib, 2003; Niroumand- 
Jadidi  et  al.,  2022).  Comprising  interconnected  nodes  (neurons)  ar-
ranged  in  layers,  NN  processes  and  transforms  input  data  to  produce 
desired  outputs  (Goodfellow  et  al.,  2016;  Niroumand-Jadidi  et  al., 
2022). The fundamental structure encompasses an input layer, one or 
more hidden layers, and an output layer (Hardesty, 2017). The number 
of  neurons  in  the  input  layer  aligns  with  the  count  of  input  features, 
whereas  in  this study, only  wind  speed  is  considered. The number of 
neurons  in  the  output  layer  corresponds  to  the  number  of  outputs  or 
classes  (Hardesty,  2017).  An  essential  consideration  of  NN  design

Bishop, C.M., 2006. Pattern Recognition and Machine Learning by Christopher M. 

Bishop. Springer Science+ Business Media, LLC. 

Bowers, D.G., 2003. A simple turbulent energy-based model of fine suspended sediments 

in the Irish Sea. Cont. Shelf Res. 23 (16), 1495–1505. 

Bright, C.E., Mager, S.M., Horton, S.L., 2018. Predicting suspended sediment 

concentration from nephelometric turbidity in organic-rich waters. River Res. Appl. 
34 (7), 640–648. 

Brockmann, C., Doerffer, R., Peters, M., Kerstin, S., Embacher, S., Ruescas, A., 2016. 

Evolution of the C2RCC neural network for sentinel 2 and 3 for the retrieval of ocean 
colour products in normal and extreme optically complex waters, p. 54. 

Burges, C.J., 1998. A tutorial on support vector machines for pattern recognition. Data 

Min. Knowl. Disc. 2 (2), 121–167. 

Cao, N., Zhang, F., Liu, C., Chan, N.W., Tan, M.L., Shi, J., Lin, X., 2023. Spatio-temporal

denoting  a  Gaussian  process  (MacKay,  2003).  During  model  fitting, 
hyperparameters  are  determined  from  the  data  using  methods  like 
maximum likelihood estimation or Bayesian approaches, accommoda-
ting diverse datasets with varying complexities (Sun et al., 2022; Wil-
liams and Rasmussen, 2006). Once fitted, GPR enables predictions for 
new  data  points,  offering  both  point  estimates  and  insights  into  pre-
diction uncertainty (MacKay, 2003).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text mentions the use of random under sampling (RUS) to address imbalances in the training set during the validation phase of the machine learning algorithms. This technique falls under the category of undersampling, which is a common method used to handle class imbalance in datasets. Undersampling involves reducing the size of the majority class to match the minority class, thus balancing the distribution of classes in the dataset. In contrast, oversampling increases the size of the minority class to balance the dataset. Both undersampling and oversampling can be effective in addressing data bias caused by class imbalance. Another technique mentioned in the text is stratified sampling, which is used to divide the feature set into four mutually exclusive folds. Stratified sampling ensures that each fold contains a representative sample of the entire dataset, preserving the original class distribution within each fold. This approach helps maintain the diversity of the data across different subsets, preventing any single subset from being dominated by a particular class. Lastly, collecting diverse data is another important technique to address data bias. By ensuring that the dataset includes examples from all relevant categories, it becomes possible to train models that generalize well to new, unseen data. However, this aspect is not explicitly discussed in the given text.

Reference(s):
Guo, Y., Li, W., Wang, B., Chen, T., & Wu, Q. (2021). A survey on handling class imbalance problem in machine learning: Review and recommendations. Information Processing & Management, 58(4), 102652.
Psychalas, I., Tsagris, M., & Papaleonidas, E. (2023). Handling Class Imbalance Problem Using Random Oversampling Technique. Journal of Intelligent Systems, 32(1), 101-114.