Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Kovalev, V., Kalinovsky, A., Kovalev, S., 2016. Deep Learning with Theano, Torch, Caffe, 
Tensorflow, and deeplearning4j: Which One Is the Best in Speed and Accuracy?. 
Larsen, O., Christensen-Dalsgaard, J., Maxwell, A., Hansen, K., Wahlberg, M., 2017, June 
9. Cormorant audiograms under water and in air. Acoust. Soc. Am. J. 141 (5), 3667. 

LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521 (7553), 436–444. 
Lodi, G., Aniello, L., Di Luna, G.A., Baldoni, R., 2014. An event-based platform for 

collaborative threats detection and monitoring. Inf. Syst. 39, 175–195. 

Lohr, B., Wright, T.F., Dooling, R.J., 2003, Apr. Detection and discrimination of natural 
calls in masking noise by birds: estimating the active space of a signal. Anim. Behav. 
65 (4), 763–777. Retrieved from.

In summary, we want to take advantage of the rapid development in 
machine  learning  without  having  to  constrain  the  environment  too 
much.  We  want  to  enable  re-use  of  developed  components  in  other 
experimental  setups  to  improve  standardisation  and  convergence  of 
methods. Further, we want to base the solution on mature well-known 
technologies and off-the-shelf hardware to keep it easy to maintain. 

We  therefore  propose  an  architecture,  based  on  modern  IT  infra-
structure,  that  delivers  on  those  requirements.  In  the  following,  we 
describe the architecture and explain why we think the solution should 
build on IT infrastructure. 

2.1. Architectural considerations

A topic that we did not discuss in this paper is edge computing (Davis 
et al., 2004; Shi et al., 2016), essentially meaning to process data before 
sending it  on the network and  thus improve  response times  and  save 
bandwidth. This requires processing power close to the sensor, which we 
have, but we used it to stream data to the network and not to reduce the 
amount of data to transmit. However, a reduction does happen at the 
edge of the cluster where data streams are transformed to event streams 
and  could  thus  also  happen  at  the  sensor,  given  sufficient  processing 
power for the task. An important advantage of reducing the amount of 
data  is  that  data  can  be  transferred  from  remote  locations  via  low 
bandwidth solutions, such as LoRa (a long range, low-power, wide area 
network modulation technique) or Starlink (satellite based internet ac-
cess). Although the architecture and online computational ethology in

Combining many different frameworks, APIs, methods and technol-
ogies  in  one  project  meant  that  much  of  the  time  normally  spent  on 
writing software was instead spent on learning to use existing software. 
However, once mastered, the use of open free and open source software 
reduces development time and makes the application easier to maintain. 
Off-the-shelf components like Raspberry Pi, PiCamera, routers, switches, 
PCs and graphics cards were used to build the system. The microphone 
array was the only non-commodity hardware, demonstrating that most 
sensors can be adapted to streaming. Most biologists would need tech-
nical  assistance  to  establish  the  system  and  for  support.  The  imple-
mentation  presented  here  was  built  by  lab  technicians,  trained  as 
engineers, in collaboration with engineering students and researchers. 
A strength of this architecture is exploiting open source resources,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention the specific hardware resources used for training the deep learning models. However, there are some clues about the hardware used in the overall setup. For instance, the text mentions using off-the-shelf components like Raspberry Pi, PiCamera, routers, switches, PCs, and graphics cards to build the system. Additionally, the authors state that they used open free and open source software, which often benefits from GPU acceleration for faster computation. Given these points, it is reasonable to infer that the team might have employed GPUs for training their deep learning models, considering the widespread usage of GPUs in machine learning tasks due to their parallel processing capabilities. Nevertheless, without explicit information regarding the hardware resources used specifically for training the deep learning models, it remains uncertain whether the team utilized GPUs, TPUs, or any other specialized hardware.