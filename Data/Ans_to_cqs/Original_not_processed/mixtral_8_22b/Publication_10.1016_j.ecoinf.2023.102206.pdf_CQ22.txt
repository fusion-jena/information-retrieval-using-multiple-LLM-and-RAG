Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Further  discussions  analyze  IFTL  and  FTL  for  their  abilities  to 
improve learning by restricting overconfidence (controlling hesitancy) 
during TL by considering GRNN and SVR as the TUR. Overconfidence in 
ELM,  GRNN,  or  SVR  arises  when  they  make  predictions  on  a  dataset 
(target  domain) that has a huge data distribution difference from the 
source domain data on which they are trained. In this scenario, they just 
use their training experience to make predictions during testing without 
considering the distribution divergence in the testing dataset from the 
training  dataset.  We  conclude  this  section  with  the  execution  time 
analysis of the approaches.  

a)  GDP prediction using only CO2 emission data2

improvement in the prediction accuracy over traditional ELM and FTL. 
The overall IFTL refinement effectiveness can be seen by the percentage 
(%) reduction in RMSE, which ranges from 10% to 23% when GRNN, 
SVR, and ELM are considered as TUR.

Hence, it is validated that IFTL is a refinement approach that can be 
applied to the predictions done by any other existing techniques. Table 6 
summarizes these results along with ELM predictions. Third column of 
this table depicts the percentage (%) reduction in RMSE, which ranges 
from 10% to 23%. The proposed IFTL is used as a refinement over the 
results  of  GRNN,  SVR,  and  ELM  trained  in  different  source  domains 
while keeping γ  (Gamma: the Refinement Impact Factor) fixed at 0.1. 
IFTL carefully considers the vast differences in the data distribution of 
the source domain and the target domain by which it ensures better TL 
in GRNN, SVR, or ELM.  

c)  Execution time analysis 

IFTL_error 

Improvement (%) 

542.39 
1728.4 
279.1 

43,111 
24,568 
466.55 

11.13 
13.12 
22.96  

10.16 
10.08 
16.88

b)  IFTL Refinement over GRNN and SVR 

In previous results, ELM is chosen as TUR, and IFTL is implemented 
on the ELM predictions to improve its knowledge transfer. Here, GRNN 
and SVR are chosen one by one as a TUR model in the process described 
in Fig. 2. Then, IFTL with the same parameter settings (as was in the case 
of ELM in the previous subsection, where γ = 0.1) is applied over their 
prediction. The improvement of IFTL over these approaches are depicted 
in Fig. 6, where ‘GRNN_IF’  denotes the error in IFTL prediction when 
IFTL  is  implemented,  choosing  GRNN  as  TUR.  Similarly,  ‘SVR_IF’  de-
notes the IFTL error when IFTL is implemented, choosing SVR as TUR. 

EcologicalInformatics77(2023)1022069S. Kumar et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, the metric used to evaluate the performance of the deep learning models such as Extreme Learning Machine (ELM), General Regression Neural Network (GRNN), and Support Vector Regression (SVR) is Root Mean Square Error (RMSE). The paper discusses the use of Improved Feature Transfer Learning (IFTL) as a refinement approach to enhance the predictions made by these models. The authors validate the effectiveness of IFTL by analyzing the percentage reduction in RMSE, ranging from 10% to 23%, when compared to traditional ELM and FTL methods. Additionally, the paper mentions the execution time analysis of the approaches but does not provide specific details about other evaluation metrics like accuracy, precision, or recall. Therefore, based on the given context, the primary metric used to assess the performance of the deep learning models is RMSE.