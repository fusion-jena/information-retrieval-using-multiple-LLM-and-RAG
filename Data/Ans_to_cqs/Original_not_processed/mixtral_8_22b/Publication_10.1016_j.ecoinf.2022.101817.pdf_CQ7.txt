Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

classification  pipeline.  The  validation  performance  of  CNN  Model  4 
with respect to each of the six environmental conditions is shown in the 
confusion matrix of Fig. 7 (b).

environment condition classification models, the potential influence of 
fish being in the extracted frames was considered negligible. 

The  12,000  frames  (8  frames  *  1500  videos)  extracted  from  the 
training  and  testing  dataset  were  then used  to  generate  five  different 
data sets using repeated random sub-sampling (see Fig. 4 (2)). Each of 
the  sets  was  further  split  into  a  training/testing  split  of  80/20,  con-
taining 9600 frames for training and 2400 for testing. Five CNN models 

using  the  same  model  architecture  were  then  trained  and  tested.  All 
models were trained over 100 epochs and returned an average loss value 
of  0.0126  with  an  average  accuracy  of  99.3%  during  training  and 
testing. Figures  for the  individual models are provided  in the  supple-
mentary material.

. 

2.4.1. Training the environmental condition model

5ValidationFramesValidationEC ClassesPredictedEC ClassesPerformance* environmentalconditionswith highestprobabilitiesPredictedEC ClassesProbabilityTurbidity79.12 %Biofilm14.11 %Overexposure6.65 %Bubbles0.07 %Clear0.05 %Low Light0.0 %decending orderJ. Soom et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors used repeated random sub-sampling to create five different datasets from the 12,000 frames extracted from the training and testing dataset. Each set was then divided into a training/testing split of 80/20, containing 9600 frames for training and 2400 for testing. This means that they randomly selected 80% of the frames for training and the remaining 20% for testing. They did not mention any specific criteria for splitting the data other than this ratio. However, it can be assumed that the selection was done randomly without considering any particular characteristics or features of the frames.

Regarding the validation set, the authors do not explicitly state how they created it. However, based on the information given, we can infer that they might have used a portion of the training set as the validation set during the training process. This is a common practice in machine learning where a part of the training set is held back and used to validate the model's performance after each epoch. In this case, since the authors mentioned that all models were trained over 100 epochs, it is likely that they used a similar approach. Nevertheless, without explicit confirmation from the authors, this remains speculation.