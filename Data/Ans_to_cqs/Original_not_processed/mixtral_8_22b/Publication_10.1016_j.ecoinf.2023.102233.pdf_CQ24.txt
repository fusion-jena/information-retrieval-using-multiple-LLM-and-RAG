Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Active  learning  iterations  used  a  batch  size  of  64,  ten  epochs  and 
learning rate of 0.001. We used a grid search technique (Mohri et al., 
2018) to tune hyperparameters of the final model including the number 
of epochs, batch size and learning rate. 

2.3.3. Active learning framework 

We  applied  an  active  learning  approach  to  iteratively  train  and 
improve  the  CNN  model.  The  active  learning  approach  is  depicted 
within Fig. 3 and described below.

Sankupellay, M., Konovalov, D., 2018. Bird call recognition using deep convolutional 

neural network, ResNet-50. In: Proceedings of Acoustics. 

Sekercioglu, C.H., et al., 2008. Climate change, elevational range shifts, and bird 

extinctions. Conserv. Biol. 22 (1), 140–150. 

Settles, B., Craven, M., 2008. An analysis of active learning strategies for sequence 

labeling tasks. In: Proceedings of the 2008 Conference on Empirical Methods in 
Natural Language Processing, pp. 1070–1079. 

Teixeira, D., et al., 2022. Fledge or fail: Nest monitoring of endangered black-cockatoos 
using bioacoustics and open-source call recognition. Ecol. Inform. 69, 101656. 
Thakur, A., Thapar, D., Rajan, P., Nigam, A., 2019. Deep metric learning for bioacoustic 

classification: Overcoming training data scarcity using dynamic triplet loss. 
J. Acoust. Soc. Am. 146 (1), 534–547. 

Threatened Species Scientific Committee (TSSC), 2005. Commonwealth Listing Advice

Hüllermeier, E., Waegeman, W., 2021. Aleatoric and epistemic uncertainty in machine 
learning: an introduction to concepts and methods. Mach. Learn. 110, 457–506. 
Kahl, S., et al., 2021. BirdNET: a deep learning solution for avian diversity monitoring. 

Ecol. Inform. 61, 101236. 

Karimi, D., et al., 2020. Deep learning with noisy labels: exploring techniques and 

remedies in medical image analysis. Med. Image Anal. 65, 101759. 

Kingma, D.P., Ba, J., 2014. Adam: a method for stochastic optimization. Proceedings of 
the 3rd International Conference on Learning Representations. arXiv preprint arXiv: 
1412.6980, pp. 1–15. 

Koehler, J., et al., 2017. The use of bioacoustics in anuran taxonomy: theory, 

terminology, methods and recommendations for best practice. Zootaxa 4251 (1), 
1–124. 

Koenecke, A., et al., 2020. Racial disparities in automated speech recognition. Proc. Natl. 

Acad. Sci. 117 (14), 7684–7689.

5. Conclusions 

Our study investigated the efficacy of active learning as a framework 
for  building deep  learning models  in a  setting  where  limited  training 
data were available and the cost to obtain training data was high. Using 
field  recordings  of  a  threatened  species,  the  southern  black-throated 
finch,  we  successfully  developed  and  demonstrated  the  value  of  an 
open  access  active  learning  method  that  considered  imbalanced  and 
unlabelled data and ambiguous vocalisations, which are common bar-
riers to constructing call recognition models for rare or cryptic species, 
and other species that vocalise infrequently. Our results demonstrate the 
utility of these methods in developing effective call recognisers for rare 
and difficult to survey species.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, it mentions the application of an active learning approach to improve the CNN model iteratively. This suggests that the researchers might have used some form of cross-validation or bootstrapping techniques to ensure robustness against randomness. Additionally, they utilized a grid search technique to fine-tune hyperparameters like the number of epochs, batch size, and learning rate. Grid search involves systematically trying different combinations of parameters and selecting the one that performs best based on a chosen performance metric. While this doesn't directly address randomness from sources like random seed values, it can help mitigate their impact by finding optimal parameter configurations.