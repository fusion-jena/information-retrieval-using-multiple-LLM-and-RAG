Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

For the CSVM approach, the architecture comprised three convolutional layers, including ReLU,
each one followed by a Max-pooling layer. The output size of each layer is shown in Table 5.
In this method and for the baseline, the validation samples were added to the training set. For the
computation of the weights of the SVM ﬁlters, the multicore Liblinear software package [50] was
used. The parameter setup of the CSVM was: stride equal to one for the Conv and MaxPool layers,
12 SVMs used in each Conv layer. The training set was split in such a way that each SVM had the
same number of samples for both classes. The size of the mini-patches used for learning the SVMs
was equal to 3 × 3 × 16 for the ﬁrst convolutional layer and 3 × 3 × 12 for the second and third
layers. The estimation of the regularization parameter C for each SVM was performed using three-fold
cross-validation restrained in the range [10−1, 103].

Table 5. Architecture details of the CSVM model.

Layer

a) T1 (2016)b) T2 (2017)c) Referenced) SVM-1Te) EF-1Tf) SN-1Tg) CSVM-1Th) SVM-2Ti) EF-2Tj) SN-2Tk) CSVM-2Tl) SVM-3Tm) EF-3Tn) SN-3To) CSVM-3Tp) SVM-4Tq) EF-4Tr) SN-4Ts) CSVM-4TRemote Sens. 2020, 12, 910

17 of 28

contained in 10% of the image. Hence, instead of looking at the entire image, the analyst would focus
on 10% of it, reducing human work by 90%. As expected, as Recall increased, the area to be observed
also increased, but, in this particular case, CSVM (with three layers) presented the best results (see
Figure 13a). For Recall beyond 96%, the threshold values were very close to zero, most pixels tended
to be classiﬁed as deforestation, and the area to be observed went up to 100%, as can be observed in
Figure 13b.

Figure 12. Predicted maps for tile 14 computed by SVM, EF, SN, and CSVM using one, two, three,
and four tiles for training.

a) T1 (2017)b) T2 (2018)c) Referenced) SVM-1Te) EF-1Tf) SN-1Tg) CSVM-1Th) SVM-2Ti) EF-2Tj) SN-2Tk) CSVM-2Tl) SVM-3Tm) EF-3Tn) SN-3To) CSVM-3Tp) SVM-4Tq) EF-4Tr) SN-4Ts) CSVM-4TRemote Sens. 2020, 12, 910

22 of 28

Figure 20. Predicted maps tile 8 produced by SVM, EF, SN, and CSVM using one, two, three, and four
tiles for training.

3.4. Alarm Area vs. Recall for Cerrado Biome

a) T1 (2017)b) T2 (2018)c) Referenced) SVM-1Te) EF-1Tf) SN-1Tg) CSVM-1Th) SVM-2Ti) EF-2Tj) SN-2Tk) CSVM-2Tl) SVM-3Tm) EF-3Tn) SN-3To) CSVM-3Tp) SVM-4Tq) EF-4Tr) SN-4Ts) CSVM-4TRemote Sens. 2020, 12, 910

23 of 28

Figure 21. (a) Recall vs. Alarm Area (deforested area) for Cerrado biome using one training tile. (b) The
recall values are obtained by threshold variation.

Figure 22. (a) Recall vs. Alarm Area (deforested area) for Cerrado biome using two training tiles.
(b) The recall values are obtained by threshold variation.

Figure 23. (a) Recall vs. Alarm Area (deforested area) for Cerrado biome using three training tiles.
(b) The recall values are obtained by threshold variation.

Remote Sens. 2020, 12, 910

24 of 28

Figure 24. (a) Recall vs. Alarm Area (deforested area) for Cerrado biome using four training tiles.
(b) The recall values are obtained by threshold variation.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about the specific data format used in the deep learning pipeline. However, based on the context, we can infer that the input data might be images or satellite imagery since the paper discusses deforestation detection from remote sensing data. Furthermore, the use of convolutional neural networks (CNNs), which are commonly employed for processing grid-like topology data such as images, also suggests that the input data could be in image format. Nevertheless, without more detailed information regarding the dataset or preprocessing steps, we cannot definitively state the exact data format used in the deep learning pipeline.