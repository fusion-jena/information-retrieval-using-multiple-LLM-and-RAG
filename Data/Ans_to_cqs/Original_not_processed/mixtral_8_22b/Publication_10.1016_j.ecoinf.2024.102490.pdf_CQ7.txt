Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

For model creation, 80% of the data was used as the training set, with 
the  remaining  20%  (the  evaluation  set)  used  to  assess  model  perfor-
mance. This procedure was necessary for thoroughly assessing the pre-
cision of our models. To evaluate the accuracy of our models, we used 
two metrics: the area under the curve (AUC) of the receiver operating 
characteristics (ROC) and the true skill statistics (TSS) (Allouche et al., 
2006; Wani et al., 2022). To  ensure the robustness of our results, we 
applied committee averaging and weighted mean approaches to create 
separate ensemble models for each climate scenario and period. When 
selecting the final ensemble models, special attention was given to those 
with a TSS score of ≥0.7.

Jim´enez et al., 2022). To further refine our projections, we tested two 
types of cutouts; one is called the general extent (GE), encompassing the 
total sum of the natural distribution areas of the four species, and the 
other is referred to as the specific extent (SE), restricted to the individual 
distribution  of  each  species.  To  crop  the  bioclimatic  layers,  we  used 
QGIS  v.3.16.11  (https://www.qgis.org/)  between  01
S  and 
34

Spline 

Maximum Entropy 
eXtreme Gradient Boosting 

CTA 
GLM 
GAM 
SER 
FDA 
ANN 
GBM 
RF 
MaxEnt 

MARS 

MaxNet 

Vayssi`eres et al., 2000 
Guisan et al., 2002 
Guisan et al., 2002 
Busby, 1991 
Hastie et al., 1994 
Venables and Ripley, 2013 
Elith et al., 2008 
Mi et al., 2017 
Phillips et al., 2006 

Friedman, 1991 
Phillips et al., 2006; Friedman 
et al., 2010 

Training 

XGBOOST 

Chen et al., 2015  

Among the ten climatic variables, Bio04 (Temperature Seasonality) 
and Bio14 (Precipitation of Driest Month) contributed the most to the 
prediction of climatic suitability for all the species; Bio17 (Precipitation 
of Driest Quarter) was shown as the third environmental variable as it 
was present in three of the four species (Table 4). The relative contri-
bution of Bio04 and Bio14 was >32% for all species, with Bio04 being 
the largest contributor. 

3.3. Past projections and present climatic suitability

◦
◦–34

W. 

processes  in  the  atmosphere,  ocean,  cryosphere,  and  land  surface  to 
simulate the planet’s response to global climate change: BBC-CSM2-MR, 
developed  by  the  National  Climate  Center  (Beijing),  and  the  sixth 
version  of  the  Model  for  Interdisciplinary  Research  on  Climate 
(MIROC6),  developed  by  a  Japanese  modeling  community  from  the 
WorldClim database.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the splitting of data into training, testing, or validation sets specifically for deep learning models. However, it mentions that for model creation, 80% of the data was used as the training set, while the remaining 20% was used as the evaluation set to assess model performance. Although this division is not explicitly stated as being for deep learning models, it can be assumed that these percentages could also apply to such models. In machine learning and deep learning, it is common practice to divide datasets into training, testing, and sometimes validation sets. Typically, the majority of the dataset is allocated to the training set, which is used to fit the model parameters. A smaller portion of the dataset is then reserved for the testing set, which is employed to estimate how well the model will perform on unseen data. Occasionally, another subset known as the validation set may be utilized during the training process to fine-tune hyperparameters and prevent overfitting.