Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A.1.2. Loading the pre-trained module 

By default, LaDeco employs the deeplabv3 þ resnet269 model. The deeplabv3 part is a semantic segmentation algorithm developed by Google 
(Chen et al., 2018), and Resnet269 is a 269-layer Resnet neural network (Zhang et al., 2020). Users can switch to other pre-trained models as needed 
(Please refer to https://cv.gluon.ai/api/model_zoo.html#). 

A.1.3. Setting the threshold 

The primary function of LaDeco is to calculate the pixel percentage of each landscape element in the image. Users can set a threshold to filter out 

negligible values; for example, values below 1% can be rounded to zero. This threshold is customizable. 

A.1.4. Output format

An  AI  platform  operates  on  a  Central  Processing  Unit  (CPU)  or 
Graphics Processing Unit (GPU). It uses MXNet to provide the essential 
modules and functions required for the program operation. 

The  programming  platform  encompasses  four  primary  computa-

tional functions:  

(1)  Analysis  Module:  Responsible  for  conducting  core  analytical 

tasks.  

(2)  Data Filtering Module: Filters irrelevant data.  

(1)  The computer initially read the images and forwarded them to the 

SS model.  

(2)  The SS model produced a pixel count for 150 objects.  
(3)  Any data that fell below a certain threshold were assigned a value 

of zero.  

(4)  Finally,  the  percentages  of  each  element  and  category  were 
calculated based on a visual landscape classification framework. 
The  results  were  then  exported  in  Comma-Separated  Values 
(CSV) format.

(4)  Computational efficiency 

Because  LaDeco  processes  image  data,  high-quality  Graphics  Pro-
cessing Units (GPU) are essential. In this study, for example, a total of 
8301 images were analyzed on a computer with 128GB RAM, an Intel-i9 
CPU,  and  a  Nvidia-RTX5000  GPU,  taking  a  total  time  of  5087  s  (an 
average of 0.61 s per image). To improve the processing speed, espe-
cially  when  dealing  with  large  datasets,  it  is  advisable  to  use  more 
advanced GPU. 

6. Conclusion

EcologicalInformatics78(2023)1022893L.-C. Ho                                                                                                                                                                                                                                           

Fig. 3. Hierarchical classification system.  

NFI =

∑

∑

all pixels of Natural Landscape (L1)
∑

all pixels of Natural Landscape (L1) +

all pixels of Man (cid:0) made Landscape (L1)

(1)   

(3)  Data Processing Module: Processes the cleaned data.  
(4)  Output Module: Produces the final output. 

3.2. The architecture of LaDeco 

The computational workflow proceeds as follows:  

The architecture of LaDeco is divided into two main components as 

shown in Fig. 4: the AI platform and a programming platform.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there is no explicit mention of a specific strategy implemented to monitor the model performance during training. However, some general strategies used in machine learning include tracking metrics such as accuracy, precision, recall, F1 score, etc., using validation sets, cross-validation techniques, early stopping criteria, and learning curves. These methods help evaluate how well the model is performing and whether it is overfitting or underfitting the data. Since LaDeco utilizes deep learning algorithms like DeepLabv3+ResNet269, these common monitoring strategies could potentially apply here too. But without further details about the implementation, we cannot confirm which exact method was employed.