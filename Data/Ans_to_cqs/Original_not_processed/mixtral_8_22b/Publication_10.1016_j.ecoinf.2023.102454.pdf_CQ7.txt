Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

System, n.d.). Table 1 shows the specific data types and their sources.

Its  data  sources  mainly  include  the  following:  (1)  The  nighttime 
lighting data is extended NPP-VIIRS-like NTL Data for 2000–2021. The 
dataset  is  available  for  free  download  at  the  National  Earth  System 
Science Data Centre (National Earth System Science Data Center, n.d.). 
(2) Provincial statistical energy data for 2000–2021 are obtained from 
the China Statistical Yearbook (China Statistical Press, n.d.), municipal 
statistical data are obtained from the Xi'an Statistical Yearbook (Xi'an 
Municipal  Bureau  of  Statistics,  n.d.),  and  carbon  emission  factors  for 
various energy sources are obtained from the “2019 Refinement to the 
2006  IPCC  Guidelines  for  National  Greenhouse  Gas  Inventory”.  (3) 
Administrative  boundary  data  for  Xi'an  (district,  county,  and  street 
administrative  boundaries)  were  provided  by  the  National  Basic 
Geographic Information System (National Basic Geographic Information

A =

44
12

∑9

i=1

GiKiEi

(2-1)  

where  i  is  the  type  of  energy  source;  Gi  is  the  annual  consumption 
amount of energy i, Ei  is the standard coal conversion factor of energy 
source type i, and each type of energy consumption can be converted to 
standard coal consumption based on its calorific value; Ki is the emission 
coefficient of CO2 for each type of energy source; and 44/12 is the molar 
ratio of CO2  to C. The energy consumption statistics of this study are 
broadly classified into nine categories, encompassing raw coal, crude, 
coke, gasoline, kerosene, diesel fuel, fuel oil, natural gas, and electricity. 

EcologicalInformatics79(2024)1024544Y. Zhang et al.                                                                                                                                                                                                                                   

2.3.2. Constructing provincial-scale fitting models

Funding 

none. 

CRediT authorship contribution statement 

Jing  Quan:  Writing  –  review  &  editing,  Writing  –  original  draft, 
Software, Methodology, Data curation. Yaqian Kong: Software, Meth-
odology, Data curation. Qian Wang: Visualization, Software, Method-
ology. Yuxin Zhang: Writing – review & editing, Methodology, Funding 
acquisition, Conceptualization. 

Declaration of competing interest 

none. 

Data availability 

Data will be made available on request. 

References 

A Y S, A D G, B J L, et al., 2017. Methodology and applications of city level CO 2 emission 

accounts in China[J]. J. Clean. Prod. 161, 1215–1225. https://doi.org/10.1016/j. 
jclepro.2017.06.075. 

Cai, L., Luo, J., Wang, M., et al., 2023a. Pathways for municipalities to achieve carbon 
emission peak and carbon neutrality: a study based on the LEAP model[J]. Energy 
262, 125435. https://doi.org/10.1016/j.energy.2022.125435.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). Therefore, I cannot provide an accurate response based solely on the given context. However, common practices often involve splitting the dataset into three subsets: training set, validation set, and testing set. The training set is used to fit the model, while the validation set helps tune hyperparameters and prevent overfitting. Lastly, the testing set evaluates the final performance of the trained model. The proportion of these sets varies depending on the size of the dataset and the problem complexity. Typically, researchers use 80% of the data for training, 10% for validation, and 10% for testing.