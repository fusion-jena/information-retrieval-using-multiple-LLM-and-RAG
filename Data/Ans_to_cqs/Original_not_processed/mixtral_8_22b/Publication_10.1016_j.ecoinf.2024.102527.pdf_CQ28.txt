Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

respectively.  N  represented  the  number  of  images  in  the  test  set  or 
validation set. 

2.2.6. Model training and hyper-parameters 

We  trained  models  on  the  training  sets  and  tracked  the  model 
training process on the validation set. The training process was stopped 
when  the  loss  value  of  the  model  on  the  validation  set  no  longer 
decreased. We then tested the model performance on the test set. Our 
computing platform was a Dell PowerEdge C4130 rack server with two 
Tesla  K80  GPUs  and  256  GB  of  memory.  For  the  deep  learning  envi-
ronment,  we  utilized  the  PyTorch  1.7.1  platform.  We  employed  the 
Stochastic Gradient Descent (SGD) optimizer with a momentum value of 
μ  = 0.9 to train the model. Other hyper-parameter settings for model 
training were shown in Table S.4 of the Supporting Information. 

3. Results 

3.1. Experiment results of transfer strategy optimization

EcologicalInformatics80(2024)1025279D.-Q. Yang et al.

Norouzzadeh et al. (2021) then transferred the ResNet-50 model pre- 
trained  on  the  ImageNet  dataset  to  the  SS  dataset  by  updating  only 
the fully connected layer. They achieved 92.2% accuracy on the species 
identification  task  using  a  small  target  training  samples  (~  25,000). 
Willi et al. (2019) transferred the ResNet-18 model pre-trained on the SS 
dataset  to  three  ecological  monitoring  datasets  by  updating  only  the 
fully connected layer, achieving a high accuracy of 92.4–97.7% on the 
empty image recognition task and 91.4–96.6% on the species recogni-
tion task. Researchers have been attempting to optimize the selection of 
update layers while using transfer learning to process ecological moni-
toring  data  (Dufourq  et  al.,  2022;  Nazir  and  Kaleem,  2024).  Dufourq 
et al. (2022) compared the performance of a transfer model that updates 
all layers with that of a model that updates only the fully connected layer

Appendix A. Supplementary data 

Supplementary data to this article can be found online at https://doi. 

org/10.1016/j.ecoinf.2024.102527. 

EcologicalInformatics80(2024)10252710D.-Q. Yang et al.                                                                                                                                                                                                                                

References 

Afridi, M., Ross, A., Shapiro, E., 2018. On automated source selection for transfer 

learning in convolutional neural networks. Pattern Recogn. 73, 65–75. https://doi. 
org/10.1016/j.patcog.2017.07.019. 

Agrawal, P., Carreira, J., Malik, J., 2015. Learning to see by moving. In: 2015 IEEE 

International Conference On Computer Vision (ICCV). Presented at the 2015 IEEE 
International Conference on Computer Vision (ICCV), pp. 37–45. https://doi.org/ 
10.1109/ICCV.2015.13.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about which cloud platform was used to deploy the deep learning model. However, it mentions that the computing platform used during the development phase was a Dell PowerEdge C4130 rack server with two Tesla K80 GPUs and 256 GB of memory. Additionally, the PyTorch 1.7.1 platform was used for the deep learning environment.