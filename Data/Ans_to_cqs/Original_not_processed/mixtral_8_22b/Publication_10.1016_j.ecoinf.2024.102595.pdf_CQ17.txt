Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

In  the  development  stage,  the  preprocessed  data  was  divided  into 
training (80%), validation (10%), and test sets (10%) for model training 
and testing purposes (Shah et al., 2018), followed by the construction of 
predictive  models  using  both  deep  learning  algorithms  (e.g.,  Deep 
Neural  Networks)  and  traditional  machine  learning  approaches  (e.g., 
AdaBoost  Regressor,  Support  Vector  Regressor,  etc.),  with  hyper-
parameter tuning performed via GridSearchCV with cross-validation (cv 
= 10).  While some studies  might  use different proportions, such as  a 
70–30 split between training and testing/validation (Khan et al., 2022), 
the  80–10-10  split  employed  in  this  study  ensured  a  more  extensive 
training set, potentially leading to a better-generalized model. The test 
set,  which  the  model  has  not  previously  seen  during  the  training  or 
validation phases indicates the model’s performance in real-world sce-
narios (Shah et al., 2018).

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Oil palm 
Yield prediction 
Machine learning 
Deep learning 
Agriculture

Thus, this research aims to fulfill three primary objectives to advance 
yield predictions within the oil palm industry through the integration of 
machine  and  deep  learning  techniques:  1)  to  compile  and  analyze  a 
comprehensive  dataset  that  encompasses  a  wide  array  of  variables 
affecting oil palm yields, such as weather conditions, progeny, soil types, 
nutrient  levels,  and  agricultural  practices,  including  irrigation  and 
fertilization  strategies, 2) to refine predictive modeling by addressing 
overfitting through sophisticated feature selection and cross-validation 
methods,  while  also  employing  a  feature-importance  approach  to 
quantify  the  impact of  various factors  on yield predictions,  and  3)  to 
compare the effectiveness of linear and nonlinear modeling techniques 
in accurately forecasting the complex, nonlinear trends observed in oil 
palm yields. 

2. Materials and methods 

2.1. The study area

Recognizing the significant role of oil palm, extensive research has been 
conducted,  as  evidenced  by  studies  from  Melidawati  et  al.  (2021), 
Tuerxun et al. (2020), and Ang et al. (2022), each contributing insights 
into  oil  palm  cultivation  and  management.  Predicting  oil  palm  crop 
yields is crucial to effectively managing and optimizing the palm supply 
chain. It requires the incorporation of multiple datasets and is influenced 
by numerous variables, including climate patterns, soil quality, fertilizer 
use, and seed varieties (Xu et al., 2019). Applying Machine learning and 
deep learning models can accurately predict crop yields, aiding farmers 
in harvest planning and crop management decisions (Attri et al., 2023). 
Although these techniques have been implemented across various crops 
for environment-based yield forecasting, their deployment for predictive 
analysis of oil palm yields remains in its infancy (Rajakal et al., 2021).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific regularization methods used to prevent overfitting in the deep learning pipeline. However, it mentions that sophisticated feature selection and cross-validation methods were employed to address overfitting. These methods could include techniques like dropout and L2 regularization, but without further details, we cannot confirm if they were specifically utilized in this case. Dropout is a technique where randomly selected neurons are ignored during training, which helps prevent overfitting by making the network more robust. On the other hand, L2 regularization adds a penalty term to the loss function, discouraging large weights and thus reducing complexity and preventing overfitting. Other common regularization methods include early stopping, weight decay, and batch normalization.