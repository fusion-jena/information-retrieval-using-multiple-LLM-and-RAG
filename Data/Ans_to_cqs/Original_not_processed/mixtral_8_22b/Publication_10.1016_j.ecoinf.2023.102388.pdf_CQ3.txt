Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.2.2.3. Label-only  (Choquette-Choo  et  al.,  2021). Rather  than  using 
confidence predictions, query-based attacks restrict the attack to using 
only the predicted labels from the target model. More precisely, label- 
only attacks determine membership status by issuing multiple queries 
to the target model. In practice, these queries are obtained by applying 
adversarial  perturbations  to  the  input  sample  until  a  change  in  the 
predicted label occurs. The attack assesses the perturbation’s size and 
categorizes  a  data  sample  as  a  member  if  its  magnitude  surpasses  a 
predefined threshold. More formally, if we have an estimate dist(x, y)
representing a point’s l2-distance from the model’s boundary, the attack 
predicts that x is a member when dist(x, y) ≥ τ, in which τ is a specific 
threshold value.

• No-overfitting. In this setting, the optimization algorithm of CNNs is 
Stochastic Gradient Descent (SGD), with a learning rate of 0.0001 
and a weight decay of 0.5. The batch size is set to 32, the number of 
training epochs to 200 and finally the batch-norm and dropout (0.5) 
are used to reduce the overfitting level.  

• Overfitting.  We  use  the  same  hyperparameters  setting  as  the  no- 
overfitting  but  we  remove  the  use  of  batch-norm,  weight  decay 
and dropout techniques to ensure that the model overfits.

Strengthening the ability of trained models to generalize effectively 
poses  a  significant  challenge  within  the  domain  of  deep  learning. 
Indeed, generalization refers to the variation in a model’s performance 
when applied to data it has been trained on, as opposed to data it en-
counters for the first time during testing. This issue is of fundamental 
importance and has far-reaching implications for applications employ-
ing  deep  neural  networks.  In  particular,  this  challenge  becomes 

Table 7 
Discrimination  accuracy  (%)  of  ensemble  MIA  and  SNN  for  the  GREMM 
dataset.  

Approach 

Siamese Neural Network (SNN) 
Ensemble MIA 

Discrimination (%) 

65.86 
86.22  

EcologicalInformatics79(2024)10238814V.M. Araújo et al.

Image Recognition. CoRR abs/1409.1556. 

Skalski, P., 2019. Make Sense. https://github.com/SkalskiP/make-sense/. 
Song, L., Shokri, R., Mittal, P., 2019. Membership inference attacks against adversarially 
robust deep learning models. In: 2019 IEEE Security and Privacy Workshops (SPW), 
pp. 50–56. https://doi.org/10.1109/SPW.2019.00021. 

Taigman, Y., Yang, M., Ranzato, M., Wolf, L., 2014. Deepface: closing the gap to human- 
level performance in face verification. In: Proceedings of the IEEE Conference on 
Computer Vision and Pattern Recognition, pp. 1701–1708. 

Tayama, I., Shimdate, M., Kubuta, N., Nomura, Y., 1982. Application for optical sensor to 

fish sorting. Reito (Tokyo). Refrigeration 57, 1146–1150. 

Tuia, D., Kellenberger, B., Beery, S., Costelloe, B.R., Zuffi, S., Risse, B., Mathis, A., 
Mathis, M.W., van Langevelde, F., Burghardt, T., et al., 2022. Perspectives in 
machine learning for wildlife conservation. Nat. Commun. 13, 792.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the data annotation techniques used in the deep learning pipeline such as bounding box annotation or instance segmentation. Therefore, based on the provided context, I cannot give a helpful answer to the query.