Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

search algorithms such as the genetic algorithm (GA) and particle swarm 
optimization (PSO) are often used to solve model parameter problems, 
for instance, the number of neurons in neural networks, error penalty 
factor in SVM, etc. For example, Yan used GA and PSO to optimize a BP 
neural network to build a DO estimation model of Beijing Lake in Beijing 
(Yan et al., 2019). Compared with the GA algorithm, PSO is used more in 
DO  modeling  in  combination  with  BPNN,  GRU,  LSTM,  SVM,  support 
vector regression (SVR), and other algorithms (Wu et al., 2018; Huan 
et al., 2020; Zhu et al., 2021; Huang et al., 2021; Cao et al., 2021b; Liu 
et al., 2014, exhibiting high efficiency and good robustness with mini-
mal calculation. Other optimization algorithms, such as the multi-verse 
optimizer,  have  also  been  adopted  for  parameter  optimization  (Yang 
et al., 2021).

The bold values in Table 6 represent the best evaluation results for 
each algorithm. For these five algorithms, the third input combination, 
that is, Tem, Ec, Tur, and H, was selected as prediction inputs, achieving 
the highest R2 as well as the lowest MSE and MAE in both the training 
and  validation  phases.  Thus,  it  can  be  inferred  that  these  four  moni-
toring variables  all contribute positively to the prediction of DO con-
centration. In addition, the results in Table 6 show that compared with 
the  single  SVR model, the  MSE  and MAE of  the WTD-SVR model are 
reduced  by  8.33%  and  0.14%,  respectively,  indicating  that  the  SVR

an improved LSSVM integrated with a bat algorithm (LSSVM-BA) model 
for  predicting  DO  concentration  in  rivers,  which  outperformed  the 
M5Tree  and  MARS  models  (Yaseen  et  al.,  2018).  Tree-based  models 
usually include decision trees, random forest (RF), and extreme gradient 
boosting  (XGBoost).  Lu  proposed  a  short-term  DO  prediction  model 
based  on  XGBoost  and  RF,  which  was  applied  to  the  data  after  pre-
processing with complete ensemble empirical mode decomposition with 
adaptive noise (CEEMDAN)(Lu and Ma, 2020). Heddam used extreme 
randomized  tree  and  RF  to  predict  DO  concentrations  in  the  Charles 
River  and  Mystic  River,  with  better  model  accuracy  than  those  of 
multilayer perceptron neural network (MLPNN) models (Adnan et al., 
2021). Ahmed proposed a quantile regression forest algorithm for pre-
dicting DO levels in three rivers, and the results show that their model

offers  the  advantages  of  high  learning  efficiency  and  strong  general-
ization  ability  (AntanasijeviÂ´c  et  al.,  2013).  ELM  has  been  studied  by 
many scholars (O'Donncha et al., 2022; Heddam et al., 2022; Heddam 
and  Kisi,  2017.  In  addition,  Hedda  used  an  optimally  pruned  ELM 
(OPELM) algorithm based on ELM, to predict DO concentrations in the 
Klamath River, Oregon, USA (Heddam, 2016). The results show that the 
performance of OPELM is more accurate than that of the MLPNN model. 
In  addition  to  the  three  typical  feedforward  neural  network  models 
mentioned  above,  other  neural  network  algorithms  have  also  been 
extensively reported, such as the deep recurrent neural network, which 
has also been discussed for predicting DO concentrations in river water 
(Moghadam et al., 2021). The long short-term memory (LSTM) network, 
which is an advanced AI tool for time-series data analysis, was used by

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

According to the given context, various search algorithms are employed to optimize model parameters, including the genetic algorithm (GA) and particle swarm optimization (PSO). These algorithms help determine optimal hyperparameters for different machine learning models like neural networks, SVMs, and others.

For instance, Yan utilized GA and PSO to optimize a backpropagation (BP) neural network for building a dissolved oxygen (DO) estimation model of Beijing Lake in Beijing [1]. Moreover, PSO has been widely used in conjunction with several algorithms, such as BPNN, GRU, LSTM, SVM, support vector regression (SVR), and others, demonstrating high efficiency and robustness with minimal computation [2][3][4][5][6][7].

Additionally, other optimization algorithms, like the multi-verse optimizer, have been implemented for parameter optimization [8]. However, the context does not explicitly mention specific methods such as grid search or random search for hyperparameter tuning. Nonetheless, it implies that search algorithms like GA and PSO play a significant role in optimizing model parameters, contributing to enhanced performance and accuracy in predicting DO concentrations in rivers.