Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

shown in the Fig. 6. 

The network is designed with four convolution kernel pooling layers 
to extract deep features. After the convolution pooling, the data enters 
the fully connected layer for connection. The network adds a dropout 
layer  to  the  fully  connected  layer  to  reduce  network  parameters.  A 
Dense_1 layer is added after flatten to reduce the dimension of the deep 
features, and sets the parameter to 500, which is the parameter of the 
deep feature dimension extracted from different views. 

4.2. Feature selection

In the work, the CNN pre-training models are constructed with the 
multi-view data of WT spectrum, HHT spectrum and STFT spectrum as 
the input of the network. And the output data is 500 features obtained 
from  the  Dense_1  layer  of  each  CNN.  The  CNN  pre-training  model  is 

1 

2 

3 

4 

5 

6 

7 

8 

9 

10 
11 
12 
13 
14 

Conv 
Input 

Input Layer 

– 

Conv 1 

Convolution2D 

Pool 1 

MaxPool2D 

Conv 2 

Convolution2D 

Pool 2 

MaxPool2D 

Conv 3 

Convolution2D 

Pool 3 

MaxPool2D 

Conv 3 

Convolution2D 

Pool 3 

MaxPool2D 

3 × 3 

2 × 2 

3 × 3 

2 × 2 

3 × 3 

2 × 2 

3 × 3 

2 × 2 

– 
– 
– 
– 
– 

Dropout (0.4) 
Flatten 
Dense 
Dense_1 
Output 

– 
– 
– 
– 
– 

– 

1 

2 

1 

2 

1 

2 

1 

2 

– 
– 
– 
– 
– 

– 

64 

– 

64 

– 

32 

– 

32 

– 

– 
– 
– 
– 
– 

112 × 112 
× 3 
112 × 112 
× 3 
112 × 112 
× 64 
56 × 56 ×
64 
56 × 56 ×
64 
28 × 28 ×
64 
28 × 28 ×
32 
14 × 14 ×
32 
14 × 14 ×
32 
7 × 7 × 32 
7 × 7 × 32 
1568 
500 
16

5.2. Result analysis 

The datasets are divided into training set and test set according to the 
ratio of 8:2. And the number of test samples and training samples are 
3094 and 12,340, respectively. The classification models are built with 
the training set, and accuracy on test set is used as indicator to evaluate 
performance of classification models. 

5.2.1. Classic CNN model 

The three features of F1, F2 and F3 are input into CNN model, and 

their classification performance on the test set is shown in Table 6. 

Feature 

F1 
F2 
F3 

CNN 

81.00 
88.36 
89.11 

Number of features 

500 
500 
500  

Table 7 
Test accuracy (in %) of various features.  

Feature 

F4 
F5 
F6 
F7 
F4⊕F5⊕F6 
F4⊕F5⊕F6⊕F7 
Fdh 

RF 

82.92 
87.93 
88.47 
85.70 
90.76 
91.10 
95.43 

SVM 

85.59 
91.11 
91.60 
64.51 
93.96 
93.96 
96.19 

MLP 

83.85 
89.53 
90.46 
73.45 
93.40 
93.53 
96.03 

Number of features 

500 
500 
500 
13 
1500 
1513 
96  

5.2.3. Proposed models

In recent years, deep learning has an excellent performance and is 
also widely used in computer vision, speech recognition and other fields. 
Xie et al. used Chirplet transform, STFT and Mel cepstrum transform to 
obtain the spectrogram, and combined with the bird species recognition 
method of deep learning, classified and recognized 18 species of birds 
(Xie et al., 2018). Since 2015, many research teams have exploited deep 
learning to classify birdsong in the LifeCLEF bird recognition challenge. 
For example, Piczak used deep learning to identify South American birds 
in the BirdCLEF 2016 competition (Piczak, 2016). T´oth et al. used CNN 
for feature learning in the same competition, and achieved good results 
(T´oth  and  Czeba,  2016).  Based  on  Xception,  extracted  logmel  or  log-
linear  spectra  as  features  in  BirdCLEF  2020,  Bai  et  al.  used  data 
enhancement technology to improve the detection performance of bird

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that there isn't explicit information about specific preprocessing steps such as normalization, scaling, or cleaning prior to training the deep learning model. However, we can infer some general preprocessing steps based on common practices in deep learning applications.

Before feeding the multi-view data of WT spectrum, HHT spectrum, and STFT spectrum into the CNN pre-training models, it is likely that these spectral representations were generated from raw audio signals using techniques like Fast Fourier Transform (FFT), Hilbert Huang Transform (HHT), Short Time Fourier Transform (STFT), etc. These transformations convert time domain signals into frequency domain representations, which can be more informative for certain tasks like sound event detection or bird species identification.

Additionally, since the dataset was split into training and testing sets with an 8:2 ratio, it implies that the data might have been shuffled beforehand to ensure randomness during splitting. This step helps prevent any potential biases due to ordering effects in the original dataset.

Although not explicitly mentioned, it is also possible that the authors performed standardization or normalization on their input features to bring them to a similar scale. This practice often improves the convergence rate and overall performance of deep learning models by making the optimization landscape smoother.

Lastly, while not directly related to preprocessing, the use of a Dropout layer in the fully connected layer suggests that the authors employed regularization techniques to mitigate overfitting and enhance the model's ability to generalize well to unseen data.

To summarize, although the exact preprocessing steps aren't detailed in the provided context, one could reasonably assume that the following steps may have been taken: generating spectral representations from raw audio signals, shuffling the dataset, applying standardization/normalization, and incorporating regularization methods like Dropout.