Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

respectively.  N  represented  the  number  of  images  in  the  test  set  or 
validation set. 

2.2.6. Model training and hyper-parameters 

We  trained  models  on  the  training  sets  and  tracked  the  model 
training process on the validation set. The training process was stopped 
when  the  loss  value  of  the  model  on  the  validation  set  no  longer 
decreased. We then tested the model performance on the test set. Our 
computing platform was a Dell PowerEdge C4130 rack server with two 
Tesla  K80  GPUs  and  256  GB  of  memory.  For  the  deep  learning  envi-
ronment,  we  utilized  the  PyTorch  1.7.1  platform.  We  employed  the 
Stochastic Gradient Descent (SGD) optimizer with a momentum value of 
μ  = 0.9 to train the model. Other hyper-parameter settings for model 
training were shown in Table S.4 of the Supporting Information. 

3. Results 

3.1. Experiment results of transfer strategy optimization

Fig. 1. Conceptual model of transfer learning. Si (i = 0,1, …,n) represented the five convolutional stages and the final fully connected stage (including softmax) of the 
ResNext-101 model. 

Table 2 
Source domain data splitting on SS dataset.   

Usage 

Number of 
images 

Class 
number 

Description 

S_2_10 

Training 

100,000 

S_2_50 

Training 

500,000 

S_2_100 

Training 

1,000,000 

S_2_V 

Validation 

8095 

S_2_T 

Test 

8118 

S_10_10 
S_10_50 
S_10_100 
S_10_V 
S_10_T 

Training 
Training 
Training 
Validation 
Test 

100,000 
500,000 
1,000,000 
61,693 
60,342 

2 

2 

2 

2 

2 

10 
10 
10 
10 
10 

Empty image vs. 
Animal image 
Empty image vs. 
Animal image 
Empty image vs. 
Animal image 
Empty image vs. 
Animal image 
Empty image vs. 
Animal image 
10 species 
10 species 
10 species 
10 species 
10 species  

2.2.4. Experiment design  

(1)  Transfer learning strategy optimization

Convolutional Neural Networks, in: Proceedings of the 5th ACM on International 
Conference on Multimedia Retrieval, ICMR ‘15. Association for Computing 
Machinery, New York, NY, USA, pp. 643–650. https://doi.org/10.1145/ 
2671188.2749408. 

Ghafoorian, M., Mehrtash, A., Kapur, T., Karssemeijer, N., Marchiori, E., Pesteie, M., 

Guttmann, C.R.G., de Leeuw, F.-E., Tempany, C.M., van Ginneken, B., Fedorov, A., 
Abolmaesumi, P., Platel, B., Wells, W.M., 2017. Transfer learning for domain 
adaptation in MRI: Application in brain lesion segmentation. In: Descoteaux, M., 
Maier-Hein, L., Franz, A., Jannin, P., Collins, D.L., Duchesne, S. (Eds.), Medical 
Image Computing and Computer Assisted Intervention (cid:0) MICCAI 2017. Springer 
International Publishing, Cham, pp. 516–524.

Regarding source model construction, we suggest that practitioners 
with abundant computational resources should build the source model 
with a larger number of readily available labeled samples. Doing so can 
contribute  to  improved  transfer  learning  performance.  However,  for 
those  with  limited  computational  resources,  it  may  be  necessary  to 
compromise between sample size and computational resources based on 
the potential threshold effect. 

CRediT authorship contribution statement

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors used the Stochastic Gradient Descent (SGD) optimizer with a momentum value of μ = 0.9 to train their deep learning model. They did not explicitly mention other hyperparameters such as learning rate, batch size, or weight decay in this section. However, they noted that other hyperparameter settings for model training can be found in Table S.4 of the Supporting Information.