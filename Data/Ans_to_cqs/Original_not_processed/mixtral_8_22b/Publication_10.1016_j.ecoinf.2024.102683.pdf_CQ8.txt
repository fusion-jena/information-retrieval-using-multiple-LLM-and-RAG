Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Therefore, it is important to take into account several features and 
place  emphasis  on  the  features  that  are  efficient  for  different  herbs. 
Performance  of  deep  neural  networks  will  be  enhanced  when  the 
attention  mechanism  enables  them  to  precisely  focus  on  all  relevant 
input elements. This method has become a popular technique in DL for 
text classification, image interpretation, and sentiment analysis (Wani 
et al., 2020). Models like attention mechanisms have high accuracy, and 
most of these mechanisms can be jointly trained with a basic model, such 
as a recurrent neural network or a convolutional neural network (CNN), 
using  a  regular  back-propagation  algorithm.  In  DL  models,  feature 
extraction  takes  place  hierarchically  through  CNNs  from  a  global 
perspective. At the same time, the attention mechanism focuses on the 
significant information of an image, improving the performance of CNN

attention mechanisms enhance efficiency of deep learning (DL) networks by allowing them to precisely focus on 
all relevant input elements. In order to enhance the performance of the proposed model, the CA was implemented 
based on four pooling operations including global average pooling-based CA (GAP-CA), mixed pooling-based CA 
(Mixed-CA), gated pooling-based CA (Gated-CA), and tree pooling-based CA (Tree-CA) operations. The results 
showed that the DL model based on Tree-CA had promising performance and outperformed other state-of-the-art 
models, achieving the values of 99.63%, 99.38%, 99.52%, 99.74%, and 99.42%, for accuracy, precision, recall, 
specificity, and F1-score, respectively. The findings support our proposed attention model's success in identifying 
medicinal  plants  from  similar  poisonous  plants.  Recent  advancements  in  computer-based  technologies  and

In Fig. 8, the performance of the presented models in different epochs 
is  reported.  As  can  be  seen,  the  performance  of  the  proposed  models 
increases with the number of epochs and the number of training data. 
According to Fig. 8a, the SCAM-Herb model based on Tree-CA module 
with 50% of dataset and 100 epochs achieved an accuracy of 96.64%. 
With  90%  of  the  trained  dataset,  this  model  was  able  to  diagnose 

EcologicalInformatics82(2024)1026835R. Azadnia et al.                                                                                                                                                                                                                                

Fig. 5. Schematic representation of improved split attention used in the proposed CA module: a) Mixed-CA, b) Gated-CA, c) Tree-CA, and d) GAP-CA.

EcologicalInformatics82(2024)1026837R. Azadnia et al.                                                                                                                                                                                                                                

Fig. 8. Accuracy of training sets at different epochs by SCAM-Herb model based on (a) Tree-CA, (b) Gated-CA, (c) Mixed-CA, and (d) GAP-CA modules.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide any information about where the code repository of the deep learning pipeline is available. Therefore, I cannot determine whether the code repository is available on platforms such as GitHub, GitLab, or BitBucket. Please refer to additional sources or contact the authors directly for more information regarding the availability of the code repository.