Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Data-driven models have evolved as effective decision-support tools
for HABs monitoring and prediction. These models are essential for
using patterns between water quality parameters and ecosystem vari-
ables to predict algal-related parameters such as chlorophyll-a, phyco-
cyanin, algal cells, and toxins (Busari et al., 2023; Kimambo et al.,
2019). Machine learning (ML) models such as random forest (RF),
Multilayer perceptron (MLP), long-short term memory (LSTM), and
support vector regression (SVR) have been used successfully to predict
different algal-related parameters and help identify drivers of HABs (Liu
et al., 2019; Qian et al., 2023; Zhang et al., 2015, Busari et al., 2023).
Model predictions are, however, influenced by varying degrees of un-
certainty (Gawlikowski et al., 2023). According to Guzman et al. (2015),
uncertainty refers to the variation between the actual state of a variable
and its theoretical assessment at a particular time. These prediction

included during the model training phase when introducing high-
frequency datasets. This is unsurprisingly as dataset size is often line-
arly related to number of regression trees required to build the models
(Biau and Scornet, 2016). This will enable the RF model to learn more
patterns
in the water quality datasets efficiently and improve
chlorophyll-a predictions. The most occurring max_depth when using
the manually sampled dataset was 28, which increased to 37 when more
datasets were used to train the model. Deeper trees in the continuous
high frequency data allows the model to learn intrinsic water quality
patterns. Less deep trees in the manually sampled datasets helps the
model to learn effectively with the few datasets without overfitting. The
inclusion of the chlorophyll-a sensor values as a predictor variable made
little impact on the parameter distribution for both RF_with_Sensor and
RF_w/o_Sensor (Fig. 5). This suggests that increasing predictor numbers

III. Model Development

i. All the datasets were divided randomly into two: 80 % for
training the RF and SVR models, and 20 % for testing the
model, although the training set was further randomly
sampled to select training and validation set to obtain opti-
mized model hyperparameters.

EcologicalInformatics82(2024)1027355I. Busari et al.

Table 3
Description of models developed in the study.

Model abbreviation

Description

RF_with_Sensor

RF_w/o_Sensor

SVR_with_Sensor

SVR_w/oSensor

RF_with_Sensor_cont

RF_w/o_Sensor_cont

SVR_with_Sensor_cont

SVR_w/o_Sensor_cont

Fig. 6. Distribution of SVR hyperparameters after 1000 samplings. (Left columns are without chlorophyll-a sensor values, while the right column represents the
scenario with sensor values).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the deployment process of the trained deep learning model. Therefore, I cannot provide a helpful answer regarding the specific steps taken for model deployment, such as model serialization or platform selection.