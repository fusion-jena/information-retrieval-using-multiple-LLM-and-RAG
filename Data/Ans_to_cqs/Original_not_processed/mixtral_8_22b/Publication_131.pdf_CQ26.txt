Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

proper databases for CNN training.

Sensors 2021, 21, x FOR PEER REVIEW 14 of 18    Figure 11. Structure of the designed CNN. For network training, 80% of the samples were used as training samples, and 20% as tests. This strategy is widely used to enhance the generalization of a machine learning model and prevent overfitting. A balanced sampling was carried out for the test set. For it, one audio sample (with its corresponding data augmentation samples) out of five was selected for each type of anuran call. Thus, 7623 samples were used for training and 1892 for testing. As mentioned in the data augmentation section above, a CNN was first trained for the four sound classes covered in the classification model developed in previous work [18–21]. Later, a second CNN was trained to expand the classification system to the total of the five classes detailed in Table 1. For the first network, the best results were obtained with training in only eight epochs (number of passes of the entire training dataset) and a batch size

As mentioned in the data augmentation section above, a CNN was ﬁrst trained for
the 4 sound classes covered in the classiﬁcation model developed in previous work [20–23].
Later, a second CNN was trained to expand the classiﬁcation system to the total of the
5 classes detailed in Table 1.

For the ﬁrst network, the best results were obtained with training in only 8 epochs
(number of passes of the entire training dataset) and a batch size (number of samples
utilized in one training iteration) equal to 32. For the second network, the best training was
achieved with 6 epochs and, again, a batch size equal to 32. For both networks, the initial
learning rate [33] with 0.001 and the “adam” optimizer [34] were the parameters used in
the training process.

3. Results
3.1. CPS Performance

11 of 19

2.2. CNN Classiﬁcation System

In order to carry out the design of the CNN classiﬁcation system, a set of stages
were followed. These stages are represented in Figure 9 and described in the following
subsections.

Figure 9. Stages in the classiﬁcation system.

Each of the stages was programmed with Python using the Keras library [30] for CNNs.

2.2.1. Data Augmentation

In order to generate a more robust training set, an augmentation process was carried
out using the sound database. When one deals with CNN and images, data augmenta-
tion consists of extending the set of images from their transformations (rotations, size
modiﬁcations, etc.). For the purpose of the present work on sounds, the transformations
must be made on the audios, and later these transformations will be reﬂected in the
mel-spectrogram images.

In this way, for each of the 865 audio samples in the database, 10 additional audios

were generated:
•
•
•

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, there are some indications of strategies employed to improve the performance and generalization of the machine learning models.

One approach mentioned is the use of a balanced sampling technique for the test set. In this case, one audio sample out of every five was chosen for each type of anuran call to ensure representation from all classes in the test set. This can help mitigate potential biases by ensuring that the test set contains a fair distribution of examples from different classes.

Additionally, the authors mention using data augmentation to create a more robust training set. By generating ten additional audios for each of the 865 original audio samples, they effectively increase the diversity of the training data. This can also help reduce any potential biases in the dataset by providing a broader range of examples for the model to learn from.

While these approaches do not directly correspond to the techniques listed in the query, they demonstrate efforts to manage data imbalances and promote better model performance through improved data representation and diversity.