Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1. Hyperparameter ﬁne-tuning results.

Scenario Number of Blocks Number of Filters

Learning Rate Mean IoU Accuracy

1
2
3
4
5
6
7
8
9
10

3
4
5
6
4
4
4
4
4
4

64 , 64, 64
64, 64, 64, 64
64, 64, 64, 64, 64
64, 64, 64, 64, 64, 64
16, 32, 64, 128
32, 64, 128, 256
64, 128, 256, 512
16, 32, 64, 128
16, 32, 64, 128
16, 32, 64, 128

0.001
0.001
0.001
0.001
0.001
0.001
0.001
0.01
0.0005
0.00001

0.30
0.38
0.36
0.32
0.42
0.38
0.31
0.008
0.42
0.39

82%
89%
86%
86%
94%
88%
84%
71%
94%
90%

Scenario 5 was selected as the optimal solution as it had the best values for IoU and accuracy
while training on fewer epochs. The resulting architecture is shown in Figure 4 and described in
the following.

2.5.1. Encoding Path

During our study, we tested different hyperparameters to ﬁnd an optimal setting for our problem.
The different parts of our ﬁnal architecture, as well as the tested hyperparameter settings are described
in the following.

Figure 4. U-net architecture (experimental setup with 3 encoding blocks).

Remote Sens. 2019, 11, 1976

6 of 14

Figure 5. Loss function of the model (training and validation).

2.4. Evaluation Metrics

To assess the performance of the neural network, several evaluation metrics were used. Evaluation
metrics were computed during the forward pass, and were not subject to maximization, but were
rather used as a performance indicator. This helped to optimize the hyperparameters of the model.
In this study, we used a custom implementation of the intersection over union metric. It computes the
intersection of the reference dataset and the predicted classiﬁcation and divides it by the union of the
two (Equation (1)). In addition, we calculated the overall accuracy of the model (Equation (2)).

IoU =

TP
TP + FP + FN

Accuracy =

TP + TN
TP + FN + FP + TN

(1)

(2)

where TP, TN, FP, and FN are true positive, true negative, false positive, and false negative.

In general, the limitations of deep learning in comparison to other machine learning methods
are the requirement of large and high-quality training data, as well as hardware limitations related to
GPU computing power. The most notable advantage of deep learning is the grade of automatization
and a high potential to generalize when using large amounts of representative training data, which
might, however, not always be available; especially with respect to ground-truth labels that might be
scarce or not exist at all.. Furthermore, the black-box nature makes these algorithms a good choice for
classiﬁcation as suggested in this study, but a challenge for modeling physical properties, as is often
the case in forestry. This case study relied on high-resolution orthophotos with 20-cm spatial resolution
obtained from an aerial survey. The great advantage of these data is that many details can be detected.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there is no explicit mention of specific measures taken to ensure the generalizability of the deep learning model such as using a diverse dataset, implementing cross-validation, or stratified splitting. However, the text does state that one of the advantages of deep learning is its ability to generalize when using large amounts of representative training data. Additionally, the study uses a custom implementation of the Intersection over Union (IoU) metric and calculates the overall accuracy of the model to evaluate its performance. These steps could potentially contribute to ensuring the robustness and reliability of the model across various datasets. Nonetheless, without further information regarding the composition of the training dataset and the methodology employed for model development, it cannot be definitively stated what measures were specifically taken to guarantee the generalizability of the deep learning model.