Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Pytorch (Paszke et al., 2019) ML framework for deep learning (CNNs). 
These libraries also include tools for data pre-processing, model selec-
tion and evaluation. To keep our model training and analysis pipelines 
comparable, we use skorch, a scikit-learn compatible neural network li-
brary that wraps PyTorch. This allows the same scikit-learn training and 
evaluation procedure to be used for both models. Skorch is also helpful 
for end-users in CNN training, as it has a clear and simple interface. It 
only requires end-users to add the prepared datasets, model and specify 
the associated hyperparameters (Table 4). Documentation for the entire 
machine learning pipeline can be found at (PyTorch, 2023) for Pytorch 
(Paszke  et  al.,  2019;  scikit-learn,  2023)  for  scikit-learn  and  (skorch, 
2022)  for  skorch.  Commercial  restrictions  apply  to  the  availability  of 
data  used  in  this  work.  However,  links  to  public  code  examples  of

2.2.4. Feature extraction & visualisation 

In  each  of  our  ML  pipelines,  every  image  that  passes  through  the 
VGG16 feature extractor (Fig. 2) results in a matrix of 1 × 4096 features. 
These  are  then  passed  as  inputs  to  the  classifier.  This  happens  auto-
matically in the CNN approach, as the classification (FC) layers are still 
present in the architecture. 

These extracted ‘deep’ features are numerous and difficult to inter-
pret. Therefore, before undertaking any classification of the extracted 

EcologicalInformatics81(2024)1026195C.A. Game et al.                                                                                                                                                                                                                                

Table 4 
Model hyperparameter glossary for CNN & SVM training.  

CNN: 
Batch size 

Epochs 
Loss 

function 

Learning 
rate 

Optimizer 

SVM: 
C 

γ

From a coding perspective, training an SVM is extremely straight-
forward, with training, optimisation and testing executed within only a 
few simple lines of code. The relative complexity with the CNN þ SVM 
approach,  and  by  extension  the  CNN  approach,  rather  lies  in  data 
management and feature extraction. The complexity of these steps is not 
so  much  related to the  actions required, but navigating  the extensive 
literature and knowing “where to start”. As one of the contributions of 
this paper we hope to better guide the user with clear and detailed de-
scriptions  of  these  steps,  that  are  applicable  across  ML  frameworks 
(Table 3). Aside from these preparations, training the CNN classifier is 
further complicated since an optimal is not automatically found. Instead 
performance  metrics  must  be  monitored  across  epochs  and  decisions 
made on when to stop training - typically the point at which training and

EcologicalInformatics81(2024)1026194C.A. Game et al.                                                                                                                                                                                                                                

Fig. 2. Infographic of the ML workflows (CNN & CNN þ SVM) used in this study.  

VGG16 network cannot be trained, we therefore unfroze (replaced) the 
final  FC  layers  (FC2  &  FC3)  to  re-initialize  the  weights  for  training. 
Training only these FC layers enables comparison to the CNN þ SVM 
approach in which they have been replaced with an SVM classifier. We 
also reduced the number of output nodes in FC3 from 1000 (number of 
ImageNet  classes)  to  3,  to  prepare  the  CNN  to  classify  the  3  habitat 
classes. 

2.2.4. Feature extraction & visualisation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available to provide a direct link to the specific code repository mentioned in the given text. However, based on the references provided, I would recommend checking out the official documentation and resources for PyTorch, Scikit-learn, and Skorch, as well as their respective GitHub pages or other online platforms where their source codes might be hosted. Here are some useful links:

* [PyTorch](https://pytorch.org/)
* [Scikit-learn](https://scikit-learn.org/stable/)
* [Skorch](https://github.com/skorch-dev/skorch)

Please note that commercial restrictions may apply to the data used in this work, so accessing the exact code repository might require additional permissions or licenses.