Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  points  were  randomized  and  divided  into  training  (80%)  and 
validation  (20%)  sets.  A  15  m  buffer  was  applied  around  all  sample 
points  to  ensure  independence  between  the  datasets  (Fig.  4).  The 
reference points were then exported to the cloud for model training and 
validation. 

2.4. Indexes calculation

8 

6 

118 

20 

0 
Exponential 
Linear Unit 

0.05 
Exponential 
Linear Unit 

0.15 
Rectified Linear 
Unit  

or Bayesian optimization approaches and should, therefore, be used if 
sufficient computation resources are available. 

Learning  and  loss  curves  were  also  used  to  diagnose  the  learning 
performance of the three models over time (Fig. 7). The training accu-
racy curve provides insight into how the model is learning, while the 
validation accuracy gives insight into the generalizing process. Likewise, 
the training loss curve shows the model’s performance on the training 
data when the optimization algorithm adjusts the model parameters to 
minimize  the  loss  function.  The  validation  loss  curve  measures  the 
model’s performance on new unseen data.

adjustable parameters that control network architecture, optimization 
procedure,  and  regularization.  Common  hyperparameters  include 
number of layers and nodes, learning rate, dropout rate, etc. However, 
optimizing  model hyperparameters  remains imperative  for leveraging

The  main  advantage  of  Hyberband  is  that  it  discards  poorly  per-
forming  configurations  early  in  the  learning  process  to  reduce  the 
computational cost of model training and evaluation while improving 
classification accuracy. This is done using the early stopping technique, 
which allows the algorithm to evaluate the performance of a configu-
ration after only a small fraction of the total training time has elapsed 
since  it has  been shown that many ML models can still achieve good 
performance  early  in  the  training  process.  In  some  cases,  it  has  even 
offered better results than state-of-the-art algorithms, such as Bayesian 
optimization  and  grid  search  (Falkner  et  al.,  2018).  The  Hyperband 
method also improved classification accuracy significantly compared to 
other  optimization  methods  for  image  recognition  and  reinforcement 
learning tasks. (Jamieson and Talwalkar, 2015; Li et al., 2018). 

2.6.3. Bayesian optimization

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the specific requirements of the project or study. Some common postprocessing steps include:

1. Model Evaluation: After training the model, its performance needs to be evaluated using various metrics such as accuracy, precision, recall, F1 score, ROC curve, confusion matrix, etc. These metrics help in understanding the strengths and weaknesses of the model and provide insights into areas where improvements can be made.

2. Hyperparameter Tuning: Hyperparameters are the adjustable parameters that control the network architecture, optimization procedure, and regularization. Optimizing these hyperparameters is essential for achieving optimal performance from the model. Techniques like Grid Search, Random Search, Bayesian Optimization, and Hyperband can be employed for this purpose.

3. Learning Curves Analysis: Learning curves show the model's performance on both training and validation data during the training process. They provide valuable insights into the model's learning behavior and help identify issues like underfitting, overfitting, or convergence problems.

4. Feature Importance: Understanding which features contribute most to the model's predictions can be crucial for interpreting the results and gaining domain knowledge. Methods like saliency maps, SHAP values, LIME, etc., can be used to visualize feature importance.

5. Model Deployment: Once satisfied with the model's performance, it can be deployed in production environments. This involves integrating the trained model into existing systems, setting up APIs, monitoring performance, and ensuring scalability.