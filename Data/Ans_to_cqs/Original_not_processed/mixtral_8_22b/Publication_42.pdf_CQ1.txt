Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Sensors 2021, 21, 343

11 of 18

7,047,754 learnable parameters gave a F1-score of 84.93% which is even lower. CNN
architectures with many parameters (more than 20,000,000) such as ResNetV50 [38] and
InceptionNetV3 [39] gave a high training accuracy, but a lower validation F1-score of 69.1%
and 81.7%, respectively. This result indicates overﬁtting and that more training data are
needed when such large deep learning networks are used. A very high F1-score of 96.6%
was ﬁnally achieved by transfer learning on ResNetV50 using pretrained weights and only
training the output layers. This indicates that the state-of-the-art was able to outperform
our proposed model, but requires pretrained weights with many more parameters.

2.2.4. Summary Statistics

Finally, the customized CNN architectures were compared with selected state-of-
the-art CNN optimized architectures. EfﬁcientNetB0 [36] is scaled to work with a small
image input size of 224 × 224 pixel and has 4,030,358 learnable parameters. Using the
moths dataset with the same data augmentation, the EfﬁcientNetB0 achieved a F1-score
of 88.62%, which is lower than our top ﬁve best architectures. DenceNet121 [37] with

Sensors 2021, 21, 343

11 of 18

Figure 6. Examples of the eight moth species that were observed and labeled for training of the CNN models. The axes
indicate the number of pixels of the annotated bounding boxes.

The dataset was created by selecting images of different individual insects from the
captured sequences of images in the period of observation. To collect sufﬁcient number of
samples for each class several images with different orientations of the same individual

Sensors 2021, 21, 343

9 of 18

Result

0.79
0.22

3.2. Summary Statistics

To evaluate the ﬁnal system, including tracking and classiﬁcation, three survey nights
were selected (30 August to 2 September 2019). This period contained a high number of
moths and a high variation of species, wherein all eight moths species were represented.
The duration of the survey every night was from 22:30 to 05:00, adding up to a total of
22.5 h. Fewer than 1% of the images from this period of survey were used to train the CNN
model. In this way, the algorithm was tested on a mostly unknown data material.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: The method utilized for collecting raw data in the deep learning pipeline involves capturing sequences of images during specific periods of observation. Individual insects are then selected from these captured sequences to create a dataset. Different orientations of the same individual are included to ensure sufficient samples for each class. For instance, in the given context, images from three survey nights (30 August to 2 September 2019) were used to test the algorithm on a mostly unknown data material. It can be inferred that the primary method for gathering raw data is through conducting surveys or observations using image capture devices like cameras or sensors. Public datasets do not seem to have been explicitly mentioned as sources of raw data in the provided context.