Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

Accuracy 

Raw 

Train 

98.75% 
96.77% 
82.25% 
93.71% 

Validation 

97.16% 
98.30% 
89.04% 
91.30% 

Test 

96.16% 
95.15% 
83.30% 
86.48% 

Pre-processed  

Train 

98.21% 
96.94% 
77.25% 
91.61% 

Validation 

97.92% 
97.92% 
79.02% 
87.33% 

Test 

95.98% 
96.52% 
75.44% 
86.29%  

Table 5 
Accuracy of the models swapping the testing sets (source → target).  

Model 

Accuracy 

Raw → Pre-processed 

Pre-processed → Raw 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

82.35% 
82.70% 
69.22% 
65.26% 

54.76% 
78.87% 
29.56% 
33.97%  

Fig. 5. Confusion matrices for the VGG-19 architecture.  

et al., 2017) and SmoothGrad (Smilkov et al., 2017) methods over each 
model. These methods plot a point cloud, where the density denotes the 
input space relevance. Thus, a higher density in a region suggests that 
the network ponderates it the most when classifying.

2. Peruvian Amazon forestry dataset

Kingma, D.P., Ba, J., 2014. Adam: A Method for Stochastic Optimization. arXiv preprint 

arXiv:1412.6980. 

Kornblith, S., Shlens, J., Le, Q.V., 2019. Do better imagenet models transfer better?. In: 

Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 
pp. 2661–2671. https://doi.org/10.1109/CVPR.2019.00277. 

Krause, J., Sapp, B., Howard, A., Zhou, H., Toshev, A., Duerig, T., Philbin, J., Fei-Fei, L., 
2016. The unreasonable effectiveness of noisy data for fine-grained recognition. In: 
European Conference on Computer Vision. Springer, pp. 301–320. https://doi.org/ 
10.1007/978-3-319-46487-9_19. 

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classification with deep 
convolutional neural networks. In: Advances in Neural Information Processing 
Systems, pp. 1097–1105. 

Pizer, S.M., Amburn, E.P., Austin, J.D., Cromartie, R., Geselowitz, A., Greer, T., ter Haar

Figs. 6 and 7 show the visual representation of features when fine- 
tuning  with  raw  and  segmented  images,  respectively.  These  results 
bolster the ones gets in qualitative analysis (Table 4). AlexNet and VGG- 
19 learn high-level leaf features, such as venations and shapes (VGG-19 
more  than  AlexNet).  Moreover,  the  models  fine-tuned  with  the  raw 
dataset  fit  even  better  than  the  other  ones.  A  clear  example  of  this 
observation  is  the  ResNet-101  fine-tuned  with  pre-processed  images 
(Fig.  7).  This  model  has  learned  to  classify  based  on  lateral  sections, 
almost ignoring the leaf. So, the fine-tuned ResNet-101 probably have 
exploited an error in the background removal algorithm of some images. 

6. Discussion

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide explicit information about how the hyperparameters of the model were optimized. However, one can infer from the context that the authors might have used stochastic optimization methods like Adam (Kingma & Ba, 2014), which is mentioned in the references. It is also possible that they could have employed techniques like grid search or random search, but there is no direct evidence supporting these assumptions. Therefore, without further clarification, we cannot definitively state how the hyperparameters of the model were optimized.