Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Matej Buzinkai: Conceptualisation, Writing – original draft, Writing 
–  review  &  editing,  Investigation,  Formal  analysis,  Visualisation,  Su-
pervision. Marko Radeta: Conceptualisation, Methodology, Software, 
Data curation,  Resources, Supervision.  Claudio  Rodrigues: Software, 
Data curation. Francisco Silva: Software, Data curation. Ruben Frei-
tas: Software, Data curation. Sahar Chebaane: Methodology, Investi-
gation,  Writing  –  review  &  editing.  Paola  Parretti:  Methodology, 
Investigation, Visualisation, Data curation, Writing – review & editing. 
Susanne  Sch¨afer:  Methodology,  Conceptualisation,  Investigation, 
Writing – review & editing. Rodrigo Silva: Methodology, Investigation. 
Francesca  Gizzi:  Methodology,  Writing  –  review  &  editing.  Silvia 
Almeida: Formal analysis, Resources. Sonia K.M. Gueroun: Method-
ology,  Investigation,  Visualisation,  Writing  –  review  &  editing.  Jo˜ao

sponses  and  open-ended  queries  to  get  insight  into  the  best  way  the 
monitoring program can bring value to the dive community. Responses 
were compiled  and data was used to calculate the average SUS score 
(Kumar, 2020).

of standardisation, by focusing on the frequency and abundance of specific taxa, while retaining a recreational 
dive  plan.  Additionally,  the  app  also  collects  metadata  on  location,  number  of  dives  and  number  of  divers 
enabling normalisation based on “sampling effort”. In this pilot study, the use of the app was tested to compile 
information on the frequency and abundance of 18 marine taxa selected by local experts based on their con-
servation  status,  commercial  interest,  ecological  function  and/or  their  non-indigenous  origin.  Additionally,  a 
question-based survey was conducted to assess the opinion of users on the app’s usability and the potential value 
for the diving community/industry, showcasing a high usability score and interest among users. Basic statistical 
analysis of the data crowdsourced over the 1-month trial illustrates the potential and value of regional moni-

curator while using the app as a tool for post-dive debriefing. Combined, 
these two steps ensure that there is a specific checklist to cross out and 
that the interview is embedded in regular operations of the dive centre. 
Another aspect that could influence data quality is the possibility of 
misidentifying  species  that  are  less  known  to  the  citizen  scientists 
(Austen  et  al.,  2016;  Freiwald  et  al.,  2018).  This  is  especially  true 
because the app does not require submission of photographic evidence, 
which  could  be  validated  by  experts  (Kosmala  et  al.,  2016)  or  using 
machine learning (Saoud et  al., 2020). Once again, by relying on the 
dive guide to conduct the interview, there is some level of validation of 
the species sighted and reported, as they are often knowledgeable and 
experienced in local fauna and flora. This approach has also been used in 
previous studies as a safeguard for data quality (Branchini et al., 2015;

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about how the data was split for deep learning model training (e.g., train, test, validation). However, it mentions that the app collected metadata on location, number of dives, and number of divers, which suggests that these factors might have been considered when splitting the data. It also states that basic statistical analysis was performed on the crowdsourced data, but it doesn't specify if any machine learning techniques were applied. Therefore, without further context, we cannot determine the exact criteria used to split the data for deep learning model training.