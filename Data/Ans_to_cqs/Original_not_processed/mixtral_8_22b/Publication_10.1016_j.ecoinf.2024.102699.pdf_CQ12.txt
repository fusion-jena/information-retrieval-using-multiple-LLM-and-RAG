Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

For the ViT models, we adapted the approach of pretraining deep
bidirectional transformers for language understanding (BERT) by Devlin
et al. (2018) for birdsong classification. Table 3 provides an overview of
the investigated ViT models with their respective parameterizations.
ViT-S/16, for example, denotes a ViT variant of reduced complexity with
an input patch size of 16 × 16. The sequence length of the transformer
models is inversely proportional to the square of the provided patch size.
In the following, ViT-B/16 is further investigated as it strikes a balance
between general model complexity and classification performance.

2.4. Model architecture

The proposed model architectures are based on DenseNet-161
(Huang et al., 2017) and ResNet-50 (He et al., 2016a, 2016b) as well
as different vision transformers (ViT) (Dosovitskiy et al., 2021; Steiner
et al., 2022) for sound event detection.

The design of our SED models is inspired by the 2019 DCASE
workshop and large-scale PANNs for audio pattern recognition (Kong
et al., 2019). DenseNets are utilized to improve the information flow

7 AudioSet project page, https://research.google.com/audioset/

html

8 librosa project page, https://librosa.org/doc/latest/index.

EcologicalInformatics82(2024)1026996A.S. Kumar et al.

Fig. 3. Comparison of different augmentation methods and their combinations in Table 4 using DenseNet-161 and ViT-B/16. Additionally, plot marks for the
conducted experiments and their results are provided.

transformers see like convolutional neural networks? In: Ranzato, M.,
Beygelzimer, A., Dauphin, Y., Liang, P., Vaughan, J.W. (Eds.), Advances in Neural
Information Processing Systems 34 (NeurIPS 2021), Curran Associates, Inc.. Pp.
12116–12128. URL: https://proceedings.neurips.cc/paper_files/paper/2021/hash/
652cf38361a209088302ba2b8b7f51e0-Abstract.html.

Schlosser, T., Friedrich, M., Beuth, F., Kowerko, D., 2022. Improving automated visual
fault inspection for semiconductor manufacturing using a hybrid multistage system
of deep neural networks. J. Intell. Manuf. 33, 1099–1123. URL: https://link.springer.
com/article/10.1007/s10845-021-01906-9.

Schlosser, T., Friedrich, M., Meyer, T., Kowerko, D., 2024. A Consolidated Overview of

✓
✓
✓
✓
✓
✓
✓

✓

✓
✓

✓

15
15
13
13
13
13
13
26
15
15
40
29
16
13
13
15
15
16
10

24
24
30
30
30
30
30
45
26
26
60
45
40
30
30
30
30
35
20

✓
✓
✓

✓

✓
✓

✓

✓

ID

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

Table 3
Summarized DNN layer configuration for the backbone models DenseNet-161 and ResNet-50 as well as ViT-S/16, ViT-B/16, and ViT-L/16. S, B, and L denote the ViT
models’ small, base, and large variants.

Model

DenseNet-161

ResNet-50

ViT-S/16

ViT-B/16

ViT-L/16

Layers

161

50

8

12

24

Hidden size

MLP size

Params [m.]

Training time [min. / epoch]

Testing time [sec. / sample]

48

64

786

786

1024

397

397

2 358

3 072

4 096

28.5

25.6

48.6

86.8

304.6

15

15

20

35

45

7

7

22

27

36

ʹ(t) = tanh(γ⋅x(t) ),
x

(13)

samples.

ʹ(t) is the distorted audio signal,
where x(t) is the original audio signal, x
and γ is the pre-gain applied to the signal before distortion, which
controls its intensity.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The paper uses several types of deep learning models in the pipeline, including Convolutional Neural Networks (CNNs) such as DenseNet-161 and ResNet-50, as well as Vision Transformers (ViTs) like ViT-S/16, ViT-B/16, and ViT-L/16. These models are employed for tasks related to sound event detection and birdsong classification.