Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Model retraining 

Based on the quality check, the researcher can decide whether model 

performance  is  satisfactory  or  if  the  model  performance  should  be 
improved by selecting new training images and retraining the model. If 
images from new sites have been classified, model performance can be 
improved by including images from these sites in the training data set. If 
the model had problems with some classes; e.g. identification of some 
species,  it  might  help  to  include  more  images  of  these  species  in  the 
training data set. When selecting new training images, the model output 
from the original model can be helpful to find images that meet a certain 
criteria, e.g. to find images of a certain species. However, all training 
images should be reviewed manually instead of relying on model out-
puts only to avoid misclassified training images. 

2.5. Manual classification

some images from the previous years to the training data set. We then 
retrained the neural network as described before.

We trained a deep neural network in R (R Core Team, 2022) using the 
R-package  keras  (Chollet  et  al.,  2017),  an  interface  to  TensorFlow 
(Abadi et al., 2015) for R. We used the ResNet50 architecture (for details 
about the model architecture see He et al., 2016) with an adam opti-
mizer (Kingma and Ba, 2014). We trained the model from scratch for 55 

EcologicalInformatics76(2023)1021504H. B¨ohner et al.                                                                                                                                                                                                                                 

Fig. 3. The camera trap developed by Soininen et al. (2015) consists of a Reconyx camera that is mounted on the ceiling of a metal box that can be entered by small 
mammals. The camera traps are protected with stones when placed in the field.

Fig. 4. Example images of a vole (A), a lemming (B), a stoat (C), a least weasel (D), a shrew (E), and a bird (F).  

epochs with a one-cycle learning rate policy with a minimum learning 
rate of 0.000001 and a maximum learning rate of 0.001 (Smith, 2018). 
We explored different hyper-parameters and choose the ones that gave 

the best results for training the final model. All images were resized to 
224 x 224 pixels previous to training and image augmentation (shifts, 
horizontal flips, rotations, zooms and shears) was applied to expand the 

EcologicalInformatics76(2023)1021505H. B¨ohner et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, several preprocessing steps may be involved depending on the specific requirements of the dataset and the chosen model architecture. In this case, the authors mention two main preprocessing steps: resizing and image augmentation.

Firstly, they resize all images to 224 x 224 pixels prior to training. This step ensures that each input image has consistent dimensions, which is essential for most convolutional neural networks (CNNs) like the ResNet50 architecture used here. By having uniform input sizes, the CNN can effectively learn spatial hierarchies of features across the entire dataset.

Secondly, the authors apply image augmentation techniques such as shifts, horizontal flips, rotations, zooms, and shears. Image augmentation helps increase the size of the training dataset artificially by creating modified versions of existing images. These modifications introduce variations into the dataset, making the model more robust and generalizable. For instance, applying random transformations like rotation and zoom can help the model recognize objects even when presented in various orientations or scales.

While not explicitly mentioned in the given context, other common preprocessing steps for deep learning models may include normalization, scaling, and cleaning. Normalization involves adjusting pixel values so that they fall within a specified range (usually between 0 and 1), while scaling refers to changing the scale of pixel intensities. Cleaning entails removing noise or irrelevant information from the images, such as background elements unrelated to the target object.

In summary, the primary preprocessing steps discussed in the given context involve resizing images to a standard dimension and employing image augmentation techniques to enhance the diversity of the training dataset. Other potential preprocessing steps for deep learning models could encompass normalization, scaling, and cleaning, although these are not specifically addressed in the provided text.