Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Nearest Neighbors, Support Vector Machines, Decision Trees, Boosting, 
and Random Trees (Yang et al., 2010). However, a growing subarea in 
machine learning, called deep learning, can leverage large image data-
sets  to train  deep neural networks such as  Convolutional Neural  Net-
works (CNNs) (Jordan and Mitchell, 2015) to make accurate predictions 
on new, unseen images.

Usually,  growers  or  entomologists  manually  monitor  pests  using 
morphology keys, pest guides, and images to match key characteristics 
with  common  genera  and  species  names  reported  in  the  literature 
(Bishop and Hutchings, 2011). However, using machine learning, and 
specifically, deep learning approaches, has the potential to expedite this 
important component to the monitoring process by automating several 
tasks using imagery (Grijalva et al., 2023a; Grijalva et al., 2023b; Wang 
et al., 2023). Species detection and classification of organisms found in 
production sorghum fields are common tasks during standard scouting 
events  or  bouts.  Machine  learning  can  automate  these  tasks  with  the 
slightest  use  of  labor  and  time  (Chen  et  al.,  2021).  Many  traditional 
machine  learning  algorithms  have  been  used  to  classify  pests;  these 
include  the  Normal  Bayes  classifier  (a.k.a.,  Naïve  Bayes  classifier),  K

2.3. Imagery splitting ratio 

We split the dataset in a ratio of 80:10:10 for training, validation, and 
testing sets, respectively. This ratio was used due to prior evidence of 
exceed performances in detecting small insects and diseases using deep 
learning models (Kiratiratanapruk et al., 2022; Krishnadas and Sampa-
thila, 2021; Mulchandani et al., 2019). The training dataset consisted of 
1543 images, 243 images for the validation set, and 247 images for the 
testing set and all were at input resolution of 640 × 640 pixels. The 1280 
× 1280 pixels input resolution consisted of 1637 images for the training 
set, 255 images for the validation set, and 262 images for the testing set. 
Independently,  we  trained  5  different  versions  of  the  YOLOv5  model 
family  including:  YOLOv5n,  YOLOv5s,  YOLOv5m,  YOLOv5l,  and 
YOLOv5x models to detect alates on sorghum leaves. 

2.4. Characteristics of deep learning models

tecture family using two different image sizes, including input resolutions of 640 × 640, and 1280 × 1280 pixels. 
We trained models to detect and count individual alates, which ranged between 1 and 100 alates/leaf. Among 
models,  the  YOLOv5l  Pytorch  detection  model  had the  best  overall  performance  at 1280  × 1280  input  pixel 
resolution.  The  YOLOv5l  model  is  a  candidate  model  for  quantifying  alates  on  sorghum  leaves  using  deep 
learning  with  a  precision  of  83.80%,  85.60%  recall,  and  89%  mAP@0.5  with  a  lower  mean  percent  error  of 
misdetection. To enable the use of our best deep learning model by the research community, we developed a 
web-based application that is freely available to the public. Using this application, users can upload images to 
detect and count alates with a low error of misdetection.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, it mentions the use of various deep learning models like YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x for detecting alates on sorghum leaves. These models might employ techniques to manage randomness, but specific details aren't mentioned.

In general, some commonly used strategies to handle randomness in deep learning pipelines include setting fixed seeds for reproducibility, using ensemble methods to average out results from multiple runs, and applying cross-validation techniques to ensure robustness against variations in the training data. Additionally, hyperparameter tuning and regularization methods can help reduce overfitting caused by random fluctuations in the data.