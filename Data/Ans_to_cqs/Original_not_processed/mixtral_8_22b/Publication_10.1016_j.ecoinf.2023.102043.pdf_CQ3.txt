Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

with a relevant audio file, the domain expert can first address such cases. 
The  annotations  are  saved  into  an  SQL  database.  The  database 
management system in use is PostgreSQL version 9.2.24. The main en-
tities contained in the database are event types, event instances, and audio 
files. Event types and event instances are in a one-to-many relationship; 
examples of event types include “goat birth”, “goat death”, “food dis-
tribution”, etc. The occurrence of a given event type can be periodical 
(with  a  daily  or  yearly  frequency),  sporadic,  or  unpredictable.  Event 
instances are, for example, the birth or death of a goat or the distribution 
of fresh grass occurring in a given farm, at a given date and time.

The annotation process is based on the information provided by the 
available farm records filled by the stock persons and the output of the 
YAMNet-based goat vocalization detection algorithm described in Sec-
tion 3.3. Furthermore, cameras were positioned in the barns, and videos 
were transmitted via WiFi to a digital video recorder and stored on a 
hard disk. These videos, together with farm records, were used to sup-
port animal scientists in the labeling of goat vocalizations. To match the 
registers and domain expert knowledge, we designed and developed a 
web-based annotation tool available in the back-end area of the official 
project’s Web site (https://vocapra.lim.di.unimi.it/). The list of possible 
events (i.e., event types) was provided by domain experts, namely ani-
mal scientists  and  farmers. Fig.  8 illustrates  the  variables  used in  the 
study (i.e. contexts of emission) are those out of boxes and are organized

model for extracting the embeddings. 

These are pulled from YAMNet and then fed as input to a sequential 
and  a  reduce  mean  layer  mapping  to  the  classes  mentioned  above 
(Ntalampiras et al., 2021). At this point, the final layers of the network 
map the YAMNet embeddings to the available labels as shown in Fig. 5. 

3.3. Results on goat vocalization detection 

The  dataset  presented  in  Section  3.2  was  divided  into  70%  for 
training, 10% for validation, and 20% for testing purposes. The division 
was  kept  the  same  when  experimenting  with  RF  and  YAMNet-based 

3  The 

librosa  python  package  available  at  https://librosa. 

org/doc/latest/index.html was employed at this stage 

Fig. 3. A close-up picture of a Sensortile.

Farm 

A 
B 
C 
D 
Total 

# Annotated Events 

# Audio Files 

Duration (h) 

1046 
791 
961 
2171 
4969 

3,468,415 
2,939,211 
1,662,819 
1,920,752 
9,991,197 

~ 10,527.82 
~ 12,519.97 
~ 5036.06 
~ 6172.18 
~ 34,256.03  

Therefore, the recording campaign was planned to last an entire year so 
as  to  capture  the  variations  that  goat  vocalizations  demonstrate 
throughout  the  year.  Overall,  we  have  collected  approximately  10  M 
sound  events  lasting  more  than  34,000  h.  Fig.  7  illustrates  the  data 
distribution per farm in terms of number of audio files, annotations and 
durations.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, the data annotation technique used in the deep learning pipeline is not explicitly stated as either bounding box annotation or instance segmentation. However, it is clear that the annotation process involves matching registers and domain expert knowledge using a web-based annotation tool. This tool allows animal scientists and farmers to label goat vocalizations based on the information provided by farm records and the output of a YAMNet-based goat vocalization detection algorithm. Additionally, cameras were placed in barns to record videos that could support the labeling process. Therefore, it appears that the annotation technique used here is more related to audio and video annotation rather than image-based annotation methods like bounding box annotation or instance segmentation.