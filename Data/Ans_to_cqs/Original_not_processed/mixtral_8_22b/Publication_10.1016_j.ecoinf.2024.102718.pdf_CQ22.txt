Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 5
Performance Evaluation Metrics.

Metric

Definition

Formula

Accuracy (Acc)

Loss
Area Under Curve

(AUC)

Cohen’s Kappa

(CK)

Precision

Recall

(Sensitivity)

F1 Score

Model Size

Inference Time

FLOP Count

Analysis Time

This metric measures the proportion of correctly classified instances out of the total instances in
the dataset. It provides an overall indication of how well the model is performing.
Measures the error between predicted and actual values in a model.
Represents the area under the Receiver Operating Characteristic (ROC) curve.

Accuracy = Number of Correct Predictions
Total Number of Predictions
–
–

Measures the agreement between two raters classifying items into mutually exclusive categories.

Measures the proportion of true positive predictions among all positive predictions made by the
model.
Measures the proportion of true positive predictions among all actual positive instances in the
dataset.
Harmonic mean of precision and recall.

Refers to the size of the trained model, usually measured in terms of parameters or memory
footprint.
Measures the time taken by the model to process a single input and generate an output
prediction.
Represents the number of arithmetic operations performed by the model during inference or
training.
Measures the time taken by the model to process a given dataset or perform a specific task.

CK = po (cid:0) pe
1 (cid:0) pe

where po is the observed agreement and pe is

the expected agreement.

Precision =

True Positives
True Positives + False Positives

True Positives
True Positives + False Negatives

Recall =
F1 = 2 × Precision × Recall
Precision + Recall
–

–

–

–

EcologicalInformatics82(2024)1027188A. Chakrabarty et al.

Table 6
Leaf Disease Classification Performance for PlantVillage Dataset (With Noise Added).

Model

ViT
Xception
Inception V3
DenseNet 169
VGG 16
ResNet 50
Proposed BEiT (12 M)

Acc

90.33
88.69
89.33
91.26
90.33
92.82
97.33

Loss

The proposed BEiT model exhibits considerable performance im-
provements in the classification task compared to various conventional
deep learning models, as summarized in Table 16. Achieving an accu-
racy of 98.1%, the BEiT model exceeds all other State-of-the-art models,
including the previously top-performing model by Farian et al. (96.1%).
This improvement in accuracy is statistically significant, with signifi-
cance denoted by the α markers, indicating p < 0.05 using a two-sided
McNemar’s test against the BEiT model. It achieves a precision of
98.2%, a recall of 97.7%, and an F1-score of 96.5%, which are higher
than those of other models such as the ViT-30, ViT-20, and LAMP-LFD
models. Vivek et al.’s model, which shows high precision (94.5%) and
recall (95.0%), still falls short of the BEiT model’s comprehensive

Table 11
Ablation study evaluating BEiT model performance without added noise.

Model

Acc

Loss

AUC

CK

Precision

Recall

F1

98.33
99.33
97.33

0.092
0.082
0.121

5. Performance evaluation and analysis

When assessing the effectiveness of models, a range of measures are
employed to gauge different facets of model performance. Presented
here are several essential performance measurements, accompanied by
their respective descriptions and calculations.

5.1. Performance evaluation metrics

Table 5 summarizes the parameters and matrices used for measuring
the performance of the methods studied in this research along with the
proposed method.

5.2. Performance comparison

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

To evaluate the performance of the deep learning models, several metrics are employed. These include Accuracy, Loss, Area Under Curve (AUC), Cohen’s Kappa (CK), Precision, Recall (also known as Sensitivity), F1 Score, Model Size, Inference Time, Floating Point Operations Per Second (FLOPs) count, and Analysis Time.

Accuracy measures the proportion of correctly classified instances out of the total instances in the dataset. This gives an overall indication of how well the model is performing. The formula for calculating accuracy is:

Accuracy = Number of Correct Predictions / Total Number of Predictions

Loss represents the error between predicted and actual values in a model. Lower loss indicates better performance.

Area Under Curve (AUC) represents the area under the Receiver Operating Characteristic (ROC) curve. Higher AUC means better performance.

Cohen’s Kappa (CK) measures the agreement between two raters classifying items into mutually exclusive categories. It takes into account the possibility of the agreement occurring by chance. CK is calculated as:

CK = po - pe / 1 - pe

where po is the observed agreement and pe is the expected agreement.

Precision measures the proportion of true positive predictions among all positive predictions made by the model. High precision relates to low false positive rate. The formula for calculating precision is:

Precision = True Positives / (True Positives + False Positives)

Recall (or sensitivity) measures the proportion of true positive predictions among all actual positive instances in the dataset. High recall relates to low false negative rate. The formula for calculating recall is:

Recall = True Positives / (True Positives + False Negatives)

F1 score is the harmonic mean of precision and recall. It tries to balance both precision and recall. The formula for calculating F1 score is:

F1 = 2 * (Precision * Recall) / (Precision + Recall)

Model Size refers to the size of the trained model, usually measured in terms of parameters or memory footprint. Smaller model sizes are generally preferred due to lower computational requirements.

Inference Time measures the time taken by the model to process a single input and generate an output prediction. Shorter inference times indicate faster processing speed.

Floating Point Operations Per Second (FLOPs) count represents the number of arithmetic operations performed by the model during inference or training. Lower FLOPs count implies more efficient computation.

Analysis Time measures the time taken by the model to process a given dataset or perform a specific task. Shorter analysis times suggest quicker data processing capabilities.