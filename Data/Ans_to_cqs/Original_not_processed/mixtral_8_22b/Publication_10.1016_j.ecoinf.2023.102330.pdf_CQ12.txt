Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

then be retrained, or used as-is, to detect the target species of interest. 
Training a CNN for acoustic detection is also becomingly increasingly 
more  accessible  as  researchers  develop  and  publish  their  models,  for

Markovian transience or dispersal. Popul. Ecol. 58, 53–62. 

Ruff, Z.J., Lesmeister, D.B., Duchac, L.S., Padmaraju, B.K., Sullivan, C.M., 2020. 

Automated identification of avian vocalizations with deep convolutional neural 
networks. Remote Sens. Ecol. Conserv. 6, 79–92. 

Rusk, J.P., Hern´andez, F., Arredondo, J.A., Hern´andez, F., Bryant, F.C., Hewitt, D.G., 

Redeker, E.J., Brennan, L.A., Bingham, R.L., 2007. An evaluation of survey methods 
for estimating northern bobwhite abundance in southern Texas. J. Wildl. Manag. 71, 
1336–1343. 

Sebasti´an-Gonz´alez, E., Camp, R.J., Tanimoto, A.M., de Oliveira, P.M., Lima, B.B., 

Marques, T.A., Hart, P.J., 2018. Density estimation of sound-producing terrestrial 
animals using single automatic acoustic recorders and distance sampling. Avian Cons 
13, 7. 

Shonfield, J., Bayne, E., 2017. Autonomous recording units in avian ecological research: 

current use and future applications. Avian Conserv. Ecol 12.

Recordings were analyzed using a previously developed CNN model 
(Nolan  et  al., 2022)  trained on covey call  spectrogram data collected 
separately to this study from Di-Lane and other sites around Georgia and 
Alabama,  USA.  Our  covey  call  acoustic  CNN  is  trained  to  detect  and 
localize all covey calls per ARU during the recording period and note 
their associated time and peak power (dB). We chose to use a relatively 
conservative  score  threshold  echoing  that  of  other  similar  studies 
ˇ
Sirovi´c, 2021; Ruff et al., 2020), where only calls that 
(Rasmussen and 
received a score of 0.95 or higher were officially classified as a positive 
bobwhite detection. All CNN detections at a 0.95 score threshold from a 
random sample of five one-hour files from each year were then manually 
reviewed to evaluate model accuracy and to calculate a false positive 
rate “i.e. how many calls were incorrectly labelled as bobwhite”. Across

We then use data augmentation to estimate σARU by adding a number 
of known ‘non-detections’ with distance of NA to our dataset of detected 
or simulated calls, increasing our total number of observations M to 300 
per ARU. We used a data augmentation variable zi,j for each observation 
to indicate whether it was a true call or not, so that the total realized 
M
number of calls including false positive CNN detections (NFPi =
j=1zi,j) 
can be modelled in relation to our data augmentation parameter ψ, pi,j 
and the binary detection outcomes of each call (yi,j)(eq. 10–12). 

∑

zi,j ∼ Bernoulli(ψ)

mui,j = zi,j*pi,j

(cid:0)
yi,j ∼ Bernoulli

mui,j

)

(10)  

(11)  

(12)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The pipeline uses a Convolutional Neural Network (CNN) model for acoustic detection. This is mentioned in several places throughout the provided context. For instance, it is stated that "Recordings were analyzed using a previously developed CNN model" and later it is referred to as the "covey call acoustic CNN." Additionally, there are references to other studies that have used CNNs for automated identification of avian vocalizations. Therefore, based on the given information, we can conclude that a CNN is the type of deep learning model used in the pipeline.