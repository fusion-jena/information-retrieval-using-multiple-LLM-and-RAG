Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.1.3. Data partition 

The raw dataset was randomly shuffled, after which the shuffled data 
were divided into training, validation, and test sets. The training set was 
used to learn the parameters of the model during the training process, 
and the validation set was used to evaluate the modeling and tune its 
hyperparameters. Finally, the performance and generalizability of the 
optimal model were evaluated using the test set. The data partitioning 
ratio between the training, validation, and test sets was set as 8:1:1 and 
the random partition was repeated ten times to reduce the influence of 
random splitting while ensuring converged performance (Geras et al., 
2017). 

2.2. MLP model and model assessments 

2.2.1.

Introduction of MLP

an input layer with the 4200 dimensions of the spectral reflectance data; 
ii) the first hidden layer containing 2048 neurons, which uses the ReLu 
activation function to learn the nonlinear expression of the data; iii) a 
batch normalization layer followed by a dropout layer (random dropout

The performance of a neural network is traditionally improved by 
optimizing  its  hyperparameters,  which  influence  the  overall  model 
performance.  Using  different  hyperparameter  combinations  (e.g., 
combining  different  learning  rates  and  dropout  values)  will  lead  to 
marked  differences  in  the  predictive  performance  of  a  model.  As  a 
traditional  hyperparameter  optimization  method,  the  grid  search 
approach is widely used to optimize a model by comparing the values of 
evaluation  metrics  for  different  parameters  and  selecting  the  optimal 
parameters from a large search space (Bhagat et al., 2020). This method 
can optimize the model by comparing the values of evaluation metrics 
for different parameters and selecting the optimal parameters from the 
search space. In this study, the grid search method was used to optimize 
five of the MLP model’s hyperparameters. The hyperparameter adjust-

EcologicalInformatics81(2024)1026153M. Zhou et al.                                                                                                                                                                                                                                   

Fig. 3. The performance optimization of the MLP model.  

Table 1 
Hyperparameters tuning ranges.  

Hyperparameters 

Type 

Tuning range 

The number of neural network layers 
The number of neurons per layer 
Dropout 
Learning rate 
Batch size 

Integer 
Integer 
Float 
Float 
Integer 

1–5 
64, 128, 256, 512, 1024, 2048 
0.1, 0.25, 0.35, 0.5 
0.001, 0.0001, 0.00001 
32, 64, 128, 256  

Table 2 
the optimal MLP architecture and parameters.  

Layer type 

Input 
Dense 
Batch normalization 
Dropout 
Dense 
Batch normalization 
Dropout 
Dense(output) 
Total parameters 

Layer size 

4200 
2048 
2048 
2048 
1024 
1024 
1024 
1 
10,715,137  

Parameters 

0 
8,603,648 
8192 
0 
2,098,176 
4096 
0 
1025

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the raw dataset was randomly shuffled before being divided into training, validation, and test sets. This step helps prevent any potential bias or pattern in the original order of the data that could affect the model's ability to generalize well on unseen data. Secondly, the data partitioning ratio between the training, validation, and test sets was set as 8:1:1. This distribution allows for a larger portion of the data to be used for training the model, while still reserving enough data for validation and testing purposes. Thirdly, the random partition was repeated ten times to reduce the influence of random splitting while ensuring converged performance. This repetition ensures that the results are not due to chance but rather represent the true performance of the model. Lastly, the grid search method was used to optimize five of the MLP model’s hyperparameters. By systematically searching through a defined set of possible parameter values, the grid search method can help find the best combination of hyperparameters that result in the highest accuracy and generalizability of the model. These measures collectively contribute to improving the robustness and reliability of the deep learning model.