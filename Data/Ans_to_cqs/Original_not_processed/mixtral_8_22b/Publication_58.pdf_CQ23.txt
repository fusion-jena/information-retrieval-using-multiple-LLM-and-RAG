Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

40.32%
35.97%
46.56%
50.21%
38.75%
50.40%
48.38%

For the LU detection task, all deep learning techniques except AlexNet outperformed
XGBoost. Differences were signiﬁcant, with up to 15 percent points in OA. As in the
previous section, the best performing “single-pixel” architecture is DenseNet and the best
“semantic labeling” network is DeepLab. Interestingly, DenseNet reached the best PA,
although DeepLab dominated the remaining metrics.

For the remainder of this study, the best performing “single-pixel” and “semantic
labeling” were selected. There was little difference between the architectures, so the
architectures with the best F1-score for the LU classiﬁcation were chosen arbitrarily.

4.3. Inﬂuence of Neo-Channels and Land Cover as Input on the Learning

12 of 22

3.5. Mapping and Confusion Matrix

After ﬁtting the parameters of the different Deep Learning architectures as well as
XGBoost on the training set, they were run on the test set to obtain a complete mapping of
LC and LU as described above. Confusion matrices were extracted from these results. Four
quality metrics are used: Overall Accuracy (OA), Producer Accuracy (PA), User Accuracy
(UA) and the F1-score. The OA takes the sum of the diagonal of the confusion matrix. The
PA takes the number of well-ranked individuals divided by the sum of the column in the
confusion matrix. The UA takes the number of well-ranked individuals divided by the sum
of the line. Finally, the F1-score is calculated as the harmonic mean of precision and recall.
This last metric allows calculating the accuracy of a model by giving an equal importance
between the PA and the UA. Note that the shadow and cloud areas were not taken into
account in the confusion matrix.

3.4. Sampling Method

The SPOT6 satellite data for our ﬁve study areas were preprocessed to be fed into the
different Deep Learning architectures and the XGBoost model. First, the data were split
into three mutually exclusive parts: a learning set, a validation set and a test set totally
independent of the two previous ones.

Four of the ﬁve areas were used for learning and validation. The last, isolated scene
was then used as the test set. It contained all the classes for the two nomenclatures, the ﬁve
LC classes, and the 12 LU classes. In addition, this image contained all the environments
representing the New Caledonian landscape: urban, mining, mountainous and forest
environment with variations from the coastline to the inland mountain areas. It is on this
entire scene that the ﬁnal confusion matrix and quality metrics were computed.

Remote Sens. 2021, 13, 2257

13 of 22

between 12 land type classes for the classiﬁcation, as described in the nomenclature in
Table 4. Table 8 presents the results of the LU classiﬁcation on the test area and Table A2, in
the Appendix, presents the results of the LU classiﬁcation on the four training areas.

Table 8. Results of Deep Learning architecture and XGBoost for the LU detection task with RGBNIR
as input.

Architectures

XGboost
AlexNet
ResNet
DenseNet
SegNet
DeepLab
FCN

OA

51.56%
45.79%
55.96%
59.59%
58.36
61.45%
56.07%

PA

42.61%
33.93%
43.89%
46.18%
37.16
49.77%
49.59%

UA

38.27%
38.26%
49.58%
55.00%
40.48
51.04%
47.22%

F1-Score

40.32%
35.97%
46.56%
50.21%
38.75%
50.40%
48.38%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of the deep learning models, several measures were taken during the development process. One such measure was the use of diverse datasets. The study utilized five distinct study areas, each containing various landscapes representing the New Caledonian environment, including urban, mining, mountainous, and forest environments. These varied landscapes helped create a more comprehensive and diverse dataset, which improved the model's ability to generalize across different scenarios.

Additionally, the dataset was split into three mutually exclusive parts: a learning set, a validation set, and a test set. This separation allowed for proper evaluation of the model's performance and prevented overfitting, ensuring that the model could perform well on unseen data. Specifically, four of the five areas were used for learning and validation, while the fifth, isolated scene was reserved exclusively for testing. This independent test set contained all the classes for both nomenclatures, making it representative of real-world conditions and further enhancing the model's generalizability.

Moreover, the final confusion matrix and quality metrics were computed using the entire test scene, encompassing all the environments present in the New Caledonian landscape. By evaluating the model's performance on this comprehensive test set, researchers could assess its ability to accurately classify land cover and land use types across diverse environmental settings.

In summary, the study employed multiple strategies to enhance the generalizability of the deep learning models. These included utilizing diverse datasets, separating the data into distinct sets for learning, validation, and testing, and evaluating the model's performance on a comprehensive test set that represented the full range of New Caledonian landscapes.