Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Data-driven models have evolved as effective decision-support tools
for HABs monitoring and prediction. These models are essential for
using patterns between water quality parameters and ecosystem vari-
ables to predict algal-related parameters such as chlorophyll-a, phyco-
cyanin, algal cells, and toxins (Busari et al., 2023; Kimambo et al.,
2019). Machine learning (ML) models such as random forest (RF),
Multilayer perceptron (MLP), long-short term memory (LSTM), and
support vector regression (SVR) have been used successfully to predict
different algal-related parameters and help identify drivers of HABs (Liu
et al., 2019; Qian et al., 2023; Zhang et al., 2015, Busari et al., 2023).
Model predictions are, however, influenced by varying degrees of un-
certainty (Gawlikowski et al., 2023). According to Guzman et al. (2015),
uncertainty refers to the variation between the actual state of a variable
and its theoretical assessment at a particular time. These prediction

included during the model training phase when introducing high-
frequency datasets. This is unsurprisingly as dataset size is often line-
arly related to number of regression trees required to build the models
(Biau and Scornet, 2016). This will enable the RF model to learn more
patterns
in the water quality datasets efficiently and improve
chlorophyll-a predictions. The most occurring max_depth when using
the manually sampled dataset was 28, which increased to 37 when more
datasets were used to train the model. Deeper trees in the continuous
high frequency data allows the model to learn intrinsic water quality
patterns. Less deep trees in the manually sampled datasets helps the
model to learn effectively with the few datasets without overfitting. The
inclusion of the chlorophyll-a sensor values as a predictor variable made
little impact on the parameter distribution for both RF_with_Sensor and
RF_w/o_Sensor (Fig. 5). This suggests that increasing predictor numbers

ensemble models, while the other 20 % was used to validate each model
to obtain individual optimized model hyperparameters. The optimiza-
tion algorithm adopted was the Optuna (Akiba et al., 2019), which
employs complex optimization algorithms to automatically search the
hyperparameter space for the greatest combination of hyperparameters
that minimizes the mean squared error.

required to split the node during tree construction. The min_samples_leaf
determines the number of samples required at a leaf node (Probst et al.,
2019).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text mentions that the dataset was divided into three parts: 80% for training ensemble models, and the remaining 20% for validating each model to obtain individual optimized model hyperparameters. However, it does not explicitly mention any specific criteria used to split the data for deep learning model training, such as train, test, or validation sets. It only states that the optimization algorithm used was Optuna, which employs complex optimization algorithms to automatically search the hyperparameter space for the best combination of hyperparameters that minimizes the mean squared error. Additionally, the text discusses two important hyperparameters for Random Forest models: max_features and min_samples_leaf, but these do not directly relate to splitting the data for deep learning model training. Therefore, based on the given information, there is no clear criterion mentioned for splitting the data for deep learning model training.