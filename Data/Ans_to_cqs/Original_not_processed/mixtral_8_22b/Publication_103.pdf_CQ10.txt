Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Discussion and conclusions
This study is, to our knowledge, the first one that ana-
lyzes a big dataset with thousands of specimen images
from herbaria and uses deep learning. Results show the
potential of deep learning on herbarium species identifi-
cation, particularly by training and testing across different
herbarium datasets. This could potentially lead to the cre-
ation of a semi, or even fully, automatic system to help

Jose et al. BMC Evolutionary Biology  (2017) 17:181 

Page 12 of 14

Fig. 7 Comparison of losses of R.PC.PC, I.PC.PC and H1K.PC.PC experiments

taxonomists and experts do their annotation, classifica-
tion, and revision work at herbarium.

Finally, based on our results, we believe that the devel-
opment of deep learning technology based on herbarium
data, together with the recent recognition of e-publication
in the International Code of Nomenclature [41] will also
contribute to significantly increase the volume of descrip-
tions of new species in the following years.

Acknowledgements
Thanks to the National Museum of Costa Rica for their help with the collection,
identification, and digitization of samples in the Costa Rican leaf-scan dataset.
Special thanks to the Costa Rica Institute of Technology for partially sponsoring
this research. We would also like to thank the large community that has actively
engaged in iDigBio initiative for the valuable access to the herbarium data.

Jose et al. BMC Evolutionary Biology  (2017) 17:181 

Page 13 of 14

Funding
This work was partially supported by the Costa Rica Institute of Technology.

ertheless, in the last five years, deep learning has become
a promising tool to handle extremely complex computer
vision tasks. Additionally, online portals of ambitious ini-
tiatives such as iDigBio already provide access to more
than 14 million herbarium images [9] that are particu-
larly useful for deep learning approaches [10]. Thus, it
is now possible to use images of herbaria thanks to cur-
rent advances in machine learning and initiatives such as
iDigBio.

Results:
potentially exploited for species identification with deep learning technology. In addition, we propose to study if the
combination of herbarium sheets with photos of plants in the field is relevant in terms of accuracy, and finally, we
explore if herbarium images from one region that has one specific flora can be used to do transfer learning to another
region with other species; for example, on a region under-represented in terms of collected data.
Conclusions: This is, to our knowledge, the first study that uses deep learning to analyze a big dataset with
thousands of species from herbaria. Results show the potential of Deep Learning on herbarium species identification,
particularly by training and testing across different datasets from different herbaria. This could potentially lead to the
creation of a semi, or even fully automated system to help taxonomists and experts with their annotation,
classification, and revision works.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available in the given context to determine the exact code repository link of the deep learning pipeline used in this study. The authors did not mention any links to GitHub, GitLab, BitBucket, or any other version control systems where they might have stored their code. Therefore, without additional information, it is impossible to accurately identify the code repository link of the deep learning pipeline used in this study.