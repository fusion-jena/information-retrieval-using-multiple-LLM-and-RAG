Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  iterative  model  exploration  in  this  work  roughly  follows  the 
Bayesian workflow described by Gelman et al. (Gelman et al., 2020). The 
Bayesian and non-Bayesian model pairs are chosen so that one repre-
sents  a  less  flexible  model  in  terms  of  possible  shapes  of  its  decision 
boundary (Bayesian logistic regression and MLE logistic regression) and 
one  represents  a  more  flexible  model  (Bayesian  GAM  and  random 
forest).

Our process of finding the best model roughly follows the Bayesian 
workflow described by Gelman et al. (Gelman et al., 2020). This is an 
iterative modeling process in which one systemically repeats the cycle of 
inspecting the outputs of a model, analyzing the effects of the model and 
its  configurations,  and  adjusting  the  configurations  or  switching  to 
another model type according to the observations. The cycle is repeated 
multiple times while recording the observations and results.

In  our  case,  the  possible  configurations  we  explored  were  these 
modeling  options:  two  sets  of  features  selected  from  a  larger  pool  of 
available features (method in Section 5.2.1), whether or not to scale the 
features, choice of prior strength, and for Bayesian GAM only, the basis 
dimension. For the priors, we were partially able to utilize the priorsense 
package (Kallioinen et al., 2021) to optimize the exploration of different 
configurations.  For  the  rest  of  the  settings  however,  we  kept  to  the 
repeated iterations of the Bayesian workflow. Our workflow results are 
the visualizations and scores presented in Figs. 3, 4, and B.11, and the 
observations are the discussions and analysis in this text: what we can 
interpret from the scores and visualizations and diagnoses of problems, 
if any. 

5.2. Modeling options 

5.2.1. Feature selection

Following this, forward feature selection (FFS) was performed. FFS is 
a  common  stepwise  selection  procedure  (Hastie  et  al.,  2020),  which 
begins with an empty model, and iteratively selects the next feature from 
the initial set which most improves model performance. Candidate lo-
gistic  regression  and  random  forest  models  were  evaluated  via  (1) 
random cross-validation (CV) and (2) spatial CV (Roberts et al., 2017), 
in which the full training dataset was partitioned into spatial blocks like 
those shown in Fig. 2. 

Because model performance estimated via spatial CV is dependent on 
the spatial configuration of the CV folds, the procedure was repeated 
over 100 random blocking configurations; those features selected most 

Fig.  2. One  spatial-CV  fold  pattern  used  in  feature  selection.  This  particular 
fold was also utilized when calculating numerical scores for the models.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps are mentioned in the given context. These include inspecting the outputs of the model, analyzing the effects of the model and its configurations, and adjusting the configurations or switching to another model type based on the observations. This process is part of the iterative modeling process called the Bayesian workflow, described by Gelman et al. (Gelman et al., 2020).

To evaluate the model performance during the feature selection phase, candidate logistic regression and random forest models were assessed using both random cross-validation (CV) and spatial CV (Roberts et al., 2017). In spatial CV, the full training dataset was divided into spatial blocks, as depicted in Figure 2. Since the model performance estimation through spatial CV depends on the spatial arrangement of the CV folds, the procedure was carried out over 100 random blocking configurations.

Additionally, the workflow results included visualizations and scores presented in Figures 3, 4, and B.11, along with discussions and analyses found within the text. These interpretations focused on understanding the scores and visualizations, as well as identifying potential issues, if present. However, specific details regarding saliency maps, metrics calculations, confusion matrices, or other explicit postprocessing techniques are not explicitly mentioned in the provided context.