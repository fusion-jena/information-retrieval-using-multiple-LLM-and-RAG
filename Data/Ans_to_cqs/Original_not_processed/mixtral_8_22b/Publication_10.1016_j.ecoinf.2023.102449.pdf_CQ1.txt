Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  encoder  uses  a  pre-processing  block  containing  a  convolution 
with a wide receptive field (5 × 5 kernel) and signal coarsening along 
the time axis (2 × 1 kernel) (Kahl et al., 2021). Coarsening follows the 
changes suggested in (He et al., 2018) and replicates later versions of 
BirdNet’s  down-sampling  strategy  by  recombining  the  concatenated 
output  of  2 × 2  maximum and  2  × 2 average  pooling using  a  1 × 1 
convolution.  After  convolution,  feature  representations  are  chunked 
along the time axis into T = 19 independent frames each corresponding 
to 3.072 s. Each frame is flattened and passed through a final linear layer 
to  output  T  d-dimensional  mean  μ  and  log  variance  logσ2  vectors  as 
parameters  for  the  Gaussian  variational  posterior.  A  latent  vector  for 
each frame in the time-series is sampled from the posterior using the 
reparameterisation trick. We set d = 128 for comparability with ecoa-

for comprehensive details about acoustic surveys and appendix B for a 
link to the data repository.

Group 

Encoder    
Pre-processing 

ResStack 1 

ResStack 2 

ResStack 3 

ResStack 3 

Temporal Framing 
Bottleneck     

Reparameterisation 

Decoder    
Temporal Framing 
ResStack 3 

ResStack 3 

ResStack 2 

ResStack 1 

Post-processing 

Operation 

Input Shape 

Output Shape 

5 × 5 Conv + BatchNorm + ReLU 
Max & Avg pooling +1 × 1 Conv 
Downsampling block 
2 × Residual Block 
Downsampling block 
2 × Residual Block 
Downsampling block 
2 × Residual Block 
Downsampling block 
2 × Residual Block 
Reshape 

Flatten 
Linear 
Sample 
Linear 
Unflatten 

Reshape 
Upsampling block 
2 × Residual Block 
Upsampling block 
2 × Residual Block 
Upsampling block 
2 × Residual Block 
Upsampling block 
2 × Residual Block 
1 × 1 Conv + BatchNorm + ReLU 
2 × 2 ConvTranspose + BatchNorm + ReLU 
5 × 5 Conv

van den Oord, Aaron, Vinyals, Oriol, Kavukcuoglu, Koray, 2018. Neural Discrete 

1605.07146 [cs.CV.  

Representation Learning arXiv: 1711.00937 [cs.LG].  

Zaugg, Serge, et al., 2023. Towards small and accurate convolutional neural networks for 

White, Tom, 2016. Sampling Generative Networks arXiv: 1609.04468 [cs.NE].  

acoustic biodiversity monitoring arXiv: 2312.03666 [cs.SD].  

EcologicalInformatics80(2024)10244917

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information on the method used for collecting raw data in the deep learning pipeline. However, it mentions the use of acoustic surveys, which suggests that audio recordings might be one source of raw data. Additionally, there is a reference to a link for a data repository in Appendix B, indicating that publicly available datasets could also be part of the data collection process. Unfortunately, without more specific information, I cannot definitively state what methods are being used for collecting raw data in this particular case.