Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

vancements in deep learning to enhance performance. Specifically, our 
MLP architecture consists of four layers, each containing 512 neurons 
and connected with residual connections (He et al., 2016). We employ 
batch normalization (Ioffe and Szegedy, 2015) and the Rectified Linear 
Unit (ReLU) activation function in all layers except the final one, where 
instead a sigmoid function is used to enable multi-label classification. 
The model is trained with a batch size of 256 for 30 epochs using the 
AdamW optimizer (Loshchilov and Hutter, 2017). Both the weight decay 
and learning rate are set to 0.0001. Additionally, we employ a learning 
rate scheduler with exponential decay of 0.95, and introduce dropout

Cambridge University Press. 

Gorishniy, Y., Rubachev, I., Khrulkov, V., Babenko, A., 2021. Revisiting deep learning 

models for tabular data. Adv. Neural Inf. Proces. Syst. 34, 18932–18943. 
Grinsztajn, L., Oyallon, E., Varoquaux, G., 2022. Why do tree-based models still 

outperform deep learning on typical tabular data?. In: In Thirty-sixth Conference on 
Neural Information Processing Systems Datasets and Benchmarks Track. 
Guisan, A., Tingley, R., Baumgartner, J.B., Naujokaitis-Lewis, I., Sutcliffe, P.R., 

Tulloch, A.I., Regan, T.J., Brotons, L., McDonald-Madden, E., Mantyka-Pringle, C., 
et al., 2013. Predicting species distributions for conservation decisions. Ecol. Lett. 16 
(12), 1424–1435. 

EcologicalInformatics81(2024)10262313R. Zbinden et al.

We aim to bridge this gap since the use of neural networks and deep 
learning  techniques  stands  as  a  promising  and  efficient  approach  for 
SDMs (Botella et al., 2023; Davis et al., 2023; Teng et al., 2023). These

Edwards Jr., T.C., Guala, G.F., Howard, T.G., Morisette, J.T., et al., 2019. 
Development and delivery of species distribution models to inform decision-making. 
BioScience 69 (7), 544–557. 

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., 2014. 

Dropout: a simple way to prevent neural networks from overfitting. J. Machine 
Learn. Res. 15 (1), 1929–1958. 

Stokland, J.N., Halvorsen, R., Støa, B., 2011. Species distribution modelling—effect of 
design and sample size of pseudo-absence observations. Ecol. Model. 222 (11), 
1800–1809. 

Teng, M., Elmustafa, A., Akera, B., Bengio, Y., Radi, H., Larochelle, H., Rolnick, D., 2023. 

Satbird: a dataset for bird species distribution modeling using remote sensing and 
citizen science data. In: In Thirty-seventh Conference on Neural Information 
Processing Systems Datasets and Benchmarks Track.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The paper uses a Multi-Layer Perceptron (MLP) architecture for its deep learning model. This architecture consists of four layers, each containing 512 neurons and connected with residual connections. The model employs batch normalization and the Rectified Linear Unit (ReLU) activation function in all layers except the final one, where instead a sigmoid function is used to enable multi-label classification. The model is trained with a batch size of 256 for 30 epochs using the AdamW optimizer. Both the weight decay and learning rate are set to 0.0001. Additionally, a learning rate scheduler with exponential decay of 0.95 is employed, and dropout is introduced to prevent overfitting.