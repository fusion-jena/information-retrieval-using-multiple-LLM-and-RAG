Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  methods  compared  in  this  study  are  evaluated  in  terms  of 
classification  accuracy.  We  divide  the  CLO-43SD  dataset  into  5 
folds  and  perform 5-fold cross  validation,  and  report the  results  as 
a  box-plot  generated  from  the  per-fold  accuracies.  For  identfying 
the best training epoch for the CNN model we use  1 of the 4 training 
folds  as  a validation set, and train on the remaining 3 folds. 

4.  RESULTS AND DISCUSSION 

The results for the MFCC baseline, SKM and CNN models are pro 
vided  in  Figure  1  (left  of the  dashed  line).  Mean  accuracies  are 
indicated  by  the  red  squares.  We  see  that  both  models  based  on 

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:58:01 UTC from IEEE Xplore.  Restrictions apply. 

142 

1.00 

0.98 

0.96 

,., 
~ 0.94 
:; 
8  0.92 
<l: 
ยง  0.90 
~ '"'  0.88 
. ~ 
.!l!  0.86 
ร 

0.84 

0.82 

0.80 

MFCC 

SKM 

CNN 

FUSION

Index  Terms- Convolutional  neural  networks,  bioacoustics, 

flight calls, deep learning, data augmentation. 

1.  INTRODUCTION

During training the model optimi zes cross-entropy loss via mini-
batch  stochastic  gradient descent  [26].  We  use  a constant learning 
rate  of 0.01  and  apply  dropout [27]  to  the  input of the  last two lay 
ers  with  probability 0.5.  L2-regularization  is  applied to  the  weights 
of the last two layers  with  a penalty  factor  of 0.001.  The  model  is 
trained for  100 epochs and is  checkpointed after each epoch.  A val 
idation  set  is  used to  identify  the  parameter setting  (epoch)  achiev 
ing the  highest classification accuracy.  The CNN is  implemented  in 
Python using Lasagne [28] , and data stream  multiplexing (for train 
ing)  is implemented using Pescador [29].

The  automated  classification  of  migrating  birds'  ftight  calls  has 
the  potential  to  yield  new  biologieal  insights  and  conservation  ap 
plications  for  birds  that  vocalize  during  migration.  In  this  paper 
we  explored  two  state-of-the-art classification  techniques  for large 
vocabulary  bird  species  classification  from  flight  calls:  a  "shallow 
learning" unsupervised dietionary learning  method and  a deep con 
volutional  neural  network  combined  with  data  augmentation.  The 
models  were evaluated on a dataset of 5428  ftight  calls from 43  dif 
ferent  species, and  were  compared  against  a  baseline  model  based 
on  MFCCs.  We  showed  that  the  two  models  perform  comparably, 
yielding  a  mean  classification  accuracy  of 0.94  and  significantly 
outperforming  the  MFCC  baseline  (0.85).  We  also  compared  the 
performance of the CNN model  with  and  without augmentation and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the authors divided the CLO-43SD dataset into five folds for performing 5-fold cross-validation. This means that they split the dataset into five equal parts or 'folds'. Four of these folds are used for training the model, while one fold is held back for testing. This process is repeated five times, such that each fold serves once as the test set. Additionally, for identifying the best training epoch for the CNN model, one of the four training folds was used as a validation set, and the model was trained on the remaining three folds. Therefore, the criteria used to split the data for deep learning model training in this case were 5-fold cross-validation and using one fold as a validation set within the training data.