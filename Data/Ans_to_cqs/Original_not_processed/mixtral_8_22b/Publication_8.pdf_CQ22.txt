Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Results

This   rising   number   of   digitised   herbarium   sheets   provides   an   opportunity   to   employ
computer-based   image   processing   techniques,   such   as   deep   learning,   to   automatically
identify species and higher taxa (Carranza-Rojas et al. 2017, Younis et al. 2018, Carranza-
Rojas   et   al.   2018)   or   to   extract   other   useful   information   from   the   images,   such   as   the
presence   of   pathogens   (as   done   for   live   plant   photos   by   Mohanty   et   al.   2016).   Deep
learning is a subset of machine learning methods for learning data representation. Deep
learning   techniques   require   huge   amounts   of   training   data   to   learn   the   features   and
representation of those data for the specified task by fine tuning parameters of hundreds or
thousands of neural networks, arranged in multiple layers. Learning the value of these
parameters can take vast computer and time resources, especially on huge datasets.

1063

117

AP

37.9

18.3

7.9

0.0

25.1

11.8

The model was trained again on all the annotated scans earlier and tested on a different
un-annotated dataset. The model performed well, based on visual inspection. In order to
evaluate the performance of the model with an average precision metric, around 200 of
these   scans   were   annotated   by   hand,   based   on   the   predicted   bounding   boxes.   The
predicted bounding boxes dramatically reduced the time to annotate these scans, since the
predictions for leaves and stems were fairly accurate. After being annotated, these scans
were compared with the predictions to evaluate the precision of the organ detection model
on this dataset.

the overlap, the higher the IoU score. The evaluation method considers all predictions as
positive that have IoU of at least 0.5 and the average precision at this level of IoU is called
AP50. Similarly, the average precision with a minimum IoU of 0.75 is called AP75, whereas
AP   is   the   average   over   10   IoU   levels   from   0.5   to   0.95   with   a   step   size   of   0.05.   The

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: The performance of the deep learning model is evaluated using the Average Precision (AP) metric. This metric is calculated based on the Intersection over Union (IoU) scores between the predicted bounding boxes and the ground truth annotations. A higher IoU score indicates better overlap between the prediction and the actual object. The evaluation method considers all predictions as positive that have an IoU of at least 0.5, and the average precision at this level of IoU is called AP50. Similarly, the average precision with a minimum IoU of 0.75 is called AP75. Additionally, AP is also calculated as the average over 10 IoU levels from 0.5 to 0.95 with a step size of 0.05.