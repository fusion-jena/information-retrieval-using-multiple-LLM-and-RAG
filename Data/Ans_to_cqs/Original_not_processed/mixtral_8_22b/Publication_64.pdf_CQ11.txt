Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Finally for the ResNet50 evaluation we use random ten
crop testing with smaller data augmentation parameters than
those used during training.

4.1 The datasets

4.1.1 Google Search Image. For this dataset we select the
3680 labels (around 60% of all labels) with more than 12
images in our training dataset. For each one of these labels

1Code is available at github.com/IgnacioHeredia/plant classification

Table 1: Accuracy results of the two algorithms for
all three test datasets.

Datasets

Google Image Search
Portuguese Flora
iNaturalist

Accuracy %
ResNet50 (paper) PlantNet (usual)
Top1
40
29
33

Top5
63
47
49

Top1
18
15
18

Top5
37
29
30

we automatically retrieve the 10 ﬁrst images returned by the
Google Image Search engine. As this is done in an automated
fashion some minor mislabeled or corrupt examples might
appear in the dataset. By choosing only the most popular
labels and retrieving the top results, we expect to minimize
the presence of mislabeled images.

In addition we have seen that trained with the same image
dataset, the ResNet architecture outperforms the most wide-
spread online public plant classiﬁcation algorithm by around
a factor of 2 in top1 and top5 accuracies. Besides our model
does not require to enter a suggested image tag along with
the observation.

With all this information in hand we think that large-scale
biodiversity projects like the Global Biodiversity Information
Facility (GBIF) [17] or LifeWatch [18], the European research
infrastructure on biodiversity, could very well beneﬁt from
this new techniques to build a fast and reliable method to
automatically monitor biodiversity. This tool can deﬁnitely
open the ﬁeld to active contributions of non expert users
including citizen scientists.

2 THE DATASET
As training dataset we use the great collection of images
which are available in PlantNet under a Creative-Common
Attribution-ShareAlike 2.0 license. It consists of around 250K
images belonging to more than 6K plant species of Western
Europe. These species are distributed in 1500 genera and
200 families. Each image has been labeled by experts and
comes with a tag which speciﬁes the focus of the image,
like ’habit’, ’ﬂower’, ’leaf’, ’bark’, etc. Most images have
resolutions ranging from 200K to 600K pixels and aspect
ratios ranging from 0.5 to 2. The dataset is highly unbalanced
because most labels contain very few images.

We train on the whole dataset (without making validation
or test splits) as we intend to build a classiﬁer trained on the
same dataset as the PlantNet tool so that their performances
can be fairly compared. At test time we will use three external
datasets to conﬁdently measure the performance of our net.

259CF’17, May 15-17, 2017, Siena, Italy

As deep learning framework we use the Lasagne [11] module
built on top of Theano [12, 13]. We initialize the weights of
the model with the pretrained weights on the ImageNet
dataset provided in the Lasagne Model Zoo. We train the
model for 100 epochs on a GTX 1080 for 6 days using Adam
[14] as learning rule. During training we apply standard data
augmentation (as sheer, translation, mirror, etc) so that the
network never sees the same image. We do not apply rotation
or upside down mirroring to the images tagged as ’habit’, as it
does not make much sense to have a tree or a landscape upside
down. After applying the transformations we downscale the
image to the ResNet standard 224

224 input size. 1

⇥

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide any specific details about the data repository link of the deep learning pipeline. However, it mentions that the training dataset used was obtained from PlantNet, which is available under a Creative-Common Attribution-ShareAlike 2.0 license. Additionally, the paper discusses potential benefits of the proposed technique for large-scale biodiversity projects such as the Global Biodiversity Information Facility (GBIF). Unfortunately, without further information, I cannot provide a direct link to the data repository for the deep learning pipeline.