Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.1. BirdNET performance for different species 

In this analysis we used the annotated calls of 23 species, recorded in 
the Agmon Hula Lake Park between November 2020 and August 2022. 
For each species, we randomly selected 200 segments of 1 s of vocali-
zation  each,  annotated  by  an  expert  birder.  The  recall  and  precision 
results of applying BirdNET-Analyzer to this dataset, which contained a 
total  of  4600  vocalizations,  are  summarized  in  Table  1.  The  average 
recall was 29.7% ± 3.9 SE, and the average precision was 80.9% ± 3.8 
SE. Although the recall is relatively low (above 30% only for 12 out of 23 
species),  for  most  species  the  precision  is  consistently  above  70% 
(Table 1), indicating reliable species detections for subsequent analysis. 
We used a fixed confidence threshold of 0.35 for all species (see P´erez- 
Granados, 2023), which is a good compromise between false positives 
and missed detections for the preliminary analysis.

In this study we demonstrated the use of our monitoring pipeline for 
computing  long-term  activity  behavior  of  several  species  recorded 
continuously for over two years in the Agmon Hula Lake Park located in 
the Hula Valley, a major migratory flyway. We generated the Agmon 
annotated dataset to examine the BirdNET deep learning model. A total 
of 23 species with the highest precision/recall values were selected for 
further analysis. When using automated deep learning models such as 
BirdNET the confidence score can strongly affect the automated iden-
tification  process  (Cole  et  al.,  2022;  P´erez-Granados,  2023).  We 
demonstrated that using BirdNET the relationships between the confi-
dence thresholds and the precision and recall values are species-specific. 
Accordingly,  we  used  species-specific  confidence  thresholds  which 
yielded detection scores that accounts for the precision-recall tradeoff.

Our  monitoring  framework  relies  mainly  on  BirdNET-Analyzer, 
version V2.2,  released in August  2022 (Kahl  et al., 2021), which  is a 
free  BirdNET  application  (Kahl  et  al.,  2021).  BirdNET-Analyzer  is  a 
convolutional  neural  network  with  ResNet  blocks  (He  et  al.,  2016) 
which has been trained to identify >3000 bird species. We used the pre- 
trained  model  with  the  default  sensitivity  (1.0)  and  both  pre-defined 
threshold  confidence  score  values  of  0.35,  0.25  and  0.15  for  the  top 
three identifications, and species specific thresholds (see below) when 
applying our pipeline to conduct long-term analysis. The species specific 
threshold was determined for filtering out false positives while preser-
ving the recall score separately for each species. We computed the recall 
and  precision  for  various  threshold  values  of  the  confidence  score 
(Malamut, 2022), from 0.0 (i.e. without a threshold) to 0.95, with a step 
of 0.05.

In this paper, we present an automated framework that allows the 
monitoring of a large number of bird species by their vocalizations over 
extended periods and across various time scales. The framework relies 
on the BirdNET Analyzer deep learning model (BirdNET-Analyzer, n.d.), 

* Corresponding author at: Dept. of Computer Science, Tel-Hai College, Upper Galilee 12210, Israel. 

E-mail address: yizharle@telhai.ac.il (Y. Lavner).  

https://doi.org/10.1016/j.ecoinf.2024.102528 
Received 4 October 2023; Received in revised form 12 February 2024; Accepted 15 February 2024

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model, BirdNET, is evaluated using the metrics of recall and precision. Recall measures the proportion of true positive predictions made out of all actual positive instances in the data. In this case, it refers to the ability of the model to correctly identify the presence of a particular bird species based on its vocalization. On the other hand, precision measures the proportion of true positive predictions made out of all predicted positive instances. It indicates how many of the detected bird species are actually correct.

In this study, the average recall was found to be 29.7% ± 3.9 SE, and the average precision was 80.9% ± 3.8 SE. Although the recall is relatively low, the precision is consistently high for most species, indicating reliable species detections for further analysis. The authors also mention that they used a fixed confidence threshold of 0.35 for all species, which is a good compromise between false positives and missed detections for preliminary analysis. However, they note that the relationships between the confidence thresholds and the precision and recall values are species-specific, so they used species-specific confidence thresholds to account for the precision-recall tradeoff.