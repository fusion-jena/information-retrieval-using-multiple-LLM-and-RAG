Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.6. Evaluation metrics of the trained models 

In this study, we evaluated four metrics, which are common metrics 
used to evaluate detector models (Padilla et al., 2020). These metrics 
were  the  precision,  mean  average  precision  (mAP@0.5),  recall,  and 
mean  percent  error  of  misdetection.  The  precision  metric  is  the  per-
centage  of  correct  positive  predictions  (Padilla  et  al.,  2020).  The 
mAP@0.5, measures the accuracy of object detection models using an 
Intersection-over-union measure set to 0.5 (Padilla et al., 2020), and the 
recall metric shows how successfully a model can make correct detection 
predictions out of all of the predictions it should make (Padilla et al., 
2020).

2.3. Imagery splitting ratio 

We split the dataset in a ratio of 80:10:10 for training, validation, and 
testing sets, respectively. This ratio was used due to prior evidence of 
exceed performances in detecting small insects and diseases using deep 
learning models (Kiratiratanapruk et al., 2022; Krishnadas and Sampa-
thila, 2021; Mulchandani et al., 2019). The training dataset consisted of 
1543 images, 243 images for the validation set, and 247 images for the 
testing set and all were at input resolution of 640 × 640 pixels. The 1280 
× 1280 pixels input resolution consisted of 1637 images for the training 
set, 255 images for the validation set, and 262 images for the testing set. 
Independently,  we  trained  5  different  versions  of  the  YOLOv5  model 
family  including:  YOLOv5n,  YOLOv5s,  YOLOv5m,  YOLOv5l,  and 
YOLOv5x models to detect alates on sorghum leaves. 

2.4. Characteristics of deep learning models

3. Results 

Out of the YOLOv5 family of detection models, the YOLOv5x model 
performed the highest with a precision of 84%, a recall of 86.90%, and 
90.40% mAP@0.5 (Table 1). The trained models using images at 1280 
× 1280 pixel input resolution performed higher than those using a 640 
× 640 pixel input resolution based on the calculated metrics. Therefore, 
we focused on the  trained models with images  at 1280 × 1280  pixel 
input resolution for the remainder of the results. 

YOLOv5x had the highest precision of 84%, and only <1% lower for 
the YOLOv5l detection model (Table 1). The recall and mAP@0.5 were 

EcologicalInformatics80(2024)1025404I. Grijalva et al.

Nearest Neighbors, Support Vector Machines, Decision Trees, Boosting, 
and Random Trees (Yang et al., 2010). However, a growing subarea in 
machine learning, called deep learning, can leverage large image data-
sets  to train  deep neural networks such as  Convolutional Neural  Net-
works (CNNs) (Jordan and Mitchell, 2015) to make accurate predictions 
on new, unseen images.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: In this study, the authors use four evaluation metrics to assess the performance of their deep learning models. These include precision, mean average precision (mAP@0.5), recall, and mean percent error of misdetection. Precision is defined as the percentage of correct positive predictions made by the model. Mean average precision (mAP@0.5) measures the accuracy of object detection models using an Intersection-over-Union measure set to 0.5. Recall indicates how well the model can correctly identify objects from all possible detections it should make. Lastly, mean percent error of misdetection calculates the proportion of incorrect detections made by the model.