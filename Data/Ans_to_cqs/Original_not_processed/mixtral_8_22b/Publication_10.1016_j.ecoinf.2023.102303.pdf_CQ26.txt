Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 3. Distribution plot of the measured Nephelometric Turbidity Units (NTU) 
in the same geolocation as our FishInTurbidWater dataset gathering. 

2.2. Semi-supervised contrastive learning 

To further reduce the impact of reliance on a high volume of accu-
rately labeled data, we also opted to use another well-known technique 
in deep learning, i.e., contrastive learning. For this, we developed a two- 
phase  semi-supervised  contrastive  learning  approach  as  illustrated  in 
Fig.  4.  Our  proposed  model  consists  of  a  self-supervised  contrastive 
learning phase (phase 1), followed by fully-supervised incremental fine- 
tuning learning (phase 2). It is worth noting that, for the full supervision 
training stage of our model, we use our weakly labeled fish dataset. This 
is in contrast to prior works that mostly use carefully labeled data for the

We collected the FishInTurbidWater dataset and quickly and weakly 
labeled  it  to  contribute  to  the  first  weakly-supervised  fish  dataset  in 
turbid  waters.  We,  then  used  this  dataset  to  develop  two  novel  deep 
learning networks, one using semi-supervised contrastive learning for 
significantly  accelerated  model  deployment  time,  and  one  weakly- 
supervised  model  to  shorten  deployment  time,  while  providing  high 
accuracy. 

For  semi-supervised  contrastive  learning,  we  first  trained  a  self- 
supervised  contrastive  learning  model  and  then  fine-tuned  it  on  our

Labeling Time 
Training Time 
Turnaround 

Time 
Accuracy 

Very Short 
1.0 h 

4 h 

89.4% 

Short 
6.9 h 

22 h 

94.0% 

Very Long 
~3.5 h 

94 h 

98%  

4. Discussions 

The  development  of  deep  learning  methodologies  continues  to 
advance at an astonishing rate and be applied to various applications 
ranging from biomedical (Azghadi et al., 2020), hydrological processes 
in river channels (Talukdar et al., 2023) and agricultural (Olsen et al., 
2019) systems, to marine (Laradji et al., 2021; Saleh et al., 2022b), and 
environmental (Jahanbakht et al., 2022a) sciences. The application of 
deep learning technologies has been also used in profiling the ecosystem 
services of estuarine habitats by community members (Yee et al., 2023). 
In this paper, we extend the application of deep learning methodologies 
to advance state-of-the-art underwater fish video processing techniques 
applied to turbid waters.

1.  Collecting and presenting a new fish dataset in turbid waters.  
2.  Weakly  labelling  this  dataset  to  provide  the  worldâ€™s  first  weakly 

labeled fish dataset in turbid waters.  

3.  Developing two novel deep learning models to achieve two different 

goals.  
a.  A  semi-supervised  model  for  accelerating  model  development 

speed from data collection to deployment.  

b.  A  weakly-supervised  model  for  accelerating  the  development 
time,  while  also  conserving  the  accuracy,  compared  to  the  fast 
semi-supervised model.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some relevant information can still be extracted.

The authors have mentioned collecting a new fish dataset in turbid waters called FishInTurbidWater and labeling it quickly and weakly to create the first weakly-supervised fish dataset in turbid waters. They also discuss developing two novel deep learning networks using this dataset - one with semi-supervised contrastive learning and another with weak supervision. These approaches aim to significantly accelerate model deployment times while maintaining high accuracy.

Although not directly addressing data bias, these methods could potentially help mitigate its effects indirectly. By creating a large, weakly-labeled dataset, they may introduce more diversity into their training data, which could help counteract potential biases present in smaller, carefully curated datasets. Additionally, employing semi-supervised and weakly-supervised learning techniques might enable the models to learn better representations from limited amounts of accurately labeled data, thus reducing the risk of overfitting due to imbalanced classes or other forms of data bias.