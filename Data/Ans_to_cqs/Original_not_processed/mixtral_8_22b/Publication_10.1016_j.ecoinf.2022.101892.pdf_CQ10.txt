Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2.2. ResNet 

However,  with  the  network  depth  increasing,  the  degradation 
problem has been exposed. The degradation indicates that the gradient 
vanishing will limit the performance of the network. Inspired by VGG 
nets, ResNet (He et al., 2016) was proposed to address this problem by 
adding identity mapping (two-branch architecture). ResNets have lower 
complexity and higher performance. In this work, we used ResNet-18 
and ResNet-50 as backbone networks for our experiments. 

2.2.3. RepVGG 

Multi-branch architectures have better performance during training, 
but inference speed is limited. Thus, RepVGG was developed to use a re- 
parameterization technique to decouple the training-time multi-branch 
and inference-time plain architecture to increase inference speed while 
maintaining performance (Ding et al., 2021). RepVGG models are over 
80% faster than ResNets with better performance. And RepVGG-A0 and 
RepVGG-A1 were applied in our experiments. 

2.2.4. MobileNet-V3

Vanhoucke, V., Rabinovich, A., 2015. Going deeper with convolutions. In: 
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 
pp. 1–9. https://doi.org/10.1109/CVPR.2015.7298594. 

Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., Le, Q.V., 2019. 

Mnasnet: Platform-aware neural architecture search for mobile. In: Proceedings of 
the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 
pp. 2820–2828. https://doi.org/10.1109/CVPR.2019.00293. 

W¨agele, J.W., Bodesheim, P., Bourlat, S.J., Denzler, J., Diepenbroek, M., Fonseca, V., 
Frommolt, K.-H., Geiger, M.F., Gemeinholzer, B., Gl¨ockner, F.O., et al., 2022. 
Towards a multisensor station for automated biodiversity monitoring. Basic Appl. 
Ecol. 59, 105–138. https://doi.org/10.1016/j.baae.2022.01.003.

RepVGG has fewer parameters and the highest speed (Table 3). For 
example,  RepVGG-A0  was  26%  and  17%  faster  than  ResNet-18  and 
MobileNet-V3, respectively. RepVGG-A1 was 4.7 times as fast as VGG- 
16-BN  with  roughly  same  number  of  parameters.  RepVGG  showed  a 
favorable  MAE-speed  trade-off  (Table  2  and  Table  3).  Among  these, 
RepVGG-A0 with the OR method achieved the lowest MAE (2.51) and 
the fastest speed (4270). Notably, the number of parameters was not the 
only factor affecting the inference speed, as RepVGG Networks are more 
parameter-efficient than VGG and ResNet networks. 

3.1. Experiment results

2.2.1. VGG 

VGG nets (Simonyan and Zisserman, 2015) achieved huge success in 
image recognition since it was proposed in 2014. VGG nets use small 
(3×3) convolutional filters to increase the depth of the networks, which 
shows  that  scaling  up  networks  by  depth  can  achieve  better  perfor-
mance. By stacking different numbers of convolutional layers can obtain 

EcologicalInformatics72(2022)1018923H.-X. Zang et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not provide information about the code repository link of the deep learning pipeline. Therefore, I cannot provide the requested information based on the available context. Please provide additional details or sources so that I can assist you further.