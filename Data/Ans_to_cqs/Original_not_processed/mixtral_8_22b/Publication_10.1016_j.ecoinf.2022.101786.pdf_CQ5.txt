Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ‘Imagenet classification with deep 
convolutional neural networks’, in. Adv. Neural Inf. Proces. Syst. 1097–1105. 
Langenk¨amper, D., et al., 2017. BIIGLE 2.0 - browsing and annotating large marine 

image collections. Front. Mar. Sci. 4 (83) https://doi.org/10.3389/ 
fmars.2017.00083. 

LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. nature 521 (7553), 436. 
Levin, L.A., 1991. Interaction between metazoans and large, agglutinating protozoans: 
implications for the community structure of deep-sea benthos. Am. Zool. 31, 
886–900. 

Levin, L.A., Gooday, A.J., 1992. Possible roles for Xenophyophores in deep-sea carbon 
cycling. In: Rowe, G.T., Pariente, V. (Eds.), Deep-Sea Food Chains and the Global 
Carbon Cycle. Kluwer, Netherlands, pp. 93–104. 

Levin, L.A., et al., 2019. Global observing needs in the Deep Ocean. Front. Mar. Sci. 6 

(241) https://doi.org/10.3389/fmars.2019.00241.

Training  the  CNN  took  approximately  18  h  to  complete  the  6000 
iterations. Measuring the accuracy of the different CNNs and the effect of 
different confidence thresholds took several hours but could be further 
automated. Predictions on the 58,148 images took approximately 10 h 
however  the  training  and  predictions  phases  do  not  require  constant 
supervision and can be performed overnight or while the analysist is free 
to attend to other tasks. Finally, the calculation-intensive nature of the 
training, and to a lesser extent, prediction phases makes their duration 
largely  dependent  on  the  hardware  used  and  thus  may  vary  between 
users. Overall, the whole pipeline could be completed within one or two 
weeks (10 days) once the analysists are familiar with it. 

4. Discussion

Some model parameters were modified from the default configura-
tion to balance use of resources and training speed. We retained a res-
olution of 704 × 704, batch size 64, 32 subdivisions and trained up to 
6000 iterations. Other parameters were kept to default or set according 
to guidance by the developers (https://github.com/AlexeyAB/darknet). 
Manual annotations were used to generate training, validation and 
testing  datasets.  Biigle  annotations  (label  name,  centre  x,  center  y, 

EcologicalInformatics71(2022)1017863N. Piechaud and K.L. Howell

2.4. Model evaluation 

The testing dataset was composed of 500 manually annotated images 
from  the  same  transect  and  was  only  used  to  calculate  performances 
outside  the  Darknet  framework  by  comparing  CNN  predictions  with 
manual annotations. 

Predictions  come  as  a  .JSON  file  containing  the  coordinate  of  the 
bounding box of each tentative annotation as well as a confidence score 
ranging from 0.05 at minimum (lower confidence scores introduced too 
much  noise  and  therefore  were  not  recorded)  to  1  at  maximum.  Pre-
dictions made on the testing set were compared to the manual annota-
tion of the same images.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The paper does not explicitly mention which specific datasets were used in the deep learning pipeline. However, it mentions that the testing dataset consisted of 500 manually annotated images from the same transect. Additionally, the authors state that they generated training, validation, and testing datasets using manual annotations. Therefore, we can infer that the datasets used in this study were likely custom datasets created specifically for this research rather than commonly used benchmark datasets such as MNIST, CIFAR, or ImageNet.