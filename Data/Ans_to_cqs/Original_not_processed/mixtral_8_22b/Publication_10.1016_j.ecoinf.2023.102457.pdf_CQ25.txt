Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

contribute  to  larger  data  input  for  future  training  of  deep  learning 
models (Best  et  al., 2023).  Accordingly, the  rapid growth of  artificial 
intelligence  and  deep  learning  methods  could  bring  about  important 
innovations related to feature extraction and classification with the aim 
of overcoming the current challenges halting the use of PAM for indi-
vidual acoustic discrimination and succeeding in a sustained and non- 
invasive monitoring of animal populations.

The second approach we used to extract embeddings was from the 
pre-trained  BirdNET  model.  The  original  version  of  the  model  was

capable of identifying 984 North American and European bird species by 
sound (Kahl et al., 2021). BirdNET was trained using a dataset derived 
from  three  primary  sources:  eBird,  Xeno-canto,  and  the  Macaulay  Li-
brary  of  Natural  Sounds.  We  used  BirdNET  version  2.4  which  was 
trained on over 6000 bird and non-bird species (https://github.com/kah 
st/BirdNET-Analyzer). The task-specific model architecture of BirdNET 
was derived from the family of residual networks (ResNets) (Kiyokawa 
et al., 2019), that consists of 157 layers with >27 million parameters, 
and was trained using extensive data pre-processing, augmentation, and 
mixup. BirdNET creates a mel-scale spectrogram between 150 Hz and 
15 kHz and returns 1024 embeddings per 3-s of audio sample. As with 
the VGGish model, we took the mean and standard deviation for em-
beddings over the entire duration of the call, resulting in a feature vector

We expected higher performance of the embeddings, but a possible 
limitation to our study may be the use of pre-trained CNNs. This may 
have limited the potential performance of using embedding from neural 
networks.  Interestingly,  higher  classification  accuracy was  seen  when 
using  BirdNET,  a  CNN  trained  on  audio  data  of  bird  vocalizations  in 
comparison  with  VGGish  and  Wav2Vec  2.0,  two  models  trained 
respectively on a vast Youtube audio dataset and a human speech audio 
dataset. This suggests that training a model with data input of gibbon 
vocalizations might result in an even better performance of neural net-
works for individual gibbon discrimination. However, such data training 
requires a large dataset and is very computationally costly, hence why 
we chose to test pre-trained CNNs.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The purpose of the deep learning model discussed in this context is primarily focused on feature extraction and classification. More specifically, it aims to contribute to larger data inputs for future training of deep learning models, with the goal of improving individual acoustic discrimination and enabling sustained, non-invasive monitoring of animal populations. In particular, the authors utilized the pre-trained BirdNET model, which is capable of identifying numerous bird species based on sound. This model uses a task-specific architecture derived from Residual Networks (ResNets) and generates embeddings from audio samples. These embeddings are then processed further to create feature vectors. While the authors acknowledge that their use of pre-trained convolutional neural networks (CNNs) may have limited the potential performance of using embeddings from neural networks, they also note that higher classification accuracy was observed when using BirdNET compared to other models like VGGish and Wav2Vec 2.0. Ultimately, the objective of these deep learning techniques is to enhance the ability to distinguish between different animals or individuals within a species based on their unique acoustic characteristics.