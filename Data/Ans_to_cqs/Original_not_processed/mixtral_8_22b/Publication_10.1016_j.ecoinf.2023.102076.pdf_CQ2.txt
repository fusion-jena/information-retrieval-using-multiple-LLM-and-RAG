Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics75(2023)1020762S.B. Hunter et al.                                                                                                                                                                                                                               

Fig. 1. Graphical representation of the full classification pipeline, which brings together three binary classification tasks with increasingly specific relevancy criteria. 
At each step, irrelevant texts are filtered out and the remaining relevant texts are used to generate training data for the next classification task. 

Fig. 2. Representation of the different data types collected from online searches.  

EcologicalInformatics75(2023)1020763S.B. Hunter et al.

2.2.2. Training and testing data 

For each classification task in the pipeline, training, development, 
and  testing  sets  were  created  through  manual  annotation  of  2000 
randomly selected data points (randomly split into datasets using 60–20- 
20 ratio), according to the relevancy criteria outlined in Fig.1. To avoid 
over-fitting, development sets were used to evaluate classification per-
formance during experiments, whilst the testing sets were used used to 
evaluate the final classifier for each classification task. As the best per-
forming models and training parameters were identified during exper-
imentation, the testing sets allowed us to identify whether the classifiers 
can maintain their performance when applied to unseen data.

Here,  we  demonstrate  and  evaluate  a  text  classification  pipeline, 
designed to address both the issue of imbalanced datasets and the need 
for large training datasets, using an example data collection scenario. 
Importantly,  we  use  a  hierarchical  classification  approach,  whereby 
data are passed through a series of classifiers with increasingly specific

ventional  ‘flat’  classification  has  been  previously  demonstrated  as  a 
useful  tool  for  filtering  standardised  datasets,  such  as  academic  ab-
stracts,  data  collection  from  online  platforms  often  generates  large 
volumes of highly variable textual data which, as demonstrated by our 
study,  can  necessitate  using  a  hierarchical  classification  approach. 
Although we focused on collecting social media posts and web articles, 
the models and pipeline developed in this study can be applied to other 
forms of textual data, such as listings from E-commerce platforms.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The paper does not explicitly mention the format of the input data used in the deep learning pipeline. However, it is mentioned that the data was collected from online sources, specifically social media posts and web articles. This suggests that the data used in the pipeline is likely to be in text format rather than images, audio, or videos. Furthermore, the authors discuss the challenges of dealing with large volumes of highly variable textual data, further supporting the idea that the data used in the pipeline is primarily text-based. Therefore, based on the information available in the given context, it can be concluded that the data used in the deep learning pipeline is most likely in text format.