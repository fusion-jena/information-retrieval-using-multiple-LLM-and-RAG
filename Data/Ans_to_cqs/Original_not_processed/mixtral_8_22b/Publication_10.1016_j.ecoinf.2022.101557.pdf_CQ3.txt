Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Since the collection and annotation of data for the training of models, 
as  the  one  in  this  paper,  is  a  labour-intensive  process,  it  would  be 
valuable  to  perform  such  profound  investigations  and  quantify  the 
amount of data that may be needed. Another way forward, which avoids 
the labour intense labelling, would be to look for already annotated data 
that have been used for other purposes and then use that data to build AI 
models. One technique, which needs to be further investigated, in order 
to facilitate the collected data better, is to generate additional synthet-
ical  samples  from the  annotated  dataset, using  generative  adversarial 
models,  such  as  in  the  presented  work  by  Fang  et  al.  (2019)  and  Li 
(2019). In such approaches, several new samples are created in a real-
istic  way,  adding  more  variation  and  more  samples  to  the  original 
dataset. Hence, a small dataset can be extended with samples that are

Fig. 4. An excerpt of the map is shown in (a). The areas that are annotated as wetlands, produced by a human, is coloured with blue and shown in (c). The cor-
responding annotation that is produced by a CNN, which has not seen this part of the map during training, is shown in (d). The similarities and differences between 
these two annotations are shown in (b). Here the areas for which the human and the CNN annotations are the same are displayed in green. The areas where the CNN 
annotate the land as wetland but the human did not (false positives) is displayed in pink. Finally, the areas that the humans annotated as wetland but, the CNN did 
not recognise as such (false negatives) are displayed in orange. (For interpretation of the references to colour in this figure legend, the reader is referred to the web 
version of this article.)

2.4. Data pre-processing 

2.2. Convolutional neural networks 

The  idea  behind  convolutional  neural  networks  (CNNs)  was  first 

As mentioned in the previous sections, the data is first split up into 
several  larger  blocks,  depending  on  coordinates,  with  the  purpose  to 
cross validate the model. These blocks are then split into many smaller 
areas of 80 × 80 pixels, due to limitations in the available amount of 

EcologicalInformatics68(2022)1015572N. Ståhl and L. Weimann

realistic augmentations of the original dataset (Shorten and Khoshgof-
taar,  2019).  However,  even  generative  methods  requires  some  anno-
tated  data  to  get  started  and  it  is  uncertain  if  artefacts  from  the 
generative  process  will  be  kept  in  the  generated  data  and  how  these 
artefacts will be expressed.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention specific data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, it does discuss the labor-intensive nature of data collection and annotation for training models. It also mentions the possibility of using already annotated data for building AI models. Furthermore, the text suggests generating additional synthetic samples from annotated datasets using generative adversarial models like those proposed by Fang et al. (2019) and Li (2019). This approach aims to create realistic augmentations of the original dataset, potentially increasing its size and diversity. Nevertheless, it is important to note that even generative methods require some initial annotated data and could introduce artifacts in the generated data.