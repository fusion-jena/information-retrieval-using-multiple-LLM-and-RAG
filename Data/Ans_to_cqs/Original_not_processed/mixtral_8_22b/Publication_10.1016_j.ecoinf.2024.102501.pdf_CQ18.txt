Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics80(2024)1025019D. Feng et al.                                                                                                                                                                                                                                    

Table 6 
Performances of different models.  

Models 

Training 

Validation 

SVR1 
SVR2 
SVR3 
WTD-SVR1 
WTD-SVR2 
WTD-SVR3 
WTD-GWO- 
SVR1 
WTD-GWO- 
SVR2 

WTD-GWO- 
SVR3 
LSTM1 
LSTM2 
LSTM3 
BPNN1 
BPNN2 
BPNN3 

R2 

MSE 

MAE 

R2 

MSE 

MAE 

0.7264 
0.7772 
0.8575 
0.7273 
0.7783 
0.8548 

0.5873 
0.4157 
0.2657 
0.5802 
0.4134 
0.2708 

0.3834 
0.3032 
0.217 
0.3712 
0.3015 
0.2247 

0.7352 
0.8254 
0.8838 
0.7348 
0.8271 
0.8935 

0.3833 
0.2527 
0.1681 
0.384 
0.2502 
0.1541 

0.3669 
0.2631 
0.211 
0.7021 
0.2551 
0.2107 

0.9393 

0.1131 

0.1135 

0.9729 

0.0392 

0.1221 

0.9920 

0.0148 

0.0471 

0.996 

0.0057 

0.0422 

0.9966 

0.0061 

0.0404 

0.9973 

0.0038 

0.0381

search algorithms such as the genetic algorithm (GA) and particle swarm 
optimization (PSO) are often used to solve model parameter problems, 
for instance, the number of neurons in neural networks, error penalty 
factor in SVM, etc. For example, Yan used GA and PSO to optimize a BP 
neural network to build a DO estimation model of Beijing Lake in Beijing 
(Yan et al., 2019). Compared with the GA algorithm, PSO is used more in 
DO  modeling  in  combination  with  BPNN,  GRU,  LSTM,  SVM,  support 
vector regression (SVR), and other algorithms (Wu et al., 2018; Huan 
et al., 2020; Zhu et al., 2021; Huang et al., 2021; Cao et al., 2021b; Liu 
et al., 2014, exhibiting high efficiency and good robustness with mini-
mal calculation. Other optimization algorithms, such as the multi-verse 
optimizer,  have  also  been  adopted  for  parameter  optimization  (Yang 
et al., 2021).

3.1. Data and test environment 

In this experiment, the data from the first eight days were used as the 
training set, and the data from the last two days were used as the vali-
dation set. The four water quality parameters, Ec, Tem, Tur, and H, were 
used as inputs of the model to predict the DO concentration after 10 min. 
The test environment consisted of an Intel I5â€“5200U processor with 
CPU clock speed of 2.2 GHz and memory of 8 GB. The operating system 
was Windows 10 (64-bit). The programming language was Python 3.7 
(64-bit), and the integrated development environment was Anaconda 3, 
with Anaconda's sklearn package used for support vector regression and 
PyWavelets used for the wavelet transform. 

Fig. 3. Flowchart of the proposed WTD-GWO-SVR method for predicting DO concentration levels.

an improved LSSVM integrated with a bat algorithm (LSSVM-BA) model 
for  predicting  DO  concentration  in  rivers,  which  outperformed  the 
M5Tree  and  MARS  models  (Yaseen  et  al.,  2018).  Tree-based  models 
usually include decision trees, random forest (RF), and extreme gradient 
boosting  (XGBoost).  Lu  proposed  a  short-term  DO  prediction  model 
based  on  XGBoost  and  RF,  which  was  applied  to  the  data  after  pre-
processing with complete ensemble empirical mode decomposition with 
adaptive noise (CEEMDAN)(Lu and Ma, 2020). Heddam used extreme 
randomized  tree  and  RF  to  predict  DO  concentrations  in  the  Charles 
River  and  Mystic  River,  with  better  model  accuracy  than  those  of 
multilayer perceptron neural network (MLPNN) models (Adnan et al., 
2021). Ahmed proposed a quantile regression forest algorithm for pre-
dicting DO levels in three rivers, and the results show that their model

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, it appears that the strategy implemented to monitor the model performance during training involves using a portion of the dataset as a validation set. Specifically, the data from the first eight days were used as the training set, while the data from the last two days were used as the validation set. This approach allows for the evaluation of the model's ability to generalize to new data and provides insight into its performance during training. Additionally, various metrics such as R2, MSE, and MAE were used to assess the model's performance on both the training and validation sets. However, there is no explicit mention of any specific techniques or methods employed to further improve the model's performance during training beyond what has already been described.