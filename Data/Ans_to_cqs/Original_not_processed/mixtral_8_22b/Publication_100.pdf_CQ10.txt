Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

As commonly done in deep learning, we iteratively learn the model
parameters with stochastic gradient descend, starting from a random
initialization. In each iteration, we randomly sample a batch of ùêµ = 64
reference data patches of size 15 √ó 15 pixels, where a patch is only
considered for training if the center pixel is forested. We consider a
pixel forested if and only if it contains vegetation points (points with
ùê∑ùëß > 1.3 m, see Section 3.1) and also is considered forested based on
NIBIO‚Äôs Norway-wide timber volume map (Astrup et al., 2019). We use
the latter as an additional precautionary measure to avoid unnecessary
noise from non-forested areas, as we are interested in learning forest
characteristics only. For every reference data patch, we randomly pick
an optical image from the correct year and two SAR images (one as-
cending and one descending orbit) with acquisition dates near the one
of the optical image. Using SAR with both ascending and descending

4.5. Implementation details

We have implemented our models in PyTorch (Paszke et al., 2017).
We trained ùëÄ = 5 models with batch size ùêµ = 64 and a base learning
rate ùõº = 10‚àí4. The learning rate is automatically reduced by a factor
of 0.1 when the validation loss has not improved for 15 consecutive
epochs. We apply weight decay to control the strength of the unit
Gaussian prior, with an empirically chosen magnitude of 10‚àí3 that
is inversely proportional to the hyperparameter ùúÜ from Eq. (1). We
chose ùõΩ1 = 0.9, ùõΩ2 = 0.999 and ùúñ = 10‚àí8 as hyper-parameters for the
Adam optimizer. Each neural network was trained on a single Nvidia
RTX2080Ti GPU for ‚àº14 days.

5. Experimental results and discussion

Gast, J., Roth, S., 2018. Lightweight probabilistic deep networks. In: Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3369‚Äì3378.
Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014. Rich feature hierarchies for
accurate object detection and semantic segmentation. In: Conference on Computer
Vision and Pattern Recognition (CVPR). pp. 580‚Äì587.

Goodfellow, I., Bengio, Y., Courville, A., 2016. Deep Learning. MIT Press, http://www.

deeplearningbook.org.

Guo, C., Pleiss, G., Sun, Y., Weinberger, K.Q., 2017. On calibration of modern
neural networks. In: Proceedings of the 34th International Conference on Machine
Learning, Vol. 70. pp. 1321‚Äì1330.

Gustafsson, F.K., Danelljan, M., Schon, T.B., 2020. Evaluating scalable bayesian
deep learning methods
the
IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. pp.
1289‚Äì1298.

robust computer vision.

In: Proceedings of

for

In this paper, we go a step further and exploit recent advances
from the field of Bayesian deep learning (BDL) to densely map forest
structure variables and associated uncertainties from optical and SAR
satellite images. BDL is understood as the deep learning counterpart
to traditional Bayesian inference techniques, for instance those for
linear regression (Rasmussen, 2004, Ch. 2 to 2.1.1) or Gaussian process
regression (Rasmussen, 2004, Ch. 2.1.2 to 2.3). Instead of commit-
ting to a single solution of model parameters, BDL is characterized
by (approximate) marginalization over a posterior distribution of all
possible models, given some assumptions about the prior and the data
likelihood. Such a principled approach is particularly attractive for
data-driven models, where the model uncertainty is not a consequence
of explicit modeling decisions, but instead is caused by the limited
training data. Bayesian marginalization may improve the predictive

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: Unfortunately, there isn't enough information available to provide the exact code repository link of the deep learning pipeline used in this study. However, it is mentioned that the authors have implemented their models using PyTorch, which is an open source machine learning library developed by Facebook's AI Research lab. You can find more information about PyTorch and its documentation here: https://pytorch.org/. Additionally, the authors mention that they trained their models on a single Nvidia RTX2080Ti GPU for approximately 14 days, suggesting that the implementation might be computationally intensive. Without access to the original research article or contacting the authors directly, it would be difficult to determine the specific code repository link for this particular deep learning pipeline.