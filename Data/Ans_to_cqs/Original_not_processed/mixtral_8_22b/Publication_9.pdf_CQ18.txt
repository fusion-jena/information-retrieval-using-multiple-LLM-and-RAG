Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

specific segmentation models. The full instructions and options are 

cluded in model training are shown in Figure 1.

provided on the GitHub repository.

2.3 | Model training procedure

2.5 | Sashimi online model repository

We first used the VGG Image Annotator Version 1.0.6 (https://www.

We constructed a website to serve as a repository for the fish seg-

robots.ox.ac.uk/~vgg/softw are/via/via- 1.0.6.html;  Dutta  et  al., 
2016) to manually annotate pixel coordinates to create precise po-

mentation model (presented here) and future, community generated 

organismal  segmentation  models  (https://sashi mi.shawn tyler schwa 

lygonal mask contours directly around the fish body boundary (i.e. 

rtz.com). We aim to inspire other biologists interested in automated 

where the foreground pixels of the target fish body meet those of 

segmentation to create pre- trained models for their organism(s) of 

the background). We intentionally assigned all segmentation masks

tract the foreground pixels from the background pixels at the bound-

aries of the target. Such model training may require hundreds or even 

thousands of relevant example images and may possibly require addi-

tional generations of training. Users should also consider the quality 

of their supplied mask annotations for training dataset images. Care 

should be taken during manual annotation to ensure coordinates re-

flect a smooth boundary delineating the background pixels from the 

foreground  pixels,  rather  than  a  more  jagged,  rough  approximation 

of the target's location within the image. In sum, users interested in 

refining the model for different use cases should anticipate iteratively 

training models with different sized training datasets and parameters 

until suitable performance is achieved.

Overall,  Sashimi  provides  an  extensible  toolkit  for  automating 

and  evaluating  image  segmentation  performance  using  the  power-

select both common and rarer examples of digitized organismal im-

ages reflecting a diverse set of appearances, backdrops, and contexts. 

Gathering images representing high phenotypic and contextual visual 

diversity  should  help  enhance  model  generalizability  and  perfor-

mance in most cases. Over and above training dataset construction is 

considering the iterative nature of model training required to achieve 

performance  suitable  for  one's  specific  needs.  For  instance,  if  an 

ecologist aims to segment the bodies of organisms for a color pattern 

analysis,  images  with  small  visual  artifacts  along  the  boundaries  of 

the body should not expectedly impact downstream analytical goals. 

However, a morphometric analysis aiming to measure landmarks on 

regions at the edge of the body may require more fine- grained model 

tuning  such  that  predicted  segmentation  masks  more  carefully  ex-

a CNN pre- trained on ImageNet, interested users could implement 

approach  optimizes  the  magnitude  of  change  for  model  weights 

a  machine  vision  task  without  needing  to  train  an  entire  neural 

SCHWARTZ And ALFARO 2041210x, 2021, 12, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13712 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseMethods in Ecology and Evolu(cid:13)on

    |  2343

network from the ground up. Although, model performance may be 

downstream  image  analysis  workflows  without  additional  training. 

weak  if  the  contents  of  input  images  are  distantly  related  or  com-

On  the  other  hand,  COCO  can  be  used  as  a  backbone  for  training

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the strategy implemented to monitor the model performance during training. However, it mentions that users should consider the iterative nature of model training required to achieve performance suitable for their specific needs. This suggests that monitoring the model performance during training might involve assessing its accuracy and adjusting the training process accordingly until satisfactory results are obtained. Additionally, the text emphasizes the importance of considering the quality of the supplied mask annotations for training dataset images, which implies that monitoring the model performance might include checking the precision of the segmentation masks created during the training process.