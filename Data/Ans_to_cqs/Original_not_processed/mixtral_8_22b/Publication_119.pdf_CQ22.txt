Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 8. Accuracy metrics—overall accuracy (Equation (2)) and kappa coeff. (Equation (3))—based
on the predictions of best performing models, SVM and U-Net, compared with the edited map seen in
Figure 8. The accuracy of modelsis much lower compared to the accuracy derived from independent
testing data.

Model Name

Accuracy (%)

Kappa Coeff.

SVM
U-Net

66.5
77.3

0.650
0.655

Remote Sens. 2021, 13, 3495

8 of 29

layer 5 and a batch normalization layer after hidden layer 2 increased the testing accuracy
of the model. These additional layers—dropout and batch normalization—reduce the
over-ﬁtting of the model on the training data and increase generalization on testing data.
The hyperparameters in this network—the learning rate, number of epochs, and batch
size—were further tuned such that the testing accuracy and the kappa were the best among
all models. The optimized hyperparameter values for learning rate and batch size were
0.007 and 48, respectively.

Figure 4. Network architecture implemented for the Deep Neural Network (DNN) model along
with the number of neurons that were optimized for each hidden layer. The output layer contains
11 neurons, corresponding to the number of classes to be classiﬁed.

2.7. Accuracy Assessment

Table 3. Overall accuracy (Equation (2)) and percent change for all classiﬁcation models including
(16 bands) and excluding (8 bands) the shortwave infrared (SWIR) bands.

Accuracy Metric

Overall Accuracy (%) (16 bands)
Overall Accuracy (%) (8 bands)
Percent Decrease

U-Net

90.9
89.2
−1.87

SVM

88.6
83.8
−5.42

RF

84.8
82.1
−3.18

DNN

86.6
79.2
−8.55

a batch normalization layer after hidden layer 2 increased the testing accuracy of the model. These additional layers—dropout and batch normalization—reduce the over-fitting of the model on the training data and increase generalization on testing data. The hyperparameters in this network—the learning rate, number of epochs, and batch size—were further tuned such that the testing accuracy and the kappa were the best among all models. The optimized hyperparameter values for learning rate and batch size were 0.007 and 48, respectively.  Figure 4. Network architecture implemented for the Deep Neural Network (DNN) model along with the number of neurons that were optimized for each hidden layer. The output layer contains 11 neurons, corresponding to the number of classes to be classified. 2.7. Accuracy Assessment To compare the accuracy of various models independent testing data, i.e., same for all models, is used for model evaluation. The confusion/error matrix and subsequent met-rics are

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The performance of the deep learning model, specifically the DNN model mentioned in the given context, is evaluated using two main metrics: overall accuracy and Kappa coefficient.

The overall accuracy metric measures the proportion of correct predictions out of the total number of instances. It can be calculated by dividing the sum of true positives and true negatives by the total number of instances. This metric provides a simple and intuitive measure of how well the model performs across all classes.

On the other hand, the Kappa coefficient is a more robust metric that takes into account the agreement between predicted and actual labels due to chance alone. It ranges from -1 to +1, where +1 indicates perfect agreement, 0 represents no better than random agreement, and negative values indicate disagreement. The Kappa coefficient is particularly useful when dealing with imbalanced datasets or multi-class classification problems, as it provides a more reliable assessment of the model's performance.

In addition to these metrics, the context also mentions the use of a confusion/error matrix for evaluating the model's performance. A confusion matrix is a table that summarizes the prediction results by comparing them against the actual values. It allows for the calculation of various metrics such as precision, recall, F1 score, etc., which provide insights into the model's ability to correctly identify positive cases (precision), its sensitivity towards detecting positive cases (recall), and a balance between precision and recall (F1 score). However, the context does not explicitly mention the use of these specific metrics for evaluating the DNN model.