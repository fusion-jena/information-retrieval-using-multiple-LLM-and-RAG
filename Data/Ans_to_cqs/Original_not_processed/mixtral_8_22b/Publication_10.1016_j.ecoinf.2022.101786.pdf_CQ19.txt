Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Some model parameters were modified from the default configura-
tion to balance use of resources and training speed. We retained a res-
olution of 704 × 704, batch size 64, 32 subdivisions and trained up to 
6000 iterations. Other parameters were kept to default or set according 
to guidance by the developers (https://github.com/AlexeyAB/darknet). 
Manual annotations were used to generate training, validation and 
testing  datasets.  Biigle  annotations  (label  name,  centre  x,  center  y, 

EcologicalInformatics71(2022)1017863N. Piechaud and K.L. Howell

P100 GPU (16 GB of VRAM memory). The Colab notebook was also set 
to “high RAM session” to avoid memory limitations that could interrupt 
the training process.

Beyan, C., Browman, H.I., 2020. Setting the stage for the machine intelligence era in 
marine science. ICES J. Mar. Sci. 77 (4), 1267–1273. https://doi.org/10.1093/ 
icesjms/fsaa084. 

Bisong, E., 2019. Google Colaboratory. In: Bisong, E. (Ed.), Building Machine Learning 
and Deep Learning Models on Google Cloud Platform: A Comprehensive Guide for 
Beginners. Apress, Berkeley, CA, pp. 59–64. https://doi.org/10.1007/978-1-4842- 
4470-8_7. 

Bochkovskiy, A., Wang, C.-Y., Liao, H., 2020. YOLOv4: optimal speed and accuracy of 

object detection. ArXiv, arXiv:2004.10934 [Preprint].  

Borja, A., et al., 2016. Bridging the gap between policy and science in assessing the 
health status of marine ecosystems. Front. Mar. Sci. 3 (175) https://doi.org/ 
10.3389/fmars.2016.00175. 

Brady, H.B., 1883. IV. Note on syringammina, a new type of arenaceous rhizopoda. 

Proceedings of the Royal Society of London 35 (224–226), 155–161.

Training  the  CNN  took  approximately  18  h  to  complete  the  6000 
iterations. Measuring the accuracy of the different CNNs and the effect of 
different confidence thresholds took several hours but could be further 
automated. Predictions on the 58,148 images took approximately 10 h 
however  the  training  and  predictions  phases  do  not  require  constant 
supervision and can be performed overnight or while the analysist is free 
to attend to other tasks. Finally, the calculation-intensive nature of the 
training, and to a lesser extent, prediction phases makes their duration 
largely  dependent  on  the  hardware  used  and  thus  may  vary  between 
users. Overall, the whole pipeline could be completed within one or two 
weeks (10 days) once the analysists are familiar with it. 

4. Discussion

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention which specific deep learning framework was used to build the model. However, it mentions using Darknet, which is an open-source neural network framework written in C and CUDA. It is mainly used for object detection tasks and supports YOLO (You Only Look Once) versions such as YOLOv4 mentioned in the paper. Therefore, we can infer that Darknet was used as the primary framework for building the deep learning model.