Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

http://orcid.org/0000-0002-2176-7935 

R E F E R E N C E S

Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., … Kudlur, M. 
(2016). TensorFlow: A system for large- scale machine learning. OSDI, 
16, 265–283.

Anderson, T. M., White, S., Davis, B., Erhardt, R., Palmer, M., Swanson, A., 
… Packer, C. (2016). The spatial distribution of African savannah her-
bivores: Species associations and habitat occupancy in a landscape 
context.  Philosophical  Transactions  of  the  Royal  Society  B:  Biological 
Sciences, 371, 20150314. https://doi.org/10.1098/rstb.2015.0314
Babaee,  M.,  Dinh,  D.  T.,  &  Rigoll,  G.  (2017).  A  deep  convolutional  neu-
ral  network  for  background  subtraction.  Pattern  Recognition,  76, 
635–649.

classes. Dropout is a form of regularisation that randomly removes 

a  proportion  of  nodes  to  reduce  overfitting  (Srivastava,  Hinton, 

Krizhevsky, Sutskever, & Salakhutdinov, 2014). The fully connected 

layer reduces the vector of image features to the desired dimension-

ality of length two (foreground and background). The softmax layer 

normalises  this  vector  into  probabilities  that  sum  to  one  across  all 

classes.  DeepMeerkat  is  designed  to  be  conservative,  with  a  high 

threshold for retaining frames (acceptance value = 0.1). This means 

that the model must be more than 90% confident that a frame does 

not contain a foreground object to assign a background label. This 

prioritises minimising false negatives at the potential expense of in-

Methods in Ecology and Evolu(cid:13)on

    |  1437

download  for  Mac  and  Windows  with  the  pre- trained  humming-

bird model. In addition, I provide reproducible scripts for local and 

3 |  R E S U LT S

Google  cloud  environments  to  allow  users  to  train  new  models, 

which can then be used in the local software.

2.2 | Test dataset

Feature  extraction  of  the  fixed  inception  layers  completed  in  1 hr 

and  26 min  on  15  CPUs.  Training  of  the  new  layers  completed  in 

27 min on a single CPU. Model evaluation on the 70 test videos com-

pleted in 4 hr and 38 min on 30 CPUs with an average frame rate of 

My  collaborators  and  I  have  been  studying  hummingbird  ecol-

17 frames/s. On average, a video contained  545.84 candidate  mo-

ogy  using  time- lapse  cameras  in  the  Ecuadorian  Andes  since  2013 

tion frames (2.5% of total frames) that were sent for classification by 

(Weinstein & Graham, 2017). Cameras turn on at dawn, off at dusk,

tification. OCEANS 2016 MTS/IEEE Monterey, 1–5.

Nogueira, K., Penatti, O. A. B., & dos Santos, J. A. (2017). Towards bet-
ter  exploiting  convolutional  neural  networks  for  remote  sensing 
scene  classification.  Pattern  Recognition,  61,  539–556.  https://doi.
org/10.1016/j.patcog.2016.07.001

Pimm, S. L., Alibhai, S., Bergl, R., Dehgan, A., Giri, C., Jewell, Z., … Loarie, 
S.  (2015).  Emerging  technologies  to  conserve  biodiversity.  Trends 
in  Ecology  &  Evolution,  30,  685–696.  https://doi.org/10.1016/ 
j.tree.2015.08.008

Price  Tack,  J.  L.,  West,  B.  S.,  McGowan,  C.  P.,  Ditchkoff,  S.  S.,  Reeves, 
S.  J.,  Keever,  A.  C.,  &  Grand,  J.  B.  (2016).  AnimalFinder:  A  semi- 
automated  system  for  animal  detection  in  time- lapse  camera  trap 
images. Ecological Informatics, 36, 145–151. https://doi.org/10.1016/ 
j.ecoinf.2016.11.003

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper referenced here does not explicitly discuss strategies for handling randomness in the deep learning pipeline, such as managing random seed values. However, it does mention the use of dropout, which is a technique used during training to prevent overfitting. Dropout works by randomly removing a certain percentage of neurons from the network during each iteration of training, effectively creating a different 'view' of the data for each iteration. This introduces some level of randomness into the process but is controlled and intentional rather than being due to unpredictable factors like seed values. Other common strategies for managing randomness include setting specific seed values for reproducibility or using techniques like ensemble methods to combine multiple models trained with different seeds.