Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

those conditions (Gutzwiller and Serno, 2023; Muckley et al., 2023). We 
expected that creating a mask to delineate the “area of applicability” for 
the trained model (Meyer and Pebesma, 2021) would successfully filter 
out a significant portion of regions lacking training data, particularly in

Keshavamurthy, R., Dixon, S., Pazdernik, K.T., Charles, L.E., 2022. Predicting infectious 
disease for biopreparedness and response: a systematic review of machine learning 
and deep learning approaches. One Health 15, 100439. https://doi.org/10.1016/J. 
ONEHLT.2022.100439. 

Khun, M., 2022. Classification and Regression Training: Package caret. Available at: http 
s://cran.r-project.org/web/packages/caret/caret.pdf (Accessed: 26 January 2023).  
Laaksonen, M., Sajanti, E., Sormunen, J.J., Penttinen, R., H¨anninen, J., Ruohom¨aki, K., 
et al., 2017. Crowdsourcing-based nationwide tick collection reveals the distribution 
of Ixodes ricinus and I. persulcatus and associated pathogens in Finland. Emerg. 
Microb. Infect. 6 (5) https://doi.org/10.1038/EMI.2017.17.

The attained performance of the trained models (R2  values ranging 
from 0.38 to 0.41) demonstrates the potential for predicting tsetse fly 
relative numbers using machine learning methodologies. Our analysis 
indicates that using environmental and weather data near the period of 
tsetse monitoring yields more accurate predictions compared to longer- 
term averages. When extrapolating tsetse number predictions based on 
different  sets  of  predictors,  significant  disparities  emerge.  VSURF- 
retained variables of 2021 reveal pronounced tsetse hotspots (>6 FTD) 
within  known  tsetse  belts  (McCord  et  al.,  2012).  On  the  other  hand, 
predictions based on RFE-retained variables did not identify prominent 
hotspots,  and  most  of  these  predictions  fell  outside  the  range  of  the 
environmental and weather data used for model training. Notably, for 
RFE-retained variables and VSURF long-term variables, extrapolations

prevent  potential  performance  degradation  of  the  model  and  avoids 
overfitting, which can limit the ability to make good extrapolations to 
unseen regions (Duque-Lazo et al., 2016). In this study, we employed 
two common variable elimination techniques for random forests: 1) RFE 
(Recursive  Feature  Elimination,  Khun,  2022)  and  2)VSURF  (Variable 
Selection Using Random Forests; Genuer et al., 2022). In RFE, the user 
defines a termination condition for model performance, and the algo-
rithm  iteratively  removes  one  variable  at  a  time  while  evaluating  its 
impact  on  the  model’s  performance.  This  process  continues  until  the 
algorithm reaches the best predefined level of model performance. In 
this study, Root Mean Square Error (RMSE) was used as the termination 
condition. As a result, RFE retained all variables whose removal led to a 
deterioration in the best RMSE value. VSURF follows a three-step pro-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no information available regarding the specific hyperparameters used in the deep learning model mentioned in the given context. The context only discusses the use of two common variable elimination techniques for random forests - Recursive Feature Elimination (RFE) and Variable Selection Using Random Forests (VSURF), but does not provide any details about the hyperparameters used in the deep learning model itself. Therefore, it is not possible to determine what hyperparameters were used in the deep learning model from the given context alone.