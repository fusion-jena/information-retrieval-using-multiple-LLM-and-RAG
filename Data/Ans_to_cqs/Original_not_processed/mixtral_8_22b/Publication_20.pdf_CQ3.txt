Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The criteria for the annotation were:

1) Annotate a ﬁsh only if there is no > 10% of its surface covered by

another object (ﬁsh, coral, or substrate).

2) Annotate a ﬁsh only if it can be identiﬁed at the species level in the
frame (i.e. independently from previous or next frames where the
same ﬁsh could have a better position for identiﬁcation).

3) Annotate a ﬁsh only if its apparent size is larger than 3000 squared

pixels, i.e. ignoring ﬁsh individuals too far from the camera.

4) Annotate images from diﬀerent habitats and depths to represent a
broad range of light conditions and environment, and target at least
1200 thumbnails per species.

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet Classiﬁcation with Deep
Convolutional Neural Networks. InAdvances in Neural Information Processing
Systems. pp. 1097–1105.

Krueck, N.C., Ahmadia, G.N., Possingham, H.P., Riginos, C., Treml, E.A., Mumby, P.J.,

2017. Marine reserve targets to sustain and rebuild unregulated ﬁsheries. PLoS Biol.
15 (1), e2000537.

Kulbicki, M., Parravicini, V., Bellwood, D.R., Arias-Gonzàlez, E., Chabanet, P., Floeter,
S.R., ... Mouillot, D., 2013. Global biogeography of reef ﬁshes: a hierarchical quan-
titative delineation of regions. PLoS One 8 (12), e81847.

Langlois, T.J., Harvey, E.S., Fitzpatrick, B., Meeuwig, J., Shedrawi, G., Watson, D., 2010.
Cost-eﬃcient sampling of ﬁsh assemblages: comparison of baited video sta=tions

244

and diver video transects. Aquat. Biol. 9, 155–168.

A link to a depository with architecture details is given at the end of
references. We stopped the network training after 70 epochs (i.e. a
complete scope of the dataset where each image is used only once), to
−5, an exponential
prevent overﬁtting. We used a learning rate of 10
learning decay with a Gamma of 0.95, a dropout of 50% and an Adam
Solver type as learning parameters. Those are classic hyper-parameters
for a fast convergence of the network without over-ﬁtting (Srivastava
et al., 2014). The weight initialization is also classic with a random
Gaussian initialization. The training lasted 8 days on our conﬁguration;
we trained and ran our code on a computer with 64GB of RAM, an i7
3.50GHz CPU and a Titan X GPU card for 900,000 images.

We used at least 2200 thumbnails per ﬁsh species class, and batches

240

S. Villon et al.

Ecological Informatics 48 (2018) 238–244

We used a GoogLeNet architecture as it was the winner of the 2015
competition imageNet (Szegedy et al., 2015), an identiﬁcation chal-
lenge on 1000 diﬀerent classes. This CNN is composed of 22 layers. It
uses inception modules. Inception modules allow the network to use
convolutions of diﬀerent sizes (1*1, 3*3 and 5*5 pixels) and to weight
each of these convolutions. This network could thus account more or
less strongly for the context of each pixel, which increases the range of
possibilities to improve its performance during the training.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the authors did not explicitly mention the specific data annotation technique they employed for their deep learning pipeline. However, based on the information provided, we can infer that they likely utilized some form of object detection or classification annotation methodology.

This is because the authors mentioned using a GoogLeNet architecture, which is designed for image classification tasks. They also stated that they aimed to annotate at least 2200 thumbnails per fish species class, indicating that they were working with labeled datasets for supervised learning purposes.

Additionally, the authors listed several criteria for annotating fishes, such as annotating only if the fish covers no more than 10% of another object, if the fish can be identified at the species level within the frame, and if the apparent size of the fish is larger than 3000 square pixels. These criteria suggest that the authors may have been performing manual annotations, possibly involving bounding boxes around individual fish instances.

However, without explicit confirmation from the authors regarding the exact data annotation technique used, we cannot definitively state whether they employed bounding box annotation, instance segmentation, or any other specific method.