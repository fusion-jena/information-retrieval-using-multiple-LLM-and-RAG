Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

III. 

MATERIALS AND METHODS 

In  this  section  the  dataset  used  in  the  study  is  presented 
along with the modelling approach taken and the evaluation 
metrics used to evaluate the trained model. The section also 
discusses data pre-processing using the Librosa library. Keras 
and TensorFlow 2.2 are utilised as the backend and an Nvidia 
2070 super GPU with 8GB of memory is utilised to accelerate 
model training. In addition, the proposed inferencing pipeline 
is discussed along with the associated technologies. 
A.  Data Collection and Description

The results presented in this section were obtained over 100 
epochs. Figure 9 shows the loss of the model using both the 
test  and  validation  data  during  model  training.  The  figure 
shows  that  there  was  no  overfitting  during  training  and  that 
the dropout layers helped with model regularisation. Although 
model convergence was achieved early in the training session 
the loss shows continuing decreases throughout the specified 
epochs. 

Figure 10. Train and Validation Accuracy During the 
Training Session. 

Table 1 shows the performance metrics obtained using the 
test data. The best performing class was the Eurasian Collard 
Dove achieving a Sensitivity of 0.86 and a Specificity of 0.90. 
The  worst  performing  class  was 
the  Lesser  Spotted 
Woodpecker  where  the  model  attained  a  Sensitivity  of  0.58 
and a Specificity of 0.91. 

Table 1. Performance Metrics for Test Set 

Species 

Sensitivity 

Specificity

Figure 8. Date Pre-processing Stages 

The  acquired  audio  files  are  transmitted  over  4G  using 
SMTP. The audio file is segmented into 15 second windows. 
Each of the sample windows are passed to the feature extractor 
function where MFCC is used to return the extracted features 
for the classifier. The predicted vector is processed and logged 
to the site for review. 

IV. 

EVALUATION AND DISCUSSION 

In this section the classification results are presented using 
the  evaluation  metrics  outlined  previously.  The  deployment 
and inferencing of the trained model in test environment are 
also presented to ascertain the effectiveness of the end-to-end 
pipeline. 
A.  Species Classification Performance

CNN  approaches  require  a  large  corpus  of  high-quality 
annotated  data  that  can  be  used  to  train  the  network.  Given 
that there is limited availability of publicly available data that 
satisfy this requirement there are currently no viable models 
capable of classifying within species animal types.  Another 
major challenge to overcome is the deployment and automated 
inference  of  acoustic  sensors.  Individually,  sensors  may 
generate  reasonable  amounts  of  data,  but  collectively  the 
amount  of  data  that  needs  to  be  processed  will  increase 
exponentially based on the number of sensors deployed. The 
first challenge relates directly to how the data is obtained. The 
second  is  the  cost  of  compute  needed  to  process  the  data. 
Deploying  trained  models  on  edge  devices  for  real-time 
inferencing will take some consideration which has not been 
sufficiently  reported  in  the  literature.  Centralising  inference

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, it appears that the text does not explicitly mention the specific process followed to deploy the trained deep learning model. However, we can infer from the information provided that the authors utilized Keras and TensorFlow 2.2 as their backend frameworks for building and training the model. Additionally, they mentioned utilizing an Nvidia 2070 Super GPU with 8GB of memory to accelerate model training. This suggests that the model might have been developed and optimized for deployment on hardware with similar or compatible specifications.

Regarding platform selection, the context mentions that the trained model was intended for use in an end-to-end pipeline involving acoustic sensors. It is possible that the chosen platform could involve edge computing devices capable of running the model locally, near the source of the sensor data. However, without explicit details about the deployment process, it remains speculative.

As for model serialization, while the context does not provide direct evidence, it is common practice in machine learning projects to serialize trained models for easier storage, transfer, and deployment. Therefore, it is plausible that the authors serialized their trained model before deploying it onto the target platform.

In conclusion, although the exact process followed to deploy the trained deep learning model is not explicitly stated in the provided context, one can reasonably assume that the authors likely employed practices such as selecting appropriate hardware, possibly considering edge computing platforms, and potentially serializing the trained model for efficient deployment.