Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 1. Schematic diagram of pipeline. We first built model
and then test the model. There are three python scripts used to
for
Coverting_image.py,
including
Making_database.py, and Training.py in a self-developed open
source software Waveman. Tested process using both filtered
images and unfiltered audio-files.

modelling,

2

X. Chen, et al.

Biological Conservation 241 (2020) 108269

Table 1
Taxa summary of the 36 species and itscall information.

Family

Species

Individual number**

No. of images***

Location

Release type

Biological Conservation 241 (2020) 108269

Contents lists available at ScienceDirect

Biological Conservation

journal homepage: www.elsevier.com/locate/biocon

Automatic standardized processing and identification of tropical bat calls
using deep learning approaches

T

Xing Chena,1, Jun Zhaob,1, Yan-hua Chena, Wei Zhoub,*, Alice C. Hughesa,*
a Center for Integrative Conservation, Xishuangbanna Tropical Botanical Garden, Chinese Academy of Sciences, Menglun 666303, China
b Software School, Yunnan University, Kunming 650500, China

A R T I C L E I N F O

A B S T R A C T

Keywords:
Bats
Bioacoustics
Automated monitoring
Algorithms
Deep learning
Neural network
Automatic processing
Biodiversity metrics
Machine learning
Calls
Echolocation
Monitoring protocol

In this study, we demonstrate that our model has high enough ac-
curacy to identify the 36 tropical bat species for both filtered and un-
filtered datasets. For the selected data BatNet outperforms CNNFULL by
increasing the overall accuracy rate from 77% to 91% using the vali-
dated dataset, and shows greatest improvement for the 12 vesperti-
lionid species. This improvement indicates the complicated architecture
of BatNet is more suitable for the application of unfiltered audio-files
recorded in tropical regions than simple networks (i.e., CNNFULL).
Secondly, the unfiltered data collected from different environments,
including nature habitats (i.e., CE (cave entrance) and DF (densely
forested) where bats usually emerge) and human living areas (i.e., AU
(Auditorium) is relatively wide open). The audio-files not only con-
tained no call regions, but only contained signal regions full of echos,
background noises, and high intra-species acoustic variation (such as

rate equaled 1e-3 (only a network called ResNet_v2 was set to 1e-5). We
trained a model using the training dataset (incl. 111,244 images) for
50â€“60 times using Graphic Processing Unit (GPU, Nvidia 1080ti, US)
for two hours and 10 min. After training the model contained refined
parameters and a graph which were saved for the downstream analysis.

2.2. Testing and further refinements of Waveman

We used filtered data (i.e., validation dataset in which 19,614
images were selected) to test different model and taxon bias. Then we
collected audio-files from a corridor for the 15 species to test how to
lower the misidentification and false positives. Finally, we optimized
the BatNet and collected audio from different human and natural
conditions to test the generalization of the model by recording the same
species under different conditions these audio-files are unfiltered and
were directly imported into Waveman.

2.2.1. Comparison of BatNet and other three networks

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific information on the platform used to deploy the deep learning model. It mentions the use of a GPU (Nvidia 1080ti) during the training phase, but there is no mention of any cloud platforms such as AWS, Azure, or Google Cloud Platform being used for deployment. Therefore, based on the given context, it cannot be determined which platform was used to deploy the deep learning model.