Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

kernel to expand without increasing the number of parameters [39]. This expansion of the
window is controlled by the dilation rate and it enables the network to capture information
from a larger receptive ﬁeld of view with the same parameters and computational complex-
ity as the normal convolution. The combination of spatial pyramid pooling with Atrous
convolutions resulted in an efﬁcient multi-scale processing module called Atrous spatial
pyramid pooling (ASPP). In the earlier version (DeepLabV3) [40], the last ResNet block of
the modiﬁed ResNet-101 uses different Atrous convolutions with different dilation rates.
ASPP, together with bilinear up sampling, is also used on top of the modiﬁed ResNet block.
DeepLabv3+ is an improvement in the previous version by adding an effective decoder
module to improve the boundaries of the segmentation results [41]. Furthermore, apart
from ResNet-101, an Xception model can be used as a feature extractor while applying a

Training procedure—We adapted a pre-trained VGG16 network that is a CNN trained
on the ImageNet dataset and used for transfer learning on our dataset [51]. We froze
earlier layers of the base version of the network to make them non-trainable and added an
extra max-pooling layer before the fully connected layers to reduce the dimension of the
previous layer. The feature vector of the fully connected layer was reduced from 2048 units
of the original VGG16 to 128 units, which helped in reducing the computational complexity
without sacriﬁcing much on performance. The model was implemented using Keras with
TensorFlow backend [52].

of the network to make them non-trainable and added an extra max-pooling layer before the fully connected layers to reduce the dimen-sion of the previous layer. The feature vector of the fully connected layer was reduced from 2048 units of the original VGG16 to 128 units, which helped in reducing the compu-tational complexity without sacrificing much on performance. The model was imple-mented using Keras with TensorFlow backend [52]. We trained with a batch size of 32 images per iteration and applied binary cross-entropy as the loss function. All input images were resized to 300 × 300 resolution and trained for 100 epochs with an Adam optimizer at a learning rate of 1 × 10−4. We also ap-plied data augmentation for the training images such as flipping and rotation, with height and width shift as leaves were expected to be indifferent orientations, size, and location hence helped the model to generalize better. The trained classifier was then used as a filter Sensors 2021, 21, 4549

threshold during training for 3000 iterations. At the end of the training process, the best
performing model based on the validation loss was saved and used as the Faster R-CNN
model with a NMS threshold of 0.7 during testing.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about the specific hardware resources used for training the deep learning models mentioned, such as GPUs or TPUs. However, it mentions that the models were implemented using Keras with TensorFlow backend, which suggests that they could have been trained on either CPUs or GPUs depending on the available hardware resources. Additionally, the use of data augmentation techniques like flipping, rotation, and shifting implies that the models might have benefited from GPU acceleration due to their parallelizable nature. Nevertheless, without further details regarding the exact hardware setup, it cannot be definitively stated whether GPUs, TPUs, or other hardware resources were utilized for training these deep learning models.