Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Sensors 2021, 21, 343

11 of 18

7,047,754 learnable parameters gave a F1-score of 84.93% which is even lower. CNN
architectures with many parameters (more than 20,000,000) such as ResNetV50 [38] and
InceptionNetV3 [39] gave a high training accuracy, but a lower validation F1-score of 69.1%
and 81.7%, respectively. This result indicates overﬁtting and that more training data are
needed when such large deep learning networks are used. A very high F1-score of 96.6%
was ﬁnally achieved by transfer learning on ResNetV50 using pretrained weights and only
training the output layers. This indicates that the state-of-the-art was able to outperform
our proposed model, but requires pretrained weights with many more parameters.

2.2.4. Summary Statistics

One of the potential sources of error in the algorithm was the choice of dataset used
for training and validation of the CNN model. Collecting a sufﬁciently large dataset with
enough data points for efﬁcient classiﬁcation of the rarer species was a signiﬁcant challenge.
However, it is likely that increasing the number of images available for training the CNN
model could improve performance even further. The current classiﬁcation algorithm relies
heavily on padding the bounding box found during blob segmentation. The performance
of the system changes signiﬁcantly with variation in padding before CNN prediction. The
CNN algorithm was trained on a dataset using manual annotations of the moths. These do
not surround the moths as closely as the bounding boxes placed by the blob segmentation
(see Figures 4 and 6). Thus, there is a difference in the sizes.

To ﬁnd the best CNN architecture for species classiﬁcation, different hyperparameters
were adjusted as described in Section 2.2.3. A total of 64 architectures were trained using a
dropout probability of 0.3 after the second to last hidden layer. The average F1-score for all
classes was used as a measure for a given architecture’s performance.

The ﬁve best architectures had high F1-scores, which only varied by 0.02, but had a
varying number of learnable parameters (Table 2). Compared to SGD, Adam turned out to
be the superior optimizer for training of all models. In the end, the architecture that had
a rating among the three highest F1-score but the lowest amount of learnable parameters
(2,197,578) was chosen. The reason for this is that an architecture with many parameters
and few training data would increase the risk of overﬁtting the neural network.

2.2.3. Moth Species Classiﬁcation

In the ﬁeld of deep learning, speciﬁc architectures of CNNs have provided particularly
positive results in many areas of computer vision [31]. CNNs use both pixel intensity
values and spatial information about objects in the image. It was a challenging task to ﬁnd
a suitable CNN architecture for classiﬁcation of moth species. Based on an investigation
of several CNN architectures [32,33], a customized network was designed inspired by the
work in [34]. Hyperparameters of the architecture were explored to ﬁnd the optimal
network architecture to classify moth species. The model was designed to be light and fast
for the purpose of being able to be executed on the embedded Raspberry Pi computer used
in the light trap.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the provided context, there isn't any explicit mention of specific strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, some implicit strategies can be inferred from the text.

Firstly, the authors experimented with various CNN architectures and hyperparameters to find the most effective one for their application. By testing multiple configurations, they inherently accounted for variations due to random initialization or other stochastic processes within the deep learning pipeline.

Secondly, the authors utilized dropout regularization techniques to prevent overfitting. Dropout randomly sets a fraction rate of input units to 0 at each update during training time, effectively introducing randomness into the process. This helps reduce co-adaptations between neurons and improves generalization.

Lastly, the authors chose to train their final model using the Adam optimization algorithm instead of Stochastic Gradient Descent (SGD), as Adam proved to be superior for training their models. Adam incorporates momentum and adaptive learning rates, making it less sensitive to initial parameter settings and potentially reducing the impact of randomness caused by suboptimal starting conditions.

While these strategies may not directly address handling randomness related to specific aspects like random seed values, they demonstrate approaches to mitigate the effects of randomness in the overall deep learning pipeline.