Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

applications and relevance to most current MAXENT studies. Divers. Distrib. 2014, 20, 1–9. [CrossRef]
Schmidhuber, J. Deep learning in neural networks: An overview. Neural Netw. 2015, 61, 85–117. [CrossRef]

60.
61. Guo, Y.; Liu, Y.; Oerlemans, A.; Lao, S.; Wu, S.; Lew, M.S. Deep learning for visual understanding: A review. Neurocomputing 2016,

62.

187, 27–48. [CrossRef]
Fukuda, S.; De Baets, B.; Waegeman, W.; Verwaeren, J.; Mouton, A.M. Habitat prediction and knowledge extraction for spawning
European grayling (Thymallus thymallus L.) using a broad range of species distribution models. Environ. Model. Softw. 2013, 47,
1–6. [CrossRef]

63. Harris, D.J. Generating realistic assemblages with a joint species distribution model. Methods Ecol. Evol. 2015, 6, 465–473.

[CrossRef]

64. Lin, M.; Chen, Q.; Yan, S. Network in network. arXiv Prepr. 2013, arXiv:1312.4400.
65. Agarap, A.F. Deep learning using rectiﬁed linear units (relu). arXiv Prepr. 2018, arXiv:1803.08375.
66.

A pooling layer offers downsampling functionality that decreases the dimensionality
of the feature maps to achieve translation invariance to the alterations and the biases
incorporated and thus helps in reducing the number of learnable parameters. There are
two types of pooling operations, namely Max Pooling and Global Average Pooling [64].
The ﬁrst one extracts speckles from the input feature maps and offers maximum values
in each of the speckles and leaves the remaining values unattended. The second one
downsamples a feature map with a size equaling product of height and width into an array
of a one cross one by averaging the elements of each feature map by retaining the depth of
the feature map. The advantage of Global Average Pooling lies in reducing the number of
learnable parameters along with offering the CNN with variable sized input.

Remote Sens. 2021, 13, 3284

15 of 17

Supplementary Materials: The following are available online at https://www.mdpi.com/article/10
.3390/rs13163284/s1. Table S1: Methodology of the convolution and full connected layer.

Author Contributions: Conceptualization, data curation, formal analysis: A.A., M.K.P., and P.K.S.;
funding acquisition: P.K.S.; supervision: P.K.S. and M.L.K.; validation, visualization, writing—
original draft: A.A., M.K.P., and P.K.S.; writing—review and editing: A.G., P.K.S., and M.L.K. All
authors have read and agreed to the published version of the manuscript.

Funding: National Mission on Himalayan Studies, G.B. Pant National Institute of Himalayan Envi-
ronment (NIHE), Almora, Uttarakhand, India.

Institutional Review Board Statement: Not applicable.

Informed Consent Statement: Not applicable.

Convolution is used for feature extraction, in which a kernel is applied to an input
tensor. A feature map is thus obtained through the product of kernel elements and tensor
input. The procedure is then repeated on multiple kernels to obtain random feature maps
that represent different feature extractors. The hyperparameters involved in convolution
operations are the size and number of kernels. The size could be anything from 3 × 3 to
5 × 5 to 7 × 7, and the kernel could be chosen randomly.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't any information about specific data augmentation techniques applied in the given context. However, common data augmentation techniques used in deep learning pipelines include flipping, rotation, scaling, cropping, zooming, shearing, and brightness adjustments. These techniques help increase the amount of training data and improve the generalizability of the model.

Reference(s):
None required for this helpful answer.