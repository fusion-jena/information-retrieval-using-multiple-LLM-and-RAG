Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Supporting Information section at the end of the article.

How to cite this article: Fairbrass AJ, Firman M, Williams C, 

Brostow GJ, Titheridge H, Jones KE. CityNet—Deep learning 

tools for urban ecoacoustic assessment. Methods Ecol Evol. 

2019;10:186–197. https://doi.org/10.1111/2041-210X.13114

FAIRBRASS et Al. 2041210x, 2019, 2, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13114 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

could be averaged to inspect the level of biotic and anthropogenic 

Methods), which gave considerable improvements to network ac-

activity at different times of day.

curacy above any single normalisation scheme in isolation. After 

applying different normalisation strategies, the input to the net-

The ML pipeline was written in python v.2.7.12 (Python Software 

work consisted of a 32 × 21 × 4 tensor.

Foundation,  2016)  using  theano  v.0.9.0  (The  Theano  Development 

5.  Apply CNN classifier:  As  described  above,  classification  was  per-

Team,  et al.  2016)  and  lasagne  v.0.2  (Dieleman  et al.,  2015)  for  ML 

formed with a CNN, whose parameters were learnt from training 

and librosa v.0.4.2 (McFee et al., 2015) for audio processing.

data. The CNN comprised a series of layers, each of which modi-

fied  its  input  data  with  parameterised  mathematical  operations 

which were optimised to improve classification performance dur-

2.1 | Acoustic dataset

436–444. https://doi.org/10.1038/nature14539

Lee, H., Pham, P., Largman, Y., & Ng, A. Y. (2009). Unsupervised feature 
learning for audio classification using convolutional deep belief networks 
(pp. 1096–1104). Proceedings of the 22nd International Conference 
on Neural Information Processing Systems, Istanbul, Turkey.

Lin,  T.-H.,  Fang,  S.-H.,  &  Tsao,  Y.  (2017).  Improving  biodiversity  as-
sessment  via  unsupervised  separation  of  biological  sounds  from 
long- duration  recordings.  Scientific  Reports,  7,  4547.  https://doi.
org/10.1038/s41598-017-04790-7

McFee, B., Raffel, C., Liang, D., Ellis, D. P., McVicar, M., Battenberg, E., 
&  Nieto,  O.  (2015).  librosa: Audio and music signal analysis in python 
(pp. 18–25). Proceedings of the 14th python in science conference, 
Austin, TX.

ditional  methods  (Farinha- Marques,  Lameiras,  Fernandes,  Silva,  & 

automatically  based  on  the  annotated  training  data  provided. 

Guilherme, 2011). This inhibits our ability to conduct the large- scale 

Convolutional Neural Networks, CNNs (or Deep learning) (LeCun, 

assessment that is necessary for understanding urban ecosystems.

Bengio,  &  Hinton,  2015)  can  even  choose,  based  on  the  annota-

Ecoacoustic surveying has emerged as a useful method of large- 

tions in the training dataset, the features that discriminate different 

scale  quantification  of  ecological  communities  and  their  habitats 

classes  in  datasets  without  being  specified  a  priori,  and  can  take 

(Sueur  &  Farina,  2015).  Passive  acoustic  recording  equipment  facil-

advantage of large quantities of training data where their ability to 

itates the collection of audio data over long time periods and large

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no information available regarding the specific hardware resources used for training the deep learning model in the given context. Therefore, it cannot be determined whether GPUs, TPUs, or other types of hardware resources were utilized during the training process.