Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Dujardin, J., Lehning, M., 2022. Wind-topo: downscaling near-surface wind fields to 

high-resolution topography in highly complex terrain with deep learning. Q. J. R. 
Meteorol. Soc. 148 (744), 1368–1388. 

Elith, J., Leathwick, J.R., 2009. Species distribution models: ecological explanation and 
prediction across space and time. Annu. Rev. Ecol. Evol. Syst. 40 (1), 677–697. 

Fick, S.E., Hijmans, R.J., 2017. WorldClim 2: new 1-km spatial resolution climate 

surfaces for global land areas. Int. J. Climatol. 37 (12), 4302–4315. 

Frey, S.J., Hadley, A.S., Johnson, S.L., Schulze, M., Jones, J.A., Betts, M.G., 2016. Spatial 
models reveal the microclimatic buffering capacity of old-growth forests. Sci. Adv. 2 
(4), e1501392. 

Fridley, J.D., 2009. Downscaling climate over complex terrain: high finescale (< 1000 m) 
spatial variation of near-ground temperatures in a montane forested landscape 
(Great Smoky Mountains). J. Appl. Meteorol. Climatol. 48 (5), 1033–1049.

PC 4 

59.50% 
19.19% 
87.29% 
19.33% 
71.69% 
18.39% 
73.47% 
17.68% 
74.88% 
17.63% 
74.13% 
16.86% 
74.66% 
17.53% 
74.12% 
17.52% 
72.32% 
17.90% 
69.60% 
18.85% 
58.61% 
19.21% 
56.78% 
18.94% 

PC 5 

64.51% 
6.22% 
63.33% 
6.26% 
63.02% 
6.34% 
63.02% 
6.40% 
62.50% 
6.39% 
62.08% 
6.48% 
62.53% 
6.40% 
62.45% 
6.41% 
63.21% 
6.38% 
62.97% 
6.32% 
63.98% 
6.23% 
64.68% 
6.14%   

EcologicalInformatics82(2024)10267410D. Delle Monache et al.

◦

in Appendices). Like KGE scores, MAE and RMSE increased for all the 
algorithms during the hot season, although both metrics showed limited 
variability  (0.4–1.3 
C;  Fig.  A.10c  and  Fig.  A.10d  in  Appendices). 
Percent biases were always remarkably close to zero, with little differ-
ences between algorithms (Fig. A.10b in Appendices). Altitude was the 
most relevant physiographic descriptor; however, in all algorithms but 
ANN, its relative importance decreased during the hot season. In these 
same  months,  the  relative  importance  of  the  remaining  descriptors 
generally increased (Fig. A.11 in Appendices).

)

pbias = 100 ×

tobs (cid:0)
∑

tpred

tobs  

where  tobs  and  tpred  are  observed  and  predicted  temperatures,  respec-
tively. Consequently, underestimation  corresponds with positive pbias 
values,  whereas  overestimation  with  negative  pbias  values.  MAE  and 
RMSE  are  two  commonly  used  validation  metrics,  and  we  calculated 
them as follows: 

MAE = 1
n

( ∑ ⃒
⃒
tobs (cid:0)

)

⃒
⃒

tpred

RMSE =

√

( ∑ (cid:0)

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
)
1
tobs (cid:0)
n

tpred

)
2

where n (= 33) is the number of weather stations.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information on the specific hyperparameters used in the deep learning model mentioned in the paper by Dujardin and Lehning (2022). To find this information, one would need access to the original research article or contact the authors directly.