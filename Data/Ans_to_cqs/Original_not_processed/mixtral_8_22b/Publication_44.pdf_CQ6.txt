Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

as a feature [13]. As the study showed, they require a large training sample to maintain a
good performance of their approach.

Training procedure—We adapted a pre-trained VGG16 network that is a CNN trained
on the ImageNet dataset and used for transfer learning on our dataset [51]. We froze
earlier layers of the base version of the network to make them non-trainable and added an
extra max-pooling layer before the fully connected layers to reduce the dimension of the
previous layer. The feature vector of the fully connected layer was reduced from 2048 units
of the original VGG16 to 128 units, which helped in reducing the computational complexity
without sacriﬁcing much on performance. The model was implemented using Keras with
TensorFlow backend [52].

kernel to expand without increasing the number of parameters [39]. This expansion of the
window is controlled by the dilation rate and it enables the network to capture information
from a larger receptive ﬁeld of view with the same parameters and computational complex-
ity as the normal convolution. The combination of spatial pyramid pooling with Atrous
convolutions resulted in an efﬁcient multi-scale processing module called Atrous spatial
pyramid pooling (ASPP). In the earlier version (DeepLabV3) [40], the last ResNet block of
the modiﬁed ResNet-101 uses different Atrous convolutions with different dilation rates.
ASPP, together with bilinear up sampling, is also used on top of the modiﬁed ResNet block.
DeepLabv3+ is an improvement in the previous version by adding an effective decoder
module to improve the boundaries of the segmentation results [41]. Furthermore, apart
from ResNet-101, an Xception model can be used as a feature extractor while applying a

threshold during training for 3000 iterations. At the end of the training process, the best
performing model based on the validation loss was saved and used as the Faster R-CNN
model with a NMS threshold of 0.7 during testing.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit details about any specific preprocessing steps taken before training the deep learning models mentioned. However, some common preprocessing techniques often applied when working with image datasets include:

1. Normalization: Scaling pixel values between 0 and 1 or -1 and 1 to ensure consistent input ranges across images.
2. Data augmentation: Applying transformations like rotation, flipping, zooming, etc., to increase the size of the training set and prevent overfitting.
3. Cleaning: Removing noisy data points or outliers that may negatively impact the model's performance.
4. Splitting the dataset: Dividing the dataset into training, validation, and test sets to evaluate the model's generalizability.

In this case, the authors mention adapting a pre-trained VGG16 network for transfer learning on their dataset. Transfer learning involves leveraging knowledge gained from solving one problem to solve another related problem. Here, the authors use a pre-trained network that has already learned features from the ImageNet dataset and fine-tune it on their own dataset. They freeze early layers of the network to keep these learned features intact and add extra layers to adapt the network to their task. Additionally, they modify the architecture by reducing the dimensionality of the fully connected layer to decrease computational complexity. These modifications could be considered part of the overall preparation process for training the deep learning model.