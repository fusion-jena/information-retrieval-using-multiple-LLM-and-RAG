Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Here  we  present  a  new  algorithm,  called  BirdNET,  that  builds  on 
these previous successes using CNNs and spectrogram data to classify 
984  bird  species.  We  discuss  the  necessary  steps  required  to  develop 
such a system and provide insights into our training and testing work-
flow of a deep artificial neural network. Finally, we give an outlook on 
how  this  technology  can  support  ornithologists  and  conservation  bi-
ologists in their work to identify and address the environmental chal-
lenges of our time. 

2. Methods

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

BirdNET: A deep learning solution for avian diversity monitoring 

Stefan Kahl a, *, Connor M. Wood a, Maximilian Eibl b, Holger Klinck a 
a Center for Conservation Bioacoustics, Cornell Lab of Ornithology, Cornell University, Ithaca, NY 14850, USA 
b Technische Universit¨at Chemnitz, D-09111 Chemnitz, Germany   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Bioacoustics 
Deep learning 
Convolutional neural networks 
Bird sound recognition 
Avian diversity 
Passive acoustic monitoring 
Conservation

followed  the  original  Wide  ResNet  design.  Our  downsampling  blocks 
employed the changes suggested in (Xie et al., 2018). The third and final 
component, the classification block, was derived from (Schlüter, 2018) 
and resulted in probability predictions for all 987 classes per second (i. 
e., three predictions per 3-s input spectrogram) followed by global log- 
mean-exponential  pooling  and  sigmoid  activation.  Most  convolutions 
use 3 × 3 kernels with padding and are succeeded by batch normali-
zation  (Ioffe  and  Szegedy,  2015)  and  ReLU  activation  (if  not  noted 
differently).  Because  we  treated  spectrograms  as  monochrome  input 
images, the input was a single channel mel spectrogram of size 64 × 384, 
visualizing three seconds of audio at a sampling rate of 48 kHz. 

2.5. Training

overall process mostly followed current best practices in deep learning 
which are well summarized in (Chollet, 2017).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not contain information about the specific code repository link of the deep learning pipeline used for BirdNET. Therefore, it is not possible to provide the requested information based solely on the provided text. It would be necessary to refer to additional sources or resources to find the relevant code repository link.