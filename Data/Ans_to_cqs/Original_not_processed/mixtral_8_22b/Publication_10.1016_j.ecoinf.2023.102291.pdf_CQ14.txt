Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To test the efficacy of our models, we created several segments by 
using  the  same  sliding  window  approach.  Namely,  we used  the  same 
window size that was used in training, and thus multiple segments were 
created  across  the  entire  testing  file  by  moving  the  window  by  one 
second  in  the  moored  recording.  We  converted  each  of  these  testing 
segments into spectrograms (FFT length = 1024; hop size = 128; Hann 
window) which were used as input for subsequent model prediction. All 
generated spectrogram images were created as 5 × 5 in. but varied in 
their dpi configuration, ranging from 200 × 200 (40 dpi) to 500 × 500 
(100 dpi) samples. The number of images used per class was constrained 
by our computational resources, and we used the maximum number of 
images possible in each case. We attempted a number of experiments 
and varied the number of classes. The largest dataset built comprised 
80,000 images when combining three seconds window size and 40 dpi

2. Material and methods 

2.1. Data collection

4. Discussion

70 

80 
90 

100 
40 

50 

40 

90 

40 
40 

63.9 (n = 183)** 
43.3 (n = 127)*** 
78.7 (n = 127) 
53.8 (n = 130) 
72.9 (n = 48) 
87.3 (n = 166) 
96.9 (n = 166) 
100.0 (n = 33) 
60.7 (n = 51) 
50.4 (n = 121) 
4.1 (n = 121) 
15.7 (n = 121) 
0.0 (n = 96) 
22.2 (n = 27) 
0.0 (n = 44) 
36.3 (n = 44) 
1.2 (n = 166) 
10.2 (n = 166) 
9.0 (n = 166) 
0.0 (n = 284) 
0.0 (n = 292) 

67.8 (n = 171)** 
97.0 (n = 171)*** 
97.0 (n = 171) 
95.8 (n = 192) 
88.6 (n = 106) 
80.0 (n = 10) 
100.0 (n = 10) 
50.0 (n = 4) 
94.0 (n = 101) 
99.2 (n = 136) 
2.2 (n = 136) 
2.2 (n = 136) 
100.0 (n = 9) 
100.0 (n = 9) 
100.0 (n = 4) 
75.0 (n = 4) 
100.0 (n = 10) 
80.0 (n = 10) 
100.0 (n = 10) 
36.5 (n = 41) 
96.5 (n = 29) 

– 
– 
43.9 (n = 599) 
60.8 (n = 2396)* 
75.7 (n = 598) 
– 
77.9 (n = 599) 
71.7 (n = 598) 
83.5 (n = 492) 
– 
9.0 (n = 598) 
0.5 (n = 598) 
– 
23.1 (n = 596) 
76.4 (n = 594) 
– 
– 
76.1 (n = 599) 
79.1 (n = 599) 
9.5 (n = 598) 
83.3 (n = 588)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information on how the hyperparameters of the model were optimized. Therefore, it is not possible to determine if techniques such as grid search or random search were employed. However, the text mentions that various experiments were conducted with different numbers of classes and datasets, suggesting some form of parameter tuning may have occurred. Nonetheless, without specific details regarding the optimization process, it remains unclear exactly how the hyperparameters were adjusted.