Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.1. Data filtering

using 

The  first  step  (data  filtering)  involves  data  acquisition  and  masks 
application  (Fig.  1).  From  the  EECE,  users  can  retrieve  the  EOS  data 
catalogue  from  the  GEE  online  repository  (https://developers.google. 
com/earth-engine/datasets/), 
ee.ImageCollection() 
constructor. Constructor arguments must also be included, such as fil-
terDate, which limits the collection to a selected period, and the inner 
clip function that cuts it within a specific study area extent. The identi-
fied  public  image  series  (time  series)  may  be  preprocessed,  but  also 
undergo the previously mentioned QA bands-based masking processes 
for each satellite, through optionally implementable masking functions 
(in yellow as depicted below). 

the

environmental  data  to  ecological  processes  (Chave,  2013;  Pettorelli 
et al., 2014).

2.3. Data scaling 

The final step refers to data scaling, and intrinsically to gap filling 
and data matching levels required by the user. Different scaling domains 
have been suggested by Fritsch et al. (2020). As the interest relies on 
aggregating  data  across  scales  prior  to  modelling,  our  approach  con-
forms  to  a  “pre-modelling  scaling”  protocol  (Fritsch  et  al.,  2020). 
Sequential  processes  were  implemented  within  GEE  for  scaling  up 
environmental  time  series  from  one  spatial  and/or  temporal  scale  to 
another during data extraction.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, there is no explicit information about the criteria used to split the data for deep learning model training into train, test, or validation sets. However, generally speaking, common practices include splitting the dataset randomly or based on chronology. For instance, if dealing with time series data, one might use earlier data for training and later data for testing and validation. Another method could involve using a certain percentage of the total data for training, another portion for validation, and the remaining part for testing. It is essential to ensure that the distribution of classes or labels remains consistent across all subsets to prevent any bias towards a particular class during the training process.