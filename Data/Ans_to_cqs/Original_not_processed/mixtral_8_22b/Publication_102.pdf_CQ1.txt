Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Page 4 of 10

a  high  dimensional  feature  vector1.  Then,  the  Decoder 
semantically projects the features learned by the encoder 
onto the pixel space, generating a corresponding density 
distribution for the given image. This density map is used 
to  get  the  number  of  objects  by  simply  integrating  the 
density distribution over the region (see “Counting from 
density map” section) (Fig. 1).

Data preparation

Both data sets were split into training and testing images 
with  a  ratio  of  80  :  20,  respectively.  For  the  SSLs’  data 
set,  the  first  800  images  were  used  for  training,  and  the 
remaining  148  were  used  as  test  images  to  evaluate  the 
model’s  performance.  For  the  elephants’  data  set,  1649 
images  were  used  for  training,  while  452  images  were 
used for testing.

Lafferty JD, Williams CKI, Shawe-Taylor J, Zemel RS, Culotta A, editors. 
Advances in neural information processing systems 23. Curran Associates 
Inc; 2010. p. 1324–32. http:// papers. nips. cc/ paper/ 4043- learn ing- to- 
count- objec ts- in- images. pdf

 23.  Naudé JJ, Joubert D. The aerial elephant dataset Zenodo. 2019. https:// 

doi. org/ 10. 5281/ zenodo. 32347 80.

 24.  Ronneberger O, Fischer P, Brox T. U-net: convolutional networks for 
biomedical image segmentation; 2015. CoRR arXiv: 1505. 04597.

 25.  Naude J, Joubert D. The aerial elephant dataset: A new public benchmark 
for aerial object detection. In: Proceedings of the IEEE/CVF conference on 
computer vision and pattern recognition (CVPR) Workshops; 2019.
 26.  Oñoro D, López-Sastre R. Towards perspective-free object counting with 
deep learning, vol. 9911. Berlin: Springer; 2016. https:// doi. org/ 10. 1007/ 
978-3- 319- 46478-7_ 38.

 27.  Tan M, Le QV. Efficientnet: Rethinking model scaling for convolutional

In  the  proposed  work,  the  down-sampling  (contract-
ing)  path  repeatedly  applies  a  block  comprised  of  two 
3 × 3  convolutions,  followed  by  batch-normalization, 
a  Rectified  Linear  Unit  (ReLU)  activation  and  a  2 × 2 
max-pooling  layer  of  stride  2.  The  number  of  feature 
map  channels  in  the  contracting  path  is  doubled  at 
each  down-sampling  block.  Similarly,  the  up-sampling 
(expansive)  path  replaces  the  max-pooling  layers  with 
up-sampling layers that apply nearest-neighbor interpo-
lation.  Analogous  to  the  contracting  path,  the  number 
of  feature  map  channels  is  halved  at  each  up-sampling 
block.  The  feature  maps  of  the  up-sampling  path  are 
concatenated  with  the  feature  maps  of  the  contracting 
path. Finally, the output layer results by applying a 1 × 1 
convolution.

Loss function

2018. CoRR arXiv: 1807. 11809

 16.  Kamilaris A., van den Brink C., Karatsiolis S. (2019) Training Deep Learning 
Models via Synthetic Data: Application in Unmanned Aerial Vehicles. 
In: Vento M. et al. (eds) Computer Analysis of Images and Patterns. CAIP 
2019. Communications in Computer and Information Science, vol 1089. 
Springer, Cham. https:// doi. org/ 10. 1007/ 978-3- 030- 29930-9_8

 17.  Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, 
Courville A, Bengio Y. Generative adversarial nets. In: Proceedings of the 
27th international conference on neural information processing systems. 
NIPS’14. MIT Press, Cambridge, MA, USA; 2014, vol. 2, p. 2672–2680.
 18.  Young-Chul Yoon K-JY. Animal detection in huge air-view images using 

cnn-based sliding window. In: International workshop on frontiers of 
computer vision (IWFCV); 2018.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit details about the specific methods used for collecting raw data in the deep learning pipeline. However, it mentions the use of two datasets: one for SSLs and another for elephants. It can be inferred that these datasets could have been collected through various means such as surveys, sensors, or even public datasets.

For instance, the SSLs' dataset might have been gathered using sensors or surveys, considering they are often used to collect data related to spatial statistics. On the other hand, the elephants' dataset could potentially come from aerial imagery, which is suggested by its name, 'Aerial Elephant Dataset.' This dataset might have been sourced from publicly available aerial imagery databases or captured using drones or satellite imagery.

Nonetheless, without more specific information regarding the collection process of these datasets, it remains speculative to definitively state the exact methodologies employed for gathering raw data in this particular deep learning pipeline.