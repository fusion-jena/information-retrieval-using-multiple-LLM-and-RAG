Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

methods. Environmental Pollution 297, 118759.   

Wai, K.P., Chia, M.Y., Koo, C.H., Huang, Y.F., Chong, W.C., 2022. Applications of deep 

learning in water quality  management: A state-of-the-art review. Journal of Hydrology  613, 

Journal Pre-proof

Wang, C., Xie, W., Li, T., Wu, G., Wu, Y., Wang, Q., Xu, Z., Song, H., Yang, Y., 2023. 

Analysis of Spatial and Temporal Variation in Water Coverage in the Sub-Lakes of Poyang 

Lake Based on Multi-Source Remote Sensing. Remote Sensing 15, 2788.   

Wang, H., Meng, Y., Wang, H., Wu, Z., Guan, X., 2023. The application of integrating 

comprehensive  evaluation  and  clustering  algorithms  weighted  by  maximal  information 

coefficient  for  urban  flood  susceptibility.  Journal  of  Environmental  Management  344, 

118846.   

Wang,  M.C.,  Liu,  X.Q.,  2002.  Evaluate  method  and  classification  standard  on  lake 

eutrophication. Environmental Monitoring in China 18,47-49.

with  the  testing  dataset  (Fig.  5  and Table S2). The RF  model  with  25  trees  as  hyper-parameters 

Journal Pre-proof

achieved the highest accuracy. In autumn, the optimized RF model included three input variables: 

EC, TN, and WZ. It displayed excellent performance with adj_R2 = 0.992, RMSE = 1.505, MAE = 

0.859, and KGE = 0.972 for the training data, and adj_R2 = 0.863, RMSE = 7.182, MAE = 3.598, 

and KGE = 0.824 for the testing data (Fig. 5 and Table S2). The winter RF model was optimized 

with two variables: WZ and WT. It demonstrated good performance with adj_R2 = 0.977, RMSE = 

0.620,  MAE  =  0.432,  and  KGE  =  0.938  for  training  data,  and  adj_R2 =  0.840,  RMSE  =  1.567, 

3.4. Relative Importance of Model Features 

season, the RF model with 25 trees as hyper-parameters achieved the highest accuracy. 

The selected predictor variables exerted different control (described as “Feature Importance”)

a  and  a  multitude  of  potentially  influential  factors  is  often  nonlinear  or  even  non-monotonic. 

Commonly used correlation analysis methods, such as the Pearson correlation, cannot accurately 

capture  these  complex  relationships.  To  address  this  deficiency,  MIC  analysis  is  often 

recommended  to  detect  both  linear  and  nonlinear  associations  between  two  variables  in  large 

datasets  (Reshef  et  al.,  2011).  MIC  has  been  extensively  used  to  select  candidate  predictors  for 

machine learning models (Su et al., 2022; Lu et al., 2023; Ouyang et al., 2023; Wang et al., 2023; 

Journal Pre-proof

Yao et al., 2023). MIC ranges from 0 to 1. The stronger the correlation between two variables, the 

larger the MIC value is. MIC scores greater than 0.3 between any given environmental factor and 

Chl  a  represent  input  variables  that  can  -in  principle-  shape  the  Chl  a  levels  in  Poyang  Lake

the Nanji wetland of Poyang Lake.   

Fig.  3:  Maximal  Information  Coefficient  values  between  the  nine  environmental  covariates  and 

chlorophyll  a  concentrations  for  (a)  the entire  study  period,  using  eleven  time  lags  (0-10  days), 

and (b) each of the four seasons.     

Fig.  4:  Random  forest  performance,  as  measured  by  adj_R2,  RMSE,  MAE,  and  KGE,  with  the 

training and testing/validation datasets for different time lags. The gray columns and orange line 

represent  the  adj_R2  and  KGE  values,  while  the  blue  solid  and  dashed  lines  correspond  to  the 

RMSE and MAE values, respectively.   

Fig. 5: Predictions of Chl a concentrations by the optimal RF model per season. 

Fig. 6: Relative importance of the predictor variables included in the optimal random forest model 

Journal Pre-proof

Fig. 7: GAM analysis: Non-linear relationships between the two key influential factors and Chl a

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it appears that the authors use several metrics to evaluate the performance of their machine learning models, specifically the Random Forest (RF) model. These metrics include adjusted R-squared (adj\_R2), Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Kling-Gupta Efficiency (KGE). However, it should be noted that these metrics are not specific to deep learning models but are commonly used for evaluating various types of regression models, including machine learning models like Random Forest.

* Adjusted R-squared (adj\_R2): This metric measures how well the predicted values fit the observed values. Unlike the regular R-squared, which increases when new predictors are added, the adjusted R-squared takes into account the number of predictors in the model and only increases if the new term improves the model more than would be expected by chance.
* Root Mean Square Error (RMSE): This metric quantifies the difference between the predicted and actual values. Lower values indicate better model performance.
* Mean Absolute Error (MAE): Similar to RMSE, MAE also measures the average magnitude of errors in a set of predictions. However, unlike RMSE, MAE does not penalize larger errors as heavily.
* Kling-Gupta Efficiency (KGE): This metric combines three components – correlation, bias, and variability – to provide a comprehensive measure of model performance. A KGE score closer to 1 indicates better model performance.