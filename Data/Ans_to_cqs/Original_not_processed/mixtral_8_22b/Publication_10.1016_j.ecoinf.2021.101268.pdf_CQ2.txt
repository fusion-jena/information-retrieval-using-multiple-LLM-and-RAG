Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(13)  

4.2. Architecture configurations 

Convolutional neural networks (CNN) outstand over DL techniques 
by disentangling high-level representations across multiple processing 
layers. CNN’s process data on two levels: a convolutional block for the 
automatic  feature  extraction,  and  fully  connected  layers  to  establish 
feature-output  correlation.  The  convolutional  block  comprises  con-
volutional,  ReLU,  and  max-pooling  layers.  Each  set  of  convolutional 
layers diversify features by applying a set of parallel filters that process 
local sections of the input space. The feature vector integrates low-level 
local features from the first layers and higher-level representations from 
the latest ones.

Ideally, a robust model must classify accurately, regardless of back-
ground or input noises. We analyze the model’s behavior by swapping 
testing  sets  between  pre-processed  and  raw  images  (Table  5).  The 
experimental results on model robustness show that the models suffer an 
accuracy drop. This drop varies depending on the training data: >13% 
for raw images, and > 17% for pre-trained ones. Furthermore, ResNet- 
101  and  DenseNet-201  decrease  up  to  52%.  These  figures  draw  that 
AlexNet and VGG-19 are ideal for our context.

JPEG 
JPEG 
JPEG 
JPEG 
JPEG 
JPEG  

somewhat ambiguous methodology, but still useful, to define the best 
subset of features that represents a domain. Thenceforth, DL has risen to 
the very top of machine learning technologies, with promising results 
and  tremendous  potential  in  several  applications,  even  agricultural 
(Kamilaris and Prenafeta-Boldú, 2018; Rawat and Wang, 2017; Zhang 
et  al.,  2020).  This  review  focus  on  feature  representation  from  hand- 
crafted and deep-learning perspectives. 

3.1. Feature engineering 

Feature engineering still has majority acceptance in the plant species

Deep Learning (DL) methods are at the top of the state-of-the-art on 
feature representation for different domains; albeit, DL lacks interpret-
ability. According to Doshi-Velez and Kim (2017), interpretability lets 
human specialists understand what a model is learning, making them 
flexible  real-world  solutions.  Given  such  topics,  this  paper  has  three 
significant contributions:  

1.  The  paper  introduces  the  first  Peruvian  Amazon  Forestry  Dataset, 
including  its  detailed  metadata  and  the  acquisition  protocol 
description. The dataset collects 59,441 samples from ten of the most 
profitable  and  endangered species (Finer  et al., 2014; Pinedo-Vas-
quez et al., 1992). Further-more, we employ six different commercial 
cameras  to  ensure  variability  and  to  develop  any  flexible  solution 
with real-world conditions in the future.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific data format used in the deep learning pipeline. However, it can be inferred that the data format used is likely images since the study focuses on analyzing the performance of various Convolutional Neural Network (CNN) architectures, which are primarily designed for image classification tasks. Additionally, the authors discuss using raw and pre-processed images in their experiments. Therefore, it can be concluded that the data format used in the deep learning pipeline is likely images.