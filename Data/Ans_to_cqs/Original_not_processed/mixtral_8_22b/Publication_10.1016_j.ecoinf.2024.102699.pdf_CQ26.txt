Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The evaluated augmentation techniques consistently exhibited the
same qualitative effects across all three of our deep learning models.
Specifically, if the performance of an augmentation set improved for one
model, it also improved for the other two, and vice versa. However,
further research is needed to determine if this observation can be
generalized. For optimizing augmentation strategies, a more effective
approach would be to use only the least computationally intensive
models, e.g., DenseNet-161 or ResNet-50. The best combined augmen-
tations would then be applied to the best-performing model (ViT-B/16).
In our future work, we plan on focusing on the creation of so-called
no-call classifiers with training samples that do not contain bird events
in general. For this purpose, as well as to explore different transformer-
based models with improved prediction scores, encompassing, i.a., data-
efficient image transformers (DeiT) as well as hybrid transformers (Han

Table 2
Overview of our augmentation strategies, their IDs, and related information. For DenseNet-161 and ViT-B/16, their training times are provided in minutes per epoch
for the different augmentation methods. For IDs 5 and 6, we added noise of the bird audio detection data set from the DCASE challenge (Berger et al., 2018; Himawan
et al., 2018; Liaqat et al., 2018), which is abbreviated as BAD.

Data augmentation

Time domain

Frequency domain

Spectrogram

Training time [min. / epoch]

DenseNet-161

ViT-B/16

Gaussian noise
Pink noise (background)
Primary background noise soundscapes
Secondary background noise soundscapes
Primary background noise (BAD)
Secondary background noise (BAD)
Background noise (e.g., wind, thunder, or aircrafts)
Mixed up random bird species
Horizontal roll
Vertical roll
Pitch shift
Time mask
Frequency mask
Gain
Loudness normalization
Horizontal flip
Vertical flip
Time stretch
tanh-based distortion

✓
✓
✓
✓
✓
✓
✓

✓

✓
✓

✓

domized partial time and frequency stretching, which are frequently
used in speech recognition, and randomly added weighted noise samples
extracted from audio chunks that did not contain bird events.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L.,
Polosukhin, I., 2017. Attention is all you need. In: Guyon, I., Luxburg, U.V.,
Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., Garnett, R. (Eds.), Advances in
Neural Information Processing Systems 30 (NIPS 2017). Curran Associates, Inc, Long
Beach, California, USA, pp. 1–11. URL: https://proceedings.neurips.cc/paper_files/
paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.

Wu, H., Li, M., 2018. Construction and improvements of bird Songs’ classification

system. In: Cappellato, L., Ferro, N., Nie, J.Y., Soulier, L. (Eds.), Working Notes of
CLEF 2018 - Conference and Labs of the Evaluation Forum, CEUR-WS.org, Avignon,
France. pp. 1–8. URL: https://ceurws.org/Vol-2125/paper_77.pdf.

EcologicalInformatics82(2024)10269914

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some relevant points regarding data augmentation strategies have been discussed.

The authors employed various data augmentation techniques in both the time domain and frequency domain, including Gaussian noise, pink noise, primary and secondary background noise soundscapes, mixed-up random bird species, horizontal and vertical rolls, pitch shifts, time masks, frequency masks, gain, loudness normalization, horizontal and vertical flips, time stretches, tanh-based distortions, and others. These augmentation sets were tested across multiple deep learning models like DenseNet-161, ResNet-50, and ViT-B/16.

Moreover, the study mentions adding noise from the Bird Audio Detection dataset (BAD) from the DCASE challenge for IDs 5 and 6. This could potentially help reduce data bias by introducing additional variability into the dataset.

While these details provide insights into the data augmentation strategies used, they do not directly discuss techniques specifically aimed at addressing data bias during preprocessing. Therefore, based solely on the provided context, it cannot be determined what techniques are used to address data bias during preprocessing of the deep learning pipeline.