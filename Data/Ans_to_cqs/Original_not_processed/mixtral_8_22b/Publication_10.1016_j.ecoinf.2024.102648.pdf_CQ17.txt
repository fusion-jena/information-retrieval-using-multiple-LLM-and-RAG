Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

â—¦

Fig.  1. Illustration  of  major  deep  learning  (DL)  methods  for  prediction  of 
CLCuD in upland cotton. 

EcologicalInformatics81(2024)1026484S.K. Sain et al.                                                                                                                                                                                                                                  

Fig. 2. SMW-wise percent CLCuD percent incidence in the four locations of the north-western Zone. A. Faridkot, b. Sriganganagar, c. Sirsa, d. Hisar.  

3.5. Multi-layer perceptron (MLP): artificial neural network 

training  = 0.80 and R2

2.7. Early stopping 

It is the process that stops growing additional trees/layers/split when 
further addition of more trees/layers/split does  not improve  the vali-
dation statistic in the case of bootstrap forest and boosted tree methods. 
The  validation  statistic  included  the  (R2)  value  for  a  continuous 
response. In the case of the entire machine learning model early stop-
ping  was  enabled  so  that  the  model  would  not  overfit  the  predicted 
percent CLCuD. To address the inclination of neural networks to overfit 
data, the penalty method was employed within the framework of ANN 
models. 

3. Results 

3.1. Multiyear SMW-wise percent CLCuD incidence in the four locations

2.2. Machine learning and deep learning tools 

In the present study machine learning (bootstrap forest, boosted tree) 
and deep learning (artificial neural network) models were employed to 
forecast  the  percent  disease  incidence  of  CLCuD  under  the  prevailing 
weather data on minimum, maximum and average temperature, stan-
dard meteorological week (SMW)-wise growing degree days (henceforth 
mentioned  as  GDD),  minimum  relative  humidity  (RHmini.),  maximum 
relative humidity (RHmax.), average relative humidity (RHave.), cumu-
lative rainfall (mm) and whitefly per three leaves. The weather param-
eters recorded from 2011 to 2019 at weather stations based at all four 
locations  were  used  for  calculating  the  GDD  as  per  the  following 
equations.

Nowadays, machine learning and the artificial neural network (ANN) 
computational technique are emerging tools which has put forth a va-
riety  of  remarkable  advancements  in  algorithms  and  processing  tech-
niques. These techniques have been capable of developing models for 
accurate  prediction  utilizing  correlation  patterns  between  input  and 
output datasets, and have been utilized to solve problems in biological 
sciences  (Haykin,  1994;  Kolay  and  Baser,  2014;  Lashkarblooki  et  al., 
2012; Tufail et al., 2008; Yilmaz and Kaynar, 2011). Some researchers 
have  used  image  analysis  with  machine  learning  (ML),  deep  learning 
(DL) and model combination (MC) techniques to identify, monitor and 
estimate plant disease severity under field conditions (Alves et al., 2022; 
Mzoughi  and  Yahiaoui,  2023;  Singh  et  al.,  2022,  2023).  Moreover, 
Revathi and Hemalatha (2014) and Caldeira et al. (2021) have used ML

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In the given context, there is no explicit mention of specific regularization methods such as dropout or L2 regularization being used to prevent overfitting in the deep learning pipeline. However, it can be inferred that some form of regularization was applied to prevent overfitting in the multi-layer perceptron (MLP) model, which is a type of artificial neural network (ANN).

The text mentions that early stopping was enabled to prevent overfitting in the MLP model. Early stopping is a form of regularization where training is stopped before the model starts to overfit the training data. This helps to avoid memorizing noise in the training set and improves generalization performance on unseen data.

Additionally, the text states that the penalty method was employed within the framework of ANN models to address the tendency of neural networks to overfit data. While the exact nature of this penalty method is not specified, it could refer to various forms of regularization such as weight decay (L2 regularization) or sparsity constraints (L1 regularization).

Therefore, while the specific regularization methods used may not be explicitly mentioned, it can be deduced that some form of regularization was implemented to prevent overfitting in the deep learning pipeline.