Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

1063

117

AP

37.9

18.3

7.9

0.0

25.1

11.8

The model was trained again on all the annotated scans earlier and tested on a different
un-annotated dataset. The model performed well, based on visual inspection. In order to
evaluate the performance of the model with an average precision metric, around 200 of
these   scans   were   annotated   by   hand,   based   on   the   predicted   bounding   boxes.   The
predicted bounding boxes dramatically reduced the time to annotate these scans, since the
predictions for leaves and stems were fairly accurate. After being annotated, these scans
were compared with the predictions to evaluate the precision of the organ detection model
on this dataset.

Results

annotation was 8 to 15 herbarium sheets per hour, depending on the difficulty and number

Figure 5. 

An illustration of Feature Pyramid Network, where feature maps are indicated by blue outlines
and thicker outlines denote semantically stronger features (Lin et al. 2017).

 
 
 
8

Younis S et al

In order to reduce the training time and, more importantly, because of the small size of the
training dataset, transfer learning (Yosinski et al. 2014) was implemented to initialise the
model weights pre-trained on the ImageNet dataset (Deng et al. 2009). Since the initial
layers of a CNN usually learn very generic features that can also be used in new contexts,
pre-trained   weights   can   initialise   the   weights   for   these   layers.   For   the   deeper   layers,
transfer learning is used to initialise the parameter weights pre-trained on the ImageNet
dataset and then fine-tuned during training, using the annotated herbarium scan dataset
until convergence.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be taken to further analyze and improve the results. Based on the given context, one such step involves evaluating the performance of the model using metrics like average precision. To calculate this metric, some of the unannotated scans were manually annotated based on the predicted bounding boxes generated by the model. This process helped in reducing the time required for manual annotation significantly.

Additionally, another important postprocessing step mentioned in the context is the use of transfer learning to initialize the model weights pre-trained on the ImageNet dataset. Transfer learning helps in reducing the training time and improves the overall performance of the model, especially when dealing with smaller datasets. By leveraging the knowledge gained from pre-training on large datasets, the model can quickly adapt to new tasks or domains.

However, it should be noted that the context does not explicitly mention any other specific postprocessing techniques such as saliency maps or confusion matrices. These methods could still potentially be useful for analyzing the model's performance and identifying areas for improvement. Saliency maps, for instance, can help visualize which parts of the input images contribute most towards the final prediction made by the model. On the other hand, confusion matrices provide a summary of the classification accuracy, including false positives and negatives, allowing for better understanding of the model's strengths and weaknesses.