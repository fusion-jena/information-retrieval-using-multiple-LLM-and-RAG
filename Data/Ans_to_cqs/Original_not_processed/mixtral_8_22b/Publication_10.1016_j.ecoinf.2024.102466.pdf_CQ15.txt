Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  results  indicate  that  the  Cascade  RCNN  outperformed  other 
models at each training stage, while the FCOS model and Sparse CNN 
model consistently had lower mAP scores than others. This is consistent 
with  the  findings  of  Section  3.1.  Although  12  epochs  were  a  typical 
number of training times, almost all models reached the maximum mAP 
when the number of epochs reached 10. Therefore, for bird recognition, 
not  all  models  are  better  with  more  training  times,  and  choosing 

appropriate  training  times  for  different  models  is  beneficial  to  save 
computing resources. Specifically, the Cascade RCNN model had almost 
no  increase  in  the  mAP  at  9  epochs,  and  the  Faster  CNN  model  also 
showed a similar trend. However, the ATSS and RepPoint growth curves 
continued to 12 epochs, suggesting they require more training data or a 
longer training schedule to perform better.

The  Faster  RCNN  model  initially  achieved  a  relatively  high  mAP 
score of 0.568 in epoch 7; however, its performance plateaued in sub-
sequent  epochs,  suggesting  that  further  improvements  may  require 
modifications  to  its  architecture  or  hyperparameters.  In  contrast,  the 
Sparse RCNN model showed a slow start, with its mAP score increasing 
from 0 in epoch 1 to 0.324 in epoch 4, but achieved a steady increase in 
performance after that. 

Overall, these results suggest that Cascade RCNN and ATSS are the 
most effective models for object detection on camera trap images, while 
Faster  RCNN,  RetinaNet  and  RepPoints  are  also  viable  options.  How-
ever, FCOS and Sparse RCNN may not be suitable for this task, given 
their slower and less stable convergence and lower mAP scores. 

3.4. Baseline detectors with different backbones

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Object detection 
Bird detection 
Deep learning 
Camera trap

org/10.1016/j.ecoinf.2024.102466. 

References 

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2017. ImageNet classification with deep 

convolutional neural networks. Commun. ACM 60, 84–90. 

Leorna, S., Brinkman, T., 2022. Human vs. machine: detecting wildlife in camera trap 

images. Eco. Inform. 72, 101876. 

Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll´ar, P., 

Beery, S., Van Horn, G., Perona, P., 2018. Recognition in terra incognita. In: Proceedings 

of the European Conference on Computer Vision (ECCV), pp. 456–473. 

Bibby, C.J., 2000. Bird Census Techniques. Elsevier. 
Bicudo, T., Llusia, D., Anci˜aes, M., Gil, D., 2023. Poor performance of acoustic indices as 
proxies for bird diversity in a fragmented Amazonian landscape. Eco. Inform. 77, 
102241. 

Borowiec, M.L., Dikow, R.B., Frandsen, P.B., McKeeken, A., Valentini, G., White, A.E., 
2022. Deep learning as a tool for ecology and evolution. Methods Ecol. Evol. 13, 
1640–1660.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about the specific optimization techniques used in the deep learning pipeline. However, it mentions various models such as Cascade RCNN, FCOS, Sparse CNN, Faster CNN, ATSS, and RepPoint. These models could have been trained using popular optimization techniques like Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). Unfortunately, without additional details, we cannot confirm which specific optimization technique was employed during the training process.