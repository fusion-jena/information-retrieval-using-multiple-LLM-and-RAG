Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ence data available for training were limited, so we sought to explore 
different network sizes in conjunction with pre-training with additional 
acoustic reference data from outside of our audio domain, followed by 
fine-tuning with ROI data from our study site.

Many 2D CNNs use well-labeled training and validation data from 
the study domain intended to optimize weights in existing image-based 
architectures (e.g., ResNet, VGGish, MobileNet), i.e., transfer learning. 
These data are usually hard to acquire and thus have low sample sizes. 
This often leads to the use of larger labeled data from outside the study 
domain.  Recent  BirdCLEF  competitions  use  weakly-labeled  audio 

EcologicalInformatics75(2023)1020652M.L. Clark et al.

2.5. CNN fine-tuning data from ROIs 

We randomly sampled 50 ROIs per species with “presence” to form a 
held-out test set for accuracy assessment (Section 2.8.1). The remaining 
ROIs with species presence were used to fine-tune the CNN models. We 
randomly sampled 100 of these ROIs per species to form a validation set 
and the remaining formed a training set, which had on average 887 per 
species (min = 349, max = 3094). ROIs that were >2 s in duration were 
used in their entirety. For those that were <2 s in duration, we expanded 
the start/stop (i.e., padded) equally on each side of the ROI to total 2 s. 
Different vocalizations for a given species were combined into a single 
class per species. If any ROIs were overlapping in time from different 
pattern-matching runs for a given species, we placed those ROIs in the 
training set to avoid temporal autocorrelation in our validation and test 
data.

architectures of deep convolutional neural networks. Artif. Intell. Rev. 53 (8), 
5455–5516. 

Knight, E.C., S`olymos, P., Scott, C., Bayne, E.M., 2020 Oct. Validation prediction: a 

flexible protocol to increase efficiency of automated acoustic processing for wildlife 
research. Ecol. Appl. 30 (7), e02140 https://doi.org/10.1002/eap.2140. 

Knight, E.C., Poo Hernandez, S., Bayne, E.M., Bulitko, V., Tucker, B.V., 2020 May 3. Pre- 

processing spectrogram parameters improve the accuracy of bioacoustic 
classification using convolutional neural networks. Bioacoustics. 29 (3), 337–355. 
Lasseck, M., 2019. Bird Species Identification in Soundscapes. CLEF (Working Notes, 

p. 2380.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about the deployment process of the trained deep learning model. It discusses the methodology used for training the model, including the use of Convolutional Neural Networks (CNNs), pre-training with additional acoustic reference data, and fine-tuning with ROI data from the study site. However, it does not mention details regarding the deployment process such as model serialization or platform selection.