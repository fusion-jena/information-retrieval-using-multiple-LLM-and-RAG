Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3.1. EfficientNet 

The first model selected is EfficientNet-B7, which is a Convolutional 
Neural Network (CNN) with efficient scaling factors (Tan and Le, 2019). 
To elaborate, all CNNs are a cascade of convolutional layers that can 
scale  the  input  image’s  resolution  (width  and  height)  and  channel 
(number  of  color  channels).  CNN  architectures  can  also  scale  by  the 
number of consecutive convolutional layers (depth).

Labeling Time 
Training Time 
Turnaround 

Time 
Accuracy 

Very Short 
1.0 h 

4 h 

89.4% 

Short 
6.9 h 

22 h 

94.0% 

Very Long 
~3.5 h 

94 h 

98%  

4. Discussions 

The  development  of  deep  learning  methodologies  continues  to 
advance at an astonishing rate and be applied to various applications 
ranging from biomedical (Azghadi et al., 2020), hydrological processes 
in river channels (Talukdar et al., 2023) and agricultural (Olsen et al., 
2019) systems, to marine (Laradji et al., 2021; Saleh et al., 2022b), and 
environmental (Jahanbakht et al., 2022a) sciences. The application of 
deep learning technologies has been also used in profiling the ecosystem 
services of estuarine habitats by community members (Yee et al., 2023). 
In this paper, we extend the application of deep learning methodologies 
to advance state-of-the-art underwater fish video processing techniques 
applied to turbid waters.

As illustrated in Fig. 5a, the main advantage of EfficientNet is that it 
can uniformly scale all depth, channel, and resolution dimensions by a 
simple yet effective compound rate (Tan and Le, 2019). This rate has 
been  applied  in  nine  stages  with  different  repeat  amounts.  In  other 
words, each stage in Fig. 5a is a Conv layer that repeats exactly for the 
given  number  of  times.  Changing  this  compound  rate  gives  the  DNN 
designer  power to  arbitrarily  adjust  the  CNN’s  scaling, which  in  turn 
results in the currently existing B0 to B7 variants. Among these variants, 
the EfficientNet-B7 is proven to produce more accurate results (Tan and 
Le, 2019). 

2.3.2. Vision transformer (ViT)

We collected the FishInTurbidWater dataset and quickly and weakly 
labeled  it  to  contribute  to  the  first  weakly-supervised  fish  dataset  in 
turbid  waters.  We,  then  used  this  dataset  to  develop  two  novel  deep 
learning networks, one using semi-supervised contrastive learning for 
significantly  accelerated  model  deployment  time,  and  one  weakly- 
supervised  model  to  shorten  deployment  time,  while  providing  high 
accuracy. 

For  semi-supervised  contrastive  learning,  we  first  trained  a  self- 
supervised  contrastive  learning  model  and  then  fine-tuned  it  on  our

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the given context does not provide information about specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) being applied in the deep learning pipeline. However, it mentions that EfficientNet uses a simple yet effective compound rate applied in nine stages with different repeat amounts, allowing the designer to arbitrarily adjust the CNN's scaling. Additionally, it discusses the use of semi-supervised contrastive learning and a weakly supervised model developed for the FishInTurbidWater dataset. These methods could potentially involve optimization techniques like SGD or Adam during training, but without explicit mention in the context, I cannot confirm their usage.