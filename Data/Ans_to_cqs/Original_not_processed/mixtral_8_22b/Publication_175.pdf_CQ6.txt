Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

1)  We  trained  a  classic  DL  algorithms  architecture  with  our  biggest 

dataset AT0 as a baseline for the DL accuracy;  

2)  We  trained  the  same  DL  architecture  with  the  same  hyper- 
parameters (e.g. model architecture and training process) but on a 
much  more  limited  dataset  (AT1).  Hyper-parameters  are  the  pa-
rameters  defining  the  architecture (number of  layers, number and 
size of convolutions, connections between layers) and the training 
process  of  a  Deep  Model  (learning  rate,  neurone  activation,  back- 
propagation compotation).;  

3)  We trained the same DL architecture with limited datasets obtained 
by  subsampling  T0  to  250  and  500  images  per  class  (here  after 
“species” when we are referring to our experiments), corresponding 
to 2500 and 5000 thumbnails in AT0;

We used ResNet 100 (He et al., 2016) as our classic deep-learning 
algorithm.  Resnet  is  a  convolutional  neural  network  (CNN),  a  DL  ar-
chitecture which is able to both extract features from images and classify 
these images thanks to those features (Lecun et al., 2015). In order for a 
CNN  to  build  an  image  classification  model,  the  architecture  is  fed  a 
large dataset, composed of pairs of labels and images. Using this dataset, 
the algorithms change their inner parameters in order to minimize the 
classification  error,  through  a  process  called  back-propagation.  The 
ResNet architecture achieved the best results on ImageNet Large Scale 
Visual Recognition Competition (ILSVRC (Russakovsky et al., 2015)) in 
2015, considered the most challenging image classification competition. 
It is still one of the best classification algorithms, while being easy to use 
and implement.

2)  adapt  this  model  to  a  new  task  with  few  examples,  while  not 
forgetting  the  concepts  learned  previously  (Gidaris  et  al.,  2018;  Har-
iharan et al., 2017). Finally, optimization-based methods are designed to 
adapt quickly to new tasks, hence able to learn a classification task with 
few examples (Finn et al., 2017; Nichol and Schulman, 2018; Sun and 
Chua, 2018). Optimization-based algorithms showed promising results 
in  deep  learning  few-shot  classification  (Finn  et  al.,  2017;  Jamal  and 
Cloud, 2019; Wang et al., 2019). Such methods propose to pre-train (or 
“meta-train”)  a  model  with  existing  databases  (e.g.  MiniImageNet 
(Russakovsky et al., 2015), Ominglot (Lake et al., 2019)) on different 
tasks so it can adapt easily to a new one. For object identification, a task 
is defined by the classes the model has to discriminate. Once this model, 
called “meta-model” has been trained, it can then be tuned to operate on

Wong, S.C., Mcdonnell, M.D., Adam, G., Victor, S., 2016. Understanding data 

augmentation for classification : when to warp ?. In: 2016 International Conference 
on Digital Image Computing: Techniques and Applications (DICTA), pp. 1–6. 
Yanbin, Liu, et al., 2019. Learning to Proagate Labels: Transductive Propagation Network 

for Few-shot Learning. arXiv preprint arXiv:1805.10002, pp. 1–14. 

Young, H.S., Mccauley, D.J., Galetti, M., Dirzo, R., 2016. Patterns, causes, and 

consequences of anthropocene defaunation. Annu. Rev. Ecol. Evol. Syst. (August), 
333–358. 

Zhuang, P., Wang, Y., Qiao, Y., 2018. Wildfish : a large benchmark for fish recognition in 
the wild. In: Proceedings of the 26th ACM international conference on Multimedia, 
2, pp. 1301–1309. 

Zintzen, V., Anderson, M.J., Roberts, C.D., Harvey, E.S., Andrew, L., 2017. Effects of 

latitude and depth on the beta diversity of New Zealand fish communities. Sci. Rep. 7 
(July), 1–10. 

EcologicalInformatics63(2021)1013206

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific preprocessing steps taken before training the deep learning models. However, based on common practices in machine learning and deep learning, some typical preprocessing steps include:

1. Data Cleaning: This involves removing or correcting any inconsistencies, errors, or missing values within the dataset. It may also involve handling outliers or irrelevant data points.

2. Normalization/Standardization: These techniques help scale the input features into a similar range, ensuring that no single feature dominates the learning process due to its larger numerical value. Common methods include Min-Max Scaling, Z-Score Standardization, and Unit Vector Normalization.

3. Data Augmentation: To increase the size of the dataset artificially, various transformations like rotation, flipping, zooming, cropping, etc., can be applied to the original images. This helps improve the robustness and generalizability of the model.

4. Feature Extraction: Depending on the complexity of the problem, domain knowledge might be required to identify relevant features that could aid the learning process. In case of image data, Convolutional Neural Networks (CNNs) automatically perform feature extraction during the training phase.

5. Encoding Categorical Variables: When dealing with categorical variables, they need to be converted into numerical form using encoding schemes such as One-Hot Encoding, Label Encoding, or Binary Encoding.

Although these preprocessing steps are commonly employed, the exact methodology depends on the nature of the dataset and the requirements of the specific deep learning algorithm being utilized.