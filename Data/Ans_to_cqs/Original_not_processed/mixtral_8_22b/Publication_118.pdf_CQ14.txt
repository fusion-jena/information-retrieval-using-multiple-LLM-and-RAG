Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 4 
Comparing the execution times to generate Spectral Indices, MFCC 
and our Auto-Encoder-based feature representation on a mid-range 
laptop  (i5,  8gb  ram).  Note  that  Spectral  Indices  and  MFCC  code 
includes the time needed to generate spectrograms, but our Auto- 
encoder  workflow  generates  spectrograms  prior  to  generating 
features.   

Spectral indices 
MFCC 
Auto encoder 

Execution time (seconds) 

953.84 
8.32 
6.76  

the  “max-pooling”  output  spectrograms  still  show  a  large  amount  of 
noise. As such, it is possible that further training may be able to improve 
the performance of these networks. 

5.2.3. Lossy MP3 compression

3. Method 

3.1. Dataset

At this timescale we found that our auto-encoders with smaller feature 
representations were outperformed by MFCC. Our testing on data that 
the model has not seen before, suggests that once it is likely to be able to 
be  reused,  with  minimal  (or  without)  retraining.  Once  trained,  it  is 
possible  to use our auto-encoder to  generate features on a  mid range 
laptop. Computation times to generate acoustic indices, mfcc and our 
feature representation can be seen in Table 4.

Table 3 
Comparing the variance of bcubed and purity evaluation metrics of feature representations found using Spectral Indices, MFCC and Auto Encoder over 20 runs using a 
subset of the total dataset.   

Vector size 

bcubed precision (Variance) 

bcubed recall (Variance) 

bcubed Fscore (Variance) 

Purity (Variance) 

Spectral indices 
MFCC 
Auto encoder (implicit) 
Auto encoder (explicit max-pooling) 

2048 
1287 
384 
384 

0.003 
0.006 
0.002 
0.0007 

0.006 
0.007 
0.001 
0.0007 

0.003 
0.006 
0.002 
0.0006 

0.003 
0.005 
0.002 
0.001  

Fig.  10. 2nd t-SNE plot  generated using  spectral indices.  Cluster  represented  by color  and species  ground-truth represented  by  shape.(For  interpretation  of  the 
references to color in this figure legend, the reader is referred to the web version of this article.) 

by Dias, et al., uses varying length spectrograms, and does not focus on 
individual call types directly directly (Dias et al., 2020).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide information about how the hyperparameters of the model are optimized. Therefore, I cannot determine whether they used methods like grid search or random search for optimization.