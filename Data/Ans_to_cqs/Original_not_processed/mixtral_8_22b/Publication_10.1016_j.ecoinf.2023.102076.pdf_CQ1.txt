Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ventional  ‘flat’  classification  has  been  previously  demonstrated  as  a 
useful  tool  for  filtering  standardised  datasets,  such  as  academic  ab-
stracts,  data  collection  from  online  platforms  often  generates  large 
volumes of highly variable textual data which, as demonstrated by our 
study,  can  necessitate  using  a  hierarchical  classification  approach. 
Although we focused on collecting social media posts and web articles, 
the models and pipeline developed in this study can be applied to other 
forms of textual data, such as listings from E-commerce platforms.

fying the exploitation or sale of a particular taxa, for which there may 
not be existing proxy datasets. Alternatively, researchers can annotate a 
randomly  selected  sample  of  collected  data,  according  to  their  own 
relevancy  criteria.  However,  this  approach  is  less  suitable  for  cases 
where relevant examples make up a small proportion of the collected 
data,  as  imbalanced  training  data  can  lead  to  poor  classification  per-
formance (Schr¨oder et al., 2021).

Here,  we  demonstrate  and  evaluate  a  text  classification  pipeline, 
designed to address both the issue of imbalanced datasets and the need 
for large training datasets, using an example data collection scenario. 
Importantly,  we  use  a  hierarchical  classification  approach,  whereby 
data are passed through a series of classifiers with increasingly specific

2.2. Data collection and preparation 

2.2.1.

Initial data collection

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The provided context does not explicitly mention the specific methods used for collecting raw data in the deep learning pipeline. However, it does suggest that the authors focus on collecting social media posts and web articles. This implies that they might have used web scraping techniques or APIs provided by these platforms to gather the necessary data. Additionally, the context mentions that the models and pipeline developed in this study can be applied to other forms of textual data, such as listings from e-commerce platforms. This further suggests that the authors could have also employed similar data collection methods for gathering information from those sources. Unfortunately, without more explicit details about the data collection process, it is difficult to provide a definitive answer regarding the exact methods used for obtaining raw data in the deep learning pipeline.