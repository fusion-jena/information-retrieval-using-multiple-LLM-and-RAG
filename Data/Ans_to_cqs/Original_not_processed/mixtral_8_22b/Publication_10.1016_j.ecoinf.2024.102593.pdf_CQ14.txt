Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4.6. Input selection in active learning 

Active learning enhances and facilitates the labour-intensive process 
of data generation, important in this field given the scarcity of labelled 
data or the need to generate training data to target certain species (Allen 
et  al.,  2021).  It  progressively  increases  the  training  data  by  selecting 
those  samples  most  likely  to  improve  model  performance  from  pre-
dictions that a model generates over unlabelled data. Iteratively training 
new models with additional labelled data selected from their predictions 
reduces  the  extent  of  manual annotation  (Shuyang  et  al.,  2020). In  a 
similar process as the example of Tolkova et al. (2021) discussed above, 
our proposed method of using model embeddings and dimensionality 
reduction to display model predictions in EV can contribute to selecting 
the best sample candidates for manual annotation. 

4.7. Closing in on rare events

outputs.  The  embeddings  obtained  using  the  BirdNET-Analyzer  v2.1 
models have 420 dimensions.

Tolkova et al. (2021), that is to generate embeddings from the model, 
apply clustering and then display the results in a scatterplot by means of 
dimensionality  reduction.  But  instead  of  selecting  examples  from

Our research group has a particular interest in rare sounds and how 
to apply neural networks in the search for vocalisations of rare species. 
In the search for the Coxen’s fig-parrot, we are looking for an extremely 
rare subspecies of bird for which there are no known sound recordings. 
Therefore, we, through necessity, resort to the use of reference calls of 
another subspecies, the red-browed fig-parrot. But we don’t know the 
similarities  or  dissimilarities  between  the  calls  of  the  two  subspecies. 
Using EV with models trained on the red-browed fig-parrot gives us a 
better understanding of how a particular model performs against this 
target and other false positive calls. Through the active learning process 
discussed above, we can enhance models until their performance match 
set criteria, discriminating possible false positives without excluding any 
very rare, never-before-recorded calls of the Coxen’s fig-parrot. Then, at

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention the optimization methods used for tuning the hyperparameters of the model. However, it discusses the application of active learning, which iteratively trains new models with additional labeled data selected from their predictions to reduce manual annotation efforts. This implies that the models might be retrained multiple times during the active learning process, potentially involving hyperparameter tuning. Common methods for hyperparameter optimization include grid search, random search, Bayesian optimization, and others. Without specific information about the optimization techniques employed in this case, one cannot definitively state which method was used.