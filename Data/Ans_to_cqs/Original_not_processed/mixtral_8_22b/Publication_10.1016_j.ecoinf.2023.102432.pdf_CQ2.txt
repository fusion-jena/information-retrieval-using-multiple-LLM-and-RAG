Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Zhang, Q., Goldman, S.A., Yu, W., Fritts, J.E., 2002. Content-based image retrieval using 
multiple-instance learning. In: Proc. 19th International Conf. on Machine Learning. 
Morgan Kaufmann, pp. 682–689. 

Zhou, Z.-H., Sun, Y.-Y., Li, Y.-F., 2009. Multi-instance learning by treating instances as 
non-I.I.D. samples. In: Proceedings of the 26th Annual International Conference on 
Machine Learning, ICML ‘09. Association for Computing Machinery, New York, NY, 
USA, pp. 1249–1256. https://doi.org/10.1145/1553374.1553534. 

Zou, S., Gader, P., Zare, A., 2019. Hyperspectral tree crown classification using the 
multiple instance adaptive cosine estimator. PeerJ 7, e6405. https://doi.org/ 
10.7717/peerj.6405. 

EcologicalInformatics79(2024)10243214

Random  Forest  is  a  common  machine  learning  approach  used  in 
remote sensing for classification. This approach requires a single pixel’s 
spectrum to be associated with a single metadata record, compared to 
MTMI-SMF which can take many pixels’ spectra and associate it with a 
single metadata record. Since training locations often did not fall near 
the center of a pixel (see example in Fig. 3 where the training location 
falls at the intersection of four NAIP pixels), a random pixel from the 
pixels  in  closest  proximity  of  the  training  location  was  selected  for 
analysis. This single pixel dataset was split into training and testing data 
using 5 K-fold cross-validations. MATLAB’s (MathWorks, Inc., Natick, 
Massachusetts) TreeBagger function was used to complete the classifi-
cation using 100 trees. Looping through the k-folds, the random forest 
algorithm was calculated using 80% of the data and classification results

ping Project training locations. The buffer radius varied between remote 
sensing image sources to accommodate differences in pixel resolutions. 
The  buffer  radius  was  set  to  the  image’s  spatial  resolution,  so  NAIP 
imagery used a 1-m buffer, RapidEye used a 5-m buffer, and Landsat 
used a 30-m buffer. Using the buffer polygons, pixels’ spectral data were 
extracted from the imagery. These pixels within a single buffer polygon 
were grouped into a bag. The bag was labeled positive if the data point 
had Brazilian peppertree at any abundance level.

Table A.2 
Confusion matrix for RapidEye imagery using MTMI-SMF. Each row is an iteration of the 5 K-Folds used with values only being used on the bags excluded from 
training. 

EcologicalInformatics79(2024)10243211S. Meerdink et al.                                                                                                                                                                                                                               

Table A.3 
Confusion matrix for Landsat imagery using MTMI-SMF. Each row is an iteration of the 5 K-Folds used with values only being used on the bags excluded from training. 

Table A.4 
Confusion matrix for NAIP imagery using Random Forest. Each row is an iteration of the 5 K-Folds used with values only being used on the bags excluded from 
training.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, we can infer that the data format used in the deep learning pipeline is images. Specifically, hyperspectral images are used for tree crown classification using the Multiple Instance Adaptive Cosine Estimator (MI-ACE). Additionally, other types of remote sensing images such as NAIP, RapidEye, and Landsat are also mentioned in the context. However, there is no mention of other data formats like audio or video. Therefore, based on the given information, we can conclude that the data format used in this particular deep learning pipeline is primarily images.