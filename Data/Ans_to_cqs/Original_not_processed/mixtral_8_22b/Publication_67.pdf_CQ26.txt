Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

74. LeCun, Y.; Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436. [CrossRef]
75. Lynch, C. Big data: How do your data grow? Nature 2008, 455, 28. [CrossRef]
76.

Steinkraus, D.; Buck, I.; Simard, P.Y. Using GPUs for machine learning algorithms. In Proceedings of
the Eighth International Conference on Document Analysis and Recognition (ICDAR’05), Seoul, Korea,
31 August–1 September 2005; pp. 1115–1120.

77. Bremond, L.; Alexandre, A.; Hély, C.; Guiot, J. A phytolith index as a proxy of tree cover density in
tropical areas: Calibration with Leaf Area Index along a forest–savanna transect in southeastern Cameroon.
Glob. Planet. Chang. 2005, 45, 277–293. [CrossRef]

78. Achard, F.; Eva, H.D.; Mayaux, P.; Stibig, H.J.; Belward, A. Improved estimates of net carbon emissions from

land cover change in the tropics for the 1990s. Glob. Biogeochem. Cycles 2004, 18. [CrossRef]

Supplementary Materials: The following are available online at http://www.mdpi.com/2072-4292/12/3/343/s1,
Figure S1: Number of results in the Google scholar academic search engine. Date of queries, 28 December 2019.
[keyword + deep learning]. Keywords: AlexNet, DenseNet, GoogLeNet, Inception, MobileNet, Resnet, Resnext,
VGG, Xception. Figure S2: Illustration of the diﬀerence between the sampling design strategies, (A) Continuous
and (B) Discrete, including examples of images (0.5 ha) from each class (Three Tree-Cover levels plus the Non-Forest
class) of the training dataset. Image data: Google, Maxar, and NWPU-RESISC45 dataset. Archive S1: Metadata of
FAO’s GDA photointerpreted very high resolution plots (71,135) with zoom 19 in Google Maps. The CVS ﬁle
contains Id, UpperLeft and Downright coordinates, Zoom, Region, Aridity level, Class (Forest/Non-forest), and
Tree cover. Archive S2: Metadata of training dataset of continuous larger sample CNN-based model with very

39.
40.

41.

Cover Classiﬁcation Using Convolutional Neural Networks. Remote Sens. 2019, 11, 274. [CrossRef]
Schmidhuber, J. Deep learning in neural networks: An overview. Neural Netw. 2015, 61, 85–117. [CrossRef]
Szegedy, C.; Vanhoucke, V.; Ioﬀe, S.; Shlens, J.; Wojna, Z. Rethinking the inception architecture for computer
vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV,
USA, 27–30 June 2016; pp. 2818–2826.
Szegedy, C.; Liu, W.; Jia, Y.; Sermanet, P.; Reed, S.; Anguelov, D.; Erhan, D.; Vanhoucke, V.; Rabinovich, A.
Going Deeper with Convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), Boston, MA, USA, 7–12 June 2015.

67. Neelakantan, A.; Vilnis, L.; Le, Q.V.; Sutskever, I.; Kaiser, L.; Kurach, K.; Martens, J. Adding gradient noise

improves learning for very deep networks. arXiv 2015, arXiv:1511.06807.

68. Ganguly, S.; Kalia, S.; Li, S.; Michaelis, A.; Nemani, R.R.; Saatchi, S. Very High Resolution Tree Cover Mapping
for Continental United States using Deep Convolutional Neural Networks. In Proceedings of the AGU Fall
Meeting Abstracts, New Orlean, LA, USA, 11–15 December 2017.
Suzuki, K.; Rin, U.; Maeda, Y.; Takeda, H. Forest cover classiﬁcation using geospatial multimodal data.
Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2018, 42, 1091–1096. [CrossRef]

69.

70. Marshall, M.; Thenkabail, P. Advantage of hyperspectral EO-1 Hyperion over multispectral IKONOS,
GeoEye-1, WorldView-2, Landsat ETM+, and MODIS vegetation indices in crop biomass estimation. ISPRS J.
Photogramm. 2015, 108, 205–218. [CrossRef]

Remote Sens. 2020, 12, 343

15 of 15

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting is a technique where the data is split into training and testing sets while maintaining the same distribution of classes or labels in both sets. This ensures that the model learns from a representative sample of the entire dataset, reducing any potential bias towards certain classes.

Oversampling is another method used to balance datasets by increasing the number of instances in minority classes. This can be done by duplicating existing samples or generating synthetic ones through interpolation or extrapolation methods. By doing so, the model will have more examples to learn from, thus improving its performance on underrepresented classes.

Undersampling, conversely, involves removing instances from majority classes to achieve a balanced dataset. While this may lead to loss of information, it can help prevent overfitting and improve generalization capabilities of the model.

Lastly, collecting diverse data is crucial for mitigating data bias. Ensuring that the dataset contains various types of input data, such as different demographics, environments, or conditions, allows the model to better understand and adapt to new situations. Additionally, incorporating domain knowledge into the selection process helps ensure that relevant features are included in the dataset.

In summary, addressing data bias during preprocessing of the deep learning pipeline requires careful consideration of multiple factors. Techniques like stratified splitting, oversampling, undersampling, and diverse data collection play essential roles in creating well-balanced and representative datasets, ultimately leading to improved model performance and reduced bias.