Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

samples in GSL100 would also help in the extensibility of the developing 
a deep learning model that works on multiple levels.

Table  3  gives  insights  into  the  distribution  of  trained,  tested,  and 
validated samples across  the groups. The data suggest that consistent 
ratios across groups are maintained in the sampling process to avoid any 
potential bias during classification. Different samples are present across 
groups to establish the reliability and generalizability of the model. For 
evaluation,  both  validation  and  test  sets  are  considered  separately  to 
fine-tune the model’s hyperparameters, leading to generalizability and 
scalability towards unseen datasets. 

4.5. Classifier specifications 

The Random Forest (RF) classifier is used in both levels of the hier-
archical classification model for performing group and plant-level pre-
dictions. Let several estimators N and Fi(x) be the function of predicting 
̂
the ith  decision tree for the input X, then the prediction 
C by RF is given 
by (9). 

̂C =

1
N

∑N

i=1

Fi(X)

(9)

in the datasets. Furthermore, the classifier ability to capture the non- 
linear  relationships  among  the  feature  representation  facilitates  the 
understanding of hierarchical relationships concerning a specific class in 
datasets.  It  combines  various  decision  trees  to  produce  predictions  at 
both levels. Bootstrap sampling creates multiple subsets (with random 
selection and replacement) of training data for individual decision trees 
in  a Random Forest. The training, validation, and  testing proportions 
considered in both levels as presented in Table 3.

Azadnia, R., Al-Amidi, M.M., Mohammadi, H., Cifci, M.A., Daryab, A., Cavallo, E., 2022. 
An AI based approach for medicinal plant identification using deep CNN based on 
global average pooling. Agronomy 12 (11), 2723. 

Bambil, D., Pistori, H., Bao, F., Weber, V., Alves, F.M., Gonçalves, E.G., Bortolotto, I.M., 
2020. Plant species identification using color learning resources, shape, texture, 
through machine learning and artificial neural networks. Environ. Syst. Decis. 40 
(4), 480–484. 

Barhate, D., Pathak, S., Dubey, A.K., 2023. Hyperparameter-tuned batch-updated 
stochastic gradient descent: plant species identification by using hybrid deep 
learning. Eco. Inform. 75, 102094 https://doi.org/10.1016/j.ecoinf.2023.102094. 

Barr´e, P., St¨over, B.C., Müller, K.F., Steinhage, V., 2017. LeafNet: a computer vision 
system for automatic plant species identification. Eco. Inform. 40, 50–56.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it appears that the authors have addressed potential data bias during the preprocessing stage of their deep learning pipeline through maintaining consistent ratios across groups in the sampling process. This is evident from the information presented in Table 3, which suggests that the distribution of trained, tested, and validated samples is balanced across different groups. By doing so, they aim to prevent any potential bias during classification.

However, the context does not explicitly mention the use of specific techniques such as stratified splitting, oversampling, undersampling, or diverse data collection to address data bias. These methods could potentially be employed to further mitigate imbalances within the dataset, but without additional information, we cannot confirm whether these techniques were utilized in this particular study.

In conclusion, while the authors do take steps to maintain consistency and balance in their sample distribution across groups, there is no explicit mention of other common techniques like stratified splitting, oversampling, undersampling, or diverse data collection being applied to address data bias in this case.