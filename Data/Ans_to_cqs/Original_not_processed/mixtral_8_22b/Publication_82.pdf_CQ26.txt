Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

strong in some of the subsets of the dataset, thus removing
another potential bias.

To summarize, we have a total of 60 experimental

conﬁgurations, which vary on the following parameters:

1. Choice of deep learning architecture:

AlexNet,
GoogLeNet.

2. Choice of training mechanism:

Transfer Learning,
Training from Scratch.

3. Choice of dataset type:

Color,
Gray scale,
Leaf Segmented.

4. Choice of training-testing set distribution:

Train: 80%, Test: 20%,
Train: 60%, Test: 40%,
Train: 50%, Test: 50%,
Train: 40%, Test: 60%,
Train: 20%, Test: 80%.

this paper, we have used the notation of

Throughout
Architecture:TrainingMechanism:DatasetType:Train-Test-
Set-Distribution to refer
experiments. For
to particular
instance,
to refer to the experiment using the GoogLeNet
learning
architecture, which was
on the gray-scaled PlantVillage dataset on a train—test
set distribution of
the notation
GoogLeNet:TransferLearning:GrayScale:60–40.

trained using transfer

60–40, we will use

Measurement of Performance
To get a sense of how our approaches will perform on new unseen
data, and also to keep a track of if any of our approaches are
overﬁtting, we run all our experiments across a whole range
of train-test set splits, namely 80–20 (80% of the whole dataset
used for training, and 20% for testing), 60–40 (60% of the whole
dataset used for training, and 40% for testing), 50–50 (50% of

the whole dataset used for training, and 50% for testing), 40–60
(40% of the whole dataset used for training, and 60% for testing)
and ﬁnally 20–80 (20% of the whole dataset used for training,
and 80% for testing). It must be noted that in many cases, the
PlantVillage dataset has multiple images of the same leaf (taken
from diﬀerent orientations), and we have the mappings of such
cases for 41,112 images out of the 54,306 images; and during all

Frontiers in Plant Science | www.frontiersin.org

3

September 2016 | Volume 7 | Article 1419

Mohanty et al.

architectures,
Among
GoogLeNet
than AlexNet
performs
(Figure 3A), and based on the method of training, transfer
learning always yields better results (Figure 3B), both of which
were expected.

the AlexNet
consistently

better

The three versions of the dataset (color, gray-scale, and
segmented) show a characteristic variation in performance across
all the experiments when we keep the rest of the experimental
conﬁguration constant. The models perform the best in case
of the colored version of the dataset. When designing the
experiments, we were concerned that the neural networks might
only learn to pick up the inherent biases associated with the
lighting conditions, the method and apparatus of collection of the
data. We therefore experimented with the gray-scaled version of
the same dataset to test the model’s adaptability in the absence of
color information, and its ability to learn higher level structural

Frontiers in Plant Science | www.frontiersin.org

5

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it is not explicitly mentioned what specific techniques are used to address data bias during preprocessing of the deep learning pipeline. However, there are several common techniques used in machine learning and deep learning pipelines to mitigate data bias, including stratified sampling, oversampling, undersampling, and diverse data collection.

Stratified sampling involves dividing the dataset into different strata or groups based on certain characteristics, then randomly selecting samples from each group to ensure that the sample represents the overall population accurately. This technique can help prevent overrepresentation or underrepresentation of certain classes or features in the dataset.

Oversampling and undersampling involve adjusting the class balance in the dataset by either duplicating examples from the minority class (oversampling) or reducing the number of examples from the majority class (undersampling). These techniques can help improve the performance of the model on imbalanced datasets.

Finally, collecting diverse data can also help reduce data bias by ensuring that the dataset includes a wide variety of examples representing different scenarios, populations, and perspectives. In this study, the authors mention using various types of datasets, including color, grayscale, and segmented datasets, which could potentially help address data bias related to lighting conditions and other factors.

However, without more explicit information about the specific techniques used in this study, it is difficult to provide a definitive answer to the query.