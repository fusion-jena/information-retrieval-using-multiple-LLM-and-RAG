Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Type

Patch size / Stride

Output Size

Depth

Params

7x7/2
3x3/2

3x3/1
3x3/2

3x3/2

3x3/2

7x7/1

convolution
max pool
batch norm
LRN
convolution
max pool
batch norm
LRN
inception (3a)
inception (3b)
max pool
batch norm
inception (4a)
inception (4b)
inception (4c)
inception (4d)
inception (4e)
max pool
batch norm
inception (5a)
inception (5b)
avg pool
batch norm
linear
softmax

112x112x64
56x56x64
56x56x64
56x56x64
56x56x192
28x28x192
28x28x192
28x28x192
28x28x256
28x28x480
14x14x480
14x14x480
14x14x512
14x14x512
14x14x512
14x14x528
14x14x832
7x7x832
7x7x832
7x7x832
7x7x1024
1x1x1024
1x1x1024
1x1x10000
1x1x10000

1
0
0
0
2
0
0
0
2
2
0
0
2
2
2
2
2
0
0
2
2
0
0
1
0

Ops

34M

2.7K

112K

360M

159K
380K

128M
304M

364K
437K
463K
580K
840K

73M
88M
100M
119M
170M

1072K
1388K

54M
71M

1000K

1M

IV. EXPERIMENTS

A. Hand-crafted Feature Extraction Experiment

1) Biased Dataset: This dataset was created by randomly
taking 70% of the data in D for training and 30% for
testing. These are really approximate percentages because such
distribution has to be attempted for each species in dataset D.
How close to a 70%-30% distribution is achieved depends
on how many photos per species there are in dataset D. For
example, if a given species X has 20 photos, 14 randomly
chosen photos will go to the training dataset and 6 to the
testing dataset. However, if the number of photos for species
X is 2, one will go to the training dataset and the other one to
the testing dataset, resulting in a 50%-50% distribution. This
is the approach most of previous plant identiﬁcation studies
have followed (particularly those based on leaf-scans).

A. Hand-crafted Feature Extraction Experiment

The ﬁrst experiment consists of running a traditional com-
puter vision pipeline using a LBPU feature extractor and kNN
as explained in Section III. In terms of the four scenarios
depicted in Table I, this experiment covers scenarios 1 and
2, that is, the ﬁrst row of the table. This experiment applies
the whole traditional pipeline to the data; so,
there is a
segmentation phase in both, the biased and unbiased runs.
As indicated in the previous section, because this experiment
includes scenario 2, we aim at comparing not only the impact
of SSPB when a hand-crafted feature extraction approach is
used, but also, the scalability of accuracy by replicating the
experiments in [14] with a larger dataset.

B. Deep Learning Experiment

Throughout this paper, we use the term Same-Specimen-
Picture Bias (SSPB) to refer to a particular characteristic of
the datasets used for the training phase and the testing phase
of a supervised learning experiment with a global dataset D.
We say that SSPB is avoided (absent) if all plant images from
dataset D are distributed so that, for each specimen S all its
images are used exclusively in the training phase or in the
testing phase. Otherwise, we say SSPB is (potentially) present.

It

is critical

this point

to understand at

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided information, it appears that the focus is primarily on describing the architecture and parameters of a deep learning model, along with details about the experimental setup involving biased and unbiased datasets. Unfortunately, there isn't any explicit mention of specific postprocessing steps performed after model training, such as generating saliency maps, calculating metrics, or creating confusion matrices. Therefore, without additional context, it is difficult to provide a definitive answer regarding the postprocessing steps involved after model training.