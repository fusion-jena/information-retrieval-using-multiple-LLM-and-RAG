Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ImageNet classification with deep 

convolutional neural networks. Commun. ACM 60, 84–90. https://doi.org/10.1145/ 
3065386. 

Kumar, S., Singh, A., Walia, S., 2018. parallel big bang–big crunch global optimization 
algorithm: performance and its applications to routing in WMNs. Wirel. Pers. 
Commun. 100, 1601–1618. https://doi.org/10.1007/s11277-018-5656-y. 

EcologicalInformatics81(2024)10258115S. Ghosh et al.                                                                                                                                                                                                                                   

Liu, Z., Reynolds, A.C., 2020. A sequential-quadratic-programming-filter algorithm with 
a modified stochastic gradient for robust life-cycle optimization problems with 
nonlinear state constraints. SPE J. 25, 1938–1963. https://doi.org/10.2118/193925- 
pa.

71.17% 

98.7% 

Ganguly et al., 2022b) 

DDYOLOv5 and ResNet-50 (Hu et al., 

Pine tree classification 

98.71% 

2022) 

Deep Attention Dense CNN model ( 

Pandey and Jain, 2022b) 

Dense convolutional neural networks 

Plant leaf disease 
classification 
Plant disease classification 

97.33% 

99.1% 

() 

Proposed Approach 

Plant leaf classification 

98.97  

6.1.2. CVIP100 dataset

sample  the  feature  maps  to  reduce  dimensionality.  By  leveraging  the 
hierarchical  representations  learned  through  these  layers,  CNNs  can 
automatically  detect  and  recognize  complex  patterns  and  objects  in 
images. The training process of a CNN involves optimizing the network 
parameters using large-scale labeled training data through techniques 
such as backpropagation and gradient descent (Chouhan et al., 2020). 
Understanding the significant parameters related to CNNs is essential 
because they can drastically affect model performance. The convolution 
operation is meant to apply filters to the input image. It allows CNNs to 
extract local features and capture spatial relationships between pixels. 
The convolution operation is calculated with the help of eq. (3):

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that two datasets were used in the deep learning pipeline: Pine Tree Classification and Plant Leaf Disease Classification. However, there is no mention of specific datasets such as MNIST, CIFAR, or ImageNet being used. Additionally, the context mentions the use of the CVIP100 dataset, but does not provide further details about this dataset. Therefore, based on the information available, we cannot definitively determine which standard datasets were used in the deep learning pipeline.