Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The results obtained in this study can be used as a baseline for future 
LULC  analysis  performed  with  other  methodologies,  such  as  deep 
learning  CNN  (Jagannathan  and  Divya,  2021).  Going  forward,  the 
analysis  of  aerial  images  of  KNP  taken  about  every  two  years  deep 
learning methods will be most effective and useful to map land cover or 
more specifically woody cover. Integrating large-area historical datasets 
in  land-use  and  land-cover  analysis  can  serve  as  a  resource  to  better 
understanding  long-term  landscape  changes  and  support  ecological 
monitoring programs. The results of studies such as this one can be used 
to  better  protect  and  preserve  our  natural  heritage,  enable  effective 
management  strategies,  and  contribute  to  the  conservation  of  global 
biodiversity. 

CRediT authorship contribution statement

For assessing the variable importance of the 18 GLCM texture met-
rics, we utilized the “ee.classifier.explain” algorithm and then calculated 
the relative importance of each metric. In contrast to other image clas-
sification  software,  the  segmentation  process  is  performed  after  the 
training dataset is created, therefore, the objects obtained from the SNIC 
algorithm (Section 2.3.3) are then labeled with the corresponding LC 
labels of the training points collected in Section 2.3.2 as preparation for 
image  classification  with  the  chosen  classifier.  Therefore,  using  the 
Random Forest together with the GLCM texture metrics (independent 
variables) and the training samples identified with LC labels (dependent 
variable), we classified all other segmented objects into woody or non- 
woody LC to obtain the final woody cover classification image. 

2.3.5. Accuracy, export, and land cover count

The supervised learning workflow adheres to the steps outlined in 
Sections 2.3.1–2.3.5. However, as detailed in Section 2.3.2, we deviated 
by not generating 400 random points over the entire boundary. Instead, 
we used the vegetation types described by Gertenbach (1983) to guide 
the placement of our sampling plots, from which we then collected the 
training and validation points (Fig. A.2). The creation of several small 
sampling plots within each vegetation type, instead of using one large 
area, also helped speed up the sampling process. Performing the data 
collection  within  the  sampling  plots  ensured  that  we  had  training/ 
validation  points  that  were  representative  of  the  diverse  vegetation 
within each boundary. To determine the size of the sampling plots, we 
first calculated 5% of the total area covered by the boundary, divided 
that area by the number of vegetation types intersecting the boundary

After  each  aerial  image  was  classified,  we  evaluated  the  accuracy 
metrics using a confusion matrix in GEE to summarize the performance 
of  our  classification  workflow  (Radoux  et  al.,  2008).  Factors  that 
affected  the  measurement  of  accuracy  included  the  resolution  of  the 
aerial images, the training/validation dataset, and the LC classes chosen. 
Accuracy assessment of the performance of the Random Forest classifi-
cation  yields  values  ranging  from  0%  (no  match)  to  100%  (complete 
match) (Lillesand et al., 2004). Overall accuracy reflects the percentage 
of correctly classified pixels in a map, but it does not show how errors 
are distributed among different land cover classes. To address this, we 
calculated producer’s accuracy, which gauges the correctness of refer-
ence  pixel  classification,  and  user’s  accuracy,  which  indicates  how 
accurately  the  classification  represents  actual  ground  conditions.  To

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't any information available regarding specific optimization techniques applied in the deep learning pipeline mentioned in the given context. The text discusses the use of deep learning methods for mapping land cover, particularly woody cover, using aerial images of Kruger National Park (KNP). It mentions the utilization of the "ee.classifier.explain" algorithm for assessing the variable importance of 18 Gray Level Co-occurrence Matrix (GLCM) texture metrics. Additionally, the Random Forest classifier is employed along with these GLCM texture metrics and training samples identified with Land Cover (LC) labels. However, no details are provided on the optimization techniques used in the deep learning pipeline.