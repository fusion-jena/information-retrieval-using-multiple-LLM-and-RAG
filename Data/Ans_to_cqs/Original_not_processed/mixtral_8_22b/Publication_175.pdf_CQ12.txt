Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We used ResNet 100 (He et al., 2016) as our classic deep-learning 
algorithm.  Resnet  is  a  convolutional  neural  network  (CNN),  a  DL  ar-
chitecture which is able to both extract features from images and classify 
these images thanks to those features (Lecun et al., 2015). In order for a 
CNN  to  build  an  image  classification  model,  the  architecture  is  fed  a 
large dataset, composed of pairs of labels and images. Using this dataset, 
the algorithms change their inner parameters in order to minimize the 
classification  error,  through  a  process  called  back-propagation.  The 
ResNet architecture achieved the best results on ImageNet Large Scale 
Visual Recognition Competition (ILSVRC (Russakovsky et al., 2015)) in 
2015, considered the most challenging image classification competition. 
It is still one of the best classification algorithms, while being easy to use 
and implement.

1)  We  trained  a  classic  DL  algorithms  architecture  with  our  biggest 

dataset AT0 as a baseline for the DL accuracy;  

2)  We  trained  the  same  DL  architecture  with  the  same  hyper- 
parameters (e.g. model architecture and training process) but on a 
much  more  limited  dataset  (AT1).  Hyper-parameters  are  the  pa-
rameters  defining  the  architecture (number of  layers, number and 
size of convolutions, connections between layers) and the training 
process  of  a  Deep  Model  (learning  rate,  neurone  activation,  back- 
propagation compotation).;  

3)  We trained the same DL architecture with limited datasets obtained 
by  subsampling  T0  to  250  and  500  images  per  class  (here  after 
“species” when we are referring to our experiments), corresponding 
to 2500 and 5000 thumbnails in AT0;

Comput. Vis. 211–252. 

Salman, A., et al., 2016. Oceanography : Methods Fish Species Classification in 

Unconstrained Underwater Environments Based on Deep Learning, pp. 570–585. 

Shiu, Y., et al., 2020. Deep Neural Networks For Automated Detection of Marine 

Mammal Species, pp. 1–12. 

Stuart-smith, R.D., et al., 2013. Integrating abundance and functional traits reveals new 

global hotspots of fish diversity. Nature 501 (7468), 539–542. 

Sun, Q., Chua, Y.L.T., 2018. Meta-transfer learning for few-shot learning. Conf. Comput. 

Vis. Pattern Recognit. 403–412.

Underwater  cameras  are  widely  used  to  monitor  marine  biodiversity,  and  the  trend  is  increasing  due  to  the 
availability of cheap action cameras. The main bottleneck of video methods now resides in the manual processing 
of images, a time-consuming task requiring trained experts. Recently, several solutions based on Deep Learning 
(DL) have been proposed to automatically process underwater videos. The main limitation of such algorithms is 
that they require thousands of annotated images in order to learn to discriminate classes (here species). This 
limitation implies two issues: 1) the annotation of hundreds of common species requires a lot of efforts 2) many 
species are too rare to gather enough data to train a classic DL algorithm. Here, we propose to explore how few- 
shot learning (FSL), an emerging research field, could overcome DL limitations. Few-shot learning is based on the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study uses a Convolutional Neural Network (CNN) as its deep learning model. Specifically, it employs the ResNet 100 architecture, which was introduced by He et al. in 2016. CNNs are particularly well-suited for tasks involving visual data, making them ideal for analyzing underwater imagery. They can simultaneously extract features from images and classify these images using the extracted features. In this case, the researchers utilized ResNet 100 to create an image classification model, feeding it large datasets consisting of labeled images. Through a process known as back-propagation, the model adjusts its internal parameters to reduce classification errors. Notably, ResNet 100 has demonstrated exceptional performance in the ImageNet Large Scale Visual Recognition Competition (ILSVRC), further supporting its suitability for this application.