Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2.6. Performance evaluation 

We used a number of metrics to evaluate model performance. Each 
are  scored  between  0  &  1,  with  optimal  performance  reached  at  1. 
Perhaps the simplest of these measures is accuracy, which indicates the 
proportion  of  images  that  the  model  classifies  correctly.  However,  to 
account  for  performance  within  classes  we  also  calculated  the  recall, 
precision and F1  score for each class. Recall, or sensitivity, refers to the 
proportion of images of each class that were correctly classified. Preci-
sion however determines the accuracy of the predictions themselves; it 
measures  the  proportion  of  images  that were  assigned  a  correct  class 
when  classified.  For  each  habitat  class  c,  recall  and  precision  are 
calculated as: 

Recallc =

TPc
TPc + FNc

Precisionc =

TPc
TPc + FPc

(1)  

(2)

Table 6 
Classifier testing performance: with overall test accuracy and class-averaged metrics (Recall, Precision and F1  Score).  

Set 

Images 

Classifier 

Accuracy 

Recall 

1 

2 

3 

1671 

248 

115 

SVM:Lineard 
SVM:Linear 
SVM:RBFd 
SVM:RBF 
CNN 
SVM:Lineard 
SVM:Linear 
SVM:RBFd 
SVM:RBF 
CNN 
SVM:Lineard 
SVM:Linear 
SVM:RBFd 
SVM:RBF 
CNN 

0.93 
0.93 
0.95 
0.95 
0.95 
0.86 
0.86 
0.88 
0.89 
0.88 
0.82 
0.82 
0.83 
0.87 
0.84 

0.93 (± 0.025) 
0.93 (± 0.025) 
0.92 (± 0.055) 
0.93 (± 0.040) 
0.94 (± 0.018) 
0.75 (± 0.140) 
0.75 (± 0.140) 
0.63 (± 0.370) 
0.80 (± 0.106) 
0.87 (± 0.039) 
0.82 (± 0.041) 
0.82 (± 0.041) 
0.67 (± 0.315) 
0.80 (± 0.138) 
0.83 (± 0.168) 

1Subscript d denotes SVM with default hyperparameters. 
295% confidence intervals are shown in brackets. Bold font dictates best results. 

Precision

Table 5 
Classifier  training  performance:  with  tuned  hyperparameters,  mean  cross- 
validation (CV) and final training accuracy.      

illumination patterns. 

3.2. Classification performance 

Set 

Images 

Classifier 

Hyperparameters 

Mean CV 

Train 

Accuracy 

1 

6682 

2 

992 

3 

459 

SVM:Lineard 
SVM:Linear 
SVM:RBFd 
SVM:RBF 
CNN 
SVM:Lineard 
SVM:Linear 
SVM:RBFd 
SVM:RBF 
CNN 
SVM:Lineard 
SVM:Linear 
SVM:RBFd 
SVM:RBF 
CNN 

C = 23.0 

(cid:0)

– 

(cid:0) 15.0 

C = 23.0, γ = 2
lr = 0.001 
– 

(cid:0) 15.0 

C = 23.0 

– 

C = 23.75, γ = 2
lr = 0.001 
– 

C = 23.0 

– 

C = 25.25, γ = 2
lr = 0.001 

(cid:0) 15.0 

0.93 (± 0.003) 
0.93 (± 0.003) 
0.95 (± 0.003) 
0.96 (± 0.003) 
0.92 (± 0.023) 
0.87 (± 0.010) 
0.87 (± 0.010) 
0.87 (± 0.018) 
0.91 (± 0.016) 
0.90 (± 0.015) 
0.83 (± 0.021) 
0.83 (± 0.021) 
0.78 (± 0.016) 
0.86 (± 0.020) 
0.82 (± 0.020) 

1.00 
1.00 
0.97 
0.98 
0.98 
1.00 
1.00 
0.91 
0.97 
0.97 
1.00 
1.00 
0.84 
0.95 
0.95

Learning 
rate 

Optimizer 

SVM: 
C 

γ 

The number of images you send to the model in each iteration. 
Model parameters are updated after each batch during training. 
How many times you pass the full image dataset through the model. 
The error metric that you wish to minimize. 
e.g. Cross entropy loss for multi-class classification. 
A small number (0, 1] that determines the amount to alter parameters 
during training with respect to the loss. 
Also known as the step size. 
An algorithm that modifies CNN parameters according to a particular 
strategy to minimize the loss. 
e.g. the Adam optimizer sets the learning rate adaptively for faster and 
more efficient training.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The performance of the deep learning model was evaluated using several metrics. These include accuracy, recall, precision, and F1 score. Accuracy indicates the proportion of images that the model classifies correctly. To account for performance within classes, recall, precision, and F1 scores were calculated for each class. Recall, also known as sensitivity, refers to the proportion of images of each class that were correctly classified. Precision, on the other hand, determines the accuracy of the predictions themselves by measuring the proportion of images that were assigned a correct class when classified. The formulas for calculating recall and precision for each habitat class c are given in equations (1) and (2), respectively. The table 6 shows the classifier testing performance with overall test accuracy and class-averaged metrics (recall, precision, and F1 score) for different models.