Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(Fig. 10).  A  camera  with  20  megapixel  resolution  is
used. Images with LED flash are taken at regular, pro-
grammable intervals, typically several minutes. Subse-
quent analysis breaks down the image into dark areas
that are approximately the area of the moths to be clas-
sified. Areas that are too small are ignored, and areas
that are too large are examined to see if they remain for
only  one  period  of  time  (possibly  feeding  birds),
remain unchanged (e.g., leaf blown on), or continue to
be seen the next night (dirt on the screen). For such
images, a message is generated to trigger human action
if necessary (e.g., cleaning the screen).

5. G. Brehm, “New LED lamp for the collection of noctur-
nal Lepidoptera and a spectral comparison of light-trap-
ping lamps,” Nota Lepidopterol. 40, 87–108 (2017).
6. J. Böhlke, D. Korsch, P. Bodesheim, and J. Denzler,
“Lightweight  filtering  of  noisy  web  data:  Augmenting
fine-grained datasets with selected internet images,” in
International Conference on Computer Vision Theory and
Applications (VISAPP) (2021), pp. 466–477.

7. S. T. Buckland et al., Distance Sampling: Methods and

Applications (Springer, New York, NY, 2015).

8. T.  Chambert,  D.  A.  W.  Miller,  and  J.  D.  Nichols,
“Modeling  false  positive  detections  in  species  occur-
rence data under different study designs,” Ecology 96
(2), 332–339 (2015).

9. R. B. Chandler and J. D. Clark, “Spatially explicit inte-
grated population models,” Methods Ecol. Evol. 5 (12),
1351–1360 (2014).

20. D. Korsch and J. Denzler, “In defense of active part se-
lection for fine-grained classification,” Pattern Recog-
nit. Image Anal. 28 (4), 658–663 (2018).

21. D. Korsch, P. Bodesheim, and J. Denzler, “Classifica-
tion-specific  parts  for  improving  fine-grained  visual
categorization,” in German Conference on Pattern Rec-
ognition (GCPR) (2019), pp. 62–75.

22. A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Ima-
geNet  classification  with  deep  convolutional  neural
networks,” in Advances in Neural Information Processing
Systems (NIPS) (2012), pp. 1097–1105.

23. T. Y. Lin, P. Dollár, R. Girshick, K. He, B. Hariharan,
and S. Belongie, “Feature pyramid networks for object
detection,”  in  Proceedings  of  the  IEEE  Conference  on
Computer  Vision  and  Pattern  Recognition  (2017),
pp. 2117–2125.

Detection rates in the laboratory or at test data sets
of more than 90% can generally not be achieved in the
field under real, constantly changing conditions. For
this reason, a feedback mechanism is provided, which
involves the user in the optimization of the system, but
at  the  same  time  minimizes  the  labeling  effort  to  be
made  manually.  This  is  known  as  active  learning.  In
the actual application, the system will, at certain inter-
vals, forward images to humans, and after the annota-
tion these images will be used to train a classifier iter-
atively. Evaluation is carried out with a retained test set
of images annotated manually.

Monitoring  devices  will  likely  also  detect  species
that are unknown for the recognition system. There-
fore, novelty detection is relevant [2, 3] which allows

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide specific information about how the hyperparameters of the model are optimized. However, it mentions that a feedback mechanism involving users is employed to improve the system's performance. This process, called active learning, involves presenting certain images to humans for annotation, then using those annotated images to iteratively train a classifier. While this approach helps minimize manual labeling efforts, it doesn't explicitly mention methods like grid search or random search for hyperparameter tuning. Therefore, based on the given context, we cannot determine the exact method used for optimizing the model's hyperparameters.