Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

with batch size 512 (65.54; see Table 2). These results provide a dif-
ferent perspective than the conclusions drawn by previous studies
(Masters and Luschi, 2018; Mishkin et al., 2016) where the use of small
or even mini-batches enhanced performances. This could be explained
by the high imbalance between classes and the fine-grained nature of
the classification task. Larger batches may therefore be more re-
presentative of the intra-class variability which in turn allows the net-
work to focus on inter-class variance. It will be asserted that our best
ResNet18 (ResNet18–224; 65.94 micro-F1, see Table 3) easily out-
performed deeper network architectures, whether trained from scratch
with a smaller batch size (ResNet50–128; micro-F1 63.89), or pre-
trained with fine-tuned weights (ResNet152–224; 60.09 micro-F1) ac-
cording to standard procedures (King et al., 2018). Our results support
the findings of a recent study which advocated the use of carefully

60.64
63.82
65.77
66.30

60.17
63.57
65.54
65.94

Table 3
Performances of different ResNet architectures on validation and test sets. ResNetX-Y is written so that X indicates the network's depth and Y the input size. In bold
the best value for each metric.

Network -patch Size

Batch size

Validation set

Test set

Macro-F1

Top-1 accuracy

Micro-F1

Macro-F1

Top-1 accuracy

Micro-F1

ResNet152–224
ResNet50–128
ResNet18–128
ResNet18–224
Ensemble

16
128
128
200
128

37.45
52.04
51.40
54.93
60.56

62.38
64.07
63.90
66.70
70.60

60.46
63.85
63.88
66.44
70.35

38.26
52.27
51.62
53.93
60.38

61.71
64.35
63.60
66.30
70.54

60.09
63.89
63.44
65.94
70.37

contextual information. If the patch size is too small, it contains in-
sufficient information and most probably fails to capture whole in-
dividuals; if it is too large, the context scrambles the signature of the
central information, confusing the algorithm. The patch size 64 × 64
pixels performed the worst out of all the metrics; the large differences
between validation and test performances was indicative of its poor
capacity for generalization. A patch size of 224 × 224 gave the highest
micro-F1 on the test set (65.94). This patch size included enough con-
textual noise to regularize overfitting, and it enabled better general-
ization. While the single RestNet18 based on the patch size 224 × 224
obtained the best accuracy, our ensemble network, which was based on
the four tested patch sizes and followed the feature extraction scheme
improved classification
of the local-SPP (Mahmood et al., 2016),

ResNet18s, and used the same optimiser and parameters as mentioned
above. Data augmentation on all patches was performed for all trained
networks, in order to compensate for the high class imbalance and
allow a better generalization. We applied random rotations between 0
and 180 degrees, brightness scaling between 0.4 and 1.6, and hor-
izontal / vertical flipping to all patches on the fly as data was fed to the
networks. Trainings lasted at least 100 epochs and were stopped when
validation accuracy did not improve for 25 epochs.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention any specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, there are some hints about how the authors might have dealt with data imbalance.

Firstly, the authors mention using larger batches, which they suggest may be more representative of the intra-class variability, allowing the network to focus on inter-class variance. This could potentially help mitigate the effects of class imbalance.

Secondly, the authors discuss using different patch sizes for their images. They found that a patch size of 224 x 224 pixels performed the best, as it included enough contextual noise to regularize overfitting and enable better generalization. This suggests that the authors may have been trying to find a balance between providing enough contextual information without overwhelming the model with unnecessary detail.

Lastly, the authors mention applying data augmentation to all patches, including random rotations, brightness scaling, and horizontal/vertical flipping. This technique can help increase the diversity of the training data and reduce overfitting, especially in cases where there is a high class imbalance.

Overall, while the authors do not explicitly state that they used techniques like stratified splitting, oversampling, undersampling, or diverse data collection, they do describe several strategies that could potentially help address data bias and imbalance in their deep learning pipeline.