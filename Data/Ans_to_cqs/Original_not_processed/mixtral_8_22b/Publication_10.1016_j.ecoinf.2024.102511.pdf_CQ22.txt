Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ct.org/web/packages/PAMpal/index.html. 

Shorten, Connor, Khoshgoftaar, Taghi M., 2019. A survey on image data augmentation 
for deep learning. J. Big Data 6 (1), 60. https://doi.org/10.1186/s40537-019-0197- 
0. 

Simonis, Anne E., 2020. Passive Acoustic Survey of Deep-Diving Odontocetes in the 
California Current Ecosystem 2018: Final Report. NOAA-TM-NMFS-SWFSC-630. 
https://doi.org/10.25923/W5XX-JZ73. 

Simons, R.A., John, Chris, 2022. ERDDAP. NOAA/NMFS/SWFSC/ERD, Monterey, CA. 

https://coastwatch.pfeg.noaa.gov/erddap.  

Soldevilla, Melissa S., Elizabeth Henderson, E., Campbell, Gregory S., Wiggins, Sean M., 
Hildebrand, John A., Roch, Marie A., 2008. Classification of Risso’s and Pacific 
white-sided dolphins using spectral properties of echolocation clicks. J. Acoust. Soc. 
Am. 124 (1), 609–624. https://doi.org/10.1121/1.2932059.

Stowell, Dan, 2022. Computational bioacoustics with deep learning: a review and 
roadmap. PeerJ 10 (March), e13152. https://doi.org/10.7717/peerj.13152. 

Team, R. Core, 2013. R: A Language and Environment for Statistical Computing. 
United States National Marine Fisheries Service, 2016. 2016 Annual Report of a 
Comprehensive Assessment of Marine Mammal, Marine Turtle, and Seabird 
Abundance and Spatial Distribution in US Waters of the Western North Atlantic 
Ocean – AMAPPS II. https://doi.org/10.25923/GBAP-G480. 

LeBien, Jack G., Ioup, Juliette W., 2018. Species-level classification of beaked whale 

Yano, Kymberly M., Oleson, Erin M., Keating, Jennifer L., Ballance, Lisa, Hill, Marie C., 

echolocation signals detected in the northern Gulf of Mexico. J. Acoust. Soc. Am. 144 
(1), 387–396. https://doi.org/10.1121/1.5047435. 

Li, Kun, Sidorovskaia, Natalia A., Tiemann, Christopher O., 2020a. Model-based

Development of automated classification routines, if accurate, serves to 
improve the efficiency, reduce the subjectivity, and decrease the cost of 
analyzing large datasets.

Detectors and Classifiers Used During the 2012 Southern California Behavioral 
Response Study {NOAA} Tech Memo NOAA-TM-NMFS-SWFSC-517.  
Kirsebom, Oliver S., Frazao, Fabio, Padovese, Bruno, Sakib, Sadman, Yue, Su, 

Matwin, Stan, 2022. MERIDIAN open-source software for deep learning-based 
acoustic data analysis. J. Acoust. Soc. Am. 151 (4), A27. https://doi.org/10.1121/ 
10.0010545. 

McCullough, Jennifer L.K., Oleson, Erin M., Barlow, Jay, Allen, Ann N., Merkens, Karlina 
P.B., 2021. An acoustic survey in the Main Hawaiian islands using drifting recorders. 
In: PIFSC Administrative Report H-21-04: 26. https://doi.org/10.25923/RZZZ-0V38. 

McDonald, Mark A., Hildebrand, John A., Wiggins, Sean M., Johnston, David W., 

Polovina, Jeffrey J., 2009. An acoustic survey of beaked whales at cross seamount 
near Hawaii. J. Acoust. Soc. Am. 125 (2), 624–627. https://doi.org/10.1121/ 
1.3050317. 

Mutanu, Leah, Gohil, Jeet, Gupta, Khushi, Wagio, Perpetua, Kotonya, Gerald, 2022.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The sources provided do not explicitly mention specific metrics used to evaluate the performance of deep learning models. However, based on common practices in machine learning and deep learning, some commonly used evaluation metrics include accuracy, precision, recall, F1 score, area under the receiver operating characteristic curve (AUROC), and confusion matrix. Accuracy is the ratio of correctly predicted observations to the total observations. Precision measures the proportion of true positive predictions out of all positive predictions made by the classifier. Recall calculates the proportion of actual positives that were identified correctly. The F1 score combines both precision and recall into one metric. AUROC provides an aggregate measure of performance across all possible classification thresholds. Lastly, a confusion matrix summarizes the prediction results of a classification problem. It shows the number of correct and incorrect predictions broken down by each class.