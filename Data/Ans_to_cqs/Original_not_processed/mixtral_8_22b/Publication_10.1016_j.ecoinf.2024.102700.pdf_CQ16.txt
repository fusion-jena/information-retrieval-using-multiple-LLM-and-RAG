Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

for model validation, either in addition to internal validation strategies
(n = 22), or as the sole validation method (n = 17). Notably, a consid-
erable number of studies did not use an explicit validation method to
measure model performance or did not clearly state this in the text (n =
94, 32%) (category “not provided” in Fig. 10).

A diverse set of validation metrics emerged from the analysis of
studies performing model predictions (n = 260), with the most common
displayed in Fig. S2. The Area Under the Receiver Operating Charac-
teristic Curve (AUC-ROC curve) was the predominant choice (n = 144,
55%). However, in many cases, the metrics used were not clearly stated
or provided in the text (n = 59, 23%). Approximately half of the studies
(n = 104, 40%) considered more than one validation metric simulta-
neously to assess different aspects of model performance. Multiple
software tools were employed for modelling, with a focus on R and its
associated packages, and listed in Table S3.

3.6. Model results

employed in its collection?

iii. What kind of (correlative) modelling approaches have been

applied?

iv. Which environmental variables have been used as candidates in

the models?

v. What temporal and spatial resolution was chosen for the model?
vi. Which validation method was used and which metrics were

vii. What

the main output

for which these models were

selected?
is
implemented?

viii. What are the strengths, weaknesses and opportunities of each

modelling approach?

Based on these research questions, related eligibility criteria were
then developed using the standard approach for research questions
definition (i.e., Population, Intervention, Comparator - PIC framework,
CEE, 2022, Table 1).

EcologicalInformatics82(2024)1027002E. Pasanisi et al.

Table 1
Eligibility criteria concerning question key elements following the PIC
framework.

Question key elements

Eligibility criteria

Population (P):

● Point location/occurrence data of
Cetacean and/or Sea turtle species

Biol. Annu. Rev. 26, 553–568.

Lerebourg, L., Saboul, D., Cl´emençon, M., Coquart, J.B., 2023. Prediction of Marathon
performance using artificial intelligence. Int. J. Sports Med. 44 (05), 352–360.
https://doi.org/10.1055/a-1993-2371.

Levin, S.A., 1992. The problem of pattern and scale in ecology: the Robert H. MacArthur

award lecture. Ecol 73 (6), 1943–1967. https://doi.org/10.2307/1941447.
Machias, A., Karakassis, I., Somarakis, S., Giannoulaki, M., Papadopoulou, K.N.,

Smith, C., 2005. The response of demersal fish communities to the presence of fish
farms. Mar. Ecol. Prog.Ser. 288, 241–250. https://doi.org/10.3354/meps288241.

Maglietta, R., Saccotelli, L., Fanizza, C., et al., 2023. Environmental variables and

machine learning models to predict cetacean abundance in the Central-Eastern

EcologicalInformatics82(2024)10270016E. Pasanisi et al.

Mediterranean Sea. Sci. Rep. 13, 2600. https://doi.org/10.1038/s41598-023-29681-
y.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study does not provide specific information about the criteria used to determine when training is complete. However, it mentions that various methods of model validation were used, including internal validation strategies and external validation methods. The most commonly used validation metric was the Area Under the Receiver Operating Characteristic Curve (AUC-ROC curve). In some cases, multiple validation metrics were used simultaneously to assess different aspects of model performance. Unfortunately, there is no clear indication of how these validation methods were used to determine when training should be stopped. Therefore, based on the available information, it cannot be determined what criteria are used to determine when training is complete.