Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

networks for visual recognition. IEEE Trans. Pattern Anal. Mach. Intell. 37, 
1904–1916. 

He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. In: 
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las 
Vegas, NV, USA, pp. 770–778. https://doi.org/10.1109/CVPR.2016.90. 

Hosang, J., Benenson, R., Schiele, B., 2017. Learning non-maximum suppression. arXiv. 
Hu, J., Shen, L., Albanie, S., et al., 2019. Squeeze-and-excitation networks, arXiv: 

1709.01507v4 [cs.CV] 16 May 2019. 

Khalajzadeh, H., Manthouri, M., Teshnehlab, M., 2014. Face recognition using 

convolutional neural network and simple logistics classifier. Adv. Intell. Syst. Comp. 
223, 197–207. 

K¨orschens, M., Denzler, J., 2019. ELPephants: A fine-grained Dataset for elephant re- 
identification. In: 2019 IEEE/CVF international conference on computer vision 
workshop (ICCVW), pp. 263–270.

The work is based on the popular YOLOv5 architecture integrated 

with a SENet attention mechanism (Zhu et al., 2021). 

The  YOLO  (You  Only  Look  Once)  is  a  simple  and  extremely  fast 
object detection algorithm that avoids a complex pipeline and considers 

• Backbone: A CNN, which acts as the main body of the network, is 
designed using the New CSP-Darknet53 (Cao et al., 2023) structure. 
It extracts key features from the input image. 

EcologicalInformatics79(2024)1023986B. Bhagabati et al.                                                                                                                                                                                                                              

Fig. 3. YOLOv5 architecture with proposed attention layer. YOLOv5 blocks, SENet attention layer blocks and the embedded attention layers in the Backbone of the 
YOLOv5 model are shown.

In  order  to  determine  more  accurate  training  results  and  also  to 
explore the effect of epoch upon training result, apart from 150 epochs, 
the model with attention layer is trained with epoch values 100, 200, 
and  250  under  a  uniform  training  environment  and  with  the  same 
dataset.  The  training  summary  for  each  of  these  epochs  is  shown  in 
Tables 5, 6 and 7 for epochs 100, 200, and 250, respectively. The trends 
of mAP values with increasing epochs are shown in Figs. 14 and Fig. 15. 
The size of the dataset used for custom training is sufficiently large. 
Further, the DL model used in this work is tuned with optimized hyper 
parameters  for  which  overfitting  and  under  fitting  situations  are  pre-
vented from occurring. As mentioned above, the effort to over-train the 
model has been avoided and graded MSE convergence (Figs. 7 to 11) has 
been  adopted  to  fine-tune  the  model.  Results  obtained  for  different

Fig. 2. YOLOv5 network architecture showing the three components of the model, namely Backbone, Neck and Head. Nos. of input layers, output layers, kernel size, 
strides and blocks are also shown (Xu et al., 2021). 

3.1. Dataset 

A  publicly  available  dataset  in  Roboflow  (Roboflow  Dataset,  n.d) 
named Animal2–v1 comprising 9952 images belonging to classes Bear 
(1530  images),  Deer  (966  images),  Elephant  (1684  images),  Leopard 
(1888 images), Monkey (1214 images), Tiger (1388 images) and Wild-
boar (1282 images) is used. All the images are annotated in YOLOv5 
PyTorch  format.  The  preprocessing  applied  for  the  dataset  is  auto- 
orientation  of  pixel  data  with  EXIF-format  stripping,  and  the  images 
are resized to 416 × 416 (stretch). Here, 70% of images are used for 
training,  20%  images  for  validation,  and  10%  images  are  used  for 
testing. No image augmentation techniques are applied.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The research paper uses a publicly available dataset named Animal2-v1 from Roboflow. This dataset comprises 9952 images belonging to seven animal classes: Bear, Deer, Elephant, Leopard, Monkey, Tiger, and Wild-boar. All the images are annotated in YOLOv5 PyTorch format. For preprocessing, the dataset applies auto-orientation of pixel data with EXIF-format stripping, and the images are resized to 416 × 416 (stretch). The dataset distribution includes 70% of images for training, 20% images for validation, and 10% images for testing. No image augmentation techniques are applied.