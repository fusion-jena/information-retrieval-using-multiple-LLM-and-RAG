Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(3)  

λ = wavelength of emitted radiance (10.6 μm) 
p = h.c/ σ (1.438.10
σ = (1.38.10–23 JK
h = Planck’s constant (6.626.10
c = Velocity of light (2.998.108 ms

(cid:0) 2 m. K) 
(cid:0) 1) 

(cid:0) 34 J.s) 
(cid:0) 1) 

2.3.3. Modelling 

Artificial  neural  networks  are  a  successful  method  in  modelling 
studies and are frequently discussed in the literature. Essentially, neural 
networks learn from past and present data, uncover hidden relationships 
among  the  data,  and  utilise  them  to  make  predictions  for  future  sce-
narios. Among the various types of artificial neural network models, the 
NARX model is widely employed. In this study, the NARX feedback ANN 
model  was  utilised  to  define  vegetation  biomass  density  for  2030.  A 
hybrid  model  was  developed  by  combining  wavelet  analysis  and  the 
NARX ANN algorithm to enhance the performance of the NARX ANN 
model.

The test value R in artificial neural networks evaluates the model’s 
overall performance. A high R-value indicates that the model can make 
predictions close to the actual data and exhibits good performance. The 
model performance, dependent on the number of selected hidden layer 
neurons,  is  presented in  Table  3.  In this  context, an  R-value between 
70% and 80% signifies that the model can make predictions close to the 
actual  data  and  demonstrates  a  successful  performance  (Sa˘gık  et  al., 
2021). When 6 hidden layer neurons were selected for both stations, the 
NARX model yielded the best results. The table also includes the rela-
tionship between the target values of training, validation, and test re-
sults. The training values were 82% for Iznik and 84% for Alanya. The 
estimated percentages of all the datasets were obtained through training 
with the ANN as 80% for Iznik and 82% for Alanya. It has been deter-

After  comparing  the  MSE  and  R  values  for  different  numbers  of 
neurons in the ANN system, the best model was determined to have 6 
hidden layer neurons. The performance outcomes of this best model are 
presented in Table 4, utilising the MAPE, RMSE and MSE as performance 
indicators. MAPE, which ranges from 0 to 100, assesses the error per-
centage  between  predicted  and  actual  values.  Considering  that  lower 
MAPE  values  indicate  better  prediction  performance,  ANN  analysis 
resulting in MAPE values of 15.9% for Iznik and 5.1% for Alanya showed 
that the prediction performance was higher for Alanya. In other words, 
the ANN model demonstrated better prediction ability and reliability, 
especially  for  the  Alanya  region,  and  surpassed  the  performance 
observed  in  Iznik.  Lower RMSE  and  MSE  values  indicate  closer  prox-
imity  of  predictions  to  actual  values,  signifying  better  performance.

By employing the W-ANN model, the training values reached 96% 
for Iznik and 91% for Alanya, while the estimated percentages for all 
data increased to 95% for Iznik and 88% for Alanya, respectively. The 
developed hybrid model improved learning success, with an increase of 
18.7%  in  Iznik  and  7.3%  in  Alanya,  as  determined  by  the  network’s 
performance.  These  findings  highlight  the  hybrid  model’s  enhanced 
predictive capabilities and effectiveness in both study areas.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, there is no explicit mention of specific optimization techniques used in the deep learning pipeline such as Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), or others. However, it does discuss the use of Artificial Neural Networks (ANNs) and specifically mentions the Nonlinear Autoregressive Exogenous Model (NARX) as part of the deep learning approach.

While not explicitly stated, it can be inferred that some form of optimization technique would have been utilized during the training phase of the ANN model. This could include methods like gradient descent, stochastic gradient descent, or adaptive learning rate algorithms like Adam. These techniques help minimize the loss function during training, thereby improving the accuracy of the model.

Moreover, the text refers to the selection of the optimal number of hidden layer neurons to improve the model's performance. This process involves tuning hyperparameters, which is another aspect of optimizing a deep learning model.

However, without more detailed information about the exact implementation of the ANN model, it is impossible to definitively state which optimization techniques were used.