Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

environment condition classification models, the potential influence of 
fish being in the extracted frames was considered negligible. 

The  12,000  frames  (8  frames  *  1500  videos)  extracted  from  the 
training  and  testing  dataset  were  then used  to  generate  five  different 
data sets using repeated random sub-sampling (see Fig. 4 (2)). Each of 
the  sets  was  further  split  into  a  training/testing  split  of  80/20,  con-
taining 9600 frames for training and 2400 for testing. Five CNN models 

using  the  same  model  architecture  were  then  trained  and  tested.  All 
models were trained over 100 epochs and returned an average loss value 
of  0.0126  with  an  average  accuracy  of  99.3%  during  training  and 
testing. Figures  for the  individual models are provided  in the  supple-
mentary material.

binations  of  environmental  conditions.  For  the  training  and  testing 
phases, eight random frames from each of the training and testing videos 
were  extracted  irrespective  of  the  video  lengths.  The  frame  selection 
process was carried out using a Python script which randomly selected 
the frames using a uniform distribution. This implied that there could be 
instances  where  frames  from  fish  videos  did  not  contain  any  fish. 
However,  given  that  the  frames  were  only  used  for  training  the

Raschka, S., 2018. Model Evaluation, Model Selection, and Algorithm Selection in 

Xiao, H., Zhang, F., Shen, Z., Wu, K., Zhang, J., 2021. Classification of weather 

Machine Learning. CoRR abs/1811.12808. URL: http://arxiv.org/abs/1811.12808, 
arXiv:1811.12808.  

phenomenon from images by using deep convolutional neural network. Earth Space 
Sci. 8 https://doi.org/10.1029/2020ea001604. 

Rathi, D., Jain, S., Indu, S., 2017. Underwater fish species classification using 

convolutional neural network and deep learning. In: 2017 Ninth International 
Conference on Advances in Pattern Recognition (ICAPR), pp. 1–6. https://doi.org/ 
10.1109/ICAPR.2017.8593044. 

Salman, A., Maqbool, S., Khan, A.H., Jalal, A., Shafait, F., 2019. Real-time fish detection 
in complex backgrounds using probabilistic background modelling. Ecol. Inform. 51, 
44–51. https://doi.org/10.1016/j.ecoinf.2019.02.011. 

Schettini, R., Corchs, S., 2010. Underwater image processing: state of the art of

classification  pipeline.  The  validation  performance  of  CNN  Model  4 
with respect to each of the six environmental conditions is shown in the 
confusion matrix of Fig. 7 (b).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it appears that the strategy employed to handle randomness in the deep learning pipeline is repeated random sub-sampling. This technique involves creating multiple subsets of data from the original dataset, with each subset containing a different combination of samples. These subsets are then used to train and test the machine learning models. By repeating this process multiple times, the variability introduced by random factors such as the initial seed value can be mitigated.

In the case described in the context, five different datasets were generated using repeated random sub-sampling, and each dataset was further divided into a training/testing split of 80/20. Five CNN models were then trained and tested using these datasets. The use of multiple datasets and models helps ensure that the results obtained are robust and reliable, even when faced with random variations in the input data or model parameters.

It should also be noted that the frame selection process for extracting frames from the training and testing videos was carried out using a Python script that randomly selected frames using a uniform distribution. While this approach may result in some instances where frames do not contain any fish, it ensures that the resulting datasets are representative of the full range of possible environmental conditions encountered in the field.

Overall, the use of repeated random sub-sampling and multiple datasets and models provides a powerful tool for handling randomness in the deep learning pipeline and ensuring that the results obtained are accurate and reliable.