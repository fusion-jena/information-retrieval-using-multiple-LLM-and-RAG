Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

structures (e.g., roads and buildings) and water from slowing down the 
classification processing. This step reduced the average number of pixels 
per scene the classification model had to analyze to 3,757,323 and took, 
on average, 18 s per scene.

destructive  species.  The  assessment  was  developed  through  a  data 
analysis pipeline centered on supervised ML classification algorithms to 
identify iceplant in freely available aerial images from the 2020 National 
Agriculture Imagery Program (NAIP) archive at 0.6 m/pixel resolution. 
This open, reproducible, and adaptable workflow provides a large-scale 
detailed understanding of the location and area occupied by a harmful 
invasive species and opens a path toward repeating this assessment over 
time and transferring it to other regions.

Ustin, S.L., DiPietro, D., Olmstead, K., Underwood, E., Scheer, G.J., 2002. Hyperspectral 

remote sensing for invasive species detection and mapping. In: IEEE International 
Geoscience and Remote Sensing Symposium, 3, pp. 1658–1660. https://doi.org/ 
10.1109/IGARSS.2002.1026212. 

Vali, A., Comai, S., Matteucci, M., 2020. Deep learning for land use and land cover 

classification based on hyperspectral and multispectral earth observation data: a 
review. Remote Sens. 12 (15), 2495. https://doi.org/10.3390/rs12152495. 
Van Der Walt, S., Sch¨onberger, J.L., Nunez-Iglesias, J., Boulogne, F., Warner, J.D., 
Yager, N., Gouillart, E., Yu, T., 2014. Scikit-image: image processing in Python. 
PeerJ 2, e453. https://doi.org/10.7717/peerj.453.

We will abbreviate producer’s accuracy as PA and user’s accuracy as 
UA throughout. The goal for selecting which texture features to use was 
to  maximize  iceplant  PA  (detect  as  much  iceplant  as  possible)  while 
balancing the other accuracy metrics and keeping viable computation 
times. The highest iceplant PAs (Fig. SF4-a) were obtained using GLCM 
features over a 23 × 23 window (91.82%), GLCM features over a 25 × 25 
window  (91.52%),  and  average  and  entropy  features  over  a  13  × 13 
window (91.21%). Including average and entropy over a 13 × 13 win-
dow  produced  the  fourth  highest  OA  (92.13%)  and  the  third  highest 
other vegetation UA (93.08%), not far from the highest values, obtained 
with the GLCM features over a 23 × 23 window (92.8% OA and 93.57% 
other  veg  UA)  (see  Fig.  SF4-d,e).  GLCM  features  were  less  computa-
tionally efficient than average and entropy features, and we considered

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data format used in the deep learning pipeline is image data. Specifically, the study uses freely available aerial images from the 2020 National Agriculture Imagery Program (NAIP) archive with a resolution of 0.6 meters per pixel. These images are then processed using supervised machine learning classification algorithms to identify iceplant, a destructive invasive species. The goal is to provide a detailed understanding of the location and area occupied by the harmful invasive species and enable repeat assessments over time and in other regions.