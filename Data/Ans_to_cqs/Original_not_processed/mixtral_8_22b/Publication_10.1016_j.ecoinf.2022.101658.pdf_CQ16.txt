Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Class 

0 - Woody debris 
1 - Forb 
2 - Grass 
3 - Lichen 
4 - Feather moss 
5 - Other moss 
6 - Sphagnum moss 
7 - non-fuel 
8 - Shrub 
9 - Void 
Average 

mIoU 

0.462 
0.333 
0.49 
0.1 
0.283 
0.166 
0.74 
0.622 
0.396 
0.31 
0.39 

Accuracy 

0.756 
0.953 
0.936 
0.945 
0.901 
0.891 
0.99 
0.987 
0.914 
0.748 
0.903  

4. Discussion

characteristics in the Pusch ridge wilderness, Arizona. J. Wildl. Manag. 902–907. 

Everingham, M., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., 2010. The 

PASCAL visual object classes (VOC) challenge. Int. J. Comput. Vis. 88 (2), 303–338. 
Ferster, C.J., Coops, N.C., 2014. Assessing the quality of forest fuel loading data collected 

using public participation methods and smartphones. Int. J. Wildland Fire 23 (4), 
585–590. 

Ferster, C.J., Coops, N.C., Harshaw, H.W., Kozak, R.A., Meitner, M.J., 2013. An 

exploratory assessment of a smartphone application for public participation in forest 
fuels measurement in the wildland-urban interface. Forests 4 (4), 1199–1219. 

Graham, R.T., McCaffrey, S., Jain, T.B., 2004. Science Basis for Changing Forest 

Structure to Modify Wildfire Behavior and Severity Gen. Tech. Rep. RMRS-GTR-120 
Fort Collins, CO: U.S. United States Department of Agriculture Forest Service, Rocky 
Mountain Research Station, p. 43.

formance  metrics  by  class  for  the  test  data.  For  each  image,  we  only 
considered cover types that occupied at least 1% of the manually clas-
sified segmentation map. In most cases, the class result approaches the 
average, but some classes such as lichen and ‘other moss’ had notably 
low  mIoU  values,  which  is  not  surprising  given  the  low  frequency  of 
occurrence of these classes.

Manual image 
classification 
PM,CL data 

Algorithm-based image 
classification 
Independent validation, CK data 

Forb 
Grass 
Lichen 
Feather moss 
Sphagnum 
moss 

0.69* 
0.85* 
0.69* 
0.91* 
0.88* 

0.75* 
0.96* 
0.58 
0.67* 
0.67*

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information on the specific criteria used to determine when training is complete. However, it can be inferred from general machine learning practices that common criteria include reaching a validation loss plateau or achieving a desired level of performance on a separate validation dataset. These criteria help ensure that the model has learned useful patterns without overfitting to the training data.

Based on the table provided, it appears that the algorithm-based image classification was evaluated using independent validation data labeled 'CK data'. This suggests that the model's performance was assessed on unseen data during training, which aligns with best practices for determining when training should be stopped. Without further details about the training process, it cannot be definitively stated what exact criteria were used to decide when training was complete.