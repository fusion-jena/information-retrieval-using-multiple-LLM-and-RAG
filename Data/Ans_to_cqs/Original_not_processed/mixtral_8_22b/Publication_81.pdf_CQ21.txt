Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Intrusion Detection Dataset. J. Comput. 2017, 143–155. [CrossRef]

41. Vincent, P.; Larochelle, H.; Lajoie, I.; Bengio, Y.; Manzagol, P.A. Stacked Denoising Autoencoders: Learning Useful Representations

in a Deep Network with a Local Denoising Criterion. J. Mach. Learn. Res. 2010, 11, 3371–3408.

42. Taaffe, K.; Pearce, B.; Ritchie, G. Using kernel density estimation to model surgical procedure duration. Int. Trans. Oper. Res. 2018,

28, 401–418. [CrossRef]

43. Liu, F.T.; Ting, K.M.; Zhou, Z.H. Isolation-Based Anomaly Detection. ACM Trans. Knowl. Discov. Data 2012, 6, 1–39. [CrossRef]
44. Gou, J.; Liu, G.; Zuo, Y.; Wu, J. An Anomaly Detection Framework Based on Autoencoder and Nearest Neighbor. In Proceedings
of the 2018 15th International Conference on Service Systems and Service Management (ICSSSM), Hangzhou, China, 21–22 July
2018; IEEE: Piscataway, NJ, USA, 2018; pp. 1–6. [CrossRef]

h = σe(Wx + b)

(3)

where x denotes the input data vector, W is the weight matrix connecting the input and
hidden layers, b is the bias vector belonging to the latent layer nodes, and σe represents the
activation function, such as Sigmoid, Relu, Tanh, etc.

(2) Decoder: in this step, the hidden representation h is mapped into reconstruction

vector y, the typical form as follows:

y = σd(W(cid:48)h + b(cid:48))

(4)

where W’ is the weight matrix connecting the latent and output layers, b’ is the bias vector,
and σd represents the activation function.

Loss function is deﬁned to measure the reliability of SAE. SAE is trained to reconstruct
the features of input and adjust the weights of the encoder and decoder to minimize
the error between the output and the input. Thus, loss function is introduced, which is
expressed in terms of mean square error as follows:

L(W, b) = ∑(cid:107)y − x(cid:107)2

(5)

Symmetry 2021, 13, 1599

6 of 16

36.

Random Forest supervised learning model. BMC Genet. 2019, 20, 2. [CrossRef] [PubMed]
Jin, S.; Zeng, X.; Xia, F.; Huang, W.; Liu, X. Application of deep learning methods in biological networks. Brief. Bioinform. 2021, 22,
1902–1917. [CrossRef]

37. Kumar, S.; Stecher, G.; Li, M.; Knyaz, C.; Tamura, K. MEGA X: Molecular Evolutionary Genetics Analysis across Computing

Platforms. Mol. Biol. Evol. 2018, 35, 1547–1549. [CrossRef]

38. Chu, Z.; Yu, J. An end-to-end model for rice yield prediction using deep learning fusion. Comput. Electron. Agric. 2020, 174,

105471. [CrossRef]

39. Chen, J.; Sathe, S.; Aggarwal, C.; Turaga, D. Outlier Detection with Autoencoder Ensembles. In Proceedings of the 2017 SIAM

International Conference on Data Mining (SDM), Houston, TX, USA, 27–29 April 2017; pp. 90–98. [CrossRef]

Symmetry 2021, 13, 1599

16 of 16

40. Homoliak, I. Convergence Optimization of Backpropagation Artiﬁcial Neural Network Used for Dichotomous Classiﬁcation of

2.3. Evaluation Method

To test the performance of proposed model, the sample is divided into four situations
based on the actual classiﬁcation and the ESK predicted classiﬁcation. In Table 2, four
situations are illustrated with a confusion matrix. True positive (TP) is the number of
ingroups that are correctly classiﬁed as ingroups. True negative (TN) is the number of
outgroups that are correctly classiﬁed as outgroups. False positive (FP) is the number of
outgroups that are wrongly classiﬁed as ingroups. False negative (FN) is the number of
ingroups that are wrongly classiﬁed as outgroups.

Table 2. Confusion matrix.

Predicted Positive

Predicted Negative

Actual positive
Actual negative

TP
FP

FN
TN

With confusion matrix, the classiﬁcation performance of all experiments is measured
by three criterions: accuracy, recall, and F1-Score. Those evaluation equations are formu-
lated as follows:

Accuracy =

TP + TN
TP + TN + FP + FN

Recall =

TP
TP + FN
2TP
2TP + FP + FN

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: After the model training process, there are several postprocessing steps that can be performed depending on the specific requirements of the task or application. Some common postprocessing steps include:

1. Model validation: This involves evaluating the performance of the trained model on unseen data to ensure its generalizability. Common metrics used for model validation include accuracy, precision, recall, F1 score, ROC curves, and area under the curve (AUC).
2. Hyperparameter tuning: This involves optimizing the hyperparameters of the model to improve its performance. Techniques such as grid search, random search, and Bayesian optimization can be used for hyperparameter tuning.
3. Feature importance analysis: This involves identifying the most important features that contribute to the predictions made by the model. Techniques such as permutation feature importance, SHAP values, and LIME can be used for feature importance analysis.
4. Visualizations: Visualizations such as saliency maps, heatmaps, and t-SNE plots can be used to gain insights into how the model makes its predictions and identify any potential biases or errors.
5. Confusion matrix: A confusion matrix is a table that summarizes the performance of a classification algorithm. It shows the number of true positives, false positives, true negatives, and false negatives, allowing for the calculation of various performance metrics such as accuracy, precision, recall, and F1 score.

Overall, these postprocessing steps help to evaluate the performance of the trained model, identify areas for improvement, and provide insights into how the model makes its predictions.