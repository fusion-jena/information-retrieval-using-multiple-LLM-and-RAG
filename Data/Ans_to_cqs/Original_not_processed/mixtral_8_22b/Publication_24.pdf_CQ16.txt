Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

chunks labelled as containing the sound that were retrieved by the 

biological ambient sounds, for example, wind and rain (see Supporting 

algorithm  (Supporting  Information  Figure S2).  The  threshold  was 

Information  Table S2  for  sound  categories  and  sample  sizes).  There 

swept between 0 and 1 and the resulting values of precision and 

were  not  enough  examples  to  create  a  classifier  for  these  separate 

recall were plotted as a precision- recall curve. Summary statistics 

categories  (“invertebrate”,  “rain”,  etc.)  with  current  ML  techniques. 

were  computed  for  the  average  precision  under  all  the  threshold 

However, advances in low- shot learning (e.g., Wang, Girshick, Hebert, 

values and the recall when the threshold chosen gave a precision of 

& Hariharan, 2018) may allow our annotations to be used to create 

0.95. The fraction of true positives, false positives, true negatives 

such a fine- grained classifier in the future.

dataset  was  randomly  selected  from  the  remaining  sites  so  that 

while the  remaining 0.86 s is spent running the networks.

FAIRBRASS et Al. 2041210x, 2019, 2, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13114 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseMethods in Ecology and Evolu(cid:13)on

    |  191

(a)

(b)

(c)

Supporting Information section at the end of the article.

How to cite this article: Fairbrass AJ, Firman M, Williams C, 

Brostow GJ, Titheridge H, Jones KE. CityNet—Deep learning 

tools for urban ecoacoustic assessment. Methods Ecol Evol. 

2019;10:186–197. https://doi.org/10.1111/2041-210X.13114

FAIRBRASS et Al. 2041210x, 2019, 2, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13114 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

such a fine- grained classifier in the future.

and false negatives were also computed, using the same threshold. 

2.3 | Acoustic testing dataset and evaluation

These analyses were conducted in python v.2.7.12 (Python Software  

Foundation,  2016)  using  scikit- learn  v.0.18.1  (Pedregosa  et al., 

2011) and matplotlib v.1.5.1 (Hunter, 2007). The experiments were 

To  evaluate  the  performance  of  the  CityNet  algorithms,  we  cre-

run on a machine running Ubuntu 16.04 with a 3.60 GHz Xeon pro-

ated  a  testing  dataset  (CitySounds2017test)  by  selecting  40  1- 
min  recordings  from  CitySounds2017  from  the  remaining  30% 

cessor, 64 GB of RAM and a 2 GB Nvdia GPU. With that processing 

speed, 60 s of audio can be classified with both CityAnthroNet and 

of  sites  (19  sites,  average  2 ± 1  recordings  per  site).  The  testing 

CityBioNet in 0.977s, with 0.14 s used for computing  spectrograms

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about the specific criteria used to determine when training is complete. However, it mentions that the analysis was conducted using Python and Scikit-learn, which are commonly used tools for machine learning tasks. In general, common criteria for determining when training is complete include reaching a minimum validation loss or accuracy, achieving a certain number of epochs, or observing no further improvement in model performance. Without more specific details, it is difficult to provide a definitive answer to this question based solely on the given context.