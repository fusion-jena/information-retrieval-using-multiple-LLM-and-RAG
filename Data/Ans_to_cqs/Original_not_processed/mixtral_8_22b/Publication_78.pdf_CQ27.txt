Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

SVM ClassifierLinear KernelBleached or unbleached coral12345678910abbbb12345678910Input ImageConvolutional Layer 1Convolutional Layer 2Convolutional Layer 3Convolutional Layer 4Convolutional Layer 5Fully Connected Layer 6 Fully Connected Layer 7ClassifierOutputDescriptionStride sizeab4 x 41 x 1227 x 227 x 355 x 55 x 9627 x 27 x 25613 x 13 x 38413 x 13 x 38413 x 13 x 25640964096Big Data Cogn. Comput. 2021, 5, 53

7 of 15

Algorithm 1: k-means Clustering Algorithm.

Input: Features as data points
Let features F = {F1, F2, F2, ..., Fn} is set of data points and C = {C1, C2, C3, ..., Co}
is set of centers.

Figure 3. The proposed framework steps visual representation.

3.1. Explanation of Steps

Initially, an image is taken with the help of an underwater drone. In the next step,
the image is segmentized and divided into small patches. Features are extracted from
each patch with the help of handcrafted descriptors and D-CNNs. A visual vocabulary

Big Data Cogn. Comput. 2021, 5, 53

5 of 15

(VV) is created, as shown in Figure 4, this visual vocabulary is the features extracted
from these features, and the training features are passed to classiﬁer i.e., SVM, which
classiﬁes whether the VV-features are of bleached coral or healthy coral. We used different
handcrafted features as well as different D-CNN’s but AlexNet shows the highest accuracy.
We used different classiﬁers i.e., SVM, kNN, and decision tree, but SVM outperforms all
other classiﬁers.

Figure 4. Visual Vocabulary of features.

3.2. Feature Extraction

3.2.3. Custom D-CNN: CoralNet

We create a custom D-CNN named as CoralNet for the extraction of the spatial features.
CoralNet has thirteen layers in which three layers are convolutional layers (Conv2D), two
max-pooling (MaxPooling2D) layers, two dense layers, one ﬂatten layer, three activation
layers. The input layer size is kept at 227 × 227 × 3. Two activation layers have rectiﬁed
linear unit (ReLU) as activation function while the last activation layer uses softmax as
activation function. Features are extracted with Conv2D layers and the feature vector is
extracted at the last layer. The training options used for training CoralNet are summarized
in Table 1. The simpliﬁed architecture of the CoralNet is shown in Figure 6.

Big Data Cogn. Comput. 2021, 5, 53

6 of 15

Figure 5. Feature Extraction with AlexNet.

Table 1. Training Parameters of CoralNet.

Parameter

Optimizer
Epochs
Batch Size
Loss Function

Value

Adam
10
64
Cross Entropy

3.2. Feature Extraction

Handcrafted and spatial features are concatenated to obtained visual vocabularies
(VV). The texture and color features are extracted with the help of handcrafted descriptors
while spatial features are extracted with the D-CNN models.

3.2.1. Spatial Features

Features are extracted with handcrafted descriptors as well as D-CNN models. Initially,
an image is captured with the help of underwater drones. Then the image is preprocessed
and resized to the input size of D-CNN.

3.2.2. Pretrained D-CNN

In the case of AlexNet, the input image size is 227 × 227 × 3. AlexNet is an ImageNet
with a total of twenty-ﬁve layers. There are ﬁve convolutional layers in AlexNet to extract
the spatial features. The other layers involved in AlexNet architecture are fully connected
layers, max-pooling layers, sigmoid layer, and ReLU layer. The feature vector is obtained at
fully connected layer 7 (FC-7) of the AlexNet. Figure 5 illustrates the convolutional layers
of AlexNet.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide information on how the trained deep learning model was deployed after being trained. Therefore, it is not possible to determine what specific process was followed to deploy the trained deep learning model, such as model serialization or platform selection.