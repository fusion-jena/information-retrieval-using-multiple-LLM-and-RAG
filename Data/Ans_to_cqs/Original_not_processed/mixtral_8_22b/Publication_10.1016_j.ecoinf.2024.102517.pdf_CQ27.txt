Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

set 

is 

to 
1. 

2.3.3. Experimental setting 

In our experiment, a deep learning environment based on Python and 
Tensorflow – GPU as well as CUDA was constructed under the Windows 
operating system. The deep feature loss bird noise reduction network 
model was trained for 50 epochs on an RTX 2080 Ti GPU using the Adam 
(cid:0) 4. In each 
optimizer (Kingma and Ba, 2014) with a learning rate of 10
epoch, the entire training set was presented in a random order, with one 
noisy bird sound signal per iteration. 

2.4. Comparative algorithms 

Using the same test  set, we compared the  denoising results of the 
deep feature loss-based bird sound noise reduction network with several 
other  bioacoustics  noise  reduction  algorithms,  namely  SEGAN, 
WebRTC, wavelet transform (Priyadarshani et al., 2016), Wiener filter 
(Loizou, 2017), and MMSE STSA (Brown et al., 2017) algorithms.

(2)  

∑

Λ15 =

Λ14

j × K14

j + b,

j

where b is a learned bias term. 

Fig. 4. Framework of the bird sound noise reduction network based on deep feature loss.  

EcologicalInformatics80(2024)1025174C. Zhang et al.                                                                                                                                                                                                                                   

2.3.2. Training of the bird sound noise reduction network based on deep 
feature loss

Let  Λ0, ……, Λ15  represent  the  16  connected  layers  of  the  noise 
reduction network, where Λ0  and Λ15  represent the input and output 
layers,  respectively.  For  k = 1, …, 14,  each  intermediate  layer  Λk ∈
{
was  obtained  from  the  previous  layer  Λk(cid:0) 1  with  the 
Λ1, …, Λ14

}

following operation: 

(

Λk

i = Ψ

Γk

(

∑

Λk(cid:0) 1
j

) )

*rk Kk
i,j

,

(1)  

j

j 

i  is the i-th feature map of layer Λk, Λk(cid:0) 1

where Λk
is the j-th feature map 
of  layer  Λk(cid:0) 1,Kk
i,j  is  a  3 × 1  dilated  convolution  kernel,  and  Γk  is  an 
adaptive normalization operator. The operator *rk  is a dilated convolu-
tion;  the  dilation  factor  for  the  k-th  layer  is  set  at  rk = 2k(cid:0) 1;  for 
k ∈ {1, …, 13}. We did not use dilation (i.e., r14 = 1) between layer Λ13 
and Λ14. For the output layer Λ15, a linear transformation was used to 
synthesize the output signal samples, 

(2)  

∑

Λ15 =

Λ14

j × K14

j + b,

j

reducing noise, and accordingly, would not be suitable for processing 
large  volumes  of  recorded  data  collected  in  the  field.  Furthermore, 
compared with the bird sound noise reduction network based on deep 
feature loss and the SEGAN algorithm, we found that the noise reduction 
efficiencies of the WebRTC and Wiener Filter algorithms were notably 
higher. This disparity in performance can be attributed to the fact that 
the deep learning model is larger in size and is thus more demanding of 
computational resources. However, it should be noted that the execution 
time of the deep learning models on CPUs is acceptable.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about how the trained deep learning model was deployed after the training phase. Therefore, I cannot provide specific details regarding the deployment process such as model serialization or platform selection. However, it is mentioned that the experimental setup included a deep learning environment based on Python and TensorFlow - GPU as well as CUDA under the Windows operating system. It can be assumed that the trained model might have been utilized within this environment for further testing and evaluation purposes.