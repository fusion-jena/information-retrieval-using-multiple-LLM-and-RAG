Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model hyperparameters were tuned for each species-specific model 
using Bayesian optimization focused on reducing the root mean squared 
error (RMSE) of the predictions based on environmental cross-validation 
(Roberts et al., 2017) with ten folds, as implemented in the R package 
“mlr3mbo” (Kotlarski et al., 2014). The search space of optimal hyper-
parameters was defined by the ranges of “mtry”  (number of variables 
randomly sampled as candidates at each split), “min.node.size”  (mini-
mum size of terminal nodes), and “num.trees” (number of trees to grow) 
shown  in  Table  S3  (the  abbreviations  of  the  hyperparameters  used 
correspond to the terminology used in the R package “ranger”).

analytical  methods and  modeling tools  are needed to  deal with  these 
challenges (Tan et al., 2006). Over the past years, the field of artificial 
intelligence and machine learning has enabled significant advances in

the  field  of  ecological  informatics  (Borowiec  et  al.,  2022;  Tuia  et  al., 
2022; Christin et al., 2019; W¨aldchen and M¨ader, 2018) and promises to 
continue  to  make  further  progress  (Morera,  2024).  These  techniques 
have  allowed  to  improve  the  accuracy  of  results  compared  to  more 
traditional modeling techniques due to the possibility to approximate 
non-linear  relationships  and  to  consider  a  large  number of  predictors 
(Meyer  et  al.,  2019).  Machine  learning  in  ecology  has  been  used  for 
instance to study species distribution (Liang et al., 2022; Bellin et al., 
2022), species identification through imagery (Gao et al., 2024), char-
acterization of land use change (Gelabert et al., 2021), identification of 
conservable or restorable areas (Cheng et al., 2018), biodiversity con-
servation and estimation (Tuia et al., 2022; Chang, 2023), and invasive 
species risk assessment (Jensen et al., 2020).

synthesis and use of conservation and environmental evidence. Conserv. Biol. 32 (4), 
762–764. https://doi.org/10.1111/cobi.13117. 

Christin, S., Hervet, ´E., Lecomte, N., 2019. Applications for deep learning in ecology. 
Methods in Ecol. Evol. 10 (10), 1632–1644. https://doi.org/10.1111/2041- 
210X.13256. 

Clark, J.S., Bell, D.M., Hersh, M.H., Kwit, M.C., Moran, E., Salk, C., Stine, A., Valle, D., 
Zhu, K., 2011. Individual-scale variation, species-scale differences: inference needed 
to understand diversity. Ecol. Lett. 14 (12), 1273–1287. https://doi.org/10.1111/ 
j.1461-0248.2011.01685.x. 

Coelho, M.T.P., Diniz-Filho, J.A., Rangel, T.F., 2019. A parsimonious view of the 

parsimony principle in ecology and evolution. Ecography 42 (5), 968–976. https:// 
doi.org/10.1111/ecog.04228.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide explicit information about the specific criteria used to split the data for deep learning model training into sets such as train, test, and validation. However, it mentions that the models were evaluated using environmental cross-validation with ten folds, which is a common method for splitting datasets. In this case, the dataset would be divided into ten equal parts, where nine parts are used for training and one part is used for testing. This process is repeated ten times so that each unique part serves as the test set once. This approach helps ensure that the model generalizes well to unseen data and reduces overfitting. Additionally, the context discusses the use of Bayesian optimization to tune model hyperparameters, focusing on minimizing the root mean squared error (RMSE) of the predictions.