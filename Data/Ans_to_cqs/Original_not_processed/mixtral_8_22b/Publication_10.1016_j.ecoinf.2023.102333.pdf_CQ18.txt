Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

adjustable parameters that control network architecture, optimization 
procedure,  and  regularization.  Common  hyperparameters  include 
number of layers and nodes, learning rate, dropout rate, etc. However, 
optimizing  model hyperparameters  remains imperative  for leveraging

The  points  were  randomized  and  divided  into  training  (80%)  and 
validation  (20%)  sets.  A  15  m  buffer  was  applied  around  all  sample 
points  to  ensure  independence  between  the  datasets  (Fig.  4).  The 
reference points were then exported to the cloud for model training and 
validation. 

2.4. Indexes calculation

8 

6 

118 

20 

0 
Exponential 
Linear Unit 

0.05 
Exponential 
Linear Unit 

0.15 
Rectified Linear 
Unit  

or Bayesian optimization approaches and should, therefore, be used if 
sufficient computation resources are available. 

Learning  and  loss  curves  were  also  used  to  diagnose  the  learning 
performance of the three models over time (Fig. 7). The training accu-
racy curve provides insight into how the model is learning, while the 
validation accuracy gives insight into the generalizing process. Likewise, 
the training loss curve shows the model’s performance on the training 
data when the optimization algorithm adjusts the model parameters to 
minimize  the  loss  function.  The  validation  loss  curve  measures  the 
model’s performance on new unseen data.

The  Hyperband  method  plots  showed  a  non-smooth  pattern  with 
irregular  values.  This  “unstable”  learning  reveals  that  the  model  had 
difficulty learning the data patterns. In the loss plot, the training loss 
curve  and validation  loss curve  crossed, which  means that the  model 
performed  differently  on  the  training  dataset  than  on  the  validation 
dataset. By excluding a regulation technique, this model overfitted by 
showing good performance in the training dataset but failing to gener-
alize onto the validation dataset. Overfitting occurs when the model is 
too complex and captures noise in the training data instead of the un-
derlying patterns. Even though the Hyperband and Bayesian optimiza-
tion methods showed similar learning behaviors, they did not perform 
similarly. The training and validation accuracy curves are closer to the 
Hyperband  than  the  Bayesian  optimization  method.  The  two  curves

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The strategy implemented to monitor the model performance during training involves using learning and loss curves. These curves provide insights into how the model is learning from the training data and its ability to generalize to new, unseen data. Specifically, the training accuracy curve indicates the model's performance on the training data, while the validation accuracy curve reflects the model's ability to generalize to new data. Similarly, the training loss curve displays the model's performance on the training data as it minimizes the loss function, whereas the validation loss curve evaluates the model's performance on new, unseen data. Additionally, visual representations such as Fig. 7 are employed to illustrate these learning and loss curves, enabling a more comprehensive understanding of the model's performance during training.