Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)10261113ValidationsetTestsetPerformancemeasurein%InferencesetsF1scoreRecallPrecisionAccuracyB.R. Pushpa et al.                                                                                                                                                                                                                               

Table 6 
Performance evaluation of baseline hierarchical classification model on test set INT-TS-GSL100.  

Groups 

Validation Set 

Accuracy 

Precision 

Recall 

F1-Score 

G1 
G2 
G3 
G4 
G5 

80.66 
85.12 
82.42 
78.21 
83.09 

0.92 
0.91 
0.79 
0.8 
0.55 

0.8 
0.83 
0.86 
0.91 
0.91 

0.85 
0.87 
0.83 
0.85 
0.68 

Test Set 

Accuracy 

76.28 
82.28 
86.29 
78.74 
85.81 

Precision 

Recall 

F1-Score 

0.91 
0.86 
0.8 
0.84 
0.7 

0.83 
0.87 
0.88 
0.88 
0.92 

0.87 
0.86 
0.84 
0.86 
0.8

validation sets (VS). The inference from Table 4 indicates the less false 
positive  rate  by  achieving  the  highest  precision,  recall,  and  F1-score 
towards each group using a fusion of convolution features. Seven out 
of 11 groups always exhibit precision of more than 90% and recall of 
more than 90% for six groups, whereas in the case of test sets, the pre-
cision and recall rate of more than 90% for eight groups, and the same is 
accurate concerning the F1-score metric.

Fig. 6. Performance of baseline hierarchical classification model; (a) Accuracy of validation and test set for class labels C1 to C50 without convolution features (b) 
Accuracy of validation and test set for class labels C51 to C100 without convolution features (c) Accuracy of validation and test set for class labels C1 to C50 with 
convolution features (d) Accuracy of validation and test set for class labels C51 to C100 with convolution features (e) Measure of precision, recall and F1 score with 
and without the fusion of convolution features. 

EcologicalInformatics81(2024)1026119(a)   (b)(c)   (d)(e)85.2386.0884.5984.8884.5884.9794.3994.2494.2193.8294.293.83MEASUREOBTAINEDIN%PERFORMANCEMETRICSWithConvolutionfeaturesWithoutConvolutionfeaturesB.R. Pushpa et al.

5.6. Comparative analysis 

The performance of the proposed hierarchical classification model is 
compared  with  results  that  are  analyzed  separately  using  geometric, 
multispectral, texture, shape, and convolution features. Table 5 presents 
the  individual  feature-wise  performance  using  precision,  recall,  F1- 
Score, and accuracy towards validation and test sets. It shows that the 
proposed  baseline  hierarchical  classification  model  with  a  fusion  of 
convolution features with other machine learning features produces an 
accuracy  of  94.54%  towards  test  sets  and  93.96%  towards  validation 
sets. The texture features are the poorly performing feature represen-
tations, having validation accuracy of 19.14% and 20.52% for test sets. 
At the same time, all other features exhibit an accuracy in the range of 
35% to 50% towards validation and test sets. Out of all the features used 

Fig. 9. Performance of proposed model with RTL80 and RTP40 datasets.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model is evaluated using several metrics such as accuracy, precision, recall, and F1-score. In this study, the authors use these four metrics to assess the performance of their proposed hierarchical classification model. They report the values of these metrics for both the validation and test sets. For example, they present the accuracy, precision, recall, and F1-score for five different groups (G1 to G5) in Table 6. Additionally, they compare the performance of their proposed model with other models based on these metrics. From Fig. 6, it can be seen that the proposed model achieves high accuracy, precision, recall, and F1-score when compared to other models. Furthermore, the authors also provide a comparative analysis of the performance of their proposed model with respect to individual features such as geometric, multispectral, texture, shape, and convolution features. This analysis reveals that the proposed model with a fusion of convolution features with other machine learning features performs better than any single feature representation.