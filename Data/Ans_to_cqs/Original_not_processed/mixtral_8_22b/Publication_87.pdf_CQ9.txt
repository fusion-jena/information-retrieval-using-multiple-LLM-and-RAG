Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2

Here, we showcase a full why-what-how workflow in R using a case study on the structure of an
ecological community (a set of co-occurring species) composed of the Eurasian lynx (Lynx lynx)
and its two main preys. First, we introduce the case study and motivate the need for deep learning.
Second we illustrate deep learning for the identification of animal species in large amounts of images,
including model training and validation with a dataset of labelled images, and prediction with a
new dataset of unlabelled images. Last, we proceed with the quantification of spatial co-occurrence
using statistical models.

2 Collecting images with camera traps

With the rapid advances in technologies for biodiversity monitoring (Lahoz-Monfort and Magrath
2021), the possibility of analysing large amounts of images makes deep learning appealing to
ecologists. We hope that our proposal of a reproducible R workflow for deep learning and statistical
ecology will encourage further studies in the integration of these disciplines, and contribute to the
adoption of computer vision by ecologists.

6 Appendix: Reproducible example of species identification on

camera trap images with CPU

In this section, we go through a reproducible example of the entire deep learning workflow, including
data preparation, model training, and automatic labeling of new images. We used a subsample of
467 images from the original dataset in the Jura county to allow the training of our model with CPU
on a personal computer. We also used 14 images from the original dataset in the Ain county to
illustrate prediction.

13

Table 4: ?(caption)

Then we get the model architecture. For the sake of illustration, we use a resnet18 here, but we used
a resnet50 to get the full results presented in the main text.

learn <- cnn_learner(dls = dls,

arch = resnet18(),
metrics = list(accuracy, error_rate))

Now we are ready to train our model. Again, for the sake of illustration, we use only 2 epochs here,
but used 20 epochs to get the full results presented in the main text. With all pictures and a resnet50,
it took 75 minutes per epoch approximatively on a Mac with a 2.4Ghz processor and 64Go memory,
and less than half an hour on a machine with GPU. On this reduced dataset, it took a bit more than
a minute per epoch on the same Mac. Note that we save the model after each epoch for later use.

one_cycle <- learn %>%

fit_one_cycle(2, cbs = SaveModelCallback(every_epoch = TRUE,

fname = 'model'))

0.00%

train_loss

epoch
------ -----------
Epoch
1/2
|
Epoch
|
Epoch
|
Epoch
|

valid_loss
-----------
:
[0/36
:
[1/36
:
[2/36
:
[3/36

Paszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, et al. 2019. “PyTorch: An Imperative Style, High-Performance Deep Learning Li-
brary.” In Advances in Neural Information Processing Systems 32, edited by H. Wallach, H.
Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett, 8024–35. Curran Associates,
Inc. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-
learning-library.pdf.

Rota, Christopher T., Marco A. R. Ferreira, Roland W. Kays, Tavis D. Forrester, Elizabeth L. Kalies,

27

William J. McShea, Arielle W. Parsons, and Joshua J. Millspaugh. 2016. “A Multispecies Occu-
pancy Model for Two or More Interacting Species.” Methods in Ecology and Evolution 7 (10):
1164–73. https://doi.org/https://doi.org/10.1111/2041-210X.12587.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The document does not provide information about where the data repository of the deep learning pipeline is available. It discusses the process of collecting images with camera traps, preparing data, training models, and predicting new images using a subset of the original dataset. However, there is no mention of where the complete dataset or any part of it has been made publicly available. Therefore, I do not have enough information to determine where the data repository of the deep learning pipeline is available.