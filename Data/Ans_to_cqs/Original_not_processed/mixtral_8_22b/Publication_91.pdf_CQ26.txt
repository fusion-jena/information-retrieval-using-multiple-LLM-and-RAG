Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Deep learning

Dataset Our dataset consisted of 35 573 images for each of the
12 channels covering 35 species and resulting in a total of 426
876 images. This dataset was split into three sets for training, val-
idation, and testing in the proportions 80 : 10 : 10. All images
were centre cropped to an equally sized rectangle. In order to gain
a more robust and better generalising classiﬁer, the images in the

New Phytologist (2021) 229: 593–606
www.newphytologist.com

training set were additionally augmented in the following ways:
ﬂipped horizontal, ﬂipped vertically,
adjusted in bright-
ness (cid:3) 12.5%, adjusted in saturation (cid:3) 50.0%, adjusted by
contrast (cid:3) 12.5%, and adjusted in hue (cid:3) 20%.

Key words: convolutional neural networks,
deep learning, multispectral imaging ﬂow
cytometry, pollen, pollinator, species
identiﬁcation.

with a batch size of 32. The initial learning rate of 0.001 was
exponentially decayed every 3 epochs with a factor of 0.94.

database for training of deep learning models. Comparable stud-
ies used 1060 (Daood et al., 2016), 13 617 images (Pedersen
et al., 2017) or 19 500 images (Sevillano et al., 2020), while in
our study the CNN classiﬁer was trained with 426 876 images.

We have previously suggested that a minimum of 200 images
per species are required for accurate species identiﬁcation of phy-
toplankton (Dunker et al., 2018). By contrast, in the present
study on pollen, ﬁve out of six species with fewer than 200 pollen
grains were classiﬁed with an accuracy higher than 90%. Based
on these ﬁndings, we concluded that between 50 and 100 pollen
grains represented a reasonable amount of pollen images on a sin-
gle channel to be included in the reference library.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions some strategies employed to improve the model's performance and generalization.

To create a more robust and better-generalizing classifier, the authors applied image augmentations such as flipping horizontally and vertically, adjusting brightness, saturation, contrast, and hue. These techniques help increase the diversity of the training dataset and reduce overfitting.

Additionally, the dataset was divided into three subsets for training, validation, and testing in the proportion of 80:10:10. Although this is not explicitly stated as stratified sampling, maintaining the same distribution of classes across all subsets can help prevent biases caused by imbalanced datasets.

Furthermore, the authors mention that they had a large number of images compared to other studies, which could contribute to reducing potential biases due to limited data availability. They also suggest that having a minimum of 200 images per species might be necessary for accurate identification but found that even with fewer than 200 pollen grains, five out of six species achieved high classification accuracy.

In conclusion, based on the given context, the authors addressed data bias through various methods like image augmentation, dividing the dataset into different subsets, using a larger dataset, and suggesting a minimum number of images per species. However, there is no direct mention of techniques such as stratified splitting, oversampling, undersampling, or diverse data collection.