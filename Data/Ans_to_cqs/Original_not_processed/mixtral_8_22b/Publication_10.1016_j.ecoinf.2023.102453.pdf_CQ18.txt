Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.5. Hyperparameter optimization 

The model training process determines the values for the trainable 
parameters  of  a  model,  e.g.,  Table  4 shows  the  size  of  the  model pa-
rameters. In addition, a DNN model also has other parameters that need 
to be selected, e.g., batch size, that determines the model performance. 
The  model  parameters  define  the  model  and  are  termed  as  hyper-
parameters. Each hyperparameter has a range of values, from which an 
optimum  selection  can  improve  the  model  performance.  The  model 
hyperparameters could be in hundreds, presenting a very large search 
space, but these differ in their relative importance. The common ones for 
a DNN are learning rate, batch size, and dropout.

Hyperparameter  optimization  was  illustrated  with  only  a  single 
dataset  and  one  hyperparameter.  Such  limited  explorations  could  be 
useful unless the aim is to optimize a single model by considering all the 
important model hyperparameters (Kuncheva et al., 2023). The hyper-
parameter  tuning  was  shown  to  improve  the  model  performance 
(Fig. 13) for the selected models. Only a single hyperparameter, that is, 
the learning rate was optimized with hyperband and Bayesian Optimi-
zation techniques. In actual practice, more hyperparameters would need 
to  be  considered  to  design  an  optimized  model.  Another  factor  to 
consider  is  that  different  models  have  different  number  and  types  of 
hyperparameters,  and  trying  to  fully  optimize  each  will  require 
considerable compute resources and time as the hyperparameter search 
space would be large.

EcologicalInformatics79(2024)10245314S. Nazir and M. Kaleem                                                                                                                                                                                                                       

Fig. 13. Model Performance with three learning rates of 0.0001, 0.00001, and 0.000001 for the selected models with fine-tuning (all layers trained).  

requiring classification in the field can use small sized models with the 
low power devices. Although transfer learning with fine tuning is used in 
some studies but this paper has investigated and provided a comparison 
that can be useful in making a model selection and its fine tuning. The 
model  performance  can  also  be  further  improved  through  the  use  of 
hyperparameter optimization. 

5.1.2. Model generalization

4.4. Hyperparameter optimization 

The hyperparameter optimization results for the learning rate for the 
EfficientNetV2B0  and  MobileNetV2  model  were  obtained  using  the 
Hyperband and Bayesian Optimization for the Extinction dataset. The 
optimum values determined using the Keras Tuner for the learning rate 
were 0.00001 for both the models. The F1-Scores were then obtained for 
the  optimal  learning  rate  (0.00001),  a  higher  value  (0.0001),  and  a 
lower value (0.000001) and are shown in Fig. 13. It can be seen that the 

optimal learning rate found through the hyperparameter optimization 
provides better model classification performance for the selected models 
and the dataset. 

4.5. Visualising predictions

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: Based on the given context, there isn't any explicit information about the strategy implemented to monitor the model performance during training. However, it does mention that the model training process determines the values for the trainable parameters of a model, such as the size of the model parameters. Additionally, it discusses the concept of hyperparameter optimization, where certain non-trainable parameters like learning rate, batch size, and dropout are adjusted to improve model performance. This suggests that monitoring the model performance during training might involve tracking metrics related to these hyperparameters or observing changes in the trainable parameters over time. But without specific details, it's not possible to provide a definitive answer.