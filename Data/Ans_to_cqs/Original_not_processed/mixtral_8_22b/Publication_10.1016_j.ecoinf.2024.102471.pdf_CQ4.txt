Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

It is the transformer encoder that takes latent feature vectors from 
the  feature  encoder  as  an  input  and  processes  it  through  transformer 
blocks, 12 and 24 blocks for the base and large versions of the trans-
former, respectively. Since the input dimension is 768 and 1024 for the 
base  and  the  large  transformers, the  feature  vectors pass  through  the 
linear  projection  layer  to  increase  their  dimension  from  512  to  the 
required dimension based on the transformer used. One important idea 
of  a  transformer  is  positional  embedding  which  tries  to  preserve  the 
sequential  information  of  the  input  feature  vectors.  Instead  of  using 
fixed  pre-generated  positional  embedding's  as  used  by  basic  trans-
formers, the Wav2vec model uses a grouped convolution layer to learn 
the relative positional embedding's. The output of the context network is 
the contextualized representation of the feature vectors C. The context

The  motivation  comes  from  success  of  transformer  in  natural  lan-
guage processing (NLP) is the reason for evolution of advanced archi-
tecture called vision transformer. In (Dosovitskiy et al., 2021) proposed 
work, the attention mechanism is focused as network's core component 
for capturing long-range relationship among complex structure of image 
data.  The  vision  transformer  processes  each  input  image  as  patches 
where they are treated as tokens by NLP model. Then the model pro-
cessed the tokens to learn more about the visual representation of the 
input. Hence, in comparison to CNN techniques, transformer-based re-
sults  demonstrated  state-of-the-art  performance  by  processing  more 
deep features in limited computational resources. Subsequently, vision 
transformer is applied along with hyper-head attention mechanism for 
bird  sound  recognition  (Tang  et  al.,  2023).  In  this  work,  author  has

4.3. Baseline models 

Hybrid  CNN-LSTM  is  an  architecture  that  combines  the  temporal 
modelling ability of the LSTM with the CNN ability to learn invariant 
features  (Ayadi  and  Lachiri,  2022)  (Yadav  and  Vishwakarma,  2020) 
(Ashraf  et  al.,  2023).  The  combination  of  Convolutional  Neural  Net-
works  (CNN)  and  Long  Short-Term  Memory  (LSTM)  has  the  major 
benefit of learning spatial and temporal data. CNN excels in extracting 
spatial elements like edges, textures, and forms from an input. Mean-
while,  an  LSTM  excels  in  extracting  temporal  data,  like  the  order  of 
words in a phrase or frames in a movie. By combining the two, a model 

EcologicalInformatics80(2024)1024719B. Swaminathan et al.

3.1. Feature encoder 

The feature encoder of the pre-trained Wav2vec model reduces the 
dimensionality of the audio data, converting the raw waveform into a 
sequence of feature vectors Z every 20 milliseconds. The main compo-
nent of the feature encoder's architecture is seven layers of a 1D con-
volutional neural network with 512 channels at each layer. The size of 
the kernel and strides decreases as the layer progresses in the network. 
The waveform is normalized before passing through the convolutional 
layer, followed  by  layer  normalization and  GELU  activation function. 
Finally,  latent  feature  vectors  represent  the  latent  feature  of  bird 
vocalization.  Thus,  it  helps  the  model  to  identify  and  understand  the 
sequential information in the vocalization audio of multi-bird species. 

3.2. Context network

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't any specific mention of data augmentation techniques applied in the given context. Therefore, I cannot provide a helpful answer regarding the data augmentation techniques used in the deep learning pipeline mentioned here. However, some common data augmentation techniques used in deep learning pipelines include flipping, rotation, scaling, cropping, zooming, and adding noise. These techniques help improve the generalizability and robustness of the trained models by artificially increasing the amount of training data available.