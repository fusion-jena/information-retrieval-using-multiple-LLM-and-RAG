Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The training dataset, including 268 sample plots with 39 features in a 
tabulated format, was used as input during the training process (opti-
mizing  hyper-parameters  and  fitting  models  with  these  data).  The 
training data set was divided into two parts, in which 80% was used for 
training/validation, and the remaining 20% was kept as unseen data for 
testing. To eliminate bias, 10-fold cross-validation was used during the 
training  process,  and  mean  RMSE  was  used  as  the  objective  function 
(lost function). Table 4 shows RMSE, MAE, and R2  using different op-
timizers. In addition, we tested the differences between the RMSEs in 
Table 4 using the Wilcoxon Signed-Rank test with paired samples. The 
differences between (XGBoost-BO vs. XGBoost-TDO, XGBoost-BOHB vs. 
XGBoost-TDO) or (LightGBM-BO vs. LightGBM-TDO, LightGBM-BOHB 
vs.  LightGBM-TDO)  are  significant.  However,  the  performance  of 
XGBoost-TDO  versus  LightGBM-TDO  appears  to  be  the  same (Fig.  3),

MSAVI =

GREEN (cid:0) BLUE 
2NIR + 1 (cid:0)

√

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
(2NIR + 1)2 (cid:0) 8(NIR (cid:0) RED)

predictive efficiency, handle large datasets, and reduce training time. It 
is typically recommended for tabular datasets. LightGBM differs from 
other tree-based methods by implementing leaf-wise splits that create 
more  complex  trees,  which  are  more  efficient  in  reducing  loss  and 
resulting  in  higher  accuracy.  The  split  is  based  on  a  novel  sampling 
method named Gradient-Based One-Side Sampling (Ke et al., 2017), in 
which data with small gradients are excluded, and the rest are used for

2.3. Gradient boosters 

LightGBM,  proposed  by  Microsoft,  is  a  newly  developed  gradient 
boost  or  tree-based  learning  algorithm.  It  was  designed  to  improve 

EcologicalInformatics79(2024)1024213Q.-T. Bui et al.                                                                                                                                                                                                                                  

Table 2 
Features for AGB estimation, including original data and image indices from Sentinel 1A and Landsat 8.  

Independent variables 

Name / calculation formula 

Reference 

LANDSAT 8 

SENTINEL-1A 

Band 2 
Band 3 
Band 4 
Band 8 
Vertical Transmit-Horizontal Receive Polarizations (dB) 
(VH.) 
Vertical Transmit-Vertical Receive Polarizations (dB) 
(VV.) 
Polarisation addition (dB) (ADDITIONvhvv) 
Polarisation multiply (dB)(MULTvhvv) 

ARVI (Atmospherically Resistant Vegetation Index)

2. Data and methods 

The overall workflow of the proposed method is shown in (Fig. 1). 
For  simplicity,  the  workflow  starts  with  collecting  sample  plots  and 
image processing to generate a tabulated dataset, including on-field AGB 
and  independent  features.  This  data  set  is  fed  into  hybrid  models,  in 

which  Bayesian  optimizers  and  TDO  tune  the  hyperparameters  of 
XGBoost and LightGBM using RMSE as the objective function. The best 
model  (with  the  smallest  RMSE)  is  selected  to  estimate  AGB  for  the 
entire study area. This model was also interpreted to understand better 
what operates inside the ‘black box.’ More detailed descriptions of the 
study area,  data specifications and preparation, and  algorithm justifi-
cations are presented in the following sections. 

2.1. Field data

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The datasets used in this deep learning pipeline are not explicitly mentioned as being well-known datasets such as MNIST, CIFAR, or ImageNet. Instead, the datasets used are described as consisting of 268 sample plots with 39 features in a tabulated format. These features include bands from both Landsat 8 and Sentinel-1A satellite imagery, as well as various vegetation indices calculated from those bands. The goal of the deep learning pipeline is to use these datasets to train and validate models for estimating aboveground biomass (AGB) in a forested region.

Answer:::

Unhelpful Answer:

The datasets used in this deep learning pipeline are not specified as any of the commonly known datasets like MNIST, CIFAR, or ImageNet. Instead, they consist of 268 sample plots with 39 features in a tabulated format. These features include bands from both Landsat 8 and Sentinel-1A satellite imagery, along with several vegetation indices derived from those bands. The aim of the deep learning pipeline is to utilize these datasets to develop and evaluate models for predicting aboveground biomass (AGB) within a forested area.

Answer:::