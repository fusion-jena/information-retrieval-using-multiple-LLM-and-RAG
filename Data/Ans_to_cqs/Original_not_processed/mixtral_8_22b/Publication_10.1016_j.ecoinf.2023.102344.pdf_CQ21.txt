Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

means the images where the extracted numerical features were used in 
Approach 1 during training were the exact images used in training in

the  shortcut  connections  within  the  network  that  makes  the  training 
faster; bottleneck architecture which consists of a 1 × 1 convolutional 
layer  for  dimension  reduction,  3  × 3  convolution  layer  for  feature 
extraction, and another 1 × 1 convolutional layer for dimension resto-
ration;  shortcut  connections  which  allows  gradients  to  flow  directly 
through  the  network  due  to  the  input  added  directly  to  the  output; 
global  average  pooling  (GAP)  which  computes  spatial  average  of  the 
feature  maps  at  the  end  section  of  the  convolutional  layer;  and  skip 
connections which bypass multiple residual blocks. On the other hand, 
InceptionV3 is a 48-layer 24 CNN containing 24 × 106 parameters with 
enhancement using label smoothing and factorized convolutional layers 
in order to easily propagate the information from the input to the output 
section. For all image-based pre-trained networks, the purpose of CNN

EcologicalInformatics78(2023)1023448R. Concepcion II et al.                                                                                                                                                                                                                         

Fig. 8. Confusion matrices of optimized pre-trained network with numerical inputs through (a) EfficientNet-B0, (b) ResNet101, (c) MobileNetV2, and (d) Incep-
tionV3 for bivalve traceability (Approach 1). 

(cid:0) 4, 
The training configuration was set to an initial learn rate of 1 × 10
every-epoch shuffle technique, and the shortest sequence length. All pre- 
trained  models  under  Approach  3  converged  the  training  after  1000 
epochs with SGDM as the optimization algorithm. 

2.7. Model evaluation metrics and statistics

Table 1 
Metric evaluations of the developed traceability models using Approaches 1 to 3.  

Approach 

Feature 
Selection 

Model 

Training 

Testing 

Default 
Model 

Optimized Model 

1 

2 

PCA-NCA 

– 

3 

PCA-NCA 

EfficientNet-B0 
ResNet101 
MobileNetV2 
InceptionV3 
EfficientNet-B0 
ResNet101 
MobileNetV2 
InceptionV3 
LSTM-GRU- 
BiLSTM 
LSTM-BiLSTM- 
GRU 
GRU-LSTM- 
BiLSTM 
(BivalveNet) 
GRU-BiLSTM- 
LSTM 
BiLSTM-LSTM- 
GRU 
BiLSTM-GRU- 
LSTM 

Accuracy 

Accuracy 

Fall-out 

Precision 

Specificity 

Recall 

86.16% 
92.50% 
94.91% 
98.27% 
94.23% 
86.66% 
91.80% 
95.54% 

78.33% 
91.58% 
91.26% 
89.33% 
88.89% 
81.76% 
86.61% 
90.13% 

89.61% 
6.21% 
11.54% 
10.00% 
10.33% 
13.33% 
19.44% 
12.55% 

12.63% 
93.79% 
88.46% 
90.00% 
89.67% 
86.67% 
80.56% 
87.45% 

87.37% 
93.79% 
88.46% 
90.00% 
89.67% 
86.67% 
80.56% 
87.45% 

87.37% 
90.91% 
95.78% 
93.33% 
89.39% 
83.50% 
98.00% 
94.98% 

F1- 
score 

93.33% 
91.58% 
91.26% 
89.33% 
88.89% 
81.76% 
86.61% 
90.13%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: After the model training process, several postprocessing steps can be performed depending on the specific requirements or goals of the analysis. Some common postprocessing steps include:

1. Evaluation Metrics Calculation: This involves calculating various performance metrics such as accuracy, precision, recall, F1 score, etc., to evaluate the effectiveness of the trained model. These metrics help assess how well the model has learned to classify or predict the target variable based on the given input data.

2. Confusion Matrix Generation: A confusion matrix is a table layout that enables visualization of the performance of an algorithm. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class. The values in the cells show the number of correct and incorrect predictions made by the model.

3. Saliency Maps: Saliency maps are visualizations that highlight the regions of an input image that contribute most significantly to the final prediction made by the model. They provide insights into what parts of the input data the model focuses on when making its decisions.

4. Hyperparameter Tuning: Postprocessing may also involve fine-tuning the hyperparameters of the model to improve its performance further. This could include adjusting learning rates, regularization coefficients, batch sizes, etc.

5. Model Interpretation: Another important aspect of postprocessing is interpreting the results obtained from the model. This might involve analyzing the weights assigned to different features, examining decision boundaries, or understanding the relationships between variables.

In summary, some common postprocessing steps after model training include calculating evaluation metrics, generating confusion matrices, creating saliency maps, tuning hyperparameters, and interpreting the results.