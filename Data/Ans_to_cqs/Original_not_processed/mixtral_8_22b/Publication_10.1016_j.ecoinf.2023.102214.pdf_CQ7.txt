Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Models were trained and tested by tuning the number of required 
epochs and then inspecting the model outputs and error outcomes for 
signs of overfitting. If the model focuses excessively on data fitting, it 
may imitate insignificant noise rather than the broad properties of in-
terest, resulting in overfitting.

2.8.2.

Image classification 

To assess the efficacy of the various techniques, we compute the top- 
k accuracy on a test set, where k = 1, 5, and 10 represents the position of 
the correct match (i.e., an annotation of the same individual represented 
by a query annotation) within a list of proposed matches. Consequently, 
a top-1 rank is an accurate result supplied by the algorithm as the most 
probable match for a candidate annotation. A top-5 rating indicates that 
the correct answer might be any of the top-5 values among the returned 
options, and so on. 

EcologicalInformatics77(2023)1022145E. Bohnett et al.                                                                                                                                                                                                                                 

3. Results 

3.1. Detection algorithm

Declaration of Competing Interest 

The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper. 

Data availability 

Research-related  requests  for  annotations  and  data  used  for  ML 
training in this paper can be requested in COCO format (Lin et al., 2020) 
via the corresponding author and must be expressly and independently 
permitted by author Eve Bohnett or through an established collabora-
tion on Whiskerbook.org. Data can also be reviewed and shared via a 
collaboration request to user Eve Bohnett inside the Whiskerbook.org 
system. 

Acknowledgements

cation  studies,  a  lack  of  data  is  the  greatest  challenge  and  limitation 
researchers encounter (Schneider et al., 2019). With the data collection 
compiled  in  this  work,  we  contribute  the  largest  fully  labeled  snow 
leopard dataset for deep learning research. In addition, we anticipate 
that our novel deep learning methods will encourage other academics to 
contribute  more  datasets  to  Whiskerbook.org  for  the  purpose  of 
continuously curating and enhancing the data used to improve the deep 
learning pipeline. Comparing these results to those of an earlier study by 
Johansson et al. (2020) that depended on human manual classification, 
without  AI  or  software,  determined  that  observers  significantly  over-
estimate  the  true  abundance.  AI-based  individual  ID  within  Whiske 
rbook.org  has  demonstrated  the  potential  to  enhance  the  precision 
and  efficiency  of  manual  observers,  approaching  more  accurate  esti-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about how the data was split for deep learning model training (e.g., train, test, validation). However, it mentions that models were trained and tested by tuning the number of epochs and checking for signs of overfitting. This suggests that some form of cross-validation or holdout method may have been employed during the training process. Unfortunately, without further details, I cannot provide a definitive answer regarding the specific criteria used to split the data.