Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We  train  our  model  using  Caffe  [35]  framework.  For  the  pa- 
rameter  setting  in  training,  we  employ  step  learning  policy.  The 
learning rate was initially set to 10 −3  for all layers to accept the 
newly deﬁned last fully connected layer set to 10 −2 . It is higher 
than other layers due to the weights being trained starting from 
random. The learning rate was then decreased by a factor of 10 ev- 
ery 20K iteration and was stopped after 100K iterations. The units 
of the third fully connected layer (fc8) were changed according to 
the number of classes of training data. We set the batch size to 50 
and momentum to 0.9. We applied L 
2 weight decay with penalty 
multiplier set to 5 × 10 −4 and dropout ratio set to 0.5, respectively. 

4.2. Deconvolutional network

the parameter setting in training, we employ ﬁxed learning policy. 
We set the learning rate to 10 −3 , and then decrease it by a fac- 
tor of 10 when the validation set accuracy stops improving. The 
momentum is set to 0.9 and weight decay to 10 −4 . In this experi- 
ment, we compute the top-1 classiﬁcation accuracy as described in 
Section 4.3 . 

6.2.1. Results and discussion

conv3 

384 
3 × 3 

conv4 

384 
3 × 3 

conv5 

256 
3 × 3 

pool5 

256 
3 × 3 

fc6 

4096 
–

fc7 

4096 
–

fc8 

10 0 0 
–

pooling layer, each feature map is subsampled with max pooling 
over a q × q contiguous region to produce the so-called pooled 
maps. After performing convolution and pooling in the ﬁfth layer, 
the output is then fed into fully-connected layers to perform the 
classiﬁcation.

170 , conv 4 

373 , conv 4 

In Fig. 8 , we visualise the response of the selected ﬁlter units 
( conv 4 
365 ) in layer 4. In layer 4, 
148  and conv 4 
we  observe  mid-level  semantic  partial  abstraction  of  leaf  struc- 
tures, where the features extracted have almost similar complexity 
levels to layer 3. For example: venation-like features are observed 
in the channel conv 4 
373 ( Fig. 5 (i)) based on the deconvolution re- 
sult of the validation set; the neurons are not only activated on 
the divergent structures (secondary veins) but on the central veins 
(primary veins) as well. For the channel conv 4 
170 , the selected ﬁl- 
ters are activated by the curvature of the lobed leaves, as shown 
in the deconvolution of the top two image patches ( Fig. 5 (j)). This 
can be interpreted as extraction of conjunctions of curvature fea- 
tures  in  certain  orientations.  On  the  other  hand,  for  the  chan- 

8 

S.H. Lee et al. / Pattern Recognition 71 (2017) 1–13

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about the specific postprocessing steps involved after the model training. However, some clues can be derived from the mentioned details.

For instance, the authors use the fixed learning policy during the training phase of their deconvolutional network. They also mention computing the top-1 classification accuracy, which suggests they might calculate metrics such as precision, recall, or F1 score to evaluate the performance of their model.

Additionally, the authors discuss visualizing the response of filter units in different layers, indicating that they may generate saliency maps or heatmaps to understand how the model makes its predictions.

Lastly, although not explicitly stated, creating confusion matrices could help them analyze misclassifications and identify areas for improvement in their model.

Therefore, while the exact postprocessing steps are not specified, one can infer that calculating evaluation metrics, generating visualizations like saliency maps, and possibly constructing confusion matrices are likely part of the process.