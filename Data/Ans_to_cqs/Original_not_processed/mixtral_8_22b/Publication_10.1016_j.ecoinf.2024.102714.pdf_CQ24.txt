Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The LWHabmod was clipped with the harmonised GMEPmod squares.
Given the marginal coverage of calcareous grassland and raised bog in
GMEP, these classes were omitted leaving 15 classes to compare.
Stratified random sampling points were generated using QGIS’ ACa-
TAMa plug-in (Llano, 2023). The number of points per class was
increased by 5-fold (to 1500) based on the minimum deemed necessary
in guidelines given by (Olofsson et al., 2014; see Eq. 3) to account for
bias associated with restricted inclusion probabilities that result from
the pre-defined distribution of GMEP squares. The initial validation
label for every point was sourced from GMEPmod and every point

EcologicalInformatics82(2024)1027146S.M. Punalekar et al.

Table 3
Summary of harmonisation process resulting in 17 comparable classes in GMEPmod and LWHabmod, generated from GMEP and LWHab, respectively.

GMEP habitat classes
(UK-BAP)

88
81
93
73
85
58
59
90
81
66
60
63
05
96
28

88
81
93
47
74
73
87
77
60
89

80
92
88
86
27
84
43
39
81
79
62
77
08
96
100

80
92
88
62
74
86
92
55
97
79

88
81
93
73
92
68
59
90
81
66
60
68
16
96
28

88
81
93
47
74
73
87
77
60
89

80
92
88
86
59
84
43
39
81
79
62
77
26
96
100

80
92
88
62
74
86
92
55
97
79

>50% cover of U. galli

Molina grassland
>50% cover of M. caerulea
Juncus rushes
>50% cover of Juncus spp.

LWHab classes
(based on Phase-1)

Broadleaved woodland
Needleleaved woodland
Improved grassland,
Arable crops

Bracken
Acid grassland
Neutral grassland
Calcareous grassland
Dry dwarf shrub heath (Ddsh)
Wet dwarf shrub heath (Wdsh)
Fen, Marshy grassland, and Swamp
Modified bog
Blanket bog
Raised bog
Open dune, Dune Grassland, Dune Heath,
Dune Scrub
Saltmarsh

Ulex dominated scrub

Molina grassland

Juncus rushes

* Perennial ryegrass, Trifolium repens, Ranunculus repens, Cynosurus cristatus, Poa trivialis.

Fig. 4. Harmonisation of habitat classes within (a) GMEP to generate (c) GMEPmod demonstrated over one of the GMEP 1 km2 square (SquareID: EYAQHZ). LWHab
map (b) is also shown to demonstrate the similarities and differences with GMEP and GMEPmod.

EcologicalInformatics82(2024)1027147S.M. Punalekar et al.

based on the seasonal behaviour and respective spectral/backscatter
annual profiles. The model parameters – number of trees, maximum
depth of trees, subsample ratio of columns used for each tree, and model
learning rate - were fine-tuned through a random grid search approach.
Following map production, post-classification refinement was un-
dertaken to improve the classification for certain classes and areas (e.g.,
swamp in southern Pembrokeshire). This required additional training
data in areas known to be misclassified, with this obtained through
aerial photograph interpretation and targeted field visits. Following
reclassification of the VTs, the final nine-class VT map was generated.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, there isn't any explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, it can be inferred that some form of management might have been implemented due to the use of machine learning techniques like Random Forest Classifier and XGBoost. These algorithms inherently involve elements of randomness, which could affect reproducibility if not properly managed.

One common strategy to manage randomness in deep learning pipelines is setting fixed seeds for all sources of randomness, including those related to data shuffling, weight initialization, and dropout layers. By doing so, researchers ensure that their results remain consistent across different runs or when shared with others. Another strategy involves performing multiple runs with different seeds and averaging the results to reduce variability caused by randomness.

However, without specific details regarding the implementation of these models in the study, we cannot definitively state what strategies were employed to handle randomness in the deep learning pipeline.