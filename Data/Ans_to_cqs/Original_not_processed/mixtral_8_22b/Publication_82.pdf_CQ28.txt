Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To summarize, we have a total of 60 experimental

conﬁgurations, which vary on the following parameters:

1. Choice of deep learning architecture:

AlexNet,
GoogLeNet.

2. Choice of training mechanism:

Transfer Learning,
Training from Scratch.

3. Choice of dataset type:

Color,
Gray scale,
Leaf Segmented.

4. Choice of training-testing set distribution:

Train: 80%, Test: 20%,
Train: 60%, Test: 40%,
Train: 50%, Test: 50%,
Train: 40%, Test: 60%,
Train: 20%, Test: 80%.

this paper, we have used the notation of

Throughout
Architecture:TrainingMechanism:DatasetType:Train-Test-
Set-Distribution to refer
experiments. For
to particular
instance,
to refer to the experiment using the GoogLeNet
learning
architecture, which was
on the gray-scaled PlantVillage dataset on a train—test
set distribution of
the notation
GoogLeNet:TransferLearning:GrayScale:60–40.

trained using transfer

60–40, we will use

30/3 epochs),
• Momentum: 0.9,
• Weight decay: 0.0005,
• Gamma: 0.1,
• Batch size: 24 (in case of GoogLeNet), 100 (in case of AlexNet).

All the above experiments were conducted using our own fork of
Caﬀe (Jia et al., 2014), which is a fast, open source framework for
deep learning. The basic results, such as the overall accuracy can
also be replicated using a standard instance of caﬀe.

RESULTS

representations of

The GoogleNet architecture on the other hand is a much
deeper and wider architecture with 22 layers, while still having
considerably lower number of parameters (5 million parameters)
in the network than AlexNet (60 million parameters). An
application of the “network in network” architecture (Lin et al.,
2013) in the form of the inception modules is a key feature of
the GoogleNet architecture. The inception module uses parallel
1 × 1, 3 × 3, and 5 × 5 convolutions along with a max-pooling
layer in parallel, hence enabling it to capture a variety of features
in parallel. In terms of practicality of the implementation, the
amount of associated computation needs to be kept in check,
which is why 1 × 1 convolutions before the above mentioned
3 × 3, 5 × 5 convolutions (and also after the max-pooling
layer) are added for dimensionality reduction. Finally, a ﬁlter
concatenation layer simply concatenates the outputs of all these

Science 307, 357–359. doi: 10.1126/science.1109057

Sankaran, S., Mishra, A., Maja,

(2011). Visible-
infrared spectroscopy for detection of huanglongbing in citrus

J. M., and Ehsani, R.

near

orchards. Comput. Electron. Agric. 77, 127–134. doi: 10.1016/j.compag.2011.
03.004

Schmidhuber, J. (2015). Deep learning in neural networks: an overview. Neural

Netw. 61, 85–117. doi: 10.1016/j.neunet.2014.09.003

Simonyan, K., and Zisserman, A. (2014). Very deep convolutional networks for

large-scale image recognition. arXiv:1409.1556.

Singh, A., Ganapathysubramanian, B., Singh, A. K., and Sarkar, S. (2015). Machine
learning for highthroughput stress phenotyping in plants. Trends Plant Sci. 21,
110–124 doi: 10.1016/j.tplants.2015.10.015

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there isn't any explicit mention of the specific cloud platform or deployment environment used for implementing the deep learning models. Therefore, I cannot provide a definitive answer regarding whether AWS, Azure, Google Cloud Platform, or another service was utilized.