Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 2
Experiments training/test sets sizes for the upper-, left- and right-poses models.

Exper. No.

Method

Upper

Left

Right

E1

E2

4-CoL, NoAug,
FEE, none
4-Col, Aug,
NoFEE, none

Train: 24
Test: 66
Train: 72
Test: 68

Train: 40
Test: 59
Train: 120
Test: 62

Train: 40
Test: 68
Train: 120
Test: 67

Table 3
Precision results of each experiment for the upper-, left- and right-pose models.

Exper. No.

Measure

E1:

E2:

P1
P3
P5
P6
P1
P3
P5
P6

Upper

0.682
0.788
0.838
0.849
0.441
0.5
0.559
0.603

Left

0.356
0.61
0.712
0.78
0.323
0.484
0.581
0.629

Right

0.544
0.662
0.735
0.78
0.418
0.522
0.612
0.687

Fig. 10. (a) Upper-pose images, (b) Left-pose images, (c) Right-pose images.

EcologicalInformatics82(2024)10273712A. Levy et al.

Though the original architecture of Koch et al., (2015) used
regularized cross entropy as a loss function, better performance may
be achieved with other loss functions instead of cross entropy, as
mentioned by Wang and Deng, (2021). Contrastive loss takes as input
a pair of samples that are either similar or dissimilar, and brings
similar samples closer and dissimilar samples far apart. It is, there-
fore, a better choice for learning a metric. Contrastive loss has been
successfully used recently in several papers in machine learning as
well as with Siamese networks and outstanding results have been
reported for using it even in unsupervised contrastive learning (see e.
g., (Aruna Gladys and Vetriselvi, 2023; Choi and Kim, 2022; He et al.,
2019; Huang et al., 2019; Lian et al., 2018; Melekhov et al., 2016;
Misra and van der Maaten, 2019; Shorfuzzaman and Hossain, 2021;
Wang et al., 2021; Wang and Liu, 2021; Wu et al., 2018; Yu et al.,

performance of a fine-tuned Convolutional Neural Network (CNN) and
showed that the CNN outperforms the traditional classification methods.
Salman et al., (2016) compared traditional classification methods such
as SVM, k-Nearest Neighbours (K(cid:0) NN), and Sparse Representation
Classifier with CNN. They achieve an average classification rate of more
than 90% on the LifeCLEF14 (Joly et al., 2014) and LifeCLEF15 (Joly
et al., 2015) fish datasets using CNN and generally a significantly lower
rate using the traditional methods. Siddiqui et al., (2017) reaches clas-
sification accuracy of 94.3% performance on fish species classification
using a very deep CNN with a cross-layer pooling approach for enhanced
discriminative ability to handle the limited labeled training data prob-
lem. Nepovinnykh et al., (2018) examine two methods of Saimaa ringed
seal identification based on transfer learning: retraining of an existing
convolutional neural network (CNN) versus using the CNN trained for

The training set included 21 different individuals (classes) each
having 4 different 320 Ã— 320 pixels images. The test size included 99
other labeled images of the individuals that appeared in the training set.
Images of both training and test sizes varied in their poses and other
image characteristics, such as contrast, brightness, etc. The initial ex-
periments referred to the following issues to be decided for the chosen
framework:

1. Architecture: We examined two Siamese architectures versions
based on the work of (Koch et al., 2015), since Siamese networks that
learn a similarity function are a better choice for learning with a
small example set.13 The two architectures have either 2 or 4
convolution layers with Relu activations and Contrastive Loss (CoL)
as a loss function. The implementations are taken from the open
sources of Choi, (2020); Siyah, (2020).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, the performance of the deep learning model was evaluated using Precision as a metric. Table 3 shows the Precision results of each experiment for the upper-, left-, and right-pose models. However, no specific details about how this metric was calculated were provided. Other common evaluation metrics for deep learning models include Accuracy, Recall, F1 Score, ROC AUC, and others depending on the problem type and requirements. In this case, only Precision was mentioned as the evaluation metric.