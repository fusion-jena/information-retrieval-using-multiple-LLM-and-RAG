Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 2 
Performance metrics for both learning rates scenarios trained for each classification model (mean ±
standard deviation of the five folds). ACC – Accuracy, TPR – Sensitivity, TNR – Specificity and F1 – 
F1-score. Light grey cells highlight the best performance results for learning rate and metric. 

Table 3 
Performance metric (mAP@0.50IOU; mean average precision), average inference time per image and total 
loss (sum of the classification and localization losses) for each model. Light grey cells highlight the best model 
results for performance (mAP), total loss and speed. 

3.3. Mapping the spatial distribution of Cortaderia selloana

A.1b),  with  high  performances  (e.g.,  f1-score  values  above  93.09%; 
Table  4).  Unlike  the  training  task,  the  best  results  were  obtained  by 
(cid:0) 4,  in  terms  of  accuracy 
EfficientNetB0  with  a  learning  rate  of  10
(97.50%),  sensitivity  (96.00%)  and  f1-score  (97.46%),  followed  by 
(cid:0) 4),  which  also  showed 
Inception-v3  with  the  same  learning  rate  (10
high accuracy (96.88%), sensitivity (94.00%), specificity (99.75%) and 
f1-score (96.78%). In the case of the EfficientNetB0 model, only 4% of 
the  images  displaying  the  Cortaderia  selloana  were  confused  by  the 
model as showing no C. selloana (false negatives; Fig. A.1c). Likewise, 
from  the  images  showing  no  C.  selloana,  in  1%  of  the  cases  Effi-
cientNetB0  incorrectly  predicted  the  class  “With  Cortaderia  selloana” 
(false  positives;  Fig.  A.1d).  A  similar  pattern  was  verified  for  the 
remaining CNNs (see confusion matrices in Tables A.6 and A.7).

2.5.4. Model performance evaluation 

The  performance  of  each  classification  model  (VGG16,  ResNet50, 
ResNet101,  Inception-3,  DenseNet201 and  EfficientNetB0)  was  evalu-
ated based on commonly adopted classification metrics (Tharwat, 2018; 
Table  1):  accuracy  (ACC),  specificity  (or  True  Negative  Rate:  TNR), 
sensitivity (recall or True Positive Rate: TPR) and f1-score (F1). For the 
classification task, the term positive stands for the presence of Cortaderia 
selloana in the images (“With Cortaderia selloana”), whereas the negative 

Table 1 
Evaluation metrics considered in the classification and object detection models 
evaluation, with respective example. TP represents the True Positives, TN the 
True Negatives, FP the False Positives and FN the False Negatives.  

Metric 

Example 

Classification models 

Accuracy 

Specificity 

Sensitivity (or recall) 

F1-score

2.5.2. Model training and validation 

For  the  classification  task,  the  performance  of  the  models  was 

evaluated  using  5-fold  cross  validation  over  the  dataset  described  in 
Sections 2.3 and 2.4, as this approach provides a robust and unbiased 
estimate of a model’s performance while also guiding effective hyper-
parameter  tuning  for  improved  overall  performance  (James  et  al., 
2023). The dataset was divided into 5 subsets, and, at each iteration of 
the 5-fold cross validation, one was used to evaluate the models using 
the  performance  metrics  that  will  be  presented  in  Section  2.5.4.  The 
remaining  4  subsets  were  used  for  training  (90%  of  the  images)  and 
validation (10% of the images).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The performance of the deep learning models is evaluated using several metrics. These include accuracy (ACC), specificity (TNR - True Negative Rate), sensitivity (also known as recall or TPR - True Positive Rate), and F1-score. For the classification task, the term 'positive' refers to the presence of Cortaderia selloana in the images ("With Cortaderia selloana"), while 'negative' indicates its absence. The models' performance is assessed using 5-fold cross-validation over the dataset, providing a robust and unbiased estimate of their performance. This method also guides effective hyperparameter tuning for improved overall performance.