Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Supplementary Materials: The following are available online at http://www.mdpi.com/2072-4292/12/3/343/s1,
Figure S1: Number of results in the Google scholar academic search engine. Date of queries, 28 December 2019.
[keyword + deep learning]. Keywords: AlexNet, DenseNet, GoogLeNet, Inception, MobileNet, Resnet, Resnext,
VGG, Xception. Figure S2: Illustration of the diﬀerence between the sampling design strategies, (A) Continuous
and (B) Discrete, including examples of images (0.5 ha) from each class (Three Tree-Cover levels plus the Non-Forest
class) of the training dataset. Image data: Google, Maxar, and NWPU-RESISC45 dataset. Archive S1: Metadata of
FAO’s GDA photointerpreted very high resolution plots (71,135) with zoom 19 in Google Maps. The CVS ﬁle
contains Id, UpperLeft and Downright coordinates, Zoom, Region, Aridity level, Class (Forest/Non-forest), and
Tree cover. Archive S2: Metadata of training dataset of continuous larger sample CNN-based model with very

67. Neelakantan, A.; Vilnis, L.; Le, Q.V.; Sutskever, I.; Kaiser, L.; Kurach, K.; Martens, J. Adding gradient noise

improves learning for very deep networks. arXiv 2015, arXiv:1511.06807.

68. Ganguly, S.; Kalia, S.; Li, S.; Michaelis, A.; Nemani, R.R.; Saatchi, S. Very High Resolution Tree Cover Mapping
for Continental United States using Deep Convolutional Neural Networks. In Proceedings of the AGU Fall
Meeting Abstracts, New Orlean, LA, USA, 11–15 December 2017.
Suzuki, K.; Rin, U.; Maeda, Y.; Takeda, H. Forest cover classiﬁcation using geospatial multimodal data.
Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci. 2018, 42, 1091–1096. [CrossRef]

69.

70. Marshall, M.; Thenkabail, P. Advantage of hyperspectral EO-1 Hyperion over multispectral IKONOS,
GeoEye-1, WorldView-2, Landsat ETM+, and MODIS vegetation indices in crop biomass estimation. ISPRS J.
Photogramm. 2015, 108, 205–218. [CrossRef]

Remote Sens. 2020, 12, 343

15 of 15

74. LeCun, Y.; Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436. [CrossRef]
75. Lynch, C. Big data: How do your data grow? Nature 2008, 455, 28. [CrossRef]
76.

Steinkraus, D.; Buck, I.; Simard, P.Y. Using GPUs for machine learning algorithms. In Proceedings of
the Eighth International Conference on Document Analysis and Recognition (ICDAR’05), Seoul, Korea,
31 August–1 September 2005; pp. 1115–1120.

77. Bremond, L.; Alexandre, A.; Hély, C.; Guiot, J. A phytolith index as a proxy of tree cover density in
tropical areas: Calibration with Leaf Area Index along a forest–savanna transect in southeastern Cameroon.
Glob. Planet. Chang. 2005, 45, 277–293. [CrossRef]

78. Achard, F.; Eva, H.D.; Mayaux, P.; Stibig, H.J.; Belward, A. Improved estimates of net carbon emissions from

land cover change in the tropics for the 1990s. Glob. Biogeochem. Cycles 2004, 18. [CrossRef]

(1) Database construction phase: ﬁve training datasets were built with examples of images with
diﬀerent levels of tree cover, continuous and discrete approximations, and inclusion of auxiliary
class “Non-Forest” (see Section 2.2 and Supplementary Material, Archive S2).

(2) Training phase: training ﬁve CNN models based on Inception v.3 using two optimization

techniques, transfer learning, and data augmentation (see Section 2.3).

(3) Classiﬁcation phase: classiﬁcation of new 396 images with diﬀerent tree cover in global drylands
(see Supplementary Material, Table S1 and Archive S3) with the built CNN-based model (see
Section 2.4).

(4) Validation phase: assessment of performance on the new images (see Section 2.5).

2.2. Datasets Design

Before building the training datasets for the CNN-based models, we compiled a global database

of very high resolution satellite and aerial RGB images from two sources:

•

•

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The strategies employed to handle randomness in the deep learning pipeline include setting a fixed random seed value, which ensures reproducibility by initializing the weights and biases of the neural network in the same way every time the code is run. Another strategy is to use deterministic algorithms or set their parameters to ensure consistent outputs. Additionally, some libraries provide options to control the randomness, such as TensorFlow's tf.random.set\_seed() function. It is also important to note that while controlling randomness can help with debugging and comparing different approaches, it may limit the exploration of the solution space during training. Therefore, it is essential to strike a balance between controlling randomness and allowing enough variability for effective learning.

Based on the given context, there isn't any direct information about handling randomness in the deep learning pipeline. However, one possible approach could be using techniques like setting a fixed random seed value or employing deterministic algorithms, as mentioned above. These methods can help maintain consistency across multiple runs of the model, ensuring reproducible results.