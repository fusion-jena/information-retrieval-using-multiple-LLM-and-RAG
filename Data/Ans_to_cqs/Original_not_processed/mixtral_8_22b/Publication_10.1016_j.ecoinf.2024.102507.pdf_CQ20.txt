Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

With regards to the difference between the results of the original, 
reduced,  and  augmented  datasets  applied  to  the  deep  learning 
model, we found that the original and augmented datasets are only 
under  a  few  specific  numbers  of  bands  and  data  formats  (e.g., 
VGG19 + 8band_256_8bit, VGG19 + 72band_256_8bit, ResNet50 +
8band_256_8bit, and ResNet50 + 36band_ 256_8bit). The classifica-
tion accuracy rate reached more than 50%, and there was no regu-
larity in the classification accuracy. However, the sampling action of 
reducing the data had a very obvious and consistent impact on the 
classification  accuracy,  especially  in  the  VGG19  model,  which  is 
more  similar  to  the  traditional  CNN  model.  This  representative 
sampling  action  resulted  in  incomplete  and  complete  feature 
extraction,  and  some  key  features  were  ignored.  Given  the  above 
reasons, it is recommended that sampling actions be avoided in the

after the above training data preparation is as follows (Fig. 6). One of the 
optimal  simulation  results  (72band_256_16bit_split)  was  achieved 
through the utilization of data augmentation and flattened convolution 
kernels, as illustrated in Fig. 7.

When  the  image  units  of  bands  36  and  72  are  input  to  the  deep 
learning model, the memory capacity may be insufficient given the large 
dimensions. Therefore, when inputting sample images for bands 36 and 
72, we used Python's Rasterio module to disassemble them into single- 
band  images,  i.e.,  the  image  units  with  36  bands  were  disassembled 
into 36 single-band images and 72-band images were disassembled into 
72  single-band  images.  This  data  conversion  method  is  equivalent  to 
flattening the thick convolution kernel. During testing, we found that 
through  the  optimization  of  this  process,  the  hardware resources  and 
computing time required for deep learning can be considerably reduced, 
while the corresponding impact on the model's accuracy is limited. 

3.2. Deep learning model and testing results 

After selecting the model, the CNN model in this study was further 

built using the following steps:

EcologicalInformatics80(2024)1025078F.-C. Lin et al.                                                                                                                                                                                                                                   

Table 2 
Number of bands used in deep learning and the band numbers selected after SSDM.  

Number of bands 

Corresponding number 

3 
4 
8 
36 
72 

(13,20,32) 
(2,5,38,41) 
(2,5,8,38,41,52,63,66) 
(1,2,3,4,5,6,7,8,9,10,11,36,37,38,39,40,41,42,43,49,51,52,53,55,59,61,62,63,64,65,66,67,69,70,71,72) 
All bands  

result is shown in Fig. 4.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about the specific hardware resources used for training the deep learning model, such as GPUs or TPUs. However, it mentions that during the testing phase, the use of Python's Rasterio module to disassemble multi-band images into single-band images helped reduce the hardware resources required for deep learning. This suggests that the authors might have been concerned about resource limitations while working with high-dimensional data. Nonetheless, without explicit mention of the hardware resources used, one cannot definitively state whether GPUs, TPUs, or other types of hardware were employed for training the deep learning models.