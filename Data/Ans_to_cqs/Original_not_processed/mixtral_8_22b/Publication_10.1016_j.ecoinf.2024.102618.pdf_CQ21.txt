Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 2. Preprocessing step.  

EcologicalInformatics81(2024)1026184A.H. Ali et al.                                                                                                                                                                                                                                    

Fig. 3. The proposed model.  

minority classes during training. 

This  is  implemented  in  two  steps.  First  we  use  a  function  called 
compute_class_weights from sklearn library in Python. This function is 
responsible of calculating the weights that should be given to each class 
depending on the class numbers. 

The second step involves using these class weights as inputs to train 
the model. This is done by setting the class weight parameters using the 

previously calculated weights. The fit function inside sklearn is imple-
mented in a way to accept such parameters and it applies them during 
training. 

3.4. Deep learning models

model 

Accuracy 

DenseNet201 
efficientNetB0 
efficientNetB3 
Inceptionresnetv2 
ResNet50v2 
ensemble of EfficientNetB0, Inceptionresnetv2, resnet50v2 
ensemble of EfficientNetB0, DesNet201 
ensemble of EfficientNetB0, Desnet201, ResNet50V2 
ensemble of EfficientNetB0, EfficientNetB3 
ensemble of EffieicntNetB0, EffieicntNetB3, 
inceptionresnetv2, Desnet201, ResNet50V2 
ensemble of EfficientNetB0, inceptionresnetv2, Desnet201 
ensemble of EfficientNetB0, inceptionresnetv2, 
Desnet201, EfficientNetB3 
ensemble of EfficientNetB0, inceptionresnetv2,Desnet201, 
ResNet50V2 
ensemble of EfficientNetB0, inceptionresnetv2, 
EfficientNetB3 
ensemble of inceptionresnetv2 + Desnet201 + ResNet50V2 

F1- 
score 

0.9948 
0.9979 
0.9979 
0.9948 
0.9917 
0.9979 
0.9979 
0.9979 
0.9990 
0.9990 

0.9929 
0.9964 
0.9952 
0.9972 
0.9764 
0.9978 
0.9977 
0.9981 
0.9986 
0.9986 

0.9986 
0.9989 

0.9990 
0.9990 

0.9987 

0.9990 

0.9987 

0.9979 

0.9978 

0.9990

for the EfficientNetB3 model. Fast convergence is noticed in the model’s 
response  as  it  converges  at  the  fourth  epoch.  Figs.  4  and  5  show  the 
confusion  matrix  of  classification  of  plant  diseases  by  the  ensemble 
model and by EfficientNetB3 respectively. A confusion matrix shows the 
number of correct classifications for each class in its diagonal cells. It 
also shows the number of misclassifications in other cells than the di-
agonal.  It  can  be  seen  from  the  confusion  matrix  that  EfficientnetB3 
model misclassified class 19 with class 22 23 time. This classification 
error  is  removed  with  ensemble  modelling.  It  can  be  seen  from  the 
confusion matrix of the ensemble model that there is a small number of 
misclassifications compared to the EfficientNetB3 model. Figue 5 shows 
a small number of misclassification. It can be seen that the model biggest 
error  is  a  misclassifcations  of  class  7.  These  misclassifications  are

3.7. Performance metrics 

In this work, we measure the accuracy of the deep-learning models 

by using the following metrics:  

• Accuracy 

accuracy which is a simple metric for deep-learning classification 
models. This metric measures the overall percentage of correct pre-
dictions. However, accuracy does not take into account the different 
types  of  errors.  That  is  the  reason  we  employ  other  metrics  for 
measuring the efficiency of deep learning models. 

Accuracy =

TP + TN
TP + TN + FP + FN

• Precision 

(1)    

Precision  is  a  metric  that  measures  the  number  of  positive  pre-
dictions  that  are  actually  correct  viz.  a  viz.  correct  and  incorrect 
positive predictions. 

recall is a metric that measures the number of positive predictions 
that are actually correct viz. a viz. correct positive predictions and 
incorrect negative predictions. Recall measures how many positive 
predictions were correctly spotted by the model. 

Recall = TP

TP + FN

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, several postprocessing steps can be performed depending on the specific requirements of the project or task. Some common postprocessing steps include:

1. Model Evaluation: After training, the performance of the model needs to be evaluated using various evaluation metrics like accuracy, precision, recall, F1 score, etc. These metrics help us understand how well our model has learned to predict the target variable.

2. Confusion Matrix: A confusion matrix is a table used to evaluate the performance of a machine learning algorithm. It provides information about actual and predicted values generated by a classification model. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class.

3. Saliency Maps: Saliency maps are visualizations that highlight the pixels in an input image that contribute most strongly to the output of a convolutional neural network (CNN). They provide insights into what parts of the input data are important for making accurate predictions.

4. Hyperparameter Tuning: Postprocessing may also involve tuning hyperparameters to improve the performance of the model further. This could include adjusting the learning rate, batch size, regularization parameter, etc.

5. Ensemble Models: Another postprocessing technique is creating ensembles of multiple models to improve prediction accuracy. This involves combining the outputs of individual models to produce a final prediction.

Based on the provided context, it appears that the authors have employed some of these postprocessing techniques. For instance, they have computed the accuracy, precision, recall, and F1 scores of their deep learning models. Additionally, they have created confusion matrices to analyze the performance of their models. Furthermore, they have experimented with ensemble modeling to enhance the accuracy of their predictions.