Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

verages bagging over boosting. This implies that RF constructs trees
independently and amalgamates their forecasts, a strategy that may
prove less efficacious in capturing intricate patterns when compared
with boosting techniques like LightGBM and XGboost. Both LightGBM
and XGboost stand out as potent gradient boosting models, each char-
acterised by unique variances in their tree growth strategies - leaf-wise
and tree level-wise, respectively. LightGBM specifically emphasises
expeditious training performance through the selective sampling of
high-gradient instances within extensive datasets, high-dimensional
data sets, and categorical attributes, owing to its employment of
histogram-based segmentation and adept management of categorical
variables (Al Daoud, 2019).

and time overhead (Ke et al., 2017). LightGBM sets itself apart from
other tree-based methods through its leaf-wise splitting approach, which
generates more intricate trees. These trees are adept at minimising loss,
leading to enhanced accuracy. The splitting process is guided by a
unique sampling method called Gradient-Based One Side Sampling
(GBOSS) (Ke et al., 2017). This method excludes data with small gra-
dients while utilising the remainder for estimating information gain and
facilitating tree growth. A collection of hyperparameters, such as lear-
ning_rate, max_depth, bagging_fraction, bagging_freq, and n_estimators,
controls the algorithm. These parameters are crucial in shaping how the
leaves are structured within the trees. The model's complexity gradually
rises as the tree grows, guided by these parameters. Simultaneously, loss
decreases, and the algorithm becomes more adept at learning from the
data, thereby improving its efficiency. Moreover, this model is suscep-

tible to overfitting; therefore, it is crucial to address this issue by tuning
the hyperparameters.

resolution. However, exploring additional machine learning algorithms and explicitly boosting methods when
computing forest canopy cover using satellite remote sensing is strongly advised.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide direct information about addressing data bias during preprocessing of the deep learning pipeline. However, based on general knowledge, several techniques can be employed to mitigate data bias.

Stratified Splitting: In stratified sampling, the dataset is divided into subsets or strata, ensuring that each subset maintains the same distribution of classes as the original dataset. This technique helps maintain class balance across different stages of the deep learning pipeline.

Oversampling: Oversampling involves duplicating samples from the minority class to achieve a balanced dataset. Synthetic Minority Over-sampling Technique (SMOTE) is one popular oversampling technique where synthetic examples are created along the line segments joining any/all k-nearest neighbors of the minority class.

Undersampling: Undersampling reduces the number of majority class samples to match the size of the minority class. Random Under-Sampling (RUS), NearMiss, and Tomek Links are some common undersampling techniques.

Diverse Data Collection: Collecting diverse data ensures that the dataset represents various scenarios, reducing potential biases introduced due to limited representation. This includes collecting data from multiple sources, demographics, geographical locations, etc.

It should be noted that the choice of technique depends on factors such as the nature of the problem, available resources, and the specific type of bias present in the dataset.