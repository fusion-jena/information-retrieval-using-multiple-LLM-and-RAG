Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

these methods. By applying random erasing to the training dataset of the 
EfficientNet, performance was also moderately improved (Table 6).

acquiring new images. Data augmentation was typically performed as 
part of dataset preprocessing for training an image detection and clas-
sification  model,  such  as  the  CNN-based  model  (Shorten  and  Khosh-
goftaar,  2019).  The  procedure  included  cropping,  flipping,  scaling, 
rotating, adding noise, and color transformation.

To train the EfficientNet, we prepared 4000 images for each category 
using the data augmentation method proposed above. We used 80% of 
the 4000 images for training and the remaining 20% for validation. The 
EfficientNet was trained by the Adagrad in 100 epochs. The dropout rate 
for each task was set at 0.5. The batch size was set at 20. 

All evaluations were performed on the NVIDIA GeForce RTX 2080Ti 
GPU with 11G memory, and the software was Windows 10, Python 3.7, 
CUDA 10.2. Keras 2.4.3 were used to build all models. 

To compare model results with the test video, we used IoU as the 
threshold  for  positives  or  negatives  based  on  the  object  confidence 
scores estimated by the object detector. IoU was defined as the inter-
section  over  the  union  of  the  two  bounding  boxes,  which  were  the 
ground-truth  bounding  box  and  the  predicted  bounding  box.  In  this 
paper, we set the threshold of IoU at 0.3 to consider correct or incorrect 
detection results.

Fig. 4. Examples of data augmentation for the second stage using the EfficientNet. (a) A foreground image of P. striolata was synthesized on a background image with 
random erasing; (b) A foreground image of P. atra was synthesized on a background image; (c) A background image in which only the image processing method 
(Table 1b) was applied. 

EcologicalInformatics66(2021)1014664(a)(b)(c)H. Takimoto et al.                                                                                                                                                                                                                              

the  network  to  increase  the  receptive  field  and  to  capture  more  fine- 
grained  patterns  on  the  bigger  image,  respectively.  There  were  eight 
types of the EfficientNet, from the EfficientNet-B0 to the EfficientNet-B7, 
with an increasing network scale.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about addressing data bias during preprocessing of the deep learning pipeline. However, it mentions the use of data augmentation techniques like cropping, flipping, scaling, rotating, adding noise, and color transformation to prepare 4000 images for each category while training the EfficientNet. Additionally, random erasing is applied to the training dataset to improve performance further. These techniques can help mitigate data bias by creating diverse datasets and reducing overfitting. Nevertheless, other common techniques to address data bias include stratified splitting, oversampling, undersampling, and diverse data collection, but these are not mentioned explicitly in the given context.