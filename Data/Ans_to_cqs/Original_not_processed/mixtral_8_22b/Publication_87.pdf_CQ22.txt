Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Then we get the model architecture. For the sake of illustration, we use a resnet18 here, but we used
a resnet50 to get the full results presented in the main text.

learn <- cnn_learner(dls = dls,

arch = resnet18(),
metrics = list(accuracy, error_rate))

Now we are ready to train our model. Again, for the sake of illustration, we use only 2 epochs here,
but used 20 epochs to get the full results presented in the main text. With all pictures and a resnet50,
it took 75 minutes per epoch approximatively on a Mac with a 2.4Ghz processor and 64Go memory,
and less than half an hour on a machine with GPU. On this reduced dataset, it took a bit more than
a minute per epoch on the same Mac. Note that we save the model after each epoch for later use.

one_cycle <- learn %>%

fit_one_cycle(2, cbs = SaveModelCallback(every_epoch = TRUE,

fname = 'model'))

0.00%

train_loss

epoch
------ -----------
Epoch
1/2
|
Epoch
|
Epoch
|
Epoch
|

valid_loss
-----------
:
[0/36
:
[1/36
:
[2/36
:
[3/36

8.33%

2.78%

5.56%

1/2

1/2

1/2

accuracy
---------
|----------------------------------------

error_rate
-----------

time
-----

|---------------------------------------

|--------------------------------------

|-------------------------------------

17

Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch
Epoch

11.11%

13.89%

16.67%

19.44%

22.22%

25.00%

27.78%

30.56%

33.33%

36.11%

38.89%

41.67%

44.44%

47.22%

50.00%

52.78%

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2

1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2
1/2

55.56%

:
[4/36
:
[5/36
:
[6/36
:
[7/36
:
[8/36
:
[9/36
:

[10/36

:

[11/36

:

[12/36

:

[13/36

:

[14/36

:

[15/36

:

[16/36

:

[17/36

:

[18/36

:

[19/36

:

[20/36

:
:
:
:
:
:
:
:
:
:
:
:
:

|------------------------------------

Using the testing dataset, we calculated three metrics to evaluate our model performance at correctly
identifying species (e.g. Duggan et al. 2021). Specifically, we relied on accuracy the ratio of correct
predictions to the total number of predictions, recall a measure of false negatives (FN; e.g. an image
with a lynx for which our model predicts another species) with recall = TP / (TP + FN) where TP is
for true positives, and precision a measure of false positives (FP; e.g. an image with any species but a
lynx for which our model predicts a lynx) with precision = TP / (TP + FP). In camera trap studies, a
strategy (Duggan et al. 2021) consists in optimizing precision if the focus is on rare species (lynx),
while recall should be optimized if the focus is on commom species (chamois and roe deer).

18

1/2
1/2
1/2
1/2
1/2
2.609996
2/2

Epoch
Epoch
Epoch
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
Epoch
Epoch
Epoch
Epoch
0
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|
Epoch
|

1/2
1/2
1/2
1/2

1/2

1/2

1/2

1/2

1/2

0.00%

10.00%

20.00%

30.00%

40.00%

50.00%

0.00%

2.78%

5.56%

8.33%

2/2

2/2

2/2

2/2

2/2

2/2

2/2

2/2

2/2

2/2

2/2

2/2

11.11%

13.89%

16.67%

19.44%

22.22%

25.00%

27.78%

30.56%

33.33%

:
:
:
:
[0/10
:
[1/10
:
[2/10
:
[3/10
:
[4/10
:
[5/10
:
:
:
:
:
0.754422
:
[0/36
:
[1/36
:
[2/36
:
[3/36
:
[4/36
:
[5/36
:
[6/36
:
[7/36
:
[8/36
:
[9/36
:

[10/36

:

[11/36

:

[12/36

|---|
|--|
||
|----------------------------------------

94.44%
97.22%
100.00%

[34/36
[35/36
[36/36

|------------------------------------

|--------------------------------

|----------------------------

|------------------------

|--------------------

[7/10

[6/10

70.00%

60.00%

80.00%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The performance of the deep learning model is evaluated using three metrics: accuracy, recall, and precision. Accuracy measures the ratio of correct predictions to the total number of predictions. Recall is a measure of false negatives, calculated by dividing the number of true positives by the sum of true positives and false negatives. Precision is a measure of false positives, calculated by dividing the number of true positives by the sum of true positives and false positives. In camera trap studies, precision is optimized when focusing on rare species such as lynx, while recall is optimized when focusing on common species like chamois and roe deer.