Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3.1. Model architectures 

(1)  Unet.  By  incorporating  an  encoder-decoder  structure  that  es-
tablishes shortcut connections, Unet model extended upon FCN’s end-to- 
end concept (Ronneberger et al., 2015). The input to the network is a 
512  × 512  pixels  image  (Fig.  3).  The  encoder  (left  dashed  square) 
downsamples the input tensor and encodes it into a vector with reduced 
dimensions. It consists of multiple convolutional blocks, each including 
a  3  × 3  convolutional  kernel  layer,  batch  normalization,  and  an 

Fig. 1. (a) Overview of Tarim River Basin. (b) Remote sensing images of the study area.  

EcologicalInformatics79(2024)1024093H. Wang et al.

In recent years, the advancement of artificial intelligence technology 
has  led  to  the  emergence  of  numerous  deep  learning  algorithms, 
including U-Net (Unet), Pyramid Scene Parsing Network (Pspnet), and 
DeepLabV3+,  which  are  increasingly  applied  to  address  geographical 
and ecological challenges (Çalıs¸kan, 2023a; Chen, 2023; Minaee et al., 
2022). Notably, Unet  exhibits proficiency  in achieving  more accurate 
results by requiring a smaller number of training samples (Ronneberger 
et  al.,  2015).  On  the  other  hand,  Pspnet  employs  a  spatial  pyramid 
module  to  gather  contextual  data  from  diverse  regions,  enabling  the 
acquisition  of  comprehensive  global  information  (Zhao  et  al.,  2017). 
DeepLabV3+ integrates an asymmetric spatial pyramid pooling (ASPP) 
architecture within an encoder-decoder framework, effectively merging 
multi-scale information. This integration aids in precise object boundary

(3) Deeplabv3þ. In the encoding stage of Deeplabv3+ model, the 
backbone  network  is  replaced  with  Mobilenetv2  featuring  expanded 
convolution (Fig. 5). Mobilenetv2 network ensures higher accuracy and 
enhances  the  model’s  lightweight  nature  compared  to  the  originally 
used  Xception+ network  (Fu  et  al.,  2022),  significantly  reducing  the 
model weights file size and accelerating model prediction speed. Addi-
tionally,  the  semantic  segmentation  task  involves  incorporating  ASPP 
module into the encoder-decoder network (Chen et al., 2018b). Five sets 
of feature maps are obtained by utilizing four atrous convolution blocks 
with varied dilation rates (including convolution, batch normalization, 
and activation layers) and a global average pooling block. These feature 
maps are concatenated, then passed through a 1 × 1 convolution block, 
and  ultimately  inputted  into  the  Decoder  module.  ASPP  method  in-

The high-precision FVC dataset extracted from a deep learning-based 
framework developed in this study provides a more accurate means to 
monitor vegetation changes in arid regions. Integrating techniques like 
attention  mechanism into this framework  could enhance model accu-
racy. Future research endeavors should focus on utilizing this method to 
precisely  evaluate  the  efficacy  of  ecological  restoration  efforts  and 
accurately  quantify  carbon  storage  in  dryland.  Moreover,  leveraging 
unmanned aerial systems for acquiring higher-resolution sensing images 
offers  the  potential  for  identifying  vegetation  coverage  at  the  species 
level, warranting further exploration in subsequent research. 

CRediT authorship contribution statement

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there is no explicit mention or reference to where the code repository of the deep learning pipeline is available. Therefore, I cannot provide specific details about its location on platforms such as GitHub, GitLab, or BitBucket. To find out the exact location of the code repository, please refer to any additional resources or references mentioned in the original source material.