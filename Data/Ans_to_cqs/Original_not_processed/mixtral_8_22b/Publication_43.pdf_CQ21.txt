Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The training-zone used for training the CNN-based model. This zone is located in Cabo de
Gata-Níjar Natural Park, 36◦49(cid:48)43(cid:48)(cid:48) N, 2◦16(cid:48)22(cid:48)(cid:48) W, in the province of Almería, Spain (Figure 2).
The climate is semi-arid Mediterranean. The vegetation is scarce and patchy, mainly dominated
by large Ziziphus lotus shrubs surrounded by a heterogeneous matrix of bare soil and small
scrubs (e.g., Thymus hyemalis, Launea arborescens and Lygeum spartum) with low coverage ([49,52]).
Ziziphus lotus forms large hemispherical bushes with very deep roots and 1–3 m tall that trap and
accumulate sand and organic matter building geomorphological structures, called nebkhas, that
constitute a shelter micro-habitat for many plant and animal species ([19,49,53]).
Test-zone-1 and test-zone-2 belong to two different protected areas. Test-zone-1 is located 1.5 km

output of an intermediate inception module, and (iv) one output classiﬁer.

wt+1 = µwt − α∆J(wt)

(2)

where µ is the momentum weight for the current weights wt and α is the learning rate.

The network weights, wt, can be randomly initialized if the network is trained from scratch.
However, this is suitable only when a large labeled training-set is available, which is expensive in
practice. Several previous studies have shown that data-augmentation ([44]) and transfer learning ([45])
help overcoming this limitation.

•

4.2.3. Training Dataset for the CNN-Classiﬁer

The design of the training dataset is key to the performance of a good CNN classiﬁcation model.
From the 82 Ziziphus individuals georeferenced by botanic experts in the training-zone, we identiﬁed
100 80 × 80-pixel image patches containing Ziziphus lotus shrubs and 100 images for Bare soil with
sparse vegetation. Examples of the labeled classes can be seen in Figure 3. We distributed the
100 images of each class into 80 images for training and 20 images for validating the obtained CNNs
classiﬁers, as summarized in Table 1.

Table 1. Training and testing datasets for both CNN and OBIA used for mapping Ziziphus lotus shrubs.
Bare soil: Bare soil and sparse vegetation; Img: 80 × 80-pixel image patches; Poly: digitized polygons.

CNN Classiﬁer

OBIA Classiﬁer

Class

Training

Validation

Training

Accuracy

Assessment

Training-Zone

Test-Zone-1

Test-Zone-2 Test-Zone-1

Test-Zone-2

Ziziphus
Bare soil

80 img
80 img

20 img
20 img

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the specific requirements of the project. Some common postprocessing steps include:

1. Model Evaluation: After training the model, it is important to evaluate its performance using metrics such as accuracy, precision, recall, F1 score, etc. These metrics help us understand how well our model has learned to classify or predict the target variable. In addition, confusion matrices can also be generated to visualize the performance of the model.

2. Hyperparameter Tuning: Once the initial evaluation of the model is done, hyperparameters can be tuned to improve the performance of the model. Hyperparameters are parameters that are not directly learnt during the training process but affect the overall performance of the model. Common examples of hyperparameters include learning rate, batch size, number of epochs, etc.

3. Visualization Techniques: Various visualization techniques can be employed to better understand the behavior of the model. For example, saliency maps can be generated to highlight the regions of input images that contribute most towards the final prediction made by the model. Similarly, activation maps can be generated to visualize the activations of neurons within the convolutional layers of the model.

4. Ensemble Methods: Multiple models can be combined together to form an ensemble model. Ensemble methods aim to reduce the variance and bias of individual models, thereby improving the overall performance of the system. Popular ensemble methods include bagging, boosting, stacking, etc.

In summary, postprocessing steps after model training involve evaluating the performance of the model, tuning hyperparameters, employing various visualization techniques, and combining multiple models using ensemble methods.