Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We applied the transfer learning and fine-tuning technique with the 
deep learning model ResNet50 (He et al., 2016; Tan et al., 2018), which 
was already pre-trained on ImageNet data (Deng et al., 2009). Transfer 
learning is a technique that enabled us to overcome the issue of shortage 
of  training  data  and  construct  a  model  efficiently  by  transferring 
knowledge  from  a  similar  task  to,  in  this  case,  our  target  task.  The 
implemented  architecture  received  RGB  images  of  224×224×3  as 
inputs—in this case, color spectrograms of two-second durations—and 
included  only  the  feature  extraction  layers  from  the  ResNet50,  dis-
carding the superior classification layers (known as the top network). 
The newly created model reconfigured the top network with two fully 
connected  layers  (FC)  that  could  learn  new  features.  To  reduce  over-
fitting and imitate the training of a set of different models, a dropout

The  implemented  CNN  corresponded  to  a  modified  version  of 
ResNet50, one of the dominant architectures in bioacoustic tasks, and, 
although other authors have applied previous ImageNet training to the 
bioacoustic  domain  (LeBien  et  al.,  2020;  Zhong  et  al.,  2021),  other 
datasets such as Audio Set (Gemmeke et al., 2017) or VGG-Sound (Chen 
et al., 2020) can be just as good as ImageNet for pre-training, either on 
ResNet or on other architectures, such as VGGish, Inception or Mobile-
Net. Another viable option is to pretrain with synthetic clicks or chirps 
(Glotin  et  al.,  2017;  Yang  et  al.,  2021).  Models  already  available  in 
mobile  apps  that  perform  this  same  spectrogram-based  identification 
task are advancing rapidly. To date (October 2022), the BirdNet appli-
cation (Kahl et al., 2021) allows for the identification of more than 3000 
bird species (Wood et al., 2022). In the short term, this particular model

Tan, C., Sun, F., Kong, T., Zhang, W., Yang, C., Liu, C., 2018. A survey on deep transfer 
learning. In: International Conference on Artificial Neural Networks. Springer, 
pp. 270–279. https://doi.org/10.1007/978-3-030-01424-7_27. 

Tittensor, D.P., Beger, M., Boerder, K., Boyce, D.G., Cavanagh, R.D., Cosandey-Godin, A., 
Crespo, G.O., Dunn, D.C., Ghiffary, W., Grant, S.M., et al., 2019. Integrating climate 
adaptation and biodiversity conservation in the global ocean. Science. Advances 5, 
eaay9969. https://doi.org/10.1126/sciadv.aay9969. 

Marler, P., 2004. Bird calls: their potential for behavioral neurobiology. Ann. N. Y. Acad. 

Toews, D.P.L., 2017. From song dialects to speciation in white-crowned sparrows. Mol. 

Sci. 1016, 31–44. https://doi.org/10.1196/annals.1298.034. 

McGehee, S.M., Rozzi, R., Anderson, C., Ippi, S., V´asquez, R., Woodland, S., 2004. 

Presencia de la viudita, Colorhamphus parvirostris (Darwin) a fines de verano en Isla

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classification with deep 
convolutional neural networks. Adv. Neural Inf. Proces. Syst. 25, 1097–1105. 
Lasseck, M., 2019. Bird species identification in soundscapes. CLEF (Working Notes) 

2380. 

LeBien, J., Zhong, M., Campos-Cerqueira, M., Velev, J.P., Dodhia, R., Ferres, J.L., Aide, T. 
M., 2020. A pipeline for identification of bird and frog species in tropical soundscape 
recordings using a convolutional neural network. Ecol. Inform. 59, 101113 https:// 
doi.org/10.1016/j.ecoinf.2020.101113. 

LeCun, Y., Bengio, Y., 1995. Convolutional Networks for Images, Speech and Time Series. 

The MIT Press, pp. 255–258. 

LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521, 436–444. https:// 

doi.org/10.1038/nature14539. 

Luther, D., 2009. The influence of the acoustic community on songs of birds in a 

neotropical rain forest. Behav. Ecol. 20, 864–871. https://doi.org/10.1093/beheco/ 
arp074.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of a specific data repository link for the deep learning pipeline used in this study. Therefore, it is not possible to provide a direct answer to the query. However, some common platforms where researchers often share their datasets include Zenodo, Figshare, Dryad, and GBIF. It would be best to contact the authors directly or check any associated publications for further details regarding the dataset used in this research.