Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Model training: We process data with a deep neural
network and adjust the training epoch, batch size, and
volume size to output a classiﬁer for prediction.
3. Result output: The point cloud test set is segmented,
and we can obtain the ﬁnal segmentation results. The
output ﬁles include point cloud geometric partition
graphs, SPGs, and segmentation results.

Results and Discussion

123

2170

Journal of the Indian Society of Remote Sensing (September 2021) 49(9):2163–2172

training, we set the learning decay rate to 0.7 so that the
learning rate gradually decays as the training progresses.
Table 1 shows the experimental results in which we ﬁxed
the voxel size and batch size and adjusted the regulariza-
tion strength, from which we can be told that result is better
while regularization strength is 0.2.

2165

Fig. 1 The pipeline of the SPG framework. a Represents the original
input data (taking a tree and a pole as examples). b Is a hand-crafted
point cloud partition, c each partition is converted into a superpoint of

the SPG, and d is the network for superpoint embedding and
segmentation based on PointNet and GRU. The black lines represent
the superedges

with K ¼ P3
adjacency:

i¼1 ki,

E ¼ (cid:3)

3
X

i¼1

ki
K

log

(cid:2) (cid:3)
ki
K

in accordance with the optimal

ð1Þ

The linearity, planarity, and scattering are derived by the

following terms:

linearity ¼

planrity ¼

scattering ¼

k1 (cid:3) k2
k1
k2 (cid:3) k3
k1

k3
k1

ð2Þ

The linearity describes how elongated the adjacency is,
the planarity assesses how plane the adjacency is, the high-
scattering values are used to represent an isotropic and
spherical adjacency. We describe these three point features
as geometric features.

Hu, X., & Yuan, Y. (2016). Deep-learning-based classiﬁcation for
DTM extraction from ALS point cloud. Remote Sensing, 8(9),
730.

Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating
deep network training by reducing internal covariate shift. Paper
presented in International Conference on Machine Learning,
Lille, pp. 448–456.

Landrieu, L., & Boussaha, M. (2019). Point cloud oversegmentation
with graph-structured deep metric learning. Paper presented at

123

2172

Journal of the Indian Society of Remote Sensing (September 2021) 49(9):2163–2172

the 2019 The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR).

Landrieu, L., & Obozinski, G. (2017). Cut pursuit: Fast algorithms to
learn piecewise constant functions. Siam Journal on Imaging
Sciences, 10(4), 1724–1766.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that there isn't explicit information about the deployment process of the trained deep learning model. However, some general steps involved in deploying a trained deep learning model are:

Model Serialization: After training the model, it needs to be serialized or saved in a format that can be loaded later for making predictions. This usually involves saving the model architecture along with its weights.

Platform Selection: Once the model has been serialized, it needs to be deployed on a platform where it can receive input data and return predictions. Depending on the use case, this could involve selecting a suitable cloud service provider like AWS, Google Cloud, Azure, etc., or using edge devices such as Raspberry Pi, NVIDIA Jetson, etc.

Inference Optimizations: To ensure efficient and fast predictions, various optimizations can be applied during the deployment phase. These may include quantizing the model weights, pruning unnecessary connections, or converting the model to a more efficient representation like ONNX or TensorRT.

Monitoring and Maintenance: After deployment, it is essential to monitor the performance of the model continuously and perform any necessary maintenance tasks. This might involve retraining the model periodically with new data, updating the software dependencies, or scaling the infrastructure to handle increased traffic.