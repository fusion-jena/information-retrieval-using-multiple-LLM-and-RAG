Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

Accuracy 

Raw 

Train 

98.75% 
96.77% 
82.25% 
93.71% 

Validation 

97.16% 
98.30% 
89.04% 
91.30% 

Test 

96.16% 
95.15% 
83.30% 
86.48% 

Pre-processed  

Train 

98.21% 
96.94% 
77.25% 
91.61% 

Validation 

97.92% 
97.92% 
79.02% 
87.33% 

Test 

95.98% 
96.52% 
75.44% 
86.29%  

Table 5 
Accuracy of the models swapping the testing sets (source → target).  

Model 

Accuracy 

Raw → Pre-processed 

Pre-processed → Raw 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

82.35% 
82.70% 
69.22% 
65.26% 

54.76% 
78.87% 
29.56% 
33.97%  

Fig. 5. Confusion matrices for the VGG-19 architecture.  

et al., 2017) and SmoothGrad (Smilkov et al., 2017) methods over each 
model. These methods plot a point cloud, where the density denotes the 
input space relevance. Thus, a higher density in a region suggests that 
the network ponderates it the most when classifying.

Deep Learning (DL) methods are at the top of the state-of-the-art on 
feature representation for different domains; albeit, DL lacks interpret-
ability. According to Doshi-Velez and Kim (2017), interpretability lets 
human specialists understand what a model is learning, making them 
flexible  real-world  solutions.  Given  such  topics,  this  paper  has  three 
significant contributions:  

1.  The  paper  introduces  the  first  Peruvian  Amazon  Forestry  Dataset, 
including  its  detailed  metadata  and  the  acquisition  protocol 
description. The dataset collects 59,441 samples from ten of the most 
profitable  and  endangered species (Finer  et al., 2014; Pinedo-Vas-
quez et al., 1992). Further-more, we employ six different commercial 
cameras  to  ensure  variability  and  to  develop  any  flexible  solution 
with real-world conditions in the future.

2. Peruvian Amazon forestry dataset

Too  et  al.  (2019)  fine-tune  CNN-based  models  (VGG,  ResNet, 
Inception,  and  DenseNet)  for  plant  species  classification  and  disease 
detection. Qian et al. (2020) monitor invasive plant species in the wild 
by  fine-tuned  models  (Alexnet,  VGG,  and  GoogLeNet).  Chulif  et  al. 
(2019) classify 10,000 plant species by using pre-trained InceptionNet 
models. Kaya et al. (2019) analyze deeply the effect of four different TL 
models on four publicly leaf datasets. (Barr´e et al., 2017) visualize that 
the  first  convolution  layers  learn  to  extract  leaf  venations  and  edges, 
while deeper layers derive high-level feature abstractions.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide explicit information about the specific criteria used to split the data for deep learning model training into train, test, and validation sets. However, typically, the data is randomly divided into these subsets with a common practice being 70/20/10 or 80/10/10 splits for train, test, and validation respectively. This ensures that there is enough data for training while also having separate sets for evaluating the performance of the model during training (validation set) and after training (test set). It is important to note that the exact splitting ratio can vary depending on factors like the size of the dataset and the requirements of the project.