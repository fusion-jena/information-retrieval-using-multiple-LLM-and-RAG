Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

configuration of optimizer and learning rate which has been considered 
for the training of the framework. The EMViT-Net framework achieves 
prominent results as compared to other deep learning models and per-
forms better with an augmented set of EMDS-6 datasets.

To further validate the performance of the proposed model EMViT- 
Net,  the  acquired  findings  were  compared  with  other  state-of-the-art 
models. The performance measures used to compare the performance 
of  EMViT-Net  with  other  deep  learning  models  are  evaluated  on  the 
validation set and test set of the considered dataset EMDS-6. The com-
parison of the classification results achieved by other pre-trained deep 
learning models is given in Table 4 and Table 5 which illustrates the 
finding on each set validation set and test set respectively by calculating 
the  average  value  of  precision,  recall  and  f1-score  for  all  categories 
which are named as Avg_Precision, Avg_Recall and Avg_F1-score. The 
detailed analysis of the proposed network EMViT-Net and other deep 
learning models with specific configurations on unseen test sets is out-
lined  here  which  shows  that  the  EMViT-Net  outperforms  precision,

Table 6 
Performance comparison of EMViT Net with different deep learning models on EMDS-6 test set.  

Model 

Original dataset 

After Augmentation 

Avg. Precision 

Avg. Recall 

Avg. F1-score 

Accuracy 

Avg. Precision 

Avg. Recall 

Avg. F1-score 

Accuracy 

DenseNet121 
Alex Net 
ViT 
ResNet50 
Xception Net 
VGG19 
Inception V3 
VGG16 
EMViT-Net 

39.20% 
32.53% 
34.92% 
41.96% 
44.25% 
41.20% 
50.78% 
38.21% 
57.31% 

33.01% 
31.90% 
33.24% 
37.14% 
39.37% 
31.43% 
43.97% 
37.47% 
53.71% 

33.79% 
29.32%` 
32.63% 
36.93% 
39.07% 
29.97% 
43.41% 
36.80% 
53.45% 

33.02% 
31.91% 
33.23% 
37.14% 
39.37% 
31.43% 
43.97% 
37.46% 
53.71% 

34.92% 
38.19% 
43.55% 
46.57% 
50.87% 
52.40% 
51.91% 
50.86% 
69.53% 

33.77% 
35.87% 
37.65% 
41.58% 
44.76% 
48.57% 
48.88% 
50.15% 
67.62% 

32.45% 
35.35% 
37.92% 
42.06% 
43.03% 
47.67% 
48.10% 
50.64% 
66.89% 

33.77% 
35.87% 
37.65% 
41.58% 
44.76% 
48.57% 
48.88% 
50.15% 
67.62%

capable of learning weights for a generalized trained model on the un-
seen test set of EMDS-6. In model optimization learning rate was set to 
0.002 and the batch size was set to 32. The proposed model is trained for 
100 epochs with optimizer AdamW and the activation function GELU 
which  are  chosen  very  carefully  due  to  their  effectiveness  with  the 
proposed  model  for  the  considered  dataset.  Finally,  the  default  loss 
function  cross-entropy  is  used  to  calculate  the  loss  of  the  proposed 
network. By considering all the results of this section taken into account 
it was found that the proposed model EMViT-Net may be considered as 
fast and more reliable due to its low computational cost and efficiency. 
The loss and accuracy curves of the reported network are given in 
Fig.  5.  which  represents  training  and  validation  accuracy  with  their 
corresponding loss for the proposed model EMViT-Net with a specific

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The optimization technique applied in the deep learning pipeline for the proposed model EMViT-Net is AdamW. This optimizer is used along with a learning rate of 0.002. Additionally, the batch size is set to 32, and the model is trained for 100 epochs. The activation function used in this pipeline is GELU, which is known for its effectiveness with the proposed model and the considered dataset. Lastly, the default loss function used to calculate the loss of the proposed network is cross-entropy.