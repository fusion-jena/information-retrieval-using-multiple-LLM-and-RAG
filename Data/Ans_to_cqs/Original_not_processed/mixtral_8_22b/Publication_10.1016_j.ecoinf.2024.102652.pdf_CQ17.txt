Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.6.3. Training process 

To fit into the network, the training set must have its data normalized 
and standardized. For the training network, the batch size was set to 32. 
The purposes for selecting 32 were to not exceed the memory limit and 
to make full use of computer resources. The optimizer used Adam pro-
cessing, and the learning ratio varied with group based on the cosine 
function’s law, often in the range between 0.0 and 1.0. The 100 epochs 
are used with an early stopping function to halt the learning process if 
there is no improvement in accuracy after 20 epochs. The loss function 
used is the cross-entropy loss function (Abd-Ellah et al., 2024). 

Lce(H, ̂

H) = Hlog

(

)

H
̂
H

+ (1 (cid:0) H)log

)

(

1 (cid:0) H
1 (cid:0) ̂
H

(4)  

where H is the desired output, Lce(H, ̂
is the predicted output. 

H) is the cross-entropy error, and 

̂
H 

Fig. 5. The experimental design flow chart.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Soil salinity 
Artificial neural networks 
Deep learning 
Remote sensing 
Salinity indices

EcologicalInformatics81(2024)10265213(a)(b)0102030405060708090100POI AC0102030405060708090100POIACM. El-Rawy et al.                                                                                                                                                                                                                               

Bhattacharya, B., Solomatine, D.P., 2006. Machine learning in soil classification. Neural 

networks 19 (2), 186–195. https://doi.org/10.1016/j.neunet.2006.01.005. 

Cheng, G., Han, J., 2016. A survey on object detection in optical remote sensing images. 
ISPRS J. Photogramm. Remote Sens. 117, 11–28. https://doi.org/10.1016/j. 
isprsjprs.2016.03.014. 

Cooke, U., Brunsden, D., Doornkamp, J.C., Jones, D.K.C., 1982. Urban geomorphology in 
drylands (book review). Third World Plann. Rev. 5, 395. Available on: https://ia601 
506.us.archive.org/30/items/in.ernet.dli.2015.131892/2015.131892.Urban-Geomo 
rphology-In-Drylands_text.pdf.

Perez, D., Banerjee, D., Kwan, C., Dao, M., Shen, Y., Koperski, K., Marchisio, G., Li, J., 
2017. Deep learning for effective detection of excavated soil related to illegal tunnel 
activities. In: 2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile 
Communication Conference (UEMCON). IEEE, pp. 626–632. https://doi.org/ 
10.1109/UEMCON.2017.8249062. 

Pham, B.T., Bui, D.T., Prakash, I., Dholakia, M.B., 2017. Hybrid integration of Multilayer 

Elnaggar, A., El-Hamidi, K., Mousa, M., Albakry, M., 2017. Mapping soil salinity and 

evaluation of water quality in Siwa Oasis using GIS. J. Soil Sci. Agric. Eng. 8, 9–19. 
https://doi.org/10.21608/jssae.2017.37078. 

Perceptron Neural Networks and machine learning ensembles for landslide 
susceptibility assessment at Himalayan area (India) using GIS. Catena 149, 52–63. 
https://doi.org/10.1016/j.catena.2016.09.007.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no explicit mention of any specific regularization methods used to prevent overfitting in the deep learning pipeline. Regularization methods such as dropout or L2 regularization can be employed to avoid overfitting during model training. However, without further information about the implementation details of the deep learning pipeline, it cannot be confirmed whether these techniques were utilized.

Unhelpful Answer:
The article uses a batch size of 32 and employs the Adam optimization algorithm with a varying learning rate based on the cosine function's law. Additionally, the authors utilize the cross-entropy loss function for their model. While these aspects contribute to the overall performance of the deep learning pipeline, they do not directly address the prevention of overfitting through regularization methods like dropout or L2 regularization.