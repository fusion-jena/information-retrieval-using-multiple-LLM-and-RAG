Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. The monitoring framework 

The first step in our pipeline was to divide the acoustic signals from 
the long recordings (typically of 30 min each) into 3-s segments, with no 
overlap. For each segment, we used the BirdNET-Analyzer (https://gith 
ub.com/kahst/BirdNET-Analyzer)  to  identify  the  species  present, 
extracting the top three species with the highest confidence scores. We 
applied threshold values of fixed 0.35, 0.25 and 0.15 for the first, second 
and third species in the list, respectively, to filter out predictions with 
lower  confidence  scores,  as  they  might  be  erroneous.  Usually,  in  our 
dataset, BirdNET identification confidence scores lower than 0.15 are 
false  positives. In  addition, we used  a species  specific  thresholds (see 
above). Next, we summed the number of vocalizations for each species

3.1. BirdNET performance for different species 

In this analysis we used the annotated calls of 23 species, recorded in 
the Agmon Hula Lake Park between November 2020 and August 2022. 
For each species, we randomly selected 200 segments of 1 s of vocali-
zation  each,  annotated  by  an  expert  birder.  The  recall  and  precision 
results of applying BirdNET-Analyzer to this dataset, which contained a 
total  of  4600  vocalizations,  are  summarized  in  Table  1.  The  average 
recall was 29.7% ± 3.9 SE, and the average precision was 80.9% ± 3.8 
SE. Although the recall is relatively low (above 30% only for 12 out of 23 
species),  for  most  species  the  precision  is  consistently  above  70% 
(Table 1), indicating reliable species detections for subsequent analysis. 
We used a fixed confidence threshold of 0.35 for all species (see P´erez- 
Granados, 2023), which is a good compromise between false positives 
and missed detections for the preliminary analysis.

In this paper, we present an automated framework that allows the 
monitoring of a large number of bird species by their vocalizations over 
extended periods and across various time scales. The framework relies 
on the BirdNET Analyzer deep learning model (BirdNET-Analyzer, n.d.), 

* Corresponding author at: Dept. of Computer Science, Tel-Hai College, Upper Galilee 12210, Israel. 

E-mail address: yizharle@telhai.ac.il (Y. Lavner).  

https://doi.org/10.1016/j.ecoinf.2024.102528 
Received 4 October 2023; Received in revised form 12 February 2024; Accepted 15 February 2024

Our  monitoring  framework  relies  mainly  on  BirdNET-Analyzer, 
version V2.2,  released in August  2022 (Kahl  et al., 2021), which  is a 
free  BirdNET  application  (Kahl  et  al.,  2021).  BirdNET-Analyzer  is  a 
convolutional  neural  network  with  ResNet  blocks  (He  et  al.,  2016) 
which has been trained to identify >3000 bird species. We used the pre- 
trained  model  with  the  default  sensitivity  (1.0)  and  both  pre-defined 
threshold  confidence  score  values  of  0.35,  0.25  and  0.15  for  the  top 
three identifications, and species specific thresholds (see below) when 
applying our pipeline to conduct long-term analysis. The species specific 
threshold was determined for filtering out false positives while preser-
ving the recall score separately for each species. We computed the recall 
and  precision  for  various  threshold  values  of  the  confidence  score 
(Malamut, 2022), from 0.0 (i.e. without a threshold) to 0.95, with a step 
of 0.05.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, it appears there isn't explicit information about the strategy implemented to monitor the model performance during training. However, some insights can be derived regarding the evaluation of the model after its training phase.

The study uses BirdNET-Analyzer, a convolutional neural network model, to identify bird species based on their vocalizations. This model has been trained to recognize more than 3000 bird species. After the initial training, the researchers applied the pre-trained model with default sensitivity settings and pre-defined threshold confidence score values of 0.35, 0.25, and 0.15 for the top three identifications. Additionally, species-specific thresholds were employed to filter out false positives while preserving the recall score for individual species.

To evaluate the performance of the BirdNET-Analyzer, the authors conducted tests using annotated calls of 23 species, totaling 4600 vocalizations. They calculated the recall and precision metrics for these tests. On average, the recall was found to be around 29.7%, while the precision was approximately 80.9%. Despite the relatively low recall rate, the high precision indicates reliable species detection for further analysis.

However, the context does not provide details on how the model's performance was monitored during the actual training process or if any strategies like early stopping, validation set usage, or learning curve tracking were utilized. Therefore, I cannot provide a definitive answer to the query based solely on the given context.