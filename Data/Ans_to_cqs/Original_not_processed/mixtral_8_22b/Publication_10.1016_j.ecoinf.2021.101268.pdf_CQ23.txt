Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

Accuracy 

Raw 

Train 

98.75% 
96.77% 
82.25% 
93.71% 

Validation 

97.16% 
98.30% 
89.04% 
91.30% 

Test 

96.16% 
95.15% 
83.30% 
86.48% 

Pre-processed  

Train 

98.21% 
96.94% 
77.25% 
91.61% 

Validation 

97.92% 
97.92% 
79.02% 
87.33% 

Test 

95.98% 
96.52% 
75.44% 
86.29%  

Table 5 
Accuracy of the models swapping the testing sets (source → target).  

Model 

Accuracy 

Raw → Pre-processed 

Pre-processed → Raw 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

82.35% 
82.70% 
69.22% 
65.26% 

54.76% 
78.87% 
29.56% 
33.97%  

Fig. 5. Confusion matrices for the VGG-19 architecture.  

et al., 2017) and SmoothGrad (Smilkov et al., 2017) methods over each 
model. These methods plot a point cloud, where the density denotes the 
input space relevance. Thus, a higher density in a region suggests that 
the network ponderates it the most when classifying.

Like any other complex model, DL requires a large amount of data to 
fit appropriately, which is hard in our context. To overcome this limi-
tation, we employ different architectures pre-trained with the ImageNet 
dataset. Pre-trained models capture low-level features (e.g., edges, cor-
ners, color spots, etc.) from one domain and transfer them to another 
with  similar  characteristics.  The  transfer  process  is  called  fine-tuning 
due  to  the  model  only  learns  specific  higher-level  features  (e.g.,  ar-
rangements, venations, etc.). We compare four pre-trained models: (1) 
AlexNet (Krizhevsky et al., 2012, 2) VGG-19 (Simonyan and Zisserman, 
2014, 3) ResNet-101 (He et al., 2016, 4) DenseNet-201 (Huang et al., 
2017).  The  fully  connected  block  is  adjusted  to  feed  off  the  feature 
vector and output the ten species of leaves. Table 3 describe architecture 
characteristics 

Ih
R[i, j] = 3.2405⋅Ih
Ih
G[i, j] = (cid:0) 0.9693⋅Is
Ih
B[i, j] = 0.0556⋅Is

H . 
. (4c) Adaptive equalization of the Lightness - IRGB
ICanny. (4f) Final. (For interpretation of the references to color in this figure legend, the 

S

Table 3 
Architectures comparison: AlexNet, VGG-19, ResNet-101, and DenseNet-201.  

Network 

AlexNet 
VGG-19 
ResNet-101 
DenseNet-201 

Year 

2012 
2014 
2016 
2017 

Depth 

#parameters 

8 
19 
101 
201 

60 M 
144 M 
44.8 M 
20 M  

validation samples are selected randomly from the first group. The data 
distribution is 70.12% for training, 1.69% validation, and 28.19% for 
testing. The model feeds off with 16 elements per mini-batches using the 
ADAM optimizer (Kingma and Ba, 2014) with a learning rate of 1e-3. To 
run our experiments, we use Pytorch 1.3 framework in a PC with the 
following specifications: 4.0 GHz Intel Core i9 processor, 32 GB 3000 
MHz DDR4 memory, and NVIDIA Titan RTX. 

5. Results

Deep Learning (DL) methods are at the top of the state-of-the-art on 
feature representation for different domains; albeit, DL lacks interpret-
ability. According to Doshi-Velez and Kim (2017), interpretability lets 
human specialists understand what a model is learning, making them 
flexible  real-world  solutions.  Given  such  topics,  this  paper  has  three 
significant contributions:  

1.  The  paper  introduces  the  first  Peruvian  Amazon  Forestry  Dataset, 
including  its  detailed  metadata  and  the  acquisition  protocol 
description. The dataset collects 59,441 samples from ten of the most 
profitable  and  endangered species (Finer  et al., 2014; Pinedo-Vas-
quez et al., 1992). Further-more, we employ six different commercial 
cameras  to  ensure  variability  and  to  develop  any  flexible  solution 
with real-world conditions in the future.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of the deep learning model, several measures were taken. Firstly, a diverse dataset was collected consisting of 59,441 samples from ten of the most profitable and endangered species in the Peruvian Amazon Forest. This diversity ensures that the model can handle various scenarios and conditions found in the real world. Secondly, six different commercial cameras were employed during data collection to introduce variability into the dataset. Using multiple camera types helps create a more robust model capable of handling different image qualities and formats. Lastly, the data distribution used for training, validation, and testing was set to 70.12%, 1.69%, and 28.19%, respectively. This stratified splitting allows the model to be evaluated accurately while ensuring that it does not overfit or underfit the data. Additionally, the model uses mini-batch feeding with 16 elements per batch and the ADAM optimizer with a learning rate of 1e-3. These techniques help improve the model's performance and prevent overfitting. Overall, these measures contribute to creating a deep learning model that can generalize well to new, unseen data.