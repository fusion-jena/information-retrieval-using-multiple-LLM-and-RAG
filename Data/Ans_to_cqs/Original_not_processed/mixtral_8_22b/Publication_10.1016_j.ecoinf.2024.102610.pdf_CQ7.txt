Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

those conditions (Gutzwiller and Serno, 2023; Muckley et al., 2023). We 
expected that creating a mask to delineate the “area of applicability” for 
the trained model (Meyer and Pebesma, 2021) would successfully filter 
out a significant portion of regions lacking training data, particularly in

Keshavamurthy, R., Dixon, S., Pazdernik, K.T., Charles, L.E., 2022. Predicting infectious 
disease for biopreparedness and response: a systematic review of machine learning 
and deep learning approaches. One Health 15, 100439. https://doi.org/10.1016/J. 
ONEHLT.2022.100439. 

Khun, M., 2022. Classification and Regression Training: Package caret. Available at: http 
s://cran.r-project.org/web/packages/caret/caret.pdf (Accessed: 26 January 2023).  
Laaksonen, M., Sajanti, E., Sormunen, J.J., Penttinen, R., H¨anninen, J., Ruohom¨aki, K., 
et al., 2017. Crowdsourcing-based nationwide tick collection reveals the distribution 
of Ixodes ricinus and I. persulcatus and associated pathogens in Finland. Emerg. 
Microb. Infect. 6 (5) https://doi.org/10.1038/EMI.2017.17.

involves the separation of the training and test data beforehand. How-
ever, this approach can introduce bias, particularly when dealing with 
data that contains many zero values. Therefore, we strongly recommend 
that future research efforts adopt spatial cross-validation techniques to 
bolster model robustness. Spatial cross-validation operates by randomly 
selecting blocks of data for training while reserving others for testing. 
This process is repeated multiple times based on the number of specified 
folds. Through this iterative approach, the model refines its estimation 
of prediction errors, consequently enhancing overall model performance 
(Meyer et al., 2019). 

5. Conclusion

prevent  potential  performance  degradation  of  the  model  and  avoids 
overfitting, which can limit the ability to make good extrapolations to 
unseen regions (Duque-Lazo et al., 2016). In this study, we employed 
two common variable elimination techniques for random forests: 1) RFE 
(Recursive  Feature  Elimination,  Khun,  2022)  and  2)VSURF  (Variable 
Selection Using Random Forests; Genuer et al., 2022). In RFE, the user 
defines a termination condition for model performance, and the algo-
rithm  iteratively  removes  one  variable  at  a  time  while  evaluating  its 
impact  on  the  model’s  performance.  This  process  continues  until  the 
algorithm reaches the best predefined level of model performance. In 
this study, Root Mean Square Error (RMSE) was used as the termination 
condition. As a result, RFE retained all variables whose removal led to a 
deterioration in the best RMSE value. VSURF follows a three-step pro-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific criteria used to split the data for deep learning model training into train, test, and validation sets. However, it mentions that the separation of training and test data should be done beforehand but warns against introducing bias, especially when dealing with data containing many zeros. The authors suggest using spatial cross-validation techniques to bolster model robustness. Spatial cross-validation involves randomly selecting blocks of data for training while reserving others for testing, repeating this process multiple times based on the number of specified folds. This method helps refine the model's estimation of prediction errors and enhances overall performance.