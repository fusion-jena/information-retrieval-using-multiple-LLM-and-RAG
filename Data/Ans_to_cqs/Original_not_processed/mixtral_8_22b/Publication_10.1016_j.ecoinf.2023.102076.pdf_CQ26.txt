Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

sifiers, that can be tailored for specific research questions. In addition, 
training data in which the target class makes up a small proportion of 
text generally leads to poor classification performance, as demonstrated 
with web articles for classification task 2 in this study (Fig. 3). Never-
theless, although not applied in our pipeline, augmenting training data 
by  oversampling  of  the  minority  class  can  help  to  alleviate  this  issue 
(Padurariu and Breaban, 2019).

fying the exploitation or sale of a particular taxa, for which there may 
not be existing proxy datasets. Alternatively, researchers can annotate a 
randomly  selected  sample  of  collected  data,  according  to  their  own 
relevancy  criteria.  However,  this  approach  is  less  suitable  for  cases 
where relevant examples make up a small proportion of the collected 
data,  as  imbalanced  training  data  can  lead  to  poor  classification  per-
formance (SchrÂ¨oder et al., 2021).

Here,  we  demonstrate  and  evaluate  a  text  classification  pipeline, 
designed to address both the issue of imbalanced datasets and the need 
for large training datasets, using an example data collection scenario. 
Importantly,  we  use  a  hierarchical  classification  approach,  whereby 
data are passed through a series of classifiers with increasingly specific

3.4. The influence of data stratification 

As shown in Table 2, stratification of training data for classification 
tasks 2 and 3 influenced the performance with which classifiers were 
able  to  identify  relevant  texts  in  testing  data.  Overall,  the  recall  of 
relevant  texts  within  stratified  testing  sets  was  higher  for  classifiers 
trained  on  stratified  data  those  those  trained  on  non-stratified  data 
(Table 2). The exception to this is classification task 3, applied to web 
articles, where performance was comparable between different classi-
fiers. This may be attributed to the relatively balanced distribution of 
topics (query groups) within this labelled dataset (Table S2.3).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context discusses several techniques used to address data bias during preprocessing of the deep learning pipeline. These include stratified splitting, oversampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets based on certain characteristics, such as class labels, ensuring that each subset maintains the same proportions of these characteristics as the original dataset. This technique helps prevent overrepresentation or underrepresentation of any particular characteristic in the training or test set. As mentioned in the context, stratifying the training data for classification tasks 2 and 3 improved the ability of classifiers to identify relevant texts in testing data.

Oversampling is another method used to balance classes by increasing the number of instances in the minority class. Although not explicitly stated in the context, it is implied that oversampling could potentially improve classification performance when dealing with imbalanced datasets.

Diverse data collection refers to gathering data from various sources or employing different relevance criteria to ensure that the dataset represents a wide range of perspectives and scenarios. This approach is particularly useful when addressing issues like the exploitation or sale of a particular taxa, where no existing proxy datasets might exist.

In summary, the techniques used to address data bias during preprocessing of the deep learning pipeline include stratified splitting, oversampling, and diverse data collection. Each technique serves its unique purpose in mitigating biases and improving overall model performance.