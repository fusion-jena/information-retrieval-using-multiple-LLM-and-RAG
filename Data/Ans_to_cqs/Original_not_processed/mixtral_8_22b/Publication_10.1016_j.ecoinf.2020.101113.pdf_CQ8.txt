Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The manual effort in training data creation was reduced to template 
creation and validation of template-based detections in a graphical user 
interface (Fig. 3). This addresses an important need for more accessible 
training  data  from  study  sites  to  leverage  deep  learning  for  acoustic 
monitoring.  Our  evaluation  demonstrates  that  strong  classification 
performance  can  be  achieved  using  data  collected  from  the  study  re-
gion,  without  relying  on  crowd-sourced  public  datasets.  The  pipeline 
thus  increases  the  potential  for  region-optimized  acoustic  monitoring 
systems.  Furthermore,  the  training  data  collection  pipeline  could  ac-
celerate the collection of data for rare species. 

Our  training  scheme  allowed  for  multi-label  learning  from  single- 
label  training  data  by  defining  a  custom  training  loss  and  including

2.3.  Model training 

2.3.1.  Training data preprocessing 

The  CNN  model  used  in  this  study  requires  equally  sized  input 
images. We chose a time-frequency input window size of 2 s as it is near 
the mean and median template duration across target call types (Fig. 2). 
Most  call  types  have  a  duration  below  1  s,  and  for  those  above  2  s,

Ecological Informatics 59 (2020) 101113

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

A pipeline for identification of bird and frog species in tropical soundscape 
recordings using a convolutional neural network 
Jack LeBiena,‚Åé
Juan Lavista Ferresb, T. Mitchell Aidea,d 
a Sieve Analytics, San Juan, PR 00911, USA 
b AI for Good Research Lab, Microsoft, USA 
c Department of Physics, University of Puerto Rico, San Juan, PR 00931, USA 
d Department of Biology, University of Puerto Rico, San Juan, PR 00931, USA  

, Ming Zhongb, Marconi Campos-Cerqueiraa, Julian P. Velevc, Rahul Dodhiab,  

T

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Acoustic monitoring 
Bioacoustics 
Sound classification 
Convolutional neural network 
Deep learning

Several challenges remain to be addressed for effective application 
of deep learning in acoustic monitoring. First, CNNs often require many 
training samples for each class. Large-scale species recognition efforts, 
such  as  for  the  BirdCLEF  challenge,  often  use  crowd-sourced  public 
training data from various geographic sources (e.g. Xeno-Canto dataset,  
Vellinga, 2020;), and thus far these public datasets focus on birds and 
consist  mainly  of  recordings  targeting  single  foreground  species. 
However,  as  mentioned  above,  geographic  variation  in  soundscapes 
could require training data collected at a local or regional scale for high 
performance. This, however, would greatly increase the data labeling 
effort.  Second,  the  non-directional  nature  of  soundscape  recordings 
demands  accurate  detection  as  well  as  classification  for  species  re-
cognition. Existing studies have demonstrated the difficulty of species

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of where the code repository of the deep learning pipeline is available. It does not provide any links to GitHub, GitLab, BitBucket, or any other version control system. Therefore, I cannot determine where the code repository is located.