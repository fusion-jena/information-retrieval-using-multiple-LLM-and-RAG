Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Each rectangle indicates the operations performed at a block of layers. Conv and SConv stand for regular convolution and depth-wise separable 
convolution, respectively. The values that follow such operations indicate the number of filters, filter size, stride, and dilation rate. Regarding the 
maxpooling operation, the values correspond to the kernel dimension and stride. Dropout refers to the number of neurons randomly turned off during 
each training inference. The number of neurons in the dense layer of the classifier module corresponds to the number of classes in the dataset. 

All architectures were modified mainly in the block of fully connected layers, where we opted to use just the output layer after the feature extractor 
instead of two fully connected layers. Additionally, residual blocks were used at the architectures’ stems rather than in the full feature extractor. All 
those modifications were experimentally determined.

EcologicalInformatics80(2024)10253516P.J.S. Vega et al.                                                                                                                                                                                                                                

Fig. 9. Architecture details of the deep learning-based classifiers evaluated in this work. In the figure, each network architecture is represented in the green blocks 
separately. The orange block shows the fully connected layers at the end of all networks. (For interpretation of the references to color in this figure legend, the reader 
is referred to the web version of this article.) 

References 

Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D., Liu, L., Ghavamzadeh, M., 

Fieguth, P., Cao, X., Khosravi, A., Acharya, U.R., et al., 2021. A review of uncertainty 
quantification in deep learning: techniques, applications and challenges. Inform. 
Fusion 76, 243–297.

Appendix A. Network architectures 

The network architectures of the models evaluated in the experiments are described in detail in Fig. 9. The light green areas in that figure represent 
feature extractor modules based on the different architectures, i.e., VGG, ResNet, and Xception. The orange area represents the architecture of the 
classifier module, to which the outputs of each feature extractor are submitted.

The  experimental  results  suggest  that  there  might  be  room  to 
improve the generalization capacity of the deep learning classifiers. That 
could  be  achieved  by  better  exploiting  the  training  data,  e.g.,  with 
additional data augmentation techniques, using recent advances in un-
supervised learning techniques, such as self-supervised methods, or by 
just simplifying the classifiers in terms of the number of parameters, thus 
reducing the risk of overfitting. 

Another direction for continuing this research is to exploit the clas-
sification uncertainty further in an active learning context. The uncer-
tainty measure could be used in interactively training the deep learning 
models,  selecting  high-uncertainty  samples  in  the  datasets,  and 
increasing their importance in the computation of the loss function. 

CRediT authorship contribution statement

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: Unfortunately, I cannot provide a helpful answer to your query because none of the given pieces of context mention any information about the specific hardware resources used for training the deep learning models.