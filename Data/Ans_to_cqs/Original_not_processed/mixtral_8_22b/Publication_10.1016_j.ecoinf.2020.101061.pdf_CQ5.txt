Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Collecting a suﬃcient number of training samples will often be a
bottleneck in developing supervised methods in airborne imagery. It is
therefore useful to test the number of local training samples needed to
achieve maximum performance. We performed a sensitivity study by
training models using diﬀerent proportions of training data. We se-
lected 5%, 25%, 50% and 75% of the total hand-annotations to com-
pare to the full dataset for the within-site results for each site. We reran
this experiment ﬁve times to account for the random subsampling of
annotations. In addition, we ran the evaluation plots for the pretraining
model only (i.e. 0% hand-annotated data) to assess whether the addi-
tion of hand-annotated data improved the within-site pretraining.

3. Results

Tesla K80 GPU for 5 epochs. To align these unsupervised classiﬁcations
with the ImageNet pretraining weights, we normalized the RGB chan-
nels by subtracting the ImageNet mean from each channel. We then
retrained the network using the hand-annotated data for 40 epochs. For
more details of this approach see Weinstein et al. (2019). Data aug-
mentation of random ﬂips and translations was tested and found to
have little eﬀect on the ﬁnal score.

beyond the NEON sites may be useful for many applied problems. It is
currently unknown to what extent features learned from the 0.1 m re-
solution data used here can be applied to lower resolution satellite data
(Karlson et al., 2014) or higher resolution UAV data (Brieger et al.,
2019). Cross resolution training has not been fully explored in en-
vironmental remote sensing, but Li et al. (2018) recently showed that
deep learning networks can learn scale invariant land classiﬁcations
that can be matched among data sources. Given the ability to collect
virtually unlimited pretraining data using our data generation ap-
proach, NEON sites can be seen as an ideal training sources for RGB tree
models that could then be applied to other data types.

Within the ﬁeld of computer vision, there has been a broad shift
away from user-designed features toward approaches that learn fea-
tures from data using neural networks (Agarwal et al., 2018). There
have been few attempts to use learned features in tree detection (Dai
et al., 2018) due to the need for large amounts of labeled training data,
which is often diﬃcult or impossible to collect in ecological contexts.
Overall, generalization of deep learning algorithms across applications
in airborne remote sensing remains a challenging task (Zhu et al.,
2017). A typical neural network has millions of parameters and is
therefore at risk of overﬁtting when using the small datasets usually
available for training. Given the diversity of trees, ﬁnding general
features will require a combination of large training datasets and al-
gorithmic approaches that allow the neural networks to learn the
combination of features that characterize trees across forest types.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not explicitly mention specific datasets such as MNIST, CIFAR, or ImageNet. However, it mentions that the model was trained with hand-annotated data and that data augmentation techniques were employed. Additionally, it refers to ImageNet mean normalization, suggesting that the model might have been initialized with ImageNet pre-trained weights. Furthermore, the text discusses the potential application of features learned from high-resolution data to lower resolution satellite data or even higher resolution UAV data. This implies that the datasets used in the deep learning pipeline likely consist of high-resolution airborne imagery, possibly including NEON sites, which were used for both pretraining and fine-tuning the model.