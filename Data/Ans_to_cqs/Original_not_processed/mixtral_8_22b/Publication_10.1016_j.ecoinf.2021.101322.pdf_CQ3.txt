Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Methods 

2.1. CNN training data

Data availability 

Salmon scale 9056 image dataset: 
doi:10.21335/NMDC-1050865887 
Expert  reading  of  extra  150 

335/NMDC-1462728994 

image  dataset:  doi:10.21 

CNN based architecture: EfficientNet: https://github.com/qubvel/ 

efficientnet 

Pre-trained  network  weights  (EfficientNet–B4):  https://github. 

com/qubvel/efficientnet/blob/master/efficientnet/weights.py 

Declaration of Competing Interest 

The authors declare that they have no known competing financial 
interests or personal relationship that could have appeared to influence 
the work reported in this paper. 

Acknowledgements 

We gratefully acknowledge valuable advice on the CNN architecture 
provided by Hyeongji Kim from the Institute of Marine Research, Ber-
gen, Norway. This project was funded in part by Research Council of 
Norway  projects  270966/O70  (COGMAR  -  Ubiquitous  cognitive com-
puter vision for marine services). 

References

References 

Aas, Ø., Einum, S., Klemetsen, A., Skurdal, J., 2011. Atlantic Salmon Ecology. John Wiley 

& Sons, pp. 1–467. 

Abadi, M., et al., 2016. TensorFlow: A System for Large-Scale Machine Learning. OSDI 

2016, Savannah, GA, 2-4 November 2016, pp. 265–283. 

Anon, 2008. SALSEA-Merge - Workshop on Digital Scale Reading Methodology, 

Trondheim, Norway, 8th to 10th September 2008, pp. 1–23. 

Anon, 2019. Rømt oppdrettslaks i vassdrag i 2018. Rapport fra det nasjonale 

overvåkningsprogrammet. Fisken og havet, særnr, pp. 4–2019. ISSN: 1894–5031.  

Aronsen, T., Bakke, G.O., Barlaup, B.T., Berntsen, J.H.H., Diserud, O.H., Fiske, P., 
Fjeldheim, P.T., Larsen, B.F., Glover, K., Heino, M.P., Husebø, Å., 2019. Rømt 
oppdrettslaks i vassdrag i 2018. Rapport fra det nasjonale overvåkningsprogrammet. 
Fisken og havet, særnr, 4–2019. ISSN: 1894–5031.  

Boehlert, G.W., 1985. Using objective criteria and multiple regression models. Fish. Bull. 

83, 103–117.

Krizhevsky, Alex, Sutskever, Ilya, Hinton, Geoffrey E., 2012. ImageNet classification with 
deep convolutional neural networks. In: Advances in Neural Information Processing 
Systems, 2, pp. 1097–1105. 

LeCun, Yann, Bengio, Yoshua, Hinton, Geoffrey, May 28, 2015. Deep learning. Nature 

521 (7553), 436–444. 

Liao, K., Xua, F., Zheng, J., Zhu, Q., Yang, G., 2014. Using different multimodel ensemble 
approaches to simulate soil moisture in a forest site with six traditional pedotransfer 
functions. Environ. Model. Softw. 57, 27–32. 
Mah´e, K., 2009. AFISA Automated FISh Ageing. 
Malde, K., Handegard, N.O., Eikvil, L., Salberg, A.B., July-August 2020. Machine 

intelligence and the data-driven future of marine science. ICES J. Mar. Sci. 77 (4), 
1274–1285. https://doi.org/10.1093/icesjms/fsz057. 

McGinnity, P., Prod¨ohl, P., Ferguson, A., Hynes, R., Maoil´eidigh, N.

´
O., Baker, N., 

Cotter, D., et al., 2003. Fitness reduction and potential extinction of wild populations

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there is no explicit mention of the specific data annotation techniques used in the deep learning pipeline. However, considering that the study uses Convolutional Neural Networks (CNN) for image analysis, it can be assumed that some form of image annotation technique has been employed. Common image annotation techniques include bounding box annotation, semantic segmentation, and instance segmentation. Without further details, it cannot be determined which specific method(s) were utilized in this case.