Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

libraries	 such	 as	 TensorFlow	 (Abadi	 et	al.,	 2016).	 Currently,	 the	

Raw count data are available from Enlighten: Research Data (https://

doi.org//10.5525/gla.researchdata.732).  Source  code  is  available 

from http://dx.doi.orgI10.5281/zenodo.2562058.

greatest challenge for implementing these algorithms for bespoke 

O R C I D 

applications is obtaining sufficiently large training datasets. In this 

regard,  citizen  scientists  have  a  clear  role  to  play.  While  we  have 

shown that the trained algorithm achieves high accuracy levels, it 

Colin J. Torney 

 https://orcid.org/0000-0003-1673-7835  

should  be  noted  that  the  algorithm  employed  the  crowd- sourced 

data  to  create  the  training  sets.  Hence,  both  methods  should  be 

R E F E R E N C E S

viewed  as  complementary  approaches  with  citizen  science  data 

forming the foundation for automated algorithms (Rey et al., 2017).

science counts of the survey and comparison to expert counts.

tee  that  the  approach  is  transferable  and  how  to  appropriately 

4 |  D I S CU S S I O N

filter the data may be affected by the wording of the guidelines, 

the image resolution and sizes used, or the set of volunteers that 

participate  in  the  project.  Other  more  sophisticated  approaches 

to processing citizen science data have been proposed (Swanson 

From our results, we see that both citizen science and deep learn-

et al., 2016); however, given the range of counts provided by the 

ing methods are capable of producing highly accurate image counts. 

volunteers  and  the  large  errors  we  observe  in  the  baseline  met-

Counting the wildebeest within the survey images is a difficult and 

rics  (c.  11%  and c.  9%  undercount  for  the  mean  and  median,  re-

time- consuming task. When collecting the census images, there are

within the image. While there remains the potential for bias in the 

three main steps.

expert count, we take this count to be the gold standard. Hence, our 

Firstly, we generated a training dataset by selecting 500 of the 

results are a comparison between the two novel methods employed 

survey images at random to be used exclusively for training. Images 

and a count by a single experienced expert, which could in principle 

were tiled into 864 × 864 subimages and then passed though a ver-

deviate from the unknown true count.

sion of the YOLO DCNN using pretrained weights from the COCO 

dataset provided by (Redmon & Farhadi, 2018). This process created 

a	list	 of	the	locations	of	potential	objects	in	each	image.	As	a	first	

3 |  R E S U LT S

pass, these results were filtered by discarding any object detections 

that did not correspond to an identification from the Zooniverse data. 

We  compared  the  accuracy  of  the  methods  by  calculating  the

Sauermann,  H.,  &  Franzoni,  C.  (2015).  Crowd  science  user  contribution 
patterns and their implications. Proceedings of the National Academy of 
Sciences, 112, 679–684. https://doi.org/10.1073/pnas.1408907112
Schneider, S., Taylor, G. W., & Kremer, S. C. (2018). Deep learning object 
detection  methods  for  ecological  camera  trap  data.  arXiv  preprint 
arXiv:1803.10842.

Simonyan,	 K.,	 &	 Zisserman,	A.	 (2014).	Very	 deep	 convolutional	 networks	
for large-scale image recognition. arXiv preprint arXiv:1409.1556.
Simpson,  R.,  Page,  K.  R.,  &  De  Roure,  D.  (2014).  Zooniverse:  Observing 
the world's largest citizen science platform. In Chin-Wan Chung (Ed.), 
Proceedings of the 23rd international conference on world wide web, ACM 
(pp.	1049–1054).	New	York,	NY:	ACM.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text mentions that libraries such as TensorFlow are used to implement these algorithms. Therefore, it can be inferred that one of the frameworks used to build the deep learning model is TensorFlow. However, the text does not provide information about other possible frameworks used, so it cannot be determined if additional frameworks like PyTorch were also utilized.