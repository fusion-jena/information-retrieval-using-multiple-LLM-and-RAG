Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 2. Full comparison of training time, prediction time, optimization time (i.e., time to properly
tune the model), and hardware for each model.

Model

Training Time
(Hours)

Prediction Time (Hours)

Optimization
Time (Hours)

Hardware

CNN

XGB

4

4

2.4. Validation

4

Unknown

Desktop with 64 Gb of
RAM and one Titan X
(Maxwell) GPU.

72—can be reduced by
distributing prediction to more
cores or more machines.

2

Desktop with 64 GB of
ram and 64 logical cores.

Table 1. List of input variables in the XGBoost model (XGB) and convolutional neural network
(CNN) models. Each variable lists its respective data source, equation, description, and, if needed,
citation. For information on Sentinel-2 band information not listed in the table, see:
[66] and
https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial.

Variable

Data Source

Model

ARI

Sentinel-2

XGB/CNN

Band 2
Band 3
Band 4
DEM

NDVI

dNDVI

NDWI

POLr

PSRI

Sentinel-2
Sentinel-2
Sentinel-2
ALOS

Sentinel-2

Sentinel-2

Sentinel-2

Sentinel-1

Sentinel-2

CNN
CNN
CNN
CNN

CNN

XGB

CNN

XGB

CNN

REIP

Sentinel-2

XGB/CNN

Equation
(cid:17)
(cid:16) B8
(cid:16) B8
B3
B2

–

(cid:17)

-
-
-
-
(B8− B4)
(B8 + B4)

Description

Keywords: wetlands; Sentinel-1; Sentinel-2; Google Earth Engine; remote sensing; Alberta;
segmentation convolutional neural nets; XGBoost; land cover; SAR; machine learning

1. Introduction

Machine learning—a method where a computer discovers rules to execute a data processing
task, given training examples—can generally be divided into two categories: Shallow learning and
deep learning methods [1]. Deep learning uses many successive layered representations of data
(i.e., hundreds of convolutions/ﬁlters), while shallow learning typically uses one or two layered
representations of the data [1]. Deep learning has shown great promise for tackling many tasks such as
image recognition, natural language processing, speech recognition, superhuman Go playing, and
autonomous driving [1–3].

Remote Sens. 2020, 12, 2; doi:10.3390/rs12010002

www.mdpi.com/journal/remotesensing

right by 90 degrees, ﬂipped horizontally or vertically, or left as is. Since marsh and swamp wetland
classes were somewhat rarer than the other classes, during batch creation (using a batch size of 24),
we ensured that there were at least six patches containing each of those labels. Using a geometrically
decaying learning rate, the model was trained for 110 epochs, where each epoch was composed of 4800
training samples. Model training took approximately 3–4 h and prediction over all the study area at
10 m resolution took a similar amount of time. Training and prediction was done on a desktop with
64 Gb of RAM and one Titan X (Maxwell) GPU. A full comparison of computation time between the
models can be seen in Table 2.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit details about the deployment process of the trained deep learning model. However, it mentions that the model was trained using a geometrically decaying learning rate for 110 epochs, with each epoch consisting of 4800 training samples. It also states that the training and prediction processes were carried out on a desktop with 64 GB of RAM and one Titan X (Maxwell) GPU. Unfortunately, no specific information regarding model serialization or platform selection is mentioned in the provided context.