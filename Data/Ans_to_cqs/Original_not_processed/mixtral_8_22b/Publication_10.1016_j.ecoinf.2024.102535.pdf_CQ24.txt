Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Image classification 
Deep learning 
Hydrothermal vents 
Uncertainty analysis

The batch size was 32, and the early stopping procedure was used to 
avoid over-fitting. The patience parameter, which controls the number 
of epochs without improvements in the validation loss, was set to 10. 
Each network, with a particular architecture and considering a specific 
substratum characterization, was trained and executed three times, each 
time with a different (random) initialization of the trainable parameters 
and with a different data fold. As already mentioned, the results shown 
in  the  next  section  are  averages  of  those  three  executions.  Data 
augmentation was applied to all extracted patches: a 90∘  rotation and 
vertical and horizontal flips. 

4.4. Performance metrics

the selected architectures using images obtained from three distinct sites within the Lucky-Strike vent field and 
assessed the models’  performances on-site as well as off-site. To investigate complementarity, we evaluated a 
classification decision committee (CDC) built as an ensemble of networks in which individual predictions were 
fused  through  a  majority  voting  scheme.  The  experimental  results  demonstrated  the  suitability  of  the  deep 
learning models for deep-sea substratum classification, attaining accuracies reaching up to 80% in terms of F1- 
score. Finally, by further investigating the classification uncertainty computed from the set of individual pre-
dictions  of  the  CDC,  we  describe  a  semiautomatic  framework  for  human  annotation,  which  prescribes  visual 
inspection of only the images with high uncertainty. Overall, the results demonstrated that high accuracy values

decision  committee,  which  combines  the  outcomes  of  the  different 
network  architectures  into  a  single  decision.  We  then  visually  assess 
some of the networks’  activation maps, using an explainable artificial 
intelligence (XAI) technique to better understand the inference process. 
Finally, we analyze the classification uncertainty derived from the set of 
individual  predictions  of  the  committee  members  and  show  how  the 
uncertainty  measures  can  be  exploited  in  a  semiautomatic  decision 
process. 

5.1. Accuracy of the deep learning networks 

Table  3  shows  the  F1-scores  obtained  in  the  image  classification 
experiments. Since the MS dataset does not contain basalt samples in 
lithology nor B/P lava in morphology, for the comparative analysis to be 
fair,  such  classes  were  not  taken  into  account  during  training  and 
testing.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To handle randomness in the deep learning pipeline, particularly related to the random seed value, several strategies have been employed in this study. Firstly, each network is trained and executed three times, each time with a different (random) initialization of the trainable parameters and with a different data fold. This approach helps mitigate the impact of any one specific random initialization or data split on the overall performance of the model. Secondly, the use of early stopping procedure with a patience parameter set to 10 also contributes to handling randomness. Early stopping is a form of regularization used to avoid overfitting by halting the training process before it has a chance to converge to a minimum that may provide poor generalization. Lastly, data augmentation techniques like rotations and flips are applied to all extracted patches. These techniques help increase the diversity of the training data and reduce the risk of overfitting due to limited data variability.