Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

SDM 

Training setup 

Modeling package 

threshold values from 0 to 1. Table 5 summarizes the evaluation criteria 
for the AUC and TSS metrics for the objective comparison of the per-
formances of the SDMs. 

Elapid (Anderson, 2023) 

3. Results 

SRE 

GLM 

GAM 

MaxEnt 

RF 

GBM 

XGB 

LGBM 

ANN 

SDP- 

EPL

2.4.3. Evaluation metrics 

The predictive power of an SDM is measured by how accurately the 
model classifies given environmental variables at presence and absence 
locations. We employ four standard evaluation metrics to quantitatively 
assess the SDMs: sensitivity, specificity, the true skill statistic (TSS), and 
the  area  under  the  receiver  operating  characteristic  curve  (AUC) 
(Allouche et al., 2006). These metrics are calculated using a confusion 

Fig. 3. Experimental workflow for species distribution prediction.  

EcologicalInformatics79(2024)1024076E. Kim et al.                                                                                                                                                                                                                                     

Table 3 
Training settings for the SDMs used in this study.  

SDM 

Training setup 

Modeling package

EcologicalInformatics79(2024)1024078E. Kim et al.                                                                                                                                                                                                                                     

ranged from 50 to 400, showing higher values than ANN, but at K = 800, 
AUC  decreased  significantly.  When  K  = 200,  the  AUC  gradually 
improved  as  the  number  of  training  epochs  increased,  achieving  the 
highest score overall. 

4. Discussion

0.953 

0.789 

0.799 

0.472 

0.841 

0.576 

The best scores are indicated in bold text. The second-best scores are underlined. 
AUC is the area under the receiver operating characteristic curve. TSS is the true 
skill  statistic.  SDP-EPL  indicates  the  proposed  ensemble  teacher  model-based 
SDM. SDP-SPL indicates a single-teacher model-based SDM. Bracket indicates 
performance improvement compared to ANN. 

the distributions of the target species by varying the number of pseudo- 
labeled data points (K) added to DL from 50 to 800. Figs. 4, 5 and 6 show 
the changes in the AUC for SDP-EPL according to the training epoch of 
the student model for L. catesbeianus, A. caudatus and M. alba, respec-
tively. Note that we initially train SDP-EPL only with labeled data for the 
first 100 epochs, leading to the same performance curves for the models 
with different values of K. We iteratively add pseudo-labeled data for the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors use four standard evaluation metrics to assess the performance of their Species Distribution Models (SDMs): sensitivity, specificity, the True Skill Statistic (TSS), and the Area Under the Receiver Operating Characteristic Curve (AUC). Sensitivity measures the proportion of actual positives that were correctly identified, while specificity measures the proportion of negatives that were correctly identified. The True Skill Statistic (TSS) combines both sensitivity and specificity into one metric, providing a more comprehensive measure of classification accuracy. Finally, the Area Under the Receiver Operating Characteristic Curve (AUC) provides a measure of the model's ability to distinguish between positive and negative classes.