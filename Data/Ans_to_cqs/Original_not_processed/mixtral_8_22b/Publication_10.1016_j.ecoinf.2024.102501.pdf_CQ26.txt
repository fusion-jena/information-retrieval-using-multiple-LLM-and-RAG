Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

In addition,  in the prediction  of dissolved oxygen in  water, (Chen 
et  al.,  2020)  not  only  applied  water  quality  parameters  but  also 
considered parameters such as temperature, humidity, and atmospheric 
pressure in the air as input variables for the model, providing ideas for 
subsequent research. 

At last, for the dataset as listed in Table 1, and, three different data 
processing methods were trained and tested using the proposed method, 

4. Discussions 

Table 7 
Medians of measured versus computed DO concentration.  

The  above  results  and  analyses  show  that  traditional  machine 
learning  methods  (SVR)  and  deep  learning  methods  (LSTM)  can  be 
adapted  to  address  the  problems  of  poor  generalization  ability,  local 
optimum, underfitting, and overfitting of conventional models to predict 
DO concentration successfully. The machine learning and deep learning 
literature also discuss the prediction of DO concentration. For example, 

Models

dataset as discussed in this article because it can potentially cause poor 
predictive performance (Liu et al., 2014).

2.2. Data preprocessing 

As shown in Fig. 2, the data does not exhibit a regularity and that the 
data has large differences in dimension and magnitude values of various 
parameters. Such differences would lead to problems such as substantial 
noise interference, large fluctuations, strong concealment, and difficulty 
in data handling. Consequently, the data was normalized to reduce the 
impact  of  these  large  differences.  The  normalization  formula  is 
expressed in Eq. (1). 

′ =

Yi

Yi (cid:0) Ymin
Ymax (cid:0) Ymin

(1)  

where Yi is the i-th sample value, Ymax is the maximum value, Ymin  is the 

′
minimum value, and Yi
standardization formula is expressed in Eq. (2). 

is the normalized value of the i-th sample. The 

Xi

* =

Xi (cid:0) X
Xs

in which, 

(2)

principal component analysis (Xie et al., 2022), RF (Huan et al., 2021), 
and  XGBoost  (Wu  et  al.,  2021)  to  select  key  factors  for  input  data, 
thereby reducing data dimensionality and information redundancy, to 
improve  the  predictive  performance  of  DO  models.  Before  modeling, 
clustering algorithms are used to group datasets with different periodic 
changes, whereby the grouped datasets are modeled separately. This is 
also  a  commonly  used  data  preprocessing  method  in  combinatorial 
modeling(Shi et al., 2019; Cao et al., 2021a; Huan et al., 2017). For the 
raw time series data used in modeling, direct modeling often makes it 
difficult to fully mine and utilize various time-frequency feature infor-
mation.  Therefore,  methods  such  as  empirical  mode  decomposition 
(EMD)  and  wavelet  transform  (WT)  are  used  for  denoising  and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, several techniques are mentioned to address data bias or improve the predictive performance during the preprocessing stage of the deep learning pipeline. However, none of them directly correspond to stratified splitting, oversampling, undersampling, or diverse data collection. Instead, the context focuses on other aspects of data preprocessing.

One technique mentioned is normalization, which aims to reduce the impact of large differences in dimensions and magnitudes among various parameters. Normalization is achieved by applying formulas like those presented in equations (1) and (2).

Additionally, principal component analysis (PCA) is employed to select key factors for input data, thereby reducing data dimensionality and information redundancy. PCA helps improve the predictive performance of DO models.

Clustering algorithms are also utilized to group datasets with different periodic changes. By doing so, the grouped datasets can be modeled separately, which is another common data preprocessing method in combinatorial modeling.

Lastly, methods such as empirical mode decomposition (EMD) and wavelet transform (WT) are used for denoising and extracting features from raw time series data. These techniques help fully mine and utilize various time-frequency feature information, ultimately improving the overall performance of the deep learning pipeline.