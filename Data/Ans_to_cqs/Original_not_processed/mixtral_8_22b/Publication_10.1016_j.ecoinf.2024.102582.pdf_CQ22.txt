Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Calendar (year) 

Userâ€™s accuracy (%) 

Total accuracy (%) 
Kappa coefficient 

Impervious water surface 
Water 
Forest 
Farmland 
Mangrove forest 
Other 

1985 

83.31 
85.63 
85.00 
82.66 
81.31 
80.35 
83.04 
0.825 

1990 

84.65 
87.01 
86.03 
83.30 
82.32 
82.06 
84.21 
0.841 

1995 

86.00 
88.30 
87.02 
85.01 
84.07 
82.31 
0.853 
0.852 

2000 

87.02 
89.30 
88.65 
87.02 
84.64 
82.69 
86.57 
0.853 

2005 

88.34 
90.63 
90.01 
87.03 
86.61 
84.60 
87.86 
0.866 

2010 

89.30 
91.31 
90.63 
88.30 
87.08 
85.31 
88.66 
0.875 

2015 

91.07 
92.18 
91.26 
89.11 
87.43 
86.03 
89.52 
0.887 

2020 

91.61 
93.05 
92.03 
89.34 
88.37 
86.62 
90.13 
0.899  

analyze  changes  in  mangroves  along  the  southeastern  coast  of 
China and the influencing factors. 

3.2. Spatial analysis and transfer path of mangrove forest

5.4. Limitations and future studies 

Due to the limitations of data sources and classification methods (Jia 
et al., 2023), this may largely affect the in-deep understanding of various 
mangrove species status in China and globally. In addition, although this 
study  discussed  the  effects  of  governmental  policies  on  long-term 
mangrove  evolution,  it  was  still  difficult  to  quantify  the  contribution 
rate of policies on mangrove conservation and restoration. Future dis-
cussion  and  in-deep  study  of  quantifiable  policy  factors  as  well  as 
improved  image  resolution  and  machine  learning  approaches  toward 
accurate identification of mangrove species will be great significance for 
dynamic monitoring and evaluation of mangrove interspecies evolution. 

6. Conclusions

3.3. Landscape fragmentation index 

To  evaluate  the  number  of  land  cover  types,  distances  between 
patches of the same land cover type, and the degrees of aggregation and 
segmentation, we selected four commonly used landscape metrics: the 
number of patches per area (km2) (patch density, PD), the percentage of 
landscape area occupied by the largest patch (largest patch index, LPI), 
the spatial context of individual patches weighted by relative patch area 
(area-weighted  mean  Euclidean  nearest-neighbor  distance,  ENN_AM), 
and the degree of aggregation of patches of the same type (aggregation 
index, AI). These indices are described in greater detail, including their 
formulas and ecological significance, in the Fragstats v4.2 help files and

and total accuracy metrics for landscape classification were higher from 
2015  to  2020  than  from  1985  to  1995  (Table  2).  Furthermore,  the 
application of images with 30-m spatial resolution for remote sensing 
monitoring of mangrove forests in a previous study led to limited clas-
sification accuracy, with some small patches often being neglected (Liu 
et al., 2005). These limitations may have influenced the results of our 
finer-scale analyses.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide explicit information about the specific metrics used to evaluate the performance of a deep learning model. However, based on the given table, it can be inferred that the metrics used include user's accuracy (%), total accuracy (%), and Kappa coefficient. User's accuracy is also known as precision or positive predictive value, which measures the proportion of true positives among all predicted positives. Total accuracy represents the overall correctness of the classifier, while the Kappa coefficient is a statistical measure of agreement between two raters who each classify items into mutually exclusive categories. It takes into account the possibility of the agreement occurring by chance.

The table shows these metrics for different years, indicating that they might have been used to assess the performance of a deep learning model over time. However, without more specific details, it cannot be confirmed if these are the only metrics used or if other common metrics like recall (also known as sensitivity or true positive rate) or F1 score (a harmonic mean of precision and recall) were also considered.