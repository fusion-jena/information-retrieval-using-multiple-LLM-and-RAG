Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

WT-HMM using varying dataset sizes over 10 runs.

Sequel to training the two HMMs independently, HMM1 and HMM2 
are combined to form an ergodic-type HMM with 8 states and 4 mixture 
weights. One of the HMMs is represented by the first 1–4 states, and the 
other  HMM  is  represented  by  the  following  5–8  states.  Specifically, 
states 1–4 depict the waveform of blue whale vocalizations while states 
5–8  represent  the  noise  signal.  Subsequently,  the  feature  vectors 
extracted from the test datasets are updated using the trained Gaussian 
parameters to produce refined feature vectors. The V-alg employs these 
refined feature vectors, along with T  and π, to classify the test dataset as 
either blue whale vocalizations or noise. It is noteworthy that that the V- 
alg switches from states 1–4 to states 5–8 with equal transition proba-
bilities. Table 1 shows the parameters used for WT-HMM simulation. 

3.2. Performance evaluation metrics

The observed increasing trend in both accuracy and F1-score for the 
WT-HMM across different dataset sizes aligns with findings in similar 
studies.  Previous  research  in  bioacoustics  has  highlighted  the  impor-
tance of dataset size in training robust models for cetacean vocalization 
classification  (Lu  et  al.,  2021;  Ogundile  et  al.,  2020;  Ogundile  et  al., 
2021; Usman et al., 2020). Larger datasets provide models with more 
diverse examples, aiding in the generalization of learned features and 
patterns. The consistent improvement in accuracy and F1-score for both 
recording periods indicates that the WT-HMM is not only effective for 
smaller datasets but also scales well as the dataset size increases. This 
scalability  is  a  crucial  characteristic,  especially  in  bioacoustic  moni-
toring where datasets can vary significantly in size (Xie et al., 2020).

4. Discussion 

This section discusses the findings and results of the study on blue 
whale vocalizations, considering the performance of the proposed WT- 
HMM  across  varying  dataset  sizes,  how  it  compared  to  other  x-HMM 
detectors,  and  its  comparison  with  other  machine  learning  detectors. 
The discussion is based on relevant studies from the literature.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, we cannot directly determine the specific data format used in the deep learning pipeline. However, since the study focuses on blue whale vocalizations, it can be inferred that the data format used is likely audio files. The study mentions extracting feature vectors from the test datasets and updating them using trained Gaussian parameters, which suggests that the input data is processed into numerical representations suitable for analysis. Additionally, the study compares the proposed WT-HMM detector with other machine learning detectors, further supporting the assumption that the data format used is compatible with various machine learning algorithms.