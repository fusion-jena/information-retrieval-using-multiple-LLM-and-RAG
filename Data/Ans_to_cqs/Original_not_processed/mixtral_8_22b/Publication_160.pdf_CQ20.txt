Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

from underwater video using neural networks. Opt. Express 13, 8766. https://doi.
org/10.1364/OPEX.13.008766.

Masters, D., Luschi, C., 2018. Revisiting Small Batch Training for Deep Neural Networks.
McGill, B.J., Dornelas, M., Gotelli, N.J., Magurran, A.E., 2015. Fifteen forms of biodi-

versity trend in the Anthropocene. Trends Ecol. Evol. 30, 104–113. https://doi.org/
10.1016/j.tree.2014.11.006.

Mehdipour Ghazi, M., Yanikoglu, B., Aptoula, E., 2016. Open-Set Plant Identification

Using an Ensemble of Deep Convolutional Neural Networks. Working Notes of CLEF.
Mishkin, D., Sergievskiy, N., Matas, J., 2016. Systematic evaluation of CNN advances on
the ImageNet. Comput. Vis. Image Underst. 161, 11–19. https://doi.org/10.1016/j.
cviu.2017.05.007.

Niculescu-Mizil, A., Caruana, R., 2005. Predicting good probabilities with supervised

60.64
63.82
65.77
66.30

60.17
63.57
65.54
65.94

Table 3
Performances of different ResNet architectures on validation and test sets. ResNetX-Y is written so that X indicates the network's depth and Y the input size. In bold
the best value for each metric.

Network -patch Size

Batch size

Validation set

Test set

Macro-F1

Top-1 accuracy

Micro-F1

Macro-F1

Top-1 accuracy

Micro-F1

ResNet152–224
ResNet50–128
ResNet18–128
ResNet18–224
Ensemble

16
128
128
200
128

37.45
52.04
51.40
54.93
60.56

62.38
64.07
63.90
66.70
70.60

60.46
63.85
63.88
66.44
70.35

38.26
52.27
51.62
53.93
60.38

61.71
64.35
63.60
66.30
70.54

60.09
63.89
63.44
65.94
70.37

performances by 4.43 points (see Table 3). The biggest difference be-
tween our network and the original version of the local-SPP lies in the
fact that we concatenated the four 512-dimension feature vectors, in-
stead of the max-pooling layer, which enabled the information con-
tributed by each patch size to be processed by the consecutive MLP
without loss.

7.2. Tuning the architecture

The training procedure of ResNet18, notably the batch size para-
meter, had a great impact on classification performance. This was in-
dicated by the difference in micro-F1 values produced by a ResNet18
trained with batch size 128 (63.44; see Table 3) and a ResNet18 train

Fig. 9. Predicted vs observed percentages of sludge, bryozoans and major builders. Pearson correlations: Sludge = 0.54, Bryozoans = 0.61, Major builders = 0.82.

11

G. Marre, et al.

Ecological Informatics 59 (2020) 101110

A ResNet152 was used as the baseline for classification perfor-
mance. This network was initially programmed using pre-trained
weights lifted from the ImageNet challenge. The top fully-connected
layer was replaced with a layer using ReLU activation, followed by a
dropout layer and a softmax layer, with outputs corresponding to the
number of classes (here 61). Firstly, the top layer was trained alone;
using features extracted from the convolutional layers, a Stochastic
Gradient Descent (SGD) with a learning rate of 10−3, and weight decay
rate set to 5 × 10−4. The whole network was then trained with SGD;

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no explicit mention of the specific hardware resources used for training the deep learning models in the given context. Therefore, it cannot be determined whether GPUs, TPUs, or other hardware resources were utilized during the training process.