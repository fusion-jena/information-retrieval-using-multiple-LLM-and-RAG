Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.7. Subsetting background points 

We  made  three  random  selections  of  background  points  from  the 
training dataset for use during model construction. First, we made the 
“1×” selection, which selected the same number of background points as 
presences in the training dataset. Second, we made the “10×” selection, 
which selected a number of background points equal to ten times the 
number of presences in the training dataset. Third, we made the “10 K” 
selection, which selected 10,000 background points from the training 
dataset.  We  used  this  approach  to  maintain  consistency  across  back-
ground  points  used  to  train  each  model  so  there  was  no  variation  in 
model results due to variation in the response variable. 

2.8. Training individual models

Fig. 2. Diagram showing the procedure used to build models. (a) Obtain presences (red circles) and generate background points (black triangles). (b) Separate data 
into folds. (c) Set aside one fold to use as an external evaluation dataset and keep the remaining folds as training data. (d) Perform scale optimization for envi-
ronmental covariates: calculate focal statistics for each covariate using a moving window of radius equal to each scale to be tested, then compare scales using t-tests. 
(e) Subsample background points in the training data to create three datasets: one with the number of background points equal to the number of presences (1×), one 
with a number of background points equal to 10 times the number of presences (10×), and 10,000 background points (10K). Keep the number of presences the same. 
(f) Train component models separately using each background point subsample. (g) Evaluate component models using the evaluation dataset (using AUC and TSS).

4.2. Ensemble models

to model performance by a single component model built with subop-
timal training data. However, RF outperformed all the ensemble models, 
suggesting  that  if  researchers  use  a  single  modeling  approach,  they 
should consider using RF. It should be noted that we found RF to be more 
sensitive to the number of background points used to train the model 
than  other  modeling  methods.  However,  researchers  or  practitioners 
might choose to use a single modeling approach that is found to be less 
sensitive to the number of background points, like a GLM or MaxEnt. In 
this situation, since the gain in performance is minimal, the decision on 
how many background points to use might be instead made to minimize 
computation time and answer time-sensitive questions related to con-
servation  actions.  Nevertheless,  using  an  ensemble  of  models  helps 
overcome any issues that any single model might have, as demonstrated

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not provide information about a deep learning model. Instead, it discusses the process of building models using Random Forest (RF), Generalized Linear Model (GLM), and Maximum Entropy (MaxEnt) methods. These models are likely used for species distribution modeling based on environmental variables. The purpose of these models is to predict suitable habitats for a given species, which can inform conservation efforts.

The authors describe a methodology involving multiple steps, including obtaining presence data (locations where the species has been observed) and generating background points (randomly sampled locations within the study area). They also mention separating the data into folds for cross-validation, optimizing the spatial scale of environmental variables, subsampling background points, and evaluating the performance of component models using metrics such as Area Under the Curve (AUC) and True Skill Statistic (TSS).

In summary, the purpose of the described models is to predict suitable habitat for a target species, rather than performing tasks typically associated with deep learning models, such as image classification, object detection, or semantic segmentation.