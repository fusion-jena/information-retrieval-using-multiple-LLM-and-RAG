Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  next step  was  to  gather  standard  visual  information  and  low- 
level  image  features  from  the  datasets  that  include  traits  such  as 
colour, texture, shape, etc. (Shih et al., 2001). These features can be used 
by classifiers or deep learning models for image segmentation, image 
classification  and  object  detection.  There  are  various  techniques  for 
conducting  image  feature  extraction.  With  advancements  in  machine 
learning,  specifically  deep  learning  and  convolution  neural  networks 
(CNNs), feature extraction from images can be performed automatically 
to obtain high levels of classification accuracy (Acharya and Khoshel-
ham, 2020). Therefore, we used a deep-learning model to extract fea-
tures  of  our  image  backgrounds  for  training  a  classifier  model.  We 
adopted  a  ResNet-50  model  (He  et  al.,  2016)  for  extracting  image 
background features for classification. ResNets (Residual Networks) are

easy to train with reduced complexity, even though they have deeper 
layers than CNN models, because of the presence of skip connections 
between the input and output of each block (He et al., 2016). ResNet has 
different variants with a variety of convolution layers. We trialled three 
depths, ResNet-18, (cid:0) 50 and (cid:0) 101, and compared their training times 
and validation accuracies. They behaved similarly but ResNet-50 had a 
marginally  higher  validation  accuracy  (Section  3.1.1)  leading  us  to 
choose it for feature extraction.

ResNet-50 is made up of five convolutional blocks stacked on top of 
one  another  (Fig.  5).  The  image  features  are  extracted  from  the  fully 
connected layers pre-trained with the ImageNet database (https://imag 
e-net.org/index.php). The input to the network is an image of 224x224 

EcologicalInformatics77(2023)1022654S. Singha Roy et al.

(<i>eristalis tenax</i>) as a crop pollinator in New Zealand. NZ Plant Protect., 72: 
221–230. URL https://nzpps.org/_journal/index.php/nzpp/article/view/304. 
Jena, B. et al., 2021. Artificial intelligence-based hybrid deep learning models for image 
classification: The first narrative review. Comput. Biol. Med., 137: 104803. ISSN 
0010–4825. https://www.sciencedirect.com/science/article/pii/ 
S0010482521005977. 

Joly, A., et al., 2019. Overview of lifeclef 2019: Identification of amazonian plants, south 

& north american birds, and niche prediction. In: Experimental IR Meets 
Multilinguality, Multimodality, and Interaction. Springer International Publishing, 
Cham, ISBN 978-3-030-28577-7, pp. 387–401. https://doi.org/10.1007/978-3-030- 
28577-7_29. 

Jones, L.E., Leather, R.S., 2012. Invertebrates in urban areas: a review. EJE. ISSN:

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide specific details about the data annotation techniques used in the deep learning pipeline. However, generally speaking, there are several common data annotation techniques used in deep learning pipelines for tasks like image segmentation, image classification, and object detection. Some popular methods include:

1. Bounding Box Annotation: This technique involves drawing rectangular boxes around objects within an image to identify them. It is commonly used for object localization and detection tasks.

2. Semantic Segmentation: This method assigns a label or category to every pixel in an image, allowing for precise identification of different regions or objects within the image.

3. Instance Segmentation: Similar to semantic segmentation, this approach also labels individual pixels; however, it distinguishes between instances of the same class, making it useful for identifying multiple occurrences of similar objects.

4. Polygon Annotation: This technique uses polygons instead of rectangles to outline complex shapes more accurately. It is often employed when dealing with irregularly shaped objects.

5. Landmark Annotation: Also known as key point annotation, this method identifies specific points on an object, which can help determine its size, position, orientation, or pose.

Without explicit mention in the provided context, it cannot be confirmed which specific data annotation techniques were utilized in the described deep learning pipeline.