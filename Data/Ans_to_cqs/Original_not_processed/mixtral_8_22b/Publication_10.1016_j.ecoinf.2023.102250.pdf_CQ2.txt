Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

iii.  Experimental group III: Take 40%, 60%, and 80% of the original 
dataset as the new dataset, and then replace 80% of these three 
datasets with the generated images. 

Table 6 presents the detailed division of the datasets. The datasets 
were  split  into  train  and  test  sets  in  an  8:2  ratio,  and  all  evaluation 
metrics were computed on the test set. 

To conduct the classification experiments on all datasets, we utilized 
ResNet18, VGG16, and MobileNetV2 as the base classifier model. The 
experiments  were  conducted  with  consistent  hyperparameters, 
including a learning rate of 0.001, a batch size of 32, and 40 epochs. 

The  classification  results  of  Experiment  Group  I  are  presented  in 
Fig.  10.  The  bar  graphs  represent  the  Top-1  accuracy  of  the  Mobile-
NetV2, ResNet18, and VGG16 models on the six datasets. The fold line 
corresponds to their respective Top-5 accuracy. When 1000 generated

extended with time and time-frequency attention mechanisms. In: Conference and 
Labs of the Evaluation Forum. 

Shorten, Connor, Khoshgoftaar, Taghi M., jul 2019. A survey on image data 

augmentation for deep learning. J. Big Data 6 (1). https://doi.org/10.1186/s40537- 
019-0197-0. URL doi:10.1186%2Fs40537-019-0197-0. 

Simonyan, Karen, Zisserman, Andrew, 2014. Very Deep Convolutional Networks for 

Large-Scale Image Recognition. arXiv preprint arXiv:1409.1556. 

Sohn, Kihyuk, Lee, Honglak, Yan, Xinchen, 2015. Learning structured output 

representation using deep conditional generative models. Adv. Neural Inf. Proces. 
Syst. 28. 

EcologicalInformatics77(2023)10225016Y. Fu et al.

number  of  transformed  spectrograms,  adversely  affecting  the  classifi-
cation accuracy of CNN models. To improve the accuracy of birdsong 
classification, data augmentation (Shorten and Khoshgoftaar, 2019) can 
be used to enhance the dataset and introduce the dynamic convolutional 
kernel structure to improve the network feature extraction ability.

Fig. 1. The Proposed Framework.  

Fig. 2. Data preprocessing process.  

feature maps and weights obtained through the two convolutional layers 

′
in the residual block. The resulting feature map, denoted as X
, is then 
input into the upsampling layer to double its size and obtain Xout. These 
skip connections enable the neural network to effectively capture the 
relationship between input and output features, learn deeper represen-
tations, and enhance the quality of the generated images. 

The attention mechanism enables the network to selectively focus on 
essential parts of the feature map and enhance the weights in specific 
channels or spatial regions based on calculated attention scores. It ac-
quires  essential  information  while  enhancing  the  quality  and  level  of 
detail in the generated images. Fig. 4 illustrates the attention mecha-
nism’s model structure. 

The Convolutional Block Attention Module (CBAM) consists of both

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the study primarily focuses on image data for deep learning applications. Specifically, the research involves generating synthetic bird images from spectrograms and utilizing them for training various CNN models such as ResNet18, VGG16, and MobileNetV2. Therefore, the primary data format used in this deep learning pipeline is image data. However, it should be noted that the initial source of the data comes from audio recordings of birdsongs, which are converted into spectrograms before being processed further. Thus, although not directly mentioned, audio data also plays a role in the overall pipeline. There is no mention of other data formats like CSV or video in the provided context.