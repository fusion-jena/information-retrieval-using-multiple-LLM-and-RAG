Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Detection rates in the laboratory or at test data sets
of more than 90% can generally not be achieved in the
field under real, constantly changing conditions. For
this reason, a feedback mechanism is provided, which
involves the user in the optimization of the system, but
at  the  same  time  minimizes  the  labeling  effort  to  be
made  manually.  This  is  known  as  active  learning.  In
the actual application, the system will, at certain inter-
vals, forward images to humans, and after the annota-
tion these images will be used to train a classifier iter-
atively. Evaluation is carried out with a retained test set
of images annotated manually.

Monitoring  devices  will  likely  also  detect  species
that are unknown for the recognition system. There-
fore, novelty detection is relevant [2, 3] which allows

20. D. Korsch and J. Denzler, “In defense of active part se-
lection for fine-grained classification,” Pattern Recog-
nit. Image Anal. 28 (4), 658–663 (2018).

21. D. Korsch, P. Bodesheim, and J. Denzler, “Classifica-
tion-specific  parts  for  improving  fine-grained  visual
categorization,” in German Conference on Pattern Rec-
ognition (GCPR) (2019), pp. 62–75.

22. A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Ima-
geNet  classification  with  deep  convolutional  neural
networks,” in Advances in Neural Information Processing
Systems (NIPS) (2012), pp. 1097–1105.

23. T. Y. Lin, P. Dollár, R. Girshick, K. He, B. Hariharan,
and S. Belongie, “Feature pyramid networks for object
detection,”  in  Proceedings  of  the  IEEE  Conference  on
Computer  Vision  and  Pattern  Recognition  (2017),
pp. 2117–2125.

(Fig. 10).  A  camera  with  20  megapixel  resolution  is
used. Images with LED flash are taken at regular, pro-
grammable intervals, typically several minutes. Subse-
quent analysis breaks down the image into dark areas
that are approximately the area of the moths to be clas-
sified. Areas that are too small are ignored, and areas
that are too large are examined to see if they remain for
only  one  period  of  time  (possibly  feeding  birds),
remain unchanged (e.g., leaf blown on), or continue to
be seen the next night (dirt on the screen). For such
images, a message is generated to trigger human action
if necessary (e.g., cleaning the screen).

body  shape,  and  others  can  be  determined  from  it.
This data stream is transmitted for preprocessing to a
powerful  single-board  computer  on  the  base  station.
There, the data stream is broken down into its individ-
ual components and analyzed. Recordings are sorted
out  that  do  not  contain  animal  images  due  to  false
alarms from the motion detector (typically 40–70%).
A further reduction of the data volume is achieved by
masking out image areas where no animals can appear.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, there are several postprocessing steps that can be performed depending on the specific requirements of the project. Here are some common postprocessing steps mentioned in the given context:

1. False alarm filtering: The first step involves sorting out recordings that do not contain animal images due to false alarms from the motion detector. This helps reduce the amount of data that needs to be processed further.
2. Masking irrelevant image areas: Another step involves masking out image areas where no animals can appear. This reduces the data volume even further and makes processing faster and more efficient.
3. Breakdown of images: After filtering out irrelevant data, the remaining images are broken down into their individual components and analyzed. This could involve breaking down the image into dark areas that are approximately the size of the objects being classified.
4. Iterative training: Once the initial training phase is complete, the system may use a feedback mechanism to improve performance over time. This involves forwarding certain images to humans for manual annotation and then using those images to train the classifier iteratively.
5. Evaluation: Finally, evaluation is carried out with a retained test set of images that have been manually annotated. This helps assess the accuracy and effectiveness of the trained model.

It should be noted that the exact postprocessing steps required will depend on the specific goals and constraints of the project. However, the above steps provide a general overview of some common postprocessing techniques used in machine learning projects involving image classification.