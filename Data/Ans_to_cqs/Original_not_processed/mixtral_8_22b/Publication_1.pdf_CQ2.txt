Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We are primarily focused on processing and analyzing large, high-
bit-rate datasets such as audio (high sample rate) and image (large 
amount  of  data  per  sample)  streams.  Other  environmental  sensor 
data, like temperature or air quality, utilize much lower data rates. 
For example, to record bird vocalizations, we typically record 16-
bit stereo audio at a moderate sample rate of 22,000 samples per 
second (22 kHz) at each monitoring site. In another example, for 
tracking  populations  of  invasive  snakes  we  ingest  2048-by-1536 
8-bit 4:2:2 color images taken at least once every thirty seconds at 
each  site.    Data  are  often  collected  with  a  30%  duty  cycle  over 
each day, and light (lossless or near-lossless) data compression is 
employed. A typical survey point can easily generate more than 5 
gigabytes (GB) of data per day, and an entire monitoring project, 
integrating  multiple  sites  in  a  region  over  a  multiple-month

Thus  far,  leveraging  our  past  experience  in  DL  for  consumer 
applications, we have applied DL straightforwardly to our sensor 
data to great effect. We have employed deep convolutional neural 
networks (CNNs) and deep feed forward neural networks (DNNs) 
to  audio  spectrogram  and  image  data,  mostly  to  classify  the 
presence  or  absence  and  activity  rates  of  a  number  of  different 
endangered  species,  or  in  some  cases,  the  sounds  of  birds 
colliding with energy infrastructure. In total, we have the ability to 
classify  dozens  of  species  signals  and  event  types  across  our 
ongoing projects, and we aim to scale this up to encompass whole 
communities.  Depending  on  the  sensor  type  and  the  species,  we 
have experienced a 100x to 1000x reduction in the amount of data 
required  to  be  manually  reviewed,  when  integrated  with  our 
auditing UI and our back-end power analysis.

DL  grew  out  of  the  fields  of  representation  learning,  neural 
networks,  and  computational  neuroscience.  It  employs  trainable 
computational  models  composed  of  a  potentially  large  stack  of 
processing layers. Each layer learns a more abstract representation 
of  the  data  based  on  the  more  elementary  representation  in  the 
previous  layer.  For  instance,  in  image  recognition,  the  first  layer 
commonly  represents  any  image  by  its  low  level  visual  features 
such as local edges or gradients. Subsequent layers can be seen to 
combine these low level features in various combinations to form 
corners or textures. In the deepest layers, semantic representations 
are  formed  related  to  the  specific  task  at  hand.  For  example,  in 
face  recognition,  there  forms  a  representation  of  eyes  and  noses, 
and then combinations of those in various geometric relationships,

However,  the  rise  of  cheap  and  powerful  sensors  has  created  an 
ever-increasing data glut.  To be effective, these new tools must be 
coupled  with  new  automated  approaches  to  processing  and 
analyzing wildlife data streams. 

Here we describe examples of how we are leveraging advances in 
the areas of big data and deep learning to help researchers extract 
meaningful  information  from  the  torrent  of  new  sensor  data,  and 
improve the adaptive management of natural systems. 

4. DEEP LEARNING FOR 

BIODIVERSITY  
4.1.Big data infrastructure

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The primary focus of the described system is on processing and analyzing large, high-bit-rate datasets such as audio and image streams. Specifically, they use 16-bit stereo audio recorded at a sample rate of 22,000 samples per second (22 kHz), and 2048-by-1536 8-bit 4:2:2 color images. These data formats are used in their deep learning pipeline for tasks such as classifying the presence or absence of different endangered species and tracking populations of invasive snakes. They employ deep convolutional neural networks (CNNs) and deep feedforward neural networks (DNNs) to process audio spectrogram and image data.