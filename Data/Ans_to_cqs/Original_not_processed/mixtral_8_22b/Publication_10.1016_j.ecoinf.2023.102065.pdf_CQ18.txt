Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ence data available for training were limited, so we sought to explore 
different network sizes in conjunction with pre-training with additional 
acoustic reference data from outside of our audio domain, followed by 
fine-tuning with ROI data from our study site.

2.5. CNN fine-tuning data from ROIs 

We randomly sampled 50 ROIs per species with “presence” to form a 
held-out test set for accuracy assessment (Section 2.8.1). The remaining 
ROIs with species presence were used to fine-tune the CNN models. We 
randomly sampled 100 of these ROIs per species to form a validation set 
and the remaining formed a training set, which had on average 887 per 
species (min = 349, max = 3094). ROIs that were >2 s in duration were 
used in their entirety. For those that were <2 s in duration, we expanded 
the start/stop (i.e., padded) equally on each side of the ROI to total 2 s. 
Different vocalizations for a given species were combined into a single 
class per species. If any ROIs were overlapping in time from different 
pattern-matching runs for a given species, we placed those ROIs in the 
training set to avoid temporal autocorrelation in our validation and test 
data.

2.2.1. Regions of interest (ROI) for classifier fine-tuning training and testing 
We targeted 54 species that have distinctly unique vocalizations (call 
or song pattern) and are common in the study area during the breeding 
bird  season  (Table  1).  Although  additional  species  could  have  been 
studied (~180 species total; Sonoma County Breeding Bird Atlas, 2020), 
our project did not attempt to be exhaustive given the constraints of a 
citizen science project based on volunteer labor. Some species include 2 
to 3 different vocalizations (Table S1). Reference bird vocalizations were 
collected by citizen scientists using a web-based interface in the Arbi-
mon platform (Aide et al., 2013). In this process, an expert citizen sci-
entist  with  knowledge  of  local  bird  vocalizations  identified  parts  of 
spectrograms that represent a target bird vocalization. The system then 
used this template region of interest (ROI) and a pattern matching al-

Pre-training with auxiliary XC data resulted in improved evaluation 
metrics  leading  to  our  conclusion  that  this  step  helped  improve  final 
models. The XC archive is global, open access, and driven by bird en-
thusiasts,  and  in  the  year  2023  included  >740,000  recordings  and  >
10,500 species (xeno-canto.org). These data include recordings with a 
wide variation in quality and recording devices, which can be beneficial 
for applied research (Vellinga and Planqu´e, 2015), and are a significant 
source of training data for BirdCLEF competitions and BirdNET (Kahl 
et  al.,  2020,  2021,  2022).  Further,  we  demonstrated  an  automated 
approach to segment sound events in these recordings, thereby making 
the  data  accessible  for  use  in  CNN  development  without  a  high  pre- 
processing  cost.  A  rigorous  evaluation  of  why  CNN-XC  models 
increased precision and recall is beyond the scope of our study. How-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The strategy implemented to monitor the model performance during training involves the use of a held-out test set and a validation set. The held-out test set was created by randomly sampling 50 regions of interest (ROIs) per species with 'presence'. This set was used for accuracy assessment. The remaining ROIs with species presence were utilized to fine-tune the Convolutional Neural Network (CNN) models. From these, 100 ROIs per species were randomly selected to form a validation set. The rest formed the training set. The validation set was likely used to tune hyperparameters and prevent overfitting, while the training set was used to train the model. Different vocalizations for a given species were combined into a single class per species. Overlapping ROIs from different pattern-matching runs for a given species were placed in the training set to avoid temporal autocorrelation in the validation and test data.