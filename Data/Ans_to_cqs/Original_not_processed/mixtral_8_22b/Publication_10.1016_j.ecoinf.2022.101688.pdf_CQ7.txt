Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1 
Pre-processing hyper-parameters for each dataset and the number of testing files 
used.   

Lemurs 

Alethe 

Gibbons 

Whydah 

Low pass filter cut off 
Downsampling rate 
Nyquist rate 
Segment duration 
Number of testing files 
Testing time (min) 

4000 
9600 
4800 
4 
46 
1840 

3100 
6400 
3200 
2 
27 
810 

2000 
4800 
2400 
4 
22 
1300 

9000 
18400 
9200 
3 
78 
1560

execution the weights in the output layer of the CNN were randomly 
initialised. We split each dataset into training (60%) and testing (40%) 
by  randomly  selecting  entire  audio  files  â€“  similar  to  other  machine 
learning studies. To ensure a fair evaluation, we split the data in such a 
way that the training audio files were mutually exclusive to the testing 
audio  files.  The  testing  files  were  generally  recordings  over  different 
days. For testing, the CNNs predicted two softmax outputs on each entire 
testing file. The final class was assigned based on the softmax output 
which  had  a  value  greater  than  0.5.  This  decision  threshold  was  not 
optimised to keep the resulting models as accessible and easy-to-use as 
possible. This process was done using a sliding window of constant time 
duration.  The  window  is  shifted  by  1  second  until  the  network  had 
predicted on the entire file. The testing files were manually annotated

Since CNNs require a fixed input size, we studied the vocalisations 
within the presence class for each dataset to determine the character-
istics of the calls which would allow us to create fixed input, which we 
refer to as segments. For example, the Hainan gibbon calls vary from 2 to 
9 s (Dufourq et al., 2021), and thus a suitable input size was 4 s to ensure 
that the smallest call would fit within the segment. A longer input (>4 
seconds) would result in CNNs with more network parameters, an un-
desirable consequence as this would increase the chances to overfit. A 
shorter input (<4 s) would not contain enough information, especially 
in cases where the individual pulses that make up a call are long. A short 
input could omit parts of the call. Preliminary experiments were con-
ducted on the different datasets to minimise the input length as much as 
possible,  thus  minimising  network  parameters.  The  characteristics  of

consuming step which involves exploring various neural network hyper- 
parameters to obtain the most optimal model. When combined, these 
three  problems  render  the  creation  and  utilisation  of  CNNs  to  solve 
bioacoustics research questions challenging to machine learning experts 
and non-experts alike.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data was split into training (60%) and testing (40%) sets by randomly selecting entire audio files. The selection was made in such a way that the training audio files were mutually exclusive to the testing audio files. This approach ensured a fair evaluation of the model. The testing files were generally recordings over different days. No specific mention of a validation set was made in the given context. However, it can be assumed that a separate validation set might have been created during the pre-processing stage or during the training phase to fine-tune the model's performance.