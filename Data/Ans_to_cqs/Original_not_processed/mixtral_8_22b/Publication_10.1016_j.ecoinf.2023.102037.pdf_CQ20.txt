Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Fig. 4. Insect counts (in thousands) for each category in the dataset.  

cores at 2.4GHz) CPU, 32 GB Memory, and an NVIDIA®  Quadro RTX 
5000 (16GB Memory; CUDA Version: 11.4) GPU. 

The training procedure of the detection model ran for 150 epochs. 
The model was fed with batches of 16 tiles at a time which was moti-
vated by the available GPU memory and training efficiency. Stochastic 
Gradient Descent (SGD) was used as the model’s optimizer with a mo-
mentum of 0.9. The default data augmentation techniques of YOLOv5 
were applied during training to improve the model robustness. Predicted 
bounding boxes with intersection-over-union (IoU) ≥ 0.6 were consid-
ered  positive  while  bounding  boxes  with  IoU<0.6  were  considered 
negative (Zhang et al., 2020).

ofmineervlieg/. Accessed: 1 June 2022.  

Wang, R.J., et al., 2017. A crop pests image classification algorithm based on deep 

convolutional neural network. Telkomnika (Telecommun. Comput. Electron. Contr.) 
15 (3), 1239–1246. Available at: 10.12928/TELKOMNIKA.v15i3.5382. 

Wang, C.Y., et al., 2020a. CSPNet: A new backbone that can enhance learning capability 
of CNN. In: IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition Workshops, 2020-June, pp. 1571–1580. Available at: https://doi.org/ 
10.1109/CVPRW50498.2020.00203. 

Wang, J., et al., 2020b. Common pests image recognition based on deep convolutional 

neural network. Comput. Electron. Agric. 179 (June), 105834. Available at: https 
://doi.org/10.1016/j.compag.2020.105834.

• Aperture: F/10  
• ISO: 160  
• Shutter speed: 1/15 s  
• Focal Length: 55 mm  
• White balance: “Incandescent” 

2.3. Data splitting and image tiling

ones with flies. As discussed earlier, such challenges were avoided  in 
most reported studies by including highly dissimilar insect classes with 
low  intra-class  variability,  resulting  in  high  theoretical  classification 
rates which are difficult to hold in practice. While our approach may be 
less favorable from a machine learning point of view, it is more repre-
sentative for the real situation that the classifier will be confronted with 
in practice. 

3.2. Model performance

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: The text mentions that the training procedure of the detection model was run using a computer equipped with an Intel(R) Xeon(R) Gold 6242 (20 cores at 2.4GHz) CPU, 32 GB Memory, and an NVIDIA® Quadro RTX 5000 (16GB Memory; CUDA Version: 11.4) GPU. Therefore, the hardware resources used for training the deep learning model include a powerful multi-core CPU, a significant amount of RAM, and a high-performance GPU with substantial video memory.