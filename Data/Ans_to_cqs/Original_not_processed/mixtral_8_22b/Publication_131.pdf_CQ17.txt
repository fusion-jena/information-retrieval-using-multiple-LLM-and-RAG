Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

proper databases for CNN training.

13 of 19

ﬁlters per convolution layer is 32 for the ﬁrst one, 64 for the second one, and 128 for the
ﬁnal one. A kernel size (height and width of the convolution window) of 3 × 3 is used
on each convolution layer. The fully connected layer (FC) consists of 512 neurons and
the softmax layer with the number of units for classiﬁcation (one for each type of sound).
Figure 11 shows the structure of the CNN.

Figure 11. Structure of the designed CNN.

For network training, 80% of the samples were used as training samples, and 20%
as tests. This strategy is widely used to enhance the generalization of a machine learning
model and prevent overﬁtting. A balanced sampling was carried out for the test set. For
it, one audio sample (with its corresponding data augmentation samples) out of 5 was
selected for each type of anuran call. Thus, 7623 samples were used for training and 1892
for testing.

As mentioned in the data augmentation section above, a CNN was ﬁrst trained for
the 4 sound classes covered in the classiﬁcation model developed in previous work [20–23].
Later, a second CNN was trained to expand the classiﬁcation system to the total of the
5 classes detailed in Table 1.

For the ﬁrst network, the best results were obtained with training in only 8 epochs
(number of passes of the entire training dataset) and a batch size (number of samples
utilized in one training iteration) equal to 32. For the second network, the best training was
achieved with 6 epochs and, again, a batch size equal to 32. For both networks, the initial
learning rate [33] with 0.001 and the “adam” optimizer [34] were the parameters used in
the training process.

3. Results
3.1. CPS Performance

2020, 10, 259–264. [CrossRef]

15. Mushtaq, Z.; Su, S.-F. Environmental sound classiﬁcation using a regularized deep convolutional neural network with data

augmentation. Appl. Acoust. 2020, 167, 107389. [CrossRef]

16. Xie, J.; Hu, K.; Zhu, M.; Yu, J.; Zhu, Q. Investigation of Different CNN-Based Models for Improved Bird Sound Classiﬁcation.

IEEE Access 2019, 7, 175353–175361. [CrossRef]

17. Chi, Z.; Li, Y.; Chen, C. Deep Convolutional Neural Network Combined with Concatenated Spectrogram for Environmental
Sound Classiﬁcation. In Proceedings of the 2019 IEEE 7th International Conference on Computer Science and Network Technology
(ICCSNT), Dalian, China, 19–20 October 2019; Institute of Electrical and Electronics Engineers (IEEE): New York, New York, USA,
2019; pp. 251–254.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about specific regularization methods such as dropout or L2 regularization being used to prevent overfitting in the deep learning pipeline. However, it mentions that a balanced sampling was carried out for the test set to enhance the generalization of the machine learning model and prevent overfitting. Additionally, the use of data augmentation techniques can also be considered as a form of regularization to improve the model's performance and reduce overfitting.