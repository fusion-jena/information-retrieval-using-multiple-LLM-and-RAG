Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The model was trained over 200 epochs using the Adam optimizer 
(cid:0) 5. The batch size 
(Kingma and Ba, 2015), with a weight decay of 1 × 10
was fixed at 16, and the loss function was updated as per Eq. (6). The 
learning rate was initially set at 0.001 and was subsequently reduced by 
a  factor  of  0.1  in  a  step-wise  manner  whenever  the  validation  loss 
remained  constant  for  five  epochs.  The  minimum  learning  rate  was 
(cid:0) 5. The hyper-parameter λ in Eq. (4) was set to 0.8, 
established at 1 × 10
Mk  in Eq. (5) was defined as 2k+1(k = 1, 2, …K), and β in Eq. (6) was set 
to 0.4.

The  model’s  performance  was  assessed  using  the  mean  reciprocal 
rank  (MRR),  accuracy  (ACC),  and  hierarchical  distance  of  a  mistake 
(HDM) as metrics. The MRR (Go¨eau et al., 2018), an official evaluation 
metric of the BirdCLEF2018 competition, was employed to assess pro-
cesses that generate a list of potential responses to a sample of queries 
which are ranked by their likelihood of correctness. Accuracy was used 
to determine the proportion of correctly classified items, and an average 
accuracy across all class hierarchies (avg_ACC) was calculated to eval-
uate the efficacy of the hierarchical classification. The HDM (Bertinetto 
et al., 2020) was used to quantify the degree of misclassification when 
only  a  single  class  could  be  predicted.  For  example,  misclassifying 
Garrulax canorus as  Leiothrix lutea may not incur the same penalty as 
misclassifying Garrulax canorus as Caprimulgus jotaka. The mean height

Table 3 
Overview  of four subsets from the two benchmark datasets. The first column 
provides  the  dataset  name  and  abbreviations;  the  second  column  states  the 
publication  year;  the  third  column  shows  the  locations  where  the  recordings 
were captured; the fourth column details the samples in the training, validation, 
and test sets, and the fifth column indicates the number of categories at each 
level (from coarse to fine).  

Dataset name 

Release 
year 

Country 
with records 

#Sounds 

#Categories 

BirdCLEF2018- 
Small (BC-S) 
BirdCLEF2018- 
Large (BC-L) 
Lishui-Zhejiang 
Birdsdata (LS) 
Lishui-Zhejiang 

Birdsdata (LS*) 

2018 

2018 

2024 

Europe & 
America 
Europe & 
America 
China 

2024 

China 

3118/308/ 
308 
10,216/ 
1005/1005 
20,512/ 
2514/2513 
10,279/ 
2514/2513 

14/42/122/ 
150 
22/57/309/ 
500 
13/47/100 

13/47/100

13/47/100  

the  two  datasets  using  the  “stratified  sampling”  method.  We  selected 
birds of different class sizes from BirdCLEF2018, abbreviated as “BC-S" 
(BirdCLEF-Small)  and  “BC-L"  (BirdCLEF-Large).  From  the  Lishui- 
Zhejiang Birdsdata, we chose 100 bird species, referred to as “LS”. We 
then halved the number of training samples of each species for “LS” to 
construct  a  supplementary  small-scale  training  set,  denoted  as  “LS*”. 
The datasets were divided into three exclusive groups: 80% for training, 
10% for validation, and 10% for testing to compare the experimental 
results. Detailed statistical information is presented in Table 3. 

4.2. Experimental results 

This section presents the experimental results of our PPNN model,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Training completion is determined based on the behavior of the validation loss. Specifically, if the validation loss remains constant for five consecutive epochs during training, the learning rate is reduced by a factor of 0.1. This process continues until the minimum learning rate is reached. Therefore, the criterion used to determine when training is complete is when the validation loss does not improve after several attempts to reduce the learning rate.