Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

hyperparameters  (i.e.,  ‘AutoML’;  He  et  al.,  2021).  This  represents  an 
important  advantage  for  non-experts  in  deep  learning,  as  it  does  not 
require  the  manual  assembly  of  the  models  and  definition  of  their 
hyperparameters. The AutoML procedure starts by generating a set of 
candidate models with architectures and hyperparameters (e.g. number 
of layers; learning rate) selected at random from a prespecified range of 
values (see Fig. 2). Each candidate model is trained using a small subset 
of the data (data partition At; Fig. 2) during a small number of epochs. 
After  training,  the  performance  of  the  candidate  models  is  compared 
using a left-out validation data set (Av; Fig. 2). The selected candidate 
model (usually the best performing among candidates) is then trained on 
the full training data (Bt; Fig. 2). In this step it is required to identify an 
optimal number of training epochs, to avoid under- or overfitting of the

The  training  and  internal  validation  of  deep  learning  models  are 
sensitive to strong class imbalance (i.e., when one or several classes have 
a  much  higher  number  of  samples).  Strong  class  imbalance  can  bias 
models towards the prediction of majority classes (Menardi and Torelli, 
2014) and reduces the reliability of performance metrics such as accu-
racy sensu stricto (i.e., the proportion of correct predictions to the total 
number  of  samples),  which  is  used  for  the  automated  selection  of 
candidate models in mcfly (van Kuppevelt et al., 2020). Accordingly, we 
balanced  our  data  by  randomly  duplicating  presence  records  and  de-
leting absence records until a balance of ~50:50 is obtained, which was 
executed using the ROSE package (Lunardon et al., 2014) for R (R Core 
Team, 2020). This was done for the data sets that mcfly uses for internal 
assessment of accuracy s.s. (At, Av and Bt, Fig. 2). Data partitioning was

0.91 

Architecture 

Case study 2 

ResNet 
InceptionTime 
LSTM 
CNN 
ResNet 
LSTM 
InceptionTime 
CNN 
CNN 
ResNet 
InceptionTime 
LSTM 
ResNet 
CNN 
InceptionTime 
LSTM 
CNN 
InceptionTime 
LSTM 
ResNet 

Accuracy of 
candidate 
models (% 
correct) 

AUC of 
selected 
model 

Architecture 

Accuracy of 
candidate 
models (% 
correct) 

0.67  
0.63  
0.52  
0.82 
0.61  
0.52  
0.67  
0.52  
0.48  
0.67  
0.66  
0.52  
0.66  
0.77  
0.67  
0.52  
0.52  
0.75  
0.52  
0.7  

0.95 

Case study 3 

ResNet 
InceptionTime 
LSTM 
CNN 
ResNet 
LSTM 
InceptionTime 
CNN 
CNN 
ResNet 
InceptionTime 
LSTM 
ResNet 
CNN 
InceptionTime 
LSTM 
CNN 
InceptionTime 
LSTM 
ResNet 

0.5  
0.81 
0.8  
0.69  
0.5  
0.81  
0.76  
0.51  
0.5  
0.49  
0.5  
0.75  
0.5  
0.66  
0.5  
0.61  
0.5  
0.51  
0.77  
0.5

Table 1 
Type of architecture and accuracy of candidate models and predictive performance of selected models (bold). The accuracy of candidate models was measured using 
the proportion of correctly classified cases. The accuracy of selected models was measured using the area under the receiver operating characteristic curve (AUC).  

Candidate 
model 

Architecture 

Accuracy of 
candidate 
models (% 
correct) 

AUC of 
selected 
model 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 

Case study 1 

ResNet 
InceptionTime 
LSTM 
CNN 
ResNet 
LSTM 
InceptionTime 
CNN 
CNN 
ResNet 
InceptionTime 
LSTM 
ResNet 
CNN 
InceptionTime 
LSTM 
CNN 
InceptionTime 
LSTM 
ResNet 

0.32  
0.66  
0.31  
0.7  
0.46  
0.32  
0.57  
0.68  
0.39  
0.32  
0.32  
0.39  
0.32  
0.49  
0.85 
0.39  
0.6  
0.79  
0.36  
0.42  

0.96 

AUC of 
selected 
model  

0.91 

Architecture 

Case study 2

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, various techniques can be employed. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets while maintaining the same proportions of target variables across each split. This ensures that each subset has a representative sample of all possible outcomes, reducing the risk of biased results due to uneven distribution of target variables.

Oversampling is a technique used to increase the representation of minority classes within a dataset. It involves creating copies of existing instances of the minority class or synthesizing new instances based on existing ones. By increasing the size of the minority class, oversampling aims to reduce the impact of class imbalance on model performance.

Undersampling, on the other hand, involves removing instances from the majority class to achieve a more balanced dataset. While this approach may result in loss of information, it can help mitigate the effects of class imbalance and improve model performance.

Diverse data collection refers to the practice of collecting data from multiple sources or populations to ensure that the resulting dataset is representative of the broader population. This can involve sampling from different geographic regions, demographics, or time periods to capture variations in patterns and trends.

In the given context, the authors addressed data bias by balancing their data through random duplication of presence records and deletion of absence records until a balance of approximately 50:50 was achieved. This was executed using the ROSE package for R. This approach falls under the category of oversampling, where the goal is to create a more balanced dataset by increasing the representation of the minority class.