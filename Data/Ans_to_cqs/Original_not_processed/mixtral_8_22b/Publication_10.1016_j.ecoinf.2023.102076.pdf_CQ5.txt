Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Here,  we  demonstrate  and  evaluate  a  text  classification  pipeline, 
designed to address both the issue of imbalanced datasets and the need 
for large training datasets, using an example data collection scenario. 
Importantly,  we  use  a  hierarchical  classification  approach,  whereby 
data are passed through a series of classifiers with increasingly specific

EcologicalInformatics75(2023)1020762S.B. Hunter et al.                                                                                                                                                                                                                               

Fig. 1. Graphical representation of the full classification pipeline, which brings together three binary classification tasks with increasingly specific relevancy criteria. 
At each step, irrelevant texts are filtered out and the remaining relevant texts are used to generate training data for the next classification task. 

Fig. 2. Representation of the different data types collected from online searches.  

EcologicalInformatics75(2023)1020763S.B. Hunter et al.

fying the exploitation or sale of a particular taxa, for which there may 
not be existing proxy datasets. Alternatively, researchers can annotate a 
randomly  selected  sample  of  collected  data,  according  to  their  own 
relevancy  criteria.  However,  this  approach  is  less  suitable  for  cases 
where relevant examples make up a small proportion of the collected 
data,  as  imbalanced  training  data  can  lead  to  poor  classification  per-
formance (Schr¨oder et al., 2021).

Beltagy, I., Lo, K., Cohan, A., 2019. SciBERT: a pretrained language model for scientific 
text. In: Proceedings of the 2019 Conference on Empirical Methods in Natural 
Language Processing and the 9th International Joint Conference on Natural 
Language Processing (EMNLP-IJCNLP), pp. 3615–3620. 

Benıtez-L´opez, A., Santini, L., Schipper, A.M., Busana, M., Huijbregts, M.A., 2019. Intact 
but empty forests? Patterns of hunting-induced mammal defaunation in the tropics. 
PLoS Biol. 17 (5), e3000247. 

Blasi, D., Anastasopoulos, A., Neubig, G., 2022. Systematic inequalities in language 
technology performance across the world’s languages. In: Proceedings of the 60th 
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 
pp. 5486–5505. https://doi.org/10.18653/v1/2022.acl-long.376. 

Bojanowski, P., Grave, E., Joulin, A., Mikolov, T., 2017. Enriching word vectors with 

subword information. Trans. Assoc. Comput. Linguist. 5, 135–146.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The paper does not explicitly mention any specific dataset such as MNIST, CIFAR, or ImageNet. Instead, it discusses a general method for addressing issues related to imbalanced datasets and the need for large training datasets in a text classification pipeline. It uses a hierarchical classification approach, passing data through a series of classifiers with increasingly specific relevance criteria. The authors also suggest that researchers can annotate a randomly selected sample of collected data based on their own relevancy criteria. However, they note that this approach might not work well when relevant examples form a small portion of the collected data due to potential poor classification performance caused by imbalanced training data.