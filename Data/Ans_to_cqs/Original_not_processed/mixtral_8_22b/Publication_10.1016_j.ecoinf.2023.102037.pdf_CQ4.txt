Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

• Aperture: F/10  
• ISO: 160  
• Shutter speed: 1/15 s  
• Focal Length: 55 mm  
• White balance: “Incandescent” 

2.3. Data splitting and image tiling

ofmineervlieg/. Accessed: 1 June 2022.  

Wang, R.J., et al., 2017. A crop pests image classification algorithm based on deep 

convolutional neural network. Telkomnika (Telecommun. Comput. Electron. Contr.) 
15 (3), 1239–1246. Available at: 10.12928/TELKOMNIKA.v15i3.5382. 

Wang, C.Y., et al., 2020a. CSPNet: A new backbone that can enhance learning capability 
of CNN. In: IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition Workshops, 2020-June, pp. 1571–1580. Available at: https://doi.org/ 
10.1109/CVPRW50498.2020.00203. 

Wang, J., et al., 2020b. Common pests image recognition based on deep convolutional 

neural network. Comput. Electron. Agric. 179 (June), 105834. Available at: https 
://doi.org/10.1016/j.compag.2020.105834.

Fig. 5. A) Illustration of the procedure for separating data into training, validation and test sets, and tiling sticky plate images by finding regions of interest of a fixed 
size (512x512 pixels) that contain the maximum number of complete bounding boxes. B) Illustration of applying the YOLOv5 model on a sticky plate image using 
“Slicing Aided Hyper Inference” (SAHI). 

EcologicalInformatics75(2023)1020375I. Kalfas et al.

2021a; Wang et al., 2020c). Wang et al. (2020a, 2020b, 2020c) obtained 
a mean Average Precision (mAP) score of 63.54% using YOLOv3 (Red-
mon  and  Farhadi,  2018)  while  detecting  and  classifying  pest  species 
from  the  images  in  their  “Pest24”  dataset.  The  dataset  consisted  of 
25,378  annotated  images  coming  from  24  pest  species  that  were  all 
collected by an automatic imaging trap. Rustia et al. (2021) designed a 
multi-stage deep learning method including object detection, insect vs. 
non-insect  separation  and  a  multi-class  insect  classification  for  insect 
identification. Data were acquired by multiple wireless imaging devices 
installed  in  greenhouses  –  under  varying  lighting environments  -  and 
their classification model reached average F1-scores of up to 0.92. Hong 
et  al.  (2021)  developed  an  AI-based  pest  counting  method  for  moni-
toring  the  black  pine  bast  scale  (M.  thungergianae)  which  reached  a

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide specific information about the data augmentation techniques used in the deep learning pipeline. However, common data augmentation techniques include flipping, rotating, scaling, cropping, and adjusting brightness or contrast. These techniques help increase the size and diversity of the training dataset, improving the performance and generalization ability of the deep learning models.

Unhelpful Answer:
The paper discusses various aspects of the deep learning pipeline but does not explicitly mention the use of any specific data augmentation techniques such as flipping, rotation, or scaling. Therefore, it is not possible to determine which data augmentation techniques were applied in this study.