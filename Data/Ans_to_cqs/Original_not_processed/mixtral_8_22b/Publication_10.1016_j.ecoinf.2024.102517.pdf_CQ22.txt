Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

set 

is 

to 
1. 

2.3.3. Experimental setting 

In our experiment, a deep learning environment based on Python and 
Tensorflow – GPU as well as CUDA was constructed under the Windows 
operating system. The deep feature loss bird noise reduction network 
model was trained for 50 epochs on an RTX 2080 Ti GPU using the Adam 
(cid:0) 4. In each 
optimizer (Kingma and Ba, 2014) with a learning rate of 10
epoch, the entire training set was presented in a random order, with one 
noisy bird sound signal per iteration. 

2.4. Comparative algorithms 

Using the same test  set, we compared the  denoising results of the 
deep feature loss-based bird sound noise reduction network with several 
other  bioacoustics  noise  reduction  algorithms,  namely  SEGAN, 
WebRTC, wavelet transform (Priyadarshani et al., 2016), Wiener filter 
(Loizou, 2017), and MMSE STSA (Brown et al., 2017) algorithms.

(2)  

∑

Λ15 =

Λ14

j × K14

j + b,

j

where b is a learned bias term. 

Fig. 4. Framework of the bird sound noise reduction network based on deep feature loss.  

EcologicalInformatics80(2024)1025174C. Zhang et al.                                                                                                                                                                                                                                   

2.3.2. Training of the bird sound noise reduction network based on deep 
feature loss

Abbreviations: Signal-to-noise ratio, SNR; perceptual evaluation of speech quality, PESQ; Web real-time communications, WebRTC; voice over Internet protocol, 
VoIP; minimum mean-square error short-time spectral amplitude, MMSE STSA; speech enhancement generative adversarial network, SEGAN; generative adversarial 
network, GAN; fully convolutional neural network, FCN; deep autoencoder, DAE; leaky rectified linear unit, LReLU; detection and classification of acoustic scenes 
and events, DCASE; peak signal-to-noise ratio, PSNR. 

* Corresponding author Xinghui Gao at: School of Electronics and Communication Engineering, Guangzhou University, China. 
** Corresponding author Yingying Guo at: School of Mechanical and Electrical Engineering, Guangzhou University, China. 

E-mail addresses: gaoxh@gzhu.edu.cn (X. Gao), guoyingying@gzhu.edu.cn (Y. Guo).

reducing noise, and accordingly, would not be suitable for processing 
large  volumes  of  recorded  data  collected  in  the  field.  Furthermore, 
compared with the bird sound noise reduction network based on deep 
feature loss and the SEGAN algorithm, we found that the noise reduction 
efficiencies of the WebRTC and Wiener Filter algorithms were notably 
higher. This disparity in performance can be attributed to the fact that 
the deep learning model is larger in size and is thus more demanding of 
computational resources. However, it should be noted that the execution 
time of the deep learning models on CPUs is acceptable.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors do not explicitly mention any specific metric used to evaluate the performance of their deep learning model. However, they compare the denoising results of their proposed method with other bioacoustics noise reduction algorithms such as SEGAN, WebRTC, wavelet transform, Wiener filter, and MMSE STSA algorithms. They also discuss the differences in performance between these methods, which suggests that some form of quantitative comparison has been made. Additionally, they mention that the deep learning model is larger in size and demands more computational resources, implying that perhaps efficiency or resource usage could have been considered when evaluating its performance. Nevertheless, without explicit information about the exact metrics used, I cannot provide a definitive list of the metrics employed by the authors to assess the performance of their deep learning model.