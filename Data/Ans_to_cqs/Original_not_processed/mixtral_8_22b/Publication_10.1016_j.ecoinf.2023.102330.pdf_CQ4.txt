Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We then use data augmentation to estimate σARU by adding a number 
of known ‘non-detections’ with distance of NA to our dataset of detected 
or simulated calls, increasing our total number of observations M to 300 
per ARU. We used a data augmentation variable zi,j for each observation 
to indicate whether it was a true call or not, so that the total realized 
M
number of calls including false positive CNN detections (NFPi =
j=1zi,j) 
can be modelled in relation to our data augmentation parameter ψ, pi,j 
and the binary detection outcomes of each call (yi,j)(eq. 10–12). 

∑

zi,j ∼ Bernoulli(ψ)

mui,j = zi,j*pi,j

(cid:0)
yi,j ∼ Bernoulli

mui,j

)

(10)  

(11)  

(12)

2.2. Empirical data 

2.2.1. Study area

then be retrained, or used as-is, to detect the target species of interest. 
Training a CNN for acoustic detection is also becomingly increasingly 
more  accessible  as  researchers  develop  and  publish  their  models,  for

Recordings were analyzed using a previously developed CNN model 
(Nolan  et  al., 2022)  trained on covey call  spectrogram data collected 
separately to this study from Di-Lane and other sites around Georgia and 
Alabama,  USA.  Our  covey  call  acoustic  CNN  is  trained  to  detect  and 
localize all covey calls per ARU during the recording period and note 
their associated time and peak power (dB). We chose to use a relatively 
conservative  score  threshold  echoing  that  of  other  similar  studies 
ˇ
Sirovi´c, 2021; Ruff et al., 2020), where only calls that 
(Rasmussen and 
received a score of 0.95 or higher were officially classified as a positive 
bobwhite detection. All CNN detections at a 0.95 score threshold from a 
random sample of five one-hour files from each year were then manually 
reviewed to evaluate model accuracy and to calculate a false positive 
rate “i.e. how many calls were incorrectly labelled as bobwhite”. Across

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific details about the data augmentation techniques applied in the deep learning pipeline. However, it mentions that data augmentation was used to increase the total number of observations by adding 'known non-detections'. This suggests that the authors might have added synthetic data points to balance the classes in their dataset. The term 'data augmentation' generally refers to various techniques such as flipping, rotating, scaling, cropping, etc., which can help improve the performance of machine learning algorithms by artificially expanding the size of training datasets. In this case, since no specific techniques are mentioned, we cannot definitively state which ones were used.