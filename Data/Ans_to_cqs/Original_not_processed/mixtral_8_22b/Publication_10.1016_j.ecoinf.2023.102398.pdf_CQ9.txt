Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The training is done from scratch using GPU (Tesla T4) and CUDA 
Version-12.0 in Google Colab with the parameters (i) Input image size =
416, (ii) Batch size  = 16,  (iii) Epochs = 100, 150, 200  and 250, (iv) 
Weights  = Default  to yolov5.pt., (v) Data = custom data set  and (vi) 
Cache = True. 

EcologicalInformatics79(2024)10239811B. Bhagabati et al.                                                                                                                                                                                                                              

Fig. 11. Training Plots for the proposed model.

YOLOv5s with SENet 
attention layer 

Own created satellite image dataset SAT1 
(10), SAT1(8), SAT1(4) 
Wild animal dataset comprises tiger, panda, 
elephant, squirrel, giraffe, butterfly. 
Animal2-v1, comprises images of tiger, beer, 
leopard, monkey, elephant and wildboar. 

2628 satellite imaginary images covering area 
10 km × 10 km, 8 km × 8 km, 4 km × 4 km 
6050 images 

About 9952 images

The work is based on the popular YOLOv5 architecture integrated 

with a SENet attention mechanism (Zhu et al., 2021). 

The  YOLO  (You  Only  Look  Once)  is  a  simple  and  extremely  fast 
object detection algorithm that avoids a complex pipeline and considers 

• Backbone: A CNN, which acts as the main body of the network, is 
designed using the New CSP-Darknet53 (Cao et al., 2023) structure. 
It extracts key features from the input image. 

EcologicalInformatics79(2024)1023986B. Bhagabati et al.                                                                                                                                                                                                                              

Fig. 3. YOLOv5 architecture with proposed attention layer. YOLOv5 blocks, SENet attention layer blocks and the embedded attention layers in the Backbone of the 
YOLOv5 model are shown.

Fig. 2. YOLOv5 network architecture showing the three components of the model, namely Backbone, Neck and Head. Nos. of input layers, output layers, kernel size, 
strides and blocks are also shown (Xu et al., 2021). 

3.1. Dataset 

A  publicly  available  dataset  in  Roboflow  (Roboflow  Dataset,  n.d) 
named Animal2–v1 comprising 9952 images belonging to classes Bear 
(1530  images),  Deer  (966  images),  Elephant  (1684  images),  Leopard 
(1888 images), Monkey (1214 images), Tiger (1388 images) and Wild-
boar (1282 images) is used. All the images are annotated in YOLOv5 
PyTorch  format.  The  preprocessing  applied  for  the  dataset  is  auto- 
orientation  of  pixel  data  with  EXIF-format  stripping,  and  the  images 
are resized to 416 × 416 (stretch). Here, 70% of images are used for 
training,  20%  images  for  validation,  and  10%  images  are  used  for 
testing. No image augmentation techniques are applied.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there is no explicit mention of where the data repository of the deep learning pipeline is available. However, it can be inferred that the authors have used a publicly available dataset named Animal2-v1 from Roboflow (Roboflow Dataset, n.d.). Therefore, one could potentially access this dataset through the Roboflow platform. It should be noted that the specific version or link to the dataset was not mentioned in the provided context. Additionally, the authors did not explicitly state whether they made their own dataset available in any public repositories such as Zenodo, Figshare, Dryad, or GBIF. Thus, without further clarification or additional information, it cannot be definitively stated where the data repository of the deep learning pipeline is available.