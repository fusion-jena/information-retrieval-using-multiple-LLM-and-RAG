Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

More recently, there has been a great effort to automate the process 
of classification/mapping of specific targets using Deep Learning (Lecun 
et al., 2015) algorithms, such as the Deep Neural Network (DNN), which 
includes  a  learning  algorithm  based  on  an  artificial  neural  network 
(Langford et al., 2019). In this study, we developed a semi-automatic 
methodological approach for mapping burned areas in the entire Cer-
rado  biome  in  Brazil  using  Deep  Learning  techniques  available  on 
Google Cloud computing and Landsat 8 imagery, which consist of eleven 
spectral bands with a spatial resolution of 30 meters for bands 1-7 and 9, 
15 meters for band 8, and 100 meters for bands 10 and 11. We did not 
use  Landsat-7  imagery  because  of  the  data  gaps  observed  images  ac-
quired after 2003, which would substantially affect the spatial coverage 
of  our  analysis.  We  assessed  accuracies  and  compared  our  mapping 

2. Material and methods 

2.1. Study region

We used Landsat 8 Operational Land Imager (OLI) satellite images 
and Deep Neural Network models to detect and map burned areas within 
the  Cerrado  biome.  The  image  processing  and  classification  followed 
four steps as follows: (1) collecting spectral training samples of burned 
and non-burned areas for the entire study area, well distributed in space, 
(2) training the deep learning models, (3) developing model prediction, 
and (4) model assessment (validation and concordance analysis). Fig. 2 
uses  step-by-step  bases  to  show  all  details  of  our  methodological 
approach for detecting and mapping burned areas in the Cerrado biome 
in 2017. 

2.4.1. Training samples dataset 

The spectral training samples of burned area (BA) and non-burned

Since  deep  learning  methods  require  a  powerful  computational 
processing, we conducted our analysis using graphics processing units 
(GPUs)  and  specialized  hardware  components  for  running  parallel 
arithmetic operations (Goodfellow et al., 2016). The access to GPUs in a 
virtual  machine  environment  was  implemented  on  the  Google  Cloud 
suite  of  cloud 
Platform 

(https://console.cloud.google.com),  a 

3.1. Optimal period of burn scar mapping 

The fire hotspot data analysis provided by INPE (http://www.inpe. 
br/queimadas/bdqueimadas)  indicates  that  most  of  the  fire  events  in 
the  Cerrado  biome  occurred  between  May  and  December,  showing  a 
peak in September 2017 (Fig. 4). Based on it, we focused our mapping 
analysis of burn scars on the period between May and December, which 
comprised 98% of fire hotspots detected in 2017 by INPE. 

3.2. Burned areas in 2017

Burned 

Nonburned 

Total 

131 
38 
169 
77.5% 

69 
1962 
2031 
96.6%    

200 
2000 
2200   

65.5%  
98.1%  

Burned 
Nonburned 
Total 
Producerâ€™s 
accuracy 

Total accuracy     

CRediT authorship contribution statement 

95.1%  

Vera  L.S.  Arruda:  Conceptualization,  Methodology,  Software, 
Validation, Writing - original draft, Writing - review & editing. Valderli 
J.  Piontekowski:  Conceptualization,  Methodology,  Software,  Data 
curation, Visualization, Investigation. Ane Alencar: Conceptualization, 
Methodology,  Validation,  Writing - original  draft, Writing  - review & 

RemoteSensingApplications:SocietyandEnvironment22(2021)1004729V.L.S. Arruda et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To deploy the trained deep learning model, the authors used graphics processing units (GPUs) and specialized hardware components for running parallel arithmetic operations. They conducted their analysis using the Google Cloud suite of cloud platform (<https://console.cloud.google.com>). However, the exact process of how they deployed the trained deep learning model is not explicitly mentioned in the given context. It can be assumed that they serialized the trained model and then uploaded it to the Google Cloud platform for deployment. But without further information, it cannot be confirmed.