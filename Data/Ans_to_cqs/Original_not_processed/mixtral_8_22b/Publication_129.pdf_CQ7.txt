Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

IoU ¼

A \ B
A [ B

ð2Þ

Next, the Region of Interest (RoI) pooling layer takes the
region corresponding to a proposal from the backbone feature
map and dividing it into sub-windows. The maximum pooling
is performed over these sub-windows to give the output of RoI
pooling layer, which has a size of (N, 7, 7, 512), and N is the
number of generated region proposals by the RPN mechanism,
as shown in Fig. 2. After passing through two fully connected
layers (FCs), the features are fed into the classiﬁer and regres-
sor branches as follow. The classiﬁcation layer calculates the
probability of the region proposal contains an object such that
the probability Pi of each element in the feature map i contains
the target object using softmax function. The regions with the
top score of 300 Pi in the total rankings present the detected
target object. In addition, the regressor provides the IoU index

A new mobile application of agricultural pests recognition

4427

Fig. 3

performance utilization of
the RPN module with the
bounding box regression, as depicted in Fig. 2. Moreover,
the computational time of this deep learning approach is not
a problem in this study, because the detection and classiﬁca-
tion procedures of agricultural insect pests can be executed
in a few seconds in the cloud computing system, saving all
required hardware resources.

3.2. Faster R-CNN approach

The Faster R-CNN presents recent advancement of both Fast
R-CNN and R-CNN by Ren et al. [16]. It merges a Region
Proposal Network (RPN) as object bounds predictor and Fast
R-CNN for target detection in processed images. The role of
RPN module is to serve as the ‘‘attention” mechanism of this
uniﬁed Faster R-CNN, as depicted in Fig. 2. Three basic com-
ponents of the Faster R-CNN can be described as follow.
First, the feature extractor network to generate feature maps

[34]. Second,

[25] M.E. Karar, E.E.-D. Hemdan, M.A. Shouman, Cascaded deep
learning classiﬁers for computer-aided diagnosis of COVID-19
and pneumonia diseases in X-ray scans, Complex Intell. Syst. 7
(2021) 235–247, https://doi.org/10.1007/s40747-020-00199-4.
[26] E.C. Tetila, B.B. Machado, G. Astolﬁ, N.A.d.S. Belete, W.P.
Amorim, A.R. Roel, H. Pistori, Detection and classiﬁcation of
soybean pests using deep learning with UAV images, Comput.
Electron. Agric., 179 (2020) 105836.

[27] Y. Xu, S.M. Gray, Aphids and their transmitted potato viruses:
A continuous challenges in potato crops, J. Integr. Agric. 19
(2020) 367–375.

[28] O. Lundin, No-till protects spring oilseed rape (Brassica napus
L.) against crop damage by ﬂea beetles (Phyllotreta spp.), Agric.
Ecosyst. Environ. 278 (2019) 1–5.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In machine learning, including deep learning models like Faster R-CNN, datasets are typically divided into three parts: training set, validation set, and testing set. This division helps evaluate the performance of the model during its development phase and after deployment.

1. Training Set: This dataset is used to train the model, where the model learns patterns and relationships between input variables and outputs. During this process, the weights and biases of the neural networks are adjusted iteratively until the error or loss function is minimized.

2. Validation Set: Also known as the development set, this dataset is used to fine-tune hyperparameters and prevent overfitting. Overfitting occurs when the model performs well on the training data but poorly on unseen data due to memorizing the training examples instead of generalizing patterns. By evaluating the model's performance on the validation set, one can adjust the architecture, regularize the model, or stop training early if necessary.

3. Testing Set: Once the model is trained and optimized, it is evaluated on the testing set to measure its final performance. Since the model hasn't seen this data before, it gives an accurate estimate of how well the model will perform in real-world scenarios.

The proportion of splitting the data depends on various factors, such as the size of the dataset, complexity of the task, and available computational resources. Commonly, the ratio of 60:20:20 or 70:15:15 is used for training, validation, and testing sets, respectively. However, there isn't any hard rule, and different ratios may work better depending on specific use cases.