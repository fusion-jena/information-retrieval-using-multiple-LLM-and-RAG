Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

parallel  computing  power  provided  by  graphical  processing  units 

tion professionals to focus on other tasks. Two novel methods can 

(GPUs)  and  accessibility  of  image  training  datasets,  such  as  the 

potentially replace the use of manual counts by experts, the deploy-

COCO  dataset  (Lin  et al.,  2014),  have  led  to  rapid  improvements 

ment of citizen scientists and the use of automated object detection 

in  the  performance  of  multilayer  deep  convolutional  neural  net-

algorithms.  In  this  work,  we  deploy  both  approaches  and  evaluate 

works  (DCNNs).  These  multilayer  neural  networks  are  a  form  of 

the performance and merits of each.

deep learning and are distinct to traditional machine learning ap-

1.1 | Citizen science and the wisdom of crowds

proaches to computer vision in that no hand- crafted features are 

required;  instead,  the  convolutional  layers  extract  relevant  fea-

libraries	 such	 as	 TensorFlow	 (Abadi	 et	al.,	 2016).	 Currently,	 the	

Raw count data are available from Enlighten: Research Data (https://

doi.org//10.5525/gla.researchdata.732).  Source  code  is  available 

from http://dx.doi.orgI10.5281/zenodo.2562058.

greatest challenge for implementing these algorithms for bespoke 

O R C I D 

applications is obtaining sufficiently large training datasets. In this 

regard,  citizen  scientists  have  a  clear  role  to  play.  While  we  have 

shown that the trained algorithm achieves high accuracy levels, it 

Colin J. Torney 

 https://orcid.org/0000-0003-1673-7835  

should  be  noted  that  the  algorithm  employed  the  crowd- sourced 

data  to  create  the  training  sets.  Hence,  both  methods  should  be 

R E F E R E N C E S

viewed  as  complementary  approaches  with  citizen  science  data 

forming the foundation for automated algorithms (Rey et al., 2017).

40-	year	

the	

Redmon,	 J.,	 &	 Farhadi,	 A.	 (2017).	 YOLO9000:	 Better,	 Faster,	 Stronger,	
2017  IEEE  Conference  on  Computer  Vision  and  Pattern  Recognition 
(CVPR) 
IEEE.  https://doi.
org/10.1109/cvpr.2017.690

(pp.  6517–6525),  Honolulu,  Hawaii: 

Redmon,	 J.,	 &	 Farhadi,	 A.	 (2018).	 Yolov3:	 An	 incremental	 improvement.	

arXiv preprint arXiv:1804.02767.

Ren,	 S.,	 He,	 K.,	 Girshick,	 R.,	 &	 Sun,	 J.	 (2015).	 Faster	 r-cnn:	 Towards	 re-
al-time object detection with region proposal networks. In C. Cortes, 
N. D. Lawrence, D. D. Lee, M. Sugiyama, & R. Garnett (Eds.), Advances 
in  neural  information  processing  systems  (pp.  91–99).  Montreal, 
Canada:	Curran	Associates,	Inc.

Rey,	N.,	Volpi,	M.,	Joost,	S.,	&	Tuia,	D.	(2017).	Detecting	animals	in	African	
Savanna	 with	 UAVs	 and	 the	 crowds.	 Remote  Sensing  of  Environment, 
200, 341–351. https://doi.org/10.1016/j.rse.2017.08.026

within the image. While there remains the potential for bias in the 

three main steps.

expert count, we take this count to be the gold standard. Hence, our 

Firstly, we generated a training dataset by selecting 500 of the 

results are a comparison between the two novel methods employed 

survey images at random to be used exclusively for training. Images 

and a count by a single experienced expert, which could in principle 

were tiled into 864 × 864 subimages and then passed though a ver-

deviate from the unknown true count.

sion of the YOLO DCNN using pretrained weights from the COCO 

dataset provided by (Redmon & Farhadi, 2018). This process created 

a	list	 of	the	locations	of	potential	objects	in	each	image.	As	a	first	

3 |  R E S U LT S

pass, these results were filtered by discarding any object detections 

that did not correspond to an identification from the Zooniverse data. 

We  compared  the  accuracy  of  the  methods  by  calculating  the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text does not explicitly mention the specific hardware resources used for training the deep learning models. However, given the context, it can be inferred that Graphical Processing Units (GPUs) might have been utilized due to their parallel computing power, which is beneficial for deep learning applications. Additionally, libraries like TensorFlow, mentioned in the text, support GPU acceleration for faster computations. Therefore, while not directly stated, it is likely that GPUs were used for training the deep learning models.