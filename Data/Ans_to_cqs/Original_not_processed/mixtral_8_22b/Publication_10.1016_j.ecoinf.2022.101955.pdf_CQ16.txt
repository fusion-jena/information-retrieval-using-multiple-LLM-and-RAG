Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 2 
Accuracy assessment for the kNN classification.  

2020 

LULC class 

Croplands 
Dense forest 
Grassland savanna 
Open savanna/barelands 
Built-up areas 
Water bodies 
Wetlands 
Woody savanna 
Total 
Overall producer’s accuracy 

(%) 

Overall accuracy ¼ 91.1% 
95% CI (89%, 92%); 
Kappa statistics ¼ 89%; 
p < 0.05 

2000 
LULC class 

Croplands 
Dense forest 
Grassland savanna 
Open savanna/barelands 
Built-up areas 
Water bodies 
Wetlands 
Woody savanna 
Total 
Overall producer’s accuracy 

(%) 

Overall accuracy ¼ 89.7% 
95% CI (85%, 91%); 
Kappa statistics ¼ 88%; 
p < 0.05  

Croplands 

Dense 
forest 

Grassland 
savanna 

Open savanna/ 
barelands 

Built-up 
areas 

Water 
bodies 

Wetlands  Woody 
savanna 

80 
0 
1 
0 
0 
4 
0 
0 
85 
94.3 

Croplands 

20 
0 
0 
5 
0 
0 
0 
0 
25 
80 

0 
5 
0 
0 
0 
0 
0 
0 
5 
100 

Dense 
forest 
0 
296 
0 
0 
0 
0 
1 
0 
297 
99.7 

0 
0 
12 
0 
0 
0 
0 
0 
12 
100 

Grassland 
savanna 
0 
0 
40 
1 
0 
0 
0 
0 
41 
99

(%) 

Overall accuracy ¼ 95.8% 
95% CI (93%, 97%); 
Kappa statistics ¼ 94%; 
p < 0.05 

2000 
LULC class 

Croplands 
Dense forest 
Grassland savanna 
Open savanna/barelands 
Built-up areas 
Water bodies 
Wetlands 
Woody savanna 
Total 
Overall producer’s accuracy 

(%) 

Overall accuracy ¼ 84.4% 
95% CI (80%, 87%); 
Kappa statistics ¼ 83%; 
p < 0.05  

Croplands 

Dense 
forest 

Grassland 
savanna 

Open savanna/ 
barelands 

Built-up 
areas 

Water 
bodies 

Wetlands  Woody 
savanna 

80 
0 
1 
0 
0 
4 
0 
0 
85 
94.3 

Croplands 

79 
24 
4 
0 
0 
0 
0 
0 
107 
73.8 

0 
5 
0 
0 
0 
0 
0 
0 
5 
100 

Dense 
forest 
0 
38 
0 
0 
1 
0 
0 
0 
38 
100 

0 
0 
12 
0 
0 
0 
0 
0 
12 
100 

Grassland 
savanna 
0 
0 
41 
0 
0 
0 
0 
0 
41 
100 

0 
0 
0 
5 
3 
0 
0 
0 
8 
100 

Open savanna/ 
barelands 
0 
2 
0 
15 
0 
0 
0 
0 
17 
88.2 

0 
0 
0 
0 
3 
0 
0 
0 
3 
100 

Built-up 
areas 
0 
0 
1 
15 
31 
0 
0 
0 
47 
70 

1 
0 
0 
0 
0 
223 
0 
0 
223 
100

details)).  We  loaded  the  training  datasets  in  R,  using  the  “sp”  vector 
package, then allocated 80% of the data as test files and the remaining 
20% as validation files using the createDataPartition () function from the 
“caret”  package. The test datasets enabled us to check  optimal model 
parameters  and  initial  model  performance  based  on  repeated  cross- 
validation,  while  the  validation  dataset  enabled  us  to  check  final 
model accuracy (Qian et al., 2015).

EcologicalInformatics74(2023)1019557Y.G. Yuh et al.                                                                                                                                                                                                                                  

Table 4 
Accuracy assessment for the RF classification.  

2020 

LULC class 

Croplands 
Dense forest 
Grassland savanna 
Open savanna/barelands 
Built-up areas 
Water bodies 
Wetlands 
Woody savanna 
Total 
Overall producer’s accuracy 

(%) 

Overall accuracy ¼ 90.3% 

95 CI (94%, 97%); 
Kappa statistics ¼ 94%; 
p < 0.05 

2000 
LULC class 

Croplands 
Dense forest 
Grassland savanna 
Open savanna/barelands 
Built-up areas 
Water bodies 
Wetlands 
Woody savanna 
Total 
Overall producer’s accuracy 

(%) 

Overall accuracy ¼ 99.3% 

95 CI (94%, 99%); 
Kappa statistics ¼ 97%; 
p < 0.05  

Croplands 

Dense 
forest 

Grassland 
savanna 

Open savanna/ 
barelands 

Built-up 
areas 

Water 
bodies

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors do not explicitly state the specific criteria they use to determine when training is complete. However, they mention using a combination of techniques such as repeated cross-validation with the test datasets to optimize model parameters and check initial model performance. They also use a separate validation dataset to assess the final model accuracy. These methods suggest that the authors may have used some form of early stopping or convergence criterion to prevent overfitting during training. For example, they might stop training when the validation error stops decreasing significantly or starts increasing, indicating that the model has begun to overfit the training data. Without more detailed information about their training process, it is difficult to provide a definitive answer regarding the exact criteria used to determine when training is complete.