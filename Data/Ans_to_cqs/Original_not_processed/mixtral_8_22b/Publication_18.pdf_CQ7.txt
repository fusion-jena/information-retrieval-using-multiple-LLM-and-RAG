Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Preliminaries on CNN models for image classification and object detection in images.  Deep 
Neural Networks (DNNs) are a subset of machine learning algorithms able to learn from a training dataset to 
make predictions on new examples called testset. They are built using a hierarchical architecture of increasing 
sophistication, each level of this hierarchy is called layer. One of their main particularities is their capacity to 
extract the existent features from data automatically without the need of external hand crafted features. Under the 
supervised learning paradigm, DNNs provide a powerful framework when trained on a large number of labelled 
samples.

trends. J. Exp. Mar. Biol. Ecol. 368, 1–8 (2009).

 54.  Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017).
 55.  Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016).
 56.  Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015).
 57.  Dodge, S. & Karam, L. Understanding how image quality affects deep neural networks. In 2016 Eighth International Conference on 

Quality of Multimedia Experience (QoMEX) 1–6, https://doi.org/10.1109/QoMEX.2016.7498955 (2016).

 58.  Kim, J., Lee, J. K. & Lee, K. M. Accurate Image Super-Resolution Using Very Deep Convolutional Networks. in Proc. CVPR IEEE 

1646–1654, https://doi.org/10.1109/CVPR.2016.182 (2016).

 59.  Tabik, S., Peralta, D., Herrera-Poyatos, A. & Herrera, F. A snapshot of image pre-processing for convolutional neural networks: case

rocks” (Data S1). Whale images for training the CNN were mainly aerial images. For step-2, the training dataset 
contains 700 aerial images, with whales and background, in which each whale is annotated within a bounding box 
(the total number of bounding boxes is 945).

1

www.nature.com/scientificreportsnumber of annotated images to later make correct predictions on new images37. Although the construction of a 
dataset for training is costly, the learning of CNNs on small datasets can be boosted by data-augmentation, which 
consists of increasing the volume of the training dataset artificially, and additionally by transfer learning, which 
consists of starting the learning of the network from a prior knowledge rather from scratch38,39.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The process of splitting data into different subsets such as training set, testing set, and validation set is crucial for building robust and accurate deep learning models. The primary goal of this division is to evaluate the performance of the model during its development phase and prevent overfitting or underfitting issues. Here are some common criteria used to split the data:

1. Random sampling: This method involves randomly selecting samples from the entire dataset to create separate sets. It ensures that all classes have equal representation in each subset. However, it may not always guarantee that the distribution of the original dataset is maintained.

2. Stratified sampling: To address the limitations of random sampling, stratified sampling is often employed. This technique maintains the class proportions present in the original dataset while creating the subsets. By doing so, it helps ensure that the model generalizes well across various classes.

3. Time-based splitting: When dealing with time series data, it is essential to maintain temporal dependencies between observations. Therefore, instead of shuffling the data before splitting, one should use time-based splitting. This approach divides the data based on timestamps, ensuring that the chronological order is preserved.

4. Cross-validation: Another popular method for evaluating the performance of deep learning models is cross-validation. It involves dividing the dataset into k folds, where each fold serves as a testing set once, while the remaining folds form the training set. This procedure is repeated k times until every sample has been part of both the training and testing sets. Cross-validation provides a more reliable estimate of the model's performance compared to single splits.

In summary, depending on the nature of the problem and the available resources, different methods can be applied to divide the data into training, testing, and validation sets. These include random sampling, stratified sampling, time-based splitting, and cross-validation. Each method has its advantages and disadvantages; thus, choosing the appropriate strategy depends on factors like data size, class imbalance, and computational constraints.