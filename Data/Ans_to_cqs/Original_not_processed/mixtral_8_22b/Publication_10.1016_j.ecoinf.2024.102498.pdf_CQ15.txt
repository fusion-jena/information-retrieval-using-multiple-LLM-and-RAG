Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Due to processing limitations in GEE, it is impossible to utilize many 
samples and automate hyperparameter tuning. To fill this gap and avoid 
overfitting,  the  validation  data  were  employed  for  tuning  the  key 
hyperparameters for each model. Table 3 presents the hyperparameters 
set for each model during training and validation. 

5.3.2. Pixel-based approach 

The  pixel-based  classification  approach  relies  on  the  spectral 

Table 3 
Hyperparameters were set for each machine learning technique within the GEE 
platform.  

Model 

CART   

RF   

GTB   

SVM   

Hyperparameters 

• Max nodes: No limit  
• Min leaf population: 1 

• Number of trees: 264  
• Bag fraction: 0.5  
• Variables per split: Root of the number of variables 

• Number of trees: 20  
• Shrinkage: 0.005  
• Sampling rate: 0.7  
• Loss: Least absolute deviation 

• Kernel type: RBF  
• SVM type: C_SVC  
• Decision procedure: Voting

An alternative approach to enhancing the accuracy of LULC maps is 
to leverage deep learning techniques. These techniques operate patch- 
wise,  where  each  patch  incorporates  sophisticated  features  extracted 
from satellite imagery. This enables them to recognize intricate patterns 
effectively.  Particularly,  Convolutional  Neural  Networks  (CNNs)  are 
highly  effective  for  LULC  classification.  These  models  automatically 

EcologicalInformatics80(2024)10249824M. Ganjirad and H. Bagheri

GTB: The next algorithm used in this study is GTB, which sequen-
tially improves its classification performance. This model is an ensemble 
method  that  builds  trees  sequentially,  with  each  tree  attempting  to 
correct the weakness of the previous tree (Georganos et al., 2018). The 
execution of this model demands high computational power. This lim-
itation allowed for a maximum of 20 trees in the model for this research. 
Like RF, GTB can handle datasets with various features, and combining 
differently weighted trees prevents overfitting (Ouma et al., 2022).

Table 6 
Evaluating  the  performance  improvement  by  fusion  approach,  compared  to 
pixel-based and object-based classification approaches.  

Approach 

OA (%) 

KC (%) 

Improvement (%)    

Fused, Seasonal 
Object-based, Warm 
Object-based, Cool 
Pixel-based, Cool 
Pixel-based, Warm 

94.92 
94.04 
92.81 
83.70 
82.27 

94.19 
93.27 
91.82 
81.33 
79.94 

Overall 

Kappa 

– 
+0.88 
+2.74 
+11.22 
+12.65 

– 
+0.92 
+2.37 
+12.86 
+14.25  

initially challenging due to limited access to the study area, time con-
straints,  and  the  complexity  of  different  classes.  To  address  this,  15 
apprentices were trained, and high-resolution images from Google Earth 
were utilized to collect appropriate labels. Two experts further reviewed 
the collected labels to ensure quality and accuracy.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available in the given context to determine what specific optimization techniques have been applied in the deep learning pipeline. However, some commonly used optimization techniques in deep learning include Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), and Root Mean Square Propagation (RMSProp). These methods help minimize the loss function during the training process, allowing the model to learn more effectively from the input data. Without additional details about the deep learning pipeline mentioned in the paper, I cannot provide a definitive answer regarding the optimization techniques used.