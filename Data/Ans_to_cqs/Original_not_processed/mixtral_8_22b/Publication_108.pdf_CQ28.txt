Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The overall workﬂow of preprocessing, network design, and prediction are shown in Figure 2.
Due to the size of the orthophotos and due to memory limitations when doing computations, it is
intuitive to process the orthophotos into relatively small labeled tiles (or rather small image cubes) and
feed them into the CNN. Each orthophoto of size 10,000 × 10,000 pixels was divided into 1525 tiles of
256 × 256 pixels. The data (orthophoto and corresponding labels) were then split into three datasets:
training (80%), validation (20%), and test (two full images of 10,000 × 10,000 pixels). The training
data were used for optimizing the neural network, while the validation dataset was used to assess the
performance during the training process. The test dataset was used to assess the performance of the
ﬁnal optimized neural network. The training and validation images were read into arrays with the

Figure 2. Flowchart showing the analytical workﬂow of the study.

Remote Sens. 2019, 11, 1976

5 of 14

Figure 3. (A) Example of a tile; (B) corresponding label (black: non-damaged, white: damaged).

2.3. CNN Architecture

22. Rezaee, M.; Mahdianpari, M.; Zhang, Y.; Salehi, B. Deep Convolutional Neural Network for Complex
Wetland Classiﬁcation Using Optical Remote Sensing Imagery. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.
2018, 11, 3030–3039. [CrossRef]

23. Onishi, M.; Ise, T. Automatic classiﬁcation of trees using a UAV onboard camera and deep learning. arXiv

24.

2018, arXiv:1804.10390.
Freudenberg, M.; Nölke, N.; Agostini, A.; Urban, K.; Wörgötter, F.; Kleinn, C. Large Scale Palm Tree Detection
In High Resolution Satellite Images Using U-Net. Remote Sens. 2019, 11, 312. [CrossRef]

25. Wagner, F.H.; Sanchez, A.; Tarabalka, Y.; Lotte, R.G.; Ferreira, M.P.; Aidar, M.P.M.; Gloor, E.; Phillips,
O.L.; Aragão, L.E.O.C. Using the U-net convolutional network to map forest types and disturbance in the
Atlantic rainforest with very high resolution images. Remote Sens. Ecol. Conserv. 2019, doi:10.1002/rse2.111.
[CrossRef]

Remote Sens. 2019, 11, 1976

8 of 14

2.6. Comparison to a Support Vector Machine Classiﬁer and a Random Forest Algorithm

To better understand the performance of the CNN, comparisons with pixel-wise classiﬁcations
based on an SVM and an RF classiﬁer were carried out using the 4 spectral bands of the orthophotos
(see Section 2.1) as predictors. Due to computational reasons, it was not possible to utilize the entire
original training dataset (as used for the CNN) for the SVM and the RF classiﬁer. Thus, we used a
subsample of 10,000 randomly-selected pixels for the training phase of both classiﬁers. These pixels
were representative for the data space. Note that both classiﬁers used a pixel-based approach while the
CNN was extracting features and thus considered the spatial correlation between neighboring pixels.
For the SVM classiﬁer, the radial basis function kernel (RBF) was applied. The RF classiﬁer was run
with a maximum tree depth of 5 and 100 estimators (i.e., decision trees).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention or indication of which specific platform was used to deploy the deep learning model. Therefore, it cannot be determined whether they used Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform, or any other cloud service provider.