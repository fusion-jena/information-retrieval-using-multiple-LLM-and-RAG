Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ran in approximately 1.2 min for our experiments on the CPU, whilst 
softmax  took  12  min  on  the  GPU  to  complete  the  same  task.  So, 
although, softmax can accomplish our classification task, our proposed 
method has advantages.

easy to train with reduced complexity, even though they have deeper 
layers than CNN models, because of the presence of skip connections 
between the input and output of each block (He et al., 2016). ResNet has 
different variants with a variety of convolution layers. We trialled three 
depths, ResNet-18, (cid:0) 50 and (cid:0) 101, and compared their training times 
and validation accuracies. They behaved similarly but ResNet-50 had a 
marginally  higher  validation  accuracy  (Section  3.1.1)  leading  us  to 
choose it for feature extraction.

(<i>eristalis tenax</i>) as a crop pollinator in New Zealand. NZ Plant Protect., 72: 
221–230. URL https://nzpps.org/_journal/index.php/nzpp/article/view/304. 
Jena, B. et al., 2021. Artificial intelligence-based hybrid deep learning models for image 
classification: The first narrative review. Comput. Biol. Med., 137: 104803. ISSN 
0010–4825. https://www.sciencedirect.com/science/article/pii/ 
S0010482521005977. 

Joly, A., et al., 2019. Overview of lifeclef 2019: Identification of amazonian plants, south 

& north american birds, and niche prediction. In: Experimental IR Meets 
Multilinguality, Multimodality, and Interaction. Springer International Publishing, 
Cham, ISBN 978-3-030-28577-7, pp. 387–401. https://doi.org/10.1007/978-3-030- 
28577-7_29. 

Jones, L.E., Leather, R.S., 2012. Invertebrates in urban areas: a review. EJE. ISSN:

Fig. 5. The software classifier showing the structure of ResNet-50 generating a feature vector of size 1000. This is used to train the SVM classifier to classify the insect 
image backgrounds into two classes. The notation ‘axa, b’ in the convolution blocks 1–5 represent a filter of size a and b channels. The output of each convolution block is 
represented by ‘Size x’. The repetition of each square shape in each convolution block represents the repetition of each unit.. 

connected layer, that outputs a 1000-dimensional feature vector. 

3.1. The discovery of exceptions and special cases during the manual 
classification of image backgrounds 

2.4.3. Training and validating the classifier model

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available from the given context to determine the specific hyperparameters used in the deep learning model, such as the learning rate or optimizer. It would be necessary to refer to additional resources or documentation related to this particular study to find out more about these details.