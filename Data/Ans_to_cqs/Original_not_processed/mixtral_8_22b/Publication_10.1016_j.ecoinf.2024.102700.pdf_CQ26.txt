Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

projection
methodologies;
• Utilize long-term/

historical data to project
into future scenarios.

EcologicalInformatics82(2024)10270013E. Pasanisi et al.

analysis. However, while regression-based models remain prevalent (n
= 23), there was an increased use of machine learning techniques (n =
22), particularly Maxent, and, although limited, deep learning strategies
(e.g., neural networks, Cazau et al., 2023), likely suggesting a shift to-
wards machine learning methodologies (Maglietta et al., 2023). Another
notable trend was the increased incorporation of anthropogenic vari-
ables in modelling to assess the influence of human activity on species
habitat use, especially related to fishing and boating activities (n = 7
studies; e.g., Díaz L´opez and Methion, 2024).

2.4. Meta data coding & data synthesis

model according to specific needs and available information, incorpo-
rating “features classes” and a “regularisation multiplier” to find a
proper trade-off between flexibility and overfitting (Muscarella et al.,
2014). The advantages of Maxent accounts for its widespread use,

2.3. Screening process

Screening was performed at three stages for efficiency: title, abstract
and full text. The inclusion and exclusion criteria were aligned with
those listed and descripted in Table 1, ensuring consistency throughout
the screening process. To include abstracts and full text, all the criteria
were applied and the reason for exclusion was reported. To check for
inter-rater reliability in the inclusion criteria, two reviewers indepen-
dently screened a subset (10%) of titles and abstracts for relevance
against predetermined criteria before the screening process began. The

Fig. 1. Flow Diagram resuming the searching, screening and synthesis process performed systematically according to criteria listed in Table 1.

EcologicalInformatics82(2024)1027003E. Pasanisi et al.

Cohen's Kappa test measured a perfect agreement (k = 1, n = 100%) for
both title and abstract screening. The Fig. 1 illustrates the flow diagram
of the screening process.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide direct information about the techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on general knowledge, some common techniques used to handle data imbalance or bias include stratified sampling, oversampling, undersampling, and diverse data collection.

Stratified sampling is a technique where the dataset is divided into strata or subgroups, and then samples are drawn from each stratum in such a way that they represent the population accurately. This helps maintain the balance of different classes in the dataset.

Oversampling involves increasing the number of instances in the minority class by replicating them or creating synthetic examples using methods like SMOTE (Synthetic Minority Over-sampling Technique). Undersampling, on the other hand, reduces the size of the majority class by randomly removing instances or selecting only those that contribute most to the model's performance.

Diverse data collection aims to gather more representative data by including various sources, demographics, or features. This can help reduce bias introduced due to underrepresentation or overrepresentation of certain groups in the dataset.