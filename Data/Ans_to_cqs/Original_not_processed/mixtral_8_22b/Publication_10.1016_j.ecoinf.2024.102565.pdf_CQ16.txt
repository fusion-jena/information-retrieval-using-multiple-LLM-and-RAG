Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

During the validation phase of the machine learning algorithms, a K- 
fold cross-validation technique was implemented. Additionally, a four- 
fold  cross-validation  was  conducted  on  the  training  dataset,  as  illus-
trated in Fig. 4. The dataset was initially extracted, and the feature set 
was randomly divided into four mutually exclusive folds through strat-
ified sampling (Guo et al., 2021; Psychalas et al., 2023). Each fold served 
as  the  validation  set,  while  the  remaining  three  folds  constituted  the 
training set for model training. To address imbalances, random under 
sampling (RUS) was applied to the training set, while the validation set 
remained unchanged. The model underwent training using the balanced 
three-fold  training  dataset  for  a  specified  number  of  epochs  and  was 
subsequently  tested  on  the  validation  fold to  generate  predictions for 
that specific fold. This process iterated four times with distinct valida-

To  overcome  data  limitations  and  enhance  the  robustness  of  the 
model  training  process,  this  study  employed  a  K-fold  cross-validation 
technique with K set to four. Unlike traditional approaches that segre-
gate  data  into  distinct  sets,  this  method  maximized  the  utilization  of 
both  on-site  and  RS  datasets,  integrating  them  comprehensively  into 
both training and validation phases (Aptoula and Ariman, 2021; Escoto 
et al., 2021; Psychalas et al., 2023). The distinctive feature of the K-fold

Type 

Training Phase 

Validation Phase 

Linear Regression 
Regression Trees 
Support Vector Machines 
Gaussian Process Regression 
Neural Network 

R2 

0.796 
0.771 
0.797 
0.798 
0.882 

RMSE [g m(cid:0) 3] 

2.580 
2.752 
2.571 
2.562 
1.970 

MAE 

1.870 
2.070 
1.860 
1.890 
1.333 

MBE 

0.034 
0.067 
0.101 
0.002 
0.003 

R2 

0.790 
0.659 
0.780 
0.765 
0.840 

RMSE [g m(cid:0) 3] 

2.621 
3.342 
2.661 
2.777 
2.010 

MAE 

1.900 
2.423 
1.932 
1.994 
1.457 

MBE 

0.091 
0.317 
0.077 
0.232 
0.034  

EcologicalInformatics81(2024)10256511A. Noori et al.

cross-validation  method  lies  in  its  utilization  of  all  available  data  for 
both training and validation, providing a more holistic assessment (Guo 
et  al.,  2021;  Li  et  al.,  2021;  Psychalas  et  al.,  2023).  By  adopting this 
strategy, the study aimed to bolster the reliability of the modelâ€™s per-
formance evaluation  while making efficient  use of the  limited on-site 
and  RS  data.  The  scientific  flow  chart  illustrated  in  Fig.  2  succinctly 
outlines the adopted methodology. 

2.4.1. Case-2 Regional CoastColour (C2RCC)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the criteria used to determine when training is complete. However, it mentions that the model undergoes training using the balanced three-fold training dataset for a specified number of epochs. An epoch refers to one forward and one backward pass of all the training examples. Typically, training continues until a certain stopping criterion is met, such as reaching a maximum number of epochs or achieving a desired level of performance on a validation set. In this case, since the text mentions a specified number of epochs, it can be inferred that the training may have been stopped after completing these epochs. However, without further details, it cannot be confirmed if other stopping criteria were also considered.