Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

10 of 20

Table 1. Comparison of statistical accuracy metrics between the random forest and deep learning
models.

Model Types

MAE (Mean
Absolute Error)

RMSE (Root Mean
Square Error)

Bias

Correlation

Random Forest
Deep Learning

61.1028
28.8105

78.9512
38.5759

0.5656
10.2055

0.8843
0.9752

The training process was performed for a number of iterations in which all the training
data were exposed to the network until the loss function reached its minimum value. The
model score reached its maximum after approximately 5000 iterations with a NVIDIA
Titan X GPU (3584 CUDA cores). The number of trainable parameters was 85,569 and the
computational run-time was approximately 4 h with a training batch size of 1024.

Deep learning approaches have shown promising results in many scientiﬁc applica-
tions [67,68] but do not always guarantee better outcomes [69,70]. Therefore, we compared
the performance of the proposed DL model with a RF regression model as a baseline, since
RF showed reasonable results and is popular in various machine learning applications [71].
To determine the best values of the hyperparameters (number of trees, maximum tree
depths, and the maximum number of features) in the RF model, a grid search was used.

Due to the unique characteristics of neural networks, which solve problems by ex-
ploiting the hidden relationships inherent in multiple input variables, it was difﬁcult to
physically quantify the importance of the input variables. As an alternative, we performed
a statistical feature importance test (SFIT) to explain which feature had the greatest sig-
niﬁcance in the species richness retrievals and to determine the optimized features in
an operational retrieval system. For the SFIT, a single feature was randomly shufﬂed,
while all the other features were kept constant. We iterated this process by changing the
test variable. The feature importance shows the extent to which the model performance
decreased with random shufﬂing. In this study, we used the root mean square error (RMSE)
as the performance metric.

2.5. Independent Validation of Species Richness

70.

71.

metrics using diverse drug discovery data sets. Mol. Pharm. 2017, 14, 4462–4475. [CrossRef]
Joharestani, M.Z.; Cao, C.; Ni, X.; Bashir, B.; Talebiesfandarani, S. PM2.5 prediction based on random forest, XGBoost, and deep
learning using multisource remote sensing data. Atmosphere 2019, 10, 373. [CrossRef]
Fernández-Delgado, M.; Cernadas, E.; Barro, S.; Amorim, D. Do we need hundreds of classiﬁers to solve real world classiﬁ-cation
problems? J. Mach. Learn. Res. 2014, 15, 3133–3181.

72. Korea Forest Service. The 6th National Forest Inventory and Monitoring; Korea Forest Service: Daejeon, Korea, 2016.
73. Choe, H.; Thorne, J.H.; Huber, P.R.; Lee, D.; Quinn, J.F. Assessing shortfalls and complementary conservation areas for national

plant biodiversity in South Korea. PLoS ONE 2018, 13, e0190754. [CrossRef]

74. Malhi, Y.; Franklin, J.; Seddon, N.; Solan, M.; Turner, M.G.; Field, C.B.; Knowlton, N. Climate change and ecosystems: Threats,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The performance of the deep learning model is evaluated using several statistical accuracy metrics. These include Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Bias, and Correlation.

The MAE measures the average magnitude of errors in a set of predictions without considering their direction. It’s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.

The RMSE is a measure of the differences between predicted and observed values. It’s calculated as the square root of the mean of the squared differences between prediction and actual observation. This gives more weight to large errors, making it sensitive to outliers.

Bias refers to the difference between the expected value and the estimated value. A positive bias indicates that the estimator tends to overestimate the parameter, while a negative bias indicates that the estimator tends to underestimate the parameter.

Correlation measures the strength and direction of association between two or more variables. In this case, it likely refers to how well the predicted values correlate with the actual observations.

These metrics help assess the quality of the model's predictions and provide insights into potential biases or issues with the model. However, they do not directly correspond to traditional classification metrics like accuracy, precision, or recall, as these are typically used when dealing with categorical rather than continuous outputs.