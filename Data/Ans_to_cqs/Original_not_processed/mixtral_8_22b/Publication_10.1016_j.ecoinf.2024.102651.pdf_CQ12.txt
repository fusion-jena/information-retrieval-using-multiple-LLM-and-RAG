Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

tion and Transformer, effectively extracts richer semantic features (Xie 
et al., 2024). A network based on CNN and ViT modules classified mi-
croorganisms with an accuracy of 67.62% (Dwivedi et al., 2024).

Compared with ViT, CNN has stronger local information extraction 

ability.  In  particular,  the  residual  structure  of  ResNet  connects  the 
different network layers via shortcut, which not only preserves the input 
features  but  also  addresses  the  degradation  problem  of  the  deep 
network, thus mitigating issues such as vanishing or exploding gradi-
ents. The residual structure can help the network to learn the features in 
the input image better, thereby improving the classification effect of the 
network. 

Different classes of objects of the same species have high similarities. 
To better classify objects, CA-Hybrid network is constructed for Cervidae 
classification, based on ResNet and ViT, with the integration of CAM into 
the residual structure of ResNet. The structure of the CA-Hybrid network 
is shown in Fig. 4.

CA-Hybrid network based on CNN and ViT (Dosovitskiy et al., 2020) is 
constructed as the classification network to precisely categorize Cervi-
dae  localized  by  YOLOv7.  Within  the  CA-Hybrid  network,  by  intro-
ducing the CAM (Woo et al., 2018) in the CNN, the network was able to 
focus more on critical features, which boosted the generalization ability 
of the model. Finally, when utilizing the same classification network for 
both small  objects(pixels less than 32*32) and  medium objects(pixels 
between 32*32 and 96*96) to evaluate the influence of image size on 
classification performance, the medium objects achieved higher classi-
fication  accuracy  compared  to  small  objects  under  identical  network. 
Furthermore, by comparing the performance of our monitoring pipeline 
with  object  detection  networks,  the  effectiveness  of  the  pipeline  was 
demonstrated. The pipeline effectively resolves the issue of background

Du, P., Qu, X., Wei, T., Peng, C., Zhong, X., Chen, C., 2018. Research on small size object 
detection in complex background. In: 2018 Chinese Automation Congress (CAC). 
IEEE, pp. 4216–4220. 

Dwivedi, K., Dutta, M.K., Pandey, J.P., 2024. EMViT-net: a novel transformer-based 

network utilizing CNN and multilayer perceptron for the classification of 
environmental microorganisms using microscopic images[J]. Eco. Inform. 79, 
102451. 

Eikelboom, J.A., Wind, J., van de Ven, E., Kenana, L.M., Schroder, B., de Knegt, H.J., van 
Langevelde, F., Prins, H.H., 2019. Improving the precision and accuracy of animal 
population estimates with aerial image object detection. Methods Ecol. Evol. 10 
(11), 1875–1887. 

Feng, J., Li, J., 2022. An adaptive embedding network with spatial constraints for the use 
of few-shot learning in endangered-animal detection[J]. ISPRS Int. J. Geo Inf. 11 (4), 
256.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The pipeline uses a hybrid deep learning model called CA-Hybrid network, which combines Convolutional Neural Network (CNN) and Vision Transformer (ViT) architectures. This network is specifically designed for Cervidae classification and utilizes Class Activation Map (CAM) within its residual structure to focus more on critical features, enhancing the model's generalization ability. The CA-Hybrid network leverages the strengths of both CNN and ViT models; while CNN excels in local information extraction and addressing degradation problems in deep networks, ViT contributes to extracting richer semantic features.