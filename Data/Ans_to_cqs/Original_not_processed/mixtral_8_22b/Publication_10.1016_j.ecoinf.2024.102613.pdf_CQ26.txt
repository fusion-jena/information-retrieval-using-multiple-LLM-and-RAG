Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

24.  Which features will you need for data preprocessing?  

• Data deduplication (Eliminating excessive copies of data)  
• Data  cleansing  (Removing  incorrect,  corrupted,  incomplete 

data)  

• Data transformation (Changing the structure or format of data)  
• Data compression (Modifying or converting the bits structure 

of data)  

• I do not know  
• Not applicable  
• Other  

25.  In data processing, which one do you choose?  

• Using well-labeled training data (Supervised)  
• Combining  labeled  with  unlabeled  training  data  (Semi- 

supervised)  

• Using unlabeled training data (Unsupervised)  
• I do not know  
• Not applicable  

26.  What kind of data analytics do you need?  

• To know what happen (Descriptive analytics)  
• To know how something happen (Diagnostic analytics)  
• To know what will happen (Predictive analytics) 
• To  know  what  should  be  done  if  something  happens  (Pre-

scriptive analytics)

3.2.2.5. Data processing. In data processing features (see Fig. 18), data 
preprocessing aims to prepare and facilitate data processing operations 
(Salma et al., 2017; Yang et al., 2021). The data is cleaned, transformed, 
or  compressed  to  be  ready  for  the  analysis  stage.  Data  cleansing  is  a 
mandatory  feature  in  data  preprocessing,  while  other  features  are 
optional  and  depend  on  the  needs  or  purposes  of  data  analytics. 
Furthermore, in an agricultural system, it is common to see various types 
of  analyzing  the  data,  such  as  descriptive,  diagnostic,  predictive,  or 
prescriptive analytics. Hence, the system uses advanced analytics tech-
niques,  namely  geospatial  analysis,  mathematical  model,  statistical 
analysis, deep learning, and machine learning, depending on analytics 
types or purposes and users’ needs. The machine learning method has its 
own types to analyze the data and specific tasks to generate the analytics

2019; Zamora-Izquierdo et al., 2019) and then machine learning and, 
more  recently,  deep  learning  techniques  are  applied  to  analyze  the 
generated data (Perakis et al., 2020; Swain et al., 2020). However, the 
traditional  data  management  systems  are  inadequate  to  handle  the 
volume, velocity, and variety of the generated data by the sensors and 
IoT devices (Wolfert et al., 2017). Hence the advanced data management

3.2.2.2. Data acquisition. This feature is responsible for generating new 
data or collecting the existing ones (Demestichas and Daskalakis, 2020). 
The data acquisition features consist of data loading, data logging, data 
aggregation, and data transfer. Data aggregation has the following sub- 
features: data fusion and data integration. Data fusion refers to concat-
enating two or more representations of two identical objects into single, 
clear,  and  consistent  ones  (Demestichas  and  Daskalakis,  2020).  Data 

Fig. 14. Feature diagram of data.  

transfer  includes  the  following  sub-features:  Wireless  Sensor  Network 
(WSN), Bluetooth, Radio Frequency Identification (RFID) and Cellular 
network (see Fig. 15). 

Fig. 15. Feature diagram of data acquisition.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes within each set. This ensures that the classifier learns from a representative sample of all classes, reducing any potential bias towards certain classes.

Oversampling is a technique where synthetic samples are created from the minority class to balance the dataset. This helps prevent the classifier from being biased towards the majority class due to their higher representation in the dataset.

Undersampling, on the other hand, involves removing instances from the majority class until both classes have equal representation. While this may result in loss of information, it can help reduce bias towards the majority class.

Diverse data collection involves gathering data from different sources and environments to ensure that the dataset is representative of real-world scenarios. This can help mitigate any potential bias introduced by using only one source of data.

In summary, addressing data bias during preprocessing of the deep learning pipeline requires careful consideration of the dataset's characteristics and employing appropriate techniques such as stratified splitting, oversampling, undersampling, and diverse data collection.