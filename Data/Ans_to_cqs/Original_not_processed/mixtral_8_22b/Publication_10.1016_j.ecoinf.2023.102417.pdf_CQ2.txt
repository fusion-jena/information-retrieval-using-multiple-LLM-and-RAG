Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

processing  of  the  recorded  images.  In  some  cases,  deep  learning 
models perform quite poorly when the training data and the test data are 
recorded with different types of cameras, different illumination condi-
tions  and/or  different  acquisition  geometries.  Hence,  additional  con-
siderations  concerning  transferability  of  the  model  are  needed,  if 
training  and  model  application  are  based  on  datasets  taken  with 
different devices, as e.g., reflex camera and smartphone, respectively.

We have shown that deep learning methods can be applied to achieve 
a  valid  biocrust  classification on  species and/or  genus level  based  on 
standard RGB image data. The advantage of analyzing RGB images is, 
that they can be acquired relatively inexpensively with standard camera 
sensors, which allows an easy data acquisition for biomonitoring. The 
most time-consuming step to obtain a good segmentation model is the 
creation of the training datasets, which can be quite time consuming. In 
our case, the required labelling time was up to 2 h per image for the USA 
Data. Modern deep learning tools can be used to do an automated seg-
mentation of images to safe labelling time (Kirillov et al., 2023). Other 
segmentation models aim to do an unsupervised image segmentation, 
where the only specification is the required number of classes (Harb and 
Kn¨obelreiter, 2021; Ji et al., 2019). In our case the results of the auto-

Neural  networks  can  be  trained  in  a  supervised,  semi-supervised 
(Chen  et  al.,  2021;  Zhao  et  al.,  2020)  or  unsupervised  (Harb  and 
Kn¨obelreiter, 2021; Ji et al., 2019) way. When it comes to supervised 
learning (Deng et al., 2009; Minaee et al., 2021), the models are typi-
cally  trained with a  huge amount of  training data. This  training  data 
consist of input and target image pairs, where the input image describes 
the image that is supposed to be classified and the target image describes 
the  corresponding  classes  (labels).  For  semantic  image  segmentation, 
the  target  image  consists  of  a  fully  labeled  image,  which  means  that 
every single pixel of the training image is assigned to a certain class. In 
some cases, parts of the image that have no influence on the specific task 
can  be  ignore  by  the  model  (overexposed,  underexposed  or  blurred 
parts, unimportant parts etc.). This can be done by adjusting the loss

models  can  extract  complex  image  features  and  project  them  into  a 
latent space representation to produce an image classification based on 
these features. To achieve a suitable biocrust coverage estimation, one 
needs to classify every pixel of an image at the highest possible accuracy. 
This pixel-wise classification is called semantic segmentation. Various 
neural  network  architectures  like  UNet  (Ronneberger  et  al.,  2015)  or 
DeepLabV3  (Chen  et  al.,  2017)  were  developed  for  semantic  image 
segmentation (Minaee et al., 2021).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text primarily discusses the use of deep learning methods for biocrust classification using RGB image data. It mentions that these images can be obtained relatively inexpensively with standard camera sensors. Therefore, the primary data format used in this deep learning pipeline is RGB image data. However, the text does not explicitly mention other data formats such as audio, video, or CSV files being used in the deep learning pipeline.