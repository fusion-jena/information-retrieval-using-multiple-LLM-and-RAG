Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ll

OPEN ACCESS

difﬁcult for multimedia data which are typically much more com-
plex than other data types. For example, biodiversity and envi-
ronmental records in the form of audio, video, or image ﬁles
are typically larger and more complex than text or numeric
data. Large-scale analysis of multimedia data has only been
possible in recent years since the development of large compu-
tational facilities, both academic and commercial. Regardless,
the analysis of multimedia data is often further complicated
because of their non-standardized methods of acquisition, with
highly diverse devices, sensors, formats, scales, environmental
contexts, and taxonomic scope. Building efﬁcient, scalable,
and robust approaches to solve these problems is a difﬁcult sci-
entiﬁc challenge at the forefront of data science and machine
learning speciﬁcally.

Artiﬁcial

the Pl@ntNet user community (currently 1.8 million user accounts). At the time
of writing, the CNN architecture used is the inception model49 extended with
batch normalization.50 The network is pre-trained on the commonly used Im-
ageNet dataset and ﬁne-tuned on Pl@ntNet data. Pl@ntNet currently covers
30,261 species illustrated by more than 2.9 million images. The taxonomic
coverage of our study is therefore one to three orders of magnitude larger
than previously published studies making use of automated species identiﬁca-
tion for ecological research. The training of Pl@ntNet CNN requires the mobi-
lization of a high-performance computing infrastructure and expertise in deep,
distributed, and large-scale learning. Thus, the resulting classiﬁcation tool is in
itself a major advance in biodiversity data science.

Access to the Pl@ntNet classiﬁcation tool is provided through a dedicated
API available at my.plantnet.org. The main feature of this API is a RESTful
JSON-based web service that can accept one to ﬁve images of a plant and re-
turns a list of likely species. The species are associated with classiﬁcation
scores (the softmax output of the CNN), as well as a list of matching images
retrieved from the database. To facilitate the implementation of future studies
based on the methodology of this paper, we have developed the ‘‘plantnet’’51
R-package allowing users to query the Pl@ntNet API. The package is available
online at https://github.com/BiologicalRecordsCentre/plantnet.

Applications of AI to biological recording have to date typically
focused on active sampling, that is, images collected speciﬁcally
for the purpose of recording wildlife24 (e.g., wildlife recording
apps or camera traps). However, this has neglected large
amounts of image data that are not collected for the purposes
of biological recording, but which nonetheless may contain
useful information about biodiversity. This includes social media
imagery25 (e.g., Flickr and Instagram), CCTV, and imagery
collected along linear infrastructure (e.g., Google StreetView).
These unexploited image data could be rapidly analyzed using
‘‘AI naturalists’’ designed to locate potential images of biodiver-
sity and classify what they see. This is an example of internet
ecology or ‘‘iEcology’’ as recently proposed by Jari(cid:2)c and col-
leagues,26 whereby digital data collected for a different purpose
is analyzed to gain insights into the natural world. However,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning pipeline primarily uses image data. Specifically, it employs the Inception model, which is a type of Convolutional Neural Network (CNN) designed for processing images. The network is initially trained on the ImageNet dataset, a large collection of labeled images, and then fine-tuned using PlantNet data. The PlantNet classification tool accepts one to five images of a plant and returns a list of likely species, along with classification scores and matching images retrieved from the database. Therefore, the primary data format used in this deep learning pipeline is image data.