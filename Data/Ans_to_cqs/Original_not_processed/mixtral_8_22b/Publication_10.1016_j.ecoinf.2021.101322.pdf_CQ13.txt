Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Performance of the CNN models were assessed using four different 
metrics (test loss, mean squared error - MSE, mean average percentage 
error – MAPE and accuracy - Acc). Accuracy of the regression tasks was 
calculated  by  rounding  the  prediction  to  the  nearest  integer  age  and 
comparing it with the ground truth. The labelling provided by human 
readers  are  treated  as  the  ground  truth,  and  accuracy  and  other  per-
formance metrics relates directly to this. 

The CNN hyperparameters configurations used for all four networks 
during training are shown in Table 1. During training we use minibatch 
gradient descent. 

2.4. Comparing the CNN and six expert readers using an independent 
dataset

2. Methods 

2.1. CNN training data

2.3. Implementation and training 

The  CNN  was  implemented  using  the  Keras  (Chollet,  2015)  and 
TensorFlow  (Abadi  et  al.,  2016)  software  packages  implemented  in 
Python, and computation was performed using CUDA version 9.1 and 
CuDNN  with  Nvidia  (Nvidia  Corp.,  Santa  Clara,  California)  P100 
accelerator cards with 12 GB of GPU memory. We used a Keras imple-
mentation of EfficientNet–B4 called EfficientNet V1.1.0 (https://github. 
com/qubvel/efficientnet).  The  pre-trained  weights  used  for  transfer 
learning were available through this API.

Number of epochs without improvement in validation 
error before training will terminate early  

Table 2 
CNN performance metrics. MSE is the mean square error, MAPE is the mean 
average percentage error, and Acc% is the average accuracy. In addition, the 
number of images in the dataset (set size) for each task and the weighting of 
classes are given. The × indicates that the performance metric is not applicable 
to the specific CNN.  

Predicting 

River Age 
Sea Age 
Spawning 

Test 
loss 

0.336 
0.157 
0.113 

MSE 

MAPE 

0.336 
0.157 
×

17.34 
8.64 
×

Acc 
% 

63.20 
86.99 
96.40 

Set 
size 

6238 
8286 
9056 

Farmed 

0.187 

×

×

96.70 

5919 

Weighting classes 

– 
– 

Non-spawner: 0.5, 
Previous 
spawner:19 
Farmed: 5.87, 
Wild:0.54

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Unfortunately, the table containing the hyperparameter configurations for the Convolutional Neural Network (CNN) models mentioned in the text is not included in the provided information. However, I can tell you that during training, they used mini-batch gradient descent. Additionally, the implementation of the CNN was done using the Keras and TensorFlow software packages in Python, utilizing CUDA version 9.1 and CuDNN with Nvidia P100 accelerator cards with 12GB of GPU memory. They also employed a Keras implementation of EfficientNet-B4 known as EfficientNet V1.1.0 for their work. Pre-trained weights for transfer learning were accessible via the provided API.