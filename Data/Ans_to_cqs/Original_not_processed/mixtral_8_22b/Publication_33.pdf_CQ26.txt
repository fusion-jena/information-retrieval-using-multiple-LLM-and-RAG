Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The proposed post-processing was able to decrease the misclassification rate by at least 10.05%, for all goals, 
and 19.02% at most compared to the raw output of the Deep Learning model (Fig. 6b). The accuracy followed the 
same tendency, with an average accuracy for G1, G2 and G3 respectively equal to 0.74, 0.81 and 0.92 (Table 3).
Finally, we also performed the same experiment while switching T1 and T2 roles (Supplementary Tables S6, 
S7, S8). For each goal, the unsure classification rate was higher after the switch (+ 3.8% for G1, + 4.4% for G2, 
and + 8.9% for G3), implying lower scores were obtained in both correct classification (− 3.5%, − 5%, − 7.3%) and 
misclassification, with the exception of the 2nd goal (-0.2%, + 0.6%, − 1.6%).

to calibrate Deep Learning models using a single parameter for all  classes35. This parameter is used, instead of 
the traditional softmax function, to convert the vector output from the neural network into a real probability.

Whatever the goal, our framework is highly flexible and can be adapted by tuning the species thresholds 
regulating the trade-off between classification robustness and coverage in an attempt to monitor biodiversity 
through big datasets where species are unidentified. To unclog the bottleneck of information extraction about 
organism forms, behaviors and sounds from massive digital data, machine learning algorithms, and particularly 
the last generation of deep learning algorithms, offer immense promises. Here we propose to help the users to 
control their error rates in ecology. This is a valuable addition to the ecologist’s toolkit towards a routine and 
robust analysis of big data and real-time biodiversity monitoring from remote sensors. With this control of error 
rate in the hands of users, Deep Learning Algorithms can be used for real applications, with acceptable and 

Scientific RepoRtS  |        (2020) 10:10972  | 

https://doi.org/10.1038/s41598-020-67573-7

11

training datasets.

•  In the first phase, a classification model is built by training a CNN on a given database T0 (Fig. 2a)
•  Then, the second phase consists of tuning a risk threshold τi specific to each class (i.e. each species in our 

case), noted i, with i ∈ {1, ..., n} , using a second and independent database noted T1 (Fig. 2b).

In terms of classification, it means we transform the 2 classification options (correct, wrong) in 3 options 

(Fig. 3) by applying Eqs. (15, 16).

Computing the confidence thresholds.  After the phase 1 (model training phase), for an image X of the 
threshold tuning dataset processed by the classifier, we obtain an output {C(X), S(X)} , where C(X) is the class 
(i.e. species, belonging to the trained set of species) with the highest classification score S(X). For this image, we 
know the ground truth Y in {1, .., n} belonging to the same set of species classes.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, there isn't any explicit mention or discussion regarding addressing data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. Therefore, I cannot provide a direct answer based solely on the given text. However, these techniques are commonly employed to mitigate data imbalance issues and improve the performance of deep learning models.

Stratified splitting involves dividing the dataset into subsets ensuring that the distribution of target variables remains consistent across different sets. Oversampling increases the number of instances in minority classes, whereas undersampling reduces instances in majority classes to balance the dataset. Lastly, collecting diverse data helps ensure that the model generalizes well to various scenarios and populations.