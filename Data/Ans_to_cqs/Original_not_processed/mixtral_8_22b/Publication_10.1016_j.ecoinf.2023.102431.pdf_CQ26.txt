Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

outliers and removed from the dataset for subsequent analyses.

To identify variables with the greatest potential to discriminate be-
tween classes of objects (e.g., species or fisher sex) we used a predictor 
screening analysis that uses bootstrap forest partitioning to evaluate the 
contribution  of  predictors  on  the  response  object.  For  each  response 
object  we  employed  predictor  screening  using  1000  decision  trees  to 
evaluate all 124 potential FIT metrics. We then used the top predictor 
variables to evaluate the dataset for two potential sources of bias, 1) the 
use of mirrored right front tracks instead of only left front tracks (foot 
position  bias)  and  2)  the  potential  for  bias  between  observers  when 
manually  marking  the  landmark  points  in  the  FIT  interface (observer 
bias) which is a somewhat subjective process. Foot position (left-front or 
right-front) of each track was recorded for each track during the feature 
extraction  process.  To  evaluate  observer  bias  we  had  3  different  ob-

Alibhai  et  al.,  2023)  further  simplifies  the  approach,  increasing  effi-
ciency in the FIT process by requiring fewer landmark points, and also 
making it easier to employ on tracks of varying quality that may lack 
edge definition.

Table 1 
Sample sizes for training, test, and validation groups for discriminant analysis of 
species and sex.   

Species Discrimination 

Fisher Sex Discrimination  

Marten 
Tracks 

Fisher 
Tracks 

Training 
Validation 
Test 
Total 

82 
43 
42 
167 

184 
92 
91 
367 

Individuals 
Total (Male/ 
Female) 

29 (17/12) 
19 (9/10) 
15 (7/8) 
63 (33/30) 

Tracks 
Total (Male/ 
Female) 

169 (72/97) 
99 (55/44) 
99 (50/49) 
367 (177/190)  

EcologicalInformatics79(2024)1024315J.M. Tucker et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors use several techniques to address data bias during preprocessing of their deep learning pipeline. They first remove outliers from the dataset before conducting any subsequent analyses. This helps ensure that extreme values do not skew the results.

Next, they use a predictor screening analysis that employs bootstrap forest partitioning to evaluate the contribution of predictors on the response object. This technique allows them to select the most important features for classification tasks such as species or fisher sex discrimination. By focusing on these key features, they can reduce noise and improve model performance.

Additionally, the authors take steps to mitigate foot position bias and observer bias. Foot position bias occurs because some tracks were created using both left and right front feet, while others only used one foot. The authors record the foot position of each track during the feature extraction process and account for this variable in their models. Observer bias arises due to differences in how individuals manually mark landmark points in the FIT interface. To minimize this source of error, multiple observers independently marked the same set of tracks, allowing the authors to compare and validate their results.

Finally, the authors follow best practices for stratified sampling when dividing their datasets into training, testing, and validation sets. As shown in Table 1, they maintain roughly equal proportions of male and female tracks across all three subsets. This ensures that their models generalize well to new data and reduces overfitting.

Overall, the authors demonstrate a comprehensive approach to addressing data bias during preprocessing of their deep learning pipeline. Their methods include removing outliers, selecting relevant features through predictor screening, accounting for biases related to foot position and observer variability, and implementing stratified sampling strategies. These techniques help enhance the robustness and reliability of their machine learning models.