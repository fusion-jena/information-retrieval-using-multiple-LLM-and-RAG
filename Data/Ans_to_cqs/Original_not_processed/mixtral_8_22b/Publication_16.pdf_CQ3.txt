Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Directly  relating  to  the  approach  posited  in  this  paper, 
several  deep  learning  approaches  have  been  reported  in  the 
literature  [16]  and  [17].  In  these  studies,  features  extracted 
from visual spectrogram representations of foreground species 
recordings were used to train CNNs and achieve 0.605 MAP 
in  BirdCLEF2017.  While  [10]  combined  hand-crafted 
features with deep learning in an attempt to classify fourteen 
different  bird  species  using  three  different  feature  types 
(acoustic features, visual features, and those generated using 
deep-learning). They reported that an F1-score equal to 95.95 
was possible when all three approaches were combined in an 
ensemble configuration. 
B.  Limitations

III. 

MATERIALS AND METHODS 

In  this  section  the  dataset  used  in  the  study  is  presented 
along with the modelling approach taken and the evaluation 
metrics used to evaluate the trained model. The section also 
discusses data pre-processing using the Librosa library. Keras 
and TensorFlow 2.2 are utilised as the backend and an Nvidia 
2070 super GPU with 8GB of memory is utilised to accelerate 
model training. In addition, the proposed inferencing pipeline 
is discussed along with the associated technologies. 
A.  Data Collection and Description

CNN  approaches  require  a  large  corpus  of  high-quality 
annotated  data  that  can  be  used  to  train  the  network.  Given 
that there is limited availability of publicly available data that 
satisfy this requirement there are currently no viable models 
capable of classifying within species animal types.  Another 
major challenge to overcome is the deployment and automated 
inference  of  acoustic  sensors.  Individually,  sensors  may 
generate  reasonable  amounts  of  data,  but  collectively  the 
amount  of  data  that  needs  to  be  processed  will  increase 
exponentially based on the number of sensors deployed. The 
first challenge relates directly to how the data is obtained. The 
second  is  the  cost  of  compute  needed  to  process  the  data. 
Deploying  trained  models  on  edge  devices  for  real-time 
inferencing will take some consideration which has not been 
sufficiently  reported  in  the  literature.  Centralising  inference

While  a  limited  range  of  species  have  been  used  in  this 
study,  future  work  will  significantly  expand  the  number  of 
classes  in  the  model.  The  inclusion  of  additional  data  will 
enable us to compare the approach outlined in this paper with 
more  advanced  network  architectures  such  as  1D  CNNâ€™s. 

Figure 12. Bird Classification Using Visual Data 

By using a combination of both vision and acoustic based 
data  we  can  extend  the  reach  of  the  platform  into  habitats 
where  visual  monitoring  is  not  feasible.  By  studying  both 
image and acoustic data the system can analyse and provide a 
more holistic overview of the habitat. 

References

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention any specific data annotation techniques used in the deep learning pipeline. However, it does state that CNN approaches require a large corpus of high-quality annotated data. This suggests that some form of annotation was applied to the data used in the study. Without further information, it cannot be determined whether techniques like bounding box annotation or instance segmentation were employed.