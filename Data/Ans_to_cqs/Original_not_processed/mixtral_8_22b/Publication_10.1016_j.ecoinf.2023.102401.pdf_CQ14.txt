Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Attention module 

mAp(%) 

mAp50–95(%) 

P(%) 

R(%) 

F1(%) 

– 

SE 
CA 
CBAM 

70.9 
71.1 
72.3 
72.3 

36.9 
36.7 
37.4 
37.5 

83.5 
81.6 
81.4 
83.9 

64.7 
64.9 
66.4 
65.2 

72.9 
72.3 
73.1 
73.4  

4.5. Analysis of different attention modules

28.2 
32.2 
31.6 
15.1 
28.3 
16.2 
27.1 
31.8 
36.9 
39.3 

P(%) 

96.6 
90.8 
48.1 
80.5 
93.0 
67.8 
69.9 
87.7 
83.5 
83.6 

R(%) 

31.0 
45.9 
77.7 
21.1 
32.0 
19.9 
52.8 
50.8 
64.7 
67.2 

F1(%) 

Parm(M) 

GLOPS(G) 

46.9 
61.0 
59.4 
33.4 
47.6 
31.0 
60.2 
64.3 
72.9 
74.5 

32.665 
3.83 
28.306 
36.392 
3.941 
64 
36.5 
8.939 
7.03 
13.7 

109.714 
7.43 
940.96 
164.553 
6.216 
142 
103.2 
26.763 
16 
35.1  

This study draws the mAp comparison diagram of different networks 
to  offer  a  more  intuitive  effect  when  comparing  the  performance  of 
different  networks.  The  mAp  curve  of  YWnet  is  substantially  greater 
than the curve of other networks, as illustrated in Fig. 9. YOLOv5 is the 
next best performer, and Retinanet is the worst performer.

Datasets 

Images 

Category 

Aquarium 
Trash-ICRA19 
VisDrone 
NWPU VHR-10 
HRSID 

638 
1144 
1610 
800 
5604 

7 
3 
12 
10 
1 

Train 

510 
915 
1288 
640 
4483 

Test 

128 
229 
322 
160 
1121  

EcologicalInformatics79(2024)1024017P. Liu et al.                                                                                                                                                                                                                                       

create a single image, enhancing the background of the identified object. 
Table  2  presents  the  hyperparameters  used  for  data  augmentation, 
specifying  the  ranges  and  probabilities  for  each  augmentation  tech-
nique.  These  augmentation  techniques  introduce  diversity  into  the 
training  dataset,  enabling  the  model  to  learn  robust  features  and 
improve its performance in real-world scenarios. 

Table 3 
Comparison of networks using different attention mechanism modules.

4.2. Performance evaluation 

The most important measures of a neural network model's efficacy 
are accuracy, recall, F1 score, PR curve, and average mean accuracy. The 
mean average precision (mAp), which is the average AP of all n cate-
gories, measures the effect of accuracy and recall thoroughly. The mAp 
was chosen as the major model evaluation in the study, comprehensively 
analysing the model detection accuracy, recall, and F1 scores, which are 
derived as follows: 

P =

TP
TP + FP

(13)  

R =

TP
TP + FN

F1 =

2 × P × R
P + R

∫ 1

AP =

P(R)dR

0

(14)  

(15)  

(16)  

where TP stands for the true positive, FP stands for the false-positive, TN 
stands for the true negative and FN stands for the false-negative. 

4.3. Datasets

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't any information available regarding how the hyperparameters of the model were optimized. The given context does not mention whether grid search, random search, or another method was employed for this purpose. Therefore, it is not possible to provide a helpful response based on the provided context.