Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Vanhoucke, V., Rabinovich, A., 2015. Going deeper with convolutions. In: 
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 
pp. 1–9. https://doi.org/10.1109/CVPR.2015.7298594. 

Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., Le, Q.V., 2019. 

Mnasnet: Platform-aware neural architecture search for mobile. In: Proceedings of 
the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 
pp. 2820–2828. https://doi.org/10.1109/CVPR.2019.00293. 

W¨agele, J.W., Bodesheim, P., Bourlat, S.J., Denzler, J., Diepenbroek, M., Fonseca, V., 
Frommolt, K.-H., Geiger, M.F., Gemeinholzer, B., Gl¨ockner, F.O., et al., 2022. 
Towards a multisensor station for automated biodiversity monitoring. Basic Appl. 
Ecol. 59, 105–138. https://doi.org/10.1016/j.baae.2022.01.003.

We  used  Pytorch  to  build  our  deep  neural  network,  which  was 
trained on Nvidia V100 GPU. In order to accelerate the convergence of 
the model, our model was pre-trained on the ImageNet dataset (Deng 
et  al., 2009) and then independently  fine-tuned on our  PAD Full and 
PAD Lite datasets. However, some individuals cross multiple age groups. 
Thus, to eliminate the influence of individuals, we applied a five-fold 
subject-exclusive  (SE)  (Han  et  al.,  2014;  Pan  et  al.,  2018)  which 
ensured the same subject did not appear in the training set and testing 
set at the same time. We downscaled the resolution of all images to 224 
× 224 pixels before feeding them to seven models. To avoid overfitting 
and imbalanced problem, we applied aggressive data augmentation. Our 
original images were captured under different illumination and angles. 
Thus, we augmented all training sets randomly via horizontal flipping,

In  addition  to  calculating  MAE  values,  we  also  compared  the 
inference-time to determine the most computationally efficient model. 
We set the batch to 400 to achieve 100% GPU utilization of each model 
and to measure the maximum queries per second (QPS) achieved under 
real-world conditions (Ding et al., 2021). All models were tested under 
the same experiment setting and the same GPU to make comparisons 
between them fair. To do so, we first expand the dataset by a factor of 
five (from 8002 to 40,010 images). Then, we fed batches of 50 images 
into the model to warm up the hardware, before recording the inference- 
time of batches of 100 to quantify QPS. 

pi,j =

(cid:0)
exp

)

zi,j
(cid:0)

exp

zi,m

∑M

m=1

)

(1)  

3. Results

2.2.2. ResNet 

However,  with  the  network  depth  increasing,  the  degradation 
problem has been exposed. The degradation indicates that the gradient 
vanishing will limit the performance of the network. Inspired by VGG 
nets, ResNet (He et al., 2016) was proposed to address this problem by 
adding identity mapping (two-branch architecture). ResNets have lower 
complexity and higher performance. In this work, we used ResNet-18 
and ResNet-50 as backbone networks for our experiments. 

2.2.3. RepVGG 

Multi-branch architectures have better performance during training, 
but inference speed is limited. Thus, RepVGG was developed to use a re- 
parameterization technique to decouple the training-time multi-branch 
and inference-time plain architecture to increase inference speed while 
maintaining performance (Ding et al., 2021). RepVGG models are over 
80% faster than ResNets with better performance. And RepVGG-A0 and 
RepVGG-A1 were applied in our experiments. 

2.2.4. MobileNet-V3

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model was built using PyTorch.

Reference(s):
None required.