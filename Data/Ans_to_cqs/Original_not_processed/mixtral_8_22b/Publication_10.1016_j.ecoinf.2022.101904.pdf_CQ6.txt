Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

On the other hand, transformers are the most frequently deployed 
techniques in natural language processing (NLP) (Vaswani et al., 2017). 
Researchers  are now exploring the capability of transformers  in com-
puter  vision  and  remote  sensing,  given  their  huge  success  in  the  lan-
guage domain. They have recently proven to be practical in a variety of 
applications,  including  the  classification  of  remote  sensing  imagery 
(Bazi et al., 2021; D. Hong et al., 2021; J. He et al., 2020). Transformers 
utilize  an  attention-based  approach  rather  than  using  convolutional 
operations utilized by CNNs. As such, transformers, unlike CNNs, can 
acquire global contextual knowledge through self-attention. This means 
that transformers have a better generalization capability as compared to 
CNN algorithms. For example, the state-of-the-art vision transformer of 
Swin Transformer incorporates a hierarchical transformer with shifting

EcologicalInformatics72(2022)1019047A. Jamali et al.                                                                                                                                                                                                                                  

Table 5 
Results  of  the  proposed  deep  model  (ViT  = Vision  Transformer,  ST  = Swin 
Transformer, KI=Kappa index, AA = Average accuracy, OA = Overall accuracy).  

Class 

ViT 

ST 

CoAtNet 

CNN 
+ ST 
(ours) 

GAN 
+ ST 
(ours) 

3DUNetGSFormer 
(ours) 

Bog 
Fen 
Marsh 
Swamp 
Shallow 
water 

Urban 
Deep 

water 
Upland 
KI (%) 
OA (%) 
AA (%) 
Time (h) 

0.59 
0 
0.46 
0 
0.83 

0.97 
0.93 

0.86 
0.79 
0.88 
0.76 
0.92 

0.99 
0.97 

0.91 
0.86 
0.94 
0.82 
0.98 

0.99 
1 

0.87 
71.31 
75.62 
62.96 
2.2 

0.96 
90.66 
91.99 
88.67 
1.5 

0.97 
94.67 
95.43 
93.21 
5 

0.82 
0.76 
0.95 
0.89 
0.91 

0.98 
1 

0.98 
92.84 
93.87 
90.16 
1.5 

0.89 
0.83 
0.88 
0.9 
0.96 

0.99 
0.99

3.6. Cost of computation in terms of time 

The hardware configurations for the experiments in this study con-
sisted of Intel Core i7-10750H 2.60 GHz CPU, GeForce RTX 2070-MaxQ 
GPU, and 16GB RAM. As seen in Table 5, the Swin Transformer classifier 
had  the  least  cost  in  terms  of  time,  with  approximately  1.5  h  of  its 
required training time, while the CoAtNet algorithm required about 5 h 
for its training. The proposed 3DUNetGSFormer required around 3.5 h 
for its training time. 

4. Discussion 

Understanding  dynamic land  cover changes  in wetland-dominated 
regions such as Canada requires accurate mapping of diverse and com-
plex  wetland  ecosystems.  Up-to-date  maps  showing  wetlandsâ€™  extent 
and  spatial  pattern  are  critical  for  protecting  and  conserving  these 
important  ecosystems.  The  rapid  evolution  of  free  access  and  high

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

3DUNetGSFormer: A deep learning pipeline for complex wetland mapping 
using generative adversarial networks and Swin transformer

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, several preprocessing steps may be involved depending on the specific application and data type. These steps help prepare the input data so it is suitable for use in machine learning models. Some common preprocessing techniques include:

1. Data Cleaning: Removing or correcting erroneous, missing, or inconsistent data points from the dataset.

2. Normalization: Scaling numerical values to a standard range, typically between 0 and 1, or -1 and 1. This helps prevent any single feature from dominating the others due to differences in scales.

3. Standardization: Converting features into z-scores, which involves subtracting the mean value and dividing by the standard deviation. This technique ensures that each feature contributes equally to the final output.

4. Feature Engineering: Creating new features based on existing ones to improve the performance of the model. Examples include polynomial features, interaction terms, or binning continuous variables.

5. Dimensionality Reduction: Reducing the number of input features to simplify the model and avoid overfitting. Techniques like Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), or t-distributed Stochastic Neighbor Embedding (t-SNE) can be used for dimensionality reduction.

6. Encoding Categorical Variables: Converting categorical variables into numerical representations, such as one-hot encoding or label encoding.

These preprocessing steps ensure that the input data is well-suited for training a deep learning model, improving both its performance and efficiency. However, not all preprocessing techniques are necessary for every problem, and some might even introduce unnecessary complexity. Therefore, selecting appropriate preprocessing methods should depend on the specific requirements and characteristics of the task at hand.