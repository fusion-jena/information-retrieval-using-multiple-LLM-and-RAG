Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

◦
vertical rotation to strength and add 
horizontal and a plus-or-minus 15
variability to the trained models to changes of camera positions (Dwyer 
and Nelson, 2022).

2.5. Description of hyperparameters and training aspects 

The  five  detection  models  were  trained  using  a  manually  labeled 
image dataset for alate detection. After conducted initial computational 
experiments with different combinations of epochs of 300, 400 and 500 
with batch sizes of 8, 16, and 32, it was determined that the optimal 
hyperparameters for our training were 400 epochs with a batch size of 8 
and were constant when comparing the five detection models using 640 
× 640, and 1280 × 1280 pixels input resolutions on each model type. 
The batch defines the number of samples to be worked through before 
moving on to update the internal model parameters (Radiuk, 2017). The 
epoch  number  used  in  training  determines  the  number  of  times  the 
detection model processes the dataset dedicated to training the model 
(Brownlee,  2018).  The  computer  infrastructure  used  for  training 

2.6. Evaluation metrics of the trained models

2.7. Web application development 

In order to allow researchers and stakeholder users to interact and 
use  our  best  trained  model  to  detect  alates  on  sorghum  leaves,  we 
created and deployed a web application (Fig. 3). This application allows 
a user to upload images of sorghum leaves, then the model will process 
the  images  within  the  backend  of  the  application.  Once  images  are 

EcologicalInformatics80(2024)1025403I. Grijalva et al.                                                                                                                                                                                                                                 

Fig. 2. Examples of training images at 1280 × 1280 pixels input resolution (A, B, C, D) with annotations of alates and augmentation techniques using the cloud-based 
Roboflow environment (Dwyer and Nelson, 2022).

To  improve  the  overall  performance  of  the  developed  models,  we 
suggest  incorporating  more  training  images  with  different  alate  den-
sities collected using different devices (e.g., smartphones, drones, etc.), 
that could potentially improve the validation of these models (Grijalva 
et  al.,  2023b).  In  addition,  applying  different  preprocessing  and 
augmentation  techniques  can  diversify  the  training  data  and  increase 
overall  performance.  Our  web  application  comes  with  certain  limita-
tions, including the need for the user to follow the recommended image- 
capturing instructions and a good internet connection for proper oper-
ation. This could restrict its utility in areas where internet is not acces-
sible.  However,  the  framework  of  this  study  and  the  models  tested 
provided a better understanding of the capabilities of computer vision 
models, based on deep learning, to pest detection for pest monitoring in 
sorghum.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the specific requirements of the project. Some common postprocessing steps include calculating evaluation metrics such as accuracy, precision, recall, F1 score, and area under the curve (AUC), which help assess the performance of the trained models. Another important step is creating confusion matrices, which provide a visual representation of the classification results by displaying true positives, false positives, true negatives, and false negatives. Additionally, saliency maps or heatmaps can also be generated to highlight the regions of interest in the input images that contributed most significantly to the final prediction made by the model. These postprocessing steps aid in interpreting the model's predictions and identifying any potential biases or weaknesses in the model.