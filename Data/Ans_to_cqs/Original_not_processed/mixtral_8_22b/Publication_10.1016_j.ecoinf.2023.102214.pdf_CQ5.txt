Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

cation  studies,  a  lack  of  data  is  the  greatest  challenge  and  limitation 
researchers encounter (Schneider et al., 2019). With the data collection 
compiled  in  this  work,  we  contribute  the  largest  fully  labeled  snow 
leopard dataset for deep learning research. In addition, we anticipate 
that our novel deep learning methods will encourage other academics to 
contribute  more  datasets  to  Whiskerbook.org  for  the  purpose  of 
continuously curating and enhancing the data used to improve the deep 
learning pipeline. Comparing these results to those of an earlier study by 
Johansson et al. (2020) that depended on human manual classification, 
without  AI  or  software,  determined  that  observers  significantly  over-
estimate  the  true  abundance.  AI-based  individual  ID  within  Whiske 
rbook.org  has  demonstrated  the  potential  to  enhance  the  precision 
and  efficiency  of  manual  observers,  approaching  more  accurate  esti-

comprehensive graph matching software within the Wild Me software 
suite for cleaning data at the standard suitable for deep learning algo-
rithms. Two manual observers participated in exhaustive rounds of ID 
decisions in a process called graph matching of the 12,311 annotations, 
whereby  two  images  are  placed  side  by  side,  and  the  observer  de-
termines  whether  the  images  are  the  same  individual  or  different  in-
dividuals (same animal, different animal, cannot tell), and ranks their 
level  of  certainty  (undeniable,  certain,  somewhat  certain,  mostly  un-
certain, completely uncertain). This level of comprehensive individual 
ID enabled the subsets of our dataset to have the highest certainty for 
imagery from a field-based dataset. 

2.4. Min-3/Max-10 

A Min-3/Max-10 data subset is frequently used for training machine 
learning algorithms such as PIE. This data subset comprises individuals

and left-right mirroring data augmentation techniques, which reduced 
the  issue  of  overfitting,  and  strengthened  the  algorithms  capacity  to 
match individuals based on pelt patterns rather than the background. 
The  snow  leopard  training  pipeline  described  here  may  be  repur-
posed rather quickly to train new models if more users utilize the system 
and  additional  data  is  submitted.  The  existing  model  may  also  help 
bootstrap that data-curation process. There is a considerable possibility 
for  regional  and  global  research  collaborations  with  snow  leopard 
research  institutions  to  curate  and  independently  identify  data  that 
would advance these existing models toward greater sophistication and 
improved performance. Deep learning systems have the ability to sur-
pass humans in the re-identification of animals, even in the absence of 
obvious patterns and markings, if sufficient datasets and collaboration

image classification for individual ID for various species and has been 
incorporated into software (Burgstaller et al., 2020; Crall et al., 2013; de 
Lorm et al., 2023; Khan et al., 2022; Miguel et al., 2019; Nipko et al., 
2020; Park et al., 2019; Verschueren et al., 2023). Recent advances in 
deep  learning  have  facilitated  the  growth  of  convolutional  neural 
network  (CNN)-based  systems  that  can  now  extract  layers  of  image 
characteristics for a wide variety of ecological and environmental image 
processing  concerns,  especially  for  camera  trapping  image  analysis 
(Bogucki et al., 2019; El Abbadi and Alsaadi, 2020; Nguyen et al., 2017b; 
Norouzzadeh  et  al.,  2018a;  Shi  et  al.,  2020).  Due  to  the  capacity  to 
reduce images to numerous layers of distinct patterns, these advanced 
feature  extraction  and  CNN-based  deep  learning  approaches  have 
demonstrated  promising  results  for  identifying  individuals  (Bhatta-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this work, the researchers contributed the largest fully labeled snow leopard dataset for deep learning research. They utilized a Min-3/Max-10 data subset, which consists of individuals with three to ten instances each, along with left-right mirroring data augmentation techniques. These methods helped reduce overfitting and improved the algorithm's ability to match individuals based on pelt patterns rather than the background. Although specific dataset names like MNIST, CIFAR, or ImageNet were not mentioned, it is clear that the researchers focused on creating a custom snow leopard dataset tailored specifically for deep learning applications.