Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

include  flip, rotations  and  affine  transformation. We  then  trained the 
same dataset with ResNet-101 network with heavier augmentation for 
500 epochs. It is worth noting that the selection of image augmentations 
is  of  crucial  importance  to  improve  training  performance.  Multiply, 
linear  contrast,  sharpen,  emboss,  flip  in  horizontal  and  vertical  di-
rections,  rotations  and  affine  transformation  were  used  for  heavy 
augmentation.

models,  the  strongest  limitation  of  Mask  R-CNN  is  the  need  for  sub-
stantial  computational  resources.  Therefore,  the  training  of  the  algo-
rithm  was  carried  out  through  the  Alvis  cluster  which  is  a  national 
NAISS  resource  dedicated  for  Artificial  Intelligence  and  Machine 
Learning research. Following the methodology suggested in (Naets et al., 
2021), we split the data acquired from the experiment using Swedish soil 
into 65 images for training and 16 images for validation. We started with 
transfer learning from already annotated daily common objects dataset 
(COCO) on only head layers with RestNet 50 as backbone model (Lin 
et  al.,  2014).  Here,  transfer  learning  refers  to  fine-tuning  of  models 
already trained on different tasks and datasets that have plenty of an-
notations. Subsequently, all the layers were trained for 500 epochs fol-
lowed by another 500 epochs training with image augmentations which

Acknowledgments 

The training and data handling were enabled by resources provided 
by the National Academic Infrastructure for Supercomputing in Sweden 
(NAISS) at Chalmers Centre for Computational Science and Engineering 
(C3SE),  High  Performance  Computing  Center  North  (HPC2N)  and 
Uppsala Multidisciplinary Center for Advanced Computational Science 
(UPPMAX) partially funded by the Swedish Research Council through 
grant  agreement  no.  2022-06725.  The  authors  wish  to  thank  Lund 
University  research  infrastructure  Correlative  Image  Processing  and 
Analysis for machine learning-related consultations. The work for A.S. is

were  proven  to  succumb  to  complexity,  low  precision  and  reliability, 
whereas image analysis-based methods have now been widely adopted 
due to their efficiency and accuracy (Gupta et al., 2019; Zhang et al., 
2021).  The  deep  learning  model  successfully  segments  and  classifies 
various objects at satisfying accuracy. AI-aided soil chip analysis does 
not only allow to study abundance and biodiversity measures following 
local treatments or large biogeographic variations, but even to investi-
gate direct interactions of microbes with each other, or with additives to 
the ecosystem, such as biochar or toxins that can be added into the chips. 
The  approach  can  be  extended  to  other  microbial  groups  including

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no explicit mention of specific optimization techniques like Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) being used in the deep learning pipeline. However, it is mentioned that the models were trained for several epochs, which suggests some form of gradient descent optimization technique was likely employed. Additionally, the use of transfer learning indicates that pre-trained weights might have been utilized, possibly optimized using these techniques beforehand. But without further information, I cannot provide a definitive answer regarding the exact optimization techniques used in this case.