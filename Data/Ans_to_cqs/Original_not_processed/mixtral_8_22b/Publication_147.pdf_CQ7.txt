Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 2. Full comparison of training time, prediction time, optimization time (i.e., time to properly
tune the model), and hardware for each model.

Model

Training Time
(Hours)

Prediction Time (Hours)

Optimization
Time (Hours)

Hardware

CNN

XGB

4

4

2.4. Validation

4

Unknown

Desktop with 64 Gb of
RAM and one Titan X
(Maxwell) GPU.

72—can be reduced by
distributing prediction to more
cores or more machines.

2

Desktop with 64 GB of
ram and 64 logical cores.

Keywords: wetlands; Sentinel-1; Sentinel-2; Google Earth Engine; remote sensing; Alberta;
segmentation convolutional neural nets; XGBoost; land cover; SAR; machine learning

1. Introduction

Machine learning—a method where a computer discovers rules to execute a data processing
task, given training examples—can generally be divided into two categories: Shallow learning and
deep learning methods [1]. Deep learning uses many successive layered representations of data
(i.e., hundreds of convolutions/ﬁlters), while shallow learning typically uses one or two layered
representations of the data [1]. Deep learning has shown great promise for tackling many tasks such as
image recognition, natural language processing, speech recognition, superhuman Go playing, and
autonomous driving [1–3].

Remote Sens. 2020, 12, 2; doi:10.3390/rs12010002

www.mdpi.com/journal/remotesensing

Table 1. List of input variables in the XGBoost model (XGB) and convolutional neural network
(CNN) models. Each variable lists its respective data source, equation, description, and, if needed,
citation. For information on Sentinel-2 band information not listed in the table, see:
[66] and
https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial.

Variable

Data Source

Model

ARI

Sentinel-2

XGB/CNN

Band 2
Band 3
Band 4
DEM

NDVI

dNDVI

NDWI

POLr

PSRI

Sentinel-2
Sentinel-2
Sentinel-2
ALOS

Sentinel-2

Sentinel-2

Sentinel-2

Sentinel-1

Sentinel-2

CNN
CNN
CNN
CNN

CNN

XGB

CNN

XGB

CNN

REIP

Sentinel-2

XGB/CNN

Equation
(cid:17)
(cid:16) B8
(cid:16) B8
B3
B2

–

(cid:17)

-
-
-
-
(B8− B4)
(B8 + B4)

Description

The shallow learning classiﬁcation model was done with the XGBoost algorithm [75]. XGBoost
was used since it has been shown to be one of the better performing shallow learning models in
machine learning competitions [1], although it has limited use in remote sensing literature. It has been
the most popular shallow learning algorithm in Kaggle competitions since 2014 [1]. Early work on this
project showed XGB models slightly out performing random forest and boosted regression tree models.
We used the xgboost package [75] in R Statistical software [76]. The inputs into the XGBoost model
were: Anthocyanin Reﬂectance Index (ARI), delta Normalized Diﬀerence Vegetation Index fall–spring
(dNDVI), POLr, Red Edge Inﬂection Point (REIP), Topographic Position Index (TPI), Topographic
Wetness Index (TWI), Multi Resolution Index of Valley Bottom Flatness (VBF), VH, dVH (Table 1).
These inputs were the indices shown to be important for wetland class mapping, while also having low

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: The context does not provide explicit details about how the data was split for deep learning model training. However, it is common practice in machine learning to divide the dataset into three subsets: training set, validation set, and testing set. Typically, the training set is used to fit the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to evaluate the final performance of the model. The exact proportions can vary depending on the specific application and available resources, but a common approach is to allocate around 60-80% of the data for training, 10-20% for validation, and 10-20% for testing.