Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Finally, FRAMES was designed to facilitate submission to data re-
positories, including the NGEE Tropics Archive, the project's data re-
pository. The NGEE Tropics Archive has a web portal that allows data
originators to upload and download data packages. The Archive is
supported by a programmatic REST API built on top of Django Python
web framework with an easy-to-use web user interface built with
Foundation (Zurb, 2016) front-end framework. The Foundation front-
end framework is ﬂexible, highly customizable and provides support for
responsive, light-weight HTML for mobile application support. Django
is a fully featured open-source Python web application framework that
supports rapid development. Django makes the low-level framework
decisions so that the development is primarily focused on the applica-
tion domain rather than composing the framework features. NGEE
Tropics Archive manages the data package by storing the data package

Unidata, 2016. https://www.unidata.ucar.edu/software/netcdf/ (accessed Mar 2016).
USGS Science data catalog. http://data.usgs.gov/ (accessed November 2016).
Walker, A.P., Hanson, P.J., De Kauwe, M.G., Medlyn, B.E., Zaehle, S., Asao, S., Dietze,
M.C., Hickler, T., Huntingford, C., Iversen, C.M., Jain, A.K., Lomas, M., Luo, Y.,
McCarthy, H.R., Parton, W.J., Prentice, I.C., Thornton, P.E., Wang, S., Wårlind, D.,
Weng, E., Warren, J.M., Woodward, F.I., Oren, R., Norby, R.J., 2014. Comprehensive
ecosystem model-data synthesis using multiple data sets at two temperate forest free-
air CO2 enrichment experiments: model performance at ambient CO2 concentration.
J. Geophys. Res. Biogeosci. 119, 937–964. http://dx.doi.org/10.1002/(ISSN)2169-
8961.

Zurb, 2016. http://foundation.zurb.com/ (accessed October 2016).

158

Once submitted, data package descriptions and data ﬁles are
manually reviewed for completeness and accuracy as part of the pro-
ject's archival approval processes. After approval, data packages with
appropriate citation information are made available via the web portal
to data consumers who are assigned access privileges.

3.3.2. Data ﬁle descriptions (ﬁle submission metadata and data column
description)

For each data ﬁle submitted, data originators report the following
metadata in the MS Excel template “File Submission Metadata:” 1) Tree
ID or other Location ID if applicable, 2) time period of the data and
timestamp details (e.g., time zone and whether the timestamp is at the

To date, FRAMES templates have been used, in whole or in part, for
several submissions to the NGEE Tropics Data repository. An iterative
scientist-centered design was central to the successful use of FRAMES
within our project, where the goal is to improve a predictive under-
standing of carbon cycling in tropical forests under climate change. As
an interdisciplinary data team of ecologist, hydrologists, and data sci-
entists working closely with data originators and consumers throughout
the development process, we were able to identify features critical to
the project's science needs and develop pragmatic solutions. This

integrated data science approach will underpin further improvement to
FRAMES, and we recommend it as a model for harnessing complex and
diverse data inherent in team-science and observational networks.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide any information about the existence of a deep learning pipeline or its corresponding code repository link. Therefore, based on this context alone, it cannot be determined what the code repository link of the deep learning pipeline is.