Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

be  established  (Xie  et  al.,  2021).  Deep  noise  reduction  methods 
(Defossez et al., 2020) often use a U-net architecture which consists of an 
encoder and decoder section. The encoder produces a compressed latent 
space representation. The decoder then uses this latent space to recon-
struct the denoised waveform. Recently, transformer attention mecha-
nisms have also been applied with great success (Cao et al., 2022; Luo 
and  Mesgarani,  2019;  Luo  and  Mesgarani,  2023;  Zhang  et  al.,  2022; 
Zhao et al., 2022). As most deep-noise reduction methods focus on NLP 
applications, models are optimized for bandwidths ranging from 16 to 
22  kHz.  Bioacoustics  applications  commonly  exceed  this  bandwidth. 
Additionally, the sparsity of vocalisations in this application and many 
other  bioacoustics  applications  makes  the  development  of  large-scale 
datasets  infeasible  (Stowell,  2021).  These  factors  limit  the  success  of

Deep learning-based denoising methods are most commonly applied 
to  natural  language  processing  (NLP)  such  as  a  human  speech 
enhancement. D´efossez et al. (Defossez et al., 2020) demonstrated the 
potential for deep noise reduction techniques to achieve state-of-the-art 
(SOTA) performance and be applied in sub-real time on limited hard-
ware. These methods commonly operate on audio spectrograms but in 
recent  years  SOTA  deep  learning  methods  (Wang  et  al.,  2021)  have 
successfully  used  raw  waveform  data  (Luo and  Mesgarani,  2019; Luo 
and Mesgarani, 2023) for wider applications such as source separation 
and classification. This removes errors introduced when applying a Fast 
Fourier  Transform  (FFT)  to  generate  a  time-frequency  representation 
and reconstruction errors due to the loss of phase information. These 
networks tend to require more data for training as the latent space must

outlined in Section 3.1. 

We compare the audio enhancement model Conformer-Based Metric 
Generative Adversarial Network (CMGAN) developed by Abdulatif et al. 
(Cao et al., 2022) to traditional methods. CMGAN is a Conformer-based 
audio enhancement model that has achieved SOTA performance. This 
model  operates  in  the  time-frequency  domain.  A  pre-trained  CMGAN 
model  is  fine-tuned  using  a  maximum  of  1000  five-second  noisy  and 
clean samples. We use the default training parameters of 120 epochs, 
learning rate of 5e-4 and learning rate decay after the first 30 epochs. We 
test the data requirements of this model in the Section 4.1.1 ablation 
study. All data is down sampled to 16 kHz in alignment with the model’s 
input  requirements.  Default  values  were  used  for  all  training 
parameters.

For many bioacoustic monitoring applications, noise reduction and 
data  sparsity  are  key  considerations.  This  work  evaluates  various 
traditional and deep learning-based audio enhancement methods with 
sparse data to determine the applicability of common approaches. We 
conclude that traditional methods remain a relevant approach for many 
bioacoustics  applications.  Spectral  subtraction  performs  well  for 
sparsely  spaced  features  and  outperforms  alternative  approaches  in 
terms  of  efficiency  and  data  requirements.  Deep  learning-based  ap-
proaches have seen significant development in recent years. Our results 
demonstrate  that  fine-tuned  audio  enhancement  models  can  achieve 
comparable or better performance compared to traditional approaches 
in  terms  of  noise  reduction.  Audio  enhancement  models  can  also  be 
trained  to  remove  transient  features,  a  key  advantage  compared  to

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide specific details about the optimization techniques applied in the deep learning pipeline. However, it mentions that a pre-trained CMGAN model was fine-tuned using a maximum of 1000 five-second noisy and clean samples. The default training parameters mentioned include a learning rate of 5e-4 and learning rate decay after the first 30 epochs. While these are hyperparameters related to the optimization process, they do not explicitly mention the use of any particular optimization technique like Stochastic Gradient Descent (SGD), Adam, RMSprop, etc. Therefore, based on the provided context, I cannot definitively identify the optimization techniques applied in the deep learning pipeline.