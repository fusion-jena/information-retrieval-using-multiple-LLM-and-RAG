Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

TABLE 3. Classification performance of different methods using single
CNN-based model. Here, Mel-CNN, Harm-CNN, and Perc-CNN denote that
the input to those CNNs are Mel-spectrogram, harmonic-component
based spectrogram, and percussive-component based spectrogram.
Subnet-CNN denotes that a SubSpectralNet architecture is used with the
Mel-spectrogram as the input.

FIGURE 6. Confusion matrix (%) of the best result using the fusion of selected CNN-based models. Here, the x and y axes denote the code of each bird
species to be classified.

(95.5%) can achieve a signiﬁcantly higher classiﬁcation
accuracy than 40 mel-bin(91.2%), but with more computa-
tional load. In addition, since multiple CNN-based models
need to be trained in this study, such a high computational
load will signiﬁcantly increase the training time. Further-
more, this study aims to investigate the effectiveness of fusion
of different CNN-based models rather than obtaining a single
CNN-based model with the best performance, Therefore,
we select 40 mel-bin for the subsequent analysis.

[21] Y.
by
divisions,’’
Available:
classiﬁcation-results-a

‘‘Acoustic
based

Sakashita
ensemble

adaptive
2018.

scene

on

[22] J. Salamon, J. P. Bello, A. Farnsworth, and S. Kelling, ‘‘Fusing shallow
and deep learning for bioacoustic bird species classiﬁcation,’’ in Proc.
IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), Mar. 2017,
pp. 141–145.

[23] J. Salamon, J. P. Bello, A. Farnsworth, M. Robbins, S. Keen, H. Klinck,
and S. Kelling, ‘‘Towards the automatic classiﬁcation of avian ﬂight
calls for bioacoustic monitoring,’’ PLoS ONE, vol. 11, no. 11, pp. 1–26,
Nov. 2016.

[24] K. Simonyan and A. Zisserman, ‘‘Very deep convolutional networks for
large-scale image recognition,’’ in Proc. 3rd Int. Conf. Learn. Repre-
sentations, (ICLR), San Diego, CA, USA, 2015. [Online]. Available:
http://arxiv.org/abs/1409.1556

trogram. In addition to different TFRs, a different deep learning architecture, SubSpectralNet, is employed
to classify bird sounds. Experimental results on classifying 43 bird species show that fusing selected deep
learning models can effectively increase the classiﬁcation performance. Our best fused model can achieve a
balanced accuracy of 86.31% and a weighted F1-score of 93.31%.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The provided context does not explicitly mention any specific strategies implemented to monitor the model performance during training. However, it discusses various aspects related to the classification performance of different methods using single CNN-based models and the fusion of selected CNN-based models. It also mentions the use of different architectures like SubSpectralNet and the selection of 40 mel-bin for further analysis due to its balance between computational load and classification accuracy. Unfortunately, without additional information or context, I cannot provide a detailed response regarding the specific strategy implemented to monitor the model performance during training.