Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

overall process mostly followed current best practices in deep learning 
which are well summarized in (Chollet, 2017).

followed  the  original  Wide  ResNet  design.  Our  downsampling  blocks 
employed the changes suggested in (Xie et al., 2018). The third and final 
component, the classification block, was derived from (Schlüter, 2018) 
and resulted in probability predictions for all 987 classes per second (i. 
e., three predictions per 3-s input spectrogram) followed by global log- 
mean-exponential  pooling  and  sigmoid  activation.  Most  convolutions 
use 3 × 3 kernels with padding and are succeeded by batch normali-
zation  (Ioffe  and  Szegedy,  2015)  and  ReLU  activation  (if  not  noted 
differently).  Because  we  treated  spectrograms  as  monochrome  input 
images, the input was a single channel mel spectrogram of size 64 × 384, 
visualizing three seconds of audio at a sampling rate of 48 kHz. 

2.5. Training

Here  we  present  a  new  algorithm,  called  BirdNET,  that  builds  on 
these previous successes using CNNs and spectrogram data to classify 
984  bird  species.  We  discuss  the  necessary  steps  required  to  develop 
such a system and provide insights into our training and testing work-
flow of a deep artificial neural network. Finally, we give an outlook on 
how  this  technology  can  support  ornithologists  and  conservation  bi-
ologists in their work to identify and address the environmental chal-
lenges of our time. 

2. Methods

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

BirdNET: A deep learning solution for avian diversity monitoring 

Stefan Kahl a, *, Connor M. Wood a, Maximilian Eibl b, Holger Klinck a 
a Center for Conservation Bioacoustics, Cornell Lab of Ornithology, Cornell University, Ithaca, NY 14850, USA 
b Technische Universit¨at Chemnitz, D-09111 Chemnitz, Germany   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Bioacoustics 
Deep learning 
Convolutional neural networks 
Bird sound recognition 
Avian diversity 
Passive acoustic monitoring 
Conservation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention where the code repository of the deep learning pipeline is available. However, it is common practice for researchers to share their code repositories on platforms such as GitHub, GitLab, or BitBucket. Therefore, I would recommend checking these platforms for a repository named 'BirdNET', which corresponds to the name of the deep learning solution presented in the paper. Alternatively, one could contact the authors directly to request access to the code repository.