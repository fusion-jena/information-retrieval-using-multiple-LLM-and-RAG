Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Training a neural network requires to set several hyper-parameters
such as the learning rate, number of epochs and batch size. The learning
rate is a special one since it deﬁnes how much the weights are ‘moved’
to decrease the loss. A bigger one could cause the network not to learn,
on the other hand, a smaller one could require much more steps for
learning. To decrease this issue, we train the network with Adam op-
timizer (Kingma and Ba, 2015), a variant of the stochastic gradient
optimization where the learning rate is adjusted automatically. The rest
of the parameters are set empirically, more details are presented in the
experiments section.

5. Experiments

In this section, we present the experimental characterization of the
proposed approach. The implemented network was trained with Adam
optimizer (Kingma and Ba, 2015) on a Inter Core i7 machine with
NVIDIA GeForce 1080 GPU. The hyperparameters were set as follows:
learning rate 0.01, number of epochs 150, batch size 2500.

5.1. Data augmentation accuracy

A common practice to improve the accuracy of a deep learning
model is to do data augmentation. In this section, we compare the ac-
curacy of the network when data augmentation is included during
training. The compared training variations are the following:

(cid:129) No augmentation. The patches only are resized to 32 × 32 and

normalized.

Fig. 8. Training loss.

Fig. 9. Training accuracy.

Fig. 7. Custom LeNet-5 network for cactus recognition.

135

E. López-Jiménez, et al.

Ecological Informatics 52 (2019) 131–138

Fig. 10. Validation accuracy.

Fig. 12. Normalized confusion matrix.

(cid:129) Vertical and horizontal ﬂip. In addition to the resize and nor-
malization, the patches are ﬂip vertically or horizontally with prob-
ability 0.5. Both ﬂips are independent events.

tion. With the modiﬁed images a CNN was trained to classify three
diﬀerent legume species: white bean, red bean and soybean. A relevant
approach for deep learning is a form of transfer learning. It is well
known that deep learning networks need large amounts of data to be
trained, this has led to the use of pre-trained networks that are latter
ﬁne-tuned with speciﬁc data of the addressed problem. The aim is to
take advantage of the knowledge learned from one problem to apply it
to another closely related problem. In (Ghazi et al., 2017), three re-
cognized deep learning architectures, namely GoogLeNet, AlexNet, and
VGGNet, were used to identify the plant species captured in a photo-
graph. The authors studied the impact of critical factors (iteration size,

E. López-Jiménez, et al.

Ecological Informatics 52 (2019) 131–138

batch size, and data augmentation) aﬀect the ﬁne-tuning of pre-trained
models. DeepPlant is another example of a system for plant identiﬁ-
cation based on a CNN that uses a pre-training approach (Lee et al.,
2015). Background textures it is always an element that complicates the
classiﬁcation task. Xiao et al. proposed a segmentation and crop
method, based on Fourier transformations and a K-means algorithm, to
generate a region of interest in the images; the cropped images are then
used to train a CNN for diﬀerent plant species classiﬁcation (Xiao et al.,
2018). CNN have not been used only for taxonomic classiﬁcation of
plants, but also for the detection of diseases that can aﬀect them
(Sladojevic et al., 2016).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide information about the deployment process of the trained deep learning model. Details regarding model serialization, platform selection, or any other specific methodology for deploying the model are not mentioned. Therefore, I cannot provide a helpful answer to this query based on the given context.