Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Convolutional neural networks 
CNN 
Ecoacoustics 
Avian diversity 
Bird species classification 
Mixture of experts (MoE) 
Citizen science 
Automated recording units 
ARU 
Soundscapes to landscapes 
BirdNET 
Soundscape components

LeBien et al., 2020; Ruff et al., 2021; Stowell et al., 2019; Zhong et al., 
2020). Tuning of the network hyperparameters and convolutional filters 
provides automated feature learning, thereby removing an obstacle of 
earlier  machine  learning  methods  (Gupta  et  al.,  2021).  Sound  data 
include frequency, amplitude and temporal information, and there are 
different  approaches  to  express  these  data  in  CNN  architectures.  One 
approach is to represent sound data as amplitude-time waveforms, then 
train  1-dimensional  neural  network  architectures,  such  as  Recurrent 
Neural Networks (RNNs) to identify distinct patterns (Sang et al., 2018; 
Weninger and Schuller, 2011; Zhang et al., 2021). Another approach is 
to  train  CNNs  to  classify  2D  image  spectrograms  (Kahl  et  al.,  2021; 
LeBien et al., 2020; Ruff et al., 2021; Stowell et al., 2019; Zhong et al., 
2020).  A  popular  extension  is  to  use  mel-spectrograms  from  human

Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M.P., Shyu, M.L., Chen, S.C., 
Iyengar, S.S., 2018 Sep 18. A survey on deep learning: algorithms, techniques, and 
applications. ACM Comput. Surv. (CSUR). 51 (5), 1–36. https://doi.org/10.1145/ 
3234150. 

Priyadarshani, N., Marsland, S., Castro, I., 2018 May. Automated birdsong recognition in 

complex acoustic environments: a review. J. Avian Biol. 49 (5), jav–01447. 
Pyle, P., DeSante, D.F., 2003. Four-letter and six-letter alpha codes for birds recorded 
from the American Ornithologist’s union check-list area. North American Bird 
Bander. 28 (2), 64–79. 

Quinn, C.A., Burns, P., Gill, G., Baligar, S., Snyder, R.L., Salas, L., Goetz, S.J., Clark, M.L., 
2022 May 1. Soundscape classification with convolutional neural networks reveals 
temporal and geographic patterns in ecoacoustic data. Ecol. Indic. 138, 108831. 

Roca, I.T., Desrochers, L., Giacomazzo, M., Bertolo, A., Bolduc, P., Deschesnes, R.,

ence data available for training were limited, so we sought to explore 
different network sizes in conjunction with pre-training with additional 
acoustic reference data from outside of our audio domain, followed by 
fine-tuning with ROI data from our study site.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The article does not provide explicit information about which specific framework was used to build the deep learning models mentioned. However, it can be inferred that common deep learning frameworks like TensorFlow or PyTorch could have been utilized due to their popularity and wide usage in building Convolutional Neural Networks (CNNs) and other types of deep learning models.