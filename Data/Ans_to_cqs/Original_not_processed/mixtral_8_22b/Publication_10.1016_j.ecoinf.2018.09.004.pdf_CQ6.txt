Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The ﬁnal step is to train and test the machine learning algorithms in
this dataset for 5-class classiﬁcation. Stratiﬁed cross-validation was
used, and evaluated with Precision, Recall and F-measure. This dataset
is not balanced as can be seen in Table 1. Cymodocea is the dominant
class that constitutes the 75% of the dataset. Thus, Accuracy may not be
a suitable measure, because it measures how many correct predictions
were made overall, and if we predict all the test examples as cymo-
docea, then Accuracy would be close to 75% without even predicting
another class. This is clearly a problem because many machine learning
algorithms are designed to maximize overall Accuracy, with the ex-
ception of the tree-based algorithms. So, we resort to the F-measure; the
algorithms are ranked based on it.

3.2.5. K-nearest neighbors

It is an non-parametric ‘lazy’ learning algorithm. This means that it
does not make any assumptions on the underlying data distribution and
that it does not use the training data points to do any generalization. It
does not attempt to construct a general internal model, but simply
stores instances of the training data. Classiﬁcation is computed from a
simple majority vote of the nearest neighbors of each point: a query
point is assigned the data class which has the most representatives
within the nearest neighbors of the point.

3.2.6. Decision tree

The Decision Tree Classiﬁer is a simple and widely used classiﬁca-
tion technique. It applies a straightforward idea to solve the classiﬁ-
cation problem by posing a series of carefully crafted questions about
the attributes of the test record. Each time it receives an answer, a
follow-up question is asked until a conclusion about the class label of
the record is reached.

1116
598
598
582
597
597
1357
825

By determining which variables are most important we can simplify
the analysis of a dataset, better understand the physical concepts of it,
and exclude the ones that confuse the model achieving better accuracy
and learning/testing speed.

There exist several ways to determine variable importance, e.g.
Decision Trees, Random Forests, Chi-square, and Regression. We deal
with tree-based variable importance, like (Arthur et al., 2010) did. It

63.01%
33.76%
33.76%
32.86%
33.71%
33.71%
76.62%
46.58%

162

D. Eﬀrosynidis et al.

Ecological Informatics 48 (2018) 158–170

Fig. 4. Presence (green) and absence (red) points of seagrass in Mediterranean (above) and Sicily (below).

Cross-validation is an iterative method for calculating the expected
value of a particular measure. It splits the dataset into K equally-sized
parts that are called folds. In each iteration, diﬀerent (K − 1)-folds are
used for training and the remaining fold for testing. The overall mea-
sure of its performance is the average of the measures of the individual
iterations. The above method guarantees that every instance will be
used both for training and testing. There is an alternative of cross-va-
lidation method called stratiﬁed cross-validation, where in each fold a
balanced number of instances for each class is selected. For our ex-
perimentation, we used stratiﬁed cross-validation with K = 10 folds.

4. Experiments

In this section, we perform two experiments. First, we are trying to
predict the existence of seagrass, and then its family. We are also in-
terested on which variables aﬀecting those predictions most.

4.1. Detecting seagrass

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, various preprocessing steps are often applied to the input data. These steps aim to improve the quality and consistency of the data, making it easier for the model to learn meaningful patterns. Some common preprocessing techniques include:

1. Normalization or standardization: This involves rescaling the features so they have zero mean and unit variance, or transforming them to lie within a specific range (e.g., between 0 and 1). This helps ensure that no single feature dominates the others during training due to differences in scale.

2. Cleaning and handling missing values: Removing noise, outliers, or irrelevant information from the dataset can help prevent overfitting and improve model performance. Missing values can be handled using methods such as imputation (filling in missing values with estimates), deletion (removing rows or columns containing missing values), or encoding (representing missingness explicitly in the data).

3. Feature engineering: Creating new features or modifying existing ones can sometimes lead to improved model performance. Examples include polynomial expansion, binning, or extracting features from raw data (e.g., image pixels or text tokens).

4. Data augmentation: Generating additional synthetic samples through transformations (e.g., rotations, translations, or flips) can increase the size of the dataset and help reduce overfitting.

5. Encoding categorical variables: Converting categorical variables into numerical representations (e.g., one-hot encoding or ordinal encoding) allows them to be processed by neural networks.