Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

4 https://github.com/HKathman/pam_annotation_experiments
5 https://github.com/kahst/BirdNET-Analyzer/tree/main/checkpoints/V2.4
6 https://tfhub.dev/google/vggish/1
7 https://tfhub.dev/google/yamnet/1
8 tensorflow.keras.applications.vgg16.VGG16(weights=’imagenet’).
9 tensorflow.keras.applications.resnet_v2.ResNet152V2

(weights=’imagenet’).

Fig. 4. UMAP plots for different embedding layers of different embedding
models for AnuraSet. For UMAP generation, we randomly select 5000 samples
and discard all samples that are aligned to more than one class. Colors and
shapes indicate the 10 classes with the highest occurrence frequency. Layers are
numbered according to their distance from the classification layer, e.g. ‘Bird-
Net-1’ is the last layer before the classification layer of the BirdNet model.

EcologicalInformatics82(2024)1027105H. Kath et al.

both the target modality and the domain, yields the best performance as
a feature embedding model. Using BirdNet-1 as the embedding model,
active learning sample selection strategies significantly reduce the
required for annotation to achieve model
number of
convergence.

evaluation was done on focal and citizen-science datasets. Swaminathan
et al. (2024) extend the observation to attention-based architectures pre-
trained on human speech. Lauha et al. (2022) show that transfer
learning can be helpful also for small networks trained from scratch on
small, targeted datasets gathered from online resources such as Mac-
aulay Library2 (as opposed to foundation models trained on large
datasets). While the works cited above evaluate transfer learning models
based on classification performance, McGinn et al. (2023) take a
different approach and investigate the topology of fine grained, sub-
species sound events in the embedding space afforded by BirdNet;
they find that different call types of a same species (e.g., drumming
versus vocalization) form distinct clusters, and that the vicinity of each

We used an Intel® Core™ i7-1165G7 CPU, and 32 GB of RAM for all
computations. The pre-processing, especially the computation of the
embeddings, requires approximately 100 h of CPU time for all three
datasets for all embedding models and layers. The active learning ex-
periments require approximately 6 h of CPU time per random seed for all
three datasets. Table 1 shows the CPU time required for all sampling
strategies, normalized to random sampling.

3. Results

An annotated PAM dataset typically serves one of two primary pur-
poses: as a resource for training new machine learning models for later
deployment for inference in a related domain (e.g., geographical region,
taxa), or as an end product in itself for subsequent analysis of ecological
phenomena within the same domain. In this study, we explore the po-
tential of combining transfer learning and active learning to accelerate
the annotation of species-level sound events in PAM datasets for both
purposes.

3.1. Transfer learning

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning models mentioned in the given context use TensorFlow as the underlying framework. This is evident from the usage of 'tensorflow.keras.applications.vgg16.VGG16' and 'tensorflow.keras.applications.resnet\_v2.ResNet152V2', which are part of the TensorFlow library. Additionally, the TFHub links provided ('https://tfhub.dev/google/vggish/1' and 'https://tfhub.dev/google/yamnet/1') further confirm the use of TensorFlow. However, it should be noted that while these models use TensorFlow, other parts of the project might utilize different libraries or frameworks.