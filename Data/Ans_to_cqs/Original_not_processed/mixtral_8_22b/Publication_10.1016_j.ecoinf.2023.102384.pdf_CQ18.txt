Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

data collection and curation phases.

We  assess  our  methodology  against  the  PST  dataset  described  in 
Section 3. We utilize the training subset for the supervised learning step 
concerning PCθ, while the overall counting pipeline is evaluated on the 
test split. First, we investigate the counting ability of the proposed ap-
proaches using the counting golden standard evaluators: basically, we 
investigate the counting performance of our pipeline considering only 
the pest counting module PCθ. Then, we perform further experiments 
taking into account some hybrid metrics that simultaneously consider 
the count error and the estimated raw locations of the insects: essen-
tially, in this case, we consider the entire pipeline, i.e., the PCθ, DG, and 
SG modules. It is worth noting that The PCθ  modules discussed in Section 
4  encompass  various  general  counting  strategies,  including  detection 
and regression. These strategies are drawn from state-of-the-art meth-

training step  and  a test  split  with the  remaining eight images  for the 
model evaluation phase. Finally, it is worth noting that, even if we an-
notated only the pests belonging to the class “whitefly”, other insects 
were accidentally stucked in the traps, which represents an additional 
challenge  -  deep  learning  models  should  not  count  the  latter  insect 
species. Specifically, we found insects belonging to different orders, such 
as  Lepidoptera,  Hymenoptera,  and  Diptera  (about  21,  7,  and  113, 
respectively);  furthermore,  among  hemipterans  we  also  found  insects 
belonging to families of Psyllidae, Aphidae, and Miridae (about 4, 14, 
and  22,  respectively).  Besides, about  80% of  the  images contain  con-
taminants,  such  as  dust,  fluff,  or  leaves,  accidentally  glued  over  the 
sticky traps. Some samples of bycatches insects and contaminants can be 
found in Fig. 1 and Fig. 4.

evaluation is performed using counting metrics, again, on a non-publicly 
available dataset.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information regarding the specific strategy used to monitor the model performance during training. However, it mentions that the training subset is utilized for the supervised learning step concerning PCθ, while the overall counting pipeline is evaluated on the test split. This suggests that the model's performance might be monitored through its accuracy on the training set during the training process. Additionally, the use of a separate test split implies that the final evaluation of the model's performance would occur after the completion of the training phase.