Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

edtoimproveresultsquickly.Afterbeingtestedwithmultipleconﬁgurations,dataaugmentationprovedtobeanefﬁcientwaytoincreasetheF1score.ForimagescollectedbyUAVﬂightsataconstantheightaboveground,smallchangesinbrightnessandzoomcanhelptoimprovesigniﬁcantly,butthechangingrangeinheightandwidthcanturnallvegetationtooclosevisuallyandcreateconfusionforCNN.Mediumorlargechangesinzoomrangealsocausedegradationofresults.Identifyingspeciﬁcvegetationmixedwithnativevegeta-tionfromUAVﬂightshassomechallengesandoneoftheAuthorized

meterimprovementsusingSE-ResNet-50.WhenusingRGBimagesasinputfortraining,theﬁnaltrainednetworkcanworkwithRGBimagescapturedbyaUAV.TheresultsachievedanF1scoreof0.9034andaJaccardindexof0.8287onthetestset.BasedonpositiveresultsbyU-nettoidentifyavarietyofobjectsandplantspecies.Inthiswork,weproposeusingtheU-nettoidentifyHeidychiumCoronarium,aninvasivevegetationspeciesfortheBraziliannaturalﬂora.Wedividedthearticleisasfollows.InsectionIIisex-plainedthedatagathering,pre-processing,andthetrainandtestdatasets.SectionIIIexplorestheresultsofdifferentwaysoftrainingtheU-net;Lastly,theconclusionispresentedinSectionIV.II.METHODOLOGYTheframeworkusedtodevelopthisworkcanbeseenintheFigure1.Therearethreestages,theﬁrststepistocollectimagedataoftheHedychiumCoronariumtoclassifyit.Thesecondstepispre-processthedataanddeveloptheclassiﬁcationmethodforthecollectedimagesand,ﬁnally,themeasurementoftheresultsobtainedbytheclassiﬁcation.A.DatagatheringTogatherimagestotraintheU-Net,weuseaDJIPhantom2dronewithaGlobalPositio

ti,“Learningimagefeatureswithfewerlabelsusingasemi-superviseddeepconvolutionalnetwork,”NeuralNetworks,vol.132,pp.131–143,2020.[29]I.Ragnemalm,“Theeuclideandistancetransforminarbitrarydimensions,”PatternRecognitionLetters,vol.14,no.11,pp.883–888,1993.

-net,Intheﬁgure6itispossibletoseeontheY-axishowtheAUCreaches89%,forthis,70shortepochswereneeded,whichcanalsobeobservedontheX-axis.Figure6.AUC-AreaundertheROCCurveWithstandardbinarycross-entropy,thelosshadreached25%asitsbestresult.Afterchangingtocustomloss,thelossdroppedto12%intrainingandvalidation,ascanbeseenintheY-axisofﬁgure7.OntheY-axisaretheepochs,asinthepreviousﬁgure.Figure7.EpochlossAcomparativebetweenthegroundtruthprovidedbyaspecialistandtheresultoftheU-Net.Figure8isaimagesampleofthetestdataset,Figures8(b.1)and8(b.2)arethegroundtruthandthemaskofthegroundtruthoverlayingthesamplerespectively.TheresultreturnedgivenbytheU-NetisshowninFigure8(c.1)andFigure8(c.2)showthemaskoftheU-Netresultoverlayingthesample.Figure8.ComparisonbetweenthegroundtruthusedfortrainingandtheU-NetresultIV.CONCLUSIONSInitially,theidentiﬁcationofHedychiumCoronariumgrowinginnativevegetationdidnotreachsuchexpressiveresults.WithanAUCcloseto60%,butsometechniqueshelpedtoimproveresultsquickly.Afterbeingtestedwithmult

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To collect raw data for training a U-Net model to identify Hedychium Coronarium, an invasive vegetation species in Brazilian natural flora, a DJI Phantom 2 drone with Global Positioning System (GPS) is used. The drone captures RGB images from different heights and angles during its flight. These images serve as input for training the network. This method allows for gathering large amounts of data quickly and efficiently compared to manual collection methods such as ground surveys or sensor networks. However, it should be noted that using publicly available datasets was not mentioned in this context.