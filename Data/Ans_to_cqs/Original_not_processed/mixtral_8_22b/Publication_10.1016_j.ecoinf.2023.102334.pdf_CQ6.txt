Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

6.1. Vision transformer 

Transformer (Vaswani et al., 2017), which is a deep neural network 
first created for natural language processing (NLP), was built on a self- 
attention mechanism that makes it possible for noticeably huge recep-
tive  fields.  The Transformer  has become  a  de facto industry  standard 
procedure in NLP because of its remarkable efficiency, and it has also 
motivated  researchers  in  the  field  of  computer  vision  to  investigate 
applications  by  utilizing  the  long-term  relationships  between  pixels 
(Khan et al., 2022).

ViT  is the  first significant effort to employ  a  pure Transformer on 
pictures directly, showing that it can totally replace the conventional 
convolution processes with SOTA performance. The training of the va-
nilla ViT model, however, necessitates high computing costs, according 
to  the  experimental  findings.  As  a  result,  the  utilization  of  a  hybrid 
design  that  couples  the  Transformer  with  a  CNN  backbone  (such  as 
ResNet)  is  advocated  here.  The  Transformer  may  concentrate  on 
modelling global attention using the feature that ResNet extracted. Ac-
cording to the experimental findings, the hybrid approach can deliver 
better performance with comparatively less computing work. The main 
objective of this work was to create a model that accurately identifies 
sika deer using the idea.

ecosθyi
∑C

ecosθyi +

ecosθj

j=1,j∕=yi

(2) 

Due to the modulus of the feature being correlated with the quality of 
the input picture, features with high image quality have a big modulus 
and those with low image quality for faces have a small modulus. When 
performing  the  backpropagation  process,  the  network  will  pay  more 
attention to the poorer quality because after the feature normalization 
process, those with modulus of tiny features will have a larger gradient 
than  those  with  modulus  of  large  features.  As  a  result,  the  feature 
normalization  process  is  appropriate  for  identification  jobs  with  poor 
picture quality but not for our model.

In this work, a model that successfully captures global interdepen-
dence was presented while expanding the intrinsic field of perception 
and reducing local redundancy. It is important to note that the devel-
oped network resembles the Transformer architecture used for the text 
classification task. Transformer classifies words at the sentence level by 
taking into consideration their placement and relationships in addition 
to simply adding meaning. Furthermore, the suggested model can more 
effectively solve these concerns since the produced sika deers dataset 
was  vulnerable  to  complicated  backdrops  and  low  levels  of  pattern, 
variety,  location,  and  distribution  of  the  features.  From  the  acquired 
experimental results, it was demonstrated that the introduced model can 
effectively identify sika deers with an accuracy of 97.68% from the deer 
face  dataset.  Relatively  high  accuracy,  better  robustness,  and  better

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide explicit information about specific preprocessing steps involved before training a deep learning model such as normalization, scaling, or cleaning. However, it mentions a feature normalization process during the backpropagation phase. This process involves adjusting the values of numeric columns in the data to a common scale without distorting differences in the ranges of values or losing information. Feature normalization is essential when applying machine learning algorithms to ensure that each attribute contributes proportionately to the final output. In the given context, feature normalization is mentioned as part of the developed network, which resembles the Transformer architecture used for text classification tasks.