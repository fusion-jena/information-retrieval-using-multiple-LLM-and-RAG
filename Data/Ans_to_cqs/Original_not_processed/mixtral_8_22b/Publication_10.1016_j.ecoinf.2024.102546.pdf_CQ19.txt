Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Abbeel, Pieter, 2017. Domain randomization for transferring deep neural networks 
from simulation to the real world. In: Paper Presented at the 2017 IEEE/RSJ 
International Conference on Intelligent Robots and Systems (IROS). 

Wang, Pei, Tang, Yin, Luo, Fan, Wang, Lihong, Li, Chengsong, Niu, Qi, Li, Hui, 2022. 
Weed25: a deep learning dataset for weed identification. Front. Plant Sci. 13, 
1053329. 

Wang, Su, Saharia, Chitwan, Montgomery, Ceslee, Pont-Tuset, Jordi, Noy, Shai, 

Pellegrini, Stefano, Onoe, Yasumasa, Laszlo, Sarah, Fleet, David J., Soricut, Radu, 
2023. Imagen editor and editbench: Advancing and evaluating text-guided image 
inpainting. In: Paper presented at the Proceedings of the IEEE/CVF Conference on 
Computer Vision and Pattern Recognition. 

Weyler, Jan, L¨abe, Thomas, Magistri, Federico, Behley, Jens, Stachniss, Cyrill, 2023. 
Towards domain generalization in crop and weed segmentation for precision 
farming robots. IEEE Robot. Automat. Lett. 8 (6), 3310–3317.

Imaging platform 

Recognition task 

Dang et al. (2023) 
Gaidel et al. (2023) 
Güldenring et al. (2023) 
Kitzler et al. (2023) 
Olaniyi et al. (2023) 
Rahman et al. (2022) 
Rai et al. (2023a) 
Steininger et al. (2023) 
Weyler et al. (2023) 
Alam et al. (2022) 
Chen et al. (2022) 
Du et al. (2022) 
Krestenitis et al. (2022) 
Mylonas et al. (2022) 
Teimouri et al. (2022) 
Wang et al. (2022) 
Xu et al. (2022) 
Ahmad et al. (2021) 
Beck et al., 2021 
Fawakherji et al. (2021) 
RV et al. (2021) 
Salazar-Gomez et al. (2022) 
Bender et al. (2020) 
Madsen et al. (2020) 
Sudars et al. (2020) 
Olsen et al. (2019) 
Lottes et al. (2018) 
Sa et al. (2018) 
Teimouri et al. (2018) 
Chebrolu et al. (2017) 
Di Cicco et al. (2017) 
dos Santos Ferreira et al. (2017) 
Giselsson et al. (2017) 
Lameski et al. (2017) 
Sa et al. (2017) 
Haug and Ostermann (2015)

jitter and mosaic augmentations, while DINO implements random crop 
and scale augmentation. The original weed images, which were mostly 
with high resolutions (over 10 megapixels), were resized to the input of 
800  × 800  pixels,  which  is  compatible  with  model  architectures  and 
training efficiency. The resizing was done by rescaling the long side of 
each image to 800 and adding padding to the short side to maintain the 
original image aspect ratio. All models were trained for 40 epochs with 
batch  size  8,  which  could  adequately  converge  based  on  empirical 
observations.

3. Materials and methods 

3.1. Dataset curation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the specific frameworks used to build the deep learning models mentioned in the papers. Therefore, it is not possible to determine which frameworks such as TensorFlow or PyTorch were utilized.