Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2. Split the datasets 

In this research, the datasets were randomly divided into three parts 
for training, validation and testing. Here, 60% of the data was used to 
train the deep learning models, and 20% of them was kept to validate the 
models. The remaining 20% data was used to evaluate the performance 
of the models. Table 1 show the number of data in the dataset and how 
they are separated for training, testing and validation. 

2.3. Deep learning models

VGG16 and VGG19 are classical architectures that are well known 
for  simplicity  and  uniformity.  These  models  are  suitable  for  smaller 
datasets and can provide better accuracy by fine-tuning the pre-trained 
network (Sukegawa et al., 2020). The models have several drawbacks, 
such  as  vanishing  gradient  problems  and  loss  of  fine-grained  spatial 
information (Pan et al., 2020). On the other hand, ResNet-50 contains 
residual  connections,  which  can  overcome  the  vanishing  gradient 
problem and enable training very deep networks. The model performs 
well on both large and small datasets (Al-Masni et al., 2020).

diction  of  the  deep  learning  model.  This  dataset  was  taken  to  verify 
whether our proposed approach can handle that issue. The dataset was 
shared  by  Jiang  et  al.  (2020)  through  the  Github  repository: 
https://github.com/zhangchuanyin/weed-datasets.

custom  fully  convolutional  encoder-decoder  network  using  multiple 
VGGNet-like  blocks.  They  reduced  the  computational  complexity  by 
incorporating  large  convolutional  kernels,  skip  layers  and  multiscale 
filters  in  the  traditional  VGGNet-like  blocks.  This  model  performed 
better than several architectures including Faster R-CNN, DeepLab-v3 
and U-Net. ChechliÂ´nski et al. (2019) proposed a hybrid CNN model of 
AlexNet and VGGNET, which outperformed the original model. On the 
other hand, Trong et al. (2020) argued that it was difficult to achieve 
better accuracy by using a single DL model to classify weed species. They 
improved the performance by fusing five state-of-the-art DL models.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention where the code repository of the deep learning pipeline is available. However, it mentions that the dataset used in the study was shared by Jiang et al. (2020) through the Github repository: https://github.com/zhangchuanyin/weed-datasets. Therefore, it could be possible that the code repository might also be available on Github or another similar platform. Unfortunately, without further information, I cannot confirm the exact location of the code repository.