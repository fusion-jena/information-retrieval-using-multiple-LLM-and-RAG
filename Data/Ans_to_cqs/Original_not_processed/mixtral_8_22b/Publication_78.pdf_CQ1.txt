Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Figure 3. The proposed framework steps visual representation.

3.1. Explanation of Steps

Initially, an image is taken with the help of an underwater drone. In the next step,
the image is segmentized and divided into small patches. Features are extracted from
each patch with the help of handcrafted descriptors and D-CNNs. A visual vocabulary

Big Data Cogn. Comput. 2021, 5, 53

5 of 15

(VV) is created, as shown in Figure 4, this visual vocabulary is the features extracted
from these features, and the training features are passed to classiﬁer i.e., SVM, which
classiﬁes whether the VV-features are of bleached coral or healthy coral. We used different
handcrafted features as well as different D-CNN’s but AlexNet shows the highest accuracy.
We used different classiﬁers i.e., SVM, kNN, and decision tree, but SVM outperforms all
other classiﬁers.

Figure 4. Visual Vocabulary of features.

3.2. Feature Extraction

Similarly, in [8] hyper-spectral bottom index imagery is used for bottom-type classiﬁca-
tion in coral reef areas. The drawback of this technique is the need for an enormous number
of samples in the dataset for achieving higher accuracy. In [9], they proposed a method
of deep convolutional neural network VGG-19 for corresponding coral classiﬁcation that
needs a massive dataset for better accuracy.

https://www.mdpi.com/journal/bdcc

big data and cognitive computing(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:1)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)Big Data Cogn. Comput. 2021, 5, 53

2 of 15

healthy, bleached, and dead corals. Similarly, this Figure also demonstrates the impact of
corals bleaching on aquatic animals life.

Figure 1. Different types of corals and their impact on aquatic life.

3.2. Feature Extraction

Handcrafted and spatial features are concatenated to obtained visual vocabularies
(VV). The texture and color features are extracted with the help of handcrafted descriptors
while spatial features are extracted with the D-CNN models.

3.2.1. Spatial Features

Features are extracted with handcrafted descriptors as well as D-CNN models. Initially,
an image is captured with the help of underwater drones. Then the image is preprocessed
and resized to the input size of D-CNN.

3.2.2. Pretrained D-CNN

In the case of AlexNet, the input image size is 227 × 227 × 3. AlexNet is an ImageNet
with a total of twenty-ﬁve layers. There are ﬁve convolutional layers in AlexNet to extract
the spatial features. The other layers involved in AlexNet architecture are fully connected
layers, max-pooling layers, sigmoid layer, and ReLU layer. The feature vector is obtained at
fully connected layer 7 (FC-7) of the AlexNet. Figure 5 illustrates the convolutional layers
of AlexNet.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific methods used for collecting raw data in the deep learning pipeline. However, it mentions that an image is initially taken with the help of an underwater drone. This suggests that one possible method for collecting raw data could be using underwater drones equipped with cameras to capture images of coral reefs. Additionally, the paper references other works that use hyperspectral bottom index imagery and deep convolutional neural networks like VGG-19 for bottom-type classification in coral reef areas. These methods may require large amounts of labeled data for training, which could potentially come from publicly available datasets or manual labeling efforts. Overall, while the exact methods for collecting raw data are not explicitly stated, the text implies that various techniques such as underwater drones, hyperspectral imagery, and publicly available datasets could be employed depending on the specific application and requirements of the deep learning pipeline.