Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

proper databases for CNN training.

16 of 19

Table 3. Confusion matrix for the ﬁrst CNN (5 classes).

Predicted Values

Actual values

Ep. cal. standard

Ep. cal. chorus

Ep. cal. amplexus

Al. obs. standard

Al. obs. distress

Ep. cal. standard

94.27% (560)

Ep. cal. chorus

Ep. cal. amplexus

Al. obs. standard

Al. obs. distress

4.78% (10)

9.09% (13)

1.2% (11)

2.28% (1)

1.01% (6)

95.22% (199)

0

0

0

4.71% (28)

0

90.91% (130)

0

0

0

0

0

98.8% (902)

0

0

0

0

0

97.72% (43)

Sensors 2021, 21, 3655

17 of 19

4. Discussion and Conclusions

of the entire training dataset) and a batch size (number of samples uti-lized in one training iteration) equal to 32. For the second network, the best training was achieved with six epochs and, again, a batch size equal to 32. For both networks, the initial learning rate [30] with 0.001 and the “adam” optimizer [31] were the parameters used in the training process. 3. Results 3.1. CPS Performance Several factors were considered in evaluating the CPS. First, at the level of data transport communication, a comparison between two paradigms was carried out. The central paradigm is based on sending the audio record from an IoT node to its digital twin at the cyber system side, where it is processed. The distributed paradigm is based on pro-cessing the audio record in the IoT node and sending the obtained result to its digital twin, where it is delivered to the central processing entity. Considering a 5-second audio regis-ter recorded with a sample rate of 44.1 kHz and 32 bits per sample

For CNN, which classiﬁes the 5 types of sound detailed in Table 1, a 94.54% success
rate was obtained for the training data, and 96.2% for the test data. Table 3 shows the
confusion matrix obtained for the test data.

Table 3 shows how the errors are distributed among the 5 different classes. The
percentage of error for all classes is in the range between 1.01% and 4.78%, except for the
Epidalea calamita class with amplexus vocalization, which has a 9.09% error (13 errors versus
143 audios). On the other hand, only one error was made in the Alytes obstetricans class
with distress calls. Thus, the network classiﬁcation results can be considered good and
robust at the same time. The accuracy results for this network with respect to the ﬁrst
network decrease slightly, but they are good enough to show that the CNN is capable of
distinguishing between standard and amplexus vocalization for Epidalea calamita.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific criteria used to determine when training is completed for the given models. However, it mentions that the first CNN model was trained using five epochs, while the second network was trained using six epochs. This suggests that the number of epochs might have been used as a criterion to stop the training process. Additionally, the use of the term 'best training' implies that some form of evaluation or metric was employed to assess the performance of the models during training. Common criteria used to determine when training is complete include monitoring metrics such as validation loss, accuracy, or other performance indicators, and stopping the training process once these metrics reach a satisfactory level or start to plateau.