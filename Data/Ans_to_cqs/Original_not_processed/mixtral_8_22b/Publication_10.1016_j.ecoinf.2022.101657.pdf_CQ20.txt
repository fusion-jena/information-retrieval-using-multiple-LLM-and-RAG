Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

7.1.4. Low power neural networks in hardware 

It is desirable to reduce the power consumption of the DynAIkonTrap 
to make deployment in remote locations easier and less expensive. An 
implementation by Si et al. (2020) of a Multilayer Perceptron model on 
an Field Programmable Gate Array (FPGA) was shown to run in a similar 
time frame to a software-based approach, but at a clock speed lower by a 
factor of 144. The authors portray this as the ability to achieve a lower 
power consumption or improve performance by a factor of 144. Results 
published by Intel (2016) indicate a Convolutional Neural Network can 
be  run  on  an  FPGA  with  twice  the  efficiency  of  a  software/CPU 
implementation.

7.1.3. Bespoke neural networks for species sets 

While we selected a suitable neural network for species identifica-
tion, we spent little research so far to train this network to sets of user- 
selected  or  prevalent  species  in  the  region  where  the  camera  trap  is 
deployed.  Training  for  a  bespoke  set  of  species  is  both  possible  and 
desirable. Further research is needed to identify and automate a process 
that,  given  a  set  of  species  of  interest,  outputs  a  robust  and  reliable 
neural network model with suitable weights. 

7.1.4. Low power neural networks in hardware

It is clear that hardware implementations of neural networks offer 
improved  power efficiency  over  software-based  alternatives and  their 
use has the potential to reduce the overall system’s power consumption. 
As this idea makes use of programmable hardware, any neural network 
implementation  is  not  permanent  and  so  the  customisability  of  the 
system  is  not  sacrificed.  It  may  also  be  worthwhile  investigating  the 
potential efficiency gains of using FPGAs in the motion filtering stage. 
Ultimately, it could be possible to implement the majority of the system 
with  FPGAs,  so  a  much  lower  power  processor  could  be  used  for 
remaining tasks such as networking and human interaction. 

8. Conclusion

Si, J., Harris, S.L., Yfantis, E., 2020. Neural networks on an FPGA and hardware-friendly 
activation functions. J. Comput. Commun. 08, 251–277. https://doi.org/10.4236/ 
jcc.2020.812021. 

Smith, S.W., 2002. Digital Signal Processing: A Practical Guide for Engineers and 

Scientists. Elsevier. 

Swanson, A., Kosmala, M., Lintott, C., Simpson, R., Smith, A., Packer, C., 2015. Snapshot 
Serengeti, high-frequency annotated camera trap images of 40 mammalian species in 
an African savanna. Sci. Data 2. https://doi.org/10.1038/sdata.2015.26. 

Jumeau, J., Petrod, L., Handrich, Y., 2017. A comparison of camera trap and permanent 
recording video camera efficiency in wildlife underpasses. Ecol. Evol. 7, 7399–7407. 
https://doi.org/10.1002/ece3.3149. 

Tabak, M.A., et al., 2019. Machine learning to classify animal species in camera trap 

images: applications in ecology. Methods Ecol. Evol. 10, 585–590. https://doi.org/ 
10.1111/2041-210X.13120.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not explicitly mention which specific hardware resources were used for training the deep learning models. However, there are some relevant details about implementing neural networks on hardware. In section 7.1.4, it discusses the implementation of a Multilayer Perceptron model on an Field Programmable Gate Array (FPGA), which offers improved power efficiency compared to software-based alternatives. Additionally, Intel's results show that running a Convolutional Neural Network on an FPGA can have twice the efficiency of a CPU implementation. These findings suggest that FPGAs might be one type of hardware resource used for deploying trained deep learning models more efficiently. Nevertheless, without explicit information regarding the training phase, it cannot be confirmed whether these same hardware resources were utilized during the training process itself.