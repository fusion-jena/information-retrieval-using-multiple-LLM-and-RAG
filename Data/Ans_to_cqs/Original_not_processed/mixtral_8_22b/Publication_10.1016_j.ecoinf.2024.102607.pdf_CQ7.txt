Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To address the problem of unbalanced training data, scholars have 
explored  various  sampling  techniques,  including  major  category

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Arid zone 
LULC 
Tile 
Multiple probabilistic classification 
Spaceâ€“spectrum array 
Random forest 
Google earth engine

undersampling  (Freeman  et  al.,  2012),  minor  category  oversampling 
(Rayhan  et  al.,  2017),  and  combinations  of  oversampling  and  under-
sampling (Naboureh et al., 2020). An incorrect sampling strategy may 
increase the training complexity and lead to overfitting phenomena (Gu 
et al., 2022). These studies, through improved sampling strategies, were 
all  based  on  a  traditional  overall  model.  However,  the  overall  model 
required  significant  computing  capabilities  for  large-scale  LULC  map-
ping. To further mitigate the limitations of the overall model and tackle 
the  problem  of  unbalanced training  data  in  RF-based  LULC  mapping, 
Zhang et al. (2020) introduced a hexagonal random-sampling strategy 
along with a tile model to improve the accuracy of LULC mapping in 
Madagascar,  a  region  characterized  by  highly  heterogeneous 
landscapes.

EcologicalInformatics81(2024)1026076F. Guo et al.                                                                                                                                                                                                                                      

Fig. 5. Structure of the SSA-TPRF model.  

4.3. Effect of tile size on accuracy 

Table 4 
Experimental group design.  

Experimental 
group 

Classification model 

Classification 
approach 

Tile size 
(km) 

EXP1 
EXP2 

EXP3 

EXP4 

EXP5 
EXP6 
EXP7 
EXP8 
EXP9 
EXP10 

Overall model 
Tile model 
Overall model + Multiple 
probabilistic classification 
model 
Tile model + Multiple 
probabilistic classification 
model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 
SSA-TPRF model 

PBA  
PBA 

PBA  

PBA 

SSA 
SSA 
SSA 
SSA 
SSA 
SSA 

25 

25 

25 
10 
20 
50 
75 
100  

other PBA-based models.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide information about the specific criteria used to split the data for deep learning model training into train, test, or validation sets. However, common practices include splitting the dataset randomly, stratified sampling, or using time-series splits depending on the nature of the data and the requirements of the project. The most commonly used ratio is 80/20 or 70/30 for training and testing datasets respectively, while some portion of the training set can be reserved for validation during the training process. It should also be noted that the choice of splitting method and ratios depends on factors such as the total amount of available data, class imbalance, and computational resources.

Based on the given context, it appears that the researchers focused on addressing issues related to unbalanced training data and improving sampling strategies rather than discussing the specifics of how they divided their data for training, testing, and validation purposes. Therefore, without additional information, we cannot determine the exact criteria used to split the data for deep learning model training in this case.