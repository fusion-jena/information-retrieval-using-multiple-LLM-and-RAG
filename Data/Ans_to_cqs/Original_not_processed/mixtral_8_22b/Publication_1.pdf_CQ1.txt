Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

raw data are collected and transmitted back to a central data store. 
From  there,  the  data  may  be  analyzed  with  a  variety  of  different 
algorithms.  As  a  whole,  we’ve  found  this  approach  helps  to 
alleviate  the  sampling,  variability,  and  bias  problems  associated 
with traditional surveys. Further, the costs are reduced – the cost 
of  transporting  and  sustaining  field  crews  in  remote  locations  is 
instead applied to less frequently serviced sensor hardware. 

The  primary  challenge  for  this  approach  is  handling,  processing, 
and  analyzing  the  sheer  volume  of  data  generated  by  regional 
sensor  networks.  This  challenge  has  two  components,  one  being 
the technology infrastructure required to handle big data, and the 
other  having  to  do  with  the  amount  of  labor  required  to  process 
and analyze the data.

However,  the  rise  of  cheap  and  powerful  sensors  has  created  an 
ever-increasing data glut.  To be effective, these new tools must be 
coupled  with  new  automated  approaches  to  processing  and 
analyzing wildlife data streams. 

Here we describe examples of how we are leveraging advances in 
the areas of big data and deep learning to help researchers extract 
meaningful  information  from  the  torrent  of  new  sensor  data,  and 
improve the adaptive management of natural systems. 

4. DEEP LEARNING FOR 

BIODIVERSITY  
4.1.Big data infrastructure

We are primarily focused on processing and analyzing large, high-
bit-rate datasets such as audio (high sample rate) and image (large 
amount  of  data  per  sample)  streams.  Other  environmental  sensor 
data, like temperature or air quality, utilize much lower data rates. 
For example, to record bird vocalizations, we typically record 16-
bit stereo audio at a moderate sample rate of 22,000 samples per 
second (22 kHz) at each monitoring site. In another example, for 
tracking  populations  of  invasive  snakes  we  ingest  2048-by-1536 
8-bit 4:2:2 color images taken at least once every thirty seconds at 
each  site.    Data  are  often  collected  with  a  30%  duty  cycle  over 
each day, and light (lossless or near-lossless) data compression is 
employed. A typical survey point can easily generate more than 5 
gigabytes (GB) of data per day, and an entire monitoring project, 
integrating  multiple  sites  in  a  region  over  a  multiple-month

which  no  models  yet  exist.  A  roadmap  of  improvements  is 
envisioned  for  further  enhancing  analysts'  ability  to  explore  and 
search large volumes of sensor data, including providing a richer 
set  of  elemental  signal  attributes,  a  more  natural-language 
interface, and also the ability to search by exemplars. 

Other  exploration  tools  are  more  focused  on  visualizing  the  data 

Finally,  our  software  expedites  auditing  –  the  manual  review  of 
classification  model  output.  We  run  existing  DL  models  against 
our  survey  data  to  automatically  classify  and  detect  species  or 
events  of  interest  for  each  project.  These  models  output  the 
relative  probability  that  an  event  is  from  a  specific  data  class 
(usually  corresponding  to  a  species  or  event),  and  analysts  can 
sort the data accordingly. Analysts are then presented with ranked

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The text describes the use of regional sensor networks for collecting raw data in the deep learning pipeline. These sensors can collect various types of data, including audio and image streams, as well as other environmental sensor data such as temperature or air quality. For instance, to record bird vocalizations, they typically record 16-bit stereo audio at a moderate sample rate of 22,000 samples per second (22 kHz) at each monitoring site. Additionally, for tracking populations of invasive snakes, they ingest 2048-by-1536 8-bit 4:2:2 color images taken at least once every thirty seconds at each site. Data are often collected with a 30% duty cycle over each day, and light (lossless or near-lossless) data compression is employed.