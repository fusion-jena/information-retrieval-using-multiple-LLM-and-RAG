Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Many deep learning-based strategies have been utilised recently for 
automatic feature extraction and end-to-end classification because of the 
faster growth in the field of artificial intelligence. Several studies have 
been used convolutional neural networks (CNN) for EM image classifi-
cation (Wahid et al., 2019). Despite its success in collecting the local 
features  from  the  images,  CNN  performs  poorly  to  capture  the  long- 
distance  relationships  (Qin  et  al., 2018).  Transformer-based  networks 
are now frequently utilised by modern deep learning applications such 
as computer vision, and speech signal processing due to their ability to 
capture long-distance relationships (Lan et al., 2019; Liu et al., 2017). 
The transformer was first used as a machine translating machine. The 
first  transformer-based  architecture  utilised  in  the  field  of  computer 
vision for image classification was the Vision Transformer (ViT) (Dos-

configuration of optimizer and learning rate which has been considered 
for the training of the framework. The EMViT-Net framework achieves 
prominent results as compared to other deep learning models and per-
forms better with an augmented set of EMDS-6 datasets.

ViTs are not suitable for small-size datasets as they are unable to extract 
muti-scale features and lack the locality that CNNs were designed for. 
A novel transformer-based architecture is proposed in this study to 
increase  the  performance  of  the  ViT  even  in  the  absence  of  a  large 
dataset  and  achieve  state-of-the-art  results  for  the  classification  of 
environmental microorganisms into 21 categories using a microscopic 
image  dataset  EMDS-6.  The  key  distinction  between  the  proposed 
framework  and  earlier  research  is  the  employment  of  a  transformer 
network  incorporating  convolution  operations  with  Separable  con-
volutional  parameter-sharing  attention  (SCPSA)  in  its  core  section  to 
enable reliable and effective training of the network on a limited-size 
dataset  by  extracting  multiscale  features  from  the  images.  The  main 
contribution of the proposed study is defined as follows:

b)  Some preprocessing steps like data augmentation and normalization 
are  performed  to  address  the  diversity  of  training  data  and  data 
imbalance problems in classification tasks.  

c)  The preprocessed images are fed to the transformer-based network 
EMViT-Net for extracting the both local and global features of mi-
crobes from EM images.  

d)  The integration of the SCPSA block in the CNN module of the EMViT- 
Net makes the model more efficient in extracting depth-wise features 
from the images.  

e)  The  extracted  features  are  then  given  to  a  multilayer  perceptron 

module for final feature fusion and classification.  

f)  Finally, the performance of the proposed EMViT-Net is evaluated on 
unseen test sets of the datasets by calculating performance metrics 
accuracy, precision, recall and f1-Score. 

2.1. EMViT-Net

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it can be inferred that the deep learning pipeline uses image data format. This is evident from several mentions of images throughout the text, including phrases such as "local features from the images," "long-distance relationships within images," and "extracting multi-scale features from the images." Furthermore, the context explicitly states that the proposed framework aims to classify environmental microorganisms using a microscopic image dataset called EMDS-6. Therefore, it can be concluded that the primary data format utilized in this deep learning pipeline is image data.