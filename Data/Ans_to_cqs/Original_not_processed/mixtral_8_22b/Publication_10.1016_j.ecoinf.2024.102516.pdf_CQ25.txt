Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Plant biodiversity 
Plant cover 
Deep learning 
Convolutional neural networks 
Semantic segmentation 
Artificial intelligence

Appendix A. Supplementary data 

Supplementary data to this article can be found online at https://doi. 

org/10.1016/j.ecoinf.2024.102516. 

References 

Altalak, M., Ammad uddin, M., Alajmi, A., Rizg, A., 2022. Smart agriculture applications 

using deep learning technologies: A survey. Appl. Sci. 12 (12), 5919. 

Bambil, D., Pistori, H., Bao, F., Weber, V., Alves, F.M., Gonçalves, E.G., de Alencar 
Figueiredo, L.F., Abreu, U.G., Arruda, R., Bortolotto, I.M., 2020. Plant species 
identification using color learning resources, shape, texture, through machine 
learning and artificial neural networks. Environ. Syst. Decis. 40 (4), 480–484. 
Bauer, T., Strauss, P., 2014. A rule-based image analysis approach for calculating 

residues and vegetation cover under field conditions. Catena 113, 363–369. 

Blaschke, T., 2010. Object based image analysis for remote sensing. ISPRS J. 

Photogramm. Remote Sens. 65 (1), 2–16.

EcologicalInformatics80(2024)1025165M. K¨orschens et al.                                                                                                                                                                                                                             

Fig. 4. The basic 3-phase processing pipeline for training our network. In the first phase, a classification network is trained using GBIF image data, which applies 
class activation mapping to generate weak segmentation maps. In the second phase, these maps are used for training a segmentation network on the GBIF image data. 
In the third phase, the networks weights can be used to either train a plant cover prediction network on the actual vegetation data (like the InsectArmageddon 
dataset), or the network can be applied directly to vegetation data to generate zero-shot predictions without any training on plant cover annotations. Image adapted 
from K¨orschens et al. (2021b).

Because  of  this,  the  approach  we  introduced  in  K¨orschens  et  al. 
(2021b) trains the network in three distinct phases, as shown in Fig. 4. In 
the first phase, we perform standard classification training, i.e., we train 
the network to predict the respective plant species when given an input 
image. The trained network then utilizes the so-called class activation 
mapping (CAM) approach (Zhou et al., 2016) to generate segmentation 
maps for each image (here also referred to as “weak segmentations” or 
“weak  segmentation  maps”),  which  usually  cover  most  of  the  plant, 
including blossoms and leaves. This segmentation data is then used in 
the second training phase to train a segmentation network, which, due 
to  the  nature  of  the  previously  generated  pseudo-ground-truth  seg-
mentation maps, focuses on the complete plant instead of only single 
parts. The parameter values of this network, also known as weights, are

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The purpose of the deep learning model described in the provided context is both classification and semantic segmentation. Initially, the model is trained for classification tasks, where it learns to predict the respective plant species from input images. Afterward, the same model uses the Class Activation Mapping (CAM) technique to produce weak segmentation maps covering most parts of the plants, including flowers and leaves. These segmentation maps serve as pseudo ground truth labels for further training the model for semantic segmentation tasks. The ultimate goal of this multi-stage training process is to create a deep learning model capable of accurately identifying different plant species and generating precise segmentation masks around them within input images.