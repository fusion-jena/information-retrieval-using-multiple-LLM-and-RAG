Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

specific segmentation models. The full instructions and options are 

cluded in model training are shown in Figure 1.

provided on the GitHub repository.

2.3 | Model training procedure

2.5 | Sashimi online model repository

We first used the VGG Image Annotator Version 1.0.6 (https://www.

We constructed a website to serve as a repository for the fish seg-

robots.ox.ac.uk/~vgg/softw are/via/via- 1.0.6.html;  Dutta  et  al., 
2016) to manually annotate pixel coordinates to create precise po-

mentation model (presented here) and future, community generated 

organismal  segmentation  models  (https://sashi mi.shawn tyler schwa 

lygonal mask contours directly around the fish body boundary (i.e. 

rtz.com). We aim to inspire other biologists interested in automated 

where the foreground pixels of the target fish body meet those of 

segmentation to create pre- trained models for their organism(s) of 

the background). We intentionally assigned all segmentation masks

have  revealed  promising  utility  for  automating  data  collection  ap-

data  collection  increase.  Computer  vision  techniques  provide  one 

proaches for studies in ecology and evolutionary biology at substan-

means  for  accurate  and  scalable  image  pre- processing  in  biology 

tially greater speeds than manual approaches (Christin et al., 2019; 

(Lürig et al., 2021; Muñoz & Price, 2019; Porto & Voje, 2020).

Lürig et al., 2021; Norouzzadeh et al., 2018; Schneider et al., 2019). To 

Machine learning, and especially deep learning algorithms, which 

illustrate, deep learning with CNNs has been successful for ecologi-

permit  the  identification  and  classification  of  complex  patterns  in 

cal applications, including the automated identification of sea turtles 

noisy environments (Carranza- Rojas et al., 2017; Cheng et al., 2017; 

(Gray et al., 2018) and segmentation of cetaceans (Gray et al., 2019)

He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectifiers: 
Surpassing human- level performance on ImageNet classification. In 
2015 IEEE International Conference on Computer Vision (ICCV). IEEE.

He,  K.,  Zhang,  X.,  Ren,  S.,  &  Sun,  J.  (2016).  Deep  residual  learning  for 
image recognition. In Proceedings of the IEEE conference on computer 
vision and pattern recognition (pp. 770– 778).

Hubel,  D.  H.,  &  Wiesel,  T.  N.  (1962).  Receptive  fields,  binocular  inter-
action  and  functional  architecture  in  the  cat's  visual  cortex.  The 
Journal of Physiology, 160, 106– 154. https://doi.org/10.1113/jphys 
iol.1962.sp006837

Joly,  A.,  Bonnet,  P.,  Goëau,  H.,  Barbe,  J.,  Selmi,  S.,  Champ,  J.,  Dufour- 
Kowalski,  S.,  Affouard,  A.,  Carré,  J.,  Molino,  J.- F.,  Boujemaa,  N., 
&  Barthélémy,  D.  (2016).  A  look  inside  the  Pl@ntNet  experience. 
Multimedia  Systems,  22,  751– 766.  https://doi.org/10.1007/s0053 
0- 015- 0462- 9

overarching  goal  of  training  a  neural  network  is  to  iteratively  min-

tional  training.  The  utility  of  pre- trained  CNNs  out- of- the- box  is 

imize the error between model output and expected output by op-

constrained by how relevant the novel input data are to the data the 

timally  adjusting  model  weights  and  reaching  model  convergence, 

CNN  was  originally  trained  on.  For  instance,  ImageNet  comprises 

such that the trained neural network generalizes well to novel input 

more  than  14  million  high- resolution  images  across  nearly  22,000 

data. Model weights are adjusted to minimize error on each subse-

categories and is often used as a starting point for recognition tasks 

quent run using an algorithm called stochastic gradient descent with 

with deep learning (Deng et al., 2009; Krizhevsky et al., 2017). Using 

backpropagation  (LeCun  et  al.,  1989;  Rumelhart  et  al.,  1995).  This

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific process followed to deploy the trained deep learning model, such as model serialization or platform selection. However, it mentions that they created a website to serve as a repository for the fish segmentation model, suggesting that the deployment involved hosting the model on this website. Additionally, the use of the VGG Image Annotator tool indicates that the team likely went through a process of labeling and preparing the dataset before feeding it into the deep learning model for training. After training, the model would have been saved and possibly optimized for efficient inference before being deployed onto the web server.