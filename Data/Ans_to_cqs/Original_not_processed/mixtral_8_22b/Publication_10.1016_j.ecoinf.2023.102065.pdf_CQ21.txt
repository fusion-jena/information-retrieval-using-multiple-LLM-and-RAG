Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ence data available for training were limited, so we sought to explore 
different network sizes in conjunction with pre-training with additional 
acoustic reference data from outside of our audio domain, followed by 
fine-tuning with ROI data from our study site.

The  recordings  for  each  ROI  were  cut  using  start/stop  times  and 
sequentially appended to create a single merged .wav file for each spe-
cies and set (i.e., train, validation) combination. Each merged .wav file 
was  then  sliced  into  2-s  increments  and  mel-spectrograms  computed. 
Note that since there were some ROIs from the pattern matching that 
were >2 s, some 2-s recording clips included parts from different ROIs. 
Performing data augmentation on training datasets is a widely used 
technique in deep learning, including sound classification applications, 
to  regularize  models  and  provide  more  robust  features  (Salamon  and 
Bello, 2017). We performed data augmentation by splitting the merged . 
wav  training  file  for  each  species  in  half  and  then  adding  these  two 
halves sample-wise. This augmented .wav file was similarly split into 2-s 
increments as above and mel-spectrograms were computed. The training

We evaluated model performance with and without additional pre- 
training with external sound data prior to fine-tuning with sound data 
from our study. For the pre-trained models, we used training and vali-
dation XC mel-spectrograms to adjust the weights of each of the three 
CNN models. Pre-training with XC data was implemented for all CNN 
models starting with training the final, dense layer for 10 epochs fol-
lowed by training all layers for 10 additional epochs. 

Fine-tuning using the ROI training and validation mel-spectrograms 
was  then  applied  to  both  the  default  CNN  backbones  (i.e.,  not  pre- 
trained  on  XC)  and  to  the  XC  pre-trained  CNNs.  The fine-tuning  pro-
cess consisted of two stages: (1) model training on the classifier only (i. 
e., dense, fully-connected layer), freezing all other trainable parameters 
in CNN layers for 10 epochs (learning rate = 0.0001), and (2) fine-tuning

2.2.1. Regions of interest (ROI) for classifier fine-tuning training and testing 
We targeted 54 species that have distinctly unique vocalizations (call 
or song pattern) and are common in the study area during the breeding 
bird  season  (Table  1).  Although  additional  species  could  have  been 
studied (~180 species total; Sonoma County Breeding Bird Atlas, 2020), 
our project did not attempt to be exhaustive given the constraints of a 
citizen science project based on volunteer labor. Some species include 2 
to 3 different vocalizations (Table S1). Reference bird vocalizations were 
collected by citizen scientists using a web-based interface in the Arbi-
mon platform (Aide et al., 2013). In this process, an expert citizen sci-
entist  with  knowledge  of  local  bird  vocalizations  identified  parts  of 
spectrograms that represent a target bird vocalization. The system then 
used this template region of interest (ROI) and a pattern matching al-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it appears that the focus is primarily on the training and fine-tuning processes of the Convolutional Neural Network (CNN) models for sound classification. However, the context does not explicitly mention any specific postprocessing steps taken after the model training. Therefore, I cannot provide a direct answer regarding the postprocessing steps such as saliency maps, metrics calculation, or confusion matrix generation. These techniques are often used to evaluate and interpret machine learning models, but their application is not discussed in the provided text.