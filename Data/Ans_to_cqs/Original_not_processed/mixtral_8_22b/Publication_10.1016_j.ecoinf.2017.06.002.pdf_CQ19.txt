Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Finally, FRAMES was designed to facilitate submission to data re-
positories, including the NGEE Tropics Archive, the project's data re-
pository. The NGEE Tropics Archive has a web portal that allows data
originators to upload and download data packages. The Archive is
supported by a programmatic REST API built on top of Django Python
web framework with an easy-to-use web user interface built with
Foundation (Zurb, 2016) front-end framework. The Foundation front-
end framework is ﬂexible, highly customizable and provides support for
responsive, light-weight HTML for mobile application support. Django
is a fully featured open-source Python web application framework that
supports rapid development. Django makes the low-level framework
decisions so that the development is primarily focused on the applica-
tion domain rather than composing the framework features. NGEE
Tropics Archive manages the data package by storing the data package

Additionally, FRAMES promotes good data management practices
that beneﬁts both data originators and consumers by 1) digitally pre-
serving data with adequate metadata documentation, 2) enabling
sharing with the broader community with appropriate citation and at-
tributions, 3) facilitating interoperability with other databases, and 4)
broadening data use and reuse for purposes that stretch beyond the
initial intentions of the data collection eﬀort (particularly for use in
earth system models). Next steps involve making improvements to
FRAMES based on data originator and consumer feedback, and ex-
traction of information in data packages into a queryable database that
enables programmatic search, discovery, and processing of data.

Supplementary data to this article can be found online at http://dx.

doi.org/10.1016/j.ecoinf.2017.06.002.

Acknowledgments

A potential limitation to the framework is due to the eﬃcient re-
porting mechanism designed to make reporting easier for data origi-
nators. FRAMES does not specify data variable names, units, or formats,
which are required for database assimilation. Using FRAMES, reported
data can be translated into a standardized protocol for database as-
similation, as exempliﬁed by similar case of automation of sap ﬂow
processing by a data consumer. The outstanding questions are 1)
whether this reporting approach will ultimate result in improved
availability of data with accompanying high quality metadata, and 2)
what the tradeoﬀs are in terms of person-hours and who bears that
cost—the data originator or dedicated data team personnel. We prior-
itized reporting formats in FRAMES to maximize reporting eﬃciency
because although improving, the generally low quantity of shared data

The modular expandability of FRAMES is similar and compatible
with ODM2 (Horsburgh et al., 2016), in that metadata is bundled in
related groups. The diﬀerence is that ODM2 is a database structure for
standardized metadata and data protocols. FRAMES operationalizes
such a data structure as a reporting mechanism. In other words, data
reported via FRAMES can be translated to a standardized format for
assimilation into a database. This pre-database, standard-compatible
ﬂexibility diﬀerentiates FRAMES from other existing frameworks such
as AmeriFlux/BADM, ISCN, and Sapﬂuxnet, which collect metadata and
data in a standardized protocol designed for direct database assimila-
tion.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: Based on the provided context, there is no mention of any specific deep learning frameworks like TensorFlow or PyTorch being used to build a deep learning model. Therefore, it cannot be determined which frameworks were used to build the deep learning model.