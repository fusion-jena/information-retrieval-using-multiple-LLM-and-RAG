Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1 
Number of training images, validation images (used for model validation during 
model  training)  and  out-of-sample  test  images  (used  for  external  model  vali-
dation after training was finished) as well as number of new images selected 
from  the  images  taken  between  summer  2020  and  summer  2021  for  model 
retraining.  

Class 

Number of 
training 
images 

Number of 
validation 
images 

Number of 
out-of-sample 
test images 

Number of new 
training images 
for model 
retraining 

Bad 

6453 

quality 

Bird 
Empty 
Least 

weasel 
Lemming 
Shrew 
Stoat 
Vole 
TOTAL 

3382 
9444 
1725 

9449 
9265 
4024 
9894 
53636 

677 

219 
979 
98 

967 
962 
438 
1024 
5364 

549 

119 
3301 
69 

647 
584 
64 
919 
6252 

306 

195 
533 
424 

449 
416 
425 
528 
3276

classification tasks. Inf. Process. Manage. 45, 427–437. https://doi.org/10.1016/J. 
IPM.2009.03.002. 

Steenweg, R., Hebblewhite, M., Kays, R., Ahumada, J., Fisher, J.T., Burton, C., 

Townsend, S.E., Carbone, C., Rowcliffe, J.M., Whittington, J., Brodie, J., Royle, J.A., 
Switalski, A., Clevenger, A.P., Heim, N., Rich, L.N., 2017. Scaling-up camera traps: 
monitoring the planet’s biodiversity with networks of remote sensors. Front. Ecol. 
Environ. 15, 26–34. https://doi.org/10.1002/FEE.1448. 

Tabak, M.A., Norouzzadeh, M.S., Wolfson, D.W., Newton, E.J., Boughton, R.K., Ivan, J.S., 
Odell, E.A., Newkirk, E.S., Conrey, R.Y., Stenglein, J., Iannarilli, F., Erb, J., Brook, R. 
K., Davis, A.J., Lewis, J., Walsh, D.P., Beasley, J.C., VerCauteren, K.C., Clune, J., 
Miller, R.S., 2020. Improving the accessibility and transferability of machine 
learning algorithms for identification of animals in camera trap images: MLWIC2. 
Ecol. Evol. 10, 10374–10383. https://doi.org/10.1002/ece3.6692.

complete data set. Thus, model performance would be overestimated for 
rare  classes  and  underestimated  for  abundant  classes.  Therefore,  the 
number  of  true  positives,  false  positives  and  false  negatives  was

2.4. Model retraining 

Based on the quality check, the researcher can decide whether model 

performance  is  satisfactory  or  if  the  model  performance  should  be 
improved by selecting new training images and retraining the model. If 
images from new sites have been classified, model performance can be 
improved by including images from these sites in the training data set. If 
the model had problems with some classes; e.g. identification of some 
species,  it  might  help  to  include  more  images  of  these  species  in  the 
training data set. When selecting new training images, the model output 
from the original model can be helpful to find images that meet a certain 
criteria, e.g. to find images of a certain species. However, all training 
images should be reviewed manually instead of relying on model out-
puts only to avoid misclassified training images. 

2.5. Manual classification

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The context does not provide explicit information about the specific criteria used to determine when training is completed. However, based on common practices in machine learning, one possible criterion could be reaching a validation loss plateau. This means that the model has learned most of what it can learn from the current dataset, and further training will not significantly improve its performance. Other potential criteria could include achieving a desired level of accuracy or precision on the validation set, or meeting other predefined performance metrics. It is important to note that the choice of criteria may depend on the specific goals and requirements of the project.

The context also mentions the possibility of improving model performance through manual selection of additional training images and subsequent retraining. This suggests that the decision to stop training and consider the model finalized may involve a subjective assessment of its performance, rather than strictly adhering to quantitative criteria. Ultimately, the determination of when training is complete will likely require careful consideration of both objective performance metrics and subjective judgments regarding the model's suitability for its intended use case.