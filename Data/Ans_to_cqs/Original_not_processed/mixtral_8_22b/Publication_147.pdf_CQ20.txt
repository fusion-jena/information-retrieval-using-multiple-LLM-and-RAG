Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 2. Full comparison of training time, prediction time, optimization time (i.e., time to properly
tune the model), and hardware for each model.

Model

Training Time
(Hours)

Prediction Time (Hours)

Optimization
Time (Hours)

Hardware

CNN

XGB

4

4

2.4. Validation

4

Unknown

Desktop with 64 Gb of
RAM and one Titan X
(Maxwell) GPU.

72—can be reduced by
distributing prediction to more
cores or more machines.

2

Desktop with 64 GB of
ram and 64 logical cores.

Table 1. List of input variables in the XGBoost model (XGB) and convolutional neural network
(CNN) models. Each variable lists its respective data source, equation, description, and, if needed,
citation. For information on Sentinel-2 band information not listed in the table, see:
[66] and
https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial.

Variable

Data Source

Model

ARI

Sentinel-2

XGB/CNN

Band 2
Band 3
Band 4
DEM

NDVI

dNDVI

NDWI

POLr

PSRI

Sentinel-2
Sentinel-2
Sentinel-2
ALOS

Sentinel-2

Sentinel-2

Sentinel-2

Sentinel-1

Sentinel-2

CNN
CNN
CNN
CNN

CNN

XGB

CNN

XGB

CNN

REIP

Sentinel-2

XGB/CNN

Equation
(cid:17)
(cid:16) B8
(cid:16) B8
B3
B2

–

(cid:17)

-
-
-
-
(B8− B4)
(B8 + B4)

Description

Keywords: wetlands; Sentinel-1; Sentinel-2; Google Earth Engine; remote sensing; Alberta;
segmentation convolutional neural nets; XGBoost; land cover; SAR; machine learning

1. Introduction

Machine learning—a method where a computer discovers rules to execute a data processing
task, given training examples—can generally be divided into two categories: Shallow learning and
deep learning methods [1]. Deep learning uses many successive layered representations of data
(i.e., hundreds of convolutions/ﬁlters), while shallow learning typically uses one or two layered
representations of the data [1]. Deep learning has shown great promise for tackling many tasks such as
image recognition, natural language processing, speech recognition, superhuman Go playing, and
autonomous driving [1–3].

Remote Sens. 2020, 12, 2; doi:10.3390/rs12010002

www.mdpi.com/journal/remotesensing

The segmentation convolutional neural network was implemented in the Python programming
language using the Keras [79] deep learning library. The speciﬁc architecture used was a U-Net CNN,
which was originally developed for biomedical image segmentation [22]. The U-Net architecture
is based on a fully convolutional network and was used since it typically requires fewer training
patches and is able to train in a reasonable time [22]. A sample of the U-Net architecture can be seen in
Appendix B. The inputs used by our CNN model were: ARI, Band 2, Band 3, Band 4, DEM, NDVI,
Normalized Diﬀerence Water Index (NDWI), Plant Senescence Reﬂectance Index (PSRI), REIP, TPI,
Topographic Roughness Index (TRI), TWI, VBF, VH (Table 1). Note that these inputs were diﬀerent
from the XGB model, because diﬀerent inputs are needed to best optimize deep learning models. We

Remote Sens. 2020, 12, 2

8 of 20

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
According to Table 2, the Convolutional Neural Network (CNN) model was trained using a desktop with 64 Gb of RAM and one Titan X (Maxwell) GPU. Therefore, the hardware resource used for training the deep learning model is a GPU.

Answer:::

Answer: According to Table 2, the Convolutional Neural Network (CNN) model was trained using a desktop with 64 Gb of RAM and one Titan X (Maxwell) GPU. Therefore, the hardware resource used for training the deep learning model is a GPU.