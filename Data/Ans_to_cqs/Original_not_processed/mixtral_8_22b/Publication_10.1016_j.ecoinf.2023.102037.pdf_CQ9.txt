Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

• Aperture: F/10  
• ISO: 160  
• Shutter speed: 1/15 s  
• Focal Length: 55 mm  
• White balance: “Incandescent” 

2.3. Data splitting and image tiling

ofmineervlieg/. Accessed: 1 June 2022.  

Wang, R.J., et al., 2017. A crop pests image classification algorithm based on deep 

convolutional neural network. Telkomnika (Telecommun. Comput. Electron. Contr.) 
15 (3), 1239–1246. Available at: 10.12928/TELKOMNIKA.v15i3.5382. 

Wang, C.Y., et al., 2020a. CSPNet: A new backbone that can enhance learning capability 
of CNN. In: IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition Workshops, 2020-June, pp. 1571–1580. Available at: https://doi.org/ 
10.1109/CVPRW50498.2020.00203. 

Wang, J., et al., 2020b. Common pests image recognition based on deep convolutional 

neural network. Comput. Electron. Agric. 179 (June), 105834. Available at: https 
://doi.org/10.1016/j.compag.2020.105834.

2021a; Wang et al., 2020c). Wang et al. (2020a, 2020b, 2020c) obtained 
a mean Average Precision (mAP) score of 63.54% using YOLOv3 (Red-
mon  and  Farhadi,  2018)  while  detecting  and  classifying  pest  species 
from  the  images  in  their  “Pest24”  dataset.  The  dataset  consisted  of 
25,378  annotated  images  coming  from  24  pest  species  that  were  all 
collected by an automatic imaging trap. Rustia et al. (2021) designed a 
multi-stage deep learning method including object detection, insect vs. 
non-insect  separation  and  a  multi-class  insect  classification  for  insect 
identification. Data were acquired by multiple wireless imaging devices 
installed  in  greenhouses  –  under  varying  lighting environments  -  and 
their classification model reached average F1-scores of up to 0.92. Hong 
et  al.  (2021)  developed  an  AI-based  pest  counting  method  for  moni-
toring  the  black  pine  bast  scale  (M.  thungergianae)  which  reached  a

Fig. 5. A) Illustration of the procedure for separating data into training, validation and test sets, and tiling sticky plate images by finding regions of interest of a fixed 
size (512x512 pixels) that contain the maximum number of complete bounding boxes. B) Illustration of applying the YOLOv5 model on a sticky plate image using 
“Slicing Aided Hyper Inference” (SAHI). 

EcologicalInformatics75(2023)1020375I. Kalfas et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The information regarding the specific data repository used for storing the deep learning pipeline mentioned in this context is not explicitly stated. Therefore, it cannot be determined where exactly the data repository is located or if it has been made publicly accessible through platforms such as Zenodo, Figshare, Dryad, or GBIF. To find out more about the data repository, further research would need to be conducted or additional resources consulted.

Unhelpful Answer:
The data repository for the deep learning pipeline is stored on GitHub.

Explanation:
This response is unhelpful because there is no mention of GitHub being used as a data repository within the given context. It is important to only provide answers based on the information presented in the context and avoid making assumptions or providing false information.