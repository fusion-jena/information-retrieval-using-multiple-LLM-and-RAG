Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

predicted variables, as well as assist in combining multiple data sources 
to improve overall prediction accuracy (Deb et al., 2017). In practice, 
ANN models have often outperformed other conventional methods with 
respect  to  prediction  accuracy,  processing  rapidity,  and  nonlinear 
problem-solving capacity (Tiryaki and Aydın, 2014; Yang et al., 2018). 
Conversely, the accuracy of ANN’s training process relies on the quality 
and quantity of the sample dataset (Yang et al., 2018). Moreover, the 
optimal  numbers  of  hidden  layers  of  an  ANN  model  depend  on  the 
problem itself and the over-fitting problem can occur at any instance 
(Tiryaki and Aydın, 2014). Therefore, repeated training and testing are 
necessary  to  develop  an  optimal  neural  network  and  attain  highly

HH,σ0

HV 

HH,σ0

HV 

HH,σ0

HV 

0.63 

0.62 

0.63 
0.39 
0.63 
0.40 
0.27 

0.57 
0.57 

0.55 
0.43 
0.56 
0.43 
0.22 
0.69 

0.70 

0.69 
0.49 
0.70 
0.41 
0.40 
0.88 

0.84 

0.84 

0.60 
0.66 
0.51 
0.08 

MSE 

0.15 

0.15 

0.14 
0.23 
0.14 
0.24 
0.26 

1.26 
1.23 

1.17 
1.45 
1.20 
1.40 
1.39 
1.34 

1.34 

1.32 
1.41 
1.32 
1.45 
1.35 
1.30 

1.22 

1.12 

1.01 
1.12 
1.10 
1.12 

AIC 

16.08 

15.91 

15.32 
36.07 
14.28 
34.60 
42.92 
(cid:0) 2.16 
(cid:0) 3.69 
(cid:0) 1.35 
8.30 
(cid:0) 3.12 
7.67 
20.75 
(cid:0) 22.26 
(cid:0) 24.24 
(cid:0) 23.13 
(cid:0) 2.19 
(cid:0) 24.97 
3.00 
4.04 
(cid:0) 8.46 
0.50 
(cid:0) 1.21 
5.07 
(cid:0) 31.88 
1.66 
4.50 

BIC 

24.77 

22.86 

22.27 
43.02 
19.49 
39.81 
48.14 

6.53 
3.27 

5.60 
15.25 
2.09 
12.89 
25.96 
(cid:0) 13.57 
(cid:0) 17.29 
(cid:0) 16.18 
4.76 
(cid:0) 19.76 
8.21 
9.25 
(cid:0) 3.00 
(cid:0) 0.14 
0.12 
(cid:0) 8.99 
18.72 
(cid:0) 0.51 
2.98

HH and σ0

the  loss  function.  Moreover,  as  a  supervised  model,  it  operates  by 
modifying the weights and biases of the network’s neurons in order to 
minimize the gap between the anticipated output and the actual target 
values (Tiryaki and Aydın, 2014). The BP-ANN used here entailed an 
input layer with n co-variates, two hidden layers consisting of p hidden 
neurons, and one output layer having one output neuron. The selection 
of hidden layers and neurons was determined through a process of trial 
and error, aiming to optimize the network’s structure (Supplementary 
material 1). The ‘neuralnet’ package of R 4.1.2 software, mostly applied 
for training multi-layer perceptrons in regression analyses, was consid-
ered here for developing a BP-ANN model (Yang et al., 2018).

For developing a spatially explicit AGBpred model, commonly utilized 
parametric  and  non-parametric  regression  models  were  assessed. 
Hyperparameter tuning was also carried out to ensure the reliability of 
the ANN models. Integration of these massive datasets in the GIS plat-
form had successfully provided a pixel-by-pixel estimation of TBC stock 
down to 1 m depth in the soil. Yet, the BP-ANN model had its short-
comings, due to its complex internal mechanism. Moreover, the lack of 
robust allometric equations for many tropical wetland species prevented 
the use of species-specific AGB prediction models, leading to reliance on 
stand-specific  equations.  Similarly,  BGB  was  estimated  indirectly 
through  generalized  allometric  equations  as  destructive  sampling  of 
underground biomass was thought to be neither ethical nor ecologically 
desirable (Harishma et al., 2020). Regardless of these limitations, the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific details about how the hyperparameters of the Backpropagation Artificial Neural Network (BP-ANN) model were optimized. However, it is mentioned that hyperparameter tuning was carried out to ensure the reliability of the ANN models. This suggests that some form of optimization technique was employed, but the exact method (such as grid search or random search) remains unspecified within the given information.