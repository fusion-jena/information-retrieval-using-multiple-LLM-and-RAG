Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To  evaluate  current  advancements  in  the  field,  we  compared  the 
ResNet network to three newer architectures with either new processing 
blocks  (i.e.  self-attention)  or  improved  parameter  optimisation  and 
modern network design. Even though it is considered the current state of 
the art in image classification, the ViT network failed to improve on the 
results of ResNet. Nonetheless, a different transformer-based approach, 
the  Swin  network,  and  a  ResNet  evolution,  ConvNeXt,  clearly  out-
performed ResNet with around a 5% improvement: 77.18% and 76.20% 
accuracy, respectively.

3.3. Automatic image processing using DL 

In this section we described the methodology we used to integrate DL 
models into our study. As this is the core technology of our automatic 
framework, we also provide detailed explanations on the metrics used to 
evaluate the results of the whole study. 

3.3.1.

Image classification using deep learning

the  experts.  Then  the  network  is  fed  this  annotated  data  and  the  pa-
rameters of the model are adjusted following an optimization process. 
Once this training process is finished, the model is ready to process new 
unseen  data.  DL  networks  are,  thus,  able  to  capture  statistics  and  re-
lationships directly from the data following human expertise. If the data 
used  for  training  the  model  is  representative  of  the  problem  and  the 
annotations are carefully generated, the resulting network can perform 
at a similar level with any input data set. This capacity to translate the 
training to other independent datasets is called the generalization power 
of the network. In practice, differences in performance between the re-
sults with the training data (or data that is similar to it, i.e., from the 
same  site  and  acquired  at  the  same  time)  and  those  of  independent 
datasets (often in research papers referred to as the testing data set) can

1.  ResNet (He et al., 2016): The innovation of this approach supposed a 
breakthrough  for  convolutional  neural  networks  becoming  the 
winner of the ILSVRC challenge in 2015. By introducing the concept 
of residual connections between blocks, the arbitrary limit of stacked 
consecutive blocks caused by problems in the optimisation process 

was  lifted  and  these  connections  virtually  granted  researchers  the 
ability to have an infinite number of parameters and depth. In fact, 
residual  connections  have  become  a  staple  of  DL  and  are  still 
currently used in any modern architecture.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text mentions several types of deep learning models, including ResNet, ViT, Swin, and ConvNeXt. All of these models fall under the category of Convolutional Neural Networks (CNN), except for the Vision Transformer (ViT). However, since the ViT did not improve upon the results of ResNet, it was not chosen for further use in the pipeline. Therefore, the pipeline primarily uses CNN models, specifically ResNet, Swin, and ConvNeXt.