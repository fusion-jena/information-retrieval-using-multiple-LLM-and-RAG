Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

performing other models. Linear and Enet models performed the least,
achieving R2 values of 0.59. Overall, LightGBM performed superior to all
other machine learning models, with a minimal difference in perfor-
mance metrics.

100
5
0.05
20
0.9
0.8
5

linear as a simple statistical model and the rest of the advanced machine
learning models as machine learning. The regression analyses were
conducted using Python 3.12.2, distributed by Anaconda Inc. The Scikit-
learn library (Pedregosa et al., 2011) was employed for all models except
those utilising XGboost and LightGBM. For XGboost and LightGBM
models, the respective Python libraries “xgboost” (Chen and Guestrin,
2016) and “lightgbm” (Ke et al., 2017) were utilised. Additionally, a 5-
fold cross-validation grid search strategy was implemented to tune
hyperparameters within the training dataset for all machine learning
models, leveraging functionalities inherent in their respective Python
packages. The information on hyperparameters and their optimised
value for all machine learning models are presented in Table 4. More-
over, we converted the canopy cover output percentage to a fraction
(0–1) for convenience and smoothness in the further calculation.

Model

Train

Test

Linear Regression
Elastic Net
Support Vector Machine
Random Forest
Extreme Gradient Boosting
Light Gradient Boosting Machine

R2

0.58
0.58
0.66
0.66
0.66
0.69

R2

0.59
0.59
0.63
0.64
0.64
0.64

RMSE

rRMSE (%)

MAE

0.17
0.18
0.17
0.16
0.16
0.16

23.28
23.30
22.26
22.00
21.95
21.92

0.14
0.14
0.12
0.13
0.12
0.12

cover. The interquartile range for observed: Q1 = 65%, Q2 (median) =
86%, and Q3 = 96%, and predicted: Q1 = 63%–69%, Q2 = 83%–87%,
and Q3 = 88% –91%. The minimum and maximum canopy cover for
observed and all the models are 0% and 100%, respectively. Similarly,
the density of the observed and predicted canopy cover is higher in Q3 as
the violin's shape is expanded in those regions.

3.3. Variable importance

tible to overfitting; therefore, it is crucial to address this issue by tuning
the hyperparameters.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit details about the evaluation metrics used specifically for deep learning models. However, it mentions several performance metrics used to assess various machine learning models, including linear and ensemble methods like Random Forest, Extreme Gradient Boosting, and Light Gradient Boosting Machine. These metrics include R^2 (coefficient of determination), Root Mean Square Error (RMSE), Relative Root Mean Square Error (rRMSE), and Mean Absolute Error (MAE).

In summary, based on the given context, the performance metrics used to evaluate the machine learning models are R^2, RMSE, rRMSE, and MAE. It should be noted that these metrics might also apply to deep learning models, but the text does not explicitly confirm this.