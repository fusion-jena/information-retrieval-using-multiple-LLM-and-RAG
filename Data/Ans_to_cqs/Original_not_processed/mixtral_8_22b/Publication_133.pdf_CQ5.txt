Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Machine learning methods are increasingly applied to
biological problems that involve classiﬁcation of images and
extracting information from them. The current leading approach
to such tasks is supervised learning using deep neural networks

1https://www.gbif.org

(DNNs), and particularly convolutional neural networks (CNNs),
which are able to extract abstract high level features from images.
Identifying objects within the image and classifying them may
be treated as separate tasks. Yet, more recent methods, such as
“Faster R-CNN” (Ren et al., 2015), and YOLO (Redmon et al.,
2016) consider both problems at the same time.

Model Training
Deep learning models
iteratively: generating
learn data
predictions of the training set samples, evaluating them by

3https://github.com/ultralytics/yolov5/tree/v4.0
4https://cocodataset.org/#home

the loss function, and modifying their parameters according
to the loss function’s gradient. Thus,
the loss declines in
each training round (aka epoch), and the model’s annotation
accuracy increases (Figure 2 and Supplementary Figure 1).
As the number of parameters of a typical deep learning
model
is large, overﬁtting is a major concern. A common
(partial) remedy is the use of validation data, which are set-
aside while training, yet their annotations by the models are
the training
monitored. The validation data help to limit
duration, thereby reducing the risk of overﬁtting. In this study
we used 30 epochs per training task, based on our validation
runs (Figure 2).
The data of

Deep Learning for Insect Ecoinformatics

images will soon allow many ecological applications that are
now practically impossible. These include early detection of the
arrival of invasive species, disease vectors or crop pests into
new areas; identiﬁcation of insect migration pathways to allow
eﬀective design of ecological corridors; and predicting climate-
change eﬀects by insect densities, activity seasons, body sizes, age
distributions, and sex ratios along climatic gradients.

DATA AVAILABILITY STATEMENT

The trap images and the associated programming code are
available online at http://meshi1.cs.bgu.ac.il/FIE2020_data.

AUTHOR CONTRIBUTIONS

CK, AB-M, AS, and TK conceptualized the project. CK,
AG, and VW developed the deep learning model. AS
sampled the insects and prepared annotated images. CK
and TK wrote the manuscript. All authors reviewed the
manuscript, added their inputs, approved the ﬁnal version

the manuscript, and agreed to be held accountable

of
for its content.

1

May 2021 | Volume 9 | Article 600931

fevo-09-600931

May 17, 2021

Time: 21:42

# 2

Gerovichev et al.

Deep Learning for Insect Ecoinformatics

INTRODUCTION

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific datasets used in the deep learning pipeline. However, it mentions that the data of images is available online at <http://meshi1.cs.bgu.ac.il/FIE2020_data>. Additionally, the paper references two popular object detection frameworks, Faster R-CNN and YOLO, which have been trained on various datasets like COCO (Common Objects in Context) dataset and Pascal VOC dataset. Therefore, it can be inferred that the researchers might have used similar datasets for training their deep learning models. Nevertheless, without further details, we cannot confirm the exact datasets used in their deep learning pipeline.