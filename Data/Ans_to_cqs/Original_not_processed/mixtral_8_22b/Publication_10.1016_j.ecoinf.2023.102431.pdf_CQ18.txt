Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1 
Sample sizes for training, test, and validation groups for discriminant analysis of 
species and sex.   

Species Discrimination 

Fisher Sex Discrimination  

Marten 
Tracks 

Fisher 
Tracks 

Training 
Validation 
Test 
Total 

82 
43 
42 
167 

184 
92 
91 
367 

Individuals 
Total (Male/ 
Female) 

29 (17/12) 
19 (9/10) 
15 (7/8) 
63 (33/30) 

Tracks 
Total (Male/ 
Female) 

169 (72/97) 
99 (55/44) 
99 (50/49) 
367 (177/190)  

EcologicalInformatics79(2024)1024315J.M. Tucker et al.

3.4.1. Fisher and Marten species discrimination 

We found the best model for species discrimination between fisher 
and marten consisted of 12 variables and had near perfect classification 
success, only misclassifying 1 out of 532 tracks as the wrong species. 
However, as this full species discrimination model was so complex, we 
used backward stepwise selection to try to identify an effective model 
with fewer variables. We found a univariable model consisting only of 
variable V16 had a species classification success of over 99% only mis-
classifying  4/532  tracks  as  the  incorrect  species.  Based  on  this  single 
variable a track measurement where V16 > 3.17 has a 90% probability 
of  being  a  fisher.  The  discrimination  line  for  the  simple  species 
discrimination model is given by the Eq. (2): 

Species Discrimination Model : 28.853*V16 = 86.976

(2)

(3) 

Values above this line (>129.29) would classify the track as male and 
below the line as female. We found this simple sex discrimination model 
produced comparable classification accuracy to the more complex full 
model with some slight increase in misclassification for the training and 
validation  sets  (a  difference  of  1â€“2  individual  tracks),  but  a  modest 
improvement in the test set. (Table 3). 

Fig. 4. Illustration of the FIT calculated variables important in species and fisher sex discrimination. These are 6 of the 124 calculated variables (lengths, angles, and 
areas) generated by FIT. White circles numbered 1 to 7 represent the landmark points placed in the approximate center of each track pad in the feature extraction 
process. Fig. A: 5 top predictor variables for both species and sex discrimination, Fig. B: Final 2 variables in the simple model for fisher sex discrimination.

linski and Truex (1995) to develop a discriminant model to distinguish 
sex in marten and fisher which correctly classified 98% of training and 
95% of test data using a model consisting of three measurement vari-
ables including interdigital pad height and width and total track length. 
While both of these methods provide robust outcomes with high levels of 
classification success, they involve a detailed and time-consuming hand 
measurement process for tracks that has prohibited widespread use.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention any specific strategies used to monitor the model performance during training. However, it can be inferred from the information presented that the researchers employed a combination of cross-validation techniques and stepwise variable selection methods to optimize their models.

Cross-validation involves splitting the dataset into multiple subsets, such as training, testing, and validation datasets, to evaluate how well the model generalizes to new, unseen data. This technique helps prevent overfitting and provides a reliable estimate of the model's performance. In this study, the authors have mentioned separate sample sizes for training, validation, and test groups for both species and sex discrimination tasks.

Additionally, the researchers utilized backward stepwise selection to simplify their initial complex model while maintaining high classification accuracy. Stepwise selection is a method for selecting significant variables for inclusion in a regression or classification model. By iteratively removing less influential variables, the researchers aimed to create a simpler yet still accurate model.

Although the text does not directly discuss monitoring strategies like learning curves, early stopping, or regularization techniques, the use of cross-validation and stepwise selection suggests that the researchers were mindful of model performance and sought to minimize overfitting.