Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

to calibrate Deep Learning models using a single parameter for all  classes35. This parameter is used, instead of 
the traditional softmax function, to convert the vector output from the neural network into a real probability.

The proposed post-processing was able to decrease the misclassification rate by at least 10.05%, for all goals, 
and 19.02% at most compared to the raw output of the Deep Learning model (Fig. 6b). The accuracy followed the 
same tendency, with an average accuracy for G1, G2 and G3 respectively equal to 0.74, 0.81 and 0.92 (Table 3).
Finally, we also performed the same experiment while switching T1 and T2 roles (Supplementary Tables S6, 
S7, S8). For each goal, the unsure classification rate was higher after the switch (+ 3.8% for G1, + 4.4% for G2, 
and + 8.9% for G3), implying lower scores were obtained in both correct classification (− 3.5%, − 5%, − 7.3%) and 
misclassification, with the exception of the 2nd goal (-0.2%, + 0.6%, − 1.6%).

training datasets.

•  In the first phase, a classification model is built by training a CNN on a given database T0 (Fig. 2a)
•  Then, the second phase consists of tuning a risk threshold τi specific to each class (i.e. each species in our 

case), noted i, with i ∈ {1, ..., n} , using a second and independent database noted T1 (Fig. 2b).

In terms of classification, it means we transform the 2 classification options (correct, wrong) in 3 options 

(Fig. 3) by applying Eqs. (15, 16).

Computing the confidence thresholds.  After the phase 1 (model training phase), for an image X of the 
threshold tuning dataset processed by the classifier, we obtain an output {C(X), S(X)} , where C(X) is the class 
(i.e. species, belonging to the trained set of species) with the highest classification score S(X). For this image, we 
know the ground truth Y in {1, .., n} belonging to the same set of species classes.

Building  the  convolutional  neural  network.  Convolutional  neural  networks  (CNNs)  belong  to  the 
class  of  DLAs.  For  the  case  of  species  identification,  the  training  phase  is  supervised,  which  means  that  the 
classes  to  identify  are  pre-defined  by  human  experts  while  the  parameters  of  the  classifier  are  automatically 
optimized  in  order  to  accurately  classify  a  “training”   database24.  CNNs  are  composed  of  neurons,  which  are 
organized in layers. Each neuron of a layer computes an operation on the input data and transfers the extracted 
information to the neurons of the next layer. The specificity of CNNs is to build a descriptor for the input image 
data and the classifier at the same time, ensuring they are both optimized for each  other42. The neurons extract-
ing the characteristics from the input data in order to build the descriptors are called convolutional neurons, as

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, there isn't explicit information about any preprocessing steps taken before training the deep learning model. However, generally speaking, common preprocessing steps include normalization, scaling, cleaning, and augmentation. Normalization scales the values to a smaller range, often between 0 and 1, to prevent large values from dominating the algorithm. Scaling rescales the features so that they have the same scale, preventing those with larger ranges from being weighted more heavily during training. Cleaning involves removing or handling missing or inconsistent data points. Data augmentation generates new samples by applying random transformations to existing ones, helping improve the model's ability to generalize.