Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

19. Atkinson, P.M., Tatnall, A.R.L.: Introduction neural networks in remote sensing.

Int. J. Remote Sens. 18(4), 699–709 (1997)

20. Schmidhuber, J.: Deep learning in neural networks: an overview. Neural Netw. 61,

85–117 (2015)

21. Lecun, Y., Bottou, L., Bengio, Y., et al.: Gradient-based learning applied to doc-

ument recognition. Proc. IEEE 86(11), 2278–2324 (1998)

22. Szegedy, C., Liu, W., Jia, Y.: Going deeper with convolutions. In: Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–9 (2015)
23. Joly, A., et al.: LifeCLEF 2015: multimedia life species identiﬁcation challenges.
In: Mothe, J., Savoy, J., Kamps, J., Pinel-Sauvagnat, K., Jones, G.J.F., SanJuan,
E., Cappellato, L., Ferro, N. (eds.) CLEF 2015. LNCS, vol. 9283, pp. 462–483.
Springer, Heidelberg (2015). doi:10.1007/978-3-319-24027-5 46

When we apply the Deep Learning method directly on test thumbnails, which
consists in recognizing if a thumbnail belong to a class, we reach a F-score of
98 %. We believe that the results can not really be improved as long as we
keep the same network architecture. According to this, we focused our work on
the post and pre-processing. The reduction of performance on a frame, in most
case, comes from ﬁshes which overlap or occlude and from confusion with the
background. We tried to improve the method by adding three more classes and
also through the use of a well chosen overlap decision.

170

S. Villon et al.

At the moment, the Deep Learning method gives quite good results. A pos-
sible way to treat errors is to integrate the temporal aspect in a more advanced
way by implementing a ﬁsh tracking algorithm.

Deep Learning. The architecture of our network follows the GoogLeNet’s
with 27 layers, 9 inception layers, and a soft-max classiﬁer. Once we have a list
of cropped thumbnails and their labels, we send them to our network. We use
inception layers (Fig. 4) based on GoogLeNet architecture [22]. The inceptions
here allows us to reduce the dimension of the picture to one pixel, and therefore
not to be dependent of the dimensional impact. We adapted some parameters
such as the size of the strides and the ﬁrst convolutions adapted to the size of our
thumbnails, which allowed us to achieve better results than a classic architecture
(e.g. [18]).

3.3 Post-processing and Bounding Box Fusion

For each sliding window, we deﬁne a motion score by computing the average
absolute diﬀerence with the window at the same position in the previous frame.
Based on the hypothesis that most of the ﬁshes are moving, we use this score
for the ﬁnal detection decision.

4 The overlap ratio is deﬁned as OA = IS/U S with IS the intersection surface and

US the union surface.

168

S. Villon et al.

Fig. 6. ROC Curves of the Deep Learning method on the four test videos, with the
threshold T as parameter. (Color ﬁgure online)

Table 3. Results with the Deep Learning method (T = 98 %)

Video Precision Recall F-measure

1655

1654

1547

1546

0.58

0.68

0.77

0.60

0.69

0.63

0.64

0.52

0.62

0.65

0.70

0.55

Table 4. F-measure of the two methods with the same parameter

Video F-measure from HOG+SVM F-measure Deep Learning

1655

1654

1547

1546

0.28

0.24

0.49

0.14

0.62

0.65

0.64

0.55

than the CNN’s. Indeed, the F-measure of the HOG+SVM is always below 49 %
whereas it is always above 55 % for the CNN.

As we can observe in Fig. 7, the Deep Learning method approach eﬃciently
recognizes ﬁshes on diﬀerent resolutions even when there is a strongly textured
background and is able to distinguishes ﬁshes which are close.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model is evaluated using several metrics such as precision, recall, and F-measure. The paper mentions that the deep learning method achieves a high F-score of 98%. Additionally, Table 3 presents the precision, recall, and F-measure values obtained for different test videos using the deep learning method with a threshold value of T=98%. Furthermore, Table 4 compares the F-measures of the deep learning method and another method called HOG+SVM, showing that the deep learning method consistently outperforms the other method across all test videos.