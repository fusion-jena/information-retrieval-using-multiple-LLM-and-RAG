Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

MARHH_NO_C 

MHH_CHILD 
FHH_CHILD 

FAMILIES 
AVE_FAM_SZ 
HSE_UNITS 
URBAN 
RURAL 
VACANT 
OWNER_OCC 
RENTER_OCC 
POP_MILE 
HH_INCOME_ 
HH_10K 
HH10TO15K 
HH15TO20K 
HH20TO25K 
HH25TO30K 
HH30TO35K 
HH35TO40K 
HH40TO45K 
HH45TO50K 
HH50TO60K 
HH60TO75K 
HH75TO100K 
HH100_125K 
HH125_150K 
HH150_200K 
HH_200K 
HHMEDIAN 
PER_CAPITA 
Polygon area  

x-coordinate  
y-coordinate  

Total number of people in the census block in year 
2000 
Total number of people who are white alone 

Total number of people who are black alone 

Total number of people who are Native American 
alone 
Total number of people who are Asian alone 

Total number of people who are Hawaian Pacific 
Island alone 
Total number of people who are ‘other’ alone 

Number of Multirace Individuals in census unit 

Total number of people who are Hispanic alone

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Short-billed (common/mew) Gull Larus canus 
Geographic information system (GIS) 
Open access data 
Big data 
Socio-economics 
Multi-year field work 
Machine learning ensemble predictions 
(RandomForest Treenet CART MARS)

Distance to Railway 

Vegetation name 

Soil type 
US Census 2000 (60 

attributes) 

Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Forest Layer Tanana Valley 
State Forest  
Alaska Clearing house  
Alaska US Census portal 

Value-added map 
product by FH 
Value-added map 
product by FH 
Value-added map 
product by FH 
Value-added map 
product by FH 
Value-added map 
product by FH 

See Table 2 for details  

2.3. Machine learning ensembles

Put Fig. 4 app here: Predicted RIO for Short-billed Gulls based on a 

machine learning ensemble. 

Put Fig. 5 app here: Time series data for a ‘presence site’ in Fairbanks 
during summer 2017 that is a raven hotspot for the ecological niche in 
winter. 

Put  Table  3  app  here:  Model  Diagnostics  importance  rank  of  pre-

dictors from machine learning model. 

Put Fig. 6 app here: Model Diagnostics Partial Dependence plot of 

first top-ranked Predictor (soil type). 

Put Fig. 7 app here: Model Diagnostics Partial Dependence plot of 

second top-ranked Predictor (vegetation class). 

Put Fig. 8 app here: Model Diagnostics Partial Dependence plot of 

third top-ranked Predictor (distance to water). 

Put Fig. 9 app here: Model Diagnostics 3D Partial Dependence plot of 
top-ranked  continuous  predictor  (distance  to  water  vs  distance  to 
transfer site). 

3.3. Model assessment

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about how the data was split for deep learning model training into categories such as train, test, and validation sets. However, it mentions using machine learning ensembles and provides several figures related to model diagnostics, which suggests that some form of splitting or cross-validation may have been employed during the modeling process. Common practices include randomly dividing the dataset into training, testing, and validation subsets, with typical ratios being around 70%, 15%, and 15%, respectively. Another approach could be k-fold cross-validation, where the original sample is randomly partitioned into k equal sized subsamples. Of these k subsamples, one subsample is retained as the validation data for testing the model, while the remaining k−1 subsamples are used as training data. This process is repeated k times, with each of the k subsamples used exactly once as the validation data. The results from all k trials are then averaged to produce a single estimation. Without further specifications, we cannot determine the exact methodology used for this study.