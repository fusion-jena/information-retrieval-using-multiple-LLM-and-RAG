Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

ResNet50 
VGG16 
InceptionV3 
MobileNetV2 
DenseNet121 
NASNetMobile 
Xception 
EfficientNetB0 
ResNeXt50 
InceptionResNetV2 
Proposed Approach 

23,534,592 
14,714,688 
23,583,872 
3,538,304 
8,062,464 
4,939,648 
22,910,480 
5,330,571 
25,028,032 
55,873,736 
2,86,348 

2,56,000 
2,257,984 
14,714,688 
2,257,088 
21,802,784 
2,727,160 
2,283,084 
404,956 
2,48,523 
2,85,245 
640  

Table 9 
Performance  comparison  of  the  proposed  HPB3C-3PGA-based  approach  with 
existing transfer learning approaches.  

Model 

Dataset 

Accuracy 

Precision 

Recall 

VGG16 

Inception V3 

MobileNet V2 

ResNet 50 

DenseNet 121 

Xception 

PCA Based VGG16 

Proposed 

Approach 

Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 

76.00% 
78.80% 
82.50% 
85.20% 
87.92% 
90.52% 
88.00% 
92.80% 
88.00% 
92.72% 
88.26% 
90.56% 
95.25% 
96.28% 
98.96% 
98.97%

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ImageNet classification with deep 

convolutional neural networks. Commun. ACM 60, 84–90. https://doi.org/10.1145/ 
3065386. 

Kumar, S., Singh, A., Walia, S., 2018. parallel big bang–big crunch global optimization 
algorithm: performance and its applications to routing in WMNs. Wirel. Pers. 
Commun. 100, 1601–1618. https://doi.org/10.1007/s11277-018-5656-y. 

EcologicalInformatics81(2024)10258115S. Ghosh et al.                                                                                                                                                                                                                                   

Liu, Z., Reynolds, A.C., 2020. A sequential-quadratic-programming-filter algorithm with 
a modified stochastic gradient for robust life-cycle optimization problems with 
nonlinear state constraints. SPE J. 25, 1938–1963. https://doi.org/10.2118/193925- 
pa.

71.17% 

98.7% 

Ganguly et al., 2022b) 

DDYOLOv5 and ResNet-50 (Hu et al., 

Pine tree classification 

98.71% 

2022) 

Deep Attention Dense CNN model ( 

Pandey and Jain, 2022b) 

Dense convolutional neural networks 

Plant leaf disease 
classification 
Plant disease classification 

97.33% 

99.1% 

() 

Proposed Approach 

Plant leaf classification 

98.97  

6.1.2. CVIP100 dataset

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The information provided does not include details about which platform was used to deploy the deep learning models mentioned in the paper. Therefore, it is not possible to determine from this context alone whether platforms such as AWS, Azure, or Google Cloud were utilized for deployment.