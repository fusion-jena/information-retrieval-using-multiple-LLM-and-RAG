Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

query set are negative. Liu et al. (Liu et al., 2019) propose transductive
propagation that iteratively propagates labels from labelled instances to
unlabelled instances according to the graph structure of the embeddings.
Other semi-supervised learning techniques have been applied such as
active learning. Wang et al. (Wang et al., 2022) combines a few-shot

Fig. 2. Raw field data are segmented into 5-s spectrograms. A pre-trained feature extraction generates 527-dimensional embedding vectors for each segment.
Coloured vectors denote embeddings that were previously labelled.

EcologicalInformatics82(2024)1027344B. McEwen et al.

Fig. 3. Transfer learning using pre-trained feature extraction model and fully connected layers with adjustable output nodes.

Fig. 4. Prototypical learning provides a class probability distribution that a query belongs to each class. The probability distribution is used to rank the priority of
samples. The colours denote the class distributions in a simplified 2-dimensional view.

∑

x∈Sd

fθ(x)

3.4. Active learning

(1)

A recommender system, Fig. 4, ranks segment embeddings in order
of lowest certainty to highest certainty. Low-certainty embeddings
correspond to features on decision boundaries. The Euclidean distance ld
is computed between existing prototypes cd and the query embeddings q
providing both class suggestion and class probability using P(q ∈ d | ld)
= softmax(1 (cid:0) norm(ld)). The recommender ranks queries in terms of

This methodology has been implemented into the Listening Lab
Annotator Tool (McEwen et al., 2023b), shown in Fig. 5. The following
section demonstrates the functionality of the annotator and methodol-
ogy workflow.

EcologicalInformatics82(2024)1027346or mel-frequency cepstral coefficients (MFCC) can be represented as a
single-channel images. We evaluate a commonly applied pre-trained
ResNet-50 architecture (He et al., 2016). Dufourq et al. (Dufourq
et al., 2022) also demonstrates strong classification performance and
low data requirements of ResNet-50 when comparing alternative pre-
trained CNN-based models. With the rapid development of transformer-
based models we also evaluate two transformer models Audio Spectro-
gram Transformer (AST) (Gong et al., 2021) which, like ResNet, oper-
ates on the spectrogram. We also evaluate HuBERT (Hsu et al., 2021)
which operates directly on the 1-D waveform. We evaluate the models
using the same feature extractor fθ and user model Uϕ pipeline presented
in Fig. 1 using a two-class binary output. Hence Uϕ is a two layer {100,2}
fully connected network.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the data repository link of the deep learning pipeline. Therefore, I cannot provide an accurate answer to this query based on the available context.