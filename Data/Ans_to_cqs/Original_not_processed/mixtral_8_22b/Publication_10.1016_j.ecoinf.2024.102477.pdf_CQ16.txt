Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

regularization parameter used to control model complexity and prevent 
overfitting  by  constraining  the  loss  function  during  training.  The 
parameter ε  controls the model's fault tolerance, that is, the degree of 
tolerance for differences between predicted and actual values of training 
samples. The term σ represents a parameter of a Gaussian kernel or the 
width parameter of a radial basis function kernel. This parameter con-
trols the relationship between support vectors and hyperplanes and af-
fects model complexity and generalization ability. SVR is formulated as 
follows: 

f (x) = ωT φ(x) + b

R =

1
2

‖ω‖2 + C

)

ξi + ξ*
i

∑N
(cid:0)

i=1

(5)  

(6)  

where ω is a weight vector, φ(x), b is a bias term, C is the regularization 
constant, and ξi and ξ*
i  are slack variables that quantify how far data can 
exist from the ε tube. 

3.4. Deep learning 

3.4.1. SLSTM method

Skarlatos, K., Bekri, E.S., Georgakellos, D., Economou, P., Bersimis, S., 2023. Projecting 
annual rainfall timeseries using machine learning techniques. Energies 16, 1459. 
Sun, Z., Yuan, Y., Dong, X., Liu, Z., Cai, K., Cheng, W., Wu, J., Qiao, Z., Chen, A., 2023. 
Supervised machine learning: a new method to predict the outcomes following 
exercise intervention in children with autism spectrum disorder. Int. J. Clin. Health 
Psychol. 23, 100409. 

Supranto, J., 2000. Statistics: Theory and Applications, 6nd. Erlangga, Jakarta.  
Syafei, A.D., Ramadhan, N., Hermana, J., Slamet, A., Boedisantoso, R., Assomadi, A.F., 
2018. Application of exponential smoothing Holt winter and ARIMA models for 
predicting air pollutant concentrations. EnvironmentAsia 11. 

Vapnik, V., Golowich, S.E., Smola, A.J., 1997. Support vector method for function 

approximation, regression estimation and signal processing. Adv. Neural Inf. Proces. 
Syst. 281–287.

SVR is a machine learning method known for its superior accuracy 
compared  with  other  machine  learning  methods  and  its  ability  to 
simplify parameters, achieve global optimization, and handle nonlinear 
problems  (Chen  et  al., 2017;  Ji et  al.,  2021). In  this  study, the  expo-
(cid:0) 8–21,  σ  =
nential  parameters  were  set  as  follows:  C  = 20–210,  ε  = 2
(cid:0) 8–21 (Yang et al., 2022). Table 2 presents the training results for the 
2
hyperparameter-optimized  SVR  model.  Parameter  C  controls  error 
tolerance during training and determines the maximum deviation that 
the model permits for any individual training example. A higher C value 
allows for a larger error, which makes the model more likely to fit the 
training  data  but  also  increases  the  risk  of  overfitting.  Conversely,  a 
smaller  C  value  imposes  stricter  constraints  on  the  model,  thereby 
increasing  the  difficultly  of  fitting  the  training  data  but  potentially

Oper. Res. 9, 673–685. 

Chen, J., Chen, H., Huo, Y., Gao, W., 2017. Application of SVR models in stock index 
forecast based on different parameter search methods. Open J. Stat. 7, 194. 

Chen, J., Jing, H., Chang, Y., Liu, Q., 2019. Gated recurrent unit based recurrent neural 
network for remaining useful life prediction of nonlinear deterioration process. 
Reliab. Eng. Syst. Saf. 185, 372–382. 

Chen, J., Chen, K., Ding, C., Wang, G., Liu, Q., Liu, X., 2020. An adaptive Kalman filtering 

approach to sensing and predicting air quality index values. IEEE Access 8, 
4265–4272. 

Chen, H., Zhang, Y., Cao, Y., Xie, J., 2021. Security issues and defensive approaches in 

deep learning frameworks. Tsinghua Sci. Technol. 26, 894–905. 

Choi, K., Yi, J., Park, C., Yoon, S., 2021. Deep learning for anomaly detection in time- 
series data: review, analysis, and guidelines. IEEE Access 9, 120043–120065.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The completion of training in machine learning models like SVR (Support Vector Regression) depends on various factors such as the convergence of the algorithm, the performance on validation sets, and the desired level of accuracy. However, there isn't a specific criterion mentioned in the given context regarding when training should be considered complete.

In general, some common criteria used to determine when training is complete include:

1. Validation Loss Plateau: When the validation loss stops decreasing significantly and remains relatively constant, it may indicate that further training will not improve the model's performance. At this point, training could be stopped to avoid overfitting.

2. Maximum Number of Iterations/Epochs: Training can be stopped after reaching a predefined number of iterations or epochs. This approach assumes that the model has learned enough patterns within the specified limit.

3. Early Stopping: Based on monitoring the validation loss, if the loss does not decrease for a certain number of consecutive iterations, training can be halted. This helps prevent overfitting and saves computational resources.

4. Desired Level of Accuracy: Training can be stopped once the model achieves a satisfactory level of accuracy on the validation dataset. This requires setting a target accuracy beforehand.

However, these criteria might vary depending on the specific problem, available resources, and the chosen machine learning technique. For instance, in the case of SVR, the regularization parameter 'C' plays a crucial role in controlling the trade-off between minimizing errors and maximizing margins. Therefore, tuning this parameter appropriately would impact the decision about when to stop training.