Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

References 

Abu, A., Diamant, R., 2022. Feature set for classification of man-made underwater 

objects in optical and sas data. IEEE Sensors J. 22 (6), 6027–6041. http://dx.doi.org/ 
10.1109/JSEN.2022.3148530. 

Bibby, C., Jones, M., Marsden, S., 1998. Expedition Field Techniques: Bird Surveys. Royal 

Geographical Society, London.  

Çalıs¸kan, A., 2023. Detecting human activity types from 3d posture data using deep 
learning models. Biomed. Signal Process. Control 81, 104479. http://dx.doi.org/ 
10.1016/j.bspc.2022.104479. 

Clements, N., Robinson, W., 2022. A re-survey of winter bird communities in the Oregon 
coast range, USA, initially surveyed in 1968-1970. Biodiers. Data J. http://dx.doi. 
org/10.3897/arphapreprints.e91575. Aug.  

Davis, K.L., Silverman, E.D., Sussman, A.L., Wilson, R.R., Zipkin, E.F., 2022. Errors in 

aerial survey count data: identifying pitfalls and solutions. Ecol. Evol. 12 (3), e8733 
http://dx.doi.org/10.1002/ece3.8733.

0.982 

0.927 

0.96 

Sp 

0.997 

0.987 

0.994 

0.95 

example 

Fig. 16b 

Fig. 12b 

Fig. 14b 

Fig. 13b  

Table 10 
Detailed confusion matrix of the classifiers outlined in Table 11.    

A. Test Results (UCLAN) 

B. Evaluation (UCLAN) 

Actual Class  

Actual Class  

C. Validation (APEM)   

Actual Class    

Positive 

Negative 

% 

Positive 

Negative 

% 

Positive 

Negative 

% 

Pred 

Positive 
Negative 
% 

140 (TP) 
5 (FN) 
0.9655 (Se) 

3 (FP) 
4997 (TN) 
0.9994 (Sp) 

0.9790 (PPV) 
0.9990 (NPV) 
0.9984 (ACC) 

55 (TP) 
2 (FN) 
0.9649 (Se) 

2 (FP) 
4998 (TN) 
0.9996 (Sp) 

0.9649 (PPV) 
0.9996 (NPV) 
0.9992 (ACC) 

9 (TP) 
0 (FN) 
1 (Se) 

0 (FP) 
50 (TN) 
1 (Sp) 

1 (PPV) 
1 (NPV)  
1 (ACC)  

Table 11 
Test, evaluation and validation results in summary detailed in Table 10.  

Phase 

Positive 

Negative 

TP 

FN 

TN 

FP 

Se 

SP 

PPV 

NPV 

ACC 

Location 

Check 

Test 
Evaluation 
Validation 
Verification 

145 
57 
9 
211 

5000 
5000 
50 
10,050

145 
57 
9 
211 

5000 
5000 
50 
10,050 

140 
55 
9 
204 

5 
2 
0 
7 

4997 
4998 
50 
10,045 

3 
2 
0 
5 

0.966 
0.965 
1 
0.977 

0.997 
0.999 
1 
0.9987 

0.9790 
0.9649 
1 
0.9813 

0.9990 
0.9996 
1 
0.9995 

0.9984 
0.9992 
1 
0.9992 

UCLAN 
UCLAN 
APEM 
Average 

✓ 
✓✓ 
✓✓✓ 
✓✓✓✓

EcologicalInformatics78(2023)10228514K. Kuru et al.                                                                                                                                                                                                                                    

Table 3 
Main statistical terms and calculations used throughout the paper.  

# 

1 
2 
3 
4 
5 
6 

7 

8 

9 

10 
11 

12 
13 
14 

Abbreviation 

Description 

Detail 

P 
N 
TP 
TN 
FP 
FN 

Se 

Sp 

PPV 

NPV 
ACC 

MCC 
μ 
σ 

Positive 
Negative 
True Positive 
True Negative 
False Positive (False Alarm) 
False Negative 

Sensitivity 

Specificity 

Positive Predictive Value 

Negative Predictive Value 
Accuracy 

Matthews Correlation Coefficient 
Mean 
Standard deviation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The main statistical terms and calculations used to evaluate the performance of the deep learning model include sensitivity (Se), specificity (Sp), positive predictive value (PPV), negative predictive value (NPV), accuracy (ACC), Matthews correlation coefficient (MCC), mean (μ), and standard deviation (σ). These metrics are described in detail in Table 3 of the given context.

Sensitivity measures the proportion of actual positives that are correctly identified by the model. Specificity measures the proportion of actual negatives that are correctly identified by the model. PPV is the probability that a subject with a positive test result actually has the condition. NPV is the probability that a subject with a negative test result does not have the condition. Accuracy is the proportion of true results (both true positives and true negatives) among the total number of cases examined. MCC is a measure of the quality of binary classifications. It takes into account true and false positives and negatives, and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. Mean and standard deviation are used to summarize the distribution of values in a dataset.