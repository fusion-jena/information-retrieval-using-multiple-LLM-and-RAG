Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

1)  We  trained  a  classic  DL  algorithms  architecture  with  our  biggest 

dataset AT0 as a baseline for the DL accuracy;  

2)  We  trained  the  same  DL  architecture  with  the  same  hyper- 
parameters (e.g. model architecture and training process) but on a 
much  more  limited  dataset  (AT1).  Hyper-parameters  are  the  pa-
rameters  defining  the  architecture (number of  layers, number and 
size of convolutions, connections between layers) and the training 
process  of  a  Deep  Model  (learning  rate,  neurone  activation,  back- 
propagation compotation).;  

3)  We trained the same DL architecture with limited datasets obtained 
by  subsampling  T0  to  250  and  500  images  per  class  (here  after 
“species” when we are referring to our experiments), corresponding 
to 2500 and 5000 thumbnails in AT0;

We used ResNet 100 (He et al., 2016) as our classic deep-learning 
algorithm.  Resnet  is  a  convolutional  neural  network  (CNN),  a  DL  ar-
chitecture which is able to both extract features from images and classify 
these images thanks to those features (Lecun et al., 2015). In order for a 
CNN  to  build  an  image  classification  model,  the  architecture  is  fed  a 
large dataset, composed of pairs of labels and images. Using this dataset, 
the algorithms change their inner parameters in order to minimize the 
classification  error,  through  a  process  called  back-propagation.  The 
ResNet architecture achieved the best results on ImageNet Large Scale 
Visual Recognition Competition (ILSVRC (Russakovsky et al., 2015)) in 
2015, considered the most challenging image classification competition. 
It is still one of the best classification algorithms, while being easy to use 
and implement.

a new task with a very limited dataset, usually only 1–5 thumbnails per 
class.

Thus, there is a trade-off to make between accuracy and robustness 
on one hand, and the cost of video annotation by experts on the other. 
Modelling the accuracy of neural networks using NLME allowed to 
understand the number of images per species required for the Few-shot 
and Deep architecture to reach 99% of their maximum potential accu-
racy. In our case study, there was a 150-fold factor between the average 
number of images required for a Deep Learning architecture (1153 im-
ages) and for a Few-shot architecture (7) to reach asymptotic accuracy. 
However,  it  is  important  to  note  that  these  numbers  could  vary  ac-
cording  to  the  number  and  complexity  of  classes  fed  to  the  deep 
classifier.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention which specific framework or library was used to build the deep learning model. However, since they mentioned using ResNet 100 (He et al., 2016), it can be assumed that popular deep learning libraries such as TensorFlow or PyTorch were likely used due to their wide adoption and support for pretrained models like ResNet. Nonetheless, without explicit information about the framework used, it cannot be definitively stated whether TensorFlow, PyTorch, or another framework was utilized.