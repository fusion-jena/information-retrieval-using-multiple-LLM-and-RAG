Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Figure 10. Comparison of accuracies of different classiﬁers for all datasets.

Big Data Cogn. Comput. 2021, 5, 53

11 of 15

Table 2. Performance of hand-crafted descriptors and D-CNN models for ﬁrst dataset.

Technique’s
Name

SVM
Kernel

LBP [10]
HOG [11]
LETRIST [12]
GLCM [13]
GLCM [13]
CJLBP [14]
LTrP [15]
AlexNet [17]
ResNet-50 [18]
VGG-19 [19]
GoogleNet [20]
Inceptionv3 [21]
CoralNet
BoF

Polynomial
Linear
Linear
RBF
Polynomial
Linear
Linear
Linear
Linear
Linear
Linear
Linear
–
Linear

Sensitivity

Speciﬁcity Accuracy

F1-Score

Cohen’s
Kappa (κ)

70.1%
66.3%
56.2%
66.2%
73.1%
71.2%
48.4%
94.1%
92.2%
92.1%
85.1%
77.1%
92.1%
99.1%

75.9%
69.3%
59.7%
75.1%
80.4%
77.3%
50.2%
96.3%
96.4%
92.1%
93.1%
92.3%
97.3%
99.0%

71.8%
67.1%
56.6%
69.3%
76.7%
72.7%
49.1%
95.2%
94.5%
92.2%
88.2%
83.3%
95.0%
99.08%

0.729
0.678
0.579
0.704
0.766
0.741
0.493
0.952
0.942
0.921
0.889
0.840
0.950
0.995

0.731
0.663
0.594
0.732
0.751
0.743
0.524
0.966
0.952
0.851
0.873
0.862
0.962
0.982

SVM ClassifierLinear KernelBleached or unbleached coral12345678910abbbb12345678910Input ImageConvolutional Layer 1Convolutional Layer 2Convolutional Layer 3Convolutional Layer 4Convolutional Layer 5Fully Connected Layer 6 Fully Connected Layer 7ClassifierOutputDescriptionStride sizeab4 x 41 x 1227 x 227 x 355 x 55 x 9627 x 27 x 25613 x 13 x 38413 x 13 x 38413 x 13 x 25640964096Big Data Cogn. Comput. 2021, 5, 53

7 of 15

Algorithm 1: k-means Clustering Algorithm.

Input: Features as data points
Let features F = {F1, F2, F2, ..., Fn} is set of data points and C = {C1, C2, C3, ..., Co}
is set of centers.

Table 4. Performance of hand-crafted descriptors and D-CNN models for third dataset (Bleached,
healthy, and dead (BHD) Dataset).

Technique’s
Name

LBP [10]
HOG [11]
LETRIST [12]
GLCM [13]
CJLBP [14]
LTrP [15]
AlexNet [17]
ResNet-50 [18]
VGG-19 [19]
GoogleNet [20]
Inceptionv3 [21]
CoralNet
BoF

Classiﬁer Sensitivity

Speciﬁcity

Accuracy

F1-Score

Cohen’s
Kappa (κ)

SVM
SVM
SVM
SVM
SVM
SVM
SVM
SVM
SVM
SVM
SVM
–
SVM

69.3%
74.42%
55.3%
65.2%
70.2%
47.4%
86.37%
85.43%
82.1%
80.55%
81.10%
91.1%
98.1%

71.4%
60.05%
58.5%
74.1%
76.3%
49.2%
83.73%
85.80%
82.1%
80.51%
76.44%
96.3%
98.0%

69.8%
75.2%
55.4%
68.3%
71.7%
48.1%
92.20%
92.60%
82.2%
88.60%
86.30%
94.0%
98.11%

0.689
0.665
0.569
0.694
0.731
0.483
0.850
0.856
0.821
0.805
0.787
0.940
0.985

0.691
0.621
0.584
0.722
0.733
0.514
0.826
0.852
0.781
0.803
0.761
0.952
0.972

Big Data Cogn. Comput. 2021, 5, 53

12 of 15

Figure 11. Confusion matrices of binary class and multi-class datasets.

3.2.3. Custom D-CNN: CoralNet

We create a custom D-CNN named as CoralNet for the extraction of the spatial features.
CoralNet has thirteen layers in which three layers are convolutional layers (Conv2D), two
max-pooling (MaxPooling2D) layers, two dense layers, one ﬂatten layer, three activation
layers. The input layer size is kept at 227 × 227 × 3. Two activation layers have rectiﬁed
linear unit (ReLU) as activation function while the last activation layer uses softmax as
activation function. Features are extracted with Conv2D layers and the feature vector is
extracted at the last layer. The training options used for training CoralNet are summarized
in Table 1. The simpliﬁed architecture of the CoralNet is shown in Figure 6.

Big Data Cogn. Comput. 2021, 5, 53

6 of 15

Figure 5. Feature Extraction with AlexNet.

Table 1. Training Parameters of CoralNet.

Parameter

Optimizer
Epochs
Batch Size
Loss Function

Value

Adam
10
64
Cross Entropy

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper mentions that the optimizer used for training the custom D-CNN model called CoralNet is Adam. This information can be found in Table 1, where it lists the parameter values used for training CoralNet. In this table, under the 'Optimizer' column, it states that Adam was used as the optimizer. Therefore, we can conclude that Adam is the optimization technique applied in the deep learning pipeline for this particular study.