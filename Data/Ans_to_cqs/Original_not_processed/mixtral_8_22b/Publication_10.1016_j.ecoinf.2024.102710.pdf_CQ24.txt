Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The active learning experiments are carried out in the embedding
space of the selected transfer learning model (BirdNet-1, see Section
3.1). We explore a range of sampling strategies: uncertainty and di-
versity based, myopic (greedy) and adaptive (batch mode), and com-
binations thereof. Fig. 2 provides a schematic overview of the pure
families of sampling strategies: Random sampling selects samples arbi-
trarily, uncertainty sampling targets samples near the decision bound-
ary, and diversity sampling focuses on samples that span the entire data
space. In all cases, 5% of the samples are selected at random. Class labels
are available for all samples used in this study, and an active learning
scenario is emulated by hiding all labels from the classifier at first and
incrementally revealing the ones for each batch of samples queried by
the sampling methods. We use a batch size of 20 samples. The classifier
heads are identical to those from the transfer learning training process.

Combined sampling strategies address the limitations of pure
strategies. Uncertainty sampling selects samples close to the decision
boundaries, but may introduce redundancy. Diversity sampling covers
the entire input space, but may miss critical regions. We therefore

Fig. 2. Schematic representation of the random, uncertainty, and diversity
sampling strategies. Random sampling selects arbitrary samples. Uncertainty
sampling selects samples based on their proximity to the model's decision
boundary, calculated using the existing class 1 and class 2 labels. Diversity
sampling uses the internal data structure for sampling purposes, such as clus-
tering the data and selecting samples from each cluster.

Fig. 3. Uncertainty scores for binary inputs computed with the methods ‘ratio’
(ΦRC bi), ‘least confidence’ (ΦLC bi) and ‘entropy’ (ΦEN bi), given a model pre-
diction y.

EcologicalInformatics82(2024)1027104computed on the held-out evaluation sets described in section 2.1.

both the target modality and the domain, yields the best performance as
a feature embedding model. Using BirdNet-1 as the embedding model,
active learning sample selection strategies significantly reduce the
required for annotation to achieve model
number of
convergence.

Due to the significant imbalance of classes in the datasets, we used
the macro F1 score as the evaluation metric, and provide the corre-
sponding macro precision and macro recall values in appendix A. As a
baseline for active learning, all figures show the performance of random
sampling.

We investigate the uncertainty sampling strategies ‘least confidence’,
‘ratio’ and ‘entropy’ with the score aggregation methods ‘max’ and

Fig. 5. Transfer learning applied to AnuraSet using features extracted from the
last layer before the classification layer of BirdNet. A linear classifier (logistic
regression) is used. The resulting F1 score for each species is plotted against the
number of samples containing that species. Frequent, common and rare species
are defined according to (Ca˜nas et al., 2023).

learning results of the BirdNet-1 embedding, we use this embedding as
the feature extractor for all subsequent active learning experiments.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided context, it appears that the focus is primarily on exploring various sampling strategies for active learning experiments conducted within the embedding space of a specific transfer learning model called BirdNet-1. These strategies include uncertainty and diversity-based sampling, myopic (greedy) and adaptive (batch mode), and combinations thereof. However, none of these strategies directly addresses handling randomness in the deep learning pipeline, such as managing the impact of different random seed values.

Random sampling is mentioned as one of the pure families of sampling strategies, where 5% of the samples are selected randomly. This could be seen as a way to incorporate some level of randomness into the process. Additionally, the context mentions that class labels are initially hidden from the classifier and incrementally revealed for each batch of samples queried by the sampling methods. This might also contribute to introducing some degree of randomness or variability into the system.

However, the context does not explicitly discuss any specific strategies aimed at controlling or mitigating the effects of randomness introduced through factors like random seed values. Therefore, based solely on the information provided, I cannot offer a detailed explanation of how randomness in the deep learning pipeline is handled in this particular case.