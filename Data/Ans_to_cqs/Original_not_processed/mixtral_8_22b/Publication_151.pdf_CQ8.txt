Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Embedding size. The Layer and Rhodes (2017) (LR)
formulation requires n
1 dimensions, which introduces
some challenges. According to the theory, the number of
dimensions needs to increase by one after inserting the
query. Our supervised learning formulation does not
allow that (the embedding size is ﬁxed after training).
Thus, there is no guarantee that the embeddings remain
correct after addition, even if they are before addition.
However, we note that, in LR embeddings, adding a
leaf would require simply dividing one of the n
1
dimensions into two dimensions, leaving the rest of the
embeddings intact. Thus, one can hope that having one
less dimension has a minimal practical impact. More
broadly, for large n, training models with n-dimensional
embedding is impractical. Thus, we often set k < n
1,
and the gap can be more than an order of magnitude for
some of our tests described below. In practice, we use a
rule of thumb to select the default k (which the user can

that DEPP can update the multilocus microbial tree-of-life with single genes with high accuracy. We further demonstrate
that DEPP can combine 16S and metagenomic data onto a single tree, enabling community structure analyses that take
advantage of both sources of data. [Deep learning; gene tree discordance; metagenomics; microbiome analyses; neural
networks; phylogenetic placement.]

{

=

=

n
i

n
i

Di}
{

DR
i }

1 and

Placement.—Once the CNN model is trained, we use it to
map a given query sequence q to a vector of distances
D1 ...Dn. For data sets with missing data (gaps), we
compute two sets of distances,
1,
using the models with and without gap reconstruction,
respectively. The ﬁnal distances is set to the weighted
i , where �
sum of the distances, that is, (1
is the proportion of the sites with gaps in the query
sequences. The weighted sum is used to reduce the
impact of reconstructed bases (which are guessed, as
opposed to being observed) on the ﬁnal distance and
will be empirically tested. Given these distances, we then
place q onto T using distance-based placement (Balaban
et al. 2020), which uses dynamic programming to ﬁnd the
dqi(T))2,
placement with the minimum
where dqi(T) represents the tree-based distance between
(cid:30)
the query and each taxon i (Fig. 1).

�)Di +

(Di −

1 D−
i

�DR

−

n
i

=

2

Phylogenetic placement offers a way to use general
purpose models without simulations. Given a reference
tree, however computed, and sequence data which are
a function of the tree, we can use the reference data
to train a machine learning model (such as a DNN)
that can place a query sequence onto the reference tree.
The reference tree may be a species tree inferred using
large numbers of genes, using complex models, and
perhaps after spending much computational resources.
Such reference data are increasingly available. For
example, several comprehensive trees were published
recently with tens of thousands of microbial species
(Zhu et al. 2019; Asnicar et al. 2020; Parks et al.
2020) using 120–400 genes, with analyses that took
>200,000 h of CPU and GPU time in one case. These
available trees are excellent candidates for providing the
training data.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the provided information, I cannot determine the exact location of the code repository for the deep learning pipeline mentioned. It could be hosted on platforms such as GitHub, GitLab, or BitBucket, but without specific details, I am unable to provide an accurate answer. Please refer to any associated documentation, publications, or websites related to this project for more precise information regarding its code repository.