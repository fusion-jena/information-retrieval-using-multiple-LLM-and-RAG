Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Additionally,  we  created  a  metadata  .csv  file  that  listed  all  of  the 
necessary classification information for training the CNN and k-NN . The 
.csv file had five columns. The first, dialect_folder, listed the file path to 
the folder containing the bird song. Each folder was labeled with the 
dialect type and the year it was collected, for example, “ABLA_2022”. 
Note, each folder name contained the label of the songs inside, as this 

EcologicalInformatics82(2024)1026572B. Story et al.

For the CNN portion of our program, we used ResNet-18, a 18-layer 
CNN established in (He et al., 2016) and implemented via PyTorch. For 
the inputs, the data preparation program (0_prep_data.py) generated the 
spectrograms from the .wav of each song using the Librosa (McFee et al., 
2023) python package and cropped out all axis labels and borders from 
each image. This provided a dataset of images with pixel size 480 × 365. 
ResNet-18 requires images to be 224 × 224, so the program used the 
Pytorch function “resize” to properly re-scale each image with a built-in 
anti-aliasing feature. Then, the program converted each image into the 
appropriate  input  for  the  CNN.  The  CNN  used  a  train/validation/test 
split of 70%/10%/20% of the training dataset and was trained for 25 
epochs; we used the model state from the epoch in which the highest 
validation accuracy was achieved. 

2.2.2. k-NN structure

grams, and created the metadata .csv file necessary for training the CNN 
and k-NN. Identical in structure to the metadata file outlined above, this 
file contained the metadata for the training set as opposed to the met-
adata for the entire dataset. 

No additional preprocessing was applied to the spectrograms as the 
goal was to do the least amount of preprocessing possible in order to 
demonstrate  the  power  of  human-machine  teaming.  Further,  when 
assessing the accuracy of the CNN on noise-filtered data versus raw data, 
the accuracy levels were similar: after 10 trials, the CNN’s accuracy on 
the  filtered  data  averaged  to  99.22%  and  the  accuracy  on  the  non- 
filtered data averaged to 99.25%.

Training Data Description 

80% of each 
dialect class 

Total # of Training Songs 
Test Data Description 

2416 
20% of each 
dialect class 

No FOFU 
songs & 80% 
of other 
dialect 
classes 

1734  
All FOFU 
songs & 20% 
of other 
dialect 
classes 

No FOFU or 
LODU songs 
& 80% of 
other dialect 
classes 

1561  
All FOFU 
and LODU 
songs & 20% 
of other 
dialect 
classes 
700  

Total # of Test Songs (Songs 
from test set with location 
data) 

Test Number 
Match, Both Correct 
Match, Both Incorrect 
Mismatch, CNN Correct 
Mismatch, k (cid:0) NN Correct 
Mismatch, Both Incorrect 

460 

1 
455 
0 
2 
3 
0 

499  

2a 
443 
17 
5 
4 
30 

2b 
466 
0 
26 
7 
0 

3a 
396 
76 
0 
8 
220 

3b 
534 
0 
16 
150 
0  

remaining 20% of each of the other dialect classes.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning pipeline uses several data formats including audio files (.wav), image files (spectrograms), and comma-separated values (CSV). The audio files contain bird songs, while the spectrograms are visual representations of these sounds generated by the data preparation program using the Librosa Python package. These spectrograms have dimensions of 480 x 365 pixels but are resized to 224 x 224 pixels to meet the requirements of the Convolutional Neural Network (CNN) used in the pipeline. Additionally, a metadata CSV file is created listing all the necessary classification information for training the CNN and k-Nearest Neighbors (k-NN) algorithms. This CSV file has five columns, one of which lists the file paths to folders containing the bird songs, where each folder is labeled with the dialect type and the year it was collected.