Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Here, we trained our model on backbone trees
that ranged in size from 200 to 10,000 species. While
deep learning is believed to require extremely large
labeled data sets for training, we were able to train
DEPP, which has a moderate number of layers, with
only 200 species because we use pairwise information.
19,900 observed
Thus, with 200 species, we have
pairwise distances for training. Nevertheless, it is reas-
onable to expect that as reference trees become more
densely sampled, the accuracy of DEPP would increase.
Moreover, recall that our embedding is much smaller
than size of the tree. Our results indicate that while
theory suggests we need n
1 dimensions for Euclidean
−
embedding of trees, far fewer dimensions sufﬁce in
practice; we had to reduce k from 128 to 32 to observe
substantial drops in accuracy on simulated data (Table S2
of the Supplementary material available on Dryad). Note
that LR embedding states that n
1 dimensions are
−
sufﬁcient, but it does not state that n

Examining example trees shows that these cases of
high error tend to correspond to novel query taxa; that
is, those on long branches on sparsely sampled clades
(Fig. S3 of the Supplementary material available on
Dryad). Queries with higher terminal branch lengths
lead to higher error (Fig. S4 of the Supplementary
material available on Dryad); however, it appears that
the shortest of branches also have a higher error, perhaps
because distinguishing very similar taxa requires strong
signal. Similarly, queries with a large clade as the sister
tend to be more difﬁcult for DEPP (Fig. S4 of the
Supplementary material available on Dryad). Trees that
lead to high error tend to have long terminal branches
and short branches close to the root, a condition that
corresponds to rapid radiations; in contrast, easy cases
are those with shorter terminal branches and long
branches closer to the root (Fig. S3 of the Supplementary
material available on Dryad).

To ensure query sets (i.e., testing data) are separate
from the training data, we removed 5% of species (10 and
500 for simulations with 200 and 10,000 backbone taxon
and
445 for real data) from the species tree to obtain
reference trees. We did not re-estimate species trees after
removing queries. These left-out species are used as the
query. The reference tree is the true species tree for the
simulated data set and the ASTRAL tree for the WoL data
set (Zhu et al. 2019). For the simulated data set, branch
lengths of the backbone species tree are estimated using
sites randomly selected from the genes we used in the
experiments (32 genes for ILS data and 5 genes for HGT
data) with each gene providing 500 sites. For WoL data
set, branch lengths of the species tree are available from
the original study (estimated under GTR+� from 100
randomly selected sites from 381 marker genes). Training
is done using DEPP v0.2.2. For testing, each query taxon

{

=

=

n
i

n
i

Di}
{

DR
i }

1 and

Placement.—Once the CNN model is trained, we use it to
map a given query sequence q to a vector of distances
D1 ...Dn. For data sets with missing data (gaps), we
compute two sets of distances,
1,
using the models with and without gap reconstruction,
respectively. The ﬁnal distances is set to the weighted
i , where �
sum of the distances, that is, (1
is the proportion of the sites with gaps in the query
sequences. The weighted sum is used to reduce the
impact of reconstructed bases (which are guessed, as
opposed to being observed) on the ﬁnal distance and
will be empirically tested. Given these distances, we then
place q onto T using distance-based placement (Balaban
et al. 2020), which uses dynamic programming to ﬁnd the
dqi(T))2,
placement with the minimum
where dqi(T) represents the tree-based distance between
(cid:30)
the query and each taxon i (Fig. 1).

�)Di +

(Di −

1 D−
i

�DR

−

n
i

=

2

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The data repository link of the deep learning pipeline is not explicitly mentioned in the provided context. However, there are references to supplementary materials available on Dryad throughout the text. Therefore, it can be inferred that the data might be hosted on Dryad. To find the exact link, one could search for the relevant publication or dataset on the Dryad website.