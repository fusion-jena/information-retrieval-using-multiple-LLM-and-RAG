Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

WT-HMM using varying dataset sizes over 10 runs.

Furthermore,  the  comparison  between  recording  months  provides 
valuable insights into the tradeoffs  associated with dataset size  selec-
tion. The superior performance of the WT-HMM in the 8 to 20-h dataset 
size  range  for  both  months  suggests  the  most  suitable  range  for 
achieving  high  accuracy.  This  finding  resonates  with  studies  empha-
sizing the importance of selecting appropriate sample sizes for effective 
model training (Kahl et al., 2021).

The observed increasing trend in both accuracy and F1-score for the 
WT-HMM across different dataset sizes aligns with findings in similar 
studies.  Previous  research  in  bioacoustics  has  highlighted  the  impor-
tance of dataset size in training robust models for cetacean vocalization 
classification  (Lu  et  al.,  2021;  Ogundile  et  al.,  2020;  Ogundile  et  al., 
2021; Usman et al., 2020). Larger datasets provide models with more 
diverse examples, aiding in the generalization of learned features and 
patterns. The consistent improvement in accuracy and F1-score for both 
recording periods indicates that the WT-HMM is not only effective for 
smaller datasets but also scales well as the dataset size increases. This 
scalability  is  a  crucial  characteristic,  especially  in  bioacoustic  moni-
toring where datasets can vary significantly in size (Xie et al., 2020).

EcologicalInformatics80(2024)10246811O.P. Babalola and J. Versfeld

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention or indication of where the data repository of the deep learning pipeline is available. It could be stored in any of the mentioned platforms such as Zenodo, Figshare, Dryad, or GBIF, but without explicit information, it cannot be determined accurately. Further details are required to provide a precise response.