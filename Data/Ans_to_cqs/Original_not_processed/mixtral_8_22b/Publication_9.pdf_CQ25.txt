Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

specific segmentation models. The full instructions and options are 

cluded in model training are shown in Figure 1.

provided on the GitHub repository.

2.3 | Model training procedure

2.5 | Sashimi online model repository

We first used the VGG Image Annotator Version 1.0.6 (https://www.

We constructed a website to serve as a repository for the fish seg-

robots.ox.ac.uk/~vgg/softw are/via/via- 1.0.6.html;  Dutta  et  al., 
2016) to manually annotate pixel coordinates to create precise po-

mentation model (presented here) and future, community generated 

organismal  segmentation  models  (https://sashi mi.shawn tyler schwa 

lygonal mask contours directly around the fish body boundary (i.e. 

rtz.com). We aim to inspire other biologists interested in automated 

where the foreground pixels of the target fish body meet those of 

segmentation to create pre- trained models for their organism(s) of 

the background). We intentionally assigned all segmentation masks

lack  of  readily  available  image  datasets  with  high- resolution  image 

We then discuss the strengths and limitations of our approach for 

segmentation mask annotations limits how biologists can accessibly 

processing fish images and consider how this approach can be ex-

engage with deep learning applications to rapidly process images for 

tended to other branches of the tree of life.

SCHWARTZ And ALFARO 2041210x, 2021, 12, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13712 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License2344  |    Methods in Ecology and Evolu(cid:13)on

2 |  M ATE R I A L S A N D M E TH O DS

gamut of fish images— similar to the Gray et al. (2019) implementa-

overarching  goal  of  training  a  neural  network  is  to  iteratively  min-

tional  training.  The  utility  of  pre- trained  CNNs  out- of- the- box  is 

imize the error between model output and expected output by op-

constrained by how relevant the novel input data are to the data the 

timally  adjusting  model  weights  and  reaching  model  convergence, 

CNN  was  originally  trained  on.  For  instance,  ImageNet  comprises 

such that the trained neural network generalizes well to novel input 

more  than  14  million  high- resolution  images  across  nearly  22,000 

data. Model weights are adjusted to minimize error on each subse-

categories and is often used as a starting point for recognition tasks 

quent run using an algorithm called stochastic gradient descent with 

with deep learning (Deng et al., 2009; Krizhevsky et al., 2017). Using 

backpropagation  (LeCun  et  al.,  1989;  Rumelhart  et  al.,  1995).  This

biodiversity  across  the  tree  of  life  directly  out- of- the- box  without 

when  no  prior  task  experience  is  supplied  (Gray  et  al.,  2019).  We 

additional training.

use transfer learning with pre- trained COCO weights to successfully 

High- fidelity  image  segmentation  is  a  unique  problem  in  com-

automate  image  segmentation  of  fishes  currently  unrepresented 

puter vision and is further constrained by the taxonomic imbalance 

within COCO out- of- the- box.

of biodiversity in readily accessible, annotated datasets for training 

Here, we present Sashimi, a user- friendly toolkit that facilitates 

neural networks to perform segmentation. For image segmentation 

the  rapid  execution  of  accurate,  high- throughput  image  segmen-

to  work,  the  neural  network  must  not  only  successfully  recognize 

tation  of  digitized  organisms— requiring  no  extensive  program-

the presence or absence of a target in an image but also must isolate

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the purpose of the deep learning model (e.g., classification, segmentation, detection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The purpose of the deep learning model presented in the given context is for image segmentation. Specifically, it aims to automate the segmentation of fish images, which involves identifying and separating the fish bodies from the background in digital images. This is achieved by using a convolutional neural network (CNN), which has been trained using transfer learning with pre-trained COCO weights. The overall goal is to develop a toolkit that enables rapid and accurate high-throughput image segmentation of digitized organisms, including fishes that may not be represented within existing datasets like COCO.