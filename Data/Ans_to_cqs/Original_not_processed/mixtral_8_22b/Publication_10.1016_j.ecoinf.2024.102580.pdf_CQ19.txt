Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025802R.K. James et al.                                                                                                                                                                                                                                

Fig. 1. Workflow used to (a) select a deep learning model, (b) develop a ground-truth imagery dataset, (c) train the deep learning models, (d & e) evaluate model 
performance and (f & g) obtain the data and analyse it to quantify the spatial patterns and resilience of the ecosystem. 

2.3. Deep learning models 

2.3.1. Semantic segmentation for vegetation mapping

Access  to  required  computing  resources  is  another  challenge. 
Training  deep  neural  networks  for  semantic  segmentation  and  object 
detection traditionally requires expensive computational resources with 
multiple high-end GPUs (e.g., available on high-performance computing 

EcologicalInformatics81(2024)10258010R.K. James et al.

Python 3.8.0 (Van Rossum and Drake, 2009) and Jupyter Notebook 
v6.4.5 (Jupyter Team, 2015) were used for image processing on a per-
sonal laptop. U-Net training was carried out on the high-performance 
´
Equipements  de  Calcul  Intensif 
computing  resources  Consortium  des 
(C´ECI)  using  the  Dragon  2  cluster  hosted  at  the  University  of  Mons, 
Belgium. The specific cluster node used for the training consisted of the 
following hardware configuration –  Intel Skylake 12-cores Xeon 6126 
processor at 2.6 GHz with a Nvidia Tesla V100 GPU (5120 CUDA core/ 
16GB HBM2/7.5 TFlops double precision). 

2.3.2. Object detection model for localization of large animals 

To  identify  individual  animals  in  images  an  object  detection 
approach  was  used.  The  open-source  DEtection  TRansformer  (DETR)

3.1. Success of deep learning models 

The  semantic  segmentation  model  used  to  identify  the  substrate 
types  achieved  an  accuracy  of  92%.  The  precision  for  the  vegetation 
class was 0.90, for the bare class was 0.96, and for the ‘other’ class was 
0.50 when evaluating the model against the test dataset. The recall of 
the model (the number of instances in which the model correctly iden-
tified the pixels out of the total number of pixels in that class) reached 
0.97 for vegetation, 0.87 for bare substrate and the ‘other’ class reached 
a recall of 0.53.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors do not explicitly mention the use of any specific deep learning framework such as TensorFlow or PyTorch. However, they do state that Python 3.8.0 and Jupyter Notebook v6.4.5 were used for image processing. This suggests that the deep learning models might have been built using libraries compatible with Python, such as TensorFlow or PyTorch. Nevertheless, without explicit confirmation from the authors, we cannot definitively determine which framework was used.