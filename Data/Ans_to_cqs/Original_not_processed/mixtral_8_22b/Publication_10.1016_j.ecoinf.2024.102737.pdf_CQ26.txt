Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. on the other hand, a practically reasonable pipeline for recognition
can be achieved despite the problem specification challenges, using a
careful examination of different factors, such as pose handling, while
bearing some surprises to the Computer Vision community, e.g., the
advantage of a feature-extraction enhancement (avoiding data
augmentation) over using augmentation techniques.

Preprocessing the input instead of relying on data augmentation is a
preferred way with significantly better results, seemingly by-passing the
difficulty of the Siamese network to learn similarity in the presence of so
few examples. It could be, however, that there is still a better way to by-
pass this difficulty but also exploit the power of augmentations.

CRediT authorship contribution statement

Wang and Deng, (2021) also refer to deep face-recognition via face
preprocessing adjustment to work under various conditions, such as
poses, illuminations, expressions and occlusions. The face processing
methods are categorized by Wang and Deng, (2021) as “one-to-many
augmentation”
“One-to-many
and “many-to-one normalization”.
augmentation” methods generate many patches or images of the pose
variability from a single image to enable deep networks to learn pose-
invariant representations. Alternatively, “Many-to-one normalization”
methods recover the canonical view of face images from images of a non-
frontal view; then, face recognition is performed as if it were under
controlled conditions. Their discussion of pose handling in face recog-
nition made us realize that poses should probably be handled also for
individual BR ray recognition as the two different tasks share this
challenge.

3. Methods

In addition, using data augmentation gave inferior results to using
the feature extraction enhancement method in which these augmenta-
tion methods are useless. Nevertheless, we further examined this issue in
the next experiments.

EcologicalInformatics82(2024)10273711A. Levy et al.

Table 1
Initial experiments results. Notations: 2-CoL/4-CoL – architecture type (number
of convolution layers-loss function), Aug/NoAug – with or without data
augmentation, FEE/NoFEE – with or without the suggested feature extraction
enhancement, OM/MO/none – one-to-many, many-to-one handling of poses or
no handling of poses.

Exper. No.

Method

I1:

I2:

I3:

I4:

2-CoL, NoAug,
FEE, none
4-CoL, NoAug,
FEE, none
4-CoL, NoAug,
FEE, MO
4-CoL, NoAug,
NoFEE, none

P1

0.03

0.07

0.12

0.04

P3

0.172

0.223

0.324

0.121

P5

0.293

0.374

0.465

0.343

P6

0.333

0.455

0.485

0.364

transformation to black and white colors, which make them useless.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about specific techniques used to address data bias during preprocessing of the deep learning pipeline, such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it discusses the use of feature extraction enhancement and pose handling methods to improve the performance of deep learning models for face recognition tasks.

According to the context, A. Levy et al. conducted initial experiments comparing different architectures, loss functions, and preprocessing methods for face recognition tasks. They found that using feature extraction enhancement (FEE) resulted in significantly better results compared to using data augmentation techniques. Additionally, they explored pose handling methods, including one-to-many (OM) and many-to-one (MO) approaches, to handle variations in facial poses. These methods generated multiple patches or images of pose variability from a single image or recovered the canonical view of face images from non-frontal views, respectively.

While the context does not explicitly mention techniques for addressing data bias, it suggests that careful consideration of preprocessing methods can lead to improved model performance. In particular, the authors emphasize the importance of pose handling for individual BR ray recognition, indicating that this challenge is shared between face recognition and BR ray recognition tasks. Therefore, it may be beneficial to explore similar preprocessing strategies for addressing data biases in other deep learning applications.