Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Active  learning  iterations  used  a  batch  size  of  64,  ten  epochs  and 
learning rate of 0.001. We used a grid search technique (Mohri et al., 
2018) to tune hyperparameters of the final model including the number 
of epochs, batch size and learning rate. 

2.3.3. Active learning framework 

We  applied  an  active  learning  approach  to  iteratively  train  and 
improve  the  CNN  model.  The  active  learning  approach  is  depicted 
within Fig. 3 and described below.

Sankupellay, M., Konovalov, D., 2018. Bird call recognition using deep convolutional 

neural network, ResNet-50. In: Proceedings of Acoustics. 

Sekercioglu, C.H., et al., 2008. Climate change, elevational range shifts, and bird 

extinctions. Conserv. Biol. 22 (1), 140–150. 

Settles, B., Craven, M., 2008. An analysis of active learning strategies for sequence 

labeling tasks. In: Proceedings of the 2008 Conference on Empirical Methods in 
Natural Language Processing, pp. 1070–1079. 

Teixeira, D., et al., 2022. Fledge or fail: Nest monitoring of endangered black-cockatoos 
using bioacoustics and open-source call recognition. Ecol. Inform. 69, 101656. 
Thakur, A., Thapar, D., Rajan, P., Nigam, A., 2019. Deep metric learning for bioacoustic 

classification: Overcoming training data scarcity using dynamic triplet loss. 
J. Acoust. Soc. Am. 146 (1), 534–547. 

Threatened Species Scientific Committee (TSSC), 2005. Commonwealth Listing Advice

100 target calls. To overcome this challenge, we applied a random se-
lection  approach  that  was  stratified  across  the  model’s  predictions 
(logits).  While  this  approach  substantially  reduced  class  imbalance 
within our evaluation data and allowed for the calculation of reliable 
evaluation  metrics  (Raeder  et  al.,  2012),  the  nature  of  this  approach 
alters  the  distribution  of  data  and  prohibits  evaluation  metrics  being 
generalised  to  the  unlabelled  data.  Additional  research  is  needed  to 
investigate more appropriate evaluation methods for highly imbalanced 
and unlabelled test data.

Hüllermeier, E., Waegeman, W., 2021. Aleatoric and epistemic uncertainty in machine 
learning: an introduction to concepts and methods. Mach. Learn. 110, 457–506. 
Kahl, S., et al., 2021. BirdNET: a deep learning solution for avian diversity monitoring. 

Ecol. Inform. 61, 101236. 

Karimi, D., et al., 2020. Deep learning with noisy labels: exploring techniques and 

remedies in medical image analysis. Med. Image Anal. 65, 101759. 

Kingma, D.P., Ba, J., 2014. Adam: a method for stochastic optimization. Proceedings of 
the 3rd International Conference on Learning Representations. arXiv preprint arXiv: 
1412.6980, pp. 1–15. 

Koehler, J., et al., 2017. The use of bioacoustics in anuran taxonomy: theory, 

terminology, methods and recommendations for best practice. Zootaxa 4251 (1), 
1–124. 

Koenecke, A., et al., 2020. Racial disparities in automated speech recognition. Proc. Natl. 

Acad. Sci. 117 (14), 7684–7689.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors employed several measures to improve the generalizability of their deep learning model. Firstly, they utilized an active learning approach which involved iterative training and improvement of the Convolutional Neural Network (CNN) model. This process helped refine the model by incorporating feedback from its own predictions, thereby enhancing its performance and applicability to new datasets.

Secondly, the researchers implemented a grid search technique to fine-tune the hyperparameters of the final model. This strategy systematically explores different combinations of parameters to identify the optimal configuration, thus improving the model's adaptability to various scenarios.

Moreover, the study addressed the issue of class imbalance within the evaluation data through a random selection approach that was stratified across the model's predictions (logits). Although this method altered the original data distribution, it significantly mitigated class imbalance and enabled the computation of dependable evaluation metrics. However, the authors acknowledged that further investigation is required to develop suitable evaluation methods for highly imbalanced and unlabeled test data.

Lastly, while not explicitly mentioned in the given context, the inclusion of diverse datasets and cross-validation techniques could also contribute to ensuring the generalizability of the deep learning model. These practices help prevent overfitting and enhance the model's ability to perform well on previously unseen data.