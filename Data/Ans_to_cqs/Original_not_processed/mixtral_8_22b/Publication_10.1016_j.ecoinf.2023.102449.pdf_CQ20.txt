Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To  identify  linear  separability  of  learned  representations  by  hard-
ware,  we  train  a  logistic  regression  model  to  predict  the  device.  We 
perform L1 regularisation on the logistic regression to ascertain if fea-
tures  descriptive  of  hardware  differences  are  heavily  entangled  with 
other factors. Model features are the means μ  of the VAE’s latent dis-
tribution. We map feature vectors for each time step zkt  onto a 2-dimen-
sional manifold using UMAP to visualise the distribution by hardware. 
UMAP seeks a lower dimensional space by optimising a low dimensional 
graph that maintains relative distances in high dimensional space, pre-
serving relationships between samples and in principle the underlying 
structure of the latent space (McInnes et al., 2020). We parameterise the 
UMAP algorithm with a euclidean distance function and constrain the 
graph neighbourhood to 50 nodes to tailor the algorithm to represent 
global structure.

quency response that create a potential bias; we demonstrate how a simple linear transformation can be used to 
mitigate the effect of hardware variance on the learned representation under our approach. Our novel approach 
paves the way for development of a new class of deep neural networks that afford more interpretable learned 
ecoacoustic representations to advance both fundamental and applied science and support global conservation 
efforts.

network deepens (Ioffe and Szegedy, 2015; Prince, 2023). To mitigate 
internal covariate shift and stabilise training residual networks require 
some form  of layer  normalisation  such  as batch  normalisation.  While 
increasing  the  number  of  model  parameters,  batch  normalisation  en-
ables the use of higher learning rates, significantly speeding up training 
and  reducing  power  usage  (Ioffe  and  Szegedy,  2015).  Wide  ResNets 
increase network width and reduce depth (Zagoruyko and Komodakis, 
2017) allowing faster training due to shallower architectures. Our ar-
chitecture  draws on  the  layout  of  BirdNet’s  encoder,  preserving  their 
pre-processing block and dropping the classification layers, setting up a 
wide  residual  network  with  a  width  scaling  factor  K = 4  and  depth 
scaling factor N = 3 (Kahl et al., 2021). Hidden layer activations use a 
rectified linear unit (ReLU) activation function. Additional regularisa-

arXiv: 1609.09430 [cs.SD].  

Hsu, Wei-Ning, et al., 2021. HuBERT: Self-Supervised Speech Representation Learning by 

Masked Prediction of Hidden Units arXiv: 2106.07447 [cs.CL].  

Hurlbert, Stuart H., 1971. The nonconcept of species diversity: a critique and alternative 

parameters. Ecology 52 (4), 577–586. 

Ioffe, Sergey, Szegedy, Christian, 2015. Batch Normalization: Accelerating Deep Network 

Training by Reducing Internal Covariate Shift arXiv: 1502.03167 [cs.LG].  

Jiang, Junyan, et al., 2020. Transformer VAE: a hierarchical model for structure-aware 
and interpretable music representation learning. In: ICASSP 2020–2020 IEEE 
international conference on acoustics, Speech and Signal Processing (ICASSP), 
pp. 516–520. https://doi.org/10.1109/ICASSP40776.2020.9054554. 
Kahl, Stefan, et al., 2021. BirdNET: a deep learning solution for avian diversity 

monitoring. Eco. Inform. 61, 101236. 

Lakshminarayanan, Balaji, Pritzel, Alexander, Blundell, Charles, 2017. Simple and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not provide information about the specific hardware resources used for training the deep learning model. It discusses various aspects of the model architecture, including the use of wide residual networks, ReLU activation functions, and the application of techniques like batch normalization and L1 regularization. However, it does not mention any details regarding the type or configuration of hardware resources employed during the training process. Therefore, based on the provided context, it is not possible to determine whether GPUs, TPUs, or other types of hardware were utilized for training the deep learning model.