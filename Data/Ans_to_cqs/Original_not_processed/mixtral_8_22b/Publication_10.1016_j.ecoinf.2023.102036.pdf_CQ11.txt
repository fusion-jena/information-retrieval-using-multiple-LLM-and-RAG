Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

number  of  classes  to  be identified)  and  the  second term  refers  to  the 
small amount of K labelled images in each category. To overcome the 
limitation  in  the  dataset  size,  we  exploit  existing  deep  learning  tech-
niques in combination with statistical fundamentals.

CAM: visual explanations from deep networks via gradient-based localization. In: 
Proceedings of the IEEE International Conference on Computer Vision, pp. 618–626. 
Shorten, C., Khoshgoftaar, T.M., 2019. A survey on image data augmentation for deep 
learning. J. Big Data 6 (1), 1–48. https://doi.org/10.1186/S40537-019-0197-0/ 
FIGURES/33. 

Siddiqui, S.A., Salman, A., Malik, M.I., Shafait, F., Mian, A., Shortis, M.R., Harvey, E.S., 
2018. Automatic fish species classification in underwater videos: exploiting pre- 
trained deep neural network models to compensate for limited labelled data. ICES J. 
Mar. Sci. 75 (1), 374–389. https://doi.org/10.1093/ICESJMS/FSX109. 

Hirsch, P.E., Eckmann, R., 2015. Individual identification of Eurasian perch Perca 

Snoek, J., Larochelle, H., Adams, R.P., 2012. Practical Bayesian optimization of machine 

fluviatilis by means of their stripe patterns. Limnologica 54, 1–4. https://doi.org/ 
10.1016/J.LIMNO.2015.07.003.

the growing computing capability of machines and availability of big 
data, making it possible to extract high levels of representation of image 
content  (Hassaballah  and  Hosny,  2019).  This  field  falls  into  artificial 
intelligence  and,  in  particular,  deep  learning,  which  has  recently 
received  large  attention  from  ecologists  (Christin  et  al.,  2019).  Deep 
learning  is  a  sub-field  of  artificial  intelligence  which  focuses  on  a 
learning method based on logical structures that closely resemble the 
architectural  characteristics  of  the  brain  (the  so-called  deep  artificial 
neural networks). It consists of processing units within the global system 
that  specialize  in  detecting certain  hidden  characteristics  in the  data. 
The  first  record  of  the  application  of  computer  vision  in  the  field  of 
fisheries  dates  from  1980s,  which  consisted  in  a  method  for  sorting

Similar works are (Bouma et al., 2018; Moskvyak et al., 2021). It is 
true that (Bouma et al., 2018) considers the data scarcity problem, but 
both have bigger datasets compared to ours. This allows them to train 
fine-tuned  CNNs  and  develop  a  methodology  based  on  extracting 
particular  embeddings  of  the  species  in  question,  specializing  in 
capturing their natural markings quite well. In contrast, considering a 
realistic limited scenario forced us to explore only feature extraction by 
defining an approach that specializes in how to weight the relevance in 
the  comparison  of  the  extracted  embeddings  for  our  problem.  This 
supposes  an  advantage  with  respect  to  those  previous  works  which 
cannot just use straightforward feature extraction but continue training 
the CNN to obtain particular embeddings for their models to correctly 
identify the individuals.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available to provide a direct link to the data repository of the deep learning pipeline mentioned in the given context. The sources cited do not explicitly mention any specific links or databases used for storing or sharing the deep learning pipelines or related data. Therefore, without additional details about the project or authors involved, it is impossible to determine the exact location of the deep learning pipeline's data repository.