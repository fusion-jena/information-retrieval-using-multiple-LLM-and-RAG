Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

distinctive  annotation  profiles  influenced  by  the  complexity  of  vocalizations  and  the  annotators’  strategies, 
ranging from conservative to permissive. To address the challenges of annotation discrepancies, Convolutional 
Neural Networks (CNNs) are trained on annotations from both novices and the expert. The results show varia-
tions in model performance. Our work highlights the importance of annotation guidelines encouraging a more 
conservative  approach  to  improve  overall  annotation  quality.  In  an  effort  to  optimize  the  potential  of  multi- 
annotation  and  mitigate  the  presence  of  noisy  labels,  two  annotation  aggregation  methods  (majority  voting 
and  soft  labeling)  are  proposed  and  tested.  The  results  demonstrate  that  both  methods,  particularly  when  a 
sufficient number of annotators are involved, significantly improve model performance and reduce variability:

However,  it  has  been  observed  that  annotation  sets  used  to  train 
models qualified as “permissive annotators” get lower performance than 
the ones qualified as “conservative annotators”  even with comparable 
F1 score with the annotations from the experts. Gu et al. (2023) also 
proposed that at the same ratio of noise on the training set, the model’s 
performance can decrease differently regarding the type of noise. In this 
study,  it  seems  that  simple  convolutional  neural  network  models 
generalize better from the most obvious examples and the introduction 
of false positives deteriorates the performance more than the omission of 
a vocalization in the annotation set. For future annotation campaigns, 
this  result  might  suggest  that  instructing  annotators  to  adopt  a  more 
conservative approach could be beneficial.

2.3.3. Architecture of the model used 

Because  the  training  sets  for  both  cases  were  relatively  small 
(Table 1), we implemented a CNN comprising three convolutional layers 
followed by three fully connected layers (Fig. 4). The training for each 
vocalization’s  type  was  done  independently.  In  order  to  mitigate  the 
impact of noisy labels on the robustness of the model, a dropout layer 
(with a  dropout rate of 0.25) was incorporated to prevent overfitting 
[Jindal et al., 2017]. During the training process, we employed a binary 
cross-entropy  loss  function  that  computed  the  disparity  between  the 
annotated binary label and the network’s output. The Adam optimizer 
was  used as  the gradient descent algorithm. The implementation was 
carried out using PyTorch [Paszke et al., 2019].

During  the  campaign,  methods  are  proposed  to  assess  inter- 
annotator  variability  and  aggregate  annotation  sets.  Those  methods 
will help to define the minimal number of annotators needed [Dubus 
et al., 2023; Walter et al., 2022]. Increasing the number of annotators 
per sample could be helpful if the variability is too high. Finally, the two 
grouping  methods:  majority  voting  (Section  2.2.3)  and  soft  labeling 
(Section 2.3.2) can also be used to produce relevant annotation sets for 
deep learning. 

6. Conclusion 

In this study, new approaches were explored to improve the accuracy 
and  efficiency  of  cetacean  vocalization  detection  using  deep  learning 
models. Leveraging multi-annotation campaigns involving both expert 
and novice annotators aimed to address the challenges associated with 
the scarcity of ground truth data in underwater PAM studies.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text mentions one specific method used to prevent overfitting in the deep learning pipeline: dropout. Dropout is a regularization technique where randomly selected neurons are ignored during training, which helps to avoid over-reliance on any single feature and encourages the network to learn more generalized representations. In this case, a dropout layer with a rate of 0.25 was incorporated into the architecture of the model used. Other common regularization techniques not explicitly mentioned in the given context include L1 and L2 regularization, early stopping, and data augmentation.