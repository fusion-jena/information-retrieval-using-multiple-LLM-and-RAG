Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5. Experimental Results

5.1. Experimental Setup. +e experiments were performed
on a computer running 64-bit Linux OS with two 2.3 GHz
Intel 8-core processors. All of the utilized predictive
models were implemented in the Python programming
language version 3.8.5. Moreover, deep learning model
(i.e., GRU-DNN) implementation is performed using

Hidden layer (s) Outputlayer ...GRUcellGRUcellGRUcellGRUcellGRUcellGRUcell...XXXX......Input layer...FClayerFClayerGRUlayer 8483, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8551167 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [28/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License8

Computational Intelligence and Neuroscience

4.1. Stacked GRU-DNN Model. +e ﬁrst model is a proposed
GRU-DNN model architecture (a deep learning model).
Diﬀerent model architectures result in diﬀerent prediction
rates. +us, the main challenge was to ﬁnd the best GRU
architecture that ﬁts the data at hand. +e proposed Stacked
GRU-DNN is a ﬂexible custom model, where its architecture
is varied according to the training data. In other words, the
proposed model has no speciﬁc architecture, and its
hyperparameters are obtained during the hyperparameter
optimization process.

[13] Z. Quan, X. Lin, Z.-J. Wang, Y. Liu, F. Wang, and K. Li, “A
system for learning atoms based on long short-term memory
recurrent neural networks,” in Proceedings of the 2018 IEEE
International Conference on Bioinformatics and Biomedicine
(BIBM), pp. 728–733, IEEE, Madrid, Spain, December 2018.
[14] K. Cho, B. Van Merri¨enboer, C. Gulcehre et al., “Learning
phrase representations using RNN encoder-decoder for sta-
tistical machine translation,” 2014, https://arxiv.org/abs/1406.
1078.

[15] S. Hochreiter and J. Schmidhuber, “Long short-term mem-
ory,” Neural Computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[16] M. Ravanelli, P. Brakel, M. Omologo, and Y. Bengio, “Light
gated recurrent units for speech recognition,” IEEE Trans-
actions on Emerging Topics in Computational Intelligence,
vol. 2, no. 2, pp. 92–102, 2018.

Practically, over/underﬁtting diﬃculties in neural net-
work models are caused by the neural network model’s
excessive/insuﬃcient training epochs [43]. As a result, one
possible solution to the DL-based model’s over/underﬁtting
concerns is to apply the early stopping strategy [44], which is
used to cease training when generalisation performance
starts to degrade for a number of epochs. To track the
generalisation performance,
in the proposed model, the
training data is separated into training and validation
groups.

+e dropout approach [45] is another way to deal with
the overﬁtting problem. Dropout is a regularisation strategy
that allows you to train neural networks with alternative
topologies in parallel by randomly dropping out a certain
proportion of layer neurons. Dropout is indicated by the
black neurons in the fully connected layers, as seen in
Figure 3.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The experimental setup mentions that all predictive models were implemented in the Python programming language version 3.8.5. However, it does not explicitly state which specific deep learning framework or library was used to implement the GRU-DNN model. Therefore, without additional information, we cannot definitively determine whether TensorFlow, PyTorch, or any other deep learning framework was employed to construct this particular model.