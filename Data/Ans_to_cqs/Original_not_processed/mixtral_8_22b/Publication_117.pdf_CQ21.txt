Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

science counts of the survey and comparison to expert counts.

tee  that  the  approach  is  transferable  and  how  to  appropriately 

4 |  D I S CU S S I O N

filter the data may be affected by the wording of the guidelines, 

the image resolution and sizes used, or the set of volunteers that 

participate  in  the  project.  Other  more  sophisticated  approaches 

to processing citizen science data have been proposed (Swanson 

From our results, we see that both citizen science and deep learn-

et al., 2016); however, given the range of counts provided by the 

ing methods are capable of producing highly accurate image counts. 

volunteers  and  the  large  errors  we  observe  in  the  baseline  met-

Counting the wildebeest within the survey images is a difficult and 

rics  (c.  11%  and c.  9%  undercount  for  the  mean  and  median,  re-

time- consuming task. When collecting the census images, there are

count wildebeest, and each image was counted by 15 different vol-

tomated	count	of	the	training	images	and	the	expert	count.	All	code	

unteers.  Once  an  image  was  counted  15  times,  it  was  retired  and 

is available from http://dx.doi.org/10.5281/zenodo.2562058.

the overall project progress was displayed on a statistics bar on the 

For the final stage, we counted 1,000 survey images selected at 

home page. Once all images were retired the classification data was 

random,  but  excluding  the  500  training  images.  Counting  the  test 

downloaded. The data included the number of wildebeest counted 

images took 2 hr using the same GPU as for the training.

by each user, their username (unregistered users were given a ran-

dom username) and the pixel location of each of their identifications. 

Prior  to  analysis,  any  count  data  made  using  early  versions  of  the 

2.4 | Expert count

counting interface or collected by either developers or citizen scien-

four skilled counters c.	3–6	weeks	(Torney	et	al.,	2016).	Automating	

Rosi,  &  Post,  2017),  as  well  as  providing  vital  ecosystem  services 

this aspect of the survey would have two major advantages. First, it 

to human communities around the park (Sinclair, Metzger, Mduma, 

would remove a bottleneck in running the survey. Beyond the actual 

(a)

(b)

(c)

After	 this	 initial	 filter,	 the	 bounding	 boxes	 were	 manually	 checked	

deviation of each method from the single expert count which we 

and corrected for each of the 20,000 training images (500 full size 

assume  to  be  the  true  number  of  wildebeest  in  each  image.  For 

images were each divided into 40, 864 × 864 training images).

both the citizen science count and the YOLO count, we assess the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific postprocessing steps involved after the model training. However, based on general machine learning practices, some common postprocessing steps include metrics calculation, confusion matrix creation, saliency map generation, and model validation. In this case, the text mentions that the trained model was used to count wildebeest in 1,000 randomly selected survey images, excluding the 500 training images. This suggests that one of the postprocessing steps might involve applying the trained model to new data and evaluating its performance. Additionally, the text states that the counting data was downloaded and included the number of wildebeest counted by each user, their username, and the pixel location of each identification. This implies that another possible postprocessing step could involve analyzing the output data generated by the model.