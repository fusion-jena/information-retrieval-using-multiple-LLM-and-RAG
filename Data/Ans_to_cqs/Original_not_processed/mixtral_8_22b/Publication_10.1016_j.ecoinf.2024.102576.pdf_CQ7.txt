Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To generate training data for the PCF, 16,660 grid cells with a res-
olution  of  2560  m  were  created  in  South  Korea.  This  resolution  was 
selected because the training unit of the U-Net model was 256 pixels, 
and 2560 m contains 256 pixels of Sentinel-2 with a 10 m resolution. 
Fig. 6a and b show the extracted results, where 8330 cells (half of the 
total) were randomly extracted as a mask for training data in Fig. 6a, and 
3,332 cells (20% of the total) were randomly extracted as a mask for 
validation data in Fig. 6b. The PSI was extracted from Fig. 6a and b to 
prepare input data for model training. The sub-class land-cover map of 
South Korea can be transformed into a macro-class land-cover map by 
converting all sub-class items into macro-class items (Fig. 4). This con-
version  process  resulted  in  the  production  of  a  completely  converted 
sub-class  land-cover  map  of  South  Korea,  as  shown  in  Fig.  6c.  Addi-

the satellite. The labeling part determines the labeling methodology for 
training  the  deep  learning  model.  In  the  classification  part,  a  deep 
learning model was trained based on the results of previous steps. The 
target PSI, which has the same format as the trained PSI, can be classi-
fied using the trained model. Here, the format refers to the spatial res-
olution and spectral band used, interval in PSI, and chronological order 
of  each  band.  If  satellite  imagery  accumulates  owing  to  continuous 
satellite observations, the PSI can also be continuously generated, and 
classification can be continued using the model. This enables PCF land 
monitoring.

the  research conducted  by Kim et  al. (2021a).  Therefore, even in the 
absence of specific classes, using phenological characteristics, elements 
can still be classified on the basis of using classes that are most relevant. 
As  suggested  by  Kim  et  al.  (2021a),  the  classification  accuracy  and 
performance improved as data increased during the training of a deep 
learning  model  using  satellite  imageries  over  multiple  periods,  (Kim 
et al., 2021b). Therefore, the characteristics of a deep-learning model 
can be used effectively. As a result, by employing PCF with DA, we could

IPCC, 2006. 2006 IPCC Guidelines for National Greenhouse Gas Inventories. 
Jagannathan, J., Divya, C., 2021. Deep learning for the prediction and classification of 
land use and land cover changes using deep convolutional neural network. Ecol 
Inform 65. https://doi.org/10.1016/j.ecoinf.2021.101412. 

Jin, Y., Sung, S., Lee, D.K., Biging, G.S., Jeong, S., 2016. Mapping deforestation in North 
Korea using phenology-based multi-index and random forest. Remote Sens. 8 
https://doi.org/10.3390/rs8120997. 

Kathryn Bickel, A., Richards Michael KÂ¨ohl, G., Leonardo Vianna Rodrigues, R., Stahl, G., 
2006. 2006 IPCC Guidelines for National Greenhouse Gas Inventories Volume 4 
Agriculture, Forestry and Other Land Use, Chapter 3 Consistent Representation of 
Lands. 

Kattenborn, T., Leitloff, J., Schiefer, F., Hinz, S., 2021. Review on convolutional neural 
networks (CNN) in vegetation remote sensing. ISPRS J. Photogramm. Remote Sens. 
https://doi.org/10.1016/j.isprsjprs.2020.12.010.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly state the exact criteria used to split the data for deep learning model training. However, it mentions that out of the 16,660 grid cells created, half (8330 cells) were randomly extracted as a mask for training data, while 20% (3,332 cells) were randomly extracted as a mask for validation data. This suggests that the splitting of the data was done randomly, with no specific criteria mentioned apart from the proportions allocated for training and validation purposes.