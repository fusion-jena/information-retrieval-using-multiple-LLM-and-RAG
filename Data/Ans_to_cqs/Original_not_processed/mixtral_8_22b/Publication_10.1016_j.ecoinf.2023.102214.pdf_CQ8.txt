Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

cation  studies,  a  lack  of  data  is  the  greatest  challenge  and  limitation 
researchers encounter (Schneider et al., 2019). With the data collection 
compiled  in  this  work,  we  contribute  the  largest  fully  labeled  snow 
leopard dataset for deep learning research. In addition, we anticipate 
that our novel deep learning methods will encourage other academics to 
contribute  more  datasets  to  Whiskerbook.org  for  the  purpose  of 
continuously curating and enhancing the data used to improve the deep 
learning pipeline. Comparing these results to those of an earlier study by 
Johansson et al. (2020) that depended on human manual classification, 
without  AI  or  software,  determined  that  observers  significantly  over-
estimate  the  true  abundance.  AI-based  individual  ID  within  Whiske 
rbook.org  has  demonstrated  the  potential  to  enhance  the  precision 
and  efficiency  of  manual  observers,  approaching  more  accurate  esti-

versity.  Machine  learning  advancements  used  in  this  study  were 
partially funded by a grant from the Gordon and Betty Moore Founda-
tion. A Microsoft Sponsorship supported Azure-based development and 
model deployment in Whiskerbook.org.

comprehensive graph matching software within the Wild Me software 
suite for cleaning data at the standard suitable for deep learning algo-
rithms. Two manual observers participated in exhaustive rounds of ID 
decisions in a process called graph matching of the 12,311 annotations, 
whereby  two  images  are  placed  side  by  side,  and  the  observer  de-
termines  whether  the  images  are  the  same  individual  or  different  in-
dividuals (same animal, different animal, cannot tell), and ranks their 
level  of  certainty  (undeniable,  certain,  somewhat  certain,  mostly  un-
certain, completely uncertain). This level of comprehensive individual 
ID enabled the subsets of our dataset to have the highest certainty for 
imagery from a field-based dataset. 

2.4. Min-3/Max-10 

A Min-3/Max-10 data subset is frequently used for training machine 
learning algorithms such as PIE. This data subset comprises individuals

and left-right mirroring data augmentation techniques, which reduced 
the  issue  of  overfitting,  and  strengthened  the  algorithms  capacity  to 
match individuals based on pelt patterns rather than the background. 
The  snow  leopard  training  pipeline  described  here  may  be  repur-
posed rather quickly to train new models if more users utilize the system 
and  additional  data  is  submitted.  The  existing  model  may  also  help 
bootstrap that data-curation process. There is a considerable possibility 
for  regional  and  global  research  collaborations  with  snow  leopard 
research  institutions  to  curate  and  independently  identify  data  that 
would advance these existing models toward greater sophistication and 
improved performance. Deep learning systems have the ability to sur-
pass humans in the re-identification of animals, even in the absence of 
obvious patterns and markings, if sufficient datasets and collaboration

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the given context does not provide information about where the code repository of the deep learning pipeline is available. It only mentions that the machine learning advancements used in this study were partially funded by a grant from the Gordon and Betty Moore Foundation and that a Microsoft Sponsorship supported Azure-based development and model deployment in Whiskerbook.org. However, it does not specify any specific code repository platform like GitHub, GitLab, or BitBucket. Therefore, I do not know where the code repository of the deep learning pipeline is available.