Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Our result that deep learning networks consistently outperformed other baselines, is consis-

14 / 19

Deep learning tools for bat acoustic signal detection

S1 Fig. CNNFAST network architecture description. The CNNFAST network consists of two
convolution layers (Conv1 and Conv2), with 16 filters each (shown in yellow, with the filter
size shown inset). Both convolution layers are followed by a max pooling layer (Max Pool1 and
Max Pool2), and the network ends with a fully connected layer with 64 units (Fully Connect).
CNNFAST computes feature maps (shown as white boxes) across the entire input spectrogram,
resulting in less computation and a much faster run time. The fully connected layer is also eval-
uated as a convolution. The output of the detector is a probability vector (shown in green)
whose length is one quarter times the width of the input spectrogram. The numbers below
each layer indicate the height, weight, and depth of the corresponding layer.
(TIF)

binary classification problem. Our CNNFULL consisted of three convolution and max pooling
layers, followed by one fully connected layer (see Supplementary Information Methods for fur-
ther details). We halved the size of the input spectrogram to reduce the input dimensionality
to the CNN which resulted in an input array of size of 130 frequency bins by 20 time steps, cor-
responding to a fixed length, detection window size of 23ms. We applied the CNN in a sliding
window fashion, to predict the presence of a search-phase bat call at every instance of time in
the spectrogram (Fig 1D). As passive acoustic monitoring can generate large quantities of data,
we required a detection algorithm that would run faster than real time. While CNNs produce
state of the art results for many tasks, naïve application of them for detection problems at test
time can be extremely computationally inefficient [33]. So, to increase the speed of our system

59.

van den Oord A, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, et al. Wavenet: A generative
model for raw audio. arXiv preprint arXiv:160903499. 2016.

60. Hochreiter S, Schmidhuber J. Long short-term memory. Neural computation. 1997; 9(8):1735–80.

PMID: 9377276

61. Kosmala M, Wiggins A, Swanson A, Simmons B. Assessing data quality in citizen science. Frontiers in

Ecology and the Environment. 2016; 14(10):551–60. https://doi.org/10.1002/fee.1436

62. Welinder P, Branson S, Perona P, Belongie SJ, editors. The multidimensional wisdom of crowds.

Advances in neural information processing systems; 2010.

63. Swanson A, Kosmala M, Lintott C, Packer C. A generalized approach for producing, quantifying, and

validating citizen science data from wildlife images. Conservation Biology. 2016; 30(3):520–31. https://
doi.org/10.1111/cobi.12695 PMID: 27111678

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific framework or library used to build the deep learning models mentioned, such as CNNFULL or CNNFAST. Therefore, it cannot be determined if they were built using popular deep learning libraries like TensorFlow, PyTorch, or others.