Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Training data

2024). To make these methods more accessible, we published the data 
used in this study, the code used in the analysis, and the trained machine 
learning model.

4. Results 

4.1. Model performance 

The model achieved F1 scores above 0.991 on all the training and 
0.934 on all validation data (Table 2). For the testing data, it generalised 
exceptionally  well  over  time  at  all  locations  (“test-over_time”)  with 
scores above 0.934. Moreover, a nearly perfect F1 score was also ob-
tained  at  locations  it  had  never  seen  before  (“test-over_location”) 
reaching F1 scores of 0.985, 1, and 1 (see an example in Fig. 5). In Table 
S2, we report the F1 scores as well as the number of actual nests, TP, FP 
and FN for each individual orthomosaic. Notably, the three orthomo-
saics  in  test-over_location  contained  48  nests.  The  model  correctly 

EcologicalInformatics82(2024)1027074A. Cusick et al.

EcologicalInformatics82(2024)1027073A. Cusick et al.                                                                                                                                                                                                                                  

data  and  at  inference  time.  We  used  many  different  sets  of  hyper-
parameters in YOLOv6 but found only marginal improvements; hence, 
we decided to use the default settings. Finally, we tested working with 
different  spatial  resolutions  of  the  imagery,  most  notably  including 
training runs in which the same images were used at different spatial 
resolutions. We did not find this approach to be beneficial. 

3.2. Inference method

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no explicit mention of any specific regularization methods used to prevent overfitting in the deep learning pipeline. Regularization methods such as dropout or L2 regularization are commonly employed to avoid overfitting, but without further information, I cannot confirm if they were utilized in this particular case.