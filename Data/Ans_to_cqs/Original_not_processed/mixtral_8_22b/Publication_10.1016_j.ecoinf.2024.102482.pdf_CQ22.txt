Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

accuracy metric is defined as follows: 

Accuracy =

TP + TN
TP + TN + FP + FN

(13)  

where TP, TN, FP, and FN represent the number of true positives, true 
negatives, false positives, and false negatives, respectively. 

Similar to the impact of FN in medical image analysis or information 
security, FN in detecting water pollution can lead to irreparable damage, 
so  metrics  like  recall,  precision,  or  F1  scores  should  be  considered 
necessary. These terms are defined as follows: 

Recall =

TP
TP + FN

Precision =

TP
TP + FP

F1 =

2TP
2TP + FP + FN

(14)  

(15)  

(16) 

All experiments were repeated 20 times, and the performance met-
rics were averaged over the test data set not used for model training. The 
results are expressed as mean ± standard deviation (SD). Performance 
differences between models were evaluated using one-way analysis of 
variance (ANOVA). 

3. Results 

3.1. Performance comparisons between the LSTM model and HMM

2.2. Feature extraction 

To  solve  problems  using  the  machine  learning  method,  extracting 
features from the raw data to be used as inputs for the machine learning 
model is necessary. Although the importance of feature extraction has 
decreased with the introduction of deep learning, there are still aspects 
where features play a key role, such as considering the computing power 
of devices, reducing training time, and ensuring real-time performance 
in decision-making. 

In  this paper,  we used  the BLS  entropy profile to  characterize the 
swimming behavior of C. elegans, as in the work by Jeong et al. (2019). 
The BLS profile has also been used to calculate the Levenshtein distance, 
an indicator of how similar two sequences are, in order to illuminate the 
similarities  and  differences  in  swimming  patterns  of  C.  elegans  in  a 
controlled and chemical-contaminated water environment (Kang et al.,

Comput. Sci. Mob. Comput. 2 (6), 233–238. 

Cho, K., van Merri¨enboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., 
Bengio, Y., 2014. Learning phrase representations using RNN encoder–decoder for 
statistical machine translation. In: Proceedings of the 2014 Conference on Empirical 
Methods in Natural Language Processing, pp. 1724–1734. https://doi.org/10.3115/ 
v1/D14-1179. 

Choi, Y., Jeon, W., Kang, S.H., Lee, S.H., Chon, T.S., 2012. Characterizing temporal 

patterns in the swimming activity of Caenorhabditis elegans. J. Korean Phys. Soc. 60, 
1840–1844. https://doi.org/10.3938/jkps.60.1840. 

Concepcion, R., Guillermo, M., Tanner, S.E., Fonseca, V., Duarte, B., 2023. BivalveNet: a 
hybrid deep neural network for common cockle (Cerastoderma edule) geographical 
traceability based on shell image analysis. Ecol. Inform. 78, 102344 https://doi.org/ 
10.1016/j.ecoinf.2023.102344. 

Dehghani, A., Moazam, H.M.Z.H., Mortazavizadeh, F., Ranjbar, V., Mirzaei, M.,

curacy  below  70%  in  all  experiments,  and  it  does  not  significantly 
benefit from increasing observation time in terms of classification per-
formance. Furthermore, as shown in Fig. 7(a, b), the SD values of the 
accuracy of our LSTM model are much smaller than those of the HMM.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The performance of the deep learning model is evaluated using several metrics, including accuracy, recall, precision, and F1 score. Accuracy is calculated as the sum of true positives (TP) and true negatives (TN) divided by the total number of instances (TP + TN + false positives (FP) + false negatives (FN)). Recall is computed as the ratio of true positives to the sum of true positives and false negatives (TP / (TP + FN)), while precision is determined as the proportion of true positives among all positive predictions (TP / (TP + FP)). Lastly, the F1 score is the harmonic mean of precision and recall, which provides a single measure of overall performance. All these metrics have their own strengths and weaknesses, and they should be chosen according to the specific requirements and goals of the task at hand. For instance, if minimizing false negatives is crucial, then recall might be more important than other metrics.