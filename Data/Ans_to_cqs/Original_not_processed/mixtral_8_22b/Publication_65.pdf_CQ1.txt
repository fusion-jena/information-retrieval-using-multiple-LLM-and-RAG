Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The most signiﬁcant variation of performance is concerning the number of parameters
and with training and inference time. Despite being the best architecture in performance,
According to Table 2, DeepLabv3+ needed more parameters than the other architectures,
about 2.75 times more parameters than the U-Net, the least requiring one. The need for a
more signiﬁcant number of parameters often implies a higher demand for training samples
that our dataset or another dataset may not have met that the methods present in this
research paper may be applied, possibly causing the DeepLabV3+ architecture to perform
below its potential.

Remote Sens. 2021, 13, 3054

11 of 19

Figure 11. Convergence of the evaluated networks.

Table 2. Number of Parameters and Processing Time of the proposed approaches. The training time
represents the results for the test set of each method. The inference time stands for the time taken by
each model to make predictions for each image.

Method

FCN

U-Net

SegNet

2.2. Semantic Segmentation Methods and Experimental Setup

This section presents ﬁve state-of-the-art deep learning architectures evaluated in our
study case. These architecture were the same applied in the work of [43], our previous work
with precision agriculture, but now we want to attend the urban forest context. To better
visualize and analyze CNN’s architectures, we organize the CNN structure illustrations
with colored blocks. Each block represents a processing layer with the data as described in
Figure 3.

Figure 3. Building blocks used to illustrate the different CNNs layers.

Fully Convolutional Network (FCN): FCN architecture is presented in Figure 4. It was
proposed by [44]. This deep network creates a classiﬁcation map with a set of convolutional
layers returning a spatially reduced result. After that, it applies deconvolution layers to
upsample the initial classiﬁcation and produce a dense prediction, restoring the image’s
original resolution.

Method

FCN

U-Net

SegNet

DeepLabV3+

DDCN

Number of Parameters
(in millions)

3.83

1.86

2.32

Training Time
(GPU hours)

Inference Time
(GPU min.)

Inference Time
(CPU min.)

Inference Time
(GPU min./ha)

Inference Time
(CPU min./ha)

485

450

472

1.4

1.9

1

1.3

1.1

1.5

5.16

486

1.4

1.9

2.08

500

5.1

6.2

0.042

0.030

0.033

0.042

0.153

0.057

0.039

0.045

0.057

0.186

3.3. Visual Analysis

Some features maps, learned by the convolutional layers, are presented in Figure 12.
Speciﬁcally, this image presents low-, mid- and high-level feature maps learned by the
ﬁrst, a middle, and the last layers of the networks, respectively. We can see the each CNN
performs very differently from one another.

Therefore, our originality comes from the dataset and the exertion of deep learning
algorithms to improve the nature conservation efforts in this region, and our primary con-
tribution is related to the investigation of state-of-the-art semantic segmentation methods
to detect trees in urban areas. For this task, we used data with a high spatial resolution
(Ground Sample Distance (GSD) of 10 cm) inside an urban area inside the Cerrado biome
and used ﬁve state-of-the-art deep learning architectures to process the data. Deep learning-
based approaches designed to tackle this task receive, as input, an image and return as
output, another image, generally with the exact size of the input data with each pixel
associated with one class. We choose to use deep learning because they present a better
performance in semantic segmentation and scene interpretation tasks over traditional
machine learning and trained professionals in many ﬁelds of science as demonstrated
by [38–42].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information on the specific methods used for collecting raw data in the deep learning pipeline. However, it mentions using data with a high spatial resolution (Ground Sample Distance (GSD) of 10 cm) within an urban area inside the Cerrado biome. This suggests that remote sensing techniques, such as satellite imagery or drone photography, might have been employed to gather the required data. Additionally, the study uses five state-of-the-art deep learning architectures to process the data, indicating that the focus is primarily on utilizing existing models rather than creating new ones. Nevertheless, without further details about the source of the data, it cannot be definitively stated which specific methods were used for gathering raw data.