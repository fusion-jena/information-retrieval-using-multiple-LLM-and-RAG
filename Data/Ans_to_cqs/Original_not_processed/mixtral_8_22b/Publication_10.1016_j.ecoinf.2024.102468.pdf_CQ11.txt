Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

WT-HMM using varying dataset sizes over 10 runs.

EcologicalInformatics80(2024)10246811O.P. Babalola and J. Versfeld

The observed increasing trend in both accuracy and F1-score for the 
WT-HMM across different dataset sizes aligns with findings in similar 
studies.  Previous  research  in  bioacoustics  has  highlighted  the  impor-
tance of dataset size in training robust models for cetacean vocalization 
classification  (Lu  et  al.,  2021;  Ogundile  et  al.,  2020;  Ogundile  et  al., 
2021; Usman et al., 2020). Larger datasets provide models with more 
diverse examples, aiding in the generalization of learned features and 
patterns. The consistent improvement in accuracy and F1-score for both 
recording periods indicates that the WT-HMM is not only effective for 
smaller datasets but also scales well as the dataset size increases. This 
scalability  is  a  crucial  characteristic,  especially  in  bioacoustic  moni-
toring where datasets can vary significantly in size (Xie et al., 2020).

Furthermore,  the  comparison  between  recording  months  provides 
valuable insights into the tradeoffs  associated with dataset size  selec-
tion. The superior performance of the WT-HMM in the 8 to 20-h dataset 
size  range  for  both  months  suggests  the  most  suitable  range  for 
achieving  high  accuracy.  This  finding  resonates  with  studies  empha-
sizing the importance of selecting appropriate sample sizes for effective 
model training (Kahl et al., 2021).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there is no information about the specific data repository link of the deep learning pipeline used by O.P. Babalola and J. Versfeld. Therefore, I cannot provide the requested link to Zenodo, Figshare, Dryad, or GBIF. It would be best to refer to their original paper or contact them directly for this information.