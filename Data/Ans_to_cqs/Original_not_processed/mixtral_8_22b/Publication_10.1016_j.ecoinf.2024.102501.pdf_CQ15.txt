Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

search algorithms such as the genetic algorithm (GA) and particle swarm 
optimization (PSO) are often used to solve model parameter problems, 
for instance, the number of neurons in neural networks, error penalty 
factor in SVM, etc. For example, Yan used GA and PSO to optimize a BP 
neural network to build a DO estimation model of Beijing Lake in Beijing 
(Yan et al., 2019). Compared with the GA algorithm, PSO is used more in 
DO  modeling  in  combination  with  BPNN,  GRU,  LSTM,  SVM,  support 
vector regression (SVR), and other algorithms (Wu et al., 2018; Huan 
et al., 2020; Zhu et al., 2021; Huang et al., 2021; Cao et al., 2021b; Liu 
et al., 2014, exhibiting high efficiency and good robustness with mini-
mal calculation. Other optimization algorithms, such as the multi-verse 
optimizer,  have  also  been  adopted  for  parameter  optimization  (Yang 
et al., 2021).

In addition,  in the prediction  of dissolved oxygen in  water, (Chen 
et  al.,  2020)  not  only  applied  water  quality  parameters  but  also 
considered parameters such as temperature, humidity, and atmospheric 
pressure in the air as input variables for the model, providing ideas for 
subsequent research. 

At last, for the dataset as listed in Table 1, and, three different data 
processing methods were trained and tested using the proposed method, 

4. Discussions 

Table 7 
Medians of measured versus computed DO concentration.  

The  above  results  and  analyses  show  that  traditional  machine 
learning  methods  (SVR)  and  deep  learning  methods  (LSTM)  can  be 
adapted  to  address  the  problems  of  poor  generalization  ability,  local 
optimum, underfitting, and overfitting of conventional models to predict 
DO concentration successfully. The machine learning and deep learning 
literature also discuss the prediction of DO concentration. For example, 

Models

concentration  prediction  ability  than  the  standard  MLPNN  model 
(Areerachakul et al., 2013). Du combined RBFNN with the proportional 
integrated  derivative  algorithm  to  control  the  DO  concentration  in 
aviation  tanks.  GRNN  improves  approximation  ability  and  learning 
speed compared to RBF networks and is also suitable for predicting small 
sample sizes (Du et al., 2018). In predicting DO concentration in river 
water,  Heddam  applied  GRNN  for  modeling  hourly  DO,  at  Klamath 
River, Oregon, USA (Heddam, 2014a), whereas Cs´abr´agi used GRNN, 
RBFNN,  MLPNN,  and  MLR  for  the  River  Tisza  and  Danube  (Cs´abr´agi 
et al., 2019; Cs´abr´agi et al., 2017). Antanasijevi´c used GRNN, MLPNN, 
and  recurrent  neural  networks  (RNN)  for  DO  concentrations  in  the 
Danube River, North Serbia, and compared the results with that of MLR. 
ELM is a type of single hidden layer feedforward neural network, which

The  method  based  on  ANN  is  the  most  actively  used  method  for 
modeling DO concentrations worldwide. Except for a few scholars who 
use single-layer neural networks (Flores et al., 2024), MLPNN, which is 
the most widely used ANN architecture, is a feedforward ANN that was 
previously used in modeling DO concentration of water (He et al., 2011; 
Saber  et  al.,  2020;  Singh  et  al., 2009).  The  three  typical  feedforward 
neural  networks,  namely  radial  basis  function  neural  networks 
(RBFNN),  general  regional  neural  networks  (GRNN),  and  ELMs,  each 
have  their  advantages  and  are  continually  discussed  by  researchers 
(Chen et al., 2020; Keshtegar and Heddam, 2018). RBFNN displays good 
performance,  approaching  that  of  arbitrary  non-linear  functions,  re-
quires simple training, and overcomes local minima with fast learning 
convergence.  It  is  one  of  the  DO  concentration  prediction  algorithms

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, it appears that search algorithms like Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) are commonly employed to tackle model parameter issues in deep learning pipelines. These algorithms help determine optimal values for various parameters, including the number of neurons in neural networks or error penalty factors in Support Vector Machines (SVM).

For instance, Yan utilized both GA and PSO to enhance a Backpropagation Neural Network (BPNN) for building a Dissolved Oxygen (DO) estimation model of Beijing Lake in Beijing (Yan et al., 2019). Furthermore, PSO has been frequently used alongside BPNN, Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), SVM, Support Vector Regression (SVR), and other algorithms (Wu et al., 2018; Huan et al., 2020; Zhu et al., 2021; Huang et al., 2021; Cao et al., 2021b; Liu et al., 2014). This demonstrates its effectiveness and robustness with minimal computational requirements. Additionally, other optimization algorithms, such as the Multi-Verse Optimizer, have also been implemented for parameter optimization (Yang et al., 2021).

However, the context does not explicitly mention specific optimization techniques typically applied within the deep learning pipeline, such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). Therefore, while GA and PSO are optimization techniques used in conjunction with deep learning models, they do not directly fall into the category of optimization techniques like SGD or Adam, which are primarily used during the training process of these models.