Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.5. Model Validation

All of the input parameters are resampled in a single grid size of 100 m and are
converted into the same ﬁle format. Out of the in-situ occurrences of Rhododendron arboreum
at ground locations, only 70% of the data were used in calibrating the model, whereas
the remaining 30% of the data were used to test the model. In any type of modelling,
performance evaluation is an essential task. In terms of validation of species probability
distribution, the AUC (Area Under ROC (Receiver Operating Characteristics) Curve) is
one of the most used performance evaluation metrics [67]. The primary application of the
ROC curve is in the threshold independent assessment that characterizes the model perfor-
mance at various discrimination thresholds. This application was found in raster-based
studies focusing on predicting land use and land cover, species distribution modelling, risk
assessment, and other probability mappings.

Remote Sens. 2021, 13, 3284

17 of 17

47. Wisz, M.S.; Hijmans, R.; Li, J.; Peterson, A.T.; Graham, C.; Guisan, A.; NCEAS Predicting Species Distributions Working Group.

Effects of sample size on the performance of species distribution models. Divers. Distrib. 2008, 14, 763–773. [CrossRef]

48. Yang, W.; Tan, B.; Huang, D.; Rautiainen, M.; Shabanov, N.V.; Wang, Y.; Privette, J.L.; Huemmrich, K.F.; Fensholt, R.; Sandholt, I.
MODIS leaf area index products: From validation to algorithm improvement. IEEE Trans. Geosci. Remote Sens. 2006, 44, 1885–1898.
[CrossRef]

49. Martin, R.; Parrish, D.; Ryerson, T.; Nicks, D., Jr.; Chance, K.; Kurosu, T.; Jacob, D.J.; Sturges, E.; Fried, A.; Wert, B. Evaluation of
GOME satellite measurements of tropospheric NO2 and HCHO using regional data from aircraft campaigns in the southeastern
United States. J. Geophys. Res. Atmos. 2004, 109, 1–11. [CrossRef]

Network (CNN) architecture is proposed, designed, and tested, which eventually gave much better
accuracy than the BIOCLIM model. Both of the models were given 16 input parameters, including
ecological and atmospheric variables, which were statistically resampled and were then utilized
in establishing the linear and nonlinear relationship to better ﬁt the occurrence scenarios of the
species. The input parameters were mostly acquired from the recent satellite missions, including
MODIS, Sentinel-2, Sentinel-5p, the Shuttle Radar Topography Mission (SRTM), and ECOSTRESS.
The performance across all the thresholds was evaluated using the value of the Area Under Curve
(AUC) evaluation metrics. The AUC value was found to be 0.917 with CNN, whereas it was 0.68
with BIOCLIM, respectively. The performance evaluation metrics indicate the superiority of CNN for
species distribution over BIOCLIM.

A pooling layer offers downsampling functionality that decreases the dimensionality
of the feature maps to achieve translation invariance to the alterations and the biases
incorporated and thus helps in reducing the number of learnable parameters. There are
two types of pooling operations, namely Max Pooling and Global Average Pooling [64].
The ﬁrst one extracts speckles from the input feature maps and offers maximum values
in each of the speckles and leaves the remaining values unattended. The second one
downsamples a feature map with a size equaling product of height and width into an array
of a one cross one by averaging the elements of each feature map by retaining the depth of
the feature map. The advantage of Global Average Pooling lies in reducing the number of
learnable parameters along with offering the CNN with variable sized input.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In this study, the strategy implemented to monitor the model performance during training involves splitting the dataset into two parts - 70% for calibration and 30% for testing. The calibration set is used to train the model, while the testing set is used to evaluate its performance. To assess the performance of the model, the Area Under Curve (AUC) metric is employed. This metric measures the ability of the model to distinguish between positive and negative instances, where higher AUC values indicate better performance. Additionally, the study uses Receiver Operating Characteristic (ROC) curves to visualize the tradeoff between true positive rate and false positive rate at different classification thresholds. By evaluating the model's performance on both the calibration and testing sets, researchers can ensure that the model generalizes well to new data and avoid overfitting.