Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

when  they  are  not  trained  with  the  optimal  number  of  background 
points (Ara√∫jo and New, 2007; Shabani et al., 2016).

to model performance by a single component model built with subop-
timal training data. However, RF outperformed all the ensemble models, 
suggesting  that  if  researchers  use  a  single  modeling  approach,  they 
should consider using RF. It should be noted that we found RF to be more 
sensitive to the number of background points used to train the model 
than  other  modeling  methods.  However,  researchers  or  practitioners 
might choose to use a single modeling approach that is found to be less 
sensitive to the number of background points, like a GLM or MaxEnt. In 
this situation, since the gain in performance is minimal, the decision on 
how many background points to use might be instead made to minimize 
computation time and answer time-sensitive questions related to con-
servation  actions.  Nevertheless,  using  an  ensemble  of  models  helps 
overcome any issues that any single model might have, as demonstrated

points. Then, to obtain presences and background points to use during 
external evaluation, we set aside one fold. We then used the remaining 
four folds for internal cross-validation during model training.

4.2. Ensemble models

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The provided context does not explicitly mention the specific criteria used to determine when training is completed, such as reaching a validation loss plateau. However, it can be inferred from the text that some form of cross-validation was employed during the training process. Specifically, four folds were used for internal cross-validation during model training, while setting aside one fold for external evaluation. This suggests that the training process may involve assessing the model's performance on unseen data (i.e., the validation set) and adjusting the model accordingly until satisfactory results are achieved. Nonetheless, without explicit information regarding the stopping criterion, it cannot be definitively stated what exact metric or threshold was used to determine when training was complete.