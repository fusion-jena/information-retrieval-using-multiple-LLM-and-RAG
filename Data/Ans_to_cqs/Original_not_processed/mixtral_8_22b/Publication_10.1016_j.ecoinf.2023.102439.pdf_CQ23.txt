Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

By employing the W-ANN model, the training values reached 96% 
for Iznik and 91% for Alanya, while the estimated percentages for all 
data increased to 95% for Iznik and 88% for Alanya, respectively. The 
developed hybrid model improved learning success, with an increase of 
18.7%  in  Iznik  and  7.3%  in  Alanya,  as  determined  by  the  network’s 
performance.  These  findings  highlight  the  hybrid  model’s  enhanced 
predictive capabilities and effectiveness in both study areas.

The model’s training was conducted using data from 2005 to 2015, 
encompassing 264 data points. Subsequently, data from 2016 to 2018, 
comprising  72  data  points,  were  reserved  for  testing  and  validation 
purposes.  This  data  partitioning  resulted  in  a  distribution  of  60%  for 
training and 40% for validation and testing. 

To evaluate the performance of the model, several statistical metrics 
were  employed,  including  the  Mean  Absolute  Percent  Error  (MAPE), 
Mean Square Error (MSE), Root Mean Square Error (RMSE), and cor-
relation coefficient (R). These metrics provide insights into the accuracy 
and predictive capability of the model by measuring the deviation be-
tween the predicted EVI values and the actual observed values.

(3)  

λ = wavelength of emitted radiance (10.6 μm) 
p = h.c/ σ (1.438.10
σ = (1.38.10–23 JK
h = Planck’s constant (6.626.10
c = Velocity of light (2.998.108 ms

(cid:0) 2 m. K) 
(cid:0) 1) 

(cid:0) 34 J.s) 
(cid:0) 1) 

2.3.3. Modelling 

Artificial  neural  networks  are  a  successful  method  in  modelling 
studies and are frequently discussed in the literature. Essentially, neural 
networks learn from past and present data, uncover hidden relationships 
among  the  data,  and  utilise  them  to  make  predictions  for  future  sce-
narios. Among the various types of artificial neural network models, the 
NARX model is widely employed. In this study, the NARX feedback ANN 
model  was  utilised  to  define  vegetation  biomass  density  for  2030.  A 
hybrid  model  was  developed  by  combining  wavelet  analysis  and  the 
NARX ANN algorithm to enhance the performance of the NARX ANN 
model.

Torres-Faurrieta, L.K., Dreyfus-Le´on, M.J., Rivas, D., 2016. Recruitment forecasting of 
yellowfin tuna in the eastern Pacific Ocean with artificial neuronal networks. Eco. 
Inform. 36, 106–113. 

Turkish Statistical Institute (TURKSTAT), 2019. Data Portal for Statistical. https://data. 
tuik.gov.tr/Search/Search?text=n%C3%BCfus%20art%C4%B1%C5%9F%20h%C4 
%B1z%C4%B1&dil=1 (accessed 07 Jun 2019).  

Ukhnaa, M., Huo, X., Gaudel, G., 2019. February. Modification of urban built-up area 
extraction method based on the thematic index-derived bands. In: IOP Conference 
Series: Earth and Environmental Science, vol. 227. IOP Publishing, p. 062009. No. 6.  

Wahla, S.S., Kazmi, J.H., Tariq, A., 2023. Mapping and monitoring of spatio-temporal 
land use and land cover changes and relationship with normalized satellite indices 
and driving factors. Geol. Ecol. Landsc. 1–17.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given information, it appears that the researchers took several steps to ensure the generalizability of their deep learning model. Firstly, they used a diverse dataset comprising data from two different study areas - Iznik and Alanya. This allowed the model to learn patterns and relationships from multiple sources, thereby increasing its applicability across different scenarios.

Secondly, the researchers employed a specific data partitioning strategy where they allocated 60% of the data for training and the remaining 40% for validation and testing. This approach helps prevent overfitting, which occurs when a model performs well on the training data but poorly on new, unseen data. By reserving a portion of the data solely for validation and testing, the researchers could assess how well the model would perform on previously unseen data, thus ensuring its generalizability.

Lastly, the researchers evaluated the performance of their model using several statistical metrics such as Mean Absolute Percent Error (MAPE), Mean Square Error (MSE), Root Mean Square Error (RMSE), and correlation coefficient (R). These metrics measure the deviation between the predicted and actual observed values, providing insights into the accuracy and predictive capability of the model. By using these metrics, the researchers could objectively determine whether their model was performing well not only on the training data but also on the validation and test datasets, further enhancing its generalizability.