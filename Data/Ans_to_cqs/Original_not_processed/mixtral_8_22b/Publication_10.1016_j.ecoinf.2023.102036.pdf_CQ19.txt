Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

standard  for  most  research  teams  which  are  becoming  familiar  with 
deep learning approaches.

straightforward methodology, and it is developed within a much more 
limited scenario, which is the standard for most research teams which 
are becoming familiar with deep learning approaches.

This  system  was  built  under  Python  3.9.5  using  TensorFlow  2.4.1 
and training was performed on an Intel(R) Core(TM) i9-9900K CPU @ 
3.60GHz processor and 32GB RAM memory. Learning was performed 
with Stochastic Gradient Descendent (SGD) method, optimizing its pa-
rameters (learning rate and momentum) and binary cross-entropy as a 
loss function. The algorithm was also asked to exceed a certain threshold 
of variability in its predictions, i.e., that the standard deviation of the 
predicted probabilities exceeds a certain threshold —to be tuned—  so 
that the output of the classifier is not almost the same for all images that 
feed  the  model.  Moreover,  the  input  image  size  was  optimized,  since 
there is a trade-off between the information provided by large resolu-
tions and the number of weights of the network that need to be trained. 
The parameters were tuned with Bayesian optimization (Snoek et al.,

the growing computing capability of machines and availability of big 
data, making it possible to extract high levels of representation of image 
content  (Hassaballah  and  Hosny,  2019).  This  field  falls  into  artificial 
intelligence  and,  in  particular,  deep  learning,  which  has  recently 
received  large  attention  from  ecologists  (Christin  et  al.,  2019).  Deep 
learning  is  a  sub-field  of  artificial  intelligence  which  focuses  on  a 
learning method based on logical structures that closely resemble the 
architectural  characteristics  of  the  brain  (the  so-called  deep  artificial 
neural networks). It consists of processing units within the global system 
that  specialize  in  detecting certain  hidden  characteristics  in the  data. 
The  first  record  of  the  application  of  computer  vision  in  the  field  of 
fisheries  dates  from  1980s,  which  consisted  in  a  method  for  sorting

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model mentioned in the given context is built using TensorFlow version 2.4.1. TensorFlow is an open-source platform for machine learning and artificial intelligence applications such as neural networks. It provides a comprehensive ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML-powered applications.