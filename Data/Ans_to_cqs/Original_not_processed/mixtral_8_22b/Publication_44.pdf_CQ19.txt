Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

6 of 23

Figure 2. A schematic diagram of a fully convolution neural network for semantic segmentation. The network consists of
an encoder part where the model extracts potential useful features and the decoder part, which up-samples the extracted
feature map to produce the ﬁnal segmentation results.

kernel to expand without increasing the number of parameters [39]. This expansion of the
window is controlled by the dilation rate and it enables the network to capture information
from a larger receptive ﬁeld of view with the same parameters and computational complex-
ity as the normal convolution. The combination of spatial pyramid pooling with Atrous
convolutions resulted in an efﬁcient multi-scale processing module called Atrous spatial
pyramid pooling (ASPP). In the earlier version (DeepLabV3) [40], the last ResNet block of
the modiﬁed ResNet-101 uses different Atrous convolutions with different dilation rates.
ASPP, together with bilinear up sampling, is also used on top of the modiﬁed ResNet block.
DeepLabv3+ is an improvement in the previous version by adding an effective decoder
module to improve the boundaries of the segmentation results [41]. Furthermore, apart
from ResNet-101, an Xception model can be used as a feature extractor while applying a

is an improvement in the previous version by adding an effec-tive decoder module to improve the boundaries of the segmentation results [41]. Further-more, apart from ResNet-101, an Xception model can be used as a feature extractor while applying a depth-wise separable convolution to both ASPP and the decoder module, hence improving the speed and robustness of the encoder-decoder network.  Figure 2. A schematic diagram of a fully convolution neural network for semantic segmentation. The network consists of an encoder part where the model extracts potential useful features and the decoder part, which up-samples the extracted feature map to produce the final segmentation results. 3.2. Phase 2: Leaf Extraction Using Connected Component A classic connected component algorithm was first introduced by Azriel and John in 1966 [42]. Since then, numerous different implementations have been proposed for im-proving existing ones [43]. In image processing, connected components analysis helps to

threshold during training for 3000 iterations. At the end of the training process, the best
performing model based on the validation loss was saved and used as the Faster R-CNN
model with a NMS threshold of 0.7 during testing.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific frameworks used to build the deep learning models mentioned, such as DeepLabv3 or Faster R-CNN. However, these models are commonly implemented using popular deep learning libraries like TensorFlow and PyTorch. For instance, TensorFlow provides pre-trained models for DeepLabv3, and PyTorch has various implementations of Faster R-CNN available. Without additional context, I cannot definitively state which frameworks were used to build these models in this case.