Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3. Methodology 

The  approach  proposed  in  this  work  can  be  explained  as  follows. 
First, the dataset is balanced using the class-weighted technique. This 
step is important as the deep learning models have a bias towards classes 
with  a  large  number  of  images.  This  needs  to  be  solved  using  a  data 
balancing technique. Also, the data imbalanced in the proposed dataset 
is small hence a simple algorithm like class-weighted is proposed. Then a 
novel image pre-processing technique is proposed. A number of different 
models from the state-of-the-art deep learning models are tested. The 
results  of  the  five  best  models  are  reported.  Also,  different  ensemble 
models are tested and compared. The results show that ensemble models 
can increase the accuracy of the classification hence introducing more 
stable models. 

Table 1 
Related Work comparison.  

ref 

contribution 

disadvantages 

accuracy 

(Anandhakrishnan 
and Jaisakthi, 
2022)

3.7. Performance metrics 

In this work, we measure the accuracy of the deep-learning models 

by using the following metrics:  

• Accuracy 

accuracy which is a simple metric for deep-learning classification 
models. This metric measures the overall percentage of correct pre-
dictions. However, accuracy does not take into account the different 
types  of  errors.  That  is  the  reason  we  employ  other  metrics  for 
measuring the efficiency of deep learning models. 

Accuracy =

TP + TN
TP + TN + FP + FN

• Precision 

(1)    

Precision  is  a  metric  that  measures  the  number  of  positive  pre-
dictions  that  are  actually  correct  viz.  a  viz.  correct  and  incorrect 
positive predictions. 

recall is a metric that measures the number of positive predictions 
that are actually correct viz. a viz. correct positive predictions and 
incorrect negative predictions. Recall measures how many positive 
predictions were correctly spotted by the model. 

Recall = TP

TP + FN

Fig. 2. Preprocessing step.  

EcologicalInformatics81(2024)1026184A.H. Ali et al.                                                                                                                                                                                                                                    

Fig. 3. The proposed model.  

minority classes during training. 

This  is  implemented  in  two  steps.  First  we  use  a  function  called 
compute_class_weights from sklearn library in Python. This function is 
responsible of calculating the weights that should be given to each class 
depending on the class numbers. 

The second step involves using these class weights as inputs to train 
the model. This is done by setting the class weight parameters using the 

previously calculated weights. The fit function inside sklearn is imple-
mented in a way to accept such parameters and it applies them during 
training. 

3.4. Deep learning models

Different  deep  learning  models  are  tested  to  find  the  model  with  the 
highest accuracy. The results show that EfficientNet achieves the highest 
accuracy.  A  data  augmentation  technique  is  added  to  increase  the 
number  of  images  from 55,448  to  61,486  images.  Results  of  the  pro-
posed deep learning models on the dataset with and without augmen-
tation  are  reported. This  work  augments  the  dataset using a  complex 
data augmentation technique to produce a new dataset. However, in our 
proposed work we use an augmented version of PlanVillage that can be 
used by different researchers for comparison. Also, we propose using a

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. In the provided context, one such technique mentioned is the class-weighted technique. This method is used to balance the dataset when there is a significant difference between the number of samples in each class. By assigning higher weights to minority classes during training, the model becomes less biased towards majority classes.

Stratified splitting is another commonly used technique to maintain the original distribution of target variables while dividing the dataset into training and testing sets. It ensures that both subsets contain approximately the same proportion of examples from each class.

Oversampling and undersampling are also popular methods to handle class imbalance problems. Oversampling increases the size of the minority class by duplicating its instances or creating synthetic ones, whereas undersampling reduces the size of the majority class by randomly removing some instances. Both approaches aim to achieve a more balanced dataset.

Lastly, diverse data collection is crucial to minimize any potential bias introduced due to limited representation within certain groups or categories. Collecting a wide range of data helps ensure that the trained model generalizes well across various scenarios and populations.

In summary, addressing data bias during preprocessing of the deep learning pipeline can involve techniques such as stratified splitting, oversampling, undersampling, and diverse data collection. Additionally, the context specifically mentions the use of the class-weighted technique to counteract the inherent bias of deep learning models towards classes with larger sample sizes.