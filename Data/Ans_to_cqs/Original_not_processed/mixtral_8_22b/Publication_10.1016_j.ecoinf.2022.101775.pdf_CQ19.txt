Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

‖ps‖2 + ‖qt‖2 + b2

s + b2

t

)

(4) 

Consequently, the unknown parameters bs, bt, ps, qt can be estimated 
optimizing  the  regularized  cost  function  using  stochastic  gradient 
descent: 

ps, qt, bs, bt = argmin
ps,qt ,bs,bt

L .

2.2. Embedding layers 

(5)  

Embedding  layers  are  modules  of  deep  neural  networks  that  are 
generally  implemented  in  natural  language  processing  problems 
(Sharma  et  al.,  2020)  and  collaborative  filtering  (He  et  al.,  2017) 
because they can solve the one-hot encoding problem (Yu et al., 2022), 
where the latent representations in the classic models are composed of 
sparse representations generally using vectors mainly composed of zero 
layers  replace  such  dispersed  vectors  with 
values.  Embedding

systems. Computer 42 (8), 30–37. 

Lerer, A., Wu, L., Shen, J., Lacroix, T., Wehrstedt, L., Bose, A., Peysakhovich, A., 2019. 
Pytorch-biggraph: A large-scale graph embedding system. Proceedings of Machine 
Learning and Systems 1, 120–131. In: https://proceedings.mlsys.org/paper/201 
9/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf. 

Lim, C.-H., Ryu, J., Choi, Y., Jeon, S.W., Lee, W.-K., 2020. Understanding global pm2.5 
concentrations and their drivers in recent decades (1998–2016). Environ. Int. 144, 
106011 [Online]. Available: http://www.sciencedirect.com/science/article/pii/ 
S0160412020319668. 

Little, R.J., Rubin, D.B., 2019. Statistical Analysis with Missing Data, 793. John Wiley & 

Sons. 

Liu, H., Cai, J., Ong, Y.-S., 2018. Remarks on multi-output gaussian process regression. 
Knowl.-Based Syst. 144, 102–121 [Online]. Available: http://www.sciencedirect.co 
m/science/article/pii/S0950705117306123.

3.2. Comparison of DMF and its variations 

In  this  experiment,  we  compared  the  proposed  DMF  architectures 
described  above.  We  constructed  all  neural  networks  with  the  same 
basic  structure:  an  MLP  with  four  hidden  layers,  each  followed  by  a 
ReLU non-linear activation function, and an output layer followed by a 
Sigmoid non-linear activation function that force the network to output 
values between 0 and 1. We added dropout to the first hidden layer (p =
0.5)  to  avoid  overfitting.  We  set  the  number  of  hidden  neurons  as 
(1024,512,128,32).  DMF1  received  as  features  the  concatenation  of 
sensor and time embeddings each of size k = 512. 

Furthermore, DMF2 and DMF3 additionally concatenated temporal 
and spatial information embeddings, respectively. As a result, DMF2 and 
DMF3 received as input 2048 features. Finally, DMF4 used concatena-
tions of the four considered variables (3072 features).

Shah, J., Mishra, B., 2020. Iot-enabled low power environment monitoring system for 
prediction of pm2.5. Pervas. Mobile Comput. 67, 101175 [Online]. Available: 
http://www.sciencedirect.com/science/article/pii/S1574119220300560. 
Sharma, A.K., Chaurasia, S., Srivastava, D.K., 2020. Sentimental short sentences 

classification by using cnn deep learning model with fine tuned word2vec. Procedia 
Computer Science 167, 1139–1147. International Conference on Computational 
Intelligence and Data Science. [Online]. Available: http://www.sciencedirect.com/ 
science/article/pii/S1877050920308826. 

Tamhane, A., Arora, S., Warrier, D., 2017. Modeling contextual changes in user 

behaviour in fashion e-commerce. In: Kim, J., Shim, K., Cao, L., Lee, J.-G., Lin, X., 
Moon, Y.-S. (Eds.), Advances in Knowledge Discovery and Data Mining. Springer 
International Publishing, Cham, pp. 539–550. 

van Buuren, S., Groothuis-Oudshoorn, K., 2011. mice: Multivariate imputation by

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention which specific deep learning framework was used to build the described deep learning models. However, it mentions "stochastic gradient descent" as part of the optimization process, which is commonly used in many popular deep learning frameworks like TensorFlow and PyTorch. Additionally, there is a reference to a paper titled "Pytorch-BigGraph: A Large-Scale Graph Embedding System," suggesting that PyTorch might have been used in some capacity during the research or development process. Nonetheless, without explicit confirmation from the authors or additional context, it cannot be definitively stated which deep learning framework was used to build the deep learning models discussed in the given text.