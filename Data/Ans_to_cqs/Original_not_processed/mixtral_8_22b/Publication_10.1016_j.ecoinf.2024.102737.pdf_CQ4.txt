Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Data Augmentation Usage: We examined the effect of data
augmentation using the image transformations mentioned above (for
the BR ray detection step) on each of the original individual labeled
database images. The transformations considered here do not
include rotations, which were examined for handling different poses
(see below).

13 We used the following hyper-parameters: epoch = 25, nb filter = [64, 128,
128, 256], Adam optimizer with learning rate = 0.0001, beta1 = 0.9, beta2 =
0.999, epsilon = None, decay = 0.0, amsgrad = False.
14 Note that we do NOT claim that the loss function choice has made a dif-
ference as we did not compare to other loss functions. We only justify our
choice by previous work.

EcologicalInformatics82(2024)1027379A. Levy et al.

In addition, using data augmentation gave inferior results to using
the feature extraction enhancement method in which these augmenta-
tion methods are useless. Nevertheless, we further examined this issue in
the next experiments.

2. on the other hand, a practically reasonable pipeline for recognition
can be achieved despite the problem specification challenges, using a
careful examination of different factors, such as pose handling, while
bearing some surprises to the Computer Vision community, e.g., the
advantage of a feature-extraction enhancement (avoiding data
augmentation) over using augmentation techniques.

Preprocessing the input instead of relying on data augmentation is a
preferred way with significantly better results, seemingly by-passing the
difficulty of the Siamese network to learn similarity in the presence of so
few examples. It could be, however, that there is still a better way to by-
pass this difficulty but also exploit the power of augmentations.

CRediT authorship contribution statement

The following data augmentation techniques were used by applying
standard functions from the IMGAUG library of openCV (imgaug, 2020)
(see Fig. 3):

• Adding Gaussian noise in the range 0 (cid:0) 255*0.2: We used this
technique to create more low-resolution resembling images that
users might upload. Two augmentations of this type were performed
with different choice in the specified range.

• Sea waves distortion with alpha = 50 and sigma = 9: We used this
technique to create more images where sea waves effect is reflected.
• Blurring effect in the range (0.75, 1.5): We used this technique to
create more unclear images, as some of our original images were.
Two augmentations of this type were performed with different
choice in the specified range.

3.1. Data and code description

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study examines the use of several data augmentation techniques in their deep learning pipeline. These techniques include adding Gaussian noise, creating sea wave distortions, and applying blur effects. Specifically, they added Gaussian noise within the range of 0 to 255*0.2 to generate lower resolution images. They created sea wave distortions using alpha=50 and sigma=9 to simulate the appearance of sea waves. Lastly, they applied blur effects within the range of 0.75 to 1.5 to mimic the appearance of unclear images. However, it should be noted that the authors found that preprocessing the input was preferred over using data augmentation due to its superior performance. Despite this finding, they continued to explore the potential benefits of combining both approaches.

Reference(s):
Levy, A., et al. Ecological Informatics, 82(2024), 1027379.