Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

mainly three settings can be adjusted in BirdNET: the detection sensi-
tivity,  overlap  of  prediction  segments,  and  the  minimum  confidence 
threshold (Kahl et al., 2021). We set these values to 1.5 (highest allowed 
value),  1.5  s  of  overlap,  and  0.4,  respectively.  The  low  confidence 
threshold may result in increased recall and false positive rates, but the 
value employed was similar to the one used by Kahl et al. when evalu-
ating BirdNET accuracy on 984 bird species (value of 0.5, Kahl et al., 
2021).

as  the  validation  dataset  to  assess  the  performance  of  BirdNET  and 
Kaleidoscope  Pro.  The  software  performance  was  evaluated  by 
comparing the recall rate and the percentage of occurrences detected 
using each software when compared to the ones obtained in the vali-
dation dataset. The recall rate is an index commonly used in bioacoustics

technique. For example, Cole et al. (2022) recently evaluated BirdNET 
for detecting 13 bird species in North America and found that the recall 
rate  ranged  from  9%  to  68%.  Similarly,  the  recall  rate  obtained  by 
Tolkova et al. (2021) ranged between 11% and 71% for three common 
bird species. Previous research has claimed that the accuracy of BirdNET 
increases when analysing bird songs of species that BirdNET was more 
familiar with (Arif et al., 2020). The Eurasian bittern is a widespread 
species, with over 900 recordings uploaded to Xeno-canto database and 
the Macaulay library of sounds, which may have contributed to the high 
recall  obtained  when  using  BirdNET  with  that  target  species.  We  are 
aware that we did not verify BirdNET detection, and therefore cannot 
rule  out  some  false  positives  (mislabelled  vocalizations)  within  the 
BirdNET  output. However,  no BirdNET  detection occurred  within  the

et al., 2021; Stowell et al., 2019). Some of the state-of-the-art techniques 
for  handling  big  datasets,  such  as  deep  learning  and  convolutional 
neural networks (Stowell, 2022; Stowell et al., 2019), can be difficult to 
run for ornithologists, managers, and researchers without bioacoustics 
or  engineering  backgrounds.  However,  user-friendly  and  ready-to-use 
machine  learning  approaches  have  recently  been  developed  and  are 
increasingly accessible to respond to real-life monitoring challenges and 
the general public (Cole et al., 2022). Among these approaches is Bird-
NET, a research project between The Cornell Lab of Ornithology and the 
Chemnitz University of Technology. BirdNET facilitates the automated 
detection and classification of bird vocalizations, through a developed 
deep neural network, from sound recordings (Kahl et al., 2021). Bird-
NET is able to identify over 3000 bird species (Wood et al., 2021) and is

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model, specifically BirdNET, is evaluated using two main metrics: the recall rate and the percentage of occurrences detected. The recall rate is a measure of how many true positive predictions were made out of all actual positive instances. In other words, it measures the proportion of correctly identified bird vocalizations among all actual bird vocalizations present in the data. This metric is also known as sensitivity or true positive rate. The percentage of occurrences detected refers to the number of times the model successfully identifies a specific bird species or vocalization in comparison to the total number of instances where that particular species or vocalization occurs in the validation dataset. These evaluation methods are widely used in bioacoustic studies, including recent works like those conducted by Cole et al. (2022) and Tolkova et al. (2021).