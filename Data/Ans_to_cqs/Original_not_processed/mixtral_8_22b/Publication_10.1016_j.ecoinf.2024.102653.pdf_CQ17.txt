Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2. Methods 

Fig. 2 summarizes a series of processes in designing a deep-learning 
architecture that acts as a toxicovigilance tool. Subsequent sections will 
provide a comprehensive description of each section. 

2.1. Data collection

In the proposed architecture, the model employs dual BiLSTM layers 
in its structure. Following each BiLSTM layer, dropout regularization is 
incorporated to mitigate the risk of overfitting. Specifically, this regu-
larization method entails the random deactivation of 50% of the neural 
connections (Srivastava et al., 2014). After these first layers, the archi-
tecture introduces a densely connected layer comprised of 128 neurons. 
This  layer  utilizes  a  Rectified  Linear  Unit  (ReLU)  activation  function 
(Nair and Hinton, 2010). A mechanism was proposed to facilitate the 
classification  of  the  processed  sequences,  as  depicted  in  Fig.  3.  The 
model  harnessed  the  capabilities  of  the  NVIDIA  CUDA  Deep  Neural 
Network  (cuDNN)  library  to  enhance  computational  efficiency  and 
reduce training duration, as presented by Chetlur et al. (2014). 

2.4. Model training and hyperparameters

2.6. Performance metrics 

Conventional  metrics  were  used  to  evaluate  the  model’s  perfor-
mance, such as confusion matrices, accuracy, recall, precision, F1-score, 
Cohen  Kappa,  and  the  area under  the  ROC curve,  some of  which  are 
defined below (Johnson and Khoshgoftaar, 2019).  

Table 1 
List of hyperparameters utilized for training the Recurrent Neural Network 
model.  

Hyperparameter 

Value 

Optimizer 
Learning rate 
Batch size 
Epochs 
Dropout rate 
Loss function 

ADAM (Kingma and Ba, 2017) 
0.003 
32 
100 
0.5 
Binary Cross Entropy  

●  Confusion Matrix

2.4. Model training and hyperparameters 

The  model’s  weights  were  randomly  initialized  using  a  specific 
integer seed to guarantee consistent reproducibility of results. Further-
more, meticulous manual tuning of hyperparameters was conducted to 
achieve  optimal  model  performance.  The  selected  hyperparameters, 
which yielded the best performance metrics, are presented in Table 1. 

2.5. Model validation 

Two distinct validation methodologies were implemented. The first 
method  involved  partitioning  the dataset into  training and  validation 
sets, with 70% of the data designated for training and 30% for valida-
tion.  This  division  was  performed  through  random  selection  (Dobbin 
and Simon, 2011).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: In the described deep learning architecture, the method employed to prevent overfitting is dropout regularization. Dropout regularization involves the random deactivation of a certain percentage of the neural connections during training. In this case, 50% of the neural connections are randomly deactivated after each BiLSTM layer. This technique helps to reduce the co-dependency between nodes, thus preventing overfitting and improving the generalizability of the model. Other common regularization techniques include L1 and L2 regularizations, but they are not mentioned in the given context.