Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  results  indicate  that  the  Cascade  RCNN  outperformed  other 
models at each training stage, while the FCOS model and Sparse CNN 
model consistently had lower mAP scores than others. This is consistent 
with  the  findings  of  Section  3.1.  Although  12  epochs  were  a  typical 
number of training times, almost all models reached the maximum mAP 
when the number of epochs reached 10. Therefore, for bird recognition, 
not  all  models  are  better  with  more  training  times,  and  choosing 

appropriate  training  times  for  different  models  is  beneficial  to  save 
computing resources. Specifically, the Cascade RCNN model had almost 
no  increase  in  the  mAP  at  9  epochs,  and  the  Faster  CNN  model  also 
showed a similar trend. However, the ATSS and RepPoint growth curves 
continued to 12 epochs, suggesting they require more training data or a 
longer training schedule to perform better.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Object detection 
Bird detection 
Deep learning 
Camera trap

The  Faster  RCNN  model  initially  achieved  a  relatively  high  mAP 
score of 0.568 in epoch 7; however, its performance plateaued in sub-
sequent  epochs,  suggesting  that  further  improvements  may  require 
modifications  to  its  architecture  or  hyperparameters.  In  contrast,  the 
Sparse RCNN model showed a slow start, with its mAP score increasing 
from 0 in epoch 1 to 0.324 in epoch 4, but achieved a steady increase in 
performance after that. 

Overall, these results suggest that Cascade RCNN and ATSS are the 
most effective models for object detection on camera trap images, while 
Faster  RCNN,  RetinaNet  and  RepPoints  are  also  viable  options.  How-
ever, FCOS and Sparse RCNN may not be suitable for this task, given 
their slower and less stable convergence and lower mAP scores. 

3.4. Baseline detectors with different backbones

Sutherland, C., Matthews, N., Mudde, J., Nuseibeh, A., 2023. Removing human 
bottlenecks in bird classification using camera trap images and deep learning. 
Remote Sens. 15, 2638. 

Chen, K., Wang, J., Pang, J., Cao, Y., Xiong, Y., Li, X., Sun, S., Feng, W., Liu, Z., Xu, J., 
2019. MMDetection: open mmlab detection toolbox and benchmark arXiv preprint 
arXiv:1906.07155.  

Clarfeld, L.A., SirÂ´en, A.P., Mulhall, B.M., Wilson, T.L., Bernier, E., Farrell, J., Lunde, G., 
Hardy, N., Gieder, K.D., Abrams, R., 2023. Evaluating a tandem human-machine 
approach to labelling of wildlife in remote camera monitoring. Eco. Inform. 77, 
102257. 

Cove, M.V., Kays, R., Bontrager, H., Bresnan, C., Lasky, M., Frerichs, T., Klann, R., 

Lee Jr., T.E., Crockett, S.C., Crupi, A.P., 2021. SNAPSHOT USA 2019: a coordinated 
national camera trap survey of the United States. Ecology 102, e03353. 
Cunha, F., dos Santos, E.M., Colonna, J.G., 2023. Bag of tricks for long-tail visual

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The article does not provide specific information about the hyperparameters used in the deep learning models, such as learning rates or optimizers. It focuses primarily on comparing the mean average precision (mAP) scores of various models like Cascade RCNN, FCOS, Sparse CNN, Faster RCNN, ATSS, and RepPoint when applied to bird recognition tasks using camera traps. The study reveals that Cascade RCNN performed best among them, reaching peak performance at around 10 epochs, while some models like ATSS and RepPoint required longer training schedules. However, details regarding the exact hyperparameter settings employed during the training process remain undisclosed within the available context.