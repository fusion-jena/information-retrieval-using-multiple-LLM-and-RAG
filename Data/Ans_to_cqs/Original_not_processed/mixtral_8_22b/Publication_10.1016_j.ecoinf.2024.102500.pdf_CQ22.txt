Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

maximum depth, minimum sample split, and learning rate (Bolick et al., 
2023). These refined hyperparameters are selected to enhance the ac-
curacy and predictive capabilities of the models, rendering them suit-
able for effective utilization in academic research and publications.

Table  2  lists  nine  grid  search  ML  models  with  fivefold  cross- 
validation for four WQPs and hyperparameters. Model evaluation and 
hyperparameter selection use cross-validation resampling. The dataset is 
split  into  five  equal-sized  folds  using  fivefold  cross-validation.  Five 
times, one of each fold, the training and assessment process is validated. 
A  more  complete  model  performance  analysis  is  possible.  Averaging 
coefficient of determination (R2) or RMSE across five iterations with five 
folds  improves  model  performance  and  hyperparameter  tuning  effi-
ciency estimation. The Python library’s randint command picks integers 
within a range for hyperparameters like n_estimators and max_depth. We 
use  the  uniform  command  for  discrete  or  continuous  values  inside  a 
range,  like  the  min_samples_split  hyperparameter.  These  commands 
examined  multiple  hyperparameter  value  ranges  to  establish  model

3.2.2.8. LGBM  hyperparameter  tweaking. Table  2  shows  the  LGBM 
model  hyperparameters  selected  for  nitrate  and  DO  prediction  to 
maximize  performance.  Subsamples  reduce  overfitting  and  min_-
child_samples  control local pattern  sensitivity. Overfitting is  prevented 
via reg_lambda. As mentioned, n_estimators, learning_rate, max_depth, and 
random_state were used. 

3.2.2.9. GB  model  hyperparameter  tuning. As  seen  in  Table  2,  the 
hyperparameter values for the nitrate and DO model are reported below. 
As described in the preceding sections, each of these parameters is uti-
lized. These hyperparameter settings were carefully chosen to enhance 
the nitrate and DO model performances.

4.3.4. Do 

The statistical markers for DO prediction in the training and testing 
phases  for  various  models,  including  RF,  ET,  LGBM,  GB,  HGBM,  and 
XGB,  are  shown  in  Table  6.  Comparing  bagging  models  to  boosting 
models,  bagging  models  demonstrated  a  better  correlation  for  DO 
prediction. 

RF  outperformed  the  other  models  with  training  and  testing  R2 
values  of  0.76  and  0.66  and  RMSE  values  of  0.36  and  0.45.  The  RF 
model’s MBE, MAE, D, and NSE values lowered inaccuracy and had a 
substantial input-DO association. The RF model was used in the study of 
Derot  et  al. (2020)  to  forecast phytoplankton bloom with  the help  of 
high frequency dataset. Lap et al. (2023) also found RF to be the most 
appropriate ML model in prediction of WQI. 

The  two  bagging  models,  RF  and  ET,  and  the  three  boosting

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In the given context, the performance of the machine learning models is evaluated using several metrics. For dissolved oxygen (DO) prediction, the statistical markers used include coefficient of determination (R2), root mean square error (RMSE), mean bias error (MBE), mean absolute error (MAE), Nash–Sutcliffe efficiency (NSE), and index of agreement (D). Among these, R2 and RMSE are the primary metrics used to assess the performance of the models.

For instance, Random Forest (RF) outperforms other models with training and testing R2 values of 0.76 and 0.66, respectively, and RMSE values of 0.36 and 0.45, respectively. Additionally, the RF model has lower MBE, MAE, D, and higher NSE values, indicating reduced inaccuracies and substantial input-DO associations.

However, it should be noted that the context does not provide information on the specific metrics used to evaluate the performance of the Light Gradient Boosting Machine (LGBM), Gradient Boosting (GB), Histogram-based Gradient Boosting (HGBM), and Extreme Gradient Boosting (XGB) models. Nevertheless, based on the available information, we can infer that similar metrics such as R2, RMSE, MBE, MAE, NSE, and D may have been used to evaluate their performance.