Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Journal Pre-proof

where T is the total number of trees in the forest; Mj(t) is the set of all nodes in tree t where feature 

Xj is used for splitting; Nm is the number of samples reaching node m; N is the total number of 

samples; I(t) is the variance impurity of the parent node; I(tL) and I(tR) are the variance impurities 

of the left and right child nodes, respectively; Nt is the number of samples in the parent node; NL 

and NR are the numbers of samples in the left and right child nodes, respectively; yi is the target 

value of the i-th sample; ym is the mean target value of the samples in the node. 

The size of the decision trees was further optimized to improve our predictive capacity (see 

Tables S1-S2). Our ability to predict Chl a was examined with different time lags, ranging from 0 

to  10  days,  which  were  implemented  uniformly  (i.e.,  same  time  lag  per  iteration)  across  the

study,  the  dataset  was  randomly  divided  into  two  subsets,  the  first  one  was  used  as  a  training 

dataset  to  learn  the  optimal  model  structure  and  the  second  as  a  validation  dataset  to  test  its 

performance;  75%  of  the  data  were  devoted  to  model  training  and  25%  to  testing.  Given  the 

well-documented robustness of RF algorithms to randomly receive training data from subsets and 

establish models with high predictive capacity, we opted for random (instead of cluster) sampling 

with  one  major  condition  to  maintain  the  covariance  structure  among  the  predictor  variables 

relatively intact between the training and testing datasets. 

,(),,,(,)maxlogmin(,)xyBnIXYxyMICXYxy),,,(*yxYXI 
Journal Pre-proof

RF  modeling  can  generally  be  resilient  to  preprocessing  burdens  (e.g.,  no  feature  scaling, 

robustness  to  outliers),  flexible  with  multi-dimensional  data,  sensitive  in  elucidating  complex

methods. Environmental Pollution 297, 118759.   

Wai, K.P., Chia, M.Y., Koo, C.H., Huang, Y.F., Chong, W.C., 2022. Applications of deep 

learning in water quality  management: A state-of-the-art review. Journal of Hydrology  613, 

Journal Pre-proof

Wang, C., Xie, W., Li, T., Wu, G., Wu, Y., Wang, Q., Xu, Z., Song, H., Yang, Y., 2023. 

Analysis of Spatial and Temporal Variation in Water Coverage in the Sub-Lakes of Poyang 

Lake Based on Multi-Source Remote Sensing. Remote Sensing 15, 2788.   

Wang, H., Meng, Y., Wang, H., Wu, Z., Guan, X., 2023. The application of integrating 

comprehensive  evaluation  and  clustering  algorithms  weighted  by  maximal  information 

coefficient  for  urban  flood  susceptibility.  Journal  of  Environmental  Management  344, 

118846.   

Wang,  M.C.,  Liu,  X.Q.,  2002.  Evaluate  method  and  classification  standard  on  lake 

eutrophication. Environmental Monitoring in China 18,47-49.

(Poyang Lake, China). Journal of Hydrology 585, 124810.   

Lu,  Y.,  Tuo,  Y.,  Xia,  H.,  Zhang,  L.,  Chen,  M.,  Li,  J.,  2023.  Prediction  model  of  the 

outflow  temperature  from  stratified  reservoir  regulated  by  stratified  water  intake  facility 

based on machine learning algorithm. Ecological Indicators 154, 110560.   

Nelson, N.G., Munoz-Carpena, R., Phlips, E.J., Kaplan, D., Sucsy, P., Hendrickson, J., 

2018. Revealing biotic and abiotic controls of harmful algal blooms in a shallow subtropical 

lake  through  statistical  machine  learning.  Environmental  Science  &  Technology,  52, 

3527-3535.   

Oliver,  R.L.,  Mitrovic,  S.M.,  Rees,  C.,  2010.  Influence  of  salinity  on  light  conditions 

and phytoplankton growth in a turbid river. River Research and Applications 26, 894-903.   

Ouyang,  S.,  Chen,  Z.,  Chen,  S.,  Zhao,  J.,  2023.  Prediction  of  Freezing  of  Gait  in

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the dataset was randomly divided into two subsets for deep learning model training. The first subset was used as a training dataset to learn the optimal model structure, while the second subset was used as a validation dataset to test its performance. Approximately 75% of the data were devoted to model training, and 25% to testing. Random sampling was employed instead of cluster sampling, with the main condition being to maintain the covariance structure among the predictor variables relatively intact between the training and testing datasets. This approach leverages the well-documented robustness of RF algorithms to randomly receive training data from subsets and establish models with high predictive capacity.