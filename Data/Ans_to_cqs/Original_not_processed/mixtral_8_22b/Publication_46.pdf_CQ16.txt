Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.5. Model Validation

All of the input parameters are resampled in a single grid size of 100 m and are
converted into the same ﬁle format. Out of the in-situ occurrences of Rhododendron arboreum
at ground locations, only 70% of the data were used in calibrating the model, whereas
the remaining 30% of the data were used to test the model. In any type of modelling,
performance evaluation is an essential task. In terms of validation of species probability
distribution, the AUC (Area Under ROC (Receiver Operating Characteristics) Curve) is
one of the most used performance evaluation metrics [67]. The primary application of the
ROC curve is in the threshold independent assessment that characterizes the model perfor-
mance at various discrimination thresholds. This application was found in raster-based
studies focusing on predicting land use and land cover, species distribution modelling, risk
assessment, and other probability mappings.

3.4. Model Validation and Comparison

The accuracy or performance of the probability distribution of the incorporated models
was compared using the AUC, TSS, and kappa coefﬁcient that characterize the performance
of the models with an in situ validation dataset. Table 2 shows the statistical performance
for BIOCLIM and CNN based the probability distribution of Rhododendron arboreum. A
lower AUC value was obtained by the BIOCLIM models, which is 0.639, based on the in situ
points reserved for the validation purpose. The AUC values for the CNN-based probability
distribution was found to be 0.917, which is considered to be very good compared to
the BIOCLIM that was given an AUC of 0.68. In addition to the AUC value, TSS and

Remote Sens. 2021, 13, 3284

13 of 17

A pooling layer offers downsampling functionality that decreases the dimensionality
of the feature maps to achieve translation invariance to the alterations and the biases
incorporated and thus helps in reducing the number of learnable parameters. There are
two types of pooling operations, namely Max Pooling and Global Average Pooling [64].
The ﬁrst one extracts speckles from the input feature maps and offers maximum values
in each of the speckles and leaves the remaining values unattended. The second one
downsamples a feature map with a size equaling product of height and width into an array
of a one cross one by averaging the elements of each feature map by retaining the depth of
the feature map. The advantage of Global Average Pooling lies in reducing the number of
learnable parameters along with offering the CNN with variable sized input.

of weights between the neurons in the adjoining layers and will maximize the network
performance, which would help the neurons focus on speciﬁc patterns in the data. In the
ﬁnal layer, the parameters are passed through the SoftMax function, which transforms
them into probabilities that sum to 1, as shown in Equation (1).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the provided context, there isn't explicit information about the specific criteria used to determine when training is complete. However, it does mention the importance of model validation and performance evaluation in modeling tasks.

Model validation typically involves setting aside a portion of the available data (usually around 30%) to evaluate the trained model's performance. This process can provide insights into whether the model has been adequately trained or if further adjustments are needed.

One common criterion used to assess the completion of training is the observation of a validation loss plateau. When the validation loss stops improving significantly after several epochs, this may indicate that the model has learned all it can from the training data and no longer benefits from additional training. At this point, the training could be considered complete.

Additionally, the context mentions the use of Area Under Receiver Operating Characteristic Curve (AUC), True Skill Statistic (TSS), and Kappa coefficient as performance evaluation metrics for comparing the accuracy or performance of different models. These metrics can also serve as indicators of how well the model has been trained and whether further training is necessary.

However, without more specific details regarding the training process mentioned in the context, it is not possible to definitively state what criteria are being used to determine when training is complete.