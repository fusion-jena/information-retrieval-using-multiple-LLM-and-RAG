Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Bootstrapping 
Generalised linear model 
Machine learning 
Multi-scale 
Random forest 
Species distribution modelling

To produce accurate SDMs, not just the effects of different algorithms 
should be investigated, but also the effects of resampling techniques on 
model's  training  data  (Efron,  1982;  Freedman,  1981).  Specifically, 
bootstrapping (i.e., random subsampling with replacement) the training 
data  has  been  shown  to  increase  models'  precision  by  providing  a 
combination of models, which reduces stochastic errors in estimation (e. 
g., Vaughan and Ormerod (2005); Hefley et al. (2014); Xu and Goodacre 
(2018)).

4.2. Scaling hypotheses

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

Not seeing the forest for the trees: Generalised linear model out-performs 
random forest in species distribution modelling for Southeast Asian felids 

Ë™
Zaneta Kaszta a, Eric Ash a, b,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The article does not provide explicit information about the specific postprocessing steps involved after the model training. However, based on general machine learning practices, some common postprocessing steps include evaluating the performance of the trained model using metrics such as accuracy, precision, recall, or F1 score, creating confusion matrices to visualize the performance of the classifier, generating saliency maps to understand the importance of each feature in predicting the target variable, and fine-tuning hyperparameters to improve the model's performance. These steps can help ensure that the model is robust and reliable before it is deployed for real-world applications.