Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

offering high numbers of images per taxon, which is more difficult to

200 images in each of the three datasets used here. However, the

obtain locally, although it is critical for increasing the performance of

degree of accuracy is greatly affected by the image quality and the

the CNN-based classification (Figure 2; Donahue et al., 2013; Valan

complexity of the dataset: both the LL (low image quality) and in

et al., 2019, 2021).

(a)

(b)

F I G U R E 6

Prediction probabilities for the successful, failed and out-of-distribution predictions at a 0.95 threshold (horizontal line). (a) Intra-
dataset predictions of LH images using 400 randomly selected images for training. (b) Predictions of LH images using 800 GH images for training.

and TensorFlow 2.5.0 (https://www.tensorflow.org) libraries, and all

statistical analyses were conducted with R 4.1.0 (R Core Team, 2021).

Between-datasets classification

For the between-dataset prediction, the CNN model was trained with

RE SU LT S

a source dataset to predict images from a different target dataset. The

NN was trained with N images randomly selected from the source

Performance of within-dataset classification

dataset, which was then used to predict all images of the target data-
set and AccT and ΔAcc were measured. We ran the above procedures
for three source–target pairs (training dataset!predicted dataset),
GH!LH, GH!LL and LL!LH. These settings simulate two alternative
scenarios: (i) a global image database is used to predict local samples
(GH!LH and GH!LL) and (ii) conventional

images, as

those

Effects of datasets and the number of images

The accuracy of within-dataset classification and the effect of the

to the effect of image quality. When the LL images were used to train
the NN and then to predict the LH images, the accuracy remained
largely constant at 71% for 250 images (Figure 2b). The accuracy
reduction ΔAcc, that is, the reduction in success of predictions com-

pared to the predictions expected from within-dataset classification,
rapidly increased with the number of images (Spearman rho = 0.72,

p < 0.001), indicating that the training with LL images did not improve
the prediction of the LH images (Figure 3).

Next, we considered the critical question about the power of the

global dataset to predict the local data, using the GH and the LH as a
source–target pair. The prediction accuracy for this comparison was

accuracy increased by 6.2% (p < 0.001, Figure 4b) and the accuracy

reduction decreased by 0.060 when the DANN model was used with

training was done using taxon labels from the source images and data-

training images on prediction accuracy, whereby the CNN model was

trained with N images randomly selected from the dataset and predicted

the class (family label) of n test images randomly selected from the rest.

N ranged between 100 and 700 for LH (with intervals of 100 images),
between 50 and 250 for LL (with intervals of 50 images) and between
100 and 900 for GH (with intervals of 100 images). The number of test
images n was set to 200 for LH and GH, and 50 for LL due to the small
size of the dataset. To evaluate the consistency of prediction accuracy,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, the study primarily focuses on image data for its deep learning pipeline. Specifically, the research uses high-resolution images of various taxonomic groups (taxa) to train and validate Convolutional Neural Networks (CNNs) for species identification tasks. Although other types of data such as audio or video might be relevant for similar studies, they are not mentioned in the provided context. Therefore, based solely on the information available, the primary data format used in this deep learning pipeline appears to be images.