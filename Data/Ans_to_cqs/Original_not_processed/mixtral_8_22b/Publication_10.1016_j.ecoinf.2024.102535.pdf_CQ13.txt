Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Each rectangle indicates the operations performed at a block of layers. Conv and SConv stand for regular convolution and depth-wise separable 
convolution, respectively. The values that follow such operations indicate the number of filters, filter size, stride, and dilation rate. Regarding the 
maxpooling operation, the values correspond to the kernel dimension and stride. Dropout refers to the number of neurons randomly turned off during 
each training inference. The number of neurons in the dense layer of the classifier module corresponds to the number of classes in the dataset. 

All architectures were modified mainly in the block of fully connected layers, where we opted to use just the output layer after the feature extractor 
instead of two fully connected layers. Additionally, residual blocks were used at the architectures’ stems rather than in the full feature extractor. All 
those modifications were experimentally determined.

The  experimental  results  suggest  that  there  might  be  room  to 
improve the generalization capacity of the deep learning classifiers. That 
could  be  achieved  by  better  exploiting  the  training  data,  e.g.,  with 
additional data augmentation techniques, using recent advances in un-
supervised learning techniques, such as self-supervised methods, or by 
just simplifying the classifiers in terms of the number of parameters, thus 
reducing the risk of overfitting. 

Another direction for continuing this research is to exploit the clas-
sification uncertainty further in an active learning context. The uncer-
tainty measure could be used in interactively training the deep learning 
models,  selecting  high-uncertainty  samples  in  the  datasets,  and 
increasing their importance in the computation of the loss function. 

CRediT authorship contribution statement

(6)  

(7) 

In both equations, N stands for the number of training images, xn  is 
the n (cid:0)
th training image, while yn  represents the true label (or labels) 
codified in a one-hot vector of xn. Furthermore, h(xn) corresponds to a 
vector comprising the predicted likelihood values for each class of xn, 
computed  with  the  learned  function  h(⋅).  Additionally,  wc = N
Nc  is  the 
weight of each class c ∈ C, which comprises Nc  images. 

During  training,  the  inputs  to  the  networks  were  patches  with  di-

Due to its success in modeling complex problems, DL, characterized 
by neural networks encompassing more hidden layers and learning pa-
rameters  than  their  predecessors,  represents  a  promising  alternative. 
Additionally,  the  increasing  availability  of  optical  imagery  datasets 
organized into large-scale temporal habitat maps is very convenient for 
evaluating  the  performance  of  DL-based  techniques  in  deep-water 
studies. However, the limited availability of labeled data for properly 
training DL models in that context still remains a major obstacle.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: Unfortunately, the given context does not provide information on the specific hyperparameters used in the deep learning model, such as the learning rate or the type of optimizer employed. It primarily focuses on describing the architecture of the model, including the types of convolutions used, the number of filters, filter sizes, strides, and dilation rates. Information about max pooling dimensions and dropout percentages is also included. However, details regarding the learning rate, optimizer, batch size, epochs, or any other hyperparameters related to the training process are not mentioned in the provided context.