Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

accuracy  limits  that  we  encountered  training  DNN  models  with  the 
detailed-labelled NIPS4Bplus dataset (Bravo Sanchez et al., 2021). We 
drilled down on the results using another high-quality model (BirdNET) 
and  compared  it  to  our  SincNet  trained  models.  For  that,  we  experi-
mented  with  dimensionality  reduction  of  embeddings  and  an  initial 
dimensionality reduction technique (t-SNE). We generated embeddings 
using  the  BirdNET  model  on  a  randomly  selected  40%  sample  of  the

Neural information processing scaled for bioacoustics-from neurons to Big Data. In: 
Proceedings of Neural Information Processing Scaled for Bioacoustics: From Neurons 
to Big Data, 2013. http://sabiod.univ-tln.fr/NIPS4B2013_book.pdf. 

Gupta, Gaurav, Kshirsagar, Meghana, Zhong, Ming, Gholami, Shahrzad, Ferres, Juan 

Lavista, 2021. Comparing recurrent convolutional neural networks for large scale 
bird species classification. Sci. Rep. 11 (1), 17085. https://doi.org/10.1038/s41598- 
021-96446-w. 

He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, 2015. ‘Deep residual learning 

for image recognition’. arXiv. http://arxiv.org/abs/1512.03385. 

Hershey, Shawn, Chaudhuri, Sourish, Ellis, Daniel P.W., Gemmeke, Jort F., Jansen, Aren, 
Moore, Channing, Plakal, Manoj, et al., 2017. CNN Architectures for Large-Scale 
Audio Classification. In: International Conference on Acoustics, Speech and Signal 
Processing (ICASSP).. https://arxiv.org/abs/1609.09430.

has a frame size of 16 milliseconds and frame shift of 1 millisecond that 
are averaged over the labelled sound to obtain a prediction. In the same 
way we averaged the outputs of the penultimate layer of the model to 
obtain embeddings for each labelled sound that have 4096 dimensions. 
The ResNet152-architecture is based on the ResNet152 model (He 
et al., 2015) developed for image classification, but we did not use pre- 
trained weights. We relied on Keras (Chollet et al., 2015) implementa-
tion of ResNet152 to obtain the model architecture, added a dense layer 
and trained the models from scratch with randomly initialised weights. 
The input was 3 s sound frames converted into mel spectrograms using a 
fast Fourier transform window size of 1024, hop length of 896 and 128 
mel filterbanks. The resulting models had around 58 million trainable 
parameters.  We  trained  two  types  of  models  using  extracts  from  the

DNN  are  algorithms  consisting  of  neurons  arranged  in  successive 
layers that apply computations based on learnable parameters (weights 
and  bias)  and  activation  functions  to  inputs  from  previous  layers, 
through to an output consistent with the training data. Different types of 
layers  (convolutional,  pooling,  flatten,  etc.)  may  combine  in  large 
numbers to create complex algorithms that are difficult to interpret and 
often referred to as ‘black boxes’ (McGinn et al., 2023; Stowell, 2022). It 
is virtually impossible to follow how they use millions of parameters to 
reach a particular decision for any given input. Consequently, there is an 

array of tools and procedures to try to understand some of their inner 
workings. Here, we focus on the improved utilisation of one technique 
referred to as “analysis of embeddings”.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the provided context does not contain specific details about the hardware resources used for training the deep learning models mentioned. Therefore, I cannot provide accurate information regarding which hardware resources were utilized, such as GPUs or TPUs.