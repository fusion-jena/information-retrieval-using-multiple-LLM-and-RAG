Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The model is constructed using the EfficientNet B0 network (Tan and 
Le, 2019) which had been trained for generic image classification. The 
EfficientNet feature extraction layers are frozen (transfer learning) with 
only the weights of the final dense classification layers updated during 
training.  Training  was  conducted  within  the  Google  Collaboratory 
‘Colab’  platform  (Bisong,  2019),  using  the  Tesla  K80  GPU,  accessed 
through  cloud  computing.  An  Adam  optimizer  was  used  to  control 
gradient descent during training (Kingma and Ba, 2014), with parame-
ters set to: learning rate of 0.001, decay factor of 0.75 and a step size of 

EcologicalInformatics78(2023)1023632E.L. White et al.

way  ML  allows  the  automation  of  tasks  previously  considered  as 
requiring  manual  processing  (Stowell,  2022).  For  instance,  marine 
mammal  calls  have  been  classified  with  a  wealth  of  ML  algorithms 
including  support  vector  machines  (Jarvis  et  al.,  2008;  Roch  et  al., 
2008), generalised linear models, hidden Markov models (Brown et al., 
2010;  Pace  et  al.,  2012;  Roch  et  al.,  2011)  and  classification  and 
regression tree analysis (Oswald et al., 2003). These advances have led 
to a rise in the number of published trained CNN models available for 
researchers  to  download  and  use  as  tools.  The  performance  of  these 
CNNs has been found to rival human performance at signal recognition 
(LeCun et al., 2015). CNNs can learn to discriminate spectro-temporal 
information  directly  from  a  labelled  spectrogram,  used  as  an  image 
input. The success of CNNs within the marine bioacoustic field has been

Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., 2017. Grad- 
cam: visual explanations from deep networks via gradient-based localization. In: 
Proceedings of the IEEE International Conference on Computer Vision, pp. 618–626. 

Brown, J.C., Smaragdis, P., Nousek-McGregor, A., 2010. Automatic identification of 

Shiu, Y., Palmer, K.J., Roch, M.A., Fleishman, E., Liu, X., Nosal, E.M., Helble, T., 

individual killer whales. J. Acoust. Soc. Am. 128 (3), 93–98. 

Collum, L.A., Fritts, T.H., 1985. Sperm whales (Physeter catodon) in the Gulf of Mexico. 

Southwest. Nat. 101–104. 

Cholewiak, D., Gillespie, D., Klinck, H., 2020. Deep neural networks for automated 
detection of marine mammal species. Sci. Rep. 10 (1), 1–12. 

Stowell, D., 2022. Computational bioacoustics with deep learning: a review and 

Csurka, G. (Ed.), 2017. Domain Adaptation in Computer Vision Applications, Vol. 2. 

roadmap. PeerJ 10, e13152. 

Springer International Publishing, Cham.

(Fig.  1),  considering  its  performance  in  the  new  environment  with 
limited re-training. Starting with a pre-trained model (EfficientNet B0, 
Tan and Le, 2019), we freeze the networks original feature extractor. We 
then train fully connected layers, which operate on the output of the 
EfficientNet  B0  network,  to  classify  the  PAM  data  frames  into  the 
specified sound source classes. Audio data is input to the network in a 
novel  spectrogram representation (White  et  al.,  2022). Networks  pre- 
trained on image data have been proven to perform well on classifica-
tion  tasks  using  spectrograms  as  image  input,  transformed  from  raw 
audio data (Allen et al., 2021; Shiu et al., 2020; Stowell, 2022). In this 
work  we fine-tune the  parameters  of the fully connected layers  itera-
tively  on  small  batches  of  training  data  acquired  from  a  new  region. 
Through  an  experimental  approach  to  retraining  we  demonstrate  the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific information about the data annotation techniques used in the deep learning pipeline. However, based on common practices in machine learning and computer vision, some possible data annotation techniques could include bounding box annotation, semantic segmentation, or instance segmentation. Bounding box annotation involves drawing rectangles around objects of interest in images, while semantic segmentation involves labeling each pixel in an image with a corresponding class label. Instance segmentation combines both object detection and semantic segmentation by identifying individual instances of objects and their boundaries. Without more specific details, it cannot be determined which technique was used in this particular study.

Based on the given context, it appears that the authors used transfer learning with a pre-trained EfficientNet B0 network for feature extraction. They froze the original feature extractor and only updated the weights of the final dense classification layers during training. The audio data was input to the network in a novel spectrogram representation. It is unclear what type of data annotation techniques were used in this study, but based on common practices in machine learning and computer vision, some possibilities could include bounding box annotation, semantic segmentation, or instance segmentation.