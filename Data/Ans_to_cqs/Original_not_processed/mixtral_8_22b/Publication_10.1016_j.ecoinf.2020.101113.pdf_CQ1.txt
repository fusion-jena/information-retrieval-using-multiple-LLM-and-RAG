Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.3.  Model training 

2.3.1.  Training data preprocessing 

The  CNN  model  used  in  this  study  requires  equally  sized  input 
images. We chose a time-frequency input window size of 2 s as it is near 
the mean and median template duration across target call types (Fig. 2). 
Most  call  types  have  a  duration  below  1  s,  and  for  those  above  2  s,

The manual effort in training data creation was reduced to template 
creation and validation of template-based detections in a graphical user 
interface (Fig. 3). This addresses an important need for more accessible 
training  data  from  study  sites  to  leverage  deep  learning  for  acoustic 
monitoring.  Our  evaluation  demonstrates  that  strong  classification 
performance  can  be  achieved  using  data  collected  from  the  study  re-
gion,  without  relying  on  crowd-sourced  public  datasets.  The  pipeline 
thus  increases  the  potential  for  region-optimized  acoustic  monitoring 
systems.  Furthermore,  the  training  data  collection  pipeline  could  ac-
celerate the collection of data for rare species. 

Our  training  scheme  allowed  for  multi-label  learning  from  single- 
label  training  data  by  defining  a  custom  training  loss  and  including

Several challenges remain to be addressed for effective application 
of deep learning in acoustic monitoring. First, CNNs often require many 
training samples for each class. Large-scale species recognition efforts, 
such  as  for  the  BirdCLEF  challenge,  often  use  crowd-sourced  public 
training data from various geographic sources (e.g. Xeno-Canto dataset,  
Vellinga, 2020;), and thus far these public datasets focus on birds and 
consist  mainly  of  recordings  targeting  single  foreground  species. 
However,  as  mentioned  above,  geographic  variation  in  soundscapes 
could require training data collected at a local or regional scale for high 
performance. This, however, would greatly increase the data labeling 
effort.  Second,  the  non-directional  nature  of  soundscape  recordings 
demands  accurate  detection  as  well  as  classification  for  species  re-
cognition. Existing studies have demonstrated the difficulty of species

be  necessary  to  increase  the  training  data  size  for  rare  species.  Thus, 
future  efforts  should  investigate  optimal  data  augmentation  methods 
for  bioacoustic  recognition.  Third,  an  important  challenge  will  be  to 
maintain  high  accuracy  while  increasing  the  efficiency  of  prediction. 
This  will  require  increasing  the  prediction  speed  and  decreasing  the 
memory  footprint  of  the  model by  investigating  other  network archi-
tectures and reducing the number of parameters.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

In the given context, there isn't explicit information about the specific methods used for collecting raw data in the deep learning pipeline. However, we can infer some details based on the available information.

Firstly, the text mentions that the CNN model used in this study requires equally sized input images. These images seem to be derived from time-frequency input windows of 2 seconds, which were chosen due to their proximity to the mean and median template duration across target call types. This suggests that the raw data might be audio recordings, possibly from field surveys or sensor deployments, which are then processed into spectrograms or similar representations suitable for the CNN model.

Secondly, the context discusses the reduction of manual effort in training data creation through template creation and validation of template-based detections in a graphical user interface. This implies that the raw data might involve human intervention for creating templates and validating detections, potentially involving experts in the respective fields.

Lastly, the text highlights the importance of having data collected from the study region rather than relying on crowd-sourced public datasets. This indicates that the raw data might not solely rely on publicly available datasets but also include data specifically gathered for the study.

Therefore, although the exact methods for collecting raw data aren't explicitly stated, we can surmise that they likely involve audio recordings from field surveys or sensor deployments, with possible involvement of human expertise for template creation and validation. Additionally, the data collection process seems to prioritize gathering data from the study region over utilizing crowd-sourced public datasets.