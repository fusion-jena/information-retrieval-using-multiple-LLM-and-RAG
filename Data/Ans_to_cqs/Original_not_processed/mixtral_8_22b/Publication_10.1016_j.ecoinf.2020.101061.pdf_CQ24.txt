Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

20%. Given that the sites were selected to be as diﬀerent as possible,
and encompass a range of tree canopy conditions, this result under-
scores the ability of convolutional neural networks to learn ﬂexible
deep features. We expect that as more sites are included, the universal
model will continue to improve. This means that a way forward is to
combine pretraining from as many sites as possible. Given that each
NEON site has millions of trees, and there are dozens of sites with trees
collected annually, there is a possibility of pretraining on continental
scale. Because NEON sites are intended to represent all of the major
biogeographic regions in the United States, this broad scale pre-training
(in combination with existing local training data) has the potential to
reduce the need for new local training data by giving the model the
potential to learn the general suite of features characterizing trees (at
least those within the United States).

Collecting a suﬃcient number of training samples will often be a
bottleneck in developing supervised methods in airborne imagery. It is
therefore useful to test the number of local training samples needed to
achieve maximum performance. We performed a sensitivity study by
training models using diﬀerent proportions of training data. We se-
lected 5%, 25%, 50% and 75% of the total hand-annotations to com-
pare to the full dataset for the within-site results for each site. We reran
this experiment ﬁve times to account for the random subsampling of
annotations. In addition, we ran the evaluation plots for the pretraining
model only (i.e. 0% hand-annotated data) to assess whether the addi-
tion of hand-annotated data improved the within-site pretraining.

3. Results

2.2. Deep learning

We used our previously developed algorithm for RGB-based tree
identiﬁcation, which was used at a single site (Weinstein et al., 2019).

Fig. 1. Conceptual workﬂow of proposed approach for airborne de-
tection of individual tree crowns. Pretraining data is generated by
overlaying predicted trees from a LiDAR-based unsupervised algorithm
on to RGB imagery. These RGB images are used to pretrain a deep
learning neural network. The resulting model is retrained based on
RGB hand-annotations.

2

B.G. Weinstein, et al.

Ecological Informatics 56 (2020) 101061

Table 1
The number of tree annotations used for pretraining, retraining and evaluation.
Pretraining annotations are generated automatically using a LiDAR-based un-
supervised algorithm. Training and evaluation annotations were hand-drawn.

Forest type

Pretraining
annotations

Training
annotations

Evaluation
annotations

Oak Woodland
Mixed Pine
Alpine
Eastern Deciduous

550,905
2,522,855
3,121,036
3,131,283

2533
3405
9730
1231

293
747
1699
489

Alpine forest, and completely connected crowns in the Eastern
Deciduous forest.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To address the issue of randomness in the deep learning pipeline, such as variations due to different random seed values, the authors conducted a sensitivity study. They trained their models using different proportions of training data, specifically selecting 5%, 25%, 50%, and 75% of the total hand-annotations to compare against the full dataset for within-site results at each site. To account for the random subsampling of annotations, they repeated this experiment five times. Additionally, they evaluated the performance of the pretraining model alone (i.e., without any hand-annotated data) to determine if adding hand-annotated data improved the within-site pretraining. However, the text does not explicitly mention specific strategies to control or manage the randomness caused by factors like random seed values.