Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

WT-HMM using varying dataset sizes over 10 runs.

Ibrahim, A.K., Zhuang, H., Erdol, N., Muhamed Ali, A., 2018. Feature Extraction Methods 
for the Detection of North Atlantic Right Whale Up-Calls. In: 2018 International 
Conference on Computational Science and Computational Intelligence (CSCI), 
pp. 179–185. https://doi.org/10.1109/CSCI46756.2018.00042. 

Kahl, S., Wood, C.M., Eibl, M., Klinck, H., 2021. Birdnet: a deep learning solution for 

avian diversity monitoring. Eco. Inform. 61, 101236 https://doi.org/10.1016/j. 
ecoinf.2021.101236. 

Kaiser, G., Hudgins, L.H., 1994. A Friendly Guide to Wavelets, vol. 300. Springer. 
Ladyman, J., Lambert, J., Wiesner, K., 2013. What is a complex system? Eur. J. Philos. 

Sci. 3, 33–67.

Sequel to training the two HMMs independently, HMM1 and HMM2 
are combined to form an ergodic-type HMM with 8 states and 4 mixture 
weights. One of the HMMs is represented by the first 1–4 states, and the 
other  HMM  is  represented  by  the  following  5–8  states.  Specifically, 
states 1–4 depict the waveform of blue whale vocalizations while states 
5–8  represent  the  noise  signal.  Subsequently,  the  feature  vectors 
extracted from the test datasets are updated using the trained Gaussian 
parameters to produce refined feature vectors. The V-alg employs these 
refined feature vectors, along with T  and π, to classify the test dataset as 
either blue whale vocalizations or noise. It is noteworthy that that the V- 
alg switches from states 1–4 to states 5–8 with equal transition proba-
bilities. Table 1 shows the parameters used for WT-HMM simulation. 

3.2. Performance evaluation metrics

3. Experiments and results 

This section details the comprehensive investigation into blue whale 
vocalizations in the Antarctic region. The experimental parameters and 
different crucial steps, and performance evaluation metrics are detailed 
in the section. Additionally, the performance of the proposed WT-HMM 
with varying dataset sizes is presented, showcasing its robustness and 
scalability  across  different  temporal  subsets. The  section extends  to  a 
comparative study involving the WT-HMM and existing feature extrac-
tion  methods such  as PCA,  DMD, and MFCC  adopted with the HMM. 
Finally, the WT-HMM is compared with other machine learning models, 
including  Artificial  Neural  Network  (ANN),  Support  Vector  Machine 
(SVM),  and  Spectrogram  Correlation  Detector  (SCD),  over  different 
epochs. 

3.1. Simulation parameters and set-up

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the specific type of deep learning model used in the pipeline. However, it mentions that the proposed method is called WT-HMM, which suggests that it might be based on Hidden Markov Models (HMM). Furthermore, there is no mention of Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), or Transformers in the given context. Therefore, without additional information, we cannot determine the exact type of deep learning model used in the pipeline.