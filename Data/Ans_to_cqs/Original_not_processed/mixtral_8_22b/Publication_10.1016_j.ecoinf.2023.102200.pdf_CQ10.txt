Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Liu, T., Abd-Elrahman, A., 2018. Deep convolutional neural network training enrichment 
using multi-view object-based analysis of unmanned aerial systems imagery for 
wetlands classification. ISPRS J. Photogramm. Remote Sens. 139, 154–170. https:// 
doi.org/10.1016/j.isprsjprs.2018.03.006. 

Marasigan, R., Festijo, E., Juanico, D.E., 2019. Mangrove crown diameter measurement 
from airborne lidar data using marker-controlled watershed algorithm: exploring 
performance. In: 2019 IEEE 6th International Conference on Engineering 
Technologies and Applied Sciences (ICETAS). IEEE, pp. 1–7. 

Martins, J.A.C., Menezes, G., Goncalves, W., Sant’Ana, D.A., Osco, L.P., Liesenberg, V., 

Li, J., Ma, L., Oliveira, P.T., Astolfi, G., 2021. Machine learning and SLIC for tree 
canopies segmentation in urban areas. Ecol. Inform. 66, 101465 https://doi.org/ 
10.1016/j.ecoinf.2021.101465.

Individual  mangrove  trees,  low  shrubs,  and  other  classes  were 
labelled  manually  on  the  BEV  images,  and  the  BEV  images  with 
bounding  box  labels  were  used  to  train  the  Faster  R-CNN  detector. 
During the detector operation, the Faster R-CNN network with a Resnet- 
101 backend was trained for 20,000 iterations using Stochastic Gradient 
Descent (with momentum), with a learning rate of 0.003, momentum of 
0.9,  and  a  batch  size  of  1.  The  network  was  initialised  with  weights 
developed from training based on the MS COCO dataset.  

(2)  Individual Tree Detection and Segmentation.

Chen, X., Jiang, K., Zhu, Y., Wang, X., Yun, T., 2021. Individual tree crown segmentation 
directly from UAV-borne LiDAR data using the PointNet of deep learning. Forests 12, 
131. https://doi.org/10.3390/f12020131. 

Chen, J., Chen, Z., Huang, R., You, H., Han, X., Yue, T., Zhou, G., 2023. The effects of 

spatial resolution and resampling on the classification accuracy of wetland 
vegetation species and ground objects: a study based on high spatial resolution UAV 
images. Drones 7, 61. https://doi.org/10.3390/drones7010061. 

Danielsen, F., Sørensen, M.K., Olwig, M.F., Selvam, V., Parish, F., Burgess, N.D., 

Hiraishi, T., Karunagaran, V.M., Rasmussen, M.S., Hansen, L.B., 2005. The Asian 
tsunami: a protective role for coastal vegetation. Science 310, 643. https://doi.org/ 
10.1126/science.1118387. 

Do, A.N.T., Tran, H.D., Ashley, M., Nguyen, A.T., 2022. Monitoring landscape

Fig. 9. Segmentation results based on the light detection and ranging (LiDAR) data with BEV Faster R-CNN algorithm. (a) Low-density site. (b) Medium-density site. 
(c) High-density site. 

Table 6 
Statistics table of the segmentation results with the bird’s eye view (BEV) Faster 
region-based convolutional neural network (R-CNN) algorithm.  

Stand density 

Number 

LD site 
MD site 
HD site 

62 
67 
59 

TP 

54 
37 
26 

FN 

FP 

R 

P 

F 

5 
28 
31 

3 
2 
2 

0.915 
0.569 
0.456 

0.947 
0.949 
0.929 

0.931 
0.712 
0.612  

3.3. Effect of LiDAR point density on the CHM quality

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available to provide a direct link to the code repository for the deep learning pipeline mentioned in the given context. None of the cited papers or sources explicitly mention a specific code repository link such as those found on platforms like GitHub, GitLab, or BitBucket. Therefore, it is not possible to determine the exact location of the source code for this particular deep learning pipeline.