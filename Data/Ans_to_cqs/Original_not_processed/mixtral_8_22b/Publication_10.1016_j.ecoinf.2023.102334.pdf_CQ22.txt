Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To assess the classification accuracy of the model, the most intuitive 
and  straightforward  method  to  compute  was  employed,  which  is  the 
confusion matrix, as shown in Fig. 12. The confusion matrix was used to 
quickly  observe  the  performance  of  the  model  on  each  category  and 
calculate  the  accuracy,  precision,  and  other  evaluation  indicators  of 
each category. In the confusion matrix of the article, the data have been 
normalized in the row direction. The 6 rows and 6 columns represent 6 
categories, respectively. True denotes the actual image category of the 
sample and Precision refers to the category output by the model. The 
value of the main diagonal position in the matrix represents the ratio of 
the model to the correct prediction of each category; the sum of the data 
excluding the main diagonal position in each row represents the rate of 
the missed detection of this model for this category; in each column, the

61.42 
70.20 
45.51 
94.23 
137.49 
108.26 

Table 4 
Comparison of sheep face recognition results.  

Model 

Jwade et al. 
ResNet 
DenseNet 
Vision Transformer 
Swin Transformer 
Our model 

Accuracy(%) 

95.6 
90.96 
96.24 
97.47 
98.23 
98.58 

1.28G 
4.26G 
711.MB 
2.96G 
5.17G 
2.60G  

Loss 

16.35 
34.49 
15.80 
10.95 
13.41 
9.18  

shortcomings that should be addressed. First, the number of parameters 
in  our  method  needs  to  be  narrowed.  The  dataset in  this  work  is  the 
juvenile deer. Second, as the merganser grows, several trips to the deer 
farm should be made to collect face data to test and refine the proposed 
model until a general model of the deer from juvenile to adult phases has 
been completed. 

15. Conclusion

Model 

DenseNet 
Block 

ResNet 
Block 

Accuracy 
(%) 

Parameter size 
(MB) 

Flops 

14. Results and discussion 

Module1 and 
bulk of ViT 

The entire 
model 

√ 
×
√ 

×
√ 
×

92.58 
88.31 
97.68 

61.96 
80.81 
108.26 

1.57G 
2.51G 
2.60G  

The aim of this work was to investigate the use of computer vision 
techniques in the field of facial recognition of sika deer. Through the 
combined use of deep learning and Transformer, facial recognition of 

EcologicalInformatics78(2023)1023347H. Gong et al.                                                                                                                                                                                                                                    

Fig. 5. Overall model diagram based on ViT.

Under the condition of unchanged training methods and parameters, 
the results of each model listed in Table 3 were obtained. As compared to 
the  accuracy of  the  model in  this  work, the  VGG  model's recognition 
accuracy  was  too  low.  Although  the  traditional  DenseNet  has  fewer 
parameters  and  a  greater  identification  accuracy  than  ResNet,  its 
recognition rate is lower than that of the model in this work. Due to its 
sliding window design, the Swin Transformer is somewhat more accu-
rate than the other models. Nevertheless, the number of parameters and 
model size are excessive, consuming too many memory resources. On 
top  of  that,  the  proposed  model  exhibited  the  greatest  identification 
accuracy  but  needs  some  improvement,  in  terms  of  the  number  of 
parameters.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

The authors of the paper employ various metrics to evaluate the performance of their deep learning model. These include accuracy, precision, and other evaluation indicators. To calculate these metrics, they utilize a confusion matrix, which provides a visual representation of the model's performance across different categories. The values along the main diagonal of the matrix indicate the proportion of correctly predicted samples for each class, while the off-diagonal elements signify misclassifications or false positives/negatives. By analyzing the confusion matrix, one can quickly determine the strengths and weaknesses of the model and identify areas for potential improvement.