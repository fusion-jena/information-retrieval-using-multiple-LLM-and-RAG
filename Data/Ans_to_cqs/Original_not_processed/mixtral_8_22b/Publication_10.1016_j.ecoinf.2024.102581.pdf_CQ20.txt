Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

The workstation used for the research is equipped with an Intel i7 
CPU operating at a base clock speed of 3.80 GHz and a boost clock speed 
of 4.12 GHz. The CPU is an 8-core processor with 16 threads. To support 
our memory-intensive image processing tasks, we used 16 GB of high- 
speed  DDR4  RAM  running  at  3200  MHz,  which  allowed  us  to  effi-
ciently load and process large datasets in memory. The workstation is 
equipped with a 1 TB NVMe SSD (Samsung 970 EVO Plus) as the primary 
drive for the operating system and software installation. For the deep 
learning tasks, we utilized an NVIDIA GeForce RTX 2080 GPU. With 8 
GB of GDDR6 VRAM and 2944 CUDA cores, this GPU accelerated neural 
network training and inference. A memory bus width of 256 bits facil-
itated  efficient  data  transfer,  and  we  employed  the  CUDA  Toolkit 
version  11.1  for  GPU-based  computations.  A  Windows  11  operating 
system is used as the platform. Python 3.7.10 was used to implement and

Table 8 
Performance  comparison  of  the  proposed  HPB3C-3PGA-based  approach  with 
existing machine learning approaches.  

Table 10 
Parameter  comparison  of  the  HPB3C-3PGA-based  CNN  configuration  with 
existing transfer learning approaches.  

Model  

Accuracy 

Precision 

Recall 

F1-score 

Models 

Trainable Param 

Non-Trainable Param 

SVM 

KNN 

Decision Tree 

Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Mendeley 
CVIP100 
Proposed Approach  Mendeley 
CVIP100 

Random Forest 

CNN 

82.32% 
84.52% 
75.53% 
77.43% 
78.20% 
80.25% 
82.54% 
84.78% 
90.52% 
92.43% 
98.96% 
98.97% 

82.42% 
84.52% 
75.55% 
77.55% 
78.54% 
80.47% 
82.32% 
84.42% 
90.32% 
92.46% 
99.22% 
99.28% 

82.82% 
83.87% 
75.42% 
77.32% 
78.88% 
80.25% 
82.81% 
84.51% 
90.02% 
92.42% 
98.18% 
99.48% 

82.54% 
83.58% 
75.75% 
77.83% 
78.45% 
80.25% 
82.79% 
84.59% 
90.52% 
92.42% 
97.71% 
98.98%

71.17% 

98.7% 

Ganguly et al., 2022b) 

DDYOLOv5 and ResNet-50 (Hu et al., 

Pine tree classification 

98.71% 

2022) 

Deep Attention Dense CNN model ( 

Pandey and Jain, 2022b) 

Dense convolutional neural networks 

Plant leaf disease 
classification 
Plant disease classification 

97.33% 

99.1% 

() 

Proposed Approach 

Plant leaf classification 

98.97  

6.1.2. CVIP100 dataset

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
For training the deep learning models, the researchers utilized an NVIDIA GeForce RTX 2080 GPU. This GPU has 8 GB of GDDR6 VRAM and 2944 CUDA cores, which helped accelerate neural network training and inference. Additionally, they used a memory bus width of 256 bits for efficient data transfer and employed the CUDA Toolkit version 11.1 for GPU-based computations.