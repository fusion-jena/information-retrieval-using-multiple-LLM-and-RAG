Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

14 / 19

Deep learning tools for bat acoustic signal detection

S1 Fig. CNNFAST network architecture description. The CNNFAST network consists of two
convolution layers (Conv1 and Conv2), with 16 filters each (shown in yellow, with the filter
size shown inset). Both convolution layers are followed by a max pooling layer (Max Pool1 and
Max Pool2), and the network ends with a fully connected layer with 64 units (Fully Connect).
CNNFAST computes feature maps (shown as white boxes) across the entire input spectrogram,
resulting in less computation and a much faster run time. The fully connected layer is also eval-
uated as a convolution. The output of the detector is a probability vector (shown in green)
whose length is one quarter times the width of the input spectrogram. The numbers below
each layer indicate the height, weight, and depth of the corresponding layer.
(TIF)

Our evaluation on large-scale ecological monitoring data from Jersey [49], demonstrated
that our open-source BatDetect CNNFAST pipeline performs as well or better (controlling for
spatial and temporal non-independence) compared with an existing widely-used commercial
system (SonoBat) that had been manually filtered (false positives were removed). Here we

PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005995 March 8, 2018

13 / 19

Deep learning tools for bat acoustic signal detection

binary classification problem. Our CNNFULL consisted of three convolution and max pooling
layers, followed by one fully connected layer (see Supplementary Information Methods for fur-
ther details). We halved the size of the input spectrogram to reduce the input dimensionality
to the CNN which resulted in an input array of size of 130 frequency bins by 20 time steps, cor-
responding to a fixed length, detection window size of 23ms. We applied the CNN in a sliding
window fashion, to predict the presence of a search-phase bat call at every instance of time in
the spectrogram (Fig 1D). As passive acoustic monitoring can generate large quantities of data,
we required a detection algorithm that would run faster than real time. While CNNs produce
state of the art results for many tasks, na√Øve application of them for detection problems at test
time can be extremely computationally inefficient [33]. So, to increase the speed of our system

CNNFULL, CNNFAST, Random Forest, and the Segmentation algorithms took 53, 9.5, 11,
and 17 seconds respectively, to run the full detection pipeline on the 3.2 minutes of full spec-
trum iBats Romania and Bulgaria test dataset. Compared to CNNFULL there was therefore a
significant decrease in the time required to perform detection using CNNFAST, which was also
the fastest of our methods overall. Notably, close to 50% of the CNN runtime was spent gener-
ating the spectrograms for detection, making this the most computationally expensive stage in
the pipeline.

Ecological monitoring application results

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not provide information about where the code repository of the deep learning pipeline is available. However, it mentions that their approach is open source, so it might be available on platforms like GitHub, GitLab, or BitBucket. To find out exactly where the code repository is located, I recommend checking the references mentioned in the paper or contacting the authors directly.