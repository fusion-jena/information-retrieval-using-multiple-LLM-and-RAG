Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Table 1 
Pre-processing hyper-parameters for each dataset and the number of testing files 
used.   

Lemurs 

Alethe 

Gibbons 

Whydah 

Low pass filter cut off 
Downsampling rate 
Nyquist rate 
Segment duration 
Number of testing files 
Testing time (min) 

4000 
9600 
4800 
4 
46 
1840 

3100 
6400 
3200 
2 
27 
810 

2000 
4800 
2400 
4 
22 
1300 

9000 
18400 
9200 
3 
78 
1560

consuming step which involves exploring various neural network hyper- 
parameters to obtain the most optimal model. When combined, these 
three  problems  render  the  creation  and  utilisation  of  CNNs  to  solve 
bioacoustics research questions challenging to machine learning experts 
and non-experts alike.

Table 4 
Comparison of the average F1 score across the different network architectures and dataset configurations. The exponent approach was used for the spectrogram input. 
The feature extracted was frozen. The results are averaged across 13 unique executions. The results are ordered (highest to lowed) based on the average of each 
network architecture across all configurations. The best three performing network architectures on a particular dataset configuration is highlighted in bold.  

Method 

ResNet101V2 
ResNet152V2 
InceptionResNetV2 
ResNet50V2 
DenseNet169 
DenseNet201 
VGG16 
DenseNet121 
InceptionV3 
ResNet101 
Xception 
MobileNetV2 

G 25 

95.30 
95.18 
94.70 
94.97 
94.92 
94.84 
97.26 
94.58 
92.22 
96.17 
93.88 
94.62 

G 50 

97.40 
96.92 
96.75 
97.04 
96.95 
96.72 
98.09 
96.69 
95.42 
97.49 
95.79 
96.65 

G 100 

96.27 
96.58 
96.57 
95.13 
95.69 
95.86 
94.99 
95.00 
95.40 
94.23 
95.50 
91.65 

L 25

Xception 

Huang et al. (2017) 
Huang et al. (2017) 
Huang et al. (2017) 
Szegedy et al. (2017) 
Szegedy et al. (2016) 
Howard et al. (2017) 
He et al. (2016a) 
He et al. (2016a) 
He et al. (2016a) 
He et al. (2016a) 
Simonyan and 
Zisserman (2014) 
Chollet (2017) 

Parameters 
with FT 

6,986,626 
12,537,730 
18,154,370 
54,294,626 
21,792,930 
2,275,074 
42,634,754 
42,610,818 
58,269,826 
23,601,282 
14,731,074 

Parameters 
without FT 

32,770 
53,250 
61,442 
18,434 
24,578 
51,202 
81,922 
81,922 
81,922 
81,922 
16,386 

20,888,874 

81,922  

fine-tuning). 

For each of the experiments we executed the training of each CNN a 
number  of  times  so  that  a  distribution  of  accuracy  metrics  could  be 
determined. This was also done since there is a stochastic aspect to CNNs 
and  thus  reporting  on  few  executions  would  be  misleading.  For  each

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given information, it does not explicitly state how the hyperparameters of the model were optimized. However, it mentions that one of the challenges in creating and utilizing Convolutional Neural Networks (CNNs) for bioacoustic research questions is the consuming step involving exploring various neural network hyperparameters to obtain the most optimal model. This suggests that some form of optimization technique such as grid search or random search might have been employed to find the best set of hyperparameters. Unfortunately, without more specific details about the methodology used, I cannot provide a definitive answer regarding the exact optimization technique utilized.