Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

5.1. Setup 

Journal Pre-proof

In  our  experiments,  we  used  the  Python  3.10  programming  environment  along  with  popular 

libraries  such  as  PyTorch,  TensorFlow,  and  OpenCV.  The  detection  models  were  trained  on  a 

server equipped with an Intel® Core™ i7-8700 CPU @ 3.20GHz (32GB DDR4-2666 memory) 

and an NVIDIA GeForce RTX 3070 GPU (8GB GDDR6 memory). 

The  methods  utilizing  YOLOv5  will  undergo  training  for  300  epochs,  whereas  the 

classification network in method 1 will undergo training for 200 epochs. Here, one epoch signifies 

training the model on all data once. For YOLOv5 training, fundamental parameters such as the 

learning  rate  will  be  set  to  0.02,  with  weight  decay  and  momentum  values  of  0.001  and  0.9, 

respectively.  In  contrast,  methods  employing  Faster  RCNN  will  be  trained  with  90  thousand 

 
Journal Pre-proof

feature  images  while  retaining  crucial  features.  The  Dropout  layer  is  integrated  to  mitigate 

overfitting. Additionally, the Global Average Pooling layer summarizes features, generating input 

for the fully connected layer. This layer also facilitates the visualization of regions relied upon by 

the network for predictions. The subsequent three fully connected layers generate the predicted 

class for the original image 

Table 1: Main parameters of the classification network 

[

Input size 

Output size 

Journal Pre-proof

[

[

[

Parameters 

  conv, strides 1] 

  conv, strides 1] 

  max pool 

  conv, strides 1] 

  conv, strides 1] 

Probability 0.5 

  max pool 

[

  conv, strides 1] 

Layers 

Convolution 

Convolution 

Pooling 

Convolution 

Convolution 

Dropout 

Pooling 

Convolution 

Global Average Pooling 

Dense 

Dense 

Classification layer (Dense) 

128 

128 

128 

128 

128 

128 

1 

- 

- 

- 

-

any  size  and  outputs  a  region  proposal,  consisting  of  a  set  of  rectangle  locations  capable  of 

containing objects, along with the corresponding probability of containing the object. An essential 

aspect  of  Faster  RCNN  is  the  utilization  of  anchors  for  generating  bounding  boxes  within  the 

network.  Anchors  are  created  to  differentiate  between  positive  and  negative  anchors  based  on 

overlap.  Furthermore,  by  comparing  the  position  of  predefined  anchors  with  ground-truth 

bounding boxes (using Intersection over Union rate), the network can predict the location of the 

output region proposal. The second module of the network operates similarly to the structure of the 

Journal Pre-proof

Faster RCNN network,  responsible for both  object  classification and localization. This  module 

utilizes feature regions generated by the RPN to conduct classification and refine the coordinates

CNN architecture but  with  different  filter sizes.  The obtained  results depend on the number of 

hidden layers, filter size, and the number of filters in convolution layers. The higher the number of 

hidden layers, filter size, and filters, the higher the accuracy of classification. In [29], the authors 

proposed  four  different  models  for  bee  image  classification,  serving  different  tasks  in  beehive 

monitoring. All these models were based on different Deep Neural Networks (DNNs) that have 

been  pre-trained  on  the  ImageNet  dataset  [30]  including  AlexNet,  DenseNet-201,  GoogLeNet, 

ResNet-101, ResNet-18, VGG-16, VGG-19. In the first model, the authors used a transfer learning 

method based on these pre-trained DNNs. Meanwhile, in the second, third, and fourth models, the 

authors used the SVM classifier with deep features, shallow features, and deep+shallow features

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information in the given context to determine where the code repository of the deep learning pipeline is available. It could be hosted on platforms like GitHub, GitLab, or BitBucket, but without explicit mention, it remains unknown. Please provide more details if possible.

Answer:::

The text does not provide any information about the specific code repository of the deep learning pipeline. Therefore, I cannot accurately state whether the code repository is available on platforms such as GitHub, GitLab, or BitBucket. To find this information, additional resources would need to be consulted.