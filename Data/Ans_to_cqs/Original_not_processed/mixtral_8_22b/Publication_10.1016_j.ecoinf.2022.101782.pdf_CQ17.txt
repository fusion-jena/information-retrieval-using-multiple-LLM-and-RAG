Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

950 (4%) 
1110 (4%) 

Total 

24,675 
32,986  

passes over the entire training set) and a batch size of 64, with an ADAM 
(cid:0) 5. Image augmentation was applied 
optimiser and a learning rate of 10
in the form of horizontal flip, 0.2 degree counter clock wise shear and a 
random zoom between 0 and 0.2 - all leading to 224 × 244 pixel RGB 
input tensors. Data was normalised to ImageNet mean values, and the 
pixels values were rescaled in the range of [0, 1]. Model training took 
roughly 4 days. The best model was selected based on minimal valida-
tion loss that occurred at epoch 448. This model showed a training loss 
of 0.256, a training accuracy of 0.899, a validation loss of 0.298 and 
validation accuracy of 0.891. We evaluated the red kite model perfor-
mance based on an independent test set of 2060 images (as described in 
3.3). 950 of these images were true positive red kites images and the

identified by both textual and visual analysis, we could achieve almost 
perfect  precision  (0.992),  at  the  cost  of  lower  recall.  Thirdly,  by 
combining the two approaches, we increased the extracted data volume 
by almost 14%, while still downsamping the original dataset by around 
99.5% and with a precision 0.636. Recall for the workflow overall is not 
known, since this would require manual analysis of over 600,000 posts. 
Our results thus go further than previous work by demonstrating how 
images  retrieved  using  text  and  image  metadata  can  be  combined  to 
achieve  very  high  precision,  or  merged  to  increase  recall  while  still 
filtering initial datasets very effectively. To better understand our results 
and their transferability to other species, we looked more closely at data 
quality.  Flickr  users  often  used  relevant  textual  descriptions  to  label 
their  red  kite  sightings  with  their  captured  images.  This  high  textual

5. Discussion 

In this study we developed a workflow which leveraged citizen sci-
ence data to extract further relevant records from social media posts in 
the  same  region.  The  workflow  functions  as  a  data  filter  enabling 
downsampling of an initially very large dataset into a human analysable 
subset - in our case containing 0.5% of the original posts. By massively 
reducing  data  volumes,  it  becomes  realistic  to  analyse  the  remaining 
data by hand to select true positives, with around one hour required for 
the  4000  or  so  candidate  posts  we  identified.  Our  workflow  thus  ad-
dresses  the  research  gap  identified  by  Burke  et  al.,  2022,  using  gen-
eralisable  methods  to  extract  target  data  from  various,  unverified 
sources to enrich data.

The second CNN was our red kite image classification model. Red 
kites do not belong to the generic objects detectable by pretrained, off- 
the-shelve image classifiers. Thus, we needed to train an image classi-
fication  model  capable  of  performing  this  task.  For  this  we  applied 
transfer-learning  to  a  ResNet50  pretrained  on  ImageNet.  We  slightly 
adapted the original architecture using Keras (Chollet et al., 2015) as a 
high-level API build on top of TensorFlow. We replaced the final 1000- 
way  classification  layer  of  the  model  with  two  additional,  fully  con-
nected layers with ReLu non-linearity activation followed by a 2-way 
logistic  regression  classifier,  trained  via  standard  cross-entropy  loss. 
These layers add 1 million untrained parameters to the network which 
need to be tuned to detect red kites on 224 × 224 pixel input images. The 
pretrained network was frozen during the transfer-learning process, and

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the regularization methods used to prevent overfitting in the deep learning pipeline (e.g., dropout, L2 regularization)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, there is no explicit mention of any specific regularization method used to prevent overfitting in the deep learning pipeline. However, some common techniques used in such scenarios include Dropout, L1/L2 Regularization, Early Stopping, and Batch Normalization. These methods help reduce overfitting by adding constraints to the learning capacity of the neural networks, thereby improving generalization performance. In this particular scenario, it might have been beneficial to use techniques like Dropout or L2 Regularization to avoid overfitting, but without explicit details about the implementation, it cannot be confirmed if they were indeed employed.

Answer:::