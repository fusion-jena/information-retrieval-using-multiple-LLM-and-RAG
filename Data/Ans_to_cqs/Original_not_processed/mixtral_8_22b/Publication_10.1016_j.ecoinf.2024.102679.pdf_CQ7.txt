Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

with a 50% probability of occurrence. To avoid any risk of overfitting at 
each  training  stage,  we  selected  the  model  relative  to  the  epoch  that 
gave the best performance on the validation set. During inference, the 
patch  size  was  set  to  1024  Ã— 1,024  pixels  to  accelerate  the  process. 
Further information on the fine-tuning process is described in section 
2.5.2.

The  pre-trained  model  underwent  inference  and  fine-tuning  for  4 
iterations using the entire SW stratum employing the SAL. This iterative 
process served to enhance the model's performance and gather samples 
pertaining to each key species present in the region. The training pro-
cedure for the two first fine-tuning iterations was the one proposed in 
the  original  paper  (Delplanque  et  al.,  2023a)  which  consisted  of  two 
main steps: 1) training the architecture using positive patches for 200 
epochs, and 2) collecting and including hard negative patches, which are 
patches  containing  false  positives,  to  further  train  the  model  for  50 
epochs in order to reduce the number of false positives. During the two 
last fine-tuning iterations, only the second step of the training procedure 
was used. Hard negative patches were created using false positives that 
emerged from the thumbnail classification (step 1 of the SAL). To avoid a

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Wildlife population estimation 
Aerial surveys 
Deep learning 
Biodiversity monitoring 
Conservation technology 
African savanna

surveys of PAs covering thousands of square kilometers and generating 
thousands of images can be delayed by several months using the OCC 
approach due to the slow but necessary manual processing of images. 
Recent  advances  in  machine  learning  have  propelled  the  perspec-
tives of remotely sensed imagery for wildlife conservation (Tuia et al., 
2022),  and  announced  good  prospects  for  the  automation  of  image 
processing from SRF-OCC surveys (Delplanque et al., 2023b; Eikelboom 
et al., 2019). Deep learning (DL) is a subgroup of machine learning and 
artificial intelligence (AI) where artificial neural networks are trained to 
achieve challenging tasks (e.g. detect animals in aerial imagery) through 
a complex multi-level representation of information learned from a large 
amounts of data (LeCun et al., 2015). In the last decade, DL has been 
widely  employed  to  (semi-)automate  the  detection  and  counting  of

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, the provided context does not explicitly mention the specific criteria used to split the data for deep learning model training into sets such as train, test, or validation. However, it does indicate that a validation set was used during the training process to prevent overfitting. Overfitting occurs when a model learns the details and noise in the training data to the extent that it negatively impacts its ability to generalize from new examples. By evaluating the model's performance on a separate validation set, the researchers could select the model with the best performance on unseen data, thus minimizing the risk of overfitting. While this doesn't provide explicit criteria for splitting the data, it suggests that the researchers likely followed common practices in machine learning, such as randomly dividing their dataset into training, validation, and possibly testing sets.