Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

0.0220.0200.0180.016MAE0.0140.01220468EpochTrain lossValidation loss101214160.1400.1350.1300.1250.120MAE0.1150.11020468EpochTrain lossValidation loss1012 8483, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8551167 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [28/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License12

Computational Intelligence and Neuroscience

[11] L. Xiao, Y. Zhang, K. Li, B. Liao, and Z. Tan, “A novel re-
current neural network and its ﬁnite-time solution to time-
varying complex matrix inversion,” Neurocomputing, vol. 331,
pp. 483–492, 2019.

[12] C. Chen, K. Li, S. G. Teo et al., “Gated residual recurrent graph
neural networks for traﬃc prediction,” Proceedings of the
AAAI Conference on Artiﬁcial Intelligence, vol. 33, pp. 485–
492, 2019.

Practically, over/underﬁtting diﬃculties in neural net-
work models are caused by the neural network model’s
excessive/insuﬃcient training epochs [43]. As a result, one
possible solution to the DL-based model’s over/underﬁtting
concerns is to apply the early stopping strategy [44], which is
used to cease training when generalisation performance
starts to degrade for a number of epochs. To track the
generalisation performance,
in the proposed model, the
training data is separated into training and validation
groups.

+e dropout approach [45] is another way to deal with
the overﬁtting problem. Dropout is a regularisation strategy
that allows you to train neural networks with alternative
topologies in parallel by randomly dropping out a certain
proportion of layer neurons. Dropout is indicated by the
black neurons in the fully connected layers, as seen in
Figure 3.

Data CollectionPre-Processing&ConstructionLagHyperparam- OptiDatapreprocessingHyperparametertuningTraining &ValidationModelValidationModelpredection &deploymentModeltrainingKOREA HYDROGRAPHIC ANDOCEANOGRAPHIC AGENCY 8483, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8551167 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [28/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseComputational Intelligence and Neuroscience

7

Figure 3: Stacked GRU-DNN model.

Table 1: +e search space of the GRU-DNN model hyperparameters.

Hyperparameters
No. of GRU cells
No. of FC layers
No. of FC layers’ units
Hidden layers activation
Batch size
Droupout rate of FC layers

Value
[4, 8, 16]
[1, 2]
[4, 8, 16]
[Relu, Linear]
[4, 8, 16]
[0.0, 0.1, 0.2]

train than LSTM [16].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The criterion used to determine when training is complete is called early stopping. Early stopping is a form of regularization used to avoid overfitting by stopping the training process before it converges. In this case, the training data is divided into training and validation groups. The training continues until the validation error starts increasing for a specified number of epochs. This indicates that the model has started to overfit the training data and further training would not improve the model's ability to generalize to new data. Therefore, the optimal point to stop training is determined based on the minimum validation error achieved during the training process.

In summary, the criterion used to determine when training is complete is early stopping, where the training stops when the validation error starts increasing for a specified number of epochs.