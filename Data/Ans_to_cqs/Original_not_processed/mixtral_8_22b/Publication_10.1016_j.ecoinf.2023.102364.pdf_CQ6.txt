Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Short-billed (common/mew) Gull Larus canus 
Geographic information system (GIS) 
Open access data 
Big data 
Socio-economics 
Multi-year field work 
Machine learning ensemble predictions 
(RandomForest Treenet CART MARS)

MARHH_NO_C 

MHH_CHILD 
FHH_CHILD 

FAMILIES 
AVE_FAM_SZ 
HSE_UNITS 
URBAN 
RURAL 
VACANT 
OWNER_OCC 
RENTER_OCC 
POP_MILE 
HH_INCOME_ 
HH_10K 
HH10TO15K 
HH15TO20K 
HH20TO25K 
HH25TO30K 
HH30TO35K 
HH35TO40K 
HH40TO45K 
HH45TO50K 
HH50TO60K 
HH60TO75K 
HH75TO100K 
HH100_125K 
HH125_150K 
HH150_200K 
HH_200K 
HHMEDIAN 
PER_CAPITA 
Polygon area  

x-coordinate  
y-coordinate  

Total number of people in the census block in year 
2000 
Total number of people who are white alone 

Total number of people who are black alone 

Total number of people who are Native American 
alone 
Total number of people who are Asian alone 

Total number of people who are Hawaian Pacific 
Island alone 
Total number of people who are ‘other’ alone 

Number of Multirace Individuals in census unit 

Total number of people who are Hispanic alone

Distance to Railway 

Vegetation name 

Soil type 
US Census 2000 (60 

attributes) 

Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Fairbanks Burrough GIS, 
ARCGIS 
Forest Layer Tanana Valley 
State Forest  
Alaska Clearing house  
Alaska US Census portal 

Value-added map 
product by FH 
Value-added map 
product by FH 
Value-added map 
product by FH 
Value-added map 
product by FH 
Value-added map 
product by FH 

See Table 2 for details  

2.3. Machine learning ensembles

Put Fig. 4 app here: Predicted RIO for Short-billed Gulls based on a 

machine learning ensemble. 

Put Fig. 5 app here: Time series data for a ‘presence site’ in Fairbanks 
during summer 2017 that is a raven hotspot for the ecological niche in 
winter. 

Put  Table  3  app  here:  Model  Diagnostics  importance  rank  of  pre-

dictors from machine learning model. 

Put Fig. 6 app here: Model Diagnostics Partial Dependence plot of 

first top-ranked Predictor (soil type). 

Put Fig. 7 app here: Model Diagnostics Partial Dependence plot of 

second top-ranked Predictor (vegetation class). 

Put Fig. 8 app here: Model Diagnostics Partial Dependence plot of 

third top-ranked Predictor (distance to water). 

Put Fig. 9 app here: Model Diagnostics 3D Partial Dependence plot of 
top-ranked  continuous  predictor  (distance  to  water  vs  distance  to 
transfer site). 

3.3. Model assessment

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Before training a deep learning model, several preprocessing steps may be necessary depending on the nature and quality of the input data. These steps often include:

1. Data Cleaning: This involves removing or correcting erroneous data points such as missing values, outliers, or inconsistent entries. It also includes handling categorical variables if any.

2. Normalization or Standardization: Deep learning models perform better when all features have similar scales. Therefore, it's common practice to scale numerical inputs to a standard range like [0, 1] or [-1, 1]. This process is known as normalization. Alternatively, one could use standardization which transforms the data to have zero mean and unit variance.

3. Encoding Categorical Variables: If there are categorical variables present in the dataset, they need to be converted into numerical form using techniques like label encoding or one-hot encoding.

4. Feature Selection or Extraction: Not all features contribute equally to the prediction task. Some might even introduce noise. Hence, selecting relevant features or extracting new ones through dimensionality reduction techniques can improve model performance.

5. Train-Test Split: The dataset should ideally be split into two parts - one used for training the model and another held back for testing its performance. This helps prevent overfitting and provides a more realistic estimate of how well the model will generalize to unseen data.

6. Cross Validation: To further ensure robustness against overfitting, cross validation methods can be employed where multiple train-test splits are created and the model is trained and evaluated on each pair separately.