Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model Evaluation
Model performance evaluation included both errors and
time costs evaluation. The iteration termination condition
of the model was the same in each round training (i.e., the
loss rate of the model was less than a preset threshold ɛ
−4]). We used the same test set (Test) to
[here ɛ = 1.0 × 10
evaluate the performance of models in diﬀerent training
phases. The model error evaluation used three metrics that
included overall error, commission error, and omission
error, which were deﬁned by equations (2), (3) and (4).

Table 2. Main conﬁguration parameters of the two platforms used.

)

(2)

(3)

(4)

Commission error

=

/(
FP TP

+

FP

)

Omission error

=

/(
FN TP

+

FN

)

232

Wildlife Society Bulletin (cid:129) 45(2)

 23285540, 2021, 2, Downloaded from https://wildlife.onlinelibrary.wiley.com/doi/10.1002/wsb.1176 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [29/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseTable 1. Incremental training sets sequence. There were 36,490 images in
BMXSM dataset.

Overall error

= (

FN FP TP

)/(

+

+

TN FN FP

+

+

Training sets(i)a

Number of
images(n)

n/N (%)

Empty images
rateb (%)

1
2
3
4
5
6
7

7,298
10,947
14,596
18,245
21,894
25,543
29,192

20
30
40
50
60
70
80

80.36
80.52
80.50
80.35
80.53
80.48
80.47

a i represented serial number of training set Traini, i = 1, 2, …, 7. Here
Train1 was initial training set and Traini (i = 2, 3, …, 7) was in-
cremental training set.

At present, few researchers focus on time costs of model
training and the required computing platform. Yousif et al.
(2019) stated that they optimized their model performance,
but model training still failed to complete on a common PC.
In terms of recognition rate, their rate on a 2.6 GHz CPU
computer was 100 frames/minute, which is lower than our
recognition rate (260 images/minute). One possible reason
is that their preprocessing was more complex.

MANAGEMENT IMPLICATIONS
Our method can greatly reduce time and personnel costs in
3 ways. First, using our method to automatically ﬁlter empty
images can greatly save labor and time, and the percentage
of the labor and time savings is the same as the proportion

Yang et al. (cid:129) An Adaptive Approach for Empty Images Filtering

233

 23285540, 2021, 2, Downloaded from https://wildlife.onlinelibrary.wiley.com/doi/10.1002/wsb.1176 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [29/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License3.6 GHz central processing unit (CPU) and 32 GB of
memory, we used the incremental training mode to train
and test the DCNN model. On another Dell PowerEdge
C4130 rack server with two Tesla K80 GPUs and 256 GB
of memory, we used the zero‐start and the incremental
training modes to train and test models, respectively.

RESULTS
The incremental training mode performed consistently with
the zero‐start training mode when the training sample size

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, several postprocessing steps can be taken to evaluate the performance of the trained model. These include generating saliency maps, calculating various metrics, and creating confusion matrices.

Saliency maps help visualize the regions of input data that contribute most significantly to the output prediction made by the model. This can provide insights into how the model makes its decisions and whether it focuses on relevant features or not.

Calculation of different metrics is essential to quantify the performance of the model. As mentioned in the given context, the model performance evaluation includes both errors and time cost evaluations. Three specific metrics used here are overall error, commission error, and omission error, defined by equations (2), (3), and (4) in the paper. Overall error measures the total misclassification rate, while commission error and omission error measure false positive and false negative rates, respectively.

Creating a confusion matrix is also helpful in understanding the classification results better. A confusion matrix is a table layout that allows visualization of the performance of an algorithm. Each row of the matrix represents the instances in an actual class, while each column represents the instances in a predicted class. By analyzing this matrix, one can understand where the model performs well and where it struggles.

These postprocessing steps enable a comprehensive analysis of the model's performance and help identify areas for improvement.