Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We collected the FishInTurbidWater dataset and quickly and weakly 
labeled  it  to  contribute  to  the  first  weakly-supervised  fish  dataset  in 
turbid  waters.  We,  then  used  this  dataset  to  develop  two  novel  deep 
learning networks, one using semi-supervised contrastive learning for 
significantly  accelerated  model  deployment  time,  and  one  weakly- 
supervised  model  to  shorten  deployment  time,  while  providing  high 
accuracy. 

For  semi-supervised  contrastive  learning,  we  first  trained  a  self- 
supervised  contrastive  learning  model  and  then  fine-tuned  it  on  our

1.  Collecting and presenting a new fish dataset in turbid waters.  
2.  Weakly  labelling  this  dataset  to  provide  the  worldâ€™s  first  weakly 

labeled fish dataset in turbid waters.  

3.  Developing two novel deep learning models to achieve two different 

goals.  
a.  A  semi-supervised  model  for  accelerating  model  development 

speed from data collection to deployment.  

b.  A  weakly-supervised  model  for  accelerating  the  development 
time,  while  also  conserving  the  accuracy,  compared  to  the  fast 
semi-supervised model.

weakly  labeled  dataset.  This  semi-,  weakly-supervised  approach  re-
quires only a small portion of our weakly labeled dataset, which makes 
the  development  cycle  from  data  labeling  to  final  model  inferencing 
very fast (i.e., 4 h) while producing a relatively high accuracy of 89%. 
For  the  ensembling  approach,  we  first  trained  two  state-of-the-art 
DNNs on ImageNet. We then performed transfer learning of these two 
DNNs  on  our  weakly  labeled  dataset.  This  generated  two  weakly- 
supervised  DNNs,  which  we  ensembled using  the  XGBoost  technique. 
This novel ensemble technique significantly improves the overall accu-
racy compared to the two weakly-supervised individual DNNs.

Labeling Time 
Training Time 
Turnaround 

Time 
Accuracy 

Very Short 
1.0 h 

4 h 

89.4% 

Short 
6.9 h 

22 h 

94.0% 

Very Long 
~3.5 h 

94 h 

98%  

4. Discussions 

The  development  of  deep  learning  methodologies  continues  to 
advance at an astonishing rate and be applied to various applications 
ranging from biomedical (Azghadi et al., 2020), hydrological processes 
in river channels (Talukdar et al., 2023) and agricultural (Olsen et al., 
2019) systems, to marine (Laradji et al., 2021; Saleh et al., 2022b), and 
environmental (Jahanbakht et al., 2022a) sciences. The application of 
deep learning technologies has been also used in profiling the ecosystem 
services of estuarine habitats by community members (Yee et al., 2023). 
In this paper, we extend the application of deep learning methodologies 
to advance state-of-the-art underwater fish video processing techniques 
applied to turbid waters.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no mention of where the code repository of the deep learning pipeline is available. It could be hosted on platforms such as GitHub, GitLab, or BitBucket, but without explicit information, I cannot determine its exact location. Please refer to any additional resources or documentation associated with this project for more details.