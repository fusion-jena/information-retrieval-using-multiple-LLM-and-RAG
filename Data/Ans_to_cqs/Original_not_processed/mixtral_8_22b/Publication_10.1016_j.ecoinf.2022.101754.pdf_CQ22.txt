Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

There were statistically significant differences between model scores 
using AdaBoost, Bayes, RF, and NET machine learning methods. Pairs of 
methods (6 combinations) were tested using Tukey's range test, and all 
differences  were  shown  to  be  significant:  p-value  was  0.001  for  each 
combination  of  methods.  The  highest  scores  were  for  models  using 
AdaBoost (mean score of 45), followed in descending order by RF (mean 
score  of  42),  NET  (mean  score  of  34),  and  Bayes  (mean  score  of  31) 
(Fig. 8).

(1)  

(cid:0)

)

R2 all

+ score

where. 

_test is descriptor for test samples, 
_all is descriptor for all samples, 
AD  is  average  angle  deviation  from  the  line  1:1  for  test  samples 

[degree] (Eq. 2), 

ACT1 is accuracy with tolerance 15 t/ha ± 10% of AGB [t/ha], 
ACT2 is accuracy with tolerance 10 t/ha ± 5% of AGB [t/ha], 
RMSE is root mean squared error [t/ha] (eq. 3), 
R2 is coefficient of determination (R2; eq. 4), 
Diff_R2 is the difference between R2_test and R2_all, and. 
CV_R2 is cross-validation R2. 

EcologicalInformatics70(2022)1017545O. Brovkina et al.

Fig. 6. Individual evaluation functions for test 
model  samples.  Data  are  between  quantiles 
Q01 and Q99. AC_T1 is accuracy with assigned 
tolerance 15 t/ha ± 10% of AGB [t/ha]; AC_T2 
is accuracy with assigned tolerance 10 t/ha ±
5% of AGB t/ha]; RMSE is root mean squared 
error [t/ha] (eq. 3); R2  is coefficient of deter-
mination (R2; eq. 4); CV_R2  is cross-validation 
R2;  AD  is  average  angle  deviation  from  the 
line 1:1 for samples [degree]; _all is descriptor 
for all samples; and _test is descriptor for test 
samples.   

EcologicalInformatics70(2022)1017546O. Brovkina et al.                                                                                                                                                                                                                               

Table 1 
Ranges of individual evaluation functions in assigning the score.  

Partial score per 
attribute 

AD 
test 

AD all 

5 
3 

2 

1 

0

Xue, B., 2015. Lidar and machine learning estimation of hardwood forest biomass in 
mountainous and bottomland environments. In: Theses and Dissertations, 1274. 
http://scholarworks.uark.edu/etd/1274. 

Wu, C., Shen, H., Shen, A., Deng, J., Gan, M., Zhu, J., Xu, H., Wang, K., 2016. 

Zhang, L., Shao, Z., Liu, J., Cheng, Q., 2019. Deep learning based retrieval of forest 

Comparison of machine-learning methods for above-ground biomass estimation 
based on Landsat imagery. J. Appl. Remote. Sens. 10, 035010 https://doi.org/ 
10.1117/1.JRS.10.035010. 

aboveground biomass from combined LiDAR and Landsat 8 data. Remote Sens. 11 
(12), 1459. 

EcologicalInformatics70(2022)10175412

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study uses several metrics to evaluate the performance of the machine learning models, including AdaBoost, Bayes, Random Forest (RF), and Neural Network (NET). These metrics include:

* Average Angle Deviation (AD): This measures the deviation from the line 1:1 for both test and all samples. It is expressed in degrees.
* Accuracy with Tolerance (ACT1 and ACT2): Two levels of accuracy are considered - one with a tolerance of 15 t/ha ± 10% of Above Ground Biomass (AGB) and another with a tolerance of 10 t/ha ± 5% of AGB.
* Root Mean Squared Error (RMSE): This metric measures the standard deviation of the prediction errors or residuals. It is expressed in units of AGB [t/ha].
* Coefficient of Determination (R2): This represents the proportion of variance in the dependent variable that can be predicted from the independent variables. It ranges from 0 to 1, where 1 indicates perfect correlation.
* Cross-Validation R2 (CV\_R2): This is a measure of how well the model performs when predicting new data.

These metrics are used to compare the performance of different machine learning algorithms and determine which method provides the best results. Based on these evaluations, it was found that the AdaBoost algorithm had the highest mean score of 45, followed by RF with a mean score of 42, NET with a mean score of 34, and Bayes with a mean score of 31. All pairwise comparisons between these methods showed statistically significant differences, with a p-value of 0.001 for each combination.