Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4. Evaluation Metrics

The model is evaluated using the following metrics: Precision, Recall and F1, which are used to

measure the model detection performance [21]. The formulas include the classiﬁcation terms:

•
•
•

TP, true positive: model detects a true object;
FP, false positive: model detects a false object;
FN, false negative: model did not detect a true object.

The scores are calculated as:

Precision =

TP
TP + FP

Recal =

TP
TP + FN

F1 = 2 ∗ Precision ∗ Recall
Precision + Recall

3. Results

3.1. Training Evaluation

The model was trained for 350 epochs and evaluated using the scores precision, recall, F1, GIoU,
and mAP, as seen in Table 2. The scores are calculated from model validation data, consisting of
321 image tiles. The F1 score and mAP score are seen to follow each other closely, given indications on
the training at diﬀerent stages, the model quickly reached F1 and mAP scores of ~0.4, whereafter they
continue to increase but at a slower rate. At the end of the training, the model achieved the accuracy
scores of F1 = 0.530 and mAP = 0.557. The GIoU is steadily decreasing, indicating that the model is
becoming better at correctly locating targets.

Table 2. Training metrics at diﬀerent iteration stages.

Epoch

Precision Recall

F1 Score

GIoU

100
200
300
350

0.656
0.583
0.493
0.476

0.321
0.549
0.610
0.600

0.430
0.541
0.534
0.530

2.14
1.58
1.29
1.16

mAP

0.407
0.542
0.548
0.557

F1 = 2 ∗ Precision ∗ Recall
Precision + Recall

The precision and recall metrics both measure the model detection performance, but each account
for diﬀerent factors in the detection process. Precision is a measure of how accurate the model is at
making positive predictions, i.e., objects detected by the model. Since only detected positives are used
in the formula, the precision is likely to remain high as long as very few objects are detected. The recall
accounts for this by measuring false negatives, i.e., objects not detected, and is thereby a measure of
how much is detected out of what should have been detected. These two measures often move in

ISPRS Int. J. Geo-Inf. 2020, 9, 758

6 of 14

for deep learning. arXiv 2019, arXiv:1910.05446.

17. Ruder, S. An overview of gradient descent optimization algorithms. arXiv 2016, arXiv:1609.04747.
18. Taqi, A.M.; Awad, A.; Al-Azzo, F.; Milanova, M. The impact of multi-optimizers and data augmentation on
TensorFlow convolutional neural network performance. In Proceedings of the 2018 IEEE Conference on
Multimedia Information Processing and Retrieval (MIPR), Miami, FL, USA, 10–12 April 2018; pp. 140–145.
19. Olson, M.; Wyner, A.; Berk, R. Modern neural networks generalize on small data sets. In Proceedings of
the Advances in Neural Information, Neural Information Processing Systems 31 (NeurIPS 2018), Montreal,
BC, Canada, 3–8 December 2018; pp. 3619–3628.

20. Ammar, A.; Koubaa, A.; Ahmed, M.; Saad, A. Aerial images processing for car detection using convolutional

neural networks: Comparison between faster r-cnn and yolov3. arXiv 2019, arXiv:1910.07234.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning model is evaluated using several metrics such as Precision, Recall, and F1 score. These metrics are used to measure the model's detection performance. Additionally, the model is also evaluated using Generalized Intersection over Union (GIoU) and mean Average Precision (mAP). The scores for these metrics are calculated based on the model validation data. During the training phase, the model achieved an accuracy score of F1=0.530 and mAP=0.557. The GIoU metric indicates that the model becomes better at correctly locating targets as it steadily decreases during training.