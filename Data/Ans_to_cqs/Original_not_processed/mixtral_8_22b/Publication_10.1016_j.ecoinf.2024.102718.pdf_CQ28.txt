Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Training time is another critical factor for practical IoT device
deployment. The BEiT model achieves competitive efficiency with a
training time of 1 min and 10 s for the PlantVillage Dataset. Although
Farian et al.’s model has a slightly shorter training time of 1 min and 6 s,
it does not match the BEiT model’s overall performance, making the
BEiT model a more balanced option for both speed and accuracy.On the
whole, the proposed BEiT model’s more effective accuracy, precision,
recall, F1-score, and AUC, coupled with efficient training time, highlight
its potential for real-world applications in smart agriculture, particularly
in handling the complexities of plant disease classification.

8. Challenges and limitations

computational efficiency and speed.

Similarly, the Dhan-Shomadhan dataset, under noiseless conditions,
achieves over a 97.50% accuracy with a 0.121 loss. These figures,
particularly in contrast with the performance of the larger models, un-
derscore the 12M variant’s efficacy, presenting it as a potent alternative
that balances performance with resource efficiency—a critical consid-
eration in deployment scenarios where computational resources are
limited or efficiency is paramount.

enhance its capability to differentiate subtle imagery details, the
model’s computational
limit its deployment in
intensity may still
resource-constrained environments, a common scenario in agricultural
applications. Additionally, the model’s reliance on large datasets for
training poses challenges in scenarios where such datasets are scarce or
imbalanced. Future studies could focus on optimizing the BEiT model to
further reduce its computational demands without sacrificing accuracy,
making it more suitable for real-time applications on edge devices
commonly used in agricultural settings. Another avenue for exploration
is the development of techniques for effective training with smaller or
imbalanced datasets, possibly through advanced data augmentation or
transfer learning approaches. Furthermore, expanding the model’s
applicability to detect a wider range of diseases across different crops
could significantly broaden its utility in agricultural diagnostics. Inte-

model are illustrated in Fig.8 for both datasets. When noise is added to
the data and changes are made to the model architecture, such as
removing layers, variations in the curves become noticeable, especially
between epochs 5 to 10. The fluctuations in performance observed
during these periods can be attributed to the impact of additional noise
in the data and the continuous adjustment of the model’s structure.
Furthermore, Table 10 depicts a comparative examination of numerous
state-of-the-art models in terms of their size and analysis time. Notably,
the ViT and DenseNet 169 models stand out for their comparatively
modest sizes of 30 MB space with ViT exhibiting the shortest analysis
time of 1 min and 25 s. On the other side, models like VGG 16 and
Inception V3 have higher performance consisting of 78 MB and 60 MB
respectively, resulting in lengthier analysis durations. ResNet50 and
Xception fall in between, with sizes of 56 MB and 54 MB, with analysis

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given text does not provide information about which specific platform was used to deploy the deep learning model. It only mentions that the BEiT model has potential for real-world applications in smart agriculture, but there is no mention of any cloud platforms like AWS, Azure, or Google Cloud Platform being used for this purpose. Therefore, based on the provided context, I cannot determine which platform was used to deploy the deep learning model.