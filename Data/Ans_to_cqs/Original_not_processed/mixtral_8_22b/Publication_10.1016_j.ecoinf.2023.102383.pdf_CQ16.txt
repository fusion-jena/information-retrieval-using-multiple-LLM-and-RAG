Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

hard negative mining, which focuses on challenging negative examples 
during the training process. By selectively mining hard negative exam-
ples,  the  model  can  learn  to  better  distinguish  between  objects  and 
background regions, leading to improved overall performance.

IoU ≥ 0.5 means that it will be a true positive prediction only when 
the IoU value between a predicted bounding box and its corresponding 
ground-true bounding box is greater than or equal to 0.5. 0.5 ≤ IoU ≤
0.95 means ten IoU thresholds ranging from 0.5 to 0.95 with a step size 
of 0.05, and ten precisions for different ranges can be calculated, and 
then compute the mean of the ten values. This comprehensive evalua-
tion  accounts  for  varying  levels  of  overlap  between  predicted  and 
ground truth bounding boxes, which is often used to evaluate how well 
the bounding boxes generated by models fit corresponding objects. Ac-
cording  to  the  results  in  Table  3,  the  performance  of  both  FRC_Res-
Net18FPN and FRC_ResNet152FPN is very close and surpasses that of 
the remaining three models. Under the condition of IoU ≥ 0.5, the AP of 
the five models is shown in Fig. 13.

based on trials and errors.

in the training phase. 

3.4. Criterion for multi-scale feature map selection

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide explicit information about the specific criterion used to determine when training is complete. However, based on common machine learning practices, some possible criteria include reaching a certain number of epochs, achieving a desired level of accuracy or loss on the validation set, or observing no significant improvement in validation metrics over several epochs (i.e., a validation loss plateau). In this case, since the context mentions "trials and errors" during the training phase, it suggests that the determination might have been made through empirical observation rather than adherence to a predefined stopping rule. Nonetheless, without more detailed information, we cannot definitively state what criterion was used to decide when training should conclude.