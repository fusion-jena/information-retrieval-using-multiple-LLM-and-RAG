Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The MWST-learned network was used for the final clustering of each 
group  of  variables.  The  connections  between  nodes  for  different  taxa 
variables  were  first  removed  so  that  only  within-taxon  connections 
remained (Fig. S2). The number of factors requested for variable clus-
tering was chosen based on the number of taxa. Multiple clustering was 
used to construct a new latent factor variable for each taxon, generating 
multiple  cluster  states  within  each  latent  factor  variable.  These  four 
latent variables were then themselves clustered to create a higher-level 
latent factor variable, a meta-cluster, that summarized the cluster states 
across  taxa.  This  meta-clustering  provides  a  hierarchical  clustering 
network that summarizes information on the coral reef community from 
the measured variables across taxa. This network also includes all factor 
nodes  and  observable  nodes  from  monitoring  data  so  it  provides  an

cluster but a lower purity would be partially contained in other clusters 
from  the  posterior  probabilities.  Purity  measures  are  computed  as  an 
average  for  each  cluster  and  associated  site  data  and  as  an  overall 
average across all site data and associated cluster states of a latent factor 
variable. The supporting material contains these purity  measures and 
other statistics related to the clusters and resulting network (Table S4). 
The cluster analysis was constrained to a maximum of five states with 
a minimum of two, but low purity measures can exclude some candidate 
clusters. The optimal number of cluster states and the data contained in 
each  was  identified  using  an  automated  expectation-  maximization 
process, described above, based on a random walk with 300 steps for 
minimizing the MDL score. The final ten steps were used to check for 
stability  with  the  number  of  clusters  chosen  for  each  taxon.  A  stable

outcome would have the same number of clusters for all ten final steps. 
The contingency table fit (CTF), a network performance indicator rep-
resenting the quality of the fit to the data, provides a normalized mea-
sure from 0 to 100% with 0% (poorest fit) having the data representation 
skill of an unconnected network and 100% having the joint probability 
representation  of  the  data  of  a  completely  connected  network  (best 
possible fit) (Conrady and Jouffe, 2014; Gerassis et al., 2019). The CTF 
was extracted for the individual taxa factor networks as well as the meta- 
factor network.

All Bayesian network analysis was conducted with BayesiaLab 10.2 
(Bayesia  S.A.S.,  2022)  using  approaches  described  in  the  BayesiaLab 
help  function  and  Conrady  and  Jouffe  (2015).  Coral  reef  monitoring 
variables were discretized prior to analysis. The R2-GenOpt procedure in 
BayesiaLab for discretization was used to reconstruct the existing pat-
terns in the data. The algorithm uses genetic optimization to maximize 
the  R2  between  the  original  raw  data  distribution  and  the  density 
created by the discretization. Three intervals were selected following the 
recommended discretization number in BayesiaLab as calculated from 
the size of the data set. Discretization intervals are displayed in Table S1. 
Quantification  of  the  parameters  was  developed  through  maximum 
likelihood estimation of the parent/child state occurrences in the data-
set. This uses the counts of the data for establishing a probability for

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit details about how the hyperparameters of the model are optimized. However, there is mention of an "automated expectation-maximization process" used for identifying the optimal number of cluster states and the data contained in each. Additionally, a "random walk with 300 steps for minimizing the MDL score" is mentioned, which could potentially be part of this optimization process. Unfortunately, without more specific information, we cannot definitively determine whether techniques such as grid search or random search were employed for hyperparameter optimization.