Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

All architectures were trained with stochastic gradient descent using a similar protocol,
with a momentum of 0.9 and starting from an initial learning rate of 10−2. Every 20 epochs,
the learning rate is divided by 10 until reaching 10−6.

Neural networks do not perform well when trained with unbalanced data sets [41]. In
the case of “central-pixel labeling” architectures it is possible to make balanced data sets
with the initial pixels selection used for the learning. In the case of “semantic labeling” the
composition of the images makes it more difﬁcult to precisely control the number of pixels
per class. We tried several methods, but found negligible differences in performance. All
reported experiments use the median frequency balancing method.

3.3.1. Central-Pixel Labeling

3.4. Sampling Method

The SPOT6 satellite data for our ﬁve study areas were preprocessed to be fed into the
different Deep Learning architectures and the XGBoost model. First, the data were split
into three mutually exclusive parts: a learning set, a validation set and a test set totally
independent of the two previous ones.

Four of the ﬁve areas were used for learning and validation. The last, isolated scene
was then used as the test set. It contained all the classes for the two nomenclatures, the ﬁve
LC classes, and the 12 LU classes. In addition, this image contained all the environments
representing the New Caledonian landscape: urban, mining, mountainous and forest
environment with variations from the coastline to the inland mountain areas. It is on this
entire scene that the ﬁnal confusion matrix and quality metrics were computed.

40.32%
35.97%
46.56%
50.21%
38.75%
50.40%
48.38%

For the LU detection task, all deep learning techniques except AlexNet outperformed
XGBoost. Differences were signiﬁcant, with up to 15 percent points in OA. As in the
previous section, the best performing “single-pixel” architecture is DenseNet and the best
“semantic labeling” network is DeepLab. Interestingly, DenseNet reached the best PA,
although DeepLab dominated the remaining metrics.

For the remainder of this study, the best performing “single-pixel” and “semantic
labeling” were selected. There was little difference between the architectures, so the
architectures with the best F1-score for the LU classiﬁcation were chosen arbitrarily.

4.3. Inﬂuence of Neo-Channels and Land Cover as Input on the Learning

4.4. Confusion Matrix of the Best Deep Learning Model for LULC Classiﬁcation

The results of the best performing architecture for the LULC classiﬁcation task,
DeepLab, is detailed with two confusion matrices. Table 10 shows The LC classiﬁca-
tion task with the raw channels as input, and the LU classiﬁcation task with the LCE in
addition to the raw channels, is in Table 11. The resulting maps of the LU labelling task are
shown in Figure 9.

Table 10. Land cover confusion matrix of DeepLab.

Predicted

Buildings

Bare Soil

Forest

Low-Density Vegetation

Water Surfaces

Buildings
Bare soil
Forest
Low-density vegetation
Water surfaces

0.43
0.24
0.18
0.15
0

0
0.84
0.02
0.14
0

0
0.02
0.78
0.19
0.01

0
0.04
0.12
0.84
0

Table 11. Land use confusion matrix of DeepLab + LCM.

Predicted

s
a
e
r
A

l
a
i
r
t
s
u
d
n
I

0.32
0.43

0

0.18
0.01
0.03

0.02

s
a
e
r

A
n
a
b
r

U

0.72
0.03

0

0.05
0.01
0.06

0.09

0.04

0.01

0
0
0
0

0
0
0
0

d
n
a

s
e
t
i
s
k
r
o
W

s
e
n
i
M

0
0

0.86

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information available to provide a specific answer regarding the deployment process of the trained deep learning models mentioned in the given context. However, generally speaking, after training a deep learning model, the common steps involved in its deployment include saving or serializing the model, selecting a platform for hosting the model, and integrating the deployed model into an application or service. This usually involves exporting the model weights and architecture details into a file format such as HDF5, ONNX, or TensorFlow SavedModel, which can later be loaded onto a server or cloud environment. Popular platforms for deploying machine learning models include AWS SageMaker, Google Cloud AI Platform, Azure Machine Learning Studio, and others. Without further context, I cannot provide any specific details about the deployment process for these particular models.