Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Tree Type

Silk ﬂoss tree
Banyan tree
Flame tree
Longan
Banana
Papaya
Bauhinia
Eucalyptus trees
Carambola
Sakura tree
Pond cypress
Alstonia scholaris
Bischoﬁa javanica
Hibiscus tiliaceus
Litchi
Mango tree
Camphor tree
Others

Table 2. Classiﬁcation accuracies of the three deep learning algorithms.

VGG16 (140,000)

ResNet50 (110,000)

AlexNet (100,000)

UA (%)

PA (%)

F1-Score UA (%)

PA (%)

F1-Score UA (%)

PA (%)

F1-Score

55.56
76.47
90.20
80.77
100.00
100.00
81.61
100.00
76.47
100.00
100.00
83.33
89.19
100.00
15.00
28.57
27.59
59.14

30.61
59.77
80.70
40.38
93.75
100.00
77.17
88.00
86.67
100.00
88.89
71.43
66.00
76.92
50.00
60.00
44.44
79.11
OA = 73.25%
Kappa = 69.76%

39.47
67.10
85.19
53.85
96.77
100.00
79.33
93.62
81.25
100.00
94.12
76.92
75.86
86.96
23.08
38.71
34.04
67.68

44.44
86.76
90.20
88.46
100.00
100.00
83.91
100.00
82.35
96.88
83.33
83.33
83.78
95.00
40.00
38.10
24.14
55.48

Table 2 reports the accuracies obtained from the testing samples with the abovementioned
best training models. Taking advantage of patch-based training samples, CNNs are able to learn
discriminative texture features to identify tree species. Among the three networks, VGG16 achieved
the highest precision with an overall accuracy of 73.25%, ResNet50 achieved a slightly lower accuracy
with an overall accuracy of 72.93%, while AlexNet performed the worst with an overall accuracy of
68.53%. In the results of VGG16 and ResNet50, most of the trees could be classiﬁed well, and trees
such as banana, papaya, sakura tree, and Hibiscus tiliaceus had both higher user’s and producer’s
accuracies. Although hyperspectral chemical information was not included, the spatial or textural
features extracted by the CNN could identify these species well, especially the trees with special leaf
shapes. However, there were also some trees that performed poorly in classiﬁcation, such as the silk

= 0.7907,
RMSEMargalef
= 0.3053). While challenges remain for
RMSESimpson
individual tree detection and species classiﬁcation, the deep-learning-based solution shows potential
for mapping tree species diversity.

In their review, Ma et al. [26] showed that nearly 200 publications using deep convolutional neural
networks (CNNs) have been published in the ﬁeld of remote sensing by early 2019 of which most
focused on land use land cover (LULC) classiﬁcation [28], urban feature extraction [29–31], and
crop detection [32,33]. Deep learning approaches often require a large amount of training data, and
there are benchmark datasets publicly available for training and testing of deep learning approaches
in the abovementioned remote sensing ﬁelds. Compared with the studies mentioned above, very
few studies using deep learning have focused on trees or forest classiﬁcation [34]. Flood et al. [35]
used a U-net convolutional neural network to extract woody vegetation extent from high-resolution
three-band Earth-I imagery. In their research, a selection of 1 km2 was manually labeled for training.
The ﬁnal results were pixel-wise and only two types (trees and large shrubs) were mapped. If there are

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To evaluate the performance of the deep learning models, several metrics are used. These include Overall Accuracy (OA), Kappa Coefficient, User's Accuracy (UA), Producer's Accuracy (PA), and F1-score. The OA is calculated as the percentage of correctly classified pixels out of all test pixels. The Kappa Coefficient measures the agreement between predicted and actual classes, taking into account chance agreements. UA is the proportion of correct predictions among all positive predictions made by the model, while PA is the proportion of correct predictions among all actual positives. The F1-score combines Precision (which is equivalent to UA) and Recall (equivalent to PA) into a single metric, providing a more balanced evaluation of the model's performance. In Table 2, the performance of the three deep learning algorithms (VGG16, ResNet50, and AlexNet) is evaluated based on these metrics. For instance, VGG16 has an OA of 73.25% and a Kappa coefficient of 69.76%, indicating good performance.