Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Supplementary Materials: The following are available online at http://www.mdpi.com/2072-4292/12/3/343/s1,
Figure S1: Number of results in the Google scholar academic search engine. Date of queries, 28 December 2019.
[keyword + deep learning]. Keywords: AlexNet, DenseNet, GoogLeNet, Inception, MobileNet, Resnet, Resnext,
VGG, Xception. Figure S2: Illustration of the diﬀerence between the sampling design strategies, (A) Continuous
and (B) Discrete, including examples of images (0.5 ha) from each class (Three Tree-Cover levels plus the Non-Forest
class) of the training dataset. Image data: Google, Maxar, and NWPU-RESISC45 dataset. Archive S1: Metadata of
FAO’s GDA photointerpreted very high resolution plots (71,135) with zoom 19 in Google Maps. The CVS ﬁle
contains Id, UpperLeft and Downright coordinates, Zoom, Region, Aridity level, Class (Forest/Non-forest), and
Tree cover. Archive S2: Metadata of training dataset of continuous larger sample CNN-based model with very

74. LeCun, Y.; Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436. [CrossRef]
75. Lynch, C. Big data: How do your data grow? Nature 2008, 455, 28. [CrossRef]
76.

Steinkraus, D.; Buck, I.; Simard, P.Y. Using GPUs for machine learning algorithms. In Proceedings of
the Eighth International Conference on Document Analysis and Recognition (ICDAR’05), Seoul, Korea,
31 August–1 September 2005; pp. 1115–1120.

77. Bremond, L.; Alexandre, A.; Hély, C.; Guiot, J. A phytolith index as a proxy of tree cover density in
tropical areas: Calibration with Leaf Area Index along a forest–savanna transect in southeastern Cameroon.
Glob. Planet. Chang. 2005, 45, 277–293. [CrossRef]

78. Achard, F.; Eva, H.D.; Mayaux, P.; Stibig, H.J.; Belward, A. Improved estimates of net carbon emissions from

land cover change in the tropics for the 1990s. Glob. Biogeochem. Cycles 2004, 18. [CrossRef]

For this, we obtained ﬁve models by training Inception v.3 on the ﬁve created datasets. Several
studies have shown that increasing the size of the dataset using data augmentation improves the
performance of the CNN-based models [49,50]. These techniques have been proposed to reduce the
requirement of a large dataset for model training [43–45]. We conﬁgured the model parameters by
training the last two fully connected network layers in our dataset using a learning rate of 0.001 and a
decay factor of 16 every 30 epochs. As an optimization algorithm, we used RMSProp with a momentum
of 0.9 and epsilon of 0.1.

high resolution plots (286) and zoom 19 in Google Maps. The CVS ﬁle contains Id, UpperLeft and Downright
coordinates, Zoom, Region, Aridity level, Class (Forest/Non-Forest), and Tree cover. Archive S3: Metadata of the
results of CNN-based models in 396 plots. The CVS ﬁle contains Id, UpperLeft and Downright coordinates, Region,
Aridity level, Class (Forest/Non-Forest), and Tree cover. Consensus results. Precision, Recall, and F1-measure.
Table S1: Representativeness of the database for external validation of the CNN-method that classiﬁes orthoimages
into tree cover classes. A total of 396 images were sampled globally stratiﬁed across the diﬀerent combinations
of regions, aridity levels, tree cover levels and forest and non-forest classes according to Bastin et al. (2017).
Some combinations did not exist or did not have images with good quality. NF (Non-Forest), F(Forest), TC (Tree

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of a specific code repository link for the deep learning pipeline. Therefore, it cannot be determined where the source code resides, whether it is hosted on platforms such as GitHub, GitLab, or BitBucket. To find out more about the code repository, additional resources or documentation would need to be consulted.