Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

TABLE 3. Classification performance of different methods using single
CNN-based model. Here, Mel-CNN, Harm-CNN, and Perc-CNN denote that
the input to those CNNs are Mel-spectrogram, harmonic-component
based spectrogram, and percussive-component based spectrogram.
Subnet-CNN denotes that a SubSpectralNet architecture is used with the
Mel-spectrogram as the input.

[21] Y.
by
divisions,’’
Available:
classiﬁcation-results-a

‘‘Acoustic
based

Sakashita
ensemble

adaptive
2018.

scene

on

[22] J. Salamon, J. P. Bello, A. Farnsworth, and S. Kelling, ‘‘Fusing shallow
and deep learning for bioacoustic bird species classiﬁcation,’’ in Proc.
IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), Mar. 2017,
pp. 141–145.

[23] J. Salamon, J. P. Bello, A. Farnsworth, M. Robbins, S. Keen, H. Klinck,
and S. Kelling, ‘‘Towards the automatic classiﬁcation of avian ﬂight
calls for bioacoustic monitoring,’’ PLoS ONE, vol. 11, no. 11, pp. 1–26,
Nov. 2016.

[24] K. Simonyan and A. Zisserman, ‘‘Very deep convolutional networks for
large-scale image recognition,’’ in Proc. 3rd Int. Conf. Learn. Repre-
sentations, (ICLR), San Diego, CA, USA, 2015. [Online]. Available:
http://arxiv.org/abs/1409.1556

trogram. In addition to different TFRs, a different deep learning architecture, SubSpectralNet, is employed
to classify bird sounds. Experimental results on classifying 43 bird species show that fusing selected deep
learning models can effectively increase the classiﬁcation performance. Our best fused model can achieve a
balanced accuracy of 86.31% and a weighted F1-score of 93.31%.

[13] Á. Incze, H. Jancsó, Z. Szilágyi, A. Farkas, and C. Sulyok, ‘‘Bird sound
recognition using a convolutional neural network,’’ in Proc. IEEE 16th Int.
Symp. Intell. Syst. Inform. (SISY), Sep. 2018, pp. 000295–000300.
[14] P. Jancovic and M. Köküer, ‘‘Bird species recognition using unsu-
pervised modeling of individual vocalization elements,’’ IEEE/ACM
Trans. Audio, Speech, Language Process., vol. 27, no. 5, pp. 932–947,
May 2019.

[15] E. C. Knight, S. P. Hernandez, E. M. Bayne, V. Bulitko, and B. V. Tucker,
‘‘Pre-processing spectrogram parameters improve the accuracy of bioa-
coustic classiﬁcation using convolutional neural networks,’’ Bioacoustics,
pp. 1–19, 2019, doi: 10.1080/09524622.2019.1606734.

[16] Q. Kong, Y. Xu, and M. D. Plumbley, ‘‘Joint detection and classiﬁca-
tion convolutional neural network on weakly labelled bird audio detec-
tion,’’ in Proc. 25th Eur. Signal Process. Conf. (EUSIPCO), Aug. 2017,
pp. 1749–1753.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide information about how the hyperparameters of the model were optimized. Therefore, it is not possible to determine whether grid search, random search, or any other method was used for hyperparameter optimization.