Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.6. Model selection 

Since  performance,  accuracy,  key  parameters,  and  sensitivity  for 
prediction vary depending on which method that is used (Diniz-Filho 
et al., 2009; Elith et al., 2006; Qiao et al., 2015), we tested eight different 
machine  learning  algorithms  to  generate  our  predictive  models.  The 
included  algorithms  were:  Generalized  Linear  Model  (GLM),  Support 
Vector  Machine  (SVM),  Multivariate  Adaptive  Regression  Spline 
(MARS),  Random  Forest  (RF),  Flexible  Discriminant  Analysis  (FDA), 
Classification  and  Regression  Trees  (CART),  Generalized  Boosting 
regression Model (GBM) and Maximum-Entropy learning (MAXENT) for 
habitat suitability prediction (Table S5). 

2.7. Ensemble modeling approach

The prediction power with machine learning algorithms was tested 
with the package “sdm”  (Naimi and Araújo, 2016), “dismo”  (Hijmans 
et al., 2015), “bioclim” (Booth et al., 2014), and the ensemble modeling 
approach  implemented  in  “biomod2”  (Thuiller  et  al.,  2009;  2014). 
Model mean performances for AUC, ROC, TSS, KAPPA, and COR values 
were extracted using “shiny” packages (Chang et al., 2023) in RStudio 
(RStudio Team, 2020). 

2.10. Statistical analysis

EcologicalInformatics78(2023)1023465M. Abdelgadir et al.                                                                                                                                                                                                                            

importance,  and  regularized  training  gain  for  each  variable.  Here,  a 
variable  with  highest  regularized  training  gain  is  indicating  that  this 
variable  has  the  most  useful  information  on  its  own  when  used  in 
isolation. Model sensitivity and accuracy for habitat suitability were also 
checked  with  the  AUC  values.  Graphical  representation  of  MAXENT 
models were produced in QGIS Desktop v 3.24.2 (QGIS Development 
Team, 2022).

To verify the model’s validity, 30% of each taxon’s data records were 
utilized as testing data, while the remaining 70% were used as training 
data.  After  10  K-fold  cross-validation  and  10-fold  bootstrapping,  all 
models  were  assessed  based  on  the  mean  values  for  Area  Under  the 
Curve AUC (Hanley and McNeil, 1982), True Skill Statistics TSS (Mon-
serud  and  Leemans,  1992),  Cohen’s  KAPPA  (Allouche  et  al.,  2006), 
point-biserial correlation COR (Elith et al., 2010), and Receiver Oper-
ator Characteristics ROC (Hanley and McNeil, 1982). Bootstrapping was 
used  to  provide  unbiased  predictive  accuracy  with  a  sufficiently  low 
variance  (Harrell  et  al.,  2005;  Lima  et  al.,  2019).  For  the  model 
threshold,  the  sensitivity-specificity  sum  maximization  technique  was 
employed  (Liu  et  al.,  2005).  According  to  this  evaluation  criterion, 
species distribution can be accurately predicted (Liu et al., 2005). For

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To ensure the generalizability of their deep learning model, M. Abdelgadir et al. employed several measures. They utilized diverse datasets by including eight different machine learning algorithms to generate their predictive models. These algorithms included Generalized Linear Model (GLM), Support Vector Machine (SVM), Multivariate Adaptive Regression Spline (MARS), Random Forest (RF), Flexible Discriminant Analysis (FDA), Classification and Regression Trees (CART), Generalized Boosting regression Model (GBM), and Maximum-Entropy learning (MAXENT) for habitat suitability prediction.

Cross-validation was performed through 10 K-fold cross-validation and 10-fold bootstrapping. This process helped evaluate the models based on various metrics such as Area Under the Curve (AUC), True Skill Statistics (TSS), Cohen’s KAPPA, point-biserial correlation (COR), and Receiver Operator Characteristics (ROC). Bootstrapping was specifically used to provide unbiased predictive accuracy with a sufficiently low variance.

Stratified splitting was applied by dividing the data into training and testing sets, with 70% of each taxon’s data records being used for training and the remaining 30% for testing. This ensured that both the training and testing datasets contained representative samples from each class or category, thereby improving the model’s ability to generalize well to new, unseen data.

Overall, these measures aimed to enhance the robustness and reliability of the deep learning model, ensuring it could effectively handle diverse datasets and produce accurate predictions across various scenarios.