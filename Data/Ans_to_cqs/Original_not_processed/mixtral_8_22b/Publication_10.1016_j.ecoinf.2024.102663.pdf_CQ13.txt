Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)10266317S.V. Jansi Rani et al.                                                                                                                                                                                                                           

Fig. 13. Epochs 10 vs. 50.  

Fig. 16. Final learning rate 0.005 vs 0.01 vs 0.02.  

Fig. 14. cos_lr False vs. True.  

Fig. 17. Optimizer RMSProp vs SGD vs AdamW.  

Fig. 15. Initial learning rate 0.005 vs. 0.01 vs. 0.02.

Random Forest Regressor exhibits the longest training time. However, 
the potential improvement in performance may warrant the investment 
of additional effort. Performance of Linear Regression, Lasso, and Ridge 
models is deemed unsatisfactory despite their efficient training times.

1. Introduction 

Fish biomass estimation is essential for the fisheries and aquaculture 
industries  (Li  et  al.,  2020).  Manual  methods  of  estimation  can  be 
strenuous for the fish. Thus, there is a need for non-intrusive methods of 
fish  biomass  estimation.  Biomass  estimation  in  a  turbid  environment 
also comes with several challenges. This is where deep learning can play 
a  vital  role.  Training  a  deep  learning  model  on  large  datasets  of  fish 
images  can  provide  accurate  biomass  estimates  without  causing  un-
necessary  strain  to  the  fish  and  minimizes  manual  effort.  Hence,  the 
motivation of this research lies in providing an efficient, precise, and 
cost-effective  method  for  estimating  fish  biomass  in  turbid  environ-
ments. The reliance on fishing and aquaculture is a prominent charac-
teristic of numerous societies, playing a substantial role in bolstering the 

economic and social vitality of various nations and locations.

The graphs show how different inputs affect the output metrics. All 
parameters are kept the same except for the one that was studied. For 
example,  Fig.  13  shows  how  the  output  values  of  precision,  recall, 
mAP50  and  mAP50â€“95  are  affected  when  the  number  of  epochs  is 
changed from 10 to 50. Increasing the number of epochs from 10 to 50 
has a greater effect on the output metrics in that the performance in-
creases as the number of epochs increases. For the input parameter cos_lr 
(cosine  learning  rate  scheduler),  as  shown  in  Fig.  14,  using  a  cosine 
curve for the learning rate has different effects on the output. For some 
output  metrics,  not using the  cosine curve  is  better,  while for  others, 
using the curve is better. For initial and final learning rates, shown in 
Fig.  15  and  Fig.  16,  respectively,  the  outputs  differ,  but  it  can  be 
observed that it is good to stop at the optimal level. When increasing the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, the hyperparameters used in the deep learning model include the number of epochs, learning rate, use of cosine learning rate scheduler, and choice of optimizer. Specifically, the figures mentioned in the context compare the results obtained by varying these parameters. Figure 13 compares the performance between 10 and 50 epochs, showing that increasing the number of epochs improves the performance. Figure 14 examines the impact of using or not using the cosine learning rate scheduler, indicating mixed results depending on the specific metric being evaluated. Figures 15 and 16 explore the influence of changing the initial and final learning rates, suggesting that finding the optimal value is important. Lastly, Figure 17 contrasts three different optimizers - RMSProp, SGD, and AdamW - implying that the choice of optimizer also affects the outcome.