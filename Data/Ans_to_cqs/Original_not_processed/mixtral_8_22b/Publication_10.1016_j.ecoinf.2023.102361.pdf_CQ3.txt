Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.2. Split the datasets 

In this research, the datasets were randomly divided into three parts 
for training, validation and testing. Here, 60% of the data was used to 
train the deep learning models, and 20% of them was kept to validate the 
models. The remaining 20% data was used to evaluate the performance 
of the models. Table 1 show the number of data in the dataset and how 
they are separated for training, testing and validation. 

2.3. Deep learning models

applications of this approach could be automatic annotation of data. If 
there  is  a  larger  number  of  image  data  to  be  labelled,  then  train  the 
model with a small subset of the dataset and use that trained model to 
annotate the  rest. Moreover, these techniques can be used to achieve 
better classification accuracy.

diction  of  the  deep  learning  model.  This  dataset  was  taken  to  verify 
whether our proposed approach can handle that issue. The dataset was 
shared  by  Jiang  et  al.  (2020)  through  the  Github  repository: 
https://github.com/zhangchuanyin/weed-datasets.

VGG16 and VGG19 are classical architectures that are well known 
for  simplicity  and  uniformity.  These  models  are  suitable  for  smaller 
datasets and can provide better accuracy by fine-tuning the pre-trained 
network (Sukegawa et al., 2020). The models have several drawbacks, 
such  as  vanishing  gradient  problems  and  loss  of  fine-grained  spatial 
information (Pan et al., 2020). On the other hand, ResNet-50 contains 
residual  connections,  which  can  overcome  the  vanishing  gradient 
problem and enable training very deep networks. The model performs 
well on both large and small datasets (Al-Masni et al., 2020).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data annotation techniques used in the deep learning pipeline (e.g., bounding box annotation, instance segmentation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention any specific data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, it does suggest that one application of their approach could involve using a trained model to automatically annotate a larger set of unlabeled image data. This implies that some form of data annotation technique may have been employed during the initial labeling process, but the exact method remains unspecified within the given information.