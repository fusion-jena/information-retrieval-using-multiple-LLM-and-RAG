Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3.3. Network architecture 

The architecture used was a heavily modified version of that used in 
“Unsupervised Deep Learning with Pytorch” by github user “eelxpeng” 
(eelxpeng, 2018). As the size of our audio spectrograms has been con-
strained to 128 × 128 pixel RGB images with values repeated in each 
color channel to produce a greyscale image. For this initial experiment 
testing  the feasibility of using an auto-encoder-generated feature rep-
resentation for ecoacoustic analysis, we chose a basic auto-encoder ar-
chitecture  to  minimise  the  complications  that  may  be  introduced  by 
more advanced architectures. A rectified linear unit (ReLU) based acti-
vation function was be used, to help mitigate the vanishing/exploding 
gradient  problem  (Xu  et  al.,  2015).  Networks  using  implicit  pooling 
(determined using pytorch) and explicit max-pooling were used.

Table 3 
Comparing the variance of bcubed and purity evaluation metrics of feature representations found using Spectral Indices, MFCC and Auto Encoder over 20 runs using a 
subset of the total dataset.   

Vector size 

bcubed precision (Variance) 

bcubed recall (Variance) 

bcubed Fscore (Variance) 

Purity (Variance) 

Spectral indices 
MFCC 
Auto encoder (implicit) 
Auto encoder (explicit max-pooling) 

2048 
1287 
384 
384 

0.003 
0.006 
0.002 
0.0007 

0.006 
0.007 
0.001 
0.0007 

0.003 
0.006 
0.002 
0.0006 

0.003 
0.005 
0.002 
0.001  

Fig.  10. 2nd t-SNE plot  generated using  spectral indices.  Cluster  represented  by color  and species  ground-truth represented  by  shape.(For  interpretation  of  the 
references to color in this figure legend, the reader is referred to the web version of this article.) 

by Dias, et al., uses varying length spectrograms, and does not focus on 
individual call types directly directly (Dias et al., 2020).

Xu, B., Wang, N., Chen, T., Li, M., 2015. Empirical Evaluation of Rectified Activations in 

Stowell, D., Plumbley, M.D., 2010. Birdsong and c4dm: A Survey of Uk Birdsong and 

Convolutional Network. arXiv preprint arXiv:1505.00853. 

Machine Recognition for Music Researchers. Centre for Digital Music, Queen Mary 
University of London. Tech. Rep. C4DM-TR-09-12.  

Towsey, M., Wimmer, J., Williamson, I., Roe, P., 2014. The use of acoustic indices to 
determine avian species richness in audio-recordings of the environment. Ecol. 

Xu, Y., Huang, Q., Wang, W., Foster, P., Sigtia, S., Jackson, P.J.B., Plumbley, M.D., June 
2017. Unsupervised feature learning based on deep models for environmental audio 
tagging. IEEE/ACM Trans. Audio Speech Lang. Process. 25 (6), 1230–1241. 
Zhao, J., Li, J., Zhao, F., Yan, S., Feng, J., 2017. Marginalized cnn: Learning Deep 

Invariant Representations. 

EcologicalInformatics62(2021)10123712

Table 2 
Comparing the standard deviation of bcubed and purity evaluation metrics of feature representations found using Spectral Indices, MFCC and Auto Encoder over 20 
runs using a subset of the total dataset.   

Spectral indices 
MFCC 
Auto encoder (implicit) 
Auto encoder (explicit max- 

pooling) 

Vector 
size 

2048 
1287 
384 
384 

bcubed precision (standard 
deviation) 

bcubed recall (standard 
deviation) 

bcubed Fscore (standard 
deviation) 

Purity (standard 
deviation) 

0.06 
0.08 
0.05 
0.03 

0.08 
0.08 
0.04 
0.03 

0.06 
0.07 
0.04 
0.03 

0.06 
0.07 
0.05 
0.03  

EcologicalInformatics62(2021)1012378B. Rowe et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What measures were taken to ensure the generalizability of the deep learning model (e.g., Diverse dataset, cross-validation, Stratified splitting)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, it appears that the authors have conducted their experiments using a subset of the total dataset and performed multiple runs (specifically, 20 runs) to evaluate the performance of different feature representation methods such as Spectral Indices, MFCC, and Auto Encoders. This approach can contribute to ensuring the generalizability of the deep learning model. However, there is no specific mention of other techniques like diverse datasets, cross-validation, or stratified splitting being employed to further enhance the model's robustness and generalization capabilities. Therefore, while some steps towards ensuring generalizability are evident from the available data, additional details regarding the application of more sophisticated validation strategies would be required to provide a comprehensive response.