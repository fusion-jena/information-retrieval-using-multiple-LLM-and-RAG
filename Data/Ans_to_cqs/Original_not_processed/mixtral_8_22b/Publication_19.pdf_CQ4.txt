Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

TABLE II.  

HYPERPARAMETERS DETERMINED USING GRID SEARCH 

Model Name 

Inception-V3 
MobileNet-V2 
ResNet-18 
DenseNet-121 

Batch 
Size 
48 
32 
32 
16 

Learning 
Rate 
0.05 
0.01 
0.005 
0.001 

Parameters 
# of 
Epochs 
75 
100 
150 
100 

Input Image Size 

299 (cid:3400) 299 (cid:3400) 3 
224 (cid:3400) 224 (cid:3400) 3 
224 (cid:3400) 224 (cid:3400) 3 
224 (cid:3400) 224 (cid:3400) 3 

C.  Results 

  As  Table  III  show  all  models  performed  reasonably  well 
with macro-F1 averages above 91%. Because the models are to 
be deployed on IoT edge devices, the size of each model is an 
important  consideration.  As  Table  III  shows 
the  best 
performing model was Inception-V3 with a macro Average F1 
score of 0.93, and the smallest size of 175 MB.   

TABLE III.  

BEST RESULTS FOR EACH NN ARCHITECTURE 

Model 

InceptionV3 
DenseNet-121 
ResNet-18 
MobileNetV2 

Model Size 
(MB) 
175 
446 
480 
507 

Accuracy 

94% 
93% 
92% 
93%

Keywordsâ€”deep  learning,  transfer  learning,  convolutional 
neural  networks,  animal  classification,  camera  trap,  wildlife 
monitoring, edge computing, TensorFlow lite, raspberry pi, IoT 

I.  INTRODUCTION

results.  
   This 
However, a number of issues need to be addressed further.  First 
the data is highly unbalanced, and therefore, using SMOTE [23] 
or  similar  data  balancing  techniques  may  help  improve  the 
results further.  Secondly, recent architectures like EfficientNet 
[19]  that  performed  well  in  creating  smaller  networks  can  be 
explored  further.  In  fact,  our  initial  investigations  show  that 
EfficientNetB1 produced performance similar to Inception-V3 
(F1-score  macro  average  =  0.94)  on  this  data  set  as  well  but 
with a much smaller model size (~ 54 MB).  
   This  paper  showed  that  potentially  significant  gains  can  be 
achieved in reducing both the time to reporting, and the effort 
required 
traps.  
Consequently,  using  deep  learning  technologies  on  the  edge 
with  an  IoT  infrastructure  can  potentially  revolutionize  the 
camera  trap  value-chain.  Finally,  since  the  inference  is  being

Finally,  a  recent  architecture  called  EfficientNet  [19] 
achieved 84.4% top-1 and 97.5% top-5 accuracy on ImageNet 

while  being  6.1x  faster  on  inference  than  the  best  existing 
ConvNet and 8.4x smaller. The small size of the model and high 
accuracy achieved make this architecture a good candidate for 
running on edge devices.  

B.  Embedded Devices for the Edge Inference  
   Many neural networks have been deployed on edge devices 
for  the  purposes  of  animal  classification.  The  most  common 
edge  device  used  was  a  Raspberry  Pi  (RPi)  [11],  [14],  [20], 
[21],[22].

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the specific data augmentation techniques applied in the deep learning pipeline. However, it mentions that the input image sizes were 299 x 299 x 3 and 224 x 224 x 3 pixels, which suggests that some form of resizing or scaling might have been applied during preprocessing. Additionally, the use of convolutional neural networks implies that the images underwent spatial transformations such as flipping, rotation, and cropping. Nevertheless, without explicit mention of these techniques in the context, we cannot confirm their application.