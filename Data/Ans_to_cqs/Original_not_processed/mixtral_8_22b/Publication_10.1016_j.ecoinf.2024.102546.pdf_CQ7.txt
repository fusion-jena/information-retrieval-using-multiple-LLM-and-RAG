Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3. Materials and methods 

3.1. Dataset curation

6  https://github.com/ultralytics/ultralytics/issues/189 

EcologicalInformatics81(2024)1025466B. Deng et al.                                                                                                                                                                                                                                    

Fig. 3. Flowchart of our cross-season weed detection.  

Table 2 
Primary hyperparameter settings of the three detection models.  

Hyperparameters 

Detection models 

Initial learning 

rate 

Learning rate 
schedule 
NMS threshold 
Confidence 
threshold 
Weight decay 
Image size 
Batch size 

Optimizer 

YOLOX 

YOLOv8 

0.01 

0.01 

Warm up +
cosine decay 
0.45 

Warm up + cosine 
decay 
0.7 

0.25 

0.0005 
800 
8 

SGD 

0.25 

0.0005 
800 
8 

SGD 

Classification loss 

BCE 

Location loss 

IoU 

Data augmentation 

Color jitter 
+ mosaic 

VFL (Zhang et al., 
2021) 
DFL (Li et al., 2020) 
+ CIoU (Zheng et al., 
2021)

References 

Ahmad, A., Saraswat, D., Aggarwal, V., Etienne, A., Hancock, B., 2021. Performance of 
deep learning models for classifying and detecting common weeds in corn and 
soybean production systems. Comput. Electron. Agric. 184, 106081. 
Alam, M.S., Alam, M., Tufail, M., Khan, M.U., Günes¸, A., Salah, B., Nasir, F.E., 

Saleem, W., Khan, M.T., 2022. TobSet: A new tobacco crop and weeds image dataset 
and its utilization for vision-based spraying by agricultural robots. Appl. Sci. 12 (3), 
1308. 

Allmendinger, A., Spaeth, M., Saile, M., Peteinatos, G.G., Gerhards, R., 2022. Precision 
chemical weed management strategies: A review and a design of a new CNN-based 
modular spot sprayer. Agronomy 12 (7), 1620. 

Beck, Michael A., Liu, Chen-Yi, Bidinosti, Christopher P., Henry, Christopher J., 

Godee, Cara M., Ajmani, Manisha, 2021. Presenting an extensive lab-and field-image 
dataset of crops and weeds for computer vision tasks in agriculture. arXiv preprint 
arXiv:2108.05789.

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

Weed database development: An updated survey of public weed datasets 
and cross-season weed detection adaptation 

Boyang Deng , Yuzhen Lu *, Jiajun Xu 

Department of Biosystems & Agricultural Engineering, Michigan State University, East Lansing, MI 48824, United States of America   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Deep learning 
Domain adaptation 
Machine vision 
Precision agriculture 
Robustness 
Weed detection

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The paper does not provide explicit information on how the authors split their data for deep learning model training (e.g., into train, test, and validation sets). However, it is common practice in machine learning to use a portion of the dataset for training the model, another portion for validating the model during training, and a final portion for testing the model after training. This helps ensure that the model can generalize well to unseen data. Typically, the dataset is divided randomly into these subsets, with the most common ratios being 70% for training, 15% for validation, and 15% for testing. These percentages may vary depending on the specific requirements and constraints of each project.