Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  YOLOv8  algorithm  offers  a  range  of  network  structures, 
including  YOLOv8n,  YOLOv8s,  YOLOv8m,  YOLOv8l,  and  YOLOv8x. 
While they differ in width and depth, they follow the same principles 
and can be chosen according to specific needs. The deeper the structure, 
the higher the precision, but the slower the training and inference speed. 
YOLOv8n was chosen as the base structure to prioritize speed without 
compromising  accuracy,  with  further  enhancements  to  improve 
performance. 

Adding the P2 feature level to the YOLOv8 architecture makes the 
network  deeper  because  an  additional  layer  is  added  to  the  overall 
network structure. The YOLOv8 architecture already includes a series of 
convolutional  layers  and  a  neck  section  that  combines  features  from 

Fig. 6. Proposed C2f2 layer structure showing the number and order of filters.

It is worth noting, however, that increasing the network depth also 
comes with some potential downsides, such as increased computational 
complexity and a greater risk of overfitting the model to the training 
data. So, adding the P2 layer to the YOLOv8 architecture is a tradeoff 
that needs to be carefully balanced with other considerations, such as 
model size and performance requirements. In this sense, we proposed in 
this work a modification in the C2f layer due to its importance in the 
general architecture of YOLOv8, in the sense of making it lighter and 
counterbalancing  the  increase  obtained  with  the  addition  of  the  P2 
feature level layer. In our work, we call this new layer C2f2.

On the positive side, a smaller model might generalize better on data 
from previously unseen domains or categories, with a reduced capacity 
to  memorize  training  data;  the  model  may  focus  on  learning  more 
generic  features  that  can  be  useful  across  different  datasets  (Seema-
kurthy et al., 2022). As we will see later, this is a goal we seek in our 
model. 

A reduction in the number of filters can lead to faster inference times. 
Using  smartphone  applications,  the  model  may  process  images  more 
quickly, making it suitable for real-time applications or scenarios that 
demand rapid detection, such as NBSB detection and counting (Diwan 
et al., 2023). However, care must be taken, as if the number of filters is 
decreased,  the  model  might  become  more  prone  to  overfitting  the

introduced  variations 

in  color 

The  training  set,  comprising  the  majority  of  the  data  (82%),  con-
taining 4000 images, is used to train the model and adjust its parame-
ters, allowing it to learn from a diverse range of examples and patterns in 
the data. The validation set (13%), consisting of 607 images, is utilized 
during  training  to  fine-tune  hyperparameters  and  assess  the  model's 
performance on unseen data, helping to prevent overfitting and ensuring 
generalization. Lastly, the testing set (5%), which included 260 images, 
serves  as  an  independent  evaluation  of  the  model's  performance  on 
completely unseen data, providing a reliable measure of its real-world 
effectiveness and ability to generalize. 

2.3. Performance evaluation 

To evaluate the ablated model results, we use five metrics, namely 
Precision (Eq. (1)), Recall (Eq. (2)), mAP0.5 and mAP0.5:0.95, related to 
Eq. (3), Params(M), Flops(G), Inference(ms) and Time(h). 

Precision =

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of where the data repository of the deep learning pipeline is available. It could be stored in any of the mentioned platforms like Zenodo, Figshare, Dryad, or GBIF, or even in another platform not listed here. To find out the exact location of the data repository, one would need to refer to the original source of this information or contact the authors directly.