Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Plant biodiversity 
Plant cover 
Deep learning 
Convolutional neural networks 
Semantic segmentation 
Artificial intelligence

Appendix A. Supplementary data 

Supplementary data to this article can be found online at https://doi. 

org/10.1016/j.ecoinf.2024.102516. 

References 

Altalak, M., Ammad uddin, M., Alajmi, A., Rizg, A., 2022. Smart agriculture applications 

using deep learning technologies: A survey. Appl. Sci. 12 (12), 5919. 

Bambil, D., Pistori, H., Bao, F., Weber, V., Alves, F.M., Gonçalves, E.G., de Alencar 
Figueiredo, L.F., Abreu, U.G., Arruda, R., Bortolotto, I.M., 2020. Plant species 
identification using color learning resources, shape, texture, through machine 
learning and artificial neural networks. Environ. Syst. Decis. 40 (4), 480–484. 
Bauer, T., Strauss, P., 2014. A rule-based image analysis approach for calculating 

residues and vegetation cover under field conditions. Catena 113, 363–369. 

Blaschke, T., 2010. Object based image analysis for remote sensing. ISPRS J. 

Photogramm. Remote Sens. 65 (1), 2–16.

2.4. Network setup for investigations 

For extracting plant species cover information for our investigations, 
we  use  the  same  setup  as  described  in  K¨orschens  et  al.  (2021b)  with 
slight differences. During all three phases, we use a ResNet50 (He et al., 
2016),  which  is  initialized  with  ImageNet  (Russakovsky  et  al.,  2015) 
weights from Keras (Chollet et al., 2015) before phase 1 and phase 2, as 
well as the AdamW optimizer (Kingma and Ba, 2014; Loshchilov and 
Hutter, 2017). During each phase, we use the ResNet in conjunction with 
a  Feature  Pyramid  Network  (FPN)  (Lin  et  al.,  2017)  to  increase  the 
network output resolution. Phase-specific parameters are listed in the 

EcologicalInformatics80(2024)1025167M. K¨orschens et al.

extract  plant  cover  information  without  training  on  actual  annotated 
plant cover data. 

2.3.1. Base network

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the data repository of the deep learning pipeline available (e.g., Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The article does not provide explicit information about where the data repository of the deep learning pipeline is available. However, it mentions that supplementary data related to the article can be found online at <https://doi.org/10.1016/j.ecoinf.2024.102516>. This suggests that the authors might have uploaded their dataset or code to a digital object identifier (DOI)-issuing repository such as Zenodo, Figshare, or Dryad. To confirm the exact location of the data repository, one would need to check the DOI link mentioned in the article.