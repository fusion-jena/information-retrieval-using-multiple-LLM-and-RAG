Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

H. ovalis) with a max stride of 32. It is worth noting that data augmen-
tation is a well-proven and common technique to avoid overfitting and 
to render a model generalised. We applied random cropping, horizontal/ 
vertical flipping, image rotation, image translation, zooming, brightness 
adjustment,  contrast  adjustment,  hue  and  saturation  adjustment, 
gaussian  noise,  random  erasing  both  of  our  models  training,  which 
helped increase the size and variability of our dataset.

Recently,  attention  has  focused  on  machine  learning  and  deep- 
learning algorithms to achieve these goals. Deep learning is a branch 
of machine learning and uses algorithms inspired by the function and 
structure of neural networks in the human brain (LeCun et al., 2015). An 
important  part  of  machine  learning  is  feature  engineering,  which  in-
creases  accuracy  and  requires  expertise  in  the  specific  domain  of  the 
problem. The deep learning approaches can perform feature engineering 
independently  by  itself  (Goodfellow  et  al.,  2016;  Jalali  et  al.,  2022). 
Deep-learning are providing state-of-the-art performances of computer 
vision tasks such as classification, detection or segmentation (Kamilaris 
and Prenafeta-Boldu, 2018; Pouyanfar et al., 2018).

Fig. 2. YOLOv5 Architecture.  

EcologicalInformatics76(2023)1020474M.K. Noman et al.                                                                                                                                                                                                                              

Fig. 3. EfficientDet architecture (adopted from (Tan et al., 2020)).  

output feature. Each input layer is given an additional weight, which 
allows the network to learn the important features. Three weight fusion 
approaches are considered:  

(

w

Pout
6 = Conv

′

1.Pin

′

′

2.Ptd
6 + w
1 + w′
w′

6 + w
2 + w′

3.Resize
3 + ϵ

(cid:0)

)

Pout
5

(5) 

1.  Unbounded fusion 

∑

O =

wi.Ii

(1) 

i

A deep-learning model trained using a dataset from one location does 
not  generalise  to  other  locations  owing  to  the  data  distribution  shift 
problem. Some researchers have mitigated the issue of data distribution 
shifts in different locations. For example, Islam et al. (Islam et al., 2019), 
developed a domain adaptation model by utilising a generative adver-
sarial network that aligns marginal data distribution between the target 

and source domains.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The authors use several techniques to address data bias during preprocessing of their deep learning pipeline. They apply data augmentation techniques such as random cropping, horizontal/vertical flipping, image rotation, image translation, zooming, brightness adjustment, contrast adjustment, hue and saturation adjustment, gaussian noise, and random erasing. These techniques help increase the size and variability of their dataset, which helps prevent overfitting and makes the model more generalized. Additionally, they mention the use of domain adaptation models to mitigate the issue of data distribution shifts in different locations. However, they do not specifically mention stratified splitting, oversampling, undersampling, or diverse data collection as techniques used for addressing data bias.