Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

hyperparameters  (i.e.,  ‘AutoML’;  He  et  al.,  2021).  This  represents  an 
important  advantage  for  non-experts  in  deep  learning,  as  it  does  not 
require  the  manual  assembly  of  the  models  and  definition  of  their 
hyperparameters. The AutoML procedure starts by generating a set of 
candidate models with architectures and hyperparameters (e.g. number 
of layers; learning rate) selected at random from a prespecified range of 
values (see Fig. 2). Each candidate model is trained using a small subset 
of the data (data partition At; Fig. 2) during a small number of epochs. 
After  training,  the  performance  of  the  candidate  models  is  compared 
using a left-out validation data set (Av; Fig. 2). The selected candidate 
model (usually the best performing among candidates) is then trained on 
the full training data (Bt; Fig. 2). In this step it is required to identify an 
optimal number of training epochs, to avoid under- or overfitting of the

Intel  i7  4-Core  (3.40GHz)  processor  and  8GB  RAM  and  a  ‘high-end 
workstation’ with an AMD Ryzen 9 12-Core (3.80 GHz) processor, 64 GB 
RAM and a NVidia RTX 2060 GPU. Because CPU- and GPU-based Ten-
sorFlow  generate  distinct  random  hyperparameters,  modelling  results 
will  differ  between  the  two  computer  systems.  We  report  results  and 
processing  times  for  the  desktop  PC  system.  For  the  workstation  we 
report processing time only. We emphasize that the timings recorded in 
the  two  systems  are  not  directly  comparable  as  they  correspond  to 
distinct modelling routes.

It is important to bear in mind that the modelling strategy described 
above  aims  at  general  applicability  and  further  tailoring  for  specific 
classification  tasks  could  be  beneficial.  For  instance,  with  a  priori 
knowledge that a specific architecture, say CNN, is best suited for the 
classification task at hand (see discussion section), the selection could be 
adjusted  to  generate  only  CNN-type  candidate  models.  Further  infor-
mation about fine-tuning of mcfly model generation and selection can be 
found in van Kuppevelt et al. (2020). 

2.7. The case studies

time, from the onset of candidate model training to the 72nd training 
epoch of the selected model, took 26 min on a desktop PC. On the high- 
end workstation, a distinct modelling event took 3 min.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The optimization of the hyperparameters of the model is done through an automated process called AutoML. This process begins by generating a set of candidate models with architectures and hyperparameters chosen randomly within a predefined range of values. These candidate models are then trained using a small portion of the available data for a limited number of epochs. After training, the performance of these candidate models is evaluated using a separate validation dataset. The top-performing candidate model is subsequently trained on the entire training dataset. During this stage, it is crucial to determine an optimal number of training epochs to prevent both underfitting and overfitting. It should also be noted that different hardware configurations may yield varying modeling results due to differences in how TensorFlow generates random hyperparameters when running on CPUs versus GPUs.