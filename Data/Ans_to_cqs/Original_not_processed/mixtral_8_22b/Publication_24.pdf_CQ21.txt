Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

ditional  methods  (Farinha- Marques,  Lameiras,  Fernandes,  Silva,  & 

automatically  based  on  the  annotated  training  data  provided. 

Guilherme, 2011). This inhibits our ability to conduct the large- scale 

Convolutional Neural Networks, CNNs (or Deep learning) (LeCun, 

assessment that is necessary for understanding urban ecosystems.

Bengio,  &  Hinton,  2015)  can  even  choose,  based  on  the  annota-

Ecoacoustic surveying has emerged as a useful method of large- 

tions in the training dataset, the features that discriminate different 

scale  quantification  of  ecological  communities  and  their  habitats 

classes  in  datasets  without  being  specified  a  priori,  and  can  take 

(Sueur  &  Farina,  2015).  Passive  acoustic  recording  equipment  facil-

advantage of large quantities of training data where their ability to 

itates the collection of audio data over long time periods and large

2.1 | Acoustic dataset

ing  training  (see  Supplementary  Methods  for  details).  The  final 

We selected 63 green infrastructure (GI) sites in and around Greater 

layer produced the prediction of presence or absence of biotic or 

London,  UK  to  collect  audio  data  to  train  and  test  the  CityNet 

Audible sounds

One second of audio

Ground truth

Anthropogenic: Yes
Biotic: Yes

Anthropogenic: Yes
Biotic: No

Anthropogenic: No
Biotic: Yes

Anthropogenic: No
Biotic: No

F I G U R E   2  The four acoustic states predicted by the CityNet algorithms. Each 1 s chunk of audio may contain anthropogenic and biotic 
sound (top row), just anthropogenic sound (second row), just biotic sound (third row), or neither biotic nor anthropogenic sound (final row). 
CityBioNet and CityAnthroNet were independently used to detect presence or absence of biotic and anthropogenic sounds, allowing each 
chunk of audio to be categorised into one of four states

Supporting Information section at the end of the article.

How to cite this article: Fairbrass AJ, Firman M, Williams C, 

Brostow GJ, Titheridge H, Jones KE. CityNet—Deep learning 

tools for urban ecoacoustic assessment. Methods Ecol Evol. 

2019;10:186–197. https://doi.org/10.1111/2041-210X.13114

FAIRBRASS et Al. 2041210x, 2019, 2, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13114 by Thuringer Universitats- Und, Wiley Online Library on [16/11/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

ence of biotic sound (True Positives) in a greater proportion of audio 

as  input.  However,  it  does  not  use  the  same  normalisation  strate-

data  than  bulbul  (33.2%  in  comparison  with  18.5%  for  CityBioNet 

gies  as  CityNet,  and  it  was  not  trained  on  data  from  noisy,  urban 

and bulbul respectively) (Table 2). However, CityBioNet failed to cor-

environments.  Bulbul  was  applied  to  each  second  of  audio  data  in 

rectly predict the presence of biotic sound (False Negatives) in 13.5% 

CitySounds2017test,  using  the  pretrained  model  provided  by  the 
 authors together with their code.

2.5 | Impact of non-biotic sounds

of recordings in comparison with 28.0% incorrect predictions by bul-

bul. CityBioNet correctly predicted the absence of biotic sound (True 

Negatives)  in  51.6%  of  the  audio  data  in  comparison  with  52.6%  for 

bulbul, and CityBioNet failed to correctly predict the absence of biotic

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training process, several postprocessing steps can be taken to evaluate and interpret the results. These include:

1. Saliency Maps: These visualize which parts of the input data had the most influence on the model’s output. They help identify important features in the data and can aid in interpreting the model’s decision-making process.

2. Metrics Calculation: Various metrics such as accuracy, precision, recall, and F1 score can be calculated to assess the performance of the model. These metrics provide insights into how well the model is able to classify the data.

3. Confusion Matrix: This is a table layout that allows visualization of the performance of an algorithm. It provides information about actual and predicted values generated by a classification system. It gives us insight not only into the errors made by the classifier but more importantly the types of errors that are being made.

In the given context, the paper discusses the application of Convolutional Neural Networks (CNNs) for urban ecoacoustic assessment. After training the models, the authors likely performed similar postprocessing steps to evaluate and interpret the results. However, the specific steps taken are not explicitly mentioned in the provided context.