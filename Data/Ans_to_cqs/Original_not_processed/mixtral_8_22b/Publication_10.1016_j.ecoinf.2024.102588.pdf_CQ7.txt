Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

12.282, and 13.897 for the validation (Fig. 5a-f). Table 3 lists the mean 
and standard deviation values of the NSE and RMSE driven by the 10- 
fold  cross-validation  of  the  deep  learning  models.  The  CNN  model 
with  the  autoencoder  showed  better  estimation  performance  for  TDI, 
BMI, and FAI than the CNN model estimation without the autoencoder

To  determine  the  optimal  data-driven  model,  the  conventional 
model performances were compared with the estimation performances 
of the CNN and the CNN with the autoencoder. The ANN model uses 
hidden nodes in hidden layers with learnable weights to extract input 
data. The principles of feature extraction and model training are similar 
to those of the autoencoder and CNN models. Six hidden layers were 
designed  with  128,  128,  256,  256,  512,  and  512  nodes.  The  output 
layers with three nodes estimated the three indices. The loss function 
and optimizer were set as the mean squared error and Adam optimizer, 
respectively, at a learning rate of 0.001. The SVM regression model was 
designed to estimate TDI, BMI, and FAI. The kernel function, C-param-
eter, and gamma of the SVM were set to radial basis functions of 100 and 
0.1, respectively. The SVM was unable to estimate the indices simulta-
neously. The RF uses an ensemble regressor by applying multiple deci-

Upadhyay, A.K., Khandelwal, K., 2019. Artificial intelligence-based training learning 
from application. Development and Learning in Organizations: An International 
Journal 33 (2), 20–23. 

Wang, W., Huang, Y., Wang, Y., Wang, L., 2014. Generalized autoencoder: a neural 
network framework for dimensionality reduction. In: Proceedings of the IEEE 
Conference on Computer Vision and Pattern Recognition Workshops, pp. 490–497. 

Wang, Y., Yao, H., Zhao, S., 2016. Auto-encoder based dimensionality reduction. 

Neurocomputing 184, 232–242. 

Wang, L., Zhang, R., Yang, J., Chen, Q., He, M., Wang, J., 2021. A method to determine 
water quality categories based on biotic index of macroinvertebrates in the Yangtze 
River Delta. Ecol. Informat. 66, 101484. 

an overview and application in radiology. Insights Imag. 9 (4), 611–629. 
Yan, X., Mohammadian, A., Ao, R., Liu, J., Yang, N., 2023. Two-dimensional

This  study  used  evaluation  metrics  to  estimate  aquatic  ecosystem 
health  indices  (Moriasi  et  al.,  2007).  The  Nash–Sutcliffe  efficiency 
(NSE), Root Mean Squared Error (RMSE), and percentage bias (PBIAS) 
were  used  to  measure  the  accuracy  of  the  performance  of  the  deep 
learning  models, including the  CNN model and  CNN with an  autoen-
coder, and conventional machine learning models with ANN, SVM, RF, 
and  XGBoost  for  estimating  TDI,  BMI,  and  FAI  values.  The  NSE  is  a 
commonly  used  score  in  hydrological  and  environmental  models  and 
measures the relative magnitude of the residual variance, indicating the 
degree  of  1:1  line  fitness  of  the  observed  versus  estimated  data  plot 
(Moriasi  et  al.,  2007;  Nash  and  Sutcliffe,  1970).  NSE  ranges  from 
negative infinity to 1, and the mean observed value is used as a refer-
ence.  In  other  words,  an  NSE  below  zero  implies  that  the  estimation

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit information about the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it mentions that the CNN model with the autoencoder showed better estimation performance for TDI, BMI, and FAI than the CNN model estimation without the autoencoder using a 10-fold cross-validation. This suggests that the data might have been divided into ten folds, where nine folds were used for training and one fold for validation during each iteration. After completing all iterations, the average performance across all validations could be reported. Additionally, the use of the term 'conventional machine learning models' indicates that there may also be separate testing datasets used to evaluate these models' generalization capabilities.