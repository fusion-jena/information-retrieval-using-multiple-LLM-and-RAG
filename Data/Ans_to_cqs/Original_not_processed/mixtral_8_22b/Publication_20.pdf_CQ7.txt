Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The model was trained using thumbnails of whole ﬁsh, part of ﬁsh species and
environment (T?). Raw outputs were post-processed applying two decision
rules: (r1) keeping most likely ﬁsh class if “environment” was the most likely
class, and (r2) considering “part of species X" equivalent to “species X".

Species

Number of thumbnails
tested

Deep-learning
model

Humans

Abudefduf sparoides
Abudefduf vaigiensis
Chaetodon trifascialis
Naso elegans
Pomacentrus sulfureus
Pygoplites diacanthus
Thalassoma hardwicke
Zanclus cornutus
Zebrasoma scopas
Average success rate

88
47
149
165
443
35
73
53
144
1197

93.4
97.3
95.1
98.4
97.9
90.4
96
97.1
96.2
95.7

87.7
84.7
89.4
94.8
93.2
77.4
91
97.8
88.3
89.3

The fourth training dataset T4 contained thumbnails from T3 minus
the “part of ﬁsh”, which is replaced by 20 classes “part of species”
obtained by splitting thumbnails from each species. The diﬀerence
between T3 and T4 was that T3 contained only one global class “part of
ﬁsh” whereas T4 contained as many “part of species” classes as there
were “ﬁsh” species.

2.4. Testing the performance of models

We ﬁrst compared the performance of the 4 models trained using
each of the 4 training datasets. In addition, we tested the performance
of models after correcting their raw outputs using two a posteriori de-
cision rules. First, since the networks trained with T2, T3 or T4 are
likely to recognize environment samples with a high conﬁdence score
(over 99%) they could thus classify some ﬁsh as an environment class
(i.e. false positive). We therefore deﬁned a decision rule (r1): when the
ﬁrst proposition of the network was ‘environment’ with a conﬁdence
lower than 99% we provide, as ﬁnal output, the ﬁsh class with the
highest probability.

Similarly, as “part of species” classes present in T4 were just a
methodological choice to improve model performance (and hence were
absent from the test database), we deﬁned a second decision rule (r2):
when the result given by the network is “part of species X", we provide,
as ﬁnal output, “species X".

A link to a depository with architecture details is given at the end of
references. We stopped the network training after 70 epochs (i.e. a
complete scope of the dataset where each image is used only once), to
−5, an exponential
prevent overﬁtting. We used a learning rate of 10
learning decay with a Gamma of 0.95, a dropout of 50% and an Adam
Solver type as learning parameters. Those are classic hyper-parameters
for a fast convergence of the network without over-ﬁtting (Srivastava
et al., 2014). The weight initialization is also classic with a random
Gaussian initialization. The training lasted 8 days on our conﬁguration;
we trained and ran our code on a computer with 64GB of RAM, an i7
3.50GHz CPU and a Titan X GPU card for 900,000 images.

We used at least 2200 thumbnails per ﬁsh species class, and batches

240

S. Villon et al.

Ecological Informatics 48 (2018) 238–244

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention how the data was split into training, testing, and validation sets. However, it can be inferred that the authors used at least 2200 thumbnails per fish species class for training purposes. Additionally, the authors mentioned stopping the network training after 70 epochs to prevent overfitting, indicating that they might have used a separate validation set during training. Unfortunately, no specific information about the size or composition of the validation and testing sets is available based on the provided context.