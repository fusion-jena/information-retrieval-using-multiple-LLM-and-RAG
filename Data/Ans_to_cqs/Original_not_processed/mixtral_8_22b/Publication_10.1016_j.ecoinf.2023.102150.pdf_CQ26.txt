Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Minar, M.R., Naher, J., 2018. Recent Advances in Deep Learning: An Overview URL:htt 
p://arxiv.org/abs/1807.08169https://doi.org/10.13140/RG.2.2.24831.10403, doi: 
10.13140/RG.2.2.24831.10403,arXiv:1807.08169v1. 

M¨olle, J.P., Kleiven, E.F., Ims, R.A., Soininen, E.M., 2022. Using subnivean camera traps 
to study Arctic small mammal community dynamics during winter. Arct. Sci. 8, 
183–199. https://doi.org/10.1139/AS-2021-0006/ASSET/IMAGES/AS-2021- 
0006TAB2.GIF. 

Mos, J., Hofmeester, T.R., 2020. The Mostela: an adjusted camera trapping device as a 
promising non-invasive tool to study and monitor small mustelids. Mamm. Res. 65, 
843–853. https://doi.org/10.1007/S13364-020-00513-Y. 

Norouzzadeh, M.S., Morris, D., Beery, S., Joshi, N., Jojic, N., Clune, J., 2021. A deep

Kavzoglu, T., 2009. Increasing the accuracy of neural network classification using refined 
training data. Environ. Modell. Softw. 24, 850–858. https://doi.org/10.1016/J. 
ENVSOFT.2008.11.012. 

Kellenberger, B., Tuia, D., Morris, D., 2020. AIDE: Accelerating image-based ecological 
surveys with interactive machine learning. Methods Ecol. Evol. 11, 1716–1727. 
https://doi.org/10.1111/2041-210X.13489. 

Kingma, D.P., Ba, J., 2014. Adam: A method for stochastic optimization. arXiv 

preprintarXiv:1412.6980. 

Kleiven, E.F., Nicolau, P.G., Sørbye, S.H., Aars, J., Yoccoz, N.G., Ims, R.A., 2022. Using 
camera traps to monitor cyclic vole populations. Remote Sens. Ecol. Conserv. 
https://doi.org/10.1002/rse2.317. 

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classification with deep 
convolutional neural networks. In: Pereira, F., Burges, C.J.C., Bottou, L., 
Weinberger, K.Q. (Eds.), Advances in Neural Information Processing Systems. Curran 
Associates, Inc.

Table 1 
Number of training images, validation images (used for model validation during 
model  training)  and  out-of-sample  test  images  (used  for  external  model  vali-
dation after training was finished) as well as number of new images selected 
from  the  images  taken  between  summer  2020  and  summer  2021  for  model 
retraining.  

Class 

Number of 
training 
images 

Number of 
validation 
images 

Number of 
out-of-sample 
test images 

Number of new 
training images 
for model 
retraining 

Bad 

6453 

quality 

Bird 
Empty 
Least 

weasel 
Lemming 
Shrew 
Stoat 
Vole 
TOTAL 

3382 
9444 
1725 

9449 
9265 
4024 
9894 
53636 

677 

219 
979 
98 

967 
962 
438 
1024 
5364 

549 

119 
3301 
69 

647 
584 
64 
919 
6252 

306 

195 
533 
424 

449 
416 
425 
528 
3276

complete data set. Thus, model performance would be overestimated for 
rare  classes  and  underestimated  for  abundant  classes.  Therefore,  the 
number  of  true  positives,  false  positives  and  false  negatives  was

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers provided do not explicitly discuss specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on general practices in deep learning, several methods can be employed to mitigate data bias. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same class distribution in both sets. This ensures that each subset is representative of the overall population, reducing potential biases caused by uneven class distributions.

Oversampling and undersampling are techniques used to balance datasets containing imbalanced classes. Oversampling increases the representation of minority classes by duplicating their instances or generating synthetic samples. Undersampling reduces the majority class size by randomly removing some instances or selecting only those most informative ones. Both approaches aim to create balanced datasets, which can improve model performance when dealing with imbalanced data.

Diverse data collection focuses on gathering a wide range of examples from different sources, environments, and conditions. By incorporating various types of data, models become more robust and better equipped to handle real-world scenarios where input diversity is common.

In summary, addressing data bias during preprocessing of the deep learning pipeline often involves employing strategies such as stratified splitting, oversampling, undersampling, and diverse data collection. While these techniques were not directly discussed in the given references, they remain relevant and widely adopted practices within the field of deep learning.