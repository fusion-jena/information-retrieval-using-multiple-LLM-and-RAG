Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Name

Inputs

Name

Inputs

Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 7
Dataset 8
Dataset 9
Dataset 10
Dataset 11
Dataset 12
Dataset 13
Dataset 14
Dataset 15
Dataset 16

Spectral bands (B)
Vegetation Indices (VI)
Soil Indices (SI)
Water Indices (WI)
Cluster (C)
B + VI
B + SI
B + WI
B + C
VI + SI
VI + WI
VI + C
SI + WI
SI + C
WI + C
B + VI + SI

Dataset 17
Dataset 18
Dataset 19
Dataset 20
Dataset 21
Dataset 22
Dataset 23
Dataset 24
Dataset 25
Dataset 26
Dataset 27
Dataset 28
Dataset 29
Dataset 30
Dataset 31

B + VI + WI
B + VI + C
B + SI + WI
B + SI + C
B + WI + C
VI + SI + WI
VI + SI + C
VI + WI + C
SI + WI + C
B + VI + SI + WI
B + VI + SI + C
B + VI + WI + C
B + SI + WI + C
VI + SI + WI + C
B + VI + SI + WI + C

Table 3
LULC classes based on CLC methodology.

Class

Description

Code

RGB color

Artificial surfaces

Agricultural areas

Forest

Scrub and/or
herbaceous
vegetation

Open spaces with
little or no
vegetation
Water bodies

Taking into account Congalton (1991) and Hay (1979), who suggest
at least 50 pixels per thematic class, we decided to implement an
alternative strategy. Instead of strictly distributing 196 training areas
among the 6 thematic classes, we chose to include pure training areas.
These well-identified areas should contain at least 50 pixels in total and
prominently represent the class of interest. This distribution was carried
out through simplified random sampling (Chuvieco, 2020), allowing us
to effectively capture variability within each class and improve the

Table 1
Spectral indices calculated for each collection.

Index

NDVI
EVI
SAVI
BSI
MNDWI
NDMI

Formula

(NIR (cid:0) RED)/(NIR + RED)
C*[(NIR (cid:0) RED)/(NIR + C1*RED (cid:0) C2*BLUE + L) ]
[(NIR (cid:0) RED)/(NIR + RED + L) ]*1 + L
[(RED + SWIR) (cid:0) (NIR + BLUE) ]/[(RED + SWIR) + (NIR + BLUE) ]
(GREEN (cid:0) SWIR1)/(GREEN + SWIR1)
(NIR (cid:0) SWIR1)/(NIR + SWIR1)

Reference

A R T I C L E I N F O

A B S T R A C T

Keywords:
Fragmentation
LULC
Changes
Classification
Random Forest
Amazon
Forest

1.15
23.29
16.19
30.79
27.43
0.78
0.36
100

2023

Km2

44.00
954.20
410.50
940.80
526.56
24.30
4.60
2904.96

Gains and losses (Km2)

%

1989 to 2005

2005 to 2023

1989 to 2023

17.20
105.30
(cid:0) 85.84
154.79
(cid:0) 177.00
2.10

10.60
277.70
(cid:0) 59.86
46.30
(cid:0) 270.34
1.60

27.80
383.00
(cid:0) 145.70
201.09
(cid:0) 447.34
3.70

1.51
32.85
14.13
32.39
18.13
0.84
0.16
100

Table 9
Rate of change for the periods 1989–2005, 2005–2023 and 1989–2023.

Categories

Artificial surfaces
Agricultural areas
Forest
Scrub and/or herbaceous vegetation
Open spaces with little or no vegetation
Water bodies
NoData
Total

1989

Km2

22.73
682.88
565.12
589.13
982.02
14.23
48.84
2904.96

2005

Km2

20.82
720.18
327.63
766.17
716.84
32.82
320.50
2904.96

2023

Km2

24.41
857.13
398.80
703.09
444.86
44.03
432.64
2904.96

Rate of Change

1989 to 2005

2005 to 2023

1989 to 2023

4.52%
1.06%
(cid:0) 1.05%
1.19%
(cid:0) 1.25%
0.61%

1.53%
1.91%
(cid:0) 0.76%
0.28%
(cid:0) 2.30%
0.38%

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The study implemented a strategy to monitor the model performance during training by including pure training areas. These well-identified areas contained at least 50 pixels in total and prominently represented the class of interest. The distribution of these areas was carried out through simplified random sampling. This approach aimed to effectively capture variability within each class and improve the overall classification accuracy.