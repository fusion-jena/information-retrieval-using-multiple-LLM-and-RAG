Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Model Evaluation
Model performance evaluation included both errors and
time costs evaluation. The iteration termination condition
of the model was the same in each round training (i.e., the
loss rate of the model was less than a preset threshold ɛ
−4]). We used the same test set (Test) to
[here ɛ = 1.0 × 10
evaluate the performance of models in diﬀerent training
phases. The model error evaluation used three metrics that
included overall error, commission error, and omission
error, which were deﬁned by equations (2), (3) and (4).

Table 2. Main conﬁguration parameters of the two platforms used.

)

(2)

(3)

(4)

Commission error

=

/(
FP TP

+

FP

)

Omission error

=

/(
FN TP

+

FN

)

was the same, and the errors of models decreased as the
sample size increased (Fig. 3). Using only 7,298 images
(20% of the BMXSM dataset), the overall error, omission
error, and commission error of our method were 5.21%,
14.86%, and 11.37%, respectively (Fig. 3c). When using
29,192 images (80% of the BMXSM dataset), the three
errors were 2.69%, 6.45%, and 6.82%, respectively (Fig. 3c).
Training time costs of models varied greatly when using
diﬀerent training modes on the same computing platform
(Fig. 4). In the zero‐start training mode, the training time

232

Wildlife Society Bulletin (cid:129) 45(2)

 23285540, 2021, 2, Downloaded from https://wildlife.onlinelibrary.wiley.com/doi/10.1002/wsb.1176 by Vamsi Krishna Kommineni - Friedrich-Schiller-Universität , Wiley Online Library on [29/08/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons LicenseTable 1. Incremental training sets sequence. There were 36,490 images in
BMXSM dataset.

Overall error

= (

FN FP TP

)/(

+

+

TN FN FP

+

+

Training sets(i)a

Number of
images(n)

n/N (%)

Empty images
rateb (%)

1
2
3
4
5
6
7

7,298
10,947
14,596
18,245
21,894
25,543
29,192

20
30
40
50
60
70
80

80.36
80.52
80.50
80.35
80.53
80.48
80.47

a i represented serial number of training set Traini, i = 1, 2, …, 7. Here
Train1 was initial training set and Traini (i = 2, 3, …, 7) was in-
cremental training set.

Experiments and Platform
To study the performance of the model on each training set
when using diﬀerent training modes and computing plat-
forms, we conducted three experiments. The ﬁrst used the
zero‐start training mode to train the models on a GPU
server with the datasets Traini (i = 1, 2, …, 7). The second
used the incremental training mode to train the models on
the GPU server with Traini (i = 1, 2, …, 7). The third used
the incremental training mode to train model on a desktop
PC with Traini (i = 1, 2, …, 7).
We used two computing platforms in our study (Table 2).
On a Lenovo desktop computer with Intel Core i7‐7700

GPU Server

Desktop PC

Speciﬁcation Dell PowerEdge C4130 Rack Servers
CPU
RAM
GPU

Two Intel Xeon E5‐2600 v4 processors
256 GB
Two NVIDIA Tesla K80 with 24 GB GDDR5 Graphics Card One NVIDIA GeForce GT 730 with 2 GB GDDR5 Graphics Card

Lenovo desktop ThinkCentre
Intel(R) Core(TM) i7‐7700 3.6 GHz
32 GB

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The strategy implemented to monitor the model performance during training involved evaluating both errors and time costs. The iteration termination condition of the model remained consistent across all rounds of training, with the loss rate of the model required to be less than a predetermined threshold of 1.0 × 10^-4. A fixed test set was employed to evaluate the performance of the models at different stages of training. Model error assessment utilized three distinct metrics: overall error, commission error, and omission error, defined by equations (2), (3), and (4) respectively. As the sample size expanded, the model errors diminished while maintaining the same configuration parameters. For instance, utilizing merely 7,298 images (20% of the BMXSM dataset), the overall error, omission error, and commission error of their approach stood at 5.21%, 14.86%, and 11.37%, respectively. However, upon employing 29,192 images (80% of the BMXSM dataset), these errors reduced significantly to 2.69%, 6.45%, and 6.82%. Training time expenses varied considerably depending on the training mode and computing platform used.