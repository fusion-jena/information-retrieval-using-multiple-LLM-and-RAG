Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

All architectures were trained with stochastic gradient descent using a similar protocol,
with a momentum of 0.9 and starting from an initial learning rate of 10−2. Every 20 epochs,
the learning rate is divided by 10 until reaching 10−6.

Neural networks do not perform well when trained with unbalanced data sets [41]. In
the case of “central-pixel labeling” architectures it is possible to make balanced data sets
with the initial pixels selection used for the learning. In the case of “semantic labeling” the
composition of the images makes it more difﬁcult to precisely control the number of pixels
per class. We tried several methods, but found negligible differences in performance. All
reported experiments use the median frequency balancing method.

3.3.1. Central-Pixel Labeling

conv1
conv2
conv3
conv4
conv5
maxpool

Conv

11 × 11
5 × 5
3 × 3
3 × 3
3 × 3
2 × 2

Kernels

Stride

Pad

96
256
384
384
256
Na

4
1
1
1
1
2

0
2
1
1
1
0

ResNet (Deep Residual Network, [43]) is a Deep Learning architecture with many
layers that use skip connections, as illustrated in Figure 4. These skip connections allow
the bypassing of layers and add their activations to those of the skipped layers further
down the sequence. The dotted arrows in Figure 4 denote skip connections through a linear
projection to adapt to the channel depth.

By skipping layers and thus shortening the back-propagation path, the problem of the
“vanishing gradient” can be mitigated. Figure 4 represents a 34-layer ResNet architecture.
The ﬁrst layer uses 7 × 7 convolutions, the remaining ones 3 × 3.

Remote Sens. 2021, 13, 2257

9 of 22

Figure 4.
architecture. The number of kernels is indicated at the bottom of each convolution layer.

To run an XGBoost model, neo-channels and multiple texture ﬁlters were used. The
ﬁlters were: dissimilarity, entropy, homogeneity and mean. Input of 64 × 64 windows
were used for labeling the central pixel. The training data were the same as for the Deep
Learning architectures.

3.3. Deep Learning Architectures

The internal parameters of the employed Convolutional Neural Network (CNN)
architectures were not changed with regards to the originally proposed ones. A CNN [40]
is a machine learning technique based on sequences of layers of three different types:
convolutional, pooling or fully connected layers. Convolution and fully connected layers
are usually followed by an element-wise, non-linear activation function.

3.4. Sampling Method

The SPOT6 satellite data for our ﬁve study areas were preprocessed to be fed into the
different Deep Learning architectures and the XGBoost model. First, the data were split
into three mutually exclusive parts: a learning set, a validation set and a test set totally
independent of the two previous ones.

Four of the ﬁve areas were used for learning and validation. The last, isolated scene
was then used as the test set. It contained all the classes for the two nomenclatures, the ﬁve
LC classes, and the 12 LU classes. In addition, this image contained all the environments
representing the New Caledonian landscape: urban, mining, mountainous and forest
environment with variations from the coastline to the inland mountain areas. It is on this
entire scene that the ﬁnal confusion matrix and quality metrics were computed.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What preprocessing steps are involved before training a deep learning model (e.g., normalization, scaling, cleaning)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't explicit information about specific preprocessing steps such as normalization, scaling, or cleaning applied to the dataset before feeding it into the various Deep Learning architectures and the XGBoost model. However, we can infer some general preprocessing steps from the context.

Firstly, the context mentions that the SPOT6 satellite data was preprocessed to be fed into the models. This implies that some form of preprocessing took place, although the exact nature of these preprocessing steps is not specified.

Secondly, the context discusses how neural networks do not perform well when trained with unbalanced datasets. To address this issue, they mention creating balanced datasets with the initial pixels selection used for learning in the case of 'central-pixel labeling' architectures. They also state that they tried several methods for semantic labeling but found negligible differences in performance. Therefore, one could argue that ensuring a balanced dataset might have been part of the preprocessing step.

Lastly, the context states that the input of 64x64 windows was used for labeling the central pixel in the XGBoost model. This suggests that the raw data may have been segmented or partitioned into smaller units during preprocessing.

In conclusion, while the context does not provide detailed information regarding specific preprocessing techniques like normalization, scaling, or cleaning, it does suggest that some form of preprocessing occurred, including potentially addressing imbalance issues and segmentation of the raw data.