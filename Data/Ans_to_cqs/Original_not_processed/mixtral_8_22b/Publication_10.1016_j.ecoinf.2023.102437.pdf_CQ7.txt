Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The  recurrent  neural  network  (RNN)  model  is  an  artificial  model 
used  for  processing  sequential  data.  RNNs  have  been  successfully 
applied  in  areas  such  as  speech  recognition,  language  models,  and 
translation,  where  the  material  is  continuous.  However,  RNN  have 
limitations  in  processing  past  information  if  there  is  a  considerable 
difference  in  time  duration  between  the  initial  and  final  parts  of  the 
data.  LSTM  (Long  Short-Term  Memory)  is  a  type  of  recurrent  neural 
network (RNN) architecture designed to address some of the limitations 
of  traditional  RNNs  when  it  comes  to  handling  long  sequences  and 
capturing long-term dependencies in data. LSTM networks are used in 
machine learning and deep learning for sequential data tasks, such as 
natural language processing, speech recognition, time series forecasting, 
and  more.  Especially,  LSTM  models  possess  the  ability  to  make  pre-

To  construct  the  LSTM  model,  we  used  KERAS  (version  2.9.0),  a 
Python  package,  and  scaled  the  data  using  “MinMaxScaler()”  in  the 
Python Scikit-Learn package to improve model performance. In partic-
ular, “MinMaxScaler()” usually scales the attributes to a specific range 
[0,1]; therefore, the smallest value was converted to 0 and the largest 
value was 1; thus, all attributes ranged between 0 and 1, which is useful 
for regression analysis. The LSTM models were built with one layer of 65 

EcologicalInformatics79(2024)1024374J. Derot et al.                                                                                                                                                                                                                                    

neurons, and a batch size of 32 with 500 epochs was used. 

2.5. Interpretability methods 

2.5.1. Diagnosing the dominant event sequences

Our  findings  also  revealed  a  significant  reduction  in  computation 
time when ML models, along with preselection, were used. Unlike ex-
pected, pre-selection lowered the accuracy of the results, which likely 
indicates  a  loss  of  information  in  the  database  transformed  using  the 
signature method. As we expected that the Lasso model, in the absence 
of the signature method, would not provide convincing results; there-
fore, we only retained this analysis to maintain consistency in compar-
ison with the ML models. Though it is possible to extract PDPs from RF 
runs  coupled  with  the  signature  method,  their  interpretation  is  not 
possible because of this transformation. The amount of input data, or in 
our case, the size of the time series used during the learning phase of an 
ML  model,  can  have  a  non-negligible  influence  on  predictive  perfor-
mance (Bustillo et al., 2022; Derot et al., 2020b). In other words, a long

The above procedure was repeated after incrementing the time index 
m by 1 (see Fig. 1). Figs. A-1 in the Appendix represents a schematic 
view of the training and prediction flow. In this flow, the weight wm  was 
obtained  using  the  training  dataset  Dm.  The  prediction  from  time  tm 
using  the  signature  xm  yielded  the  value  ̂ym+ma ,  which  was  compared 
with  the  validation  data  ym+ma .  Notably,  the  size  of  the  training  data 
|Dm| = m (cid:0) ma (cid:0) mb + 1 depended on the starting time tm. The predic-
tion error was obtained by calculating ̂ym+ma
(cid:0) ym+ma  at different starting 
times. By adopting this approach, which involves conducting training 
and forecasts progressively by changing the starting time of the forecast 
but not used the information that is not accessible at the start of pre-
diction period, each forecast was assured to be a fair cross-validation. 
We used a climate time series composed of d = 12 indices in Table 1

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given context, the criteria used to split the data for deep learning model training into train, test, and validation sets are not explicitly mentioned. However, common practices in machine learning suggest that the dataset is typically divided into three subsets: training set, validation set, and testing set.

The training set is used to fit the model, i.e., adjust the weights and biases of the neurons in the network based on the input features and target labels. This process helps the model learn patterns and relationships within the data.

The validation set is employed to fine-tune hyperparameters and prevent overfitting. During the training process, the model's performance is evaluated on the validation set after each epoch or a certain number of iterations. Based on these evaluations, decisions are made regarding whether to continue training, stop early, or modify hyperparameters like learning rate, regularization parameters, etc.

Finally, the testing set serves as an independent evaluation of the trained model's performance. It provides insights into how well the model generalizes to unseen data. Typically, the testing set remains untouched until the very end of the modeling process to ensure its independence.

While the exact proportions may vary depending on the problem and available data, a commonly used ratio is 80/10/10 or 70/15/15 for splitting the data into training, validation, and testing sets, respectively.