Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

978-1-5090-1537-5/16/$31.00 ©2016 IEEEA. Classiﬁcation Process

Image representations extracted from deep neural networks,
trained on large datasets such as ImageNet [9] and ﬁne tuned
on domain speciﬁc datasets, have shown state-of-art perfor-
mance in numerous image classiﬁcation problems [14]. The
activation vectors of the ﬁrst fully connected layer of a pre-
trained VGGnet [24] are employed as feature representations
in our work. The weights of this deep network are ﬁne tuned
using the Benthoz15 dataset [23] which consists of expert-
annotated and geo-referenced marine images from Australian
seas.

Convolutional neural networks (CNNs) [9], also known as
deep networks, are an important class of machine learning
algorithms applicable, among others, to numerous computer
vision problems. Deep CNNs, in particular, are composed of
multiple layers of processing involving linear as well as non-
linear operators. To solve a particular task, the parameters of
networks are learned in an end-to-end manner. Image represen-
tations extracted from deep CNNs trained on a large dataset
such as ImageNet [10] have shown to produce a promising
performance for diverse classiﬁcation and recognition tasks
[11], [12], [13], [14] and [15]. Spatial pyramid pooling (SPP)
[16] and Multi-scale Orderless Pooling (MOP) [17] schemes
have made CNNs independent of the input image size and
robust for diverse classiﬁcation and recognition applications.
In this paper, we propose a computer vision and deep
learning based framework for the automatic annotation of

The image representations extracted at these three scales were
then max-pooled to retain the most prominent information
which is present in the neighbourhood of a labelled pixel.
These multi-scale deep features were used to train a Multi
Layer Perceptron (MLP) network for classiﬁcation. This net-
work consists of two fully connected hidden layers of neurons
followed by an output layer with 2 nodes: corals and non-
corals. The number of neurons in the hidden layers were
optimized for maximum performance. Fig. 3 shows the block
diagram of our proposed classiﬁcation method.

[10] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
A large-scale hierarchical image database,” in IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), pp. 248–255, IEEE,
2009.

[11] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and
T. Darrell, “Decaf: A deep convolutional activation feature for generic
visual recognition,” International Conference on Machine Learning
(ICML), pp. 647–655, 2014.

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on November 16,2023 at 09:41:16 UTC from IEEE Xplore.  Restrictions apply. 

NC
C

NC
C

(a)

(b)

(c)

Fig. 4: Mosaics and Coral Maps: (a) the 3 sites of the Abrolhos Island; (b) Site 3 Coral Map for 2010 and (c) Site 3 Coral
Map for 2013. Legend key: C is coral and NC is non-coral

hybrid feature representations,” IEEE International Conference on Image
Processing, in press.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no explicit mention of the specific hardware resources used for training the deep learning models in the given context. Therefore, it cannot be determined whether GPUs, TPUs, or other types of hardware resources were utilized during the training process.