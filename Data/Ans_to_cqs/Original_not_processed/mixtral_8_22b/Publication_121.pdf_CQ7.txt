Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

D. Model Training

Feature Extraction: The hardware to train the model included
a Lenovo laptop equipped with an 8265U CPU at 1.80 GHz
of Intel Core i5, 8 GB of RAM running on a Windows 10 64-
bit system. The software tools included Annaconda3 Jupyter
Notebook with Python 3.8, where the Tensorﬂow, OpenCV-
python3 [37] and Keras [38] libraries were used. The dataset
was divided in a ratio of 75:25 into a training set of 5789
images and a test set of 1930 images. To obtain the pre-
trained weight parameters, we built the base models from the
MobileNetV2, MobileNetV3-Large and MobileNetV3-Small

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on August 29,2024 at 05:51:17 UTC from IEEE Xplore.  Restrictions apply.

models, pre-trained on 1.4M images from 1000 classes. First,
the intermediate layer of all the models was selected to use
for feature extraction. For this purpose, the output of the last
layer (bottleneck layer) is commonly used prior to the ﬂatten
operation. The reason is that all the fully connected layers
are specialized to the task network was trained on; thus, the
features learned by these layers will not be useful for the new
task. The bottleneck features are more generic. Therefore, the
base models were frozen, loaded with weights trained on the
ImageNet dataset and used as a feature extractor. We added
a dropout layer with a dropout rate of 0.2 to reduce the
overﬁtting of the model. Finally, the top classiﬁer softmax
layer was added for predicting the class for an input image.
The model with the base model of MobileNetV2 was compiled
and optimized with Adam optimizer. The other with the base
model of MobileNetV3 were optimized with Gradient descent

Model Validation: The performance of the models is greatly
inﬂuenced by the number of times it goes under training.
Using sparse categorical cross-entropy loss, the models were
validated with a test dataset. The performances of the models
were evaluated by calculating accuracies and losses of training
samples in each epoch. The model based on MobileNetV2
showed (Fig. 2) the training accuracy up to 97% and validation
accuracy up to 84%. The model based on MobileNetV3-Large
exhibit a training accuracy of 94% and validation accuracy up
to 87%.
Fine-Tuning Results: After ﬁne-tuning, the training accuracy
of the MobileNetV2-based model was improved to 97%,
and validation accuracy remained at 86% at each epoch.
The training accuracy of the MobileNetV3-based model was
improved to up to 96% (Fig. 3), and validation accuracy up
to 89% after 10 epochs. Note the gap between training and
validation curves for the MobileNetV3-based model is less
than the MobileNetV2-based model.

A. Transfer Learning from Pre-trained Models

When data used to train deep learning networks is not
enough, and it is expensive to create labelled data, transfer
learning, a promising paradigm,
is applied to acquire the
knowledge learned in previous settings. The most common
strategies of transfer learning are feature extraction and ﬁne-
tuning. For feature extraction, input data is provided to the
pre-trained model, and activation values of many layers are
stored to use as features. For ﬁne-tuning, the initial layers
of the model are ﬁxed, and the ﬁnal layers of the model

Authorized licensed use limited to: Thueringer Universitaets. Downloaded on August 29,2024 at 05:51:17 UTC from IEEE Xplore.  Restrictions apply. 

Fig. 1. Transfer Learning of MobileNet-based Model for Leaf Classiﬁcation.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In the given context, the dataset was divided in a ratio of 75:25 into a training set and a test set. Specifically, there were 5789 images used for training and 1930 images used for testing. This division of data is a common practice in machine learning and deep learning projects. Typically, the larger portion of the data is allocated for training purposes, while a smaller subset is reserved for testing or validating the model's performance. In some cases, another small portion of the data may also be separated out for validation during the training process. However, in this particular scenario, only two sets of data were mentioned - one for training and one for testing.