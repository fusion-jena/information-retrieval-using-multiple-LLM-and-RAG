Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

the Pl@ntNet user community (currently 1.8 million user accounts). At the time
of writing, the CNN architecture used is the inception model49 extended with
batch normalization.50 The network is pre-trained on the commonly used Im-
ageNet dataset and ﬁne-tuned on Pl@ntNet data. Pl@ntNet currently covers
30,261 species illustrated by more than 2.9 million images. The taxonomic
coverage of our study is therefore one to three orders of magnitude larger
than previously published studies making use of automated species identiﬁca-
tion for ecological research. The training of Pl@ntNet CNN requires the mobi-
lization of a high-performance computing infrastructure and expertise in deep,
distributed, and large-scale learning. Thus, the resulting classiﬁcation tool is in
itself a major advance in biodiversity data science.

Access to the Pl@ntNet classiﬁcation tool is provided through a dedicated
API available at my.plantnet.org. The main feature of this API is a RESTful
JSON-based web service that can accept one to ﬁve images of a plant and re-
turns a list of likely species. The species are associated with classiﬁcation
scores (the softmax output of the CNN), as well as a list of matching images
retrieved from the database. To facilitate the implementation of future studies
based on the methodology of this paper, we have developed the ‘‘plantnet’’51
R-package allowing users to query the Pl@ntNet API. The package is available
online at https://github.com/BiologicalRecordsCentre/plantnet.

Once data are generated by AI natural-
ists we must consider how they are
shared to ensure recognition of their au-
thors, observation traceability, and long-
term accessibility. We suggest following
the TDWG standards,43 such as Darwin-
Core among others, to ensure the data
are interoperable with other biodiversity datasets and can be
shared via the GBIF portal (www.gbif.org). Metadata accompa-
nying these datasets should include the AI model architecture,
technical speciﬁcities of the AI model training phase, digital ob-
ject identiﬁer of the dataset used to train it, AI model version,
classiﬁcation score of each image, date, location, photograph
name, and image license. Classiﬁcation score, which provides
a mathematical value of the conﬁdence in the prediction of a
model for a speciﬁc image, is particularly important as it can
be used in subsequent analyses to ﬁlter the data by the level
of conﬁdence in the classiﬁcation accuracy. A researcher will

tions of the training data, and the gap between these and the test
data on which the developed algorithms will be evaluated.28

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which frameworks are used to build the deep learning model (e.g., TensorFlow, PyTorch)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific deep learning framework used to build the Pl@ntNet deep learning model. However, popular deep learning frameworks like TensorFlow or PyTorch could potentially be used for building such models. These frameworks provide tools and libraries to create, train, and deploy deep learning models efficiently. Without explicit information, it cannot be definitively stated which framework was utilized for developing the Pl@ntNet deep learning model.