Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.4.2. Data splitting 

The  WQ indicator  data  was  divided  into  training  and  testing  data 
sets. In ML, typical data splitting ratios for training and testing datasets 
are 80% and 20%, 67% and 33%, and 50% and 50%, respectively (Sajib 
et al., 2023). In this study, we adopted 80% and 20% ratios for splitting 
the training and testing datasets. A total of 20 and 10 random sample 
locations  were  selected  for  the  purposes  of  training  and  testing, 
respectively. A similar number or fewer sample locations were utilized 
in various previous research studies to train and test the data set (Bui 

EcologicalInformatics80(2024)1025145A.M. Sajib et al.                                                                                                                                                                                                                                 

Fig. 2. Methodological framework for selecting the best predictive model.

erquality-iiwq/wq-challenge. 

Vu, H.L., Ng, K.T.W., Richter, A., An, C., 2022. Analysis of input set characteristics and 
variances on k-fold cross validation for a recurrent neural network model on waste 
disposal rate estimation. J. Environ. Manag. 311 (October 2021), 114869 https:// 
doi.org/10.1016/j.jenvman.2022.114869. 

Wainer, J., Cawley, G., 2021. Nested cross-validation when selecting classifiers is 

overzealous for most practical applications. Expert Syst. Appl. 182 (May), 115222 
https://doi.org/10.1016/j.eswa.2021.115222. 

Wang, Y., Zhao, Y., Xu, S., 2022. Application of VNIR and machine learning technologies 
to predict heavy metals in soil and pollution indices in mining areas. J. Soils 
Sediments 22 (10), 2777â€“2791. https://doi.org/10.1007/s11368-022-03263-3. 

Whitehead, P., Bussi, G., Hossain, M.A., Dolk, M., Das, P., Comber, S., Peters, R., 

Charles, K.J., Hope, R., Hossain, S., 2018. Restoring water quality in the polluted

dicators; and (iv) aggregation function; (v) classification scheme (Gupta 
and Gupta, 2021; Syeed et al., 2023; Uddin et al., 2021). Details of these 
steps can be found in Uddin et al. (Chidiac et al., 2023; Uddin et al., 
2021).

methodology  of  Uddin et  al.  (2022a),  to evaluate the  performance of 
various  ML  algorithms.  Details  of  the  methodology  can  be  found  in 
referred material. This approach is widely used in modelling tasks like 
water  resource  management,  waste  management,  natural  hazard  pre-
diction, and environmental modelling (Gidey, 2018; Pham et al., 2020; 
Vu et al., 2022; Zhao et al., 2021). It offers high precision by utilizing ten 
subsets of the original dataset for both training and testing (Sajib et al.,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given context, there isn't any information about specific data augmentation techniques such as flipping, rotation, scaling, etc., being applied in the deep learning pipeline. Therefore, I cannot provide a helpful answer to this query with the available information.

Based on the provided context, it appears that the study focuses on using Machine Learning (ML) algorithms for evaluating water quality indicators. The data was split into training and testing sets, adopting an 80% and 20% ratio, respectively. However, no details regarding data augmentation techniques applied in the deep learning pipeline have been mentioned.