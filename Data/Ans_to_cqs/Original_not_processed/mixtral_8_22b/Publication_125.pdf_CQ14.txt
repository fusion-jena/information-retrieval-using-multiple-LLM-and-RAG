Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Training Run-Time

Prediction Run-Time

VGG16
Xception
ResNet50
DenseNet121
The proposed model

22 min 27 s
21 min 26 s
30 min 8 s
18 min 34 s
16 min 43 s

0.803 s
0.827 s
1.835 s
4.134 s
0.976 s

5.5. Discussion

Recent years have seen increasing concerns about protecting the privacy of conﬁdential
information when processing data using models. This leads to the need for cryptographic
techniques to solve privacy concerns in data-driven models. Several PPDL techniques have
been proposed in the literature to solve these concerns. This research is, to the best of our
knowledge, the ﬁrst work that investigates PPDL for satellite image classiﬁcation.

Table 3. CNN Architecture.

No.

Layers

Output Shape

Parameters

Dropout Rate

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Convolutional
Activation (ReLu)
MaxPooling
Dropout
Flatten
Fully Connected
Activation (ReLu)
Fully Connected
Activation (softmax)

128 × 128 × 3
128 × 128 × 32
—
64 × 64 × 32
64 × 64 × 32
—
32 × 32 × 32
32 × 32 × 64
—
16 × 16 × 64
16 × 16 × 64
16,384
64
—
4
—

—
896
—
—
9248
—
—
18,496
—
—
—
—
1,048,640
—
—
260

—
—
—
—
—
—
—
—
—
—
0.4
—
—
—
—
—

4.2.1. Data Augmentation

Table 6. Security evaluation.

Parameter

Plain-Images

Cipher-Images

Entropy [55]
Contrast [58]
Energy [55]
Homogeneity [55]
Mean Square Error (MSE) [54,59]
Peak signal to noise ratio [55]
Key sensitivity [60]
Uniﬁed average change intensity [58]
Structural similarity index [61]

3.1206
5.3191
0.5363
0.9044
-
-
-
-
-

7.9596
10.5767
0.0156
0.3884
2.1236 × 104
4.8601
99.5725
33.66
0.0018

5.3.2. CNN Performance

This section will present the performance of the custom CNN proposed in this study

over both encrypted and plain data.

Data Augmentation

The ﬁrst step in presenting the performance of this CNN model is to describe the
results of our data augmentation processes. This latter operation is ensured by using the
ImageDataGenerator function from the Keras deep learning library. The results obtained

Remote Sens. 2021, 13, 2221

17 of 26

The fundamental concept behind the ResNet model is to use shortcut links to bypass
blocks of convolutional layers (bottleneck). The CONV layers each have a 3 × 3 ﬁlter
and are designed according to two rules: (1) the layers have the same number of ﬁlters
with the same output feature map size and (2) the number of ﬁlters is multiplied if the
feature map size is halved. The convolutional layers conduct the downsampling with
a stride of 2. The network ends with an average POOL layer and 1000 FC layers with
a SoftMax activation function. The default input size is 224 × 224 × 3 [24].
Xception: The Xception model’s architecture was proposed by Chollet (2017). This
model is a CNN-based architecture also trained on the ImageNet dataset. The Xception
architecture comprises 36 CONV layers with a 3 × 3 ﬁlter and stride of 2. These CONV
layers are structured into 14 modules, all of which have the ReLu activation function

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given information, there isn't any explicit mention or discussion regarding the optimization of the model's hyperparameters, such as through methods like grid search or random search. Therefore, it cannot be determined how the hyperparameters were optimized based solely on the provided context. Further details would be required to provide a more accurate response.