Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

50.9 
59.7 
63.2 

90.2 

76.7 

93.1 

80.1 

LSSegNet3 (Kaijaluoto 
et al., 2022) 
DCNN (Hamraz et al., 
2019) 
RandLA-NET (Kaijaluoto 
et al., 2022) 
PointCNN (Xi et al., 
2020) 
DCNN (Fricker et al., 
2019) 

TLS 

TLS + Raster 

[X, Y, I] 

85.1 

– 

TLS 

TLS 

[X, Y, Z, R2, 
*] 

92.9 

80.6 

[X, Y, Z, I] 

83.4 

61.3 

ALS + aerial 
imagery 

[X, Y, 
Colour, *] 

86.7 

–  

EcologicalInformatics81(2024)1026128L. Comesa˜na-Cebral et al.                                                                                                                                                                                                                     

Fig. 7. MIoU and IoU values per class obtained during the training with point clouds in different formats as input data.

Contents lists available at ScienceDirect 

Ecological Informatics 

journal homepage: www.elsevier.com/locate/ecolinf 

Wildfire response of forest species from multispectral LiDAR data. A deep 
learning approach with synthetic data 

Lino Comesa˜na-Cebral *, Joaquín Martínez-S´anchez , Gabriel Su´arez-Fern´andez , Pedro Arias 

CINTECX, Universidade de Vigo, Applied Geotechnology Group, 36310 Vigo, Spain   

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Multispectral LiDAR 
Deep learning 
Fire response 
Synthetic data 
Wildfire

Regardless of the model type employed for semantic classification, 
training  a  DNN  model  from  scratch  requires  a  substantial  number  of 
training samples to grasp a diverse range of features. The lack of liter-
ature on semantic classifications of real LiDAR point clouds being pre-
trained  with  synthetic  data  emphasises  the  importance  of  integrating 
augmented  data  simulations  during  the  training  phase  of  DL  models. 
Data augmentation addresses the requirement for large training datasets 
in DNNs, which can be achieved using an external simulator. Current 
research  on  LiDAR  point-cloud  simulations  predominantly  embraces 
two perspectives: aerial and terrestrial, specifically ALS, Terrestrial, and 
Mobile Laser Scanning (TLS and MLS, respectively) point clouds.

3.2. Fuel model retrieval 

Once the DL model is trained, a few samples of real MS point clouds 
are segmented using the methodology exposed in Section 2.3 to create a 
ground truth. This ground truth was required to validate the classifica-
tions using a DL model trained with synthetic data. As mentioned in the 
previous section, the best classification performance of the SoftGroup 
semantic branch was achieved by the MS input data case; therefore, this 
pretrained  model was  used,  and  its  efficiency was  tested  by  inferring 
these real MS point clouds (Fig. 9). In addition, these inferences on real 
MS point clouds are taken as inputs for the decision tree scheme pre-
sented in Section 2.5, where the final fuel models are retrieved. The final 
fuel model classifications are summarised in Table 3. 

4. Discussion

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the location or availability of the code repository for the deep learning pipeline. Therefore, it is not possible to determine where the code repository is located based solely on the provided context.