Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The Q value, which reflects the explanatory power of each driver in 
the OPGD, is also influenced by the size of the OPGD data sampling grid. 
It is common to compare the 90% quartiles of the Q values for all drivers 
at different spatial scales and select the optimal sampling grid based on 
the criterion that the 90% quartile is the largest(Song et al., 2020; Yu 
et al., 2023). In this paper, Q values for each driver were compared at 
grid scales of 1 km*1 km, 2 km*2 km, 3 km*3 km, 4 km*4 km, 5 km*5 
km and 6 km*6 km.  

(ii)  Factor detector 

The factor detector assesses the independent explanatory power of 
each driver in relation to the spatial variance in the kNDVI using the Q 

EcologicalInformatics80(2024)1024935Z. Gu et al.

Guo, Y., Zhang, L., He, Y., Cao, S., Li, H., Ran, L., Ding, Y., Mikalai, F., 2023b. LSTM time 
series NDVI prediction method incorporating climate elements: a case study of 
Yellow River Basin, China. J. Hydrol. 130518. 

Hair, J.F., Sarstedt, M., Ringle, C.M., Mena, J.A., 2012. An assessment of the use of 

partial least squares structural equation modeling in marketing research. J. Acad. 
Mark. Sci. 40, 414–433. 

Hair, J.F., Risher, J.J., Sarstedt, M., Ringle, C.M., 2019. When to use and how to report 

the results of PLS-SEM. Eur. Bus. Rev. 31, 2–24. 

Huo, H., Sun, C., 2021. Spatiotemporal variation and influencing factors of vegetation 
dynamics based on Geodetector: a case study of the northwestern Yunnan Plateau, 
China. Ecol. Indic. 130. 

Jetz, W., Cavender-Bares, J., Pavlick, R., Schimel, D., Davis, F.W., Asner, G.P.,

Types 

Significant degradation 
Insignificant degradation 
Insignificant improvement 
Significant improvemment  

2.3.3. Optimal parameter-based geographical detector (OPGD)  

(i)  Optimal scale and discretization parameters 

As OPGD requires continuous data to be discretized before further 
analysis,  choosing  appropriate  discretization  parameters  (i.e.,  the 
number and method of discretization breakpoints) is crucial for accurate 
identification  of  driver  explanatory  power.  The  discretization  process 
involved  five  methods:  standard  deviation  (SD),  natural  breaks  (NB), 
equal  interval  (EI),  quantile  (QU),  and  geometric  interval  (GI)(Song 
et al., 2020). Following previous studies (Li et al., 2021; Zhang et al., 
2023), we considered that too many or too few breakpoints would result 
in  information  redundancy  (insufficiency).  Therefore,  the  number  of 
breakpoints was configured to range from 4 to 13 in this study.

Climate 

Terrain 

Human activity 

Evaporation 
Sunshine duration 
Relative Humidity 
Precipitation 
Temperature 
Elevation 
Slope 
Aspect 
Geomorphological type 
Nighttime light 
Population density 
Road distance 

Evap 
Sund 
Rh 
Pre 
Tem 
Elev 
Slop 
Aspe 
Geomt 
Nightl 
Popd 
Road 

mm(1 km) 
hour(1 km) 
%(1 km) 
mm(1 km) 
◦
C(1 km) 
m(30 m) 
◦
(30 m) 
-(30 m) 
-(1 km) 
-(1 km) 
person/km2(1 km) 
m(1 km) 

Continuous 
Continuous 
Continuous 
Continuous 
Continuous 
Continuous 
Continuous 
Type 
Type 
Continuous 
Continuous 
Continuous 

2001–2020 
2001–2020 
2001–2020 
2001–2020 
2001–2020 
– 
– 
– 
– 
2001–2020 
2001–2020 
–  

were then derived from the resampled DEM data using the slope and 
aspect toolbox in ArcGIS Pro 3.0.2.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no direct mention of the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it is common practice in machine learning and deep learning to randomly divide the dataset into three subsets: training set, validation set, and testing set. Typically, the training set is used to fit the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to evaluate the final performance of the model. The proportion of these subsets can vary depending on the specific application and the amount of available data, but a commonly used ratio is 70% for training, 15% for validation, and 15% for testing. It should be noted that the context does not provide any information about the specific proportions used in this particular study.