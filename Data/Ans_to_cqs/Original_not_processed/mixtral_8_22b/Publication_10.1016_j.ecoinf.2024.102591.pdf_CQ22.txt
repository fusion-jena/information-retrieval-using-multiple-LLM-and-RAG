Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

22,768 

validation 

25,217 

validation  

Fig. 3. Location of wildfires used to calibrate/validate FIREMAP algorithms for 
burned area (BA), severity (sev) and vegetation recovery (rec) across the Ibe-
rian Peninsula (southwestern Europe). 

2.2.2. Fire severity assessment

interest and for the official fire perimeters of the EFFIS database. The 
algorithm automatically selects the date range of interest for the pre- 
and post-fire scenes in the case of using an official perimeter from the 
EFFIS database. Otherwise, the date range can be manually selected by 
the user. The automatic search for pre- and post-fire scenes of acceptable 
quality can either be based on a single-date approach or on pixel-based 
temporal  mean  composites  as  determined  by  the  Sentinel  (QA60)  or 
Landsat (QA_PIXEL) quality assessment bands (see Section 2.2.1). When 
the  user requests the  calculation of a  spectral index in FIREMAP, the 
result is automatically displayed on the main screen as a continuous or 
categorized fire severity map, with the possibility of using user-defined 
thresholds.  The  latter  has  been  included  because  of  the  ecosystem- 
dependent  nature  of  the  relationships  between  the  CBI  and  spectral

Table 2 
Range of input parameters in PROSPECT-D and 4SAIL models.  

PROSPECT-D 

Symbol 

Unit 

Minimum 

Maximum 

Leaf structure parameter 
Chlorophyll a and b 
concentration 

Carotenoid concentration 

Anthocyanin concentration 

Brown pigments fraction 
Dry matter content 
Water content 
4SAIL 
Leaf area index 
Average leaf angle 
Hot spot effect 
Soil brightness factor 
Vegetation cover 

N 

Ca+b 

Ccar 

Cant 

Cbr 
Cdm 
Cw 
Symbol 
LAI 
ALA 
hspot 
αsoil 
FCOVER 

– 
μg 
(cid:0) 2 

cm

μg 
(cid:0) 2 

cm

μg 
(cid:0) 2 

cm
– 

(cid:0) 2 

(cid:0) 2 

g cm
g cm

Unit 
m2 m
◦

(cid:0) 2 

– 
– 
– 

1 

10 

0.5 

0 

0 
0.001 
0.001 

2.5 

90 

20 

50 

1 
0.02 
0.02 

Minimum  Maximum 

0 
20 
0.001 
0 
0 

6 
80 
1 
1 
1

Parks, S.A., Dillon, G.K., Miller, C., 2014b. A new metric for quantifying burn severity: 

the relativized burn ratio. Remote Sens. 6, 1827–1844. 

Parks, S.A., Miller, C., Parisien, M.A., Holsinger, L.M., Dobrowski, S.Z., Abatzoglou, J., 
2015. Wildland fire deficit and surplus in the western United States, 1984–2012. 
Ecosphere 6, 1–13. 

Parks, S.A., Holsinger, L.M., Voss, M.A., Loehman, R.A., Robinson, N.P., 2018. Mean 

composite fire severity metrics computed with Google Earth engine offer improved 
accuracy and expanded mapping potential. Remote Sens. 10, 879. 

Pausas, J.G., Keeley, J.E., 2009. A burning story: the role of fire in the history of life. 

BioScience 59, 593–601. 

Pausas, J.G., Llovet, J., Rodrigo, A., Vallejo, R., 2008. Are wildfires a disaster in the 

Mediterranean basin? – a review. Int. J. Wildland Fire 17, 713–723. 

Pettorelli, N., 2019. Satellite Remote Sensing and the Management of Natural Resources.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide information about the specific metrics used to evaluate the performance of the deep learning model. However, common metrics used to evaluate the performance of deep learning models include accuracy, precision, recall, F1 score, and Area Under Curve (AUC). Accuracy measures the proportion of correct predictions out of total predictions made. Precision measures the proportion of true positive predictions out of all positive predictions made. Recall measures the proportion of true positive predictions out of all actual positives. F1 score is the harmonic mean of precision and recall, providing a balanced measure of both. AUC represents the degree of separability between classes, indicating how well the model distinguishes between them.