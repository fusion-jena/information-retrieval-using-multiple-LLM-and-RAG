Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

3. A proposed deep learning framework for highway AQ 
monitoring and prediction 

The proposed framework is a four-layered architecture composed of 
the hardware layer, data storage layer, integration layer and analytics 
layer as depicted in Fig. 2. This section introduces these layers and their 
functionalities. 

3.1. Hardware layer

Fig. 13. An illustration of captured NO2 pollutant readings (blue highlight) and the deep learning model predictions (red highlight). These results were derived from 
an evaluation using the validation dataset. It should be pointed out that the model's predictions are not too far off the actual readings. (For interpretation of the 
references to colour in this figure legend, the reader is referred to the web version of this article.) 

Table 4 
Hardware specifications of the two oracle cloud instances used to test scalablity.  

Instance 
Type 

Bare 
Metal 

Name 

Compute – 
Ampere 
A1 – 
OCPU 

Processor 

OCPU 

GPU 
type 

– 

CPU 
cores 

CPU 
memory 

GPU 
memory 

6 

32GB 

– 

VM. 

GPU 

Pascal 

GPU2.1 

1 
NVIDIA 
P100 

12 

72GB 

16GB  

4.4. Evaluating the scalability performance of the REVIS system

(cid:0) 4,  and  steep  value  of  1.3e

4). 

(cid:0)

4.3.3. Model evaluation 

In this section, the results of the deep learning model developed are 
presented. The model was trained to make day-ahead predictions of the 
three pollutants, but first, an appropriate evaluation metric had to be 
selected.  The  top  metrics  for  regression  problems  are  mean  squared 
error/root  mean  squared  error  (MSE/RMSE),  mean  absolute  error 

Fig. 12. A plot showing the model's training and validation losses against the 
number of epochs. It is worth noting that there was a gradual decrease in both 
losses  as  the  training  epochs  increased  which  indicates  that  the  model  was 
learning. Further training beyond 20,000 epochs would have either resulted in 
overfitting or no further drop in both losses.

The  REVIS  system  was  tested  for  scalability  using  the  IoT  asset 
monitoring tool and database performance hub of two different oracle 
cloud instances. The fourteen REVIS devices were deployed sequentially 
to  capture  both  system's  response  time  and  throughput.  The  first 
experiment was run on a bare metal cloud instance with specifications as 
shown in Table 4. Fig. 14a shows the performance of this cloud instance 
as it could not scale past 8 devices and exploded at 3 and 4 devices for 
EDA  and  deep  learning  analysis.  However,  the  GPU  cloud  instance 
performed better due to its auto-scale feature. Fig. 14b shows a plot of 
the CPU cores utilised for exploratory data analysis, data storage and 
deep learning analysis as the number of deployed devices increased. It 
can be observed that the number of CPU cores increased gradually for 
each task and then stabilised at some point. The system was able to scale

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
According to the given information, the deep learning model was deployed on Oracle Cloud instances. Specifically, two types of Oracle Cloud instances were used - Bare Metal and GPU. The hardware specifications of these instances can be found in Table 4. Therefore, the platforms used to deploy the deep learning model were Oracle Cloud instances, not AWS, Azure, or Google Cloud Platform.