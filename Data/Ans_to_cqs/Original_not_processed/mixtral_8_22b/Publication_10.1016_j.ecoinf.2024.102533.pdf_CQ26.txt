Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Therefore, the data normalization stage is unnecessary.

In contrast, the Distortion method solely considers the distance of the 
data within the cluster. It is suitable for use on data with high separation 
and no longer involves the distance between clusters. Datasets with high 
overlap do not necessitate separation; they only require cohesion. We 
observe that the Distortion starts with a high value and then continues to 
decrease.  These  results  suggest  that  an  increased  cluster  number  will 
reduce the intra-cluster distance, indicating an improvement in cluster 
quality. However, our goal is not to determine good cluster quality but to 
identify the correct elbows in the transitions between clusters. There-
fore, these results are followed by analysis using the Elbow method.

2.7. Step 6: Evaluating the clustering results 

Clustering divides data into groups based on inherent characteristics; 
not requiring external information, such as, classes which become data 
labels. Therefore, the created groups align naturally with the data con-
ditions  and  the  clustering  algorithm.  As  a  result,  the  evaluation  of 
clustering results is conducted internally, using Silhouette and Calinski- 
Harabasz.  High  evaluation  scores  on  both  methods  indicate  that  the 
clustering results obtained by the clustering method is the best outcome. 

2.8. Elbow method

This research utilizes six organoleptic parameters and applies them 
to seven fish species, serving as the standard for automatically classi-
fying fish freshness. The dataset, generated over 11 days, is employed in 
machine learning experiments. In the clustering process, we exclusively 
consider Euclidean distance as a metric, given the uniform data range. 
However, alternative distance metrics have not been explored, poten-
tially  influencing  the  quality  of  freshness  class  determination.  Future 
research possibilities may involve investigating the impact of different 
distance metrics on class groups. Each distance possesses distinct char-
acteristics,  leading  to  varied  cluster  patterns.  Additionally,  extending 
this work to include other fish species could provide a more compre-
hensive understanding. 

CRediT authorship contribution statement

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The provided context does not directly discuss specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention some general concepts related to data processing and evaluation in machine learning.

Data bias can be addressed through various techniques during preprocessing. One common approach is stratified sampling, where the training set is divided into subsets or strata, ensuring each subset has approximately the same proportion of observations from each target class. This helps maintain the overall distribution of the target variable when creating training and validation sets.

Oversampling and undersampling are also popular techniques to handle imbalanced datasets. Oversampling increases the minority class size by replicating its instances, while undersampling reduces the majority class size by randomly removing instances. Both approaches aim to balance the dataset and improve model performance.

Diverse data collection is another strategy to mitigate data bias. Collecting diverse data ensures that the dataset represents all possible scenarios, reducing the risk of biased models due to underrepresented cases.

While the provided context does not explicitly cover these techniques, they are commonly used in addressing data bias during preprocessing in deep learning pipelines.