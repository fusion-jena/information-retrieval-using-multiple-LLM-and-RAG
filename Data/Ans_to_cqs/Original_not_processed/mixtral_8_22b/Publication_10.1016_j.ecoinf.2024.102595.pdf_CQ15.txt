Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

In  the  development  stage,  the  preprocessed  data  was  divided  into 
training (80%), validation (10%), and test sets (10%) for model training 
and testing purposes (Shah et al., 2018), followed by the construction of 
predictive  models  using  both  deep  learning  algorithms  (e.g.,  Deep 
Neural  Networks)  and  traditional  machine  learning  approaches  (e.g., 
AdaBoost  Regressor,  Support  Vector  Regressor,  etc.),  with  hyper-
parameter tuning performed via GridSearchCV with cross-validation (cv 
= 10).  While some studies  might  use different proportions, such as  a 
70–30 split between training and testing/validation (Khan et al., 2022), 
the  80–10-10  split  employed  in  this  study  ensured  a  more  extensive 
training set, potentially leading to a better-generalized model. The test 
set,  which  the  model  has  not  previously  seen  during  the  training  or 
validation phases indicates the model’s performance in real-world sce-
narios (Shah et al., 2018).

A R T I C L E  I N F O    

A B S T R A C T    

Keywords: 
Oil palm 
Yield prediction 
Machine learning 
Deep learning 
Agriculture

2.3.3. Transformation 

Two fundamental techniques employed in the data transformation 
process  are  the  MinMaxScaler  and  the  LabelEncoder.  The  former  is 
especially  crucial  for  algorithms  that  are  sensitive  to  the  scale  of  the 
data, such as Support Vector Regressor (SVR) and neural networks. The 
LabelEncoder was applied to transform categorical fields into numerical 
values. Agricultural datasets often include categorical data, such as soil 
types  or  crop  varieties,  which  must  be  encoded  to  numerical  labels 
before being fed into machine learning algorithms. 

2.3.4. Feature selection

Recognizing the significant role of oil palm, extensive research has been 
conducted,  as  evidenced  by  studies  from  Melidawati  et  al.  (2021), 
Tuerxun et al. (2020), and Ang et al. (2022), each contributing insights 
into  oil  palm  cultivation  and  management.  Predicting  oil  palm  crop 
yields is crucial to effectively managing and optimizing the palm supply 
chain. It requires the incorporation of multiple datasets and is influenced 
by numerous variables, including climate patterns, soil quality, fertilizer 
use, and seed varieties (Xu et al., 2019). Applying Machine learning and 
deep learning models can accurately predict crop yields, aiding farmers 
in harvest planning and crop management decisions (Attri et al., 2023). 
Although these techniques have been implemented across various crops 
for environment-based yield forecasting, their deployment for predictive 
analysis of oil palm yields remains in its infancy (Rajakal et al., 2021).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide specific information on the optimization techniques used in the deep learning pipeline. However, it mentions that hyper-parameter tuning was performed via GridSearchCV with cross-validation (cv = 10). This suggests that the authors may have used grid search for hyperparameter optimization. Grid search involves defining a range of values for each hyperparameter and then exhaustively searching through all possible combinations of those parameters to find the best one. Cross-validation is a technique used to evaluate the performance of a model by dividing the dataset into several subsets and iteratively fitting the model on one subset while evaluating it on another. In this case, cv = 10 means that the dataset was divided into ten folds, and the model was trained and evaluated on each fold separately.

Regarding optimization techniques specifically used in deep learning pipelines, Stochastic Gradient Descent (SGD) and Adaptive Moment Estimation (Adam) are commonly used optimization algorithms. SGD updates the weights of the network based on the gradient of the loss function with respect to the current weight values, while Adam combines the advantages of two other optimization methods, namely Root Mean Square Propagation (RMSProp) and momentum. These optimization techniques help minimize the error between predicted and actual outputs, thereby improving the accuracy of the model.