Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Parameter amount = k2.Cin.Cout

(14)  

(15) 

Understanding  the  computational  cost  and  parameters  of  a  single 
layer allows for precise estimation and control of the total requirements 
of our model. Computational complexity is quantified in FLOPs, calcu-
lated considering the convolutional kernel size (k2), the number of input 
Cin  and output Cout  channels, and the feature map’s height (hout) and 
width  (wout).  FPS  measure  the  model’s  speed,  encompassing  pre-
processing, inference, and non-maximum suppression speeds, providing 
an overall assessment of the model’s efficiency in real-time applications. 

4.4. Results

Lee, S., Agrawal, A., Balaprakash, P., Choudhary, A., Liao, W., 2018b. Communication- 
efficient parallelization strategy for deep convolutional neural network training. In: 
Proceedings of MLHPC 2018 : Machine Learning in HPC Environments. 

Lin, T.-Y., et al., May 2014. Microsoft COCO: common objects in context. In: 13th 

European Conference in Computer Vision (ECCV), pp. 740–755 [Online]. Available: 
http://arxiv.org/abs/1405.0312. 

Liu, W., et al., 2016. SSD: single shot MultiBox detector. Europ. Conf. Comp. Vision 1, 

852–869. https://doi.org/10.1007/978-3-319-46448-0. 

Dong, X., Yan, S., Duan, C., Aug. 2022. A lightweight vehicles detection network model 

Liu, J., Zhang, L., Li, Y., Liu, H., 2023a. Deep residual convolutional neural network 

based on YOLOv5. Eng. Appl. Artif. Intell. 113 https://doi.org/10.1016/j. 
engappai.2022.104914.

tionally, our technique is compared with state-of-the-art deep learning models, and from the baseline model we 
recorded  a  17.65%  increase  in  FPS,  28.55%  model  parameters  reduction,  and  50.92%  in  FLOPs  reduction. 
Furthermore, our model has a faster model loading time, which is critical for deployment in remote areas. This 
enables real-time species recognition on basic hardware, aiding conservation efforts through rapid analysis. The 
model advances deep learning in ecology by balancing efficiency with performance.

Number of images 

6107 
763 
764 
7634  

respectively. The extent of each MBBlock is determined by the number 
of layers, t, while the overall network size is determined by the number 
of MBBlocks and the size of the input tensor. The structure of Mobile-
NetV2 includes a stem layer, consisting of a 3 × 3 convolutional layer 
followed by batch normalization and ReLU activation, and a head layer, 
consisting of a global average pooling operation followed by a 1 × 1 
convolutional  layer  and  softmax  activation  function.  To  produce  the 
WildARe-YOLO model, the MBBlocks replace two levels of C3-X inside 

EcologicalInformatics80(2024)1025418S.R. Bakana et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about the specific hyperparameters such as learning rate or optimizer used in the deep learning model. However, it mentions some aspects related to the architecture of the model, including the use of MBBlocks, stem layer, and head layer in the WildARe-YOLO model. It also discusses the parameter amount calculation using k2.Cin.Cout, where k2 represents the convolutional kernel size, Cin denotes the number of input channels, and Cout stands for the number of output channels. Additionally, the text refers to the computational cost and parameters of a single layer, measured in FLOPs, and the importance of estimating and controlling the total requirements of the model. Nevertheless, without explicit details regarding the hyperparameters, one cannot determine the exact values used in this particular deep learning model.