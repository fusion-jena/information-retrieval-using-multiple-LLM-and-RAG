Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

For the training process, a batch size of 20 images and an RMSprop optimiser with a learning rate of 0.001 and 
a learning rate decay of 0.0001 was used. The chosen loss function was mean squared error, while the prediction 
accuracy was quantified by the MAE of the respective dataset. The MAE of the validation dataset was computed 
after each epoch. Models were trained until the validation MAE did not further improve compared to the preced-
ing epochs and diverged from the training MAE (’overfit’). The trained model was then applied to the test dataset.
All CNN were implemented using the Keras API version (2.3.0.0)54 and the TensorFlow backend (version 
2.2.0)55 in R (version 3.6.3)23. Model training was undergone on a workstation with two CUDA-compatible 
NVIDIA GPUs (GeForce RTX 2080 Ti, CUDA version 11.0).

extracted a random sample of 10% of the dataset of each trait before model training. This ‘test dataset’ was not 
involved in the training process and exclusively served for the independent evaluation of the trained models. 
The remaining data was split into ’training dataset’ and ’validation dataset’ by a ratio of 4:1 (Table 1). The train-
ing dataset was employed to train the weights of the CNN model, whereas the validation dataset indicated the 
training progress after each full training cycle (’epoch’).

Vol.:(0123456789)www.nature.com/scientificreports/Training  process  and  hyperparameters. 
In  order  to  build  upon  a  pre-existing  knowledge  base,  we 
employed  ’transfer  learning’  by  using  pre-trained  layer  weights  (the  storage  of  the  model’s  knowledge)  from 
a classification task on a dataset on www. image- net. org38 for all CNN models used in this study. The regressor 
following the basic CNN consisted of a global average pooling layer followed by two dense layers with 512 and 1 
output units. The latter forces the CNN to output exactly one prediction (trait) value. In case of the mixed data 
model (setups (3) and (4)), the CNN consisted of parallel branches to incorporate the different input data types. 
The branch processing the bioclimatic data consisted of three dense layers with 64, 32 and 4 output units, and 
the last layer of the CNN regressor contained 4 output units. After concatenating the two branches (image and

,

(1)

target denoting the log10-transformed target value, and mintrain and maxtrain being the minimum and maximum 
of the log10-transformed training dataset. Note that the minimum and maximum values used for normalising the 
targets were derived from the training dataset exclusively, preventing a leakage of information of the validation 
and test datasets to the training process. As a result, the final target values ranged exactly (for validation and test 
datasets: approximately) between 0 and 1. The same normalisation scheme was undergone for the bioclimatic 
variables.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
After the model training, several postprocessing steps can be performed depending on the specific requirements of the project or analysis. However, based on the given context, there is no explicit mention of any specific postprocessing steps such as generating saliency maps, calculating metrics like confusion matrices, precision, recall, F1 score, etc. Nevertheless, some general postprocessing steps can still be identified from the context.

Firstly, it is mentioned that the Mean Absolute Error (MAE) of the validation dataset was calculated after each epoch during the training phase. This indicates that evaluating the performance of the model using appropriate metrics is part of the postprocessing step. Additionally, the context mentions that the models were trained until the validation MAE stopped improving, which suggests monitoring the model's performance over time and deciding when to stop training based on certain criteria.

Secondly, the context states that the trained model was then applied to the test dataset. Applying the trained model to new, unseen data is another common postprocessing step. It allows us to evaluate how well our model has learned to generalize from the training data and make predictions on previously unseen examples.

Lastly, although not explicitly stated in the context, visualizing the results and interpreting them is also an important aspect of postprocessing. For example, plotting the predicted vs actual values, analyzing the residuals, or creating visualizations to understand the patterns in the data could provide valuable insights about the model's performance and help identify areas for improvement.

Therefore, based on the given context, the postprocessing steps involved after the model training include evaluating the model's performance using appropriate metrics, applying the trained model to new data, and potentially visualizing and interpreting the results.