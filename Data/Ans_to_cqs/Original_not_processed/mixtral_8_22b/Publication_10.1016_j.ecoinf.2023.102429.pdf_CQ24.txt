Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

R/PLSR 

17 

SG/PLSR 

17 

400–401, 413, 450–451, 472–473, 543–548, 560, 600, 1838, 
2098, 2429 
400, 402, 413, 434, 496, 545–547, 602, 604, 1010, 
1083–1084, 1529–1531, 2279, 

SG-FD/ 
PLSR 
SG-SD/ 
PLSR 
SG-MSC/ 
PLSR 
SG-RL/ 
PLSR 

11 

406, 582, 719, 730, 874, 1077, 1381, 1940, 1980, 2185, 2317 

5 

15 

15 

416, 417, 479, 504, 530, 665, 666, 1129, 1275, 1999 

472–473, 475–476, 565–566, 603–604, 1008, 1153, 1754, 
1781, 2172, 2188, 2449 

400, 401, 403, 435, 449, 542–546, 601–603, 1932, 2194  

EcologicalInformatics79(2024)1024293M. Hou et al.                                                                                                                                                                                                                                    

Table 3 
Importance bands for TN estimation by PLSR.  

Model 

PC 

Important bands (nm) 

R/PLSR 

16 

SG/PLSR 

15

R/PLSR 

16 

SG/PLSR 

15 

409, 414–415, 564, 566, 567, 601, 1641, 2098, 2200, 2201, 
2307, 2340, 2373, 600, 602 
401, 496, 497, 498, 555, 556, 565–567, 569, 600–601, 2098, 
2342, 2361 

SG-FD/ 
PLSR 
SG-SD/ 
PLSR 
SG-MSC/ 
PLSR 
SG-RL/ 
PLSR 

9 

5 

18 

15 

598, 599, 693, 720, 874, 875, 1601, 1951, 2049 

788, 1653, 1687, 1822, 2046 

495–500, 566–568, 600–602, 1034, 1036–1037 1811, 2028, 
2422 
407, 496–498, 546, 565–566, 1735–1756, 1869, 1936, 2026, 
2304, 2399, 2425 

PC, Number of principal components. 

R2 = 1 (cid:0)

RMSE =

∑n
∑n

√

i=1( yi (cid:0) ̂yi )2
i=1( yi (cid:0) yi )2
̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
∑n
1
( yi (cid:0) ̂yi )2
n

i=1

RPD =

SD
RMSE

RPIQ =

Q3 (cid:0) Q1
RMSE

(1)  

(2)  

(3)  

(4)  

where  yi  and  ̂yi  are  the  measured  and  predicted  values  of  sample  i, 
respectively; Q3 is the third quartile, Q1 is the first quartile and (Q3-Q1) 
is the interquartile range. 

3. Results 

3.1. Soil nutrient concentration analysis

References 

Attri, I., Awasthi, L.K., Sharma, T.P., Rathee, P., 2023. A review of deep learning 

techniques used in agriculture. Ecol. Inf. 77, 102217 https://doi.org/10.1016/j. 
ecoinf.2023.102217. 

Bai, Z., Xie, M., Hu, B., Luo, D., Wan, C., Peng, J., Shi, Z., 2022. Estimation of soil organic 
carbon using Vis-nir spectral data and spectral feature bands selection in southern 
Xinjiang, China. Sensors 22 (16), 6124. https://doi.org/10.3390/s22166124. 

Bartholomeus, H., Schaepman, M.E., Kooistra, L., Stevens, A., Hoogmoed, W., 

Spaargaren, O., 2008. Spectral reflectance based indices for soil organic carbon 
quantification. Geoderma 145 (1–2), 28–36. https://doi.org/10.1016/j. 
geoderma.2008.01.010.

EcologicalInformatics79(2024)10242910M. Hou et al.                                                                                                                                                                                                                                    

Liu, G., 1997. Soil Physical and Chemical Analysis and Profile Description. China 

Standards Press, Beijing.  

Liu, J., Dong, Z., Xia, J., Wang, H., Meng, T., Zhang, R., Han, J., Wang, N., Xie, J., 2021. 
Estimation of soil organic matter content based on CARS algorithm coupled with 
random forest. Spectrochim. Acta Part A 258, 119823. https://doi.org/10.1016/j. 
saa.2021.119823. 

Luo, T., Luo, S., Mo, B., Zhao, M., Long, Z., 2006. A study on the benefit of planting

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
To handle randomness in the deep learning pipeline, several strategies can be employed. One common approach is fixing the random seed value, which ensures reproducibility of results across different runs or experiments. This can be done using functions like numpy.random.seed() or tensorflow.random.set_seed(). Another strategy is to use deterministic algorithms instead of stochastic ones wherever possible. For example, using a deterministic optimizer such as gradient descent instead of a stochastic one like Adam. Additionally, techniques such as cross-validation and bootstrapping can also help reduce the impact of randomness on model performance. Cross-validation involves splitting the dataset into multiple subsets and training the model on each subset separately, while bootstrapping involves resampling the dataset with replacement to create new datasets for training and testing. These methods provide more robust estimates of model accuracy and generalization ability. Finally, it is important to report any sources of randomness in the experimental setup and discuss their potential impact on the results.