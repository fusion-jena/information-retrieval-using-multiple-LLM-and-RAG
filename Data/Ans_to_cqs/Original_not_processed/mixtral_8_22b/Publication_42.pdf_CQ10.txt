Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

36. Tan, M.; Le, Q.V. EfﬁcientNet: Rethinking Model Scaling for Convolutional Neural Networks. arXiv 2019, arXiv:1905.11946,
37. Huang, G.; Liu, Z.; Weinberger, K.Q. Densely Connected Convolutional Networks. arXiv 2016, arXiv:1608.06993,
38. Wu, S.; Zhong, S.; Liu, Y. ResNet. Multimed. Tools Appl. 2017. [CrossRef]
39.

Szegedy, C.; Vanhoucke, V.; Ioffe, S.; Shlens, J.; Wojna, Z. Rethinking the Inception Architecture for Computer Vision.
In
Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, 26 June–1
July 2016; pp. 2818–2826.

40. R Core Team. R: A Language and Environment for Statistical Computing; R Core Team: Geneva, Switzerland, 2020. Available online:

http://softlibre.unizar.es/manuales/aplicaciones/r/fullrefman.pdf (accessed on 9 November 2020).

Sensors 2021, 21, 343

11 of 18

7,047,754 learnable parameters gave a F1-score of 84.93% which is even lower. CNN
architectures with many parameters (more than 20,000,000) such as ResNetV50 [38] and
InceptionNetV3 [39] gave a high training accuracy, but a lower validation F1-score of 69.1%
and 81.7%, respectively. This result indicates overﬁtting and that more training data are
needed when such large deep learning networks are used. A very high F1-score of 96.6%
was ﬁnally achieved by transfer learning on ResNetV50 using pretrained weights and only
training the output layers. This indicates that the state-of-the-art was able to outperform
our proposed model, but requires pretrained weights with many more parameters.

2.2.4. Summary Statistics

2.2.3. Moth Species Classiﬁcation

In the ﬁeld of deep learning, speciﬁc architectures of CNNs have provided particularly
positive results in many areas of computer vision [31]. CNNs use both pixel intensity
values and spatial information about objects in the image. It was a challenging task to ﬁnd
a suitable CNN architecture for classiﬁcation of moth species. Based on an investigation
of several CNN architectures [32,33], a customized network was designed inspired by the
work in [34]. Hyperparameters of the architecture were explored to ﬁnd the optimal
network architecture to classify moth species. The model was designed to be light and fast
for the purpose of being able to be executed on the embedded Raspberry Pi computer used
in the light trap.

To ﬁnd the best CNN architecture for species classiﬁcation, different hyperparameters
were adjusted as described in Section 2.2.3. A total of 64 architectures were trained using a
dropout probability of 0.3 after the second to last hidden layer. The average F1-score for all
classes was used as a measure for a given architecture’s performance.

The ﬁve best architectures had high F1-scores, which only varied by 0.02, but had a
varying number of learnable parameters (Table 2). Compared to SGD, Adam turned out to
be the superior optimizer for training of all models. In the end, the architecture that had
a rating among the three highest F1-score but the lowest amount of learnable parameters
(2,197,578) was chosen. The reason for this is that an architecture with many parameters
and few training data would increase the risk of overﬁtting the neural network.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the code repository link of the deep learning pipeline (e.g., Link to GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough context to provide a direct link to the code repository of the deep learning pipeline mentioned in the text. However, based on the references cited in the paper, it can be assumed that some of these papers might contain links or resources related to their respective implementations. For instance, reference [36] discusses EfficientNet, while reference [37] talks about DenseNet. These papers may include links to their source code repositories or other relevant resources. To find the specific implementation details or code repositories for the deep learning pipelines discussed in the paper, one should refer to the original sources listed in the references section.