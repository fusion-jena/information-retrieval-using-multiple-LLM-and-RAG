Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

entropy loss or custom loss functions as in (Tian et al., 2022). While the
observed low recall necessitates careful consideration, it's important to
clarify that the scope of this study didn't encompass the optimisation for
accuracy metrics, exemplified by F1 Score. Instead, our primary goal
was to identify efficient strategies that synergise transfer learning and
active learning. To potentially elevate accuracy, strategies such as
applying Per-Channel Energy Normalization (PCEN) (Lostanlen et al.,
2019), refining spectrogram feature engineering (Dufourq et al., 2022),
or employing transfer learning with fine-tuning could be explored.

evaluation was done on focal and citizen-science datasets. Swaminathan
et al. (2024) extend the observation to attention-based architectures pre-
trained on human speech. Lauha et al. (2022) show that transfer
learning can be helpful also for small networks trained from scratch on
small, targeted datasets gathered from online resources such as Mac-
aulay Library2 (as opposed to foundation models trained on large
datasets). While the works cited above evaluate transfer learning models
based on classification performance, McGinn et al. (2023) take a
different approach and investigate the topology of fine grained, sub-
species sound events in the embedding space afforded by BirdNet;
they find that different call types of a same species (e.g., drumming
versus vocalization) form distinct clusters, and that the vicinity of each

4 https://github.com/HKathman/pam_annotation_experiments
5 https://github.com/kahst/BirdNET-Analyzer/tree/main/checkpoints/V2.4
6 https://tfhub.dev/google/vggish/1
7 https://tfhub.dev/google/yamnet/1
8 tensorflow.keras.applications.vgg16.VGG16(weights=’imagenet’).
9 tensorflow.keras.applications.resnet_v2.ResNet152V2

(weights=’imagenet’).

Fig. 4. UMAP plots for different embedding layers of different embedding
models for AnuraSet. For UMAP generation, we randomly select 5000 samples
and discard all samples that are aligned to more than one class. Colors and
shapes indicate the 10 classes with the highest occurrence frequency. Layers are
numbered according to their distance from the classification layer, e.g. ‘Bird-
Net-1’ is the last layer before the classification layer of the BirdNet model.

EcologicalInformatics82(2024)1027105H. Kath et al.

Due to the significant imbalance of classes in the datasets, we used
the macro F1 score as the evaluation metric, and provide the corre-
sponding macro precision and macro recall values in appendix A. As a
baseline for active learning, all figures show the performance of random
sampling.

We investigate the uncertainty sampling strategies ‘least confidence’,
‘ratio’ and ‘entropy’ with the score aggregation methods ‘max’ and

Fig. 5. Transfer learning applied to AnuraSet using features extracted from the
last layer before the classification layer of BirdNet. A linear classifier (logistic
regression) is used. The resulting F1 score for each species is plotted against the
number of samples containing that species. Frequent, common and rare species
are defined according to (Ca˜nas et al., 2023).

learning results of the BirdNet-1 embedding, we use this embedding as
the feature extractor for all subsequent active learning experiments.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The performance of the deep learning model is evaluated using the macro F1 score as the main metric due to the significant imbalance of classes in the datasets. Additionally, the corresponding macro precision and macro recall values are provided in Appendix A. It is important to note that the focus of this study was not on optimizing for accuracy metrics like the F1 Score but rather on identifying efficient strategies that combine transfer learning and active learning. However, potential ways to improve accuracy mentioned include applying Per-Channel Energy Normalization (PCEN), refining spectrogram feature engineering, or employing transfer learning with fine-tuning.