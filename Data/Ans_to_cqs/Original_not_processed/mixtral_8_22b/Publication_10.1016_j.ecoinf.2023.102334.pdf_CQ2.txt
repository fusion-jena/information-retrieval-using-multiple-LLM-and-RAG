Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

6.1. Vision transformer 

Transformer (Vaswani et al., 2017), which is a deep neural network 
first created for natural language processing (NLP), was built on a self- 
attention mechanism that makes it possible for noticeably huge recep-
tive  fields.  The Transformer  has become  a  de facto industry  standard 
procedure in NLP because of its remarkable efficiency, and it has also 
motivated  researchers  in  the  field  of  computer  vision  to  investigate 
applications  by  utilizing  the  long-term  relationships  between  pixels 
(Khan et al., 2022).

Model 

DenseNet 
Block 

ResNet 
Block 

Accuracy 
(%) 

Parameter size 
(MB) 

Flops 

14. Results and discussion 

Module1 and 
bulk of ViT 

The entire 
model 

√ 
×
√ 

×
√ 
×

92.58 
88.31 
97.68 

61.96 
80.81 
108.26 

1.57G 
2.51G 
2.60G  

The aim of this work was to investigate the use of computer vision 
techniques in the field of facial recognition of sika deer. Through the 
combined use of deep learning and Transformer, facial recognition of 

EcologicalInformatics78(2023)1023347H. Gong et al.                                                                                                                                                                                                                                    

Fig. 5. Overall model diagram based on ViT.

ViT  is the  first significant effort to employ  a  pure Transformer on 
pictures directly, showing that it can totally replace the conventional 
convolution processes with SOTA performance. The training of the va-
nilla ViT model, however, necessitates high computing costs, according 
to  the  experimental  findings.  As  a  result,  the  utilization  of  a  hybrid 
design  that  couples  the  Transformer  with  a  CNN  backbone  (such  as 
ResNet)  is  advocated  here.  The  Transformer  may  concentrate  on 
modelling global attention using the feature that ResNet extracted. Ac-
cording to the experimental findings, the hybrid approach can deliver 
better performance with comparatively less computing work. The main 
objective of this work was to create a model that accurately identifies 
sika deer using the idea.

Wen, Y., Zhang, K., Li, Z., Qiao, Y., 2016. A discriminative feature learning approach for 
deep face recognition. In: European Conference on Computer Vision. Springer, 
pp. 499–515. 

Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., et al., 2021. Rethinking semantic 
segmentation from a sequence-to-sequence perspective with transformers. In: IEEE 
Conference on Computer Vision and Pattern Recognition, 2, pp. 6881–6890. 
Zhou, M., Elmore, J.A., Samiappan, S., Evans, K.O., Pfeiffer, M.B., Blackwell, B.F., 
Iglay, R.B., 2021. Improving animal monitoring using small unmanned aircraft 
systems (sUAS) and deep learning networks. Sensors 21 (17), 5697. 

Zhu, Xizhou, Su, Weijie, Lu, Lewei, Li, Bin, Wang, Xiaogang, Dai, Jifeng, 2020. 

through attention. In: Proceedings of the 38th International Conference on Machine 
Learning arXiv:2012.12877.  

Deformable DETR: deformable transformers for end-to-end object detection. CoRR 
arXiv preprint arXiv:2010.04159.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, we cannot determine the exact data format used in the deep learning pipeline. However, since the research focuses on facial recognition of sika deer, it is safe to assume that images are used as input data. Additionally, the paper mentions the use of convolutional neural networks (CNN) and Transformer models, both of which typically process image or video data. Therefore, it is likely that the deep learning pipeline uses image data as input.