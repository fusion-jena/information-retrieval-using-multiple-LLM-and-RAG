Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1026244L. Szab´o et al.                                                                                                                                                                                                                                   

Table 1 
Hyperparameters in the grid search.  

Algorithm 

Hyperparameter ranges 

RF 
SVM 

MARS 

mtry: 1–20 with increments of 1 
gamma: 0.01–0.1 with increments of 0.01 
C: 2–16 with increments of 2 
degree: 1–3 
nprune: 2 to 100 with increments of 10  

(Conrad et al., 2015). The optimal segment size was chosen based on the 
extent of the patches, without losing any elements of the species pattern. 
The mean values of the segments were used for classification. Segments 
are  optimal  to  avoid  spatial  autocorrelation  when  using  k-fold  cross- 
validation  (KCV)  in  the  model-building  and/or  accuracy  assessment 
phase.

Staiano, 2019). Training data augmentation, which extends the existing 
training  data,  enhances  the  generalization  capabilities  (Lik´o  et  al., 
2023). Post-classification, generally segmentation, and filtering gener-
ally  provide  better  maps  with  a  lower  rate  of  salt-and-pepper  errors 
(Ahmed et al., 2017). We can also deal with the characteristics of the 
geometry of the training data, excluding outliers, refining the training 
samples, or changing the proportion of the training and test data. These 
strategies collectively improve classification accuracy, enabling better 
modelling of the environment.

We  classified  all  the  input  dataset combinations  (10  variable  sets; 
Table  2)  with  each  classifier  (RF,  SVM,  MARS)  and  with  two  sets  of 
classes (7C and 13C); thus, we had 60 models as a result of the classi-
fications. Classifications and hyperparameter tuning were conducted in 
R  4.2  (R  Core  Team,  2023)  with  the  caret  package  (Kuhnaut  et  al., 
2022). 

2.4. Accuracy assessment

GREEN, RED, REDEDGE, NIR, NDRE, NDVI, vNDVI, DSM, Run Percentage (k5o1) 
GREEN, RED, REDEDGE, NIR 
NDVI, NDRE, vNDVI 
Run Percentage (k2o1, k2o3, k2o5, k3o1, k3o3, k3o5, k5o1, k5o3, k5o5) 
GREEN, RED, REDEDGE, NIR, NDRE, NDVI, vNDVI 
DSM, REDEDGE, NIR, vNDVI, GREEN, NDVI 
REDEDGE, vNDVI, DSM, NIR, NDRE, NDVI 
Run Percentage (k5o1), NDVI, NDRE, vNDVI 
Run Percentage (k5o1), GREEN, RED, REDEDGE, NIR 
DSM, GREEN, RED, REDEDGE, NIR 
DSM, NDRE, NDVI, vNDVI  

EcologicalInformatics81(2024)1026245L. Szab´o et al.                                                                                                                                                                                                                                   

JM values were squared to achieve the common JM value range of 0–2 as 
the varSel used a different function (with the square root of JM). 

3.3. Class level evaluation 

3. Results 

3.1. Jeffries-Matusita separability analysis

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given information, it is not possible to determine what specific optimization techniques are applied in the deep learning pipeline, such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). This is because the provided text does not mention any details about the use of these optimization techniques in the machine learning process. However, it does discuss the application of hyperparameter tuning through a grid search method for Random Forests (RF), Support Vector Machines (SVM), and Multivariate Adaptive Regression Splines (MARS) algorithms. Additionally, the text mentions the use of the caret package in R for conducting classifications and hyperparameter tuning.