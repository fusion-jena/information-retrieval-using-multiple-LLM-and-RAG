Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

networks, Commun. ACM, 60 (2017), 84–90. 

23.  C.  Szegedy,  W.  Liu,  Y.  Jia,  P.  Sermanet,  S.  Reed,  D.  Anguelov,  et  al.,  Going  Deeper  with 
Convolutions,  2015  IEEE  Conference  on  Computer  Vision  and  Pattern  Recognition  (CVPR), 
Boston, MA, 2015. 

24.  K.  Simonyan,  A.  Zisserman,  Very  deep  convolutional  networks  for  large-scale  image 

recognition, Comput. Sci., 2014 (2014), 21–30. 

25.  K.  He,  X.  Zhang,  S.  Ren,  J.  Sun,  Deep  residual  learning  for  image  recognition,  2016  IEEE 
Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, 2016. 

©2021 the Author(s), licensee AIMS Press. This is an open access article 
distributed  under  the  terms  of  the  Creative  Commons  Attribution 
License (http://creativecommons.org/licenses/by/4.0) 

Mathematical Biosciences and Engineering 

Volume 18, Issue 2, 1121–1135.

(4) VGG is proposed by Simonyan et al. in 2014, in which the convolution filter is a 3 × 3 filter 
and  the  stride  is  2.  VGG-11,  VGG-16  and  VGG-19  respectively  include  11,  16  and  19  layers.  The 
Softmax layer is the final layer for classification [24]. 

(5) ResNet is proposed by Kaiming et al. in 2015 to address to the vanishing gradient problem and 
shows the excellent ability of classification [25]. The popular ResNet consists of 49 convolution layers. 
All  the  algorithms  in  our  experiments  are  coded  in  Matlab  R2019a.  The  values  of  initial 
parameters  are  randomly  generated  for  networks.  The  parameters  are  set  as  follows:  the  number  of 
epochs, learning rate drop factor, learning rate drop period, batch size are 200, 0.0004, 0.6, 30 and 128, 
respectively. The operating system of PC is Window 7 and the GPU is a NVIDIA with 8 GB memory. 

3.4. 

Results and discussions

(1) LeNet is firstly proposed by LeCun et al. in the 1990s, which includes three convolution layers, 
two  sampling  layers,  two  fully  connected  layers.  At  that  time,  it  is  difficult  to  run  LeNet  due  to  the 
limit of computation and memory capacity [21]. 

(2) AlexNet is proposed by Alex et al. and won the ILSVRC 2012 [22]. AlexNet achieves higher 
identifying accuracy than all the traditional machine learning algorithms. It is significant breakthrough 
for machine learning for classification. 

(3) GoogLeNet is proposed by Christian of Google and is the winner of ILSVRC 2014 [23], in 
which inception layers, including different receptive areas with different kernel sizes capturing sparse 
correlation patterns, are integrated into CNN.

Second  layer:  It is a convolution layer, which is with 128 3 × 3 filters and the stride is 1. The 
ReLU is selected as the activation function. The LRN is connected after this layer, the output results is 
the data with the size of 56×56×128. Then above data is processed by pooling operator with a 3 × 3 
window and 2 strides. The output result of this layer is the data with the size of 28 × 28 × 128. 

Third  to  eighth  layer:  These  layers  consist  of  three  inception  modules  which  consist  of  seven 

convolution modules and a pooling module. They are divided into the following four branches.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide explicit information about the specific data formats used in the deep learning pipeline. However, based on the mentioned architectures such as LeNet, AlexNet, GoogLeNet, VGG, and ResNet, we can infer that these models primarily deal with image data. For instance, LeNet was designed for handwritten digit recognition, while AlexNet, GoogLeNet, VGG, and ResNet were developed for large-scale image recognition tasks. Therefore, it can be concluded that the primary data format used in these deep learning pipelines is images.