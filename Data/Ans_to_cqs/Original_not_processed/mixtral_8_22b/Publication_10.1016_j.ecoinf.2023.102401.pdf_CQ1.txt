Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

To extract the input information, the SRC3 block employs a parallel 
analysis  of  the  input  feature  map  using  two  convolution  kernels.  In 
contrast to the C3 block, the SRC3 block incorporates two convolution 
kernels prior to the input of the bottleneck block. One of the kernels is 
responsible  for  halving  the  dimension  of  the  feature  map,  while  the 
other  maintains  the  dimension  unchanged.  This  approach  allows  for 
more  comprehensive  processing  of  the  input  features,  enabling  the 
model  to  capture  both  high-level  semantic  information  and  preserve 
relevant details during the feature extraction process. The convolution 
kernel size utilized is 3 × 3, which leads to a broader receptive field of 
information and richer characteristics compared to the 1 × 1 convolu-
tion kernel. The output semantic information can be augmented by the 
action of two convolution kernels. The information output from the first

specific steps are outlined: 

Step 1: Select appropriate water downloading gear and sensors for 
data collection. Pre-processing of the acquired data, such as denoising, 
image enhancement, and correction. In order to train and evaluate un-
derwater target detection models, the dataset needs to be labeled. Then 
separate underwater images collected from the underwater environment 
into training and test images. 

Step 2: Prepare hardware servers capable of training deep learning 
models to deploy the YWnet network. This allows learning weights to 
recognize  underwater  organisms.  Tune  the  hyperparameters  of  the 
model such as learning rate, batch size and network depth to achieve the 
best performance of the model.

The convolutional layer, batch normalization (BN) layer, and SiLU 
activation function are combined to form the CBS block. The SPPF (Li 
et  al.,  2021)  block  operates  three  maximum  pooling  layers,  and  then 
each branch is aggregated to the concat layer. It is capable of combining 
information  from  several  scales.  The  CRFPN  is  utilized  in  the  neck 
portion to combine the extractive features and convey information to the 
head  portion.  Finally,  the  head  predicts  and  presents  the  bounding 
boxes, classes, and concordance scores. 

3.1. The backbone of YWnet

3.1. The backbone of YWnet 

The  feature  extraction  phase  is  considered  crucial  in  the  training 
process,  as  it  plays  a  significant  role  in  enhancing  detection  perfor-
mance. The objective of this work is to improve detection accuracy by 
designing  a  feature  extraction  mechanism  that  incorporates  rich  se-
mantic  information  and  integrates  features  from  multiple  scales.  By 
leveraging these strategies, the aim is to capture and utilize a compre-
hensive range of relevant features, thereby enhancing the overall per-
formance of the detection system. As a result, a CBAM is added to the 
network's  backbone  to  improve  feature  extraction  from  the  incoming 
semantic information. Simultaneously, a novel feature extraction mod-
ule called SRC3 is provided to extract rich semantic information from 
the complicated undersea environment. 

3.1.1. Adding the attention module

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What methods are utilized for collecting raw data in the deep learning pipeline (e.g., surveys, sensors, public datasets)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In Step 1 of the deep learning pipeline, the method used for collecting raw data involves selecting appropriate water downloading gear and sensors for data collection. The acquired data is then pre-processed, including tasks like denoising, image enhancement, and correction. To create a dataset for training and evaluating underwater target detection models, the underwater images need to be labeled and separated into training and test images. However, specific types of sensors or equipment used for data collection are not mentioned in the given context.