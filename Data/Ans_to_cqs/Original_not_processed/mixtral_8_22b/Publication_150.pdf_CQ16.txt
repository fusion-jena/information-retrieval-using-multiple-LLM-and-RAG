Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

by class sample size. We used the SGD (stochastic gradient descent) optimizer with an initial learning rate of 
0.01 for all models except MansNet, which was initially set at 0.1. The learning rate was reduced by a factor of 
10 after steps of 30 epochs. We used batch normalization and models were trained for 150 epochs using Nvidia 
Tesla K80 or P100 GPUs.

Scientific Reports |         (2021) 11:7580  | 

https://doi.org/10.1038/s41598-021-87210-1

4

Vol:.(1234567890)www.nature.com/scientificreports/Model

#Params 
(million)

Model speed 
(ms)

Top-1 accuracy Top-2 accuracy Top-3 accuracy Top-4 accuracy Top-5 accuracy Macro recall

Wide-ResNet101 124.9

InceptionV3

ResNet101

MnasNet-A1

24.0

42.6

1.0

5.46

3.34

3.33

3.28

0.9171

0.9162

0.9133

0.8579

0.9627

0.9610

0.9633

0.9335

0.9782

0.9767

0.9787

0.9609

0.9850

0.9834

0.9852

0.9730

0.9897

0.9882

0.9892

0.9814

0.8552

0.8519

0.8499

0.7689

Macro 
precision

0.8831

0.8881

0.8740

0.8250

Gathering more images, especially of species with higher error rates, would likely improve the classification 
accuracy of our model and reduce species-specific error rates. This would allow us to capture a greater range 
of the heterogeneity in each species as well as reduce the imbalance among classes. For example, species with 
at least 4,500 images (3,600 train + 900 test) all had error rates lower than 10% (Fig. 3, Table S1). This suggests 
that, for species with error rates greater than 10%, obtaining at least 4,500 images would be an important goal 
for improving model performance. A challenge, however, is that the species with low training sample sizes are 
generally rarer in nature and/or have a restricted range. This rarity reduces their occurrence in databases such 
as Bumble Bee Watch because these species are not frequently encountered by volunteers. Some images can be

the substantial number of submissions that remain unverified because experts cannot keep up, while providing 
high quality data for pollinator conservation science.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly state the specific criteria used to determine when training is complete. However, it mentions that the models were trained for 150 epochs using Nvidia Tesla K80 or P100 GPUs. Epochs refer to one forward pass and one backward pass of all the training examples. Therefore, we can infer that the completion of training was determined based on the number of epochs rather than other metrics like validation loss plateau.