Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

III. 

MATERIALS AND METHODS 

In  this  section  the  dataset  used  in  the  study  is  presented 
along with the modelling approach taken and the evaluation 
metrics used to evaluate the trained model. The section also 
discusses data pre-processing using the Librosa library. Keras 
and TensorFlow 2.2 are utilised as the backend and an Nvidia 
2070 super GPU with 8GB of memory is utilised to accelerate 
model training. In addition, the proposed inferencing pipeline 
is discussed along with the associated technologies. 
A.  Data Collection and Description

Figure 8. Date Pre-processing Stages 

The  acquired  audio  files  are  transmitted  over  4G  using 
SMTP. The audio file is segmented into 15 second windows. 
Each of the sample windows are passed to the feature extractor 
function where MFCC is used to return the extracted features 
for the classifier. The predicted vector is processed and logged 
to the site for review. 

IV. 

EVALUATION AND DISCUSSION 

In this section the classification results are presented using 
the  evaluation  metrics  outlined  previously.  The  deployment 
and inferencing of the trained model in test environment are 
also presented to ascertain the effectiveness of the end-to-end 
pipeline. 
A.  Species Classification Performance

(3) 

The MLP is configured with a filter size of 2 and is used 
with Backpropagation as the learning algorithm and Adam as 
the optimiser. A dropout value of 50% has been used in the 
first  three  layers  to  improve  generalisation  and  reduce 
overfitting. The first three layers are composed of 256 nodes 
while the final layer is equal to the number of classes in our 
dataset. The model summary is shown in figure 5. 

overfitting.  This  section  concludes  the  methods  used  in  this 
paper to train the model. 

The  performance  of  the  trained  model  is  measured  using 
Sensitivity,  Specificity,  Precision  and  Accuracy.  The 
Sensitivity  describes 
the 
Specificity describes the true negative rate. Precision is used 
to show the number of correctly classified species. 
E.  Model Inferencing 

true  positive  rate  while 

the

true  positive  rate  while 

the 

The  trained  model  is  hosted  using  TensorFlow  2.2  and 
served  through  a  public  facing  website  developed  by  the 
authors 2 .  CUDA  11  and  cuDNN  7.6.5  enables  the  GPU 
accelerated learning aspect of the pipeline. A Samsung S10 is 
used  to  record  garden  birds  and  automatically  upload  the 
acquired audio to the platform using the Simple Mail Transfer 
Protocol (SMTP) for classification. Figure 6 shows the end-
to-end inferencing pipeline starting with the sensor and ending 
with the public facing conservationAI site as shown in Figure 
7.  Due  to  the  use  of  standard  protocols,  the  system  can 
interface  with  a  variety  of  sensors  for  real-time  inference. 
Where in field communication is unavailable, audio files can 
be batch uploaded through the website for offline inferencing. 

Figure 6. End-to-end Inferencing Pipeline 

Figure 7. ConservationAI Platform 

Inferencing

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does discuss some aspects of data preprocessing and the overall methodology employed in the study.

The context mentions that the acquired audio files are segmented into 15-second windows, which could be considered a form of data partitioning but not directly related to addressing data bias. Each of these sample windows is then passed to a feature extraction function where Mel Frequency Cepstral Coefficients (MFCC) are used to extract features for the classifier. While this process doesn't explicitly tackle data bias, it contributes to preparing the data for further processing.

Moreover, the context outlines the configuration of the Multilayer Perceptron (MLP), including the use of backpropagation as the learning algorithm and Adam as the optimizer. It also mentions employing a dropout value of 50% in the first three layers to enhance generalization and mitigate overfitting. Although this technique helps prevent overfitting, it doesn't specifically target data bias.

Lastly, the context explains how the performance of the trained model is evaluated using sensitivity, specificity, precision, and accuracy. These metrics provide insights into the model's ability to accurately predict bird species based on the input audio data. Nonetheless, they do not indicate any direct measures taken to counteract potential biases within the dataset.

Therefore, based on the provided context, I cannot definitively state what techniques were used to address data bias during preprocessing of the deep learning pipeline.