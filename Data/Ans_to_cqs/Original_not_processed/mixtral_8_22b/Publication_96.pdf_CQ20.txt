Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Since  deep  learning  methods  require  a  powerful  computational 
processing, we conducted our analysis using graphics processing units 
(GPUs)  and  specialized  hardware  components  for  running  parallel 
arithmetic operations (Goodfellow et al., 2016). The access to GPUs in a 
virtual  machine  environment  was  implemented  on  the  Google  Cloud 
suite  of  cloud 
Platform 

(https://console.cloud.google.com),  a 

3.1. Optimal period of burn scar mapping 

The fire hotspot data analysis provided by INPE (http://www.inpe. 
br/queimadas/bdqueimadas)  indicates  that  most  of  the  fire  events  in 
the  Cerrado  biome  occurred  between  May  and  December,  showing  a 
peak in September 2017 (Fig. 4). Based on it, we focused our mapping 
analysis of burn scars on the period between May and December, which 
comprised 98% of fire hotspots detected in 2017 by INPE. 

3.2. Burned areas in 2017

More recently, there has been a great effort to automate the process 
of classification/mapping of specific targets using Deep Learning (Lecun 
et al., 2015) algorithms, such as the Deep Neural Network (DNN), which 
includes  a  learning  algorithm  based  on  an  artificial  neural  network 
(Langford et al., 2019). In this study, we developed a semi-automatic 
methodological approach for mapping burned areas in the entire Cer-
rado  biome  in  Brazil  using  Deep  Learning  techniques  available  on 
Google Cloud computing and Landsat 8 imagery, which consist of eleven 
spectral bands with a spatial resolution of 30 meters for bands 1-7 and 9, 
15 meters for band 8, and 100 meters for bands 10 and 11. We did not 
use  Landsat-7  imagery  because  of  the  data  gaps  observed  images  ac-
quired after 2003, which would substantially affect the spatial coverage 
of  our  analysis.  We  assessed  accuracies  and  compared  our  mapping 

2. Material and methods 

2.1. Study region

2.3. Cloud computing 

We used the Google Earth Engine platform to collect burned and non- 
burned  spectral  signatures  in  Landsat  imagery  to  be  used  as  training 
areas for the classification model. The training areas and Landsat im-
agery  were  exported  to  Google  Cloud  Storage  and  used  as  input  in  a 
Virtual Machine to process the Deep Learning scripts. The Google Earth 
Engine  was  also  used  to  collect  the  validation  points  and  accuracy 
assessment of the burned areas products used in this analysis. 

2.4. Burned area mapping

The  algorithm  includes  two  steps:  training  and  prediction.  In  the 
training phase, the following parameters where defined, based on tests: 
the  learning  rate  (0.001),  the  batch  size  (1,000),  the  number  of  in-
teractions  (7,000),  and  the  inputs  for  classification  were  the  spectral 
data acquired from the training samples of spectral bands defined based 
on the burned and non-burned areas. The following Lansat-8 spectral 
bands were used for the classification model of burned areas: red (RED - 
0.65 μm), near-infrared (NIR - 0.86 μm), and shortwave infrared (SWIR 
1 - 1.6 μm and SWIR 2 - 2.2 μm). In addition to those selected spectral 
bands, Landsat bands 2 to 7, NDVI (Normalized Difference Vegetation 
Index), NBR, and delta NBR (Difference Normalizes Burned Index) were 
tested. The Landsat spectral bands were chosen because of their sensi-
tiveness to fire events. The input of the training data was split into two

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: Graphics Processing Units (GPUs) and specialized hardware components for running parallel arithmetic operations are used for training the deep learning model. These resources are accessed through a virtual machine environment implemented on the Google Cloud suite of cloud Platform.