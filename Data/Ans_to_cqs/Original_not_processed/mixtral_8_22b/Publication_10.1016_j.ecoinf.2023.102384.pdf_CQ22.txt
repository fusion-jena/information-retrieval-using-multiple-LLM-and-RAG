Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

evaluation is performed using counting metrics, again, on a non-publicly 
available dataset.

Counting Analysis. In the initial set of experiments conducted to assess 
counting performance, we utilize standard counting benchmarks, which 
include Mean Absolute Error (MAE), Mean Squared Error (MSE), and 
Mean  Absolute  Relative  Error  (MARE).  These  metrics  are  defined  as 
follows: 

MAE =

1
N

⃒
∑N
⃒
⃒cn

gt (cid:0) cn

pred

⃒
⃒
⃒,

n=1

MSE =

(

gt (cid:0) cn
cn

pred

)2

,

1
N

∑N

n=1

MARE =

1
N

∑N

n=1

⃒
⃒
⃒cn

pred

gt (cid:0) cn
cn
gt

⃒
⃒
⃒
.

(1)  

(2)  

(3)  

gt  and cn

Yu, F., Koltun, V., 2016. Multi-scale context aggregation by dilated convolutions. In: In 
4th International Conference on Learning Representations, ICLR 2016, San Juan, 
Puerto Rico, May 2-4, 2016, Conference Track Proceedings. 

Tan, X.L., Chen, J.L., Benelli, G., Desneux, N., Yang, X.Q., Liu, T.X., Ge, F., 2017. Pre- 

Zhong, Y., Gao, J., Lei, Q., Zhou, Y., 2018. A vision-based counting and recognition 

infestation of tomato plants by aphids modulates transmission-acquisition 

system for flying insects in intelligent agriculture. Sensors 18 (5), 1489. 

EcologicalInformatics78(2023)10238411

We  assess  our  methodology  against  the  PST  dataset  described  in 
Section 3. We utilize the training subset for the supervised learning step 
concerning PCθ, while the overall counting pipeline is evaluated on the 
test split. First, we investigate the counting ability of the proposed ap-
proaches using the counting golden standard evaluators: basically, we 
investigate the counting performance of our pipeline considering only 
the pest counting module PCθ. Then, we perform further experiments 
taking into account some hybrid metrics that simultaneously consider 
the count error and the estimated raw locations of the insects: essen-
tially, in this case, we consider the entire pipeline, i.e., the PCθ, DG, and 
SG modules. It is worth noting that The PCθ  modules discussed in Section 
4  encompass  various  general  counting  strategies,  including  detection 
and regression. These strategies are drawn from state-of-the-art meth-

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What metrics are used to evaluate the performance of the deep learning model (e.g., accuracy, precision, recall)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The evaluation of the deep learning model is performed using counting metrics. Specifically, the mean absolute error (MAE), mean squared error (MSE), and mean absolute relative error (MARE) are utilized as standard counting benchmarks. MAE measures the average magnitude of errors without considering their direction, MSE quantifies the average squared differences between predicted and actual observations, and MARE calculates the average of the absolute difference between predicted and actual values divided by the actual value. These metrics are applied to a non-publicly available dataset to assess the counting performance of the proposed approaches.