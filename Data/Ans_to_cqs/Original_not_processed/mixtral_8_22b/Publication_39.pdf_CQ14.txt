Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Stochastic Gradient Descent (SGD) is used as optimization technique. 
We start with a learning rate of 0.0005, a momentum of 0.9 and weight 
decay of 0.0005. Different settings of momentum and weight decay are 
checked but show no improvements. In the training process, we decrease 
the learning rate every 10 epochs by multiplying it with γ = 0.1. In the 
first  epoch  we  use  warmup  iterations  for  the  learning  rate  with  a 
warmup factor of 1/1000. These parameters gave the best results in our 
evaluations. We train our models for 30 epochs.

4.4. Action recognition 

The three ResNet variants are trained for 40 epochs starting with an 
initial learning rate of 0.001. The learning rate is decreased every 10 
epochs by multiplying it with a γ = 0.1. For optimization we utilize the 
Stochastic  Gradient  Descent  (SGD)  with  a  momentum  of  0.9  and  a 

EcologicalInformatics61(2021)1012158F. Schindler and V. Steinhage

The SlowFast architecture is trained in 40 epochs with an initial base 
learning rate of 0.1. We use 5 warmup epochs with a warmup learning 
rate of 0.001. Momentum is set to 0.9 and the weight decay parameter is 
(cid:0) 4.  The  learning  rate  is  decreased  with  a  cosine  strategy.  The 
1  ⋅  10
optimization technique is SGD and the loss function is the cross entropy 
loss. In this parameter selection we follow Feichtenhofer et al. (2019). 
We set the temporal length of the input to 16 frames. We set the sam-
pling rate to 4 and α = 2. The parameter β is set to 1/8 as proposed by 

EcologicalInformatics61(2021)1012159F. Schindler and V. Steinhage

Fig. 7. The SlowFast architecture: The backbone for the Slow and Fast pathway is a ResNet. Above, for both pathways the feature map sizes are denoted before the 
first convolution in the Stem. The letter T represents the number of frames that are sampled by the Slow pathway. Further, C is the number of channels and S is the 
width and height of a square crop from a frame. 

A true positive detection (TP) is given if  

• the  confidence  score  is  greater  than  a  threshold,  e.g.  0.5  (Is  the 

detection reliable?)  

• the IoU is greater than a threshold, e.g. 0.5 (Is the detection in the 

right place?)  

• the class prediction is correct

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the provided information, there isn't any explicit mention of how the hyperparameters were optimized, such as using methods like grid search or random search. However, it does state that different settings of momentum and weight decay were checked, which suggests some form of manual tuning or experimentation was conducted. Additionally, the authors note that these specific parameters gave the best results in their evaluations. Therefore, while not explicitly stated, it can be inferred that they likely tried various combinations of hyperparameters and selected those that performed best based on their evaluation metrics.