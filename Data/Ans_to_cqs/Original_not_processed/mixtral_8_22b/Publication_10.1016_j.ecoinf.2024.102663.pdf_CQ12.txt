Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

1. Introduction 

Fish biomass estimation is essential for the fisheries and aquaculture 
industries  (Li  et  al.,  2020).  Manual  methods  of  estimation  can  be 
strenuous for the fish. Thus, there is a need for non-intrusive methods of 
fish  biomass  estimation.  Biomass  estimation  in  a  turbid  environment 
also comes with several challenges. This is where deep learning can play 
a  vital  role.  Training  a  deep  learning  model  on  large  datasets  of  fish 
images  can  provide  accurate  biomass  estimates  without  causing  un-
necessary  strain  to  the  fish  and  minimizes  manual  effort.  Hence,  the 
motivation of this research lies in providing an efficient, precise, and 
cost-effective  method  for  estimating  fish  biomass  in  turbid  environ-
ments. The reliance on fishing and aquaculture is a prominent charac-
teristic of numerous societies, playing a substantial role in bolstering the 

economic and social vitality of various nations and locations.

Furthermore,  the  introduction  of  deep  learning  techniques  to  pre-
processing under extreme conditions such as low light, extreme occlu-
sion, or overlapping of fish can address unique challenges by tailoring 
datasets to specific use cases and training deep learning models on these 
datasets. Incorporating Bidirectional LSTM with GloVe (Abualigah et al., 
2024; Chen et al., 2020) embeddings could enhance the detection and 
classification of fish species within the dataset, capturing contextual and 
semantic information that improves the accuracy of fish biomass esti-
mates. Continuing to modify the architecture of deep learning models 
like YOLO, to better suit specific requirements, includes altering various 
parts of the architecture as needed to handle different environmental 
factors, such as salinity, which affect fish biomass.

Fig. 12. Actual v/s predicted for pixel to cm conversion.  

Table 7 
Finding the best model for pixel to cm converter.  

Model 

Training time 

Prediction time 

Variance 

K Neighbors Regressor 
Extra Trees Regressor 
Random Forest Regressor 
Decision Tree Regressor 
Linear Regression 
Lasso 
Ridge 
K Neighbors Regressor 
Extra Trees Regressor 

0.021 s 
0.721 s 
3.271 s 
0.065 s 
0.013 s 
0.012 s 
0.010 s 
0.021 s 
0.721 s 

0.013 s 
0.125 s 
0.029 s 
0.003 s 
0.003 s 
0.004 s 
0.004 s 
0.013 s 
0.125 s 

0.998 
1 
0.999 
1 
0.899 
0.892 
0.899 
0.998 
1 

MAE 

0.022 
0 
0.014 
0 
0.912 
0.976 
0.912 
0.022 
0 

R2 

0.998 
1 
0.999 
1 
0.899 
0.892 
0.899 
0.998 
1 

MAE/R2 

0.022 
0 
0.014 
0 
1.015 
1.094 
1.015 
0.022 
0

Random Forest Regressor exhibits the longest training time. However, 
the potential improvement in performance may warrant the investment 
of additional effort. Performance of Linear Regression, Lasso, and Ridge 
models is deemed unsatisfactory despite their efficient training times.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific type of deep learning model used in the pipeline. However, it suggests incorporating Bidirectional LSTM with GloVe embeddings, indicating that some form of Recurrent Neural Network (RNN), specifically Long Short-Term Memory (LSTM), might be employed. Additionally, the text mentions modifying the architecture of deep learning models like YOLO, suggesting that Convolutional Neural Networks (CNNs) are also considered. Without further context, it cannot be definitively stated whether the pipeline uses only one type of deep learning model or combines multiple types, such as both RNNs and CNNs.