Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.1. Data filtering

2.3. Data scaling 

The final step refers to data scaling, and intrinsically to gap filling 
and data matching levels required by the user. Different scaling domains 
have been suggested by Fritsch et al. (2020). As the interest relies on 
aggregating  data  across  scales  prior  to  modelling,  our  approach  con-
forms  to  a  “pre-modelling  scaling”  protocol  (Fritsch  et  al.,  2020). 
Sequential  processes  were  implemented  within  GEE  for  scaling  up 
environmental  time  series  from  one  spatial  and/or  temporal  scale  to 
another during data extraction.

under study. Also, data scaling may be particularly useful for gap-filling 
operations,  offering  opportunities  to  avoid  missing  information  within 
extracted  data.  Briefly,  by  increasing  the  spatio-temporal  scale  around 
ground  observations,  users  may  ensure  higher  chances  of  avoiding 
missing  data,  through  the  aggregation  of  spatio-temporal  information 
within moving windows (Fig. 1). However, this implies also a decrease in 
data-matching  accuracy  (Fig.  1).  Key  decisions  and  trade-offs  must  be 
therefore made when extracting spatio-temporal multiscale data, possibly 
involving  particular  strategic  decisions  to  overcome  eventual  imple-
mentation constraints (see the Supplementary information S1.2 section). 

2.4. Worfklow replicability

match environmental information with ground observations (e.g. wild-
life  movements),  other  ecological  processes  may  require  coarser  tem-
poral scales, hence more diluted temporal aggregation (e.g. ecosystem 
resilience). As for spatial scaling, a formula defines how data is tempo-
rally aggregated, namely by a mean, median, or standard deviation.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: The given context does not provide specific details about addressing data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it discusses two important aspects of data processing - data filtering and data scaling.

Data filtering involves removing irrelevant features or instances from the dataset to improve model performance. This can help reduce bias caused by noisy or redundant data.

Data scaling, on the other hand, deals with normalizing or transforming data into a common range or format. It helps prevent certain features from dominating others due to their larger magnitudes, which could introduce bias. In the context provided, data scaling is discussed in relation to gap filling and data matching levels required by the user. Different scaling domains have been suggested by Fritsch et al. (2020), and the approach conforms to a 'pre-modelling scaling' protocol. Sequential processes were implemented within Google Earth Engine (GEE) for scaling up environmental time series from one spatial and/or temporal scale to another during data extraction.

While these techniques do not directly address data bias in the same way as stratified splitting, oversampling, undersampling, or diverse data collection, they contribute to creating a cleaner and more balanced dataset, indirectly reducing potential sources of bias.