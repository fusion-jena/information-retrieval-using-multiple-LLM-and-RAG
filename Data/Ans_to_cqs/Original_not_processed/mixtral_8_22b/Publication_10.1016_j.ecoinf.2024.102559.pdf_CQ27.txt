Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., 
Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, ´E., 2011. Scikit-learn: machine 
learning in Python. J. Mach. Learn. Res. 12, 2825–2830. 

Petty, A.M., Setterfield, S.A., Ferdinands, K.B., Barrow, P., 2012. Inferring habitat 

suitability and spread patterns from large-scale distributions of an exotic invasive 
pasture grass in North Australia. J. Appl. Ecol. 49 (3), 742–752. https://doi.org/ 
10.1111/j.1365-2664.2012.02128.x. 

Prasai, R., Schwertner, T.W., Mainali, K., Mathewson, H., Kafley, H., Thapa, S., 

Adhikari, D., Medley, P., Drake, J., 2021. Application of Google earth engine python 
API and NAIP imagery for land use and land cover classification: A case study in 
Florida, USA. Eco. Inform. 66, 101474 https://doi.org/10.1016/j. 
ecoinf.2021.101474.

structures (e.g., roads and buildings) and water from slowing down the 
classification processing. This step reduced the average number of pixels 
per scene the classification model had to analyze to 3,757,323 and took, 
on average, 18 s per scene.

Ustin, S.L., DiPietro, D., Olmstead, K., Underwood, E., Scheer, G.J., 2002. Hyperspectral 

remote sensing for invasive species detection and mapping. In: IEEE International 
Geoscience and Remote Sensing Symposium, 3, pp. 1658–1660. https://doi.org/ 
10.1109/IGARSS.2002.1026212. 

Vali, A., Comai, S., Matteucci, M., 2020. Deep learning for land use and land cover 

classification based on hyperspectral and multispectral earth observation data: a 
review. Remote Sens. 12 (15), 2495. https://doi.org/10.3390/rs12152495. 
Van Der Walt, S., Sch¨onberger, J.L., Nunez-Iglesias, J., Boulogne, F., Warner, J.D., 
Yager, N., Gouillart, E., Yu, T., 2014. Scikit-image: image processing in Python. 
PeerJ 2, e453. https://doi.org/10.7717/peerj.453.

Acknowledgements 

Leveraging  cloud  computing  and  machine  learning  to  analyze 
remotely sensed data has great potential to create novel tools and fill 
crucial information gaps for invasive species monitoring. Particularly, 
when coupled with high resolution data, machine learning methods can 
be a powerful way to detect invasive species occupying a small fraction 
of the landscape and impacting critical and endangered ecosystems. The 
map of 2020 iceplant locations in Santa Barbara County is an example of 
such a combination of machine learning, cloud computing, and remotely 
sensed data analysis. This is the first ever map of iceplant at this scale, 
immediately  useful  for  restoration  and  conservation  efforts  in  Santa 
Barbara  County,  in  particular  in  the  Jack  and  Laura  Dangermond

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What process was followed to deploy the trained deep learning model (e.g., Model serialization, Platform selection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context does not provide specific details about the deployment process of the trained deep learning model used for creating the map of 2020 iceplant locations in Santa Barbara County. However, it mentions leveraging cloud computing and machine learning to analyze remotely sensed data. Typically, after training a deep learning model, one might follow these steps for deployment:

1. Model Serialization: Save the trained model parameters into a file or database so they can be loaded later during prediction time. Common formats include.h5 for Keras models,.pt for PyTorch models, and.pb for TensorFlow models.

2. Platform Selection: Choose a platform to host the deployed model. Popular options include cloud platforms like AWS, Azure, and Google Cloud Platform, which offer services such as Amazon SageMaker, Azure Machine Learning Studio, and AI Platform respectively. These platforms allow users to easily manage, serve, and monitor their models.

3. Deployment: Upload the serialized model onto the chosen platform and configure any necessary settings, such as scaling policies, security permissions, and API gateways. Once set up, the model will be ready to receive input data and return predictions.

Since the context doesn't explicitly mention these steps, we cannot confirm if they were followed for deploying the trained deep learning model.