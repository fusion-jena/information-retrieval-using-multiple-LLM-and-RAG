Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(minimum and maximum length, respectively); and a maximum inter-
syllable gap of 4 s. In this step Kaleidoscope automatically extracted all 
sounds  that  satisfied  the  signal  parameters  introduced  and  saved  the 
output.

Acoustic  data  analyses  were  carried  out  using  Kaleidoscope  Pro 
5.4.7, which is an automated signal recognition software able to analyze 
large acoustic datasets. Kaleidoscope extracts sounds of interest based 
on the following five parameters: minimum and maximum signal length 
(s),  minimum  and  maximum  frequency  range  (Hz),  and  maximum 
intersyllable gap (ms). The maximum intersyllable gap represents the 
maximum distance between sounds to be considered part of the same 
vocalization. To identify representative parameters of the song of the 
Nighthawk we characterized 67 songs using all recordings uploaded in 
Xeno-canto and recorded in the State of Mato Grosso (eight recordings, 
see Supplemental Table S1). Song parameters were characterized from 
spectrograms  using  Raven  Pro  1.5  (Bioacoustics  Research  Program, 
2014). The signal parameters introduced in Kaleidoscope were: 900 and 
1500 Hz (minimum and maximum frequency, respectively); 4 and 30 s

Lambert, K.T., McDonald, P.G., 2014. A low-cost, yet simple and highly repeatable 
system for acoustically surveying cryptic species. Aust. Ecol. 39 (7), 779–785. 
LeBien, J., Zhong, M., Campos-Cerqueira, M., Velev, J.P., Dodhia, R., Ferres, J.L., Aide, T. 
M., 2020. A pipeline for identification of bird and frog species in tropical soundscape 
recordings using a convolutional neural network. Ecol. Informat. 59, 101113. 
Lin, H.Y., Binley, A.D., Schuster, R., Rodewald, A.D., Buxton, R., Bennett, J.R., 2022. 
Using community science data to help identify threatened species occurrences 
outside of known ranges. Biol. Conserv. 268, 109523. 

Maxwell, S.L., Fuller, R.A., Brooks, T.M., Watson, J.E.M., 2016. Biodiversity: the ravages 

of guns, nets and bulldozers. Nature 536, 143–145.

recorded (c. 6000 recording hours). Kaleidoscope Pro ability to detect 
the Band-tailed Nighthawk in a different area may be slightly different 
owing  to  geographical  song  variations  since  the  signal  parameters 
introduced  in  our  study  were  extracted  from  recordings  collected  at 
different sites of the state of Mato Grosso and based on a reduced sample 
size (eight recordings). The creation of more advanced classifiers using 
machine learning or convolutional neural networks might be useful in 
future  studies  aiming  to  reduce  the  number  of  sounds  misclassified 
(LeBien et al., 2020).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The deep learning pipeline mentioned in the given context uses audio data. Specifically, it utilizes large acoustic datasets analyzed by Kaleidoscope Pro 5.4.7, an automated signal recognition software. This software extracts sounds of interest based on certain parameters such as minimum and maximum signal length, minimum and maximum frequency range, and maximum intersyllable gap. The goal of this pipeline is to identify bird and frog species in tropical soundscape recordings. Therefore, the primary data format used in this deep learning pipeline is audio data.