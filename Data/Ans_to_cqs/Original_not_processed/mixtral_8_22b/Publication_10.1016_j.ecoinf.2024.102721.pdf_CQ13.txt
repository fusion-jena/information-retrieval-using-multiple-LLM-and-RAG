Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Contents lists available at ScienceDirect

Ecological Informatics

journal homepage: www.elsevier.com/locate/ecolinf

Forecasting ecological water demand of an arid oasis under a drying
climate scenario based on deep learning methods

Xu-dong Wang a, Hao-jie Xu a,b,*, Yan-xia Pan c, Xue-mei Yang d
a State Key Laboratory of Herbage Improvement and Grassland Agro-ecosystems; Key Laboratory of Grassland Livestock Industry Innovation, Ministry of Agriculture and
Rural Affairs; Engineering Research Center of Grassland Industry, Ministry of Education; College of Pastoral Agriculture Science and Technology, Lanzhou University,
Lanzhou 730020, China
b Center for Remote Sensing of Ecological Environments in Cold and Arid Regions, Lanzhou University, Lanzhou 730000, China
c Northwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences, Lanzhou 730000, China
d Tourism School, Lanzhou University of Arts and Science, Lanzhou 730000, China

A R T I C L E I N F O

A B S T R A C T

2.3.3. LSTM model

The LSTM model is a type of machine learning model that is derived
from recurrent neural networks (RNN). Its special memory unit effec-
tively addresses the issue of gradient vanishing and explosion in RNN for
long-term sequences. The structure of the model is illustrated in Fig. 3.
The LSTM memory unit comprises a forget gate, input gate, output gate,
and hidden layer. Signals are transmitted between different units
through three control gates in the hidden layer, determining which in-
formation should be stored, read, and written. Because of the precise
control of information by gate structures, LSTM can effectively learn in
long time sequences and is well-suited for time series prediction.

Fig. 3. Structure of the long- and short-term memory model neural network.

EcologicalInformatics82(2024)1027215X.-d. Wang et al.

2.3.4. Bayesian optimization

Despite the growing popularity of ML models in eco-hydrological
studies, building effective models is a complex and time-consuming
process that involves tuning a large number of hyper parameters to
obtain an optimal model architecture. Because of the non-linear inter-
action between hyper parameters, manual tuning is ineffective for most
issues. Bayesian optimization (BO) is a global optimization algorithm
that optimizes the hyper parameters in ML models to achieve high
simulation accuracy. The combination of BO and LSTM improves the
performance of the model on unseen data, thereby increasing the
generalization ability and robustness of the model. The BO algorithm is
based on the Bayesian theorem to estimate the posterior distribution of
target functions. It establishes a provisional surrogate function based on
past evaluation of unknown target functions and continues to search for
the next set of hyper parameters that minimize the surrogate function

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the hyperparameters used in the deep learning model (e.g., learning rate, optimizer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide specific details about the hyperparameters used in the deep learning model. However, it mentions that Bayesian Optimization was employed to tune these hyperparameters. Commonly used hyperparameters in deep learning models include learning rate, batch size, epochs, optimizers (like Adam or Stochastic Gradient Descent), activation functions, loss functions, and regularization techniques like dropout or weight decay. These hyperparameters play a crucial role in achieving high simulation accuracy and improving the generalization ability and robustness of the model.