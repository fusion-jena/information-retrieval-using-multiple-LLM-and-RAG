Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

http://orcid.org/0000-0002-2176-7935 

R E F E R E N C E S

Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., … Kudlur, M. 
(2016). TensorFlow: A system for large- scale machine learning. OSDI, 
16, 265–283.

Anderson, T. M., White, S., Davis, B., Erhardt, R., Palmer, M., Swanson, A., 
… Packer, C. (2016). The spatial distribution of African savannah her-
bivores: Species associations and habitat occupancy in a landscape 
context.  Philosophical  Transactions  of  the  Royal  Society  B:  Biological 
Sciences, 371, 20150314. https://doi.org/10.1098/rstb.2015.0314
Babaee,  M.,  Dinh,  D.  T.,  &  Rigoll,  G.  (2017).  A  deep  convolutional  neu-
ral  network  for  background  subtraction.  Pattern  Recognition,  76, 
635–649.

classes. Dropout is a form of regularisation that randomly removes 

a  proportion  of  nodes  to  reduce  overfitting  (Srivastava,  Hinton, 

Krizhevsky, Sutskever, & Salakhutdinov, 2014). The fully connected 

layer reduces the vector of image features to the desired dimension-

ality of length two (foreground and background). The softmax layer 

normalises  this  vector  into  probabilities  that  sum  to  one  across  all 

classes.  DeepMeerkat  is  designed  to  be  conservative,  with  a  high 

threshold for retaining frames (acceptance value = 0.1). This means 

that the model must be more than 90% confident that a frame does 

not contain a foreground object to assign a background label. This 

prioritises minimising false negatives at the potential expense of in-

Methods in Ecology and Evolu(cid:13)on

    |  1437

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, 
R. (2014). Dropout: A simple way to prevent neural networks from 
overfitting.  Journal  of  Machine  Learning  Research,  15,  1929–1958. 
https://doi.org/10.1214/12-AOS1000

Swanson, A., Kosmala, M., Lintott, C., Simpson, R., Smith, A., & Packer, C. 
(2015).  Snapshot  Serengeti,  high- frequency  annotated  camera  trap 
images  of  40  mammalian  species  in  an  African  savanna.  Scientific 
Data, 2, 150026. https://doi.org/10.1038/sdata.2015.26

Swinnen,  K.  R.  R.,  Reijniers,  J.,  Breno,  M.,  &  Leirs,  H.  (2014).  A  novel 
method  to  reduce  time  investment  when  processing  videos  from 
camera trap studies. PLoS ONE, 9, e98881. https://doi.org/10.1371/
journal.pone.0098881

AC K N OW L E D G E M E N T S

Thanks to Segment for supporting this work as part of their Open 

Data Fellowship. Thanks to the many Google engineers who shared 

code samples and answering questions on deploying machine learn-

ing models. The author declares no conflict of interest.

DATA ACC E S S I B I L I T Y

A DeepMeerkat executable for Mac and Windows is available with 

cloud systems. In 2017 IEEE/ACM second international conference on 
internet-of-things  design  and  implementation  (IoTDI),  Pittsburgh,  PA, 
2017 (pp. 247–258).

Gregory, T., Carrasco Rueda, F., Deichmann, J., Kolowski, J., & Alonso, A. 
(2014).  Arboreal  camera  trapping:  Taking  a  proven  method  to  new 
heights.  Methods  in  Ecology  and  Evolution,  5,  443–451.  https://doi.
org/10.1111/2041-210X.12177

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What techniques are used to address data bias during preprocessing of the deep learning pipeline (e.g., Stratified splitting, oversampling, undersampling, Diverse data collection)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper referenced in the given context does not explicitly discuss specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, some commonly used techniques to handle data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same class proportions in both sets. This ensures that the model generalizes well to unseen data.

Oversampling and undersampling involve adjusting the number of instances in each class to balance the dataset. Oversampling increases the number of minority class examples by duplicating them or creating synthetic examples using methods such as SMOTE (Synthetic Minority Over-sampling Technique). Undersampling decreases the number of majority class examples by removing random instances or selecting only those that contribute most to the classification task.

Diverse data collection aims to gather a wide range of representative examples from different sources, environments, and conditions to ensure that the model can accurately recognize various patterns and avoid biased predictions based on limited data.

These techniques help mitigate data bias and improve the performance of deep learning models. It is essential to consider these approaches during preprocessing to build robust and reliable models.