Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

extending  the  possibility  for  a  wide  coverage.  The  improvements  in 
Explainable  Artificial  Intelligence  techniques  can  make  it  easy  to  un-
derstand and interpret the deep learning models' predictions, and also to 
evaluate  and  improve  the  models.  The  large-scale  inferences  from  a 
study could see an interplay between the low power edge devices and 
virtually unlimited storage and compute resources with cloud technol-
ogies. By incorporating the processing on the camera trap, it is possible 
to obtain timely information from large scale ecological studies, even at 
the global scale. With further improvements in the battery technologies, 
deep learning model optimizations, and better hardware, it would soon 
become easier and common for ecological studies to utilize customized 
camera  trap  devices  with  on-board  classification,  visualization,  and 
communications.

In future work, we will investigate model optimization techniques 
for deploying the deep learning models to even smaller microcontroller 
devices. Such low power devices can further economize the batteries and 
run autonomously to provide near real-time ecological insights from the 
field.  We  would  also  research  other  model  fine-tuning  techniques  to 
improve the model performance by investigating model pre-training on 
large datasets from ecological studies. 

Funding 

This  research  did  not  receive  any  specific  grant  from  funding 

agencies in the public, commercial, or not-for-profit sectors. 

Declaration of competing interest 

The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper. 

Data availability 

Data will be made available on request.  

Appendix A. Appendix  

Table A1 
Class wise statistics for the Florida-Part1 dataset.  

Technique

For model deployment to an edge device, e.g., RPi, the model needs 
to be converted to the TensorFlow Lite format, which although reduces 
its size, but also reduces the modelâ€™s accuracy. The model can then be 
used on an edge device for classification of as yet unseen images. The 
TensorFlow or TensorFlow Lite model may also optionally be optimized 
for size, or latency depending on the application requirements and the 
edge device specifications. The RPi or similar edge devices can also be 
used to  run XAI  techniques such as  Grad-CAM  for generating  visuali-
zations through heatmaps. 

3.3. Transfer learning approaches for image classification

3.2. Process flow 

This study has two perspectives, model training and development on 
a high-end computer, and the model deployment to an edge device, as 
shown in Fig. 3. The training dataset could be pre-processed, such as 
denoising,  contrast  enhancement,  and  image  resizing.  We  only  used 
image re-sizing to make the images suitable for the input image reso-
lution required for the selected models. 

After a model has been trained, it needs to be validated and tested to 
confirm that it has achieved the desired performance. The performance 
might  be  measured  using  different  metrics,  such  as  classification 

Table 2 
The class distribution in the Extinction dataset.  

Class 

Number of images

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which platform was used to deploy the deep learning model (e.g., AWS, Azure, Google Cloud platform)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, there is no explicit mention of a specific platform like AWS, Azure, or Google Cloud Platform being used to deploy the deep learning model. However, it does mention the use of TensorFlow Lite format for converting the model for deployment on an edge device like Raspberry Pi (RPi). Therefore, it seems that the focus here is more on deploying the model on local edge devices rather than on a cloud platform.