Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We  classified  all  the  input  dataset combinations  (10  variable  sets; 
Table  2)  with  each  classifier  (RF,  SVM,  MARS)  and  with  two  sets  of 
classes (7C and 13C); thus, we had 60 models as a result of the classi-
fications. Classifications and hyperparameter tuning were conducted in 
R  4.2  (R  Core  Team,  2023)  with  the  caret  package  (Kuhnaut  et  al., 
2022). 

2.4. Accuracy assessment

Thirty models of the 10 input datasets with three classifiers revealed 
that the best five medians belonged to the SVM and RF, while the MARS 
was only ranked 6th (7C) and 10th (13C) (Fig. 6). The best OAs were 
96.1% (7C) and 85.4% (13C), and the model performance also depended 
on the input datasets, while the best accuracy of 7C was obtained with 
the RFE variable selection dataset. In the case of 13C, it required the use 
of  all  variables;  nevertheless,  the  RFE  dataset  ensured  only  slightly 
(1.1%)  worse  OA.  Regarding  the  minimum  OAs,  RF  (with  the  RFE 
dataset)  provided  3.8%  better  results  than  the  SVM  (with  the  RFE 
dataset; 80.7%) in the case of 7C, and we experienced the same in the 
case of 13C, but the difference was only 1.9%. The texture index alone 
was the worst input data, with median OAs of 38.8% and 30.9% (7C and 
13C, respectively), followed by 74.0% and 66.6% for spectral indices,

Staiano, 2019). Training data augmentation, which extends the existing 
training  data,  enhances  the  generalization  capabilities  (Lik´o  et  al., 
2023). Post-classification, generally segmentation, and filtering gener-
ally  provide  better  maps  with  a  lower  rate  of  salt-and-pepper  errors 
(Ahmed et al., 2017). We can also deal with the characteristics of the 
geometry of the training data, excluding outliers, refining the training 
samples, or changing the proportion of the training and test data. These 
strategies collectively improve classification accuracy, enabling better 
modelling of the environment.

Li, Y., Deng, T., Fu, B., Lao, Z., Yang, W., He, H., Fan, D., He, W., Yao, Y., 2022. 

Evaluation of decision fusions for classifying karst wetland vegetation using one- 
class and multi-class CNN models with high-resolution UAV images. Remote Sens. 
14, 5869. https://doi.org/10.3390/rs14225869. 

Lik´o, S.B., Holb, I.J., Ol´ah, V., Burai, P., Szab´o, S., 2023. Deep learning-based training 
data augmentation combined with post-classification improves the classification 
accuracy for dominant and scattered invasive forest tree species. Remote Sens. Ecol. 
Conserv. n/a https://doi.org/10.1002/rse2.365. 

Manfreda, S., McCabe, M.F., Miller, P.E., Lucas, R., Pajuelo Madrigal, V., Mallinis, G.,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What type of deep learning model is used in the pipeline (e.g., CNN, RNN, Transformer)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not explicitly mention the specific type of deep learning model used in the pipeline. However, there are references to other studies that have used Convolutional Neural Networks (CNN) for similar tasks such as Li et al. (2022) who evaluated decision fusions for classifying karst wetland vegetation using one-class and multi-class CNN models with high-resolution UAV images. Additionally, Liko et al. (2023) mentioned using deep learning-based training data augmentation combined with post-classification to improve the classification accuracy for dominant and scattered invasive forest tree species. But they did not specify the exact type of deep learning model used. Therefore, based on the given information, it cannot be determined what type of deep learning model is used in the pipeline.