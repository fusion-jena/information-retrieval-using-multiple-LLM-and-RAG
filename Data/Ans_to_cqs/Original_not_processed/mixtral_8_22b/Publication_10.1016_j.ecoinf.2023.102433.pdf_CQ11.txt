Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics79(2024)1024336A. Montaghi et al.                                                                                                                                                                                                                              

library allows the user to query the NASA service to discover all products 
available  for  a  given  reference  date.  This  is  done  by  the  availa-
ble_products_by_date() method, which returns the list of all products along 
with their availability. This allows users to optimize the pipeline for data 
download by limiting requests to available products.

MongoDB (Reniers et al., 2019). This solution was implemented inside 
the  DataHarvester  class.  In  the  domain  of  Remote  Sensing,  the  Data-
harvester component is a set of synchronous or asynchronous processes 
which is capable to detect new satellite images from the space agency 
database.  Once  a  new  image  is  found,  the  component  downloads  the 
data  using  the  internal  scripts  (Bellini  et  al.,  2021).  Different  imple-
mentations  of  the  DataHarvester  class  can  target  other  databases, 
ensuring flexibility of use of nasawebservice for different user needs. For 
instance,  a  client  could  use  different  open-source  NoSQL  frameworks 
such as HBase introduced by Google Bigtable, Elasticsearch developed 
by Java on Apache Lucene, or eventually one of the many SQL database 
solutions.  Whichever  storage  solution  chosen  by  the  user,  the  stored 
MODIS data provides support, together with other data types, for agri-

In this manuscript, we provided an overview of new Python package 
nasawebservice,  whose  main  purpose  is  to  optimize  the  interface  with 
NASA web service and reduce the pre-processing steps and related time 
needed to download large amounts of satellite imagery for agroecolog-
ical studies. The overarching rationale for proposing this new Python 
package is to present a set of methods and  ready-to-use functions  for 
retrieving MODIS data from the NASA MODIS/VIIRS Land Products web 
service model. This package could be part of an automated data inges-
tion pipeline, both in local and cloud environment, being able to inte-
grate  the  first  part  of  an  Extract  Transform  and  Load  process  (ETL) 
scheme. The main advantage of using this package is that the data ob-
tained are in JSON format (Wang, 2011). In this way it is possible to 
avoid all those pre-processing operations that hamper the use of satellite

The Python nasawebservice is a user-friendly package that provides a 
set of classes and methods to define pipelines for the automatic MODIS 
data ingestion from the NASA MODIS/VIIRS Land Products Web Service. 
The nasawebservice is implemented in the Python 3 programming lan-
guage. Its dependencies are requests, aiohttp, and asyncio (Hunt, 2019). 
The  remaining  dependencies  used  are  standard  libraries  for  maximal 
compatibility. To facilitate the users in the creation of their data process 
workflows, the nasawebservice was designed to be as close as possible to 
the  Global  Subset  APIs  of  the  NASA  service  making  use  of  wrapper 
methods,.  Furthermore,  the  library  provides  additional  methods  with 
the purpose of making the data ingestion pipeline scalable according to 
various  user  needs.  All  these  methods  are  exposed  by  NasaWebServi-
ceAPIProvider  class. NasaWebServiceAPIProvider object is  initialized by

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
I am sorry, but there is no information about the data repository link of the deep learning pipeline in the provided context.