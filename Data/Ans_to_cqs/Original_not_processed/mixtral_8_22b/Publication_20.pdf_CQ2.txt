Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

We used a GoogLeNet architecture as it was the winner of the 2015
competition imageNet (Szegedy et al., 2015), an identiﬁcation chal-
lenge on 1000 diﬀerent classes. This CNN is composed of 22 layers. It
uses inception modules. Inception modules allow the network to use
convolutions of diﬀerent sizes (1*1, 3*3 and 5*5 pixels) and to weight
each of these convolutions. This network could thus account more or
less strongly for the context of each pixel, which increases the range of
possibilities to improve its performance during the training.

Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet Classiﬁcation with Deep
Convolutional Neural Networks. InAdvances in Neural Information Processing
Systems. pp. 1097–1105.

Krueck, N.C., Ahmadia, G.N., Possingham, H.P., Riginos, C., Treml, E.A., Mumby, P.J.,

2017. Marine reserve targets to sustain and rebuild unregulated ﬁsheries. PLoS Biol.
15 (1), e2000537.

Kulbicki, M., Parravicini, V., Bellwood, D.R., Arias-Gonzàlez, E., Chabanet, P., Floeter,
S.R., ... Mouillot, D., 2013. Global biogeography of reef ﬁshes: a hierarchical quan-
titative delineation of regions. PLoS One 8 (12), e81847.

Langlois, T.J., Harvey, E.S., Fitzpatrick, B., Meeuwig, J., Shedrawi, G., Watson, D., 2010.
Cost-eﬃcient sampling of ﬁsh assemblages: comparison of baited video sta=tions

244

and diver video transects. Aquat. Biol. 9, 155–168.

However, the accuracy of CNN methods is highly dependent on the
extent and the quality of data used during the training phase, i.e. the set
of images annotated by experts for all classes to identify. The eﬀects of
the extent of the training database (i.e. the number of images per class)
and associated post-processing decision rules on the performance of the
whole identiﬁcation process remain untested. Since real-life videos of
coral reef ﬁshes and thus images extracted from those videos are highly
diverse in terms of surrounding conditions (environment, light, con-
trast) and ﬁsh positions, the performance of identiﬁcation methods
must be carefully tested using an independent dataset to assess its ro-
bustness over changing conditions.

Ecological Informatics 48 (2018) 238–244

of 16 images to train our network. We ran this architecture on Caﬀe (Jia
et al., 2014). To focus on the impact of the training data, we used the
same CNN architecture for our training and test procedures.

2.3. Building the training datasets

Using the raw training dataset of 20 ﬁsh species (Table S1) we built
4 diﬀerent datasets to assess the inﬂuence of the dataset building on
classiﬁcation results (Table S2).

The ﬁrst training dataset T1 contained raw ﬁsh thumbnails (T0) and

their respective mirror images.

More precisely, we doubled the number of thumbnails per ﬁsh in-
dividual by ﬂipping each thumbnail with respect to the vertical axis.
Such a procedure homogenizes the proportion of left-oriented and
right-oriented individuals in the database and we hypothesize it could
improve the average identiﬁcation rate since ﬁsh individuals are seen in
all positions.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What data formats are used in the deep learning pipeline (e.g., image, audio, video, CSV)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: Based on the provided context, the data format used in the deep learning pipeline is images. Specifically, the study uses a GoogLeNet architecture, which is a type of Convolutional Neural Network (CNN) designed for image classification tasks. The authors mention using a raw training dataset of 20 fish species, where each individual fish has corresponding thumbnail images. These images were then manipulated to create additional training data by flipping them along the vertical axis. Therefore, the primary data format used in this deep learning pipeline is images.