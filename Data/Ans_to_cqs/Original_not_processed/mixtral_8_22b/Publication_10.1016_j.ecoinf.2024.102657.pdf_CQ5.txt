Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

grams, and created the metadata .csv file necessary for training the CNN 
and k-NN. Identical in structure to the metadata file outlined above, this 
file contained the metadata for the training set as opposed to the met-
adata for the entire dataset. 

No additional preprocessing was applied to the spectrograms as the 
goal was to do the least amount of preprocessing possible in order to 
demonstrate  the  power  of  human-machine  teaming.  Further,  when 
assessing the accuracy of the CNN on noise-filtered data versus raw data, 
the accuracy levels were similar: after 10 trials, the CNN’s accuracy on 
the  filtered  data  averaged  to  99.22%  and  the  accuracy  on  the  non- 
filtered data averaged to 99.25%.

Additionally,  we  created  a  metadata  .csv  file  that  listed  all  of  the 
necessary classification information for training the CNN and k-NN . The 
.csv file had five columns. The first, dialect_folder, listed the file path to 
the folder containing the bird song. Each folder was labeled with the 
dialect type and the year it was collected, for example, “ABLA_2022”. 
Note, each folder name contained the label of the songs inside, as this 

EcologicalInformatics82(2024)1026572B. Story et al.

For the CNN portion of our program, we used ResNet-18, a 18-layer 
CNN established in (He et al., 2016) and implemented via PyTorch. For 
the inputs, the data preparation program (0_prep_data.py) generated the 
spectrograms from the .wav of each song using the Librosa (McFee et al., 
2023) python package and cropped out all axis labels and borders from 
each image. This provided a dataset of images with pixel size 480 × 365. 
ResNet-18 requires images to be 224 × 224, so the program used the 
Pytorch function “resize” to properly re-scale each image with a built-in 
anti-aliasing feature. Then, the program converted each image into the 
appropriate  input  for  the  CNN.  The  CNN  used  a  train/validation/test 
split of 70%/10%/20% of the training dataset and was trained for 25 
epochs; we used the model state from the epoch in which the highest 
validation accuracy was achieved. 

2.2.2. k-NN structure

2.2.1. CNN structure 

A CNN is a type of neural network commonly used for image clas-
sification  which  includes  convolutional  layers  within  its  architecture. 
Each  convolutional  layer  applies  a  2-dimensional  convolution  of  the 
input  image or  feature  matrix by  a  collection  of learned  kernels.  The 
kernels are matrices containing learned weights of the network, whose 
size  are  typically  small  relative  to  the  size  of  the  input  images.  For 
example, many convolutional layers use a kernel of size 3 × 3. For each 
kernel, the convolution operation computes the dot product between the

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the datasets used in the deep learning pipeline (e.g., MNIST, CIFAR, ImageNet)? "

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The text does not provide explicit details about the specific datasets used in the deep learning pipeline. However, it mentions that the goal was to demonstrate the power of human-machine teaming with minimal preprocessing. It also states that the CNN used ResNet-18, a well-known 18-layer CNN architecture, and that the input data consisted of spectrograms generated from bird songs. These spectrograms were then resized to fit the required dimensions for ResNet-18. Therefore, while the exact names of the datasets are not mentioned, it can be inferred that the datasets used in this case were custom datasets consisting of bird song spectrograms.