Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The training dataset, including 268 sample plots with 39 features in a 
tabulated format, was used as input during the training process (opti-
mizing  hyper-parameters  and  fitting  models  with  these  data).  The 
training data set was divided into two parts, in which 80% was used for 
training/validation, and the remaining 20% was kept as unseen data for 
testing. To eliminate bias, 10-fold cross-validation was used during the 
training  process,  and  mean  RMSE  was  used  as  the  objective  function 
(lost function). Table 4 shows RMSE, MAE, and R2  using different op-
timizers. In addition, we tested the differences between the RMSEs in 
Table 4 using the Wilcoxon Signed-Rank test with paired samples. The 
differences between (XGBoost-BO vs. XGBoost-TDO, XGBoost-BOHB vs. 
XGBoost-TDO) or (LightGBM-BO vs. LightGBM-TDO, LightGBM-BOHB 
vs.  LightGBM-TDO)  are  significant.  However,  the  performance  of 
XGBoost-TDO  versus  LightGBM-TDO  appears  to  be  the  same (Fig.  3),

2.4. Hyperparameter optimisation 

Hyperparameter  optimization  searches  for  the  best  set  of  hyper-
parameters  for  a  machine  learning  model  that  can  perform  best  on  a 
given  task.  In  many  packages,  random  or  grid  search  is  the  default 
method  for  selecting  optimal  hyperparameters  (Snoek  et  al.,  2012). 
There are many studies on the selections of optimization algorithms for 
theoretical  problems  or  engineering  applications,  in  which  various 
versions  of  Bayesian  optimizers  and  Swarm-based  algorithms  were 
compared (Stenger et al., 2019; Stenger and Dirk, 2022).

information  gain  estimation  and  tree  growth.  This  algorithm  is 
controlled by several parameter groups, including (1) Boosting param-
eters such as Max_depth, Learning_rate, and gamma, and (2) Learning 
task  parameters  such  as  loss  function  type,  evaluation  metric,  and 
number of iterations. As a result, the model becomes more complex as 
the tree grows, but more loss is reduced than level-wise, and the algo-
rithm learns faster. 

EcologicalInformatics79(2024)1024214Q.-T. Bui et al.

MSAVI =

GREEN (cid:0) BLUE 
2NIR + 1 (cid:0)

√

̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
(2NIR + 1)2 (cid:0) 8(NIR (cid:0) RED)

predictive efficiency, handle large datasets, and reduce training time. It 
is typically recommended for tabular datasets. LightGBM differs from 
other tree-based methods by implementing leaf-wise splits that create 
more  complex  trees,  which  are  more  efficient  in  reducing  loss  and 
resulting  in  higher  accuracy.  The  split  is  based  on  a  novel  sampling 
method named Gradient-Based One-Side Sampling (Ke et al., 2017), in 
which data with small gradients are excluded, and the rest are used for

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there is no information available regarding the specific hardware resources used for training the deep learning model in this case. Therefore, it cannot be determined whether GPUs, TPUs, or other types of hardware resources were utilized for the training process.