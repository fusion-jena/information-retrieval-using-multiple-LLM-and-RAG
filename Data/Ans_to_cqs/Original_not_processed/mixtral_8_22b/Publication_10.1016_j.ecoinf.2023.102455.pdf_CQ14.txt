Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

The Bayesian Optimization program was used in this study to opti-
mize  hyperparameters  related  to  ML  algorithms.  Compared  to  grid 
search or random search methods, the Bayesian 

optimization method can accelerate and improve the optimization of 
hyperparameters.  The  Bayesian  Optimization  package  uses  Bayesian 
optimization to explore the hyperparameter space by selecting the next 
set of hyperparameters to estimate based on past evaluations (Yoshida 

EcologicalInformatics80(2024)10245518M. Jamei et al.                                                                                                                                                                                                                                  

Fig. 12. Diagnostic analysis using the relative deviation in form of the violin plots using the decomposition-based complementary models over the testing period. 
IQR represents the interquartile range of relation deviation values.

Bayesian  optimization,  and  more  direct  methods  (such  as  random 
search, grid search, and trial and error schemes).

(cid:0) γ

)

⃦
⃦xi (cid:0) xj

⃦
⃦2

(10) 

Where γ is the kernel parameter. It is notable to emphasize that the 
network training process of KELM requires the optimization of only two 
hyper-parameters,  namely  γ  and  .  This  feature  makes  KELM  more 
convenient  compared  to  other  neural  network  techniques,  such  as 
BPNN,  which  entails  the  optimization  of  more  than  six  hyper- 
parameters. Fig. 4 represents the topology of the KELM model. 

2.5. Random vector functional link (RVFL) 

Fig.  4  demonstrates  the  functional  structure  of  the  RVFL  model, 
which comprises the input layer neurons that have direct connections to 
the output layer to avoid the operation of the back-propagation process

Table 3 
Optimal hyperparameters obtained by the Bayesian optimization scheme asso-
ciated with the complementary models to -one and -three days ahead forecasting 
of the streamflow values.  

Station 

Model 

Horizon 

Hyperparameters 

t + 1 

t + 3 

t + 1 

t + 3 

t + 1 

t + 3 

t + 1 

t + 3 

t + 1 

t + 3 

t + 1 

t + 3 

t + 1 

t + 3 

t + 1 

t + 3

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
In this study, the Bayesian Optimization program was employed to optimize hyperparameters associated with machine learning algorithms. Unlike traditional methods like grid search or random search, Bayesian optimization offers a more efficient approach for hyperparameter tuning. By leveraging Bayesian optimization, the algorithm explores the hyperparameter space by choosing the subsequent set of hyperparameters to evaluate based on previous assessments. In this research, optimal hyperparameters were achieved through the application of the Bayesian optimization technique linked with various complementary models for one-day and three-days-ahead prediction of streamflow values. For instance, Table 3 displays the optimal hyperparameters acquired via the Bayesian optimization strategy connected with different complementary models for one-day and three-days-ahead projections of streamflow data.