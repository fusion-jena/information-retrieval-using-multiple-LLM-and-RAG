Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025817S. Ghosh et al.                                                                                                                                                                                                                                   

Table 4 
Search space of CNN hyperparameters to be explored.  

Hyperparameters 

Range 

Convolution Layers 
Filters 
Filter Size 
Number of Neuron 
Batch Size 
Epochs 
CNN Model Optimizer 

Lower limit = 1 and Upper limit = 10 
Lower limit = 1 and Upper limit = 64 
Lower limit = 1 and Upper limit = 10 
Lower limit = 32 and Upper limit = 1024 
Lower limit = 8 and Upper limit = 512 
Lower limit = 1 and Upper limit = 25 
ADAM, SGD, RMSProp, Adadelta, Adagrad, Adamax

hyperparameters.  The  hyperparameters  with  the  current  results  are 
saved until better accuracy is achieved. The termination criterion of the 
proposed approach is the maximum number of iterations to be executed. 
After the completion of the iterations, the proposed approach provides 
us with the best hyperparameters, thus evolving the near-optimal CNN. 
The  overall  complexity  is  dominated  by  the  iterations,  “TC”,  and 
within  each  iteration,  the  operations  depend  on  the  population  size 
“NP”.  Therefore,  the  total  complexity  can  be  approximated  as 
O(TC*NP).

71.17% 

98.7% 

Ganguly et al., 2022b) 

DDYOLOv5 and ResNet-50 (Hu et al., 

Pine tree classification 

98.71% 

2022) 

Deep Attention Dense CNN model ( 

Pandey and Jain, 2022b) 

Dense convolutional neural networks 

Plant leaf disease 
classification 
Plant disease classification 

97.33% 

99.1% 

() 

Proposed Approach 

Plant leaf classification 

98.97  

6.1.2. CVIP100 dataset

Data augmentation was used to collect all possible cases. For data 
augmentation,  we  implemented  Kera’s  flow_from_directory  method 
during the learning phase of the CNN. The applied data augmentation 
techniques used for plant image classification include random rotation, 
random cropping, random flipping, random color jittering, and random 
noise addition. This ensures that we have covered all the possible cases 
that might occur in the real world. 

6.2. Experiment setup

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What strategies are employed to handle randomness in the deep learning pipeline (e.g., random seed value)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the authors employ several strategies to handle randomness in their deep learning pipeline. One such strategy is using a search space of hyperparameters, which includes parameters like filters, filter size, number of neurons, batch size, epochs, and CNN model optimizers. By exploring this search space, they aim to find the optimal set of hyperparameters that yield the highest accuracy.

Additionally, the authors use data augmentation techniques to ensure that they cover all possible cases that may occur in the real world. These techniques include random rotation, random cropping, random flipping, random color jittering, and random noise addition. By applying these techniques during the learning phase of the CNN, they increase the diversity of the training data and reduce overfitting.

However, there is no explicit mention of how the authors handle randomness related to the initial seed value or other sources of randomness in the deep learning pipeline. It is common practice in deep learning to fix the seed value to ensure reproducibility of experiments, but this aspect is not discussed in the provided context.