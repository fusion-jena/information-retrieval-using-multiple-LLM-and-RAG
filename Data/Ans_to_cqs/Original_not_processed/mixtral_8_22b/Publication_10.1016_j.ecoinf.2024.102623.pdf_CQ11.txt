Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

vancements in deep learning to enhance performance. Specifically, our 
MLP architecture consists of four layers, each containing 512 neurons 
and connected with residual connections (He et al., 2016). We employ 
batch normalization (Ioffe and Szegedy, 2015) and the Rectified Linear 
Unit (ReLU) activation function in all layers except the final one, where 
instead a sigmoid function is used to enable multi-label classification. 
The model is trained with a batch size of 256 for 30 epochs using the 
AdamW optimizer (Loshchilov and Hutter, 2017). Both the weight decay 
and learning rate are set to 0.0001. Additionally, we employ a learning 
rate scheduler with exponential decay of 0.95, and introduce dropout

Cambridge University Press. 

Gorishniy, Y., Rubachev, I., Khrulkov, V., Babenko, A., 2021. Revisiting deep learning 

models for tabular data. Adv. Neural Inf. Proces. Syst. 34, 18932–18943. 
Grinsztajn, L., Oyallon, E., Varoquaux, G., 2022. Why do tree-based models still 

outperform deep learning on typical tabular data?. In: In Thirty-sixth Conference on 
Neural Information Processing Systems Datasets and Benchmarks Track. 
Guisan, A., Tingley, R., Baumgartner, J.B., Naujokaitis-Lewis, I., Sutcliffe, P.R., 

Tulloch, A.I., Regan, T.J., Brotons, L., McDonald-Madden, E., Mantyka-Pringle, C., 
et al., 2013. Predicting species distributions for conservation decisions. Ecol. Lett. 16 
(12), 1424–1435. 

EcologicalInformatics81(2024)10262313R. Zbinden et al.

methods have shown significant advancements when applied to large 
datasets, often outperforming traditional machine learning techniques 
in various fields (Brown et al., 2020; Christin et al., 2019; Jumper et al., 
2021; Krizhevsky et al., 2012). A distinctive advantage of deep learning 
approaches lies in their inherent flexibility, enabling the simultaneous 
integration of diverse data types and the modeling of multiple species, a 
capability  that  is  increasingly  vital  in  ecological  research.  Recent 
research emphasizes the potential of deep learning methods in SDMs, 
showing performance that matches or exceeds traditional techniques. In 
particular, this improvement seems to extend to both presence-absence 
(Chen et al., 2016; Teng et al., 2023) and presence-only datasets (Botella 
et al., 2023; Deneu et al., 2021).

In  the  field  of  machine  learning,  training  a  model  often  involves 
minimizing a loss function that quantifies the model’s error on training 
data. Generally, deep learning-based SDMs are trained with the binary 
cross-entropy loss (Benkendorf and Hawkins, 2020; Deneu et al., 2021; 
Zbinden et al., 2023; Zhang et al., 2022), with the target-group back-
ground points often used as the de facto negative samples when absence 
data is unavailable. Nevertheless, the loss function can be modified to 
reflect the specificities of the problem. In our case, we can adapt the loss 
function to inform the model about how pseudo-absences are integrated. 
This can be achieved by adjusting or assigning weights to the different 
components of the loss function. Recently, Cole et al. (2023) introduced 
the  following  full  assume  negative  loss,  designed  to  account  for  both 
target-group background points and random background points: 

⎡

L full(y, ̂y) = (cid:0) 1
S

∑S

s=1

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, based on the given information, there is no explicit mention of a data repository link for the deep learning pipeline. The text discusses the methodology, architecture, and training process of the deep learning model but does not provide any direct reference to a specific data repository. Therefore, without additional context or information, it is impossible to determine the exact data repository link for the deep learning pipeline mentioned in the text.