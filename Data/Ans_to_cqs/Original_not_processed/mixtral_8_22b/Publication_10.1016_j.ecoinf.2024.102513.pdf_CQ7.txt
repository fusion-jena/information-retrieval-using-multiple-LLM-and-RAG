Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

2.7. Training configuration 

The calculations were performed on an ASUS laptop with an Intel i7- 
11370H CPU (4 cores, 3.30 GHz), 16 GB DDR4 memory, and an NVIDIA 
GeForce RTX 3050 graphics card (4 GB). The dataset for each period was 
divided into training, testing, and validation sets in a ratio of 70:20:10, 
respectively. 

2.8. Classification accuracy 

The accuracy calculation was performed for each model trained on 
the corresponding period and was computed using the sklearn library for 

Table 2 
List of spectral indices used in the study.  

Name 

Normalized Difference Vegetation 

Index (NDVI) 

Normalized Difference Built-up 

Index (NDBI) 

Green-Red Vegetation Index (GRVI) 

Built-up Index (BU) 

Normalized Difference Water Index 

(NDWI) 

Calculation 
Formula 

Nir (cid:0) Red
Nir + Red 
SWIR (cid:0) Nir
SWIR (cid:0) Nir 
Green (cid:0) Red
Green + Red 
NDBI (cid:0) NDVI 

Green (cid:0) Nir
Green + Nir  

Reference 

(Huang et al., 2021) 

(Zha et al., 2003)

of deep learning, a neural network was meticulously trained using these 
datasets.  This  training  process  was  pivotal  in  developing  a  classifier 
capable of accurately identifying various land cover forms based on their 
spectral signatures. 

2.2. Conducting LULC analysis using deep neural network

(

âˆ‘n

zi = f

wjxj + bi

(2)  

j=1

where  zi  is  the  output  value  of  the  i-th  neuron,  wj  is  the  convolution 
weight for input value xj, bi  is the bias, and f is the activation function. 
The  Pooling  Layer  performs  data  downsampling,  reducing  dimen-
sionality and extracting essential features. The most common pooling 
method is max pooling, which selects the maximum value from a region 
of  input  data.  Pooling  helps  reduce  the  number  of  parameters  and 
computations,  enhances  invariance  to  small  shifts  and  scale  changes, 
and improves the model's generalization ability.

EcologicalInformatics80(2024)1025135D. Krivoguz                                                                                                                                                                                                                                       

Fig. 4. Temporal distribution of minimum, average and maximum levels of precipitation on Kerch Peninsula from 1990 to 2019.  

2.3. Performing LULC analysis using a deep convolutional neural network 

The  classification  of  LULC  was  carried  out  using  a  convolutional 
neural network (CNN). Convolutional Neural Networks (CNNs) are an 
architecture of deep neural networks widely applied for land use and 
land cover (LULC) classification (Balarabe and Jordanov, 2021; Li et al., 
2019;  Zaabar  et  al.,  2022).  They  are  specifically  designed  for  image 
processing  and  possess  the  capability  to  automatically  extract  spatial 
hierarchical features from data.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Answer: The dataset for each period was divided into training, testing, and validation sets in a ratio of 70:20:10, respectively. This means that 70% of the data was used for training the deep learning models, while 20% was used for testing and 10% for validation purposes. These ratios are commonly used in machine learning and deep learning applications to ensure that the models can learn effectively from the data without overfitting or underfitting. Overfitting occurs when the model becomes too complex and starts fitting noise instead of actual patterns in the data, leading to poor performance on new, unseen data. Underfitting happens when the model is not complex enough to capture the underlying patterns in the data, resulting in low accuracy even on the training set. By splitting the data into separate subsets for training, testing, and validation, we can evaluate the model's performance objectively and fine-tune it accordingly.