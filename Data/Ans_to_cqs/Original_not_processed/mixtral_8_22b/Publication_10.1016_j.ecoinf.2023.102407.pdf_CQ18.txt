Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

within the study area for MaxEnt and set up the hyperparameters as in 
Bean et al. (2012). The training settings and hyperparameters used for 
each SDM are described in Table 3.

SDM 

Training setup 

Modeling package 

threshold values from 0 to 1. Table 5 summarizes the evaluation criteria 
for the AUC and TSS metrics for the objective comparison of the per-
formances of the SDMs. 

Elapid (Anderson, 2023) 

3. Results 

SRE 

GLM 

GAM 

MaxEnt 

RF 

GBM 

XGB 

LGBM 

ANN 

SDP- 

EPL

The proposed incremental PL was also investigated in terms of AUC 
in Section 3.3. Although Figs. 4, 5, and 6 show different shapes of per-
formance  curves,  it  can  be  seen  that  incremental  PL  contributes  to 
effective training of the student model. In addition, the results showed 
that the degree to which model performance improves varies depending 
on K, and in general, model performance improves more when K is in the 
50 to 400 range rather than in the 600 to 800 range. This suggests that 
allowing the initial teacher model to generate too many pseudo-labeled 
data  points  adversely  affects  the  subsequent  training  of  the  teacher 
model, producing inaccurate student models. Therefore, the number of 
data points added in each PL iteration should be determined carefully to 
ensure the accuracy of SDP-EPL, and K = 200 performed optimally for 
most cases in our study.

EcologicalInformatics79(2024)1024075Output: Trained student model1:Initialize DTwithDL// DTrepresents a training set2:Train the ensemble teacher model with DL3:For j= 1 to Ndo4:Ifj% 100 = 0 then5:Sample maximum 10,000 unlabeled data DSfrom DU6:Predict yiusing the teacher model for DS7:Choose an equal no. of present/absence labels from the predicted labels8:Add the chosen presence/absence datato DT9:Remove the chosen presence/absence datafrom DU10:Initialize and train the teacher model with DT11:Train the student model with DT12:End forModel 1: RFModel 2: GBMModel M: XGBEnsemble teacher model(1) TrainLabeled data pointsModel: ANNStudent model(5) Add(7) Train(2) Sample(3) PredictUnlabeled data pointsSelected data points(6) Init & TrainLabeled data pointsPseudo labeled data pointsPseudo-labeled data points(4) Data selection: presence data: absence dataE. Kim et al.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the strategy implemented to monitor the model performance during training?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the given information, the authors use two main strategies to evaluate the performance of their models during training: Area Under Curve (AUC) and True Skill Statistic (TSS). These metrics are commonly used in machine learning to assess the quality of binary classifiers.

To compare the performances of various Species Distribution Models (SDMs), they employ these evaluation criteria objectively. They mention using threshold values ranging from 0 to 1, but do not provide specific details about how these thresholds were applied or selected.

Furthermore, the authors investigate the impact of incremental Pseudo Labeling (PL) on the effectiveness of training the student model. They observe that the improvement in model performance depends on the value of 'K', which represents the number of data points generated by the initial teacher model. Their findings suggest that setting 'K' between 50 and 400 generally leads to better improvements in model performance compared to higher ranges like 600 to 800.

However, the authors note that allowing the initial teacher model to produce excessive amounts of pseudo-labeled data negatively impacts the subsequent training of the teacher model, resulting in inaccurate student models. Consequently, they recommend careful consideration when determining the number of data points added in each PL iteration to ensure the accuracy of SDP-EPL. In their study, they found that 'K = 200' yielded optimal results for most cases.

Overall, while the authors discuss monitoring model performance through AUC and TSS metrics, they primarily focus on evaluating the effect of incremental PL on improving the student model's training process.