Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, 
R. (2014). Dropout: A simple way to prevent neural networks from 
overfitting.  Journal  of  Machine  Learning  Research,  15,  1929–1958. 
https://doi.org/10.1214/12-AOS1000

Swanson, A., Kosmala, M., Lintott, C., Simpson, R., Smith, A., & Packer, C. 
(2015).  Snapshot  Serengeti,  high- frequency  annotated  camera  trap 
images  of  40  mammalian  species  in  an  African  savanna.  Scientific 
Data, 2, 150026. https://doi.org/10.1038/sdata.2015.26

Swinnen,  K.  R.  R.,  Reijniers,  J.,  Breno,  M.,  &  Leirs,  H.  (2014).  A  novel 
method  to  reduce  time  investment  when  processing  videos  from 
camera trap studies. PLoS ONE, 9, e98881. https://doi.org/10.1371/
journal.pone.0098881

http://orcid.org/0000-0002-2176-7935 

R E F E R E N C E S

Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., … Kudlur, M. 
(2016). TensorFlow: A system for large- scale machine learning. OSDI, 
16, 265–283.

Anderson, T. M., White, S., Davis, B., Erhardt, R., Palmer, M., Swanson, A., 
… Packer, C. (2016). The spatial distribution of African savannah her-
bivores: Species associations and habitat occupancy in a landscape 
context.  Philosophical  Transactions  of  the  Royal  Society  B:  Biological 
Sciences, 371, 20150314. https://doi.org/10.1098/rstb.2015.0314
Babaee,  M.,  Dinh,  D.  T.,  &  Rigoll,  G.  (2017).  A  deep  convolutional  neu-
ral  network  for  background  subtraction.  Pattern  Recognition,  76, 
635–649.

classes. Dropout is a form of regularisation that randomly removes 

a  proportion  of  nodes  to  reduce  overfitting  (Srivastava,  Hinton, 

Krizhevsky, Sutskever, & Salakhutdinov, 2014). The fully connected 

layer reduces the vector of image features to the desired dimension-

ality of length two (foreground and background). The softmax layer 

normalises  this  vector  into  probabilities  that  sum  to  one  across  all 

classes.  DeepMeerkat  is  designed  to  be  conservative,  with  a  high 

threshold for retaining frames (acceptance value = 0.1). This means 

that the model must be more than 90% confident that a frame does 

not contain a foreground object to assign a background label. This 

prioritises minimising false negatives at the potential expense of in-

Methods in Ecology and Evolu(cid:13)on

    |  1437

download  for  Mac  and  Windows  with  the  pre- trained  humming-

bird model. In addition, I provide reproducible scripts for local and 

3 |  R E S U LT S

Google  cloud  environments  to  allow  users  to  train  new  models, 

which can then be used in the local software.

2.2 | Test dataset

Feature  extraction  of  the  fixed  inception  layers  completed  in  1 hr 

and  26 min  on  15  CPUs.  Training  of  the  new  layers  completed  in 

27 min on a single CPU. Model evaluation on the 70 test videos com-

pleted in 4 hr and 38 min on 30 CPUs with an average frame rate of 

My  collaborators  and  I  have  been  studying  hummingbird  ecol-

17 frames/s. On average, a video contained  545.84 candidate  mo-

ogy  using  time- lapse  cameras  in  the  Ecuadorian  Andes  since  2013 

tion frames (2.5% of total frames) that were sent for classification by 

(Weinstein & Graham, 2017). Cameras turn on at dawn, off at dusk,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The context provided does not explicitly state the specific criteria used to determine when training is complete in the given study or method. However, common practices in machine learning include monitoring metrics such as validation loss, accuracy, or other performance indicators during training. When these metrics reach a plateau or stop improving significantly, it may indicate that further training will not yield substantial improvements, suggesting that training could be considered complete. It is also possible to use early stopping techniques, where training is halted if the monitored metric stops improving after a certain number of epochs. Without explicit information regarding the criteria used in this particular case, we can only infer based on general machine learning practices.