Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

10 

10 

10 

10 

9 

9 

9 

8 

8 

7 

6 

0.0080 

0.0066 
0.0052 

0.0037 

0.0029 

0.0026 

0.0025 

0.0040 

0.0026 

0.0026 

0.0023 

0.0021 

0.0033 

0.0029 

Silicate at 50 m 

10 

0.0047 

Oxygen concentration 
integrated at 50 m 

Salinity at 50 m 

Thermocline intensity 
Surface oxygen 
concentration 

Temperature at 100 m 
Silicate at 100 m 
Chlorophyll fronts 

Chlorophyll concentration 
integrated at 50 m 
Oxygen concentration 
integrated at 50 m 
Oxygen concentration 
integrated at 125 m 
Sea level anomaly 

10 

0.0042 

10 

10 

0.0038 

0.0028 

9 

9 
9 
7 

0.0059 

Thermocline intensity 

0.0051          
0.0051          
0.0034           

9 

9 

9 

8 

7 

0.0069       

0.0055       

0.0046       

0.0056       

0.0019       

Table 4 
Mean  accuracies  and  their  standard  deviations  after  the  5  × 10-fold  cross- 
validation of each model.   

Random Forest 

SMO 

Multilayer 

Perceptron 
Naïve Bayes 

SKJ 

YFT 

BET 

FAL

YFT 

BET 

FAL 

F 

SUS 

Predictor 

F 

SUS 

Predictor 

F 

SUS 

Predictor 

F 

SUS 

SKJ 

Predictor 

SST 

Temperature at 50 m 
Month 
Temperature gradient at 

200 m 

Chlorophyll concentration 

integrated at 20 m 

Nitrate at 50 m 

Phosphate at 50 m 

10 

10 
10 

10 

10 

10 

10 

0.0078 

0.0078 
0.0075 

Oxygen concentration 
integrated at 10 m 
Temperature at 50 m 
Nitrate at 50 m 

0.0071 

Surface phosphate 

0.0069  Month 

0.0067 

Nitrate at 20 m 

0.0064 

SST 

10 

10 
10 

10 

10 

10 

10 

0.0080 

Silicate at 150 m 

0.0079 
0.0078 

Salinity at 50 m 
Temperature at 50 m 

0.0075 

SST 

0.0069 

Nitrate at 100 m 

0.0056 

0.0055 

Salinity at 200 m 
Oxygen concentration 
integrated at 50 m 
Oxygen concentration 
integrated at 175 m 

Nitrate at 20 m 

10 

0.0064 

Temperature at 150 m 

10 

0.0051 

Temperature gradient at 

150 m 

10 

0.0061 

Phosphate at 175 m 

10 

0.0050 

Phosphate at 10 m 

Sea level anomaly 

10 

0.0061 

Longitude

EcologicalInformatics81(2024)1025773N. Goikoetxea et al.                                                                                                                                                                                                                            

Fig. 1. Diagram of the model building process.  

Table 2 
Number of instances of each species and class.   

HIGH 
LOW 
ABS 

SKJ 

6307 
6533 
6300 

YFT 

5234 
5831 
5200  

BET 

3395 
3447 

FAL 

8929 

6704  

kept.  To  apply  both  the  CFS  cross-validation  and  SUS,  their  imple-
mentation in Weka (Frank et al., 2016) has been used. 

In the third step, a supervised classification model is trained with the 
selected variables. Four different methods, widely used in species dis-
tribution modelling, have been tried to build the classification model:  

• Random Forest (Breiman, 2001): Classifier that combines the output 

of multiple decision trees to reach a single result.

3.2. Performance of the models and forecast distribution 

The  mean  accuracies  and  standard  deviations  of  the  5  × 10-fold 
cross-validations  for  each  method  and  species  are  shown  in  Table  4. 
Random Forest is the method that achieves the highest accuracy for all 
the analysed species (0.718 for SKJ, 0.728 for YFT, 0.589 for BET and 
0.842 for FAL). Consequently, this is the method that has been used to 
build the prediction models. 

A  model  has  been  trained  for  each  species,  by  using  the  selected 
variables in Table 3. Then, for each model, the probabilities of finding 
high and low catches and absences of each species in the study area have 
been predicted by using the corresponding predictors given in Table 3. 
The results of the validation of the trained models are shown in Table 5,

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the postprocessing steps involved after the model training (e.g., Saliency maps, Metrics calculation, Confusion matrix)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer: After the model training, there are several postprocessing steps that can be taken depending on the specific requirements of the project or analysis. Some common postprocessing steps include calculating metrics such as accuracy, precision, recall, and F1 score to evaluate the performance of the model. Another common step is creating confusion matrices to visualize the performance of the model in terms of true positives, false positives, true negatives, and false negatives. Additionally, saliency maps can also be generated to highlight the most important features or inputs that contribute to the predictions made by the model. However, it should be noted that these postprocessing steps may vary based on the type of machine learning algorithm used and the specific goals of the project. In summary, some possible postprocessing steps after model training could include calculating metrics, generating confusion matrices, and creating saliency maps.