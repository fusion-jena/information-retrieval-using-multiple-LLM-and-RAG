Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

was analysed using various evaluation matrices. During model training, 
the input image size was set to 512 × 512 and the maximum batch size 
was limited to 4. To prevent underfitting, all models were ensured to 
follow back-propagation after accumulating the batch size 32 times. The 
models were trained using a stochastic gradient descent (SGD) optimizer 
with an initial learning rate of 0.01 and a cycle learning rate of 0.2, with 

EcologicalInformatics82(2024)1026917S. Kaukab et al.

EcologicalInformatics82(2024)1026916S. Kaukab et al.                                                                                                                                                                                                                                 

Fig. 9. Architecture of YOLOv5 with depth attention.  

Fig. 10. YOLOv5 components mechanism.  

method is compared and tested against other methods and fruits using 
different input modals and fusion techniques. 

3.1. Network training and hyper-parameters 

The impact of using multi-modal information on model performance

22, 5448. https://doi.org/10.3390/s22145448. 

Bechar, A., Vigneault, C., 2016. Agricultural robots for field operations: concepts and 

components. Biosyst. Eng. 149, 94–111. 

Capinha, C., Ceia-Hasse, A., Kramer, A., Meijer, C., 2021. Deep learning for supervised 

classification of temporal data in ecology. Ecol. Inform. 61. 

Chen, W., Zhang, J., Guo, B., Wei, Q., Zhu, Z., 2021. An apple detection method based on 
des-YOLO v4 algorithm for harvesting robots in complex environment. Math. Probl. 
Eng. 2021, 1–12.

3.2. Model evaluation 

Matrices  such  as  precision,  recall,  and  average  precision  (AP)  at 
various Intersections Over Union (IoU) thresholds were used to evaluate 
the performance of the models using Eqs. (4–6). The AP0.5, indicating 
average precision at 50% IoU, provided a more balanced reflection of 
the global detection performance of the model. The evaluation metrics 
for each model on the validation set were calculated after 300 epochs. 

Precision(P) =

True Positive
True Positive + False Positive

Recall(R) =

True Positive
True Positive + False Negative

Average Precision(AP) =

∫

x=1

x=0

Precision(Recall)d(Recall)

3.3. Performance on the test data 

(4)  

(5)  

(6)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it does not explicitly mention how the data was split for deep learning model training. However, typically, datasets are divided into three subsets: training, validation, and testing sets. This division allows us to assess the model's ability to generalize its predictions to unseen data accurately.

The training set is used to fit the parameters of the model, while the validation set helps tune the model's hyperparameters and prevents overfitting by providing feedback during the training process. Lastly, the testing set evaluates the final model's performance on completely new data.

Although the exact splitting ratios can vary depending on the dataset size and specific requirements, common practices include dividing the data into 60-80% for training, 10-20% for validation, and 10-20% for testing.

In this case, since the context mentions that the evaluation metrics for each model were calculated after 300 epochs on the validation set, we can infer that there must have been a separate validation set used for tuning the model during training.