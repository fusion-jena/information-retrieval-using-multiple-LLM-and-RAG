Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

(Reshef et al., 2011; Li et al., 2020). The MIC equation is as follows (Reshef et al., 2011): 

where  X,  Y  are  variables;  n  is  sample  size;  B(n)  is  the  parameter  to  set  the  size  of  the  grid;   

The RF method, first proposed by Breiman (2001), is a non-parametric method comprising a 

(Raschka and Mirjalili, 2019). 

2.2.2. Random Forest Analysis 

is  the  maximum  mutual  information  achievable  by  any  x×y  grid.  The  MIC 

method was implemented using the Minepy 1.2.6 (Albanese et al., 2013) library in Python 3.8.8 

Journal Pre-proof

class  of  learning  techniques  that  aim  to  improve  the  estimation  accuracy  through  the  mean 

response of an ensemble of simpler decision tree models (Breiman, 2001; Cao et al., 2020). The 

RF  algorithm  is  stronger  than  other  machine  learning  methods  due  to  its  ability  to  randomly 

receive training data from subsets and formulate decision trees (Panov and Džeroski, 2007). In this

with  the  testing  dataset  (Fig.  5  and Table S2). The RF  model  with  25  trees  as  hyper-parameters 

Journal Pre-proof

achieved the highest accuracy. In autumn, the optimized RF model included three input variables: 

EC, TN, and WZ. It displayed excellent performance with adj_R2 = 0.992, RMSE = 1.505, MAE = 

0.859, and KGE = 0.972 for the training data, and adj_R2 = 0.863, RMSE = 7.182, MAE = 3.598, 

and KGE = 0.824 for the testing data (Fig. 5 and Table S2). The winter RF model was optimized 

with two variables: WZ and WT. It demonstrated good performance with adj_R2 = 0.977, RMSE = 

0.620,  MAE  =  0.432,  and  KGE  =  0.938  for  training  data,  and  adj_R2 =  0.840,  RMSE  =  1.567, 

3.4. Relative Importance of Model Features 

season, the RF model with 25 trees as hyper-parameters achieved the highest accuracy. 

The selected predictor variables exerted different control (described as “Feature Importance”)

study,  the  dataset  was  randomly  divided  into  two  subsets,  the  first  one  was  used  as  a  training 

dataset  to  learn  the  optimal  model  structure  and  the  second  as  a  validation  dataset  to  test  its 

performance;  75%  of  the  data  were  devoted  to  model  training  and  25%  to  testing.  Given  the 

well-documented robustness of RF algorithms to randomly receive training data from subsets and 

establish models with high predictive capacity, we opted for random (instead of cluster) sampling 

with  one  major  condition  to  maintain  the  covariance  structure  among  the  predictor  variables 

relatively intact between the training and testing datasets. 

,(),,,(,)maxlogmin(,)xyBnIXYxyMICXYxy),,,(*yxYXI 
Journal Pre-proof

RF  modeling  can  generally  be  resilient  to  preprocessing  burdens  (e.g.,  no  feature  scaling, 

robustness  to  outliers),  flexible  with  multi-dimensional  data,  sensitive  in  elucidating  complex

the Nanji wetland of Poyang Lake.   

Fig.  3:  Maximal  Information  Coefficient  values  between  the  nine  environmental  covariates  and 

chlorophyll  a  concentrations  for  (a)  the entire  study  period,  using  eleven  time  lags  (0-10  days), 

and (b) each of the four seasons.     

Fig.  4:  Random  forest  performance,  as  measured  by  adj_R2,  RMSE,  MAE,  and  KGE,  with  the 

training and testing/validation datasets for different time lags. The gray columns and orange line 

represent  the  adj_R2  and  KGE  values,  while  the  blue  solid  and  dashed  lines  correspond  to  the 

RMSE and MAE values, respectively.   

Fig. 5: Predictions of Chl a concentrations by the optimal RF model per season. 

Fig. 6: Relative importance of the predictor variables included in the optimal random forest model 

Journal Pre-proof

Fig. 7: GAM analysis: Non-linear relationships between the two key influential factors and Chl a

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Based on the given context, it appears that the optimization of the hyperparameters for the Random Forest (RF) model was done by selecting the number of trees as the hyperparameter. However, the specific method used for optimizing this hyperparameter, such as grid search or random search, is not explicitly mentioned in the provided text. Therefore, based solely on the given context, I cannot provide a definitive answer regarding the exact method used for hyperparameter optimization.