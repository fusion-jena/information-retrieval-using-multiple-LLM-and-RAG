Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

libraries	 such	 as	 TensorFlow	 (Abadi	 et	al.,	 2016).	 Currently,	 the	

Raw count data are available from Enlighten: Research Data (https://

doi.org//10.5525/gla.researchdata.732).  Source  code  is  available 

from http://dx.doi.orgI10.5281/zenodo.2562058.

greatest challenge for implementing these algorithms for bespoke 

O R C I D 

applications is obtaining sufficiently large training datasets. In this 

regard,  citizen  scientists  have  a  clear  role  to  play.  While  we  have 

shown that the trained algorithm achieves high accuracy levels, it 

Colin J. Torney 

 https://orcid.org/0000-0003-1673-7835  

should  be  noted  that  the  algorithm  employed  the  crowd- sourced 

data  to  create  the  training  sets.  Hence,  both  methods  should  be 

R E F E R E N C E S

viewed  as  complementary  approaches  with  citizen  science  data 

forming the foundation for automated algorithms (Rey et al., 2017).

science counts of the survey and comparison to expert counts.

tee  that  the  approach  is  transferable  and  how  to  appropriately 

4 |  D I S CU S S I O N

filter the data may be affected by the wording of the guidelines, 

the image resolution and sizes used, or the set of volunteers that 

participate  in  the  project.  Other  more  sophisticated  approaches 

to processing citizen science data have been proposed (Swanson 

From our results, we see that both citizen science and deep learn-

et al., 2016); however, given the range of counts provided by the 

ing methods are capable of producing highly accurate image counts. 

volunteers  and  the  large  errors  we  observe  in  the  baseline  met-

Counting the wildebeest within the survey images is a difficult and 

rics  (c.  11%  and c.  9%  undercount  for  the  mean  and  median,  re-

time- consuming task. When collecting the census images, there are

you only look once, referring to the fact only a single pass through 

(Dill  &  MacCallum,  2012)  to  astronomy  (Lintott  et al.,  2008),  and 

the network is required.

appears to be growing as a tool for ecologists and conservationists 

(Ellwood,  Crimmins,  &  Miller- Rushing,  2017;  Swanson,  Kosmala, 

Lintott,  &  Packer,  2016),  where  it  has  the  major  advantage  of  not 

only  performing  scientific  analysis  of  data  but  also  engaging  the 

public  with  wildlife  conservation  (Forrester  et al.,  2017).  However, 

2 |  M ATE R I A L S A N D M E TH O DS

2.1 | Aerial surveys

despite the growth in the use and awareness of citizen science ap-

The  2015  Serengeti  wildebeest  count  was  conducted  between  23 

proaches, there is still some scepticism about the reliability of unpaid 

April	and	2	May	over	the	eastern	and	southern	plains	of	Serengeti	

and often anonymous volunteers (see (Kosmala, Wiggins, Swanson,

3.  Through  the  use  of  the  online  platform  Zooniverse,  we  collected  multiple  non-

expert counts by citizen scientists and used three different aggregation methods 

to  obtain  a  single  count  for  the  survey  images.  We  also  counted  the  images  by 

developing a bespoke deep learning method via the use of a convolutional neural 

network. The results of both approaches were then compared.

4.	 After	filtering	of	the	citizen	science	counts,	both	approaches	provided	highly	ac-

curate total estimates. The deep learning method was far faster and appears to be 

a more reliable and predictable approach; however, we note that citizen science 

volunteers played an important role when creating training data for the algorithm. 

Notably, our results show that accurate, species-specific, automated counting of 

aerial wildlife images is now possible.

K E Y W O R D S

citizen science, conservation, deep learning, monitoring, population ecology, surveys

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What is the data repository link of the deep learning pipeline (e.g., Link to Zenodo, Figshare, Dryad, GBIF)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Answer: The source code for the deep learning pipeline is available on Zenodo, which can be accessed using the following DOI: <http://dx.doi.org/10.5281/zenodo.2562058>.