Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

EcologicalInformatics81(2024)1025802R.K. James et al.                                                                                                                                                                                                                                

Fig. 1. Workflow used to (a) select a deep learning model, (b) develop a ground-truth imagery dataset, (c) train the deep learning models, (d & e) evaluate model 
performance and (f & g) obtain the data and analyse it to quantify the spatial patterns and resilience of the ecosystem. 

2.3. Deep learning models 

2.3.1. Semantic segmentation for vegetation mapping

training, which helped to reduce human error. Similar to the seagrass 
semantic  segmentation  model,  the  resolution  of  the  images  in  the 
ground-truth dataset was reduced to 1000 × 1333, and the three colour 
channels of the images were normalised by subtracting the means and 
dividing  by  the  standard  deviations  per  channel.  The  colour  channel 
means and standard deviations were based on the ImageNet dataset used 
in the training of the (pre-trained) RestNet-50 (the used mean values 
were [0.485, 0.456, 0.406], and the standard deviations were [0.229, 
0.224, 0.225]). The DETR model’s object queries parameter was set to 
100, allowing for the detection of up to 100 turtles in an image, which 
was sufficient for all case-study images.

The ground-truth dataset was divided randomly into training (80%), 
validation (10%), and test (10%) sets (Fig. 1), this division of the im-
agery allowed for a good-sized validation and test dataset for evaluating 
the  model’s  accuracy,  while  maximizing  the  training  set.  During  the 
training process, each image was subset and cropped into 6 overlapping 
patches  matching  the  output  size  of  the  network  (388  × 388  pixels), 
resulting  in  a  total  training  set  size  of  379  images.  In  addition,  data 

EcologicalInformatics81(2024)1025803R.K. James et al.

3.1. Success of deep learning models 

The  semantic  segmentation  model  used  to  identify  the  substrate 
types  achieved  an  accuracy  of  92%.  The  precision  for  the  vegetation 
class was 0.90, for the bare class was 0.96, and for the ‘other’ class was 
0.50 when evaluating the model against the test dataset. The recall of 
the model (the number of instances in which the model correctly iden-
tified the pixels out of the total number of pixels in that class) reached 
0.97 for vegetation, 0.87 for bare substrate and the ‘other’ class reached 
a recall of 0.53.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the criteria used to split the data for deep learning model training (e.g., train, test, validation)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The ground-truth dataset was divided randomly into training (80%), validation (10%), and test (10%) sets. This division of the imagery allowed for a good-sized validation and test dataset for evaluating the model’s accuracy, while maximizing the training set. Each image was subset and cropped into six overlapping patches matching the output size of the network (388 x 388 pixels). As a result, the total training set size was 379 images.