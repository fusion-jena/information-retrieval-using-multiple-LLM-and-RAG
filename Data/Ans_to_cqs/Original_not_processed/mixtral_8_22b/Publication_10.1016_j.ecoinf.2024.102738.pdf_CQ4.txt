Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Name

Inputs

Name

Inputs

Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 7
Dataset 8
Dataset 9
Dataset 10
Dataset 11
Dataset 12
Dataset 13
Dataset 14
Dataset 15
Dataset 16

Spectral bands (B)
Vegetation Indices (VI)
Soil Indices (SI)
Water Indices (WI)
Cluster (C)
B + VI
B + SI
B + WI
B + C
VI + SI
VI + WI
VI + C
SI + WI
SI + C
WI + C
B + VI + SI

Dataset 17
Dataset 18
Dataset 19
Dataset 20
Dataset 21
Dataset 22
Dataset 23
Dataset 24
Dataset 25
Dataset 26
Dataset 27
Dataset 28
Dataset 29
Dataset 30
Dataset 31

B + VI + WI
B + VI + C
B + SI + WI
B + SI + C
B + WI + C
VI + SI + WI
VI + SI + C
VI + WI + C
SI + WI + C
B + VI + SI + WI
B + VI + SI + C
B + VI + WI + C
B + SI + WI + C
VI + SI + WI + C
B + VI + SI + WI + C

Table 3
LULC classes based on CLC methodology.

Class

Description

Code

RGB color

Artificial surfaces

Agricultural areas

Forest

Scrub and/or
herbaceous
vegetation

Open spaces with
little or no
vegetation
Water bodies

A R T I C L E I N F O

A B S T R A C T

Keywords:
Fragmentation
LULC
Changes
Classification
Random Forest
Amazon
Forest

Taking into account Congalton (1991) and Hay (1979), who suggest
at least 50 pixels per thematic class, we decided to implement an
alternative strategy. Instead of strictly distributing 196 training areas
among the 6 thematic classes, we chose to include pure training areas.
These well-identified areas should contain at least 50 pixels in total and
prominently represent the class of interest. This distribution was carried
out through simplified random sampling (Chuvieco, 2020), allowing us
to effectively capture variability within each class and improve the

Table 1
Spectral indices calculated for each collection.

Index

NDVI
EVI
SAVI
BSI
MNDWI
NDMI

Formula

(NIR (cid:0) RED)/(NIR + RED)
C*[(NIR (cid:0) RED)/(NIR + C1*RED (cid:0) C2*BLUE + L) ]
[(NIR (cid:0) RED)/(NIR + RED + L) ]*1 + L
[(RED + SWIR) (cid:0) (NIR + BLUE) ]/[(RED + SWIR) + (NIR + BLUE) ]
(GREEN (cid:0) SWIR1)/(GREEN + SWIR1)
(NIR (cid:0) SWIR1)/(NIR + SWIR1)

Reference

2.3.4. Sampling size and validation areas

On this occasion, to define the training and testing samples, we relied
on Chuvieco (2020), who argues that for categorical variables, at least
196 test points should be considered. Furthermore, Chuvieco (2020),
also mentions that, at times, this number can be very small when
compared to the total number of pixels in the image. Therefore, we
explored new sampling strategies that combine the previous scientific
foundation with the current capabilities of GEE.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What are the data augmentation techniques applied in the deep learning pipeline (e.g., Fliping, Roating, Scaling)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not provide information about any specific data augmentation techniques used in a deep learning pipeline. The text discusses various datasets, spectral bands, vegetation indices, soil indices, water indices, clusters, and their combinations. It also describes the use of Random Forest classification and the implementation of an alternative strategy for defining training and testing samples. However, there is no mention of any data augmentation techniques such as flipping, rotating, scaling, etc.