Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

parameter values were selected based on the RMSEcv values (De San-
tana  et  al.,  2021).  SVM  was  performed  in  MATLAB  R2016a,  and  the 
training model was established by using the libsvm package in MATLAB.

SVMR is a kernel-based machine learning algorithm that originated 
in  statistical  theory  and  can  be  used  for  regression  and  classification 
(Cortes and Vapnik, 1995). The algorithm maps each covariate in the 
training set (sensitive bands filtered by the CARS algorithm) to a high- 
dimensional feature space by using a kernel function. Epsilon refers to 
an insensitive loss function that maps the maximum epsilon deviation of 
the independent data and the associated training data. Errors within the 
epsilon are ignored, whereas errors larger than the epsilon are penal-
ized. The epsilon-SVR model and Gaussian radial basis function (RBF) 
are  used  to  construct  the  calibration  model.  Epsilon-SVR  optimal  pa-
rameters (e.g., cost C, epsilon p, and gamma g) are used to make the 
model  achieve  the  best  accuracy,  where  parameters  C  and  p  help  us 
avoid overfitting of SVMR. For each parameter combination, the best

R/PLSR 

17 

SG/PLSR 

17 

400–401, 413, 450–451, 472–473, 543–548, 560, 600, 1838, 
2098, 2429 
400, 402, 413, 434, 496, 545–547, 602, 604, 1010, 
1083–1084, 1529–1531, 2279, 

SG-FD/ 
PLSR 
SG-SD/ 
PLSR 
SG-MSC/ 
PLSR 
SG-RL/ 
PLSR 

11 

406, 582, 719, 730, 874, 1077, 1381, 1940, 1980, 2185, 2317 

5 

15 

15 

416, 417, 479, 504, 530, 665, 666, 1129, 1275, 1999 

472–473, 475–476, 565–566, 603–604, 1008, 1153, 1754, 
1781, 2172, 2188, 2449 

400, 401, 403, 435, 449, 542–546, 601–603, 1932, 2194  

EcologicalInformatics79(2024)1024293M. Hou et al.                                                                                                                                                                                                                                    

Table 3 
Importance bands for TN estimation by PLSR.  

Model 

PC 

Important bands (nm) 

R/PLSR 

16 

SG/PLSR 

15

R/PLSR 

16 

SG/PLSR 

15 

409, 414–415, 564, 566, 567, 601, 1641, 2098, 2200, 2201, 
2307, 2340, 2373, 600, 602 
401, 496, 497, 498, 555, 556, 565–567, 569, 600–601, 2098, 
2342, 2361 

SG-FD/ 
PLSR 
SG-SD/ 
PLSR 
SG-MSC/ 
PLSR 
SG-RL/ 
PLSR 

9 

5 

18 

15 

598, 599, 693, 720, 874, 875, 1601, 1951, 2049 

788, 1653, 1687, 1822, 2046 

495–500, 566–568, 600–602, 1034, 1036–1037 1811, 2028, 
2422 
407, 496–498, 546, 565–566, 1735–1756, 1869, 1936, 2026, 
2304, 2399, 2425 

PC, Number of principal components. 

R2 = 1 (cid:0)

RMSE =

∑n
∑n

√

i=1( yi (cid:0) ̂yi )2
i=1( yi (cid:0) yi )2
̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅
∑n
1
( yi (cid:0) ̂yi )2
n

i=1

RPD =

SD
RMSE

RPIQ =

Q3 (cid:0) Q1
RMSE

(1)  

(2)  

(3)  

(4)  

where  yi  and  ̂yi  are  the  measured  and  predicted  values  of  sample  i, 
respectively; Q3 is the third quartile, Q1 is the first quartile and (Q3-Q1) 
is the interquartile range. 

3. Results 

3.1. Soil nutrient concentration analysis

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What criteria are used to determine when training is complete (e.g., validation loss plateau)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The paper does not explicitly state the specific criteria used to determine when training is complete. However, it mentions that the parameter values were selected based on the RMSEcv values, which suggests that cross-validation may have been used during the training process. In general, common criteria for determining when training is complete include reaching a minimum error threshold, achieving a stable validation loss or accuracy, or observing no further improvement in performance metrics after several iterations. Without more information from the authors, we cannot definitively say what criteria they used to determine when training was complete.