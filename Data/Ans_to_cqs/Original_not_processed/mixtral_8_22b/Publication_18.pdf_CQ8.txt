Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

trends. J. Exp. Mar. Biol. Ecol. 368, 1–8 (2009).

 54.  Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017).
 55.  Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016).
 56.  Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015).
 57.  Dodge, S. & Karam, L. Understanding how image quality affects deep neural networks. In 2016 Eighth International Conference on 

Quality of Multimedia Experience (QoMEX) 1–6, https://doi.org/10.1109/QoMEX.2016.7498955 (2016).

 58.  Kim, J., Lee, J. K. & Lee, K. M. Accurate Image Super-Resolution Using Very Deep Convolutional Networks. in Proc. CVPR IEEE 

1646–1654, https://doi.org/10.1109/CVPR.2016.182 (2016).

 59.  Tabik, S., Peralta, D., Herrera-Poyatos, A. & Herrera, F. A snapshot of image pre-processing for convolutional neural networks: case

1 2

www.nature.com/scientificreportswww.nature.com/scientificreports/

37.  LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015).
 38.  Yu, L. & Gong, P. Google Earth as a virtual globe tool for Earth science applications at the global scale: progress and perspectives. Int. 

J. Remote Sens. 33, 3966–3986 (2012).

Scientific RepoRtS  |         (2019) 9:14259  | https://doi.org/10.1038/s41598-019-50795-9

1 0

www.nature.com/scientificreportswww.nature.com/scientificreports/ 39.  Guirado, E., Tabik, S., Alcaraz-Segura, D., Cabello, J. & Herrera, F. Deep-learning Versus OBIA for Scattered Shrub Detection with 

Google Earth Imagery: Ziziphus lotus as Case Study. Remote Sens. 9, 1220 (2017).

 40.  Lecun, Y., Bottou, L., Bengio, Y. & Haffner, P. Gradient-based learning applied to document recognition. Proc. IEEE 86, 2278–2324 

(1998).

 41.  Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. & Wojna, Z. Rethinking the Inception Architecture for Computer Vision. In Proc. 

CVPR IEEE 2818–2826 (2016).

that provide good trade-off between accuracy, robustness and speed, such as, Faster-RCNN36, YOLO900043, 
FPN44, RefineDet45, DSSD46 and Focal Dense Object Detection47. Furthermore, several studies are focusing on 
improving these frameworks on specific remote sensing data48–51. In this work, we used Faster-RCNN36 based on 
Inception RenNet v2, as it is the most accurate detection framework according to the this study48.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Where is the code repository of the deep learning pipeline available (e.g., GitHub, GitLab, BitBucket)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The given context does not explicitly mention where the code repository of the deep learning pipeline is available. Therefore, I cannot provide a direct answer to the query. However, considering the nature of scientific research publications, it is common practice to share code repositories along with the publication or upon request from the authors. The best course of action would be to contact the corresponding author(s) of the paper to ask about the availability of the code repository.

If the article was published recently, there might also be a chance that the code repository has been made publicly available on platforms like GitHub, GitLab, or BitBucket. To find out if this is the case, one could look up the title of the article or the names of the authors on those platforms. But without more information, I can only suggest these possibilities rather than providing a definitive answer.