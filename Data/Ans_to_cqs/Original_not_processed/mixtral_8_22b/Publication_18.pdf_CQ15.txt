Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

trends. J. Exp. Mar. Biol. Ecol. 368, 1–8 (2009).

 54.  Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017).
 55.  Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016).
 56.  Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015).
 57.  Dodge, S. & Karam, L. Understanding how image quality affects deep neural networks. In 2016 Eighth International Conference on 

Quality of Multimedia Experience (QoMEX) 1–6, https://doi.org/10.1109/QoMEX.2016.7498955 (2016).

 58.  Kim, J., Lee, J. K. & Lee, K. M. Accurate Image Super-Resolution Using Very Deep Convolutional Networks. in Proc. CVPR IEEE 

1646–1654, https://doi.org/10.1109/CVPR.2016.182 (2016).

 59.  Tabik, S., Peralta, D., Herrera-Poyatos, A. & Herrera, F. A snapshot of image pre-processing for convolutional neural networks: case

CVPR IEEE 2818–2826 (2016).

 42.  Szegedy, C., Ioffe, S., Vanhoucke, V. & Alemi, A. Inception-v4, Inception-ResNet and the Impact of Residual Connections on 

Learning. ArXiv160207261 Cs (2016).

 43.  Redmon, J. & Farhadi, A. YOLO9000: Better, Faster, Stronger. In Proc. CVPR IEEE 7263–7271 (2017).
 44.  Lin, T.-Y. et al. Feature Pyramid Networks for Object Detection. in Proc. CVPR IEEE 2117–2125 (2017).
 45.  Zhang, S., Wen, L., Bian, X., Lei, Z. & Li, S. Z. Single-Shot Refinement Neural Network for Object Detection. in Proc. CVPR IEEE 

4203–4212 (2018).

 46.  Fu, C.-Y., Liu, W., Ranga, A., Tyagi, A. & Berg, A. C. DSSD: Deconvolutional Single Shot Detector. ArXiv170106659 Cs (2017).
 47.  Lin, T.-Y., Goyal, P., Girshick, R., He, K. & Dollár, P. Focal Loss for Dense Object Detection. ArXiv170802002 Cs (2017).
 48.  Zhang, X. et al. Geospatial Object Detection on High Resolution Remote Sensing Imagery Based on Double Multi-Scale Feature

Convolutional Neural Networks (CNNs) are a specialized type of neural networks capable of extracting spatial 
patterns from images. Their architecture is built by staking three main types of layers: (1) convolutional layer, 
which is used to extract features at different levels of the hierarchy, (2) pooling layer, which is essentially a reduc-
tion operation used to increase the abstraction level of the extracted features and (3) fully connected layer, which 
is used as a classifier at the end of the pipeline.

1

www.nature.com/scientificreportsnumber of annotated images to later make correct predictions on new images37. Although the construction of a 
dataset for training is costly, the learning of CNNs on small datasets can be boosted by data-augmentation, which 
consists of increasing the volume of the training dataset artificially, and additionally by transfer learning, which 
consists of starting the learning of the network from a prior knowledge rather from scratch38,39.

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "What optimization techniques are applied in the deep learning pipeline (e.g., SGD, Adam)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
The papers cited do not explicitly mention specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adam. However, it is common practice in deep learning pipelines to use these optimization algorithms during the training phase of Convolutional Neural Networks (CNNs). These optimization techniques help minimize the loss function and update the weights of the model accordingly. Both SGD and Adam are popular choices due to their efficiency and effectiveness in handling large-scale datasets. Other optimization techniques like RMSprop and Adagrad may also be employed depending on the specific requirements of the task at hand.