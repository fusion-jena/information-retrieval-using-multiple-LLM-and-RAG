Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Building  the  convolutional  neural  network.  Convolutional  neural  networks  (CNNs)  belong  to  the 
class  of  DLAs.  For  the  case  of  species  identification,  the  training  phase  is  supervised,  which  means  that  the 
classes  to  identify  are  pre-defined  by  human  experts  while  the  parameters  of  the  classifier  are  automatically 
optimized  in  order  to  accurately  classify  a  “training”   database24.  CNNs  are  composed  of  neurons,  which  are 
organized in layers. Each neuron of a layer computes an operation on the input data and transfers the extracted 
information to the neurons of the next layer. The specificity of CNNs is to build a descriptor for the input image 
data and the classifier at the same time, ensuring they are both optimized for each  other42. The neurons extract-
ing the characteristics from the input data in order to build the descriptors are called convolutional neurons, as

https ://arXiv .org/1712.04621 .

 42.  Goodfellow, I., Bengio, Y., Courville, A. & Bengio, Y. Deep Learning (MIT Press, Cambridge, 2016).
 43.  Abadi, M. et al. Tensorflow: A system for large-scale machine learning. OSDI 16, 265–283 (2016).
 44.  He, K., Zhang, X., Ren, S., & Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer 

Vision and Pattern Recognition 770–778 (2016).

 45.  Sarle, W. S. Stopped training and other remedies for overfitting. Computing Science and Statistics, 352–360 (1996).
 46.  Hintze, J. L. & Nelson, R. D. Violin plots: A box plot-density trace synergism. Am. Stat. 52(2), 181–184 (1998).
 47.  Catford, J. A., Bode, M. & Tilman, D. Introduced species that overcome life history tradeoffs can cause native extinctions. Nat. 

Commun. 9(1), 2131 (2018).

to calibrate Deep Learning models using a single parameter for all  classes35. This parameter is used, instead of 
the traditional softmax function, to convert the vector output from the neural network into a real probability.

The proposed post-processing was able to decrease the misclassification rate by at least 10.05%, for all goals, 
and 19.02% at most compared to the raw output of the Deep Learning model (Fig. 6b). The accuracy followed the 
same tendency, with an average accuracy for G1, G2 and G3 respectively equal to 0.74, 0.81 and 0.92 (Table 3).
Finally, we also performed the same experiment while switching T1 and T2 roles (Supplementary Tables S6, 
S7, S8). For each goal, the unsure classification rate was higher after the switch (+ 3.8% for G1, + 4.4% for G2, 
and + 8.9% for G3), implying lower scores were obtained in both correct classification (− 3.5%, − 5%, − 7.3%) and 
misclassification, with the exception of the 2nd goal (-0.2%, + 0.6%, − 1.6%).

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "Which hardware resources are used for training the deep learning model (e.g., GPUs, TPUs)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:
Unfortunately, there isn't enough information in the given context to determine what type of hardware resources were used for training the deep learning model. None of the references or citations mention any details about the hardware used during the training process. Therefore, it is not possible to provide a definitive answer based solely on this context.