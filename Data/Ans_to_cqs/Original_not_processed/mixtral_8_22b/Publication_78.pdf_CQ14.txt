Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

.

(3)

where (cid:107) ξi − ξ j (cid:107) provides the Euclidean distance between two samples. Width of Gaussian
kernel can be set by variance (cid:36) that controls the classiﬁer performance.

3.5. Confusion Matrix

It is the parameter to validate the performance of a machine learning model. It also
tells us the accomplishment of the classiﬁcation problem. Following are some of the
essential parameters of the confusion matrix.

1.
2.
3.
4.
5.

6.

7.

8.

9.

True Positive (TP): It is the accurate prediction of the bleached corals.
True Negative (TN): It is the accurate prediction of the unbleached corals.
False Positive (FP): It is the false prediction of the bleached corals.
False Negative (FN): It is the false prediction of the unbleached corals.
Sensitivity (TPR): It is the ratio of accurate prediction of the corals and can be given
by Equation (4).

Sensitivity

(TPR) =

TP
(TP + FN)

(4)

Sensitivity

(TPR) =

TP
(TP + FN)

(4)

Speciﬁcity (Sy): It is the ratio of the prediction of unbleached corals and can be given
by Equation (5).

Speci f icity =

TN
(TN + FP)

(5)

Accuracy: The ratio of correct prediction to the total number of instances can be given
by Equation (6).

Accuracy =

(TN + TP)
(FP + TP + FN + TN)

(6)

F1-score: It is the weighted mean of sensitivity and speciﬁcity and can be given by
Equation (7).

F1 − score =

∗ 2

(7)

(cid:21)

(cid:20) (TPR ∗ Sy)
(TPR + Sy)

Cohen’s Kappa (κ): κ gives us the amount of data by the execution of classiﬁer for the
examination of the its performance in case of some coincidence. It can be calculated
by Equation (8) [34].

(cid:20)

κ = 2 ∗

(TP ∗ TN − FP ∗ FN)
(TP + FP) ∗ (FP + TN) + (TP + FN) ∗ (FN + TN)

(cid:21)

(8)

3.6. Dataset

1. Randomly select ’o’ cluster centers.
2. Calculate the distance between feature and cluster centers.
3. Assign the feature to the cluster center whose distance from the cluster center is
minimum of all the cluster centers.
4. Recalculate the new cluster center using: Ci = ( 1
oi
where, (cid:48)o(cid:48)
5. Recalculate the distance between each feature and new obtained cluster centers.
6. If no feature was reassigned then stop, otherwise repeat from step 3.

i represents the number of features in ith cluster.

j=1 Fi)

∑oi

Algorithm 2: Silhouette Analysis.

For each sample
1. Compute the average distance from all features in the same cluster (αi)
2. Compute the average distance from all features in the closest cluster (βi)
3. Compute the co-efﬁcient: Sc = βi−αi
If Sc = 0 The sample is very close to the neighboring clusters.
If Sc = 1 The sample is far away from the neighboring clusters.
If Sc = −1 The sample is assigned to the wrong clusters.

max(αi,βi)

3.4. Classiﬁer

max(αi,βi)

3.4. Classiﬁer

The classiﬁer used is SVM [30–33]. It makes classiﬁcation of the objects and samples
by creating a hyperplane between the objects as depicted in Figure 7. To achieve higher
accuracy the margin is kept high. A high margin gives better accuracy. There are three
kernels of SVM. For binary classiﬁcation linear kernel of SVM proves efﬁcient while for
multi-class classiﬁcation Gaussian and polynomial kernel prove effective. The equations of
these kernels are Equations (1)–(3), respectively.

Figure 7. Demonstration of SVM.

κ(ξi, ξ j) = ξτ
i ξ j.
i ξ j)ρ.
κ(ξi, ξ j) = (1 + ξτ

(1)

(2)

Big Data Cogn. Comput. 2021, 5, 53

8 of 15

Here ξi and ξ j are used for calculating the dot products of both vectors, and are plotted

in a space of order ρ.

κ(ξi, ξ j) =

exp(− (cid:107) ξi − ξ j (cid:107)2)
2(cid:36)2

.

(3)

Question: %INSTRUCTIONS:
Use the provided pieces of context to answer the query in less than 400 words. If you don't know the answer, just say that you don't know, don't try to make up an answer.

%Query
Query: "How are the hyperparameters of the model optimized (e.g., grid search, random search)?"

Provide your answer as follows:

Answer:::
Answer: (provide your answer to query in less than 400 words)

Answer:::

Helpful Answer:

Based on the provided context, there isn't any explicit information about how the hyperparameters of the model were optimized, such as through methods like grid search or random search. However, it does mention that the width of the Gaussian kernel can be set by the variance, which controls the classifier performance. This implies that tuning the hyperparameters, including the variance, could have been done manually or through other optimization techniques not mentioned in this context. Therefore, without additional information, I cannot provide a specific method used for optimizing the hyperparameters of the model.