Based on the provided context, there is no direct mention of hyperparameters used in a deep learning model. The text mainly discusses the use of traditional machine learning algorithms, particularly the Random Forest (RF) classifier, for Land Use and Land Cover (LULC) mapping.

However, in general, deep learning models like Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs) have several hyperparameters that can be tuned for better performance. Some of these hyperparameters include:

1. Learning Rate: This is the step size at each iteration while moving toward a minimum of a loss function.
2. Optimizer: This is a method used to minimize the loss function. Examples include Stochastic Gradient Descent (SGD), Adagrad, Adadelta, and Adam.
3. Number of Epochs: This is the number of times the learning algorithm will work through the entire training dataset.
4. Batch Size: This is the number of training examples used in one iteration.
5. Number of Layers and Units: These are the architectural parameters of the model.

In the context of LULC mapping, Zhang et al. (2020) introduced a hexagonal random-sampling strategy along with a tile model to improve the accuracy of LULC mapping. However, they did not specify any deep learning models or their hyperparameters. 

Therefore, without additional information, it is not possible to provide the specific hyperparameters used in a deep learning model for LULC mapping in the context provided.