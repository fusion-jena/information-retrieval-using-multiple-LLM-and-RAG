Answer:

The strategy implemented to monitor the model performance during training involves a combination of automated data collection, human post-revision, and random splitting of data into training and validation sets. Initially, samples are collected using an automated method, followed by a careful check by human experts to ensure no mis-collected samples are present. This process takes advantage of the regular geometric shape and spatial patterns of citrus orchards to improve classification by human supervisors. A small number of samples are also collected through field surveying for visual assessment of classification performance.

After collecting the samples, each category (citrus and non-citrus) is randomly split into two groups for training and validation in a 60%-40% ratio, resulting in four collections: citrus-training, citrus-validation, non-citrus-training, and non-citrus-validation. The citrus class includes oranges and mandarin orchards, while the non-citrus class comprises all other land cover types.

The model's performance is monitored during the training phase by comparing the classifier's predictions against the actual classes of the validation samples. This comparison helps assess the classifier's ability to generalize from the training data to unseen data. The use of a separate validation set allows for an unbiased evaluation of the model's performance, as the training samples are not used in this assessment.

Additionally, the paper presents an analysis of point-wise vs. polygon-based sample selection strategies. While point-wise sampling may be faster and more efficient, it might not accurately represent the class proportions of the landscape. Polygon-based sampling, on the other hand, ensures a more representative distribution of classes but requires more time and resources. The authors suggest that analysts should consider the trade-offs between data quality and quantity when creating training data for remote sensing image classification.

In summary, the strategy to monitor the model performance during training involves a combination of automated data collection, human post-revision, and random splitting of data into training and validation sets. The authors also discuss the trade-offs between point-wise and polygon-based sampling strategies for creating training data.