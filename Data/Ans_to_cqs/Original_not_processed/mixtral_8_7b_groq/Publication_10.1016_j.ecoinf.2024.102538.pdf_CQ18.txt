Answer: The strategy implemented to monitor the model performance during training involves several hyperparameters and evaluation metrics. The model's performance was assessed using the mean reciprocal rank (MRR), accuracy (ACC), and hierarchical distance of a mistake (HDM). The MRR was used to evaluate the ranking of potential responses to a sample of queries, while accuracy determined the proportion of correctly classified items. The HDM quantified the degree of misclassification when only a single class could be predicted.

To monitor the model's performance during training, the learning rate was initially set at 0.001 and was subsequently reduced by a factor of 0.1 in a step-wise manner whenever the validation loss remained constant for five epochs. The minimum learning rate was not specified. The hyper-parameter λ in Eq. (4) was set to 0.8, and β in Eq. (6) was set to 0.4.

The model was trained over 200 epochs using the Adam optimizer with a weight decay of 1 × 10. The batch size was fixed at 16. The loss function was updated as per Eq. (6), but the specifics of the equation were not provided in the context.

Furthermore, the model's performance was evaluated on two datasets, BirdCLEF2018, and Lishui-Zhejiang Birdsdata, using the "stratified sampling" method. The datasets were divided into three exclusive groups: 80% for training, 10% for validation, and 10% for testing.

In summary, the strategy implemented to monitor the model performance during training involves using the MRR, ACC, and HDM evaluation metrics, adjusting the learning rate based on validation loss, and dividing the datasets into training, validation, and testing groups.