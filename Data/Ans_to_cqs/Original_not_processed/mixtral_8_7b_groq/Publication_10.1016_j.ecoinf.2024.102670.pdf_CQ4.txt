Answer:::

The provided context does not specifically mention the data augmentation techniques applied in the deep learning pipeline. Data augmentation techniques such as flipping, rotating, and scaling are commonly used in deep learning to increase the amount of training data, improve model performance, and prevent overfitting.

Flipping involves creating new training examples by horizontally or vertically flipping the original images. This technique helps the model to learn symmetrical features and improve its ability to generalize.

Rotating involves creating new training examples by rotating the original images by a certain angle. This technique helps the model to learn features that are invariant to rotation and improve its ability to generalize.

Scaling involves creating new training examples by resizing the original images. This technique helps the model to learn features that are invariant to scale and improve its ability to generalize.

In the context of Sharma et al. (2017), they used crowd-sourcing to obtain manual annotation for karyotyping images of chromosomes. They did not mention any data augmentation techniques used in their deep learning pipeline.

In the context of Guo et al. (2021), they extracted spherical patches around points of interest in the 3D volumetric images and used a deep learning-based model to classify the point of interest. They did not mention any data augmentation techniques used in their deep learning pipeline.

Therefore, based on the provided context, we cannot determine the data augmentation techniques applied in the deep learning pipeline.