I'm sorry for any confusion, but the context provided does not describe the use of a deep learning model. Instead, it discusses the use of Gradient Boosting Regression Trees (GBRT) and Generalized Additive Models (GAM) for regression analysis.

For the GBRT models, the tuned hyperparameters include the number of iterations, learning rate, and tree depth. The number of iterations was determined using early stopping to prevent overfitting. The learning rate, also known as a shrinkage parameter, determines the contribution of each tree to the model. The maximum tree depth, which reflects the degree of interaction in the model, is usually low for GBRT models.

Specifically, for the RI models, the learning rate was set to 0.05 and the maximum tree depth was set to 4 for both the CS and NW datasets. For the RY models, the best performing models had a slow learning rate of 0.005 and a shallow tree depth of 2 for the NW model.

For the GAM models, the context does not provide information on the specific hyperparameters used.

Therefore, I'm unable to provide the hyperparameters used in the deep learning model as it was not mentioned in the given context.