The provided context discusses several techniques used during the data preprocessing phase of a deep learning pipeline to ensure a proper and unbiased evaluation of the model. However, it does not explicitly mention the strategies of stratified splitting, oversampling, or undersampling to address data bias. Nevertheless, it does discuss a diverse data collection approach and data augmentation techniques that can help reduce bias and improve model performance.

Diverse data collection:
The context states that the data was collected from various sources and then split into training, validation, and test sets. By gathering data from different sources, it is more likely to capture a diverse range of scenarios, reducing the risk of bias towards specific patterns. This can help ensure that the model learns to handle a variety of situations and generalizes better to unseen data.

Data augmentation:
A three-step data augmentation procedure was applied to the images during training. This process included randomly flipping images horizontally, scaling the contrast of each image channel, and randomly cropping the image to a square. Data augmentation helps increase the size and diversity of the training set, reducing overfitting and the risk of bias towards specific patterns. By randomly applying these transformations, the model is exposed to a wider range of variations, which can help improve its ability to generalize to new, unseen data.

In summary, while the provided context does not explicitly mention stratified splitting, oversampling, or undersampling techniques to address data bias, it does discuss the importance of diverse data collection and data augmentation. These techniques can help reduce bias and improve model performance by exposing the model to a wider range of scenarios and variations during the training phase.