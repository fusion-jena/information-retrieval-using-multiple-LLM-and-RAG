Answer:::

The strategy implemented to monitor the model performance during training involves the use of TensorBoard, a set of visualization tools included in the TensorFlow open-source library. Specifically, for each optimization run, 3000 train iterations were conducted with a batch size of 25 individuals, resulting in a total batch size of 100 images. The model's performance was evaluated every 300 iterations, and the run that demonstrated the best performance was selected, as shown in Supplementary Fig. S3.

The optimization run consisted of tuning several parameters, including the learning rate, momentum, standard deviation threshold, and input size. The learning rate was set to 0.096, momentum was set to 0.845, the standard deviation threshold was set to 0.05, and the input size was optimized to (200, 250, 3). These parameters were selected based on the performance of multiple runs, and the set of parameters that resulted in the best validation accuracy was chosen.

The learning was performed using the Stochastic Gradient Descendent (SGD) method, which optimizes the learning rate and momentum parameters. Additionally, the algorithm was asked to exceed a certain threshold of variability in its predictions, i.e., the standard deviation of the predicted probabilities exceeds a certain threshold, to ensure that the output of the classifier is not almost the same for all images that feed the model.

The input image size was also optimized, considering the trade-off between the information provided by large resolutions and the number of weights of the network that need to be trained. The optimization of these parameters allowed the model to be trained within a day, enabling many iterations of Bayesian optimization and exploring multiple options for the tuning parameters in promising regions.

Overall, the strategy implemented to monitor the model performance during training involved the use of TensorBoard, optimizing various parameters, and evaluating the model's performance at regular intervals. This approach allowed for the selection of the best validation run and the optimization of the model's performance.