The provided context does not include information about the specific hardware resources used for training the deep learning model. It mainly focuses on the methodology and data analysis of a study related to principal component analysis (PCA) and functional data analysis (FDA).

However, it can be inferred that the computations were performed on a system capable of running complex mathematical operations, including calculating eigenvalues and eigenvectors, matrix operations, and functional data analysis. This implies that the system likely had a powerful CPU and possibly one or more GPUs or TPUs to accelerate the computations.

In general, deep learning models require substantial computational resources, and GPUs or TPUs are commonly used to train these models due to their ability to perform parallel computations efficiently. However, without specific information in the provided context, it is not possible to give a definitive answer.