Answer: The strategy implemented to monitor the model performance during training involved several steps. First, the dataset was split into training and testing sets, with 20% used for testing and the remaining 80% for training. Of the 80% training set, 10% was used as a validation subset. To reduce bias, samples were likely separated for training, testing, and validation, with a maximum of three samples extracted per file in the semi-automatic labeling stage.

The model underwent an iterative learning process with 50 training epochs, using the early stopping method with a patience of 5 to avoid overfitting. The optimal training was achieved at the end of the ninth epoch, with a maximum loss of 3 for the training and validation subsets, respectively.

To evaluate the model's performance, the multiclass predictions were assessed using typical indicator series, including true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). The prediction depended on a decision threshold θ to define it as positive (presence) or negative (absence). The precision P and recall R relationships were obtained using these θ-dependent elemental indicators.

The model's predictive performance in the testing dataset was evaluated by plotting the P-R curves of all classes on the same graph. The points closest to the coordinate (1, 1) corresponded to the best performance in the prediction, with the threshold θ associated with that point. The observed performance was ideal in the Scytalopus magellanicus class and very close to ideal in a majority group of classes. Classes far from the ideal, such as Glaucidium nana (a) and Glaucidium nana (b), suggested three likely sources of conflict: inconsistency between real and simulated samples, less relative differentiation between classes belonging to the same species, and, in the case of G. nana (a), a gap in the data.

The UMAP technique was used to reveal the variety and clustering of the representative samples in both feature spaces (STFT and FCT), which allowed for a prediction of separability in a supervised learning process. However, considering the high dimensionality of the hyper-vectors extracted with FCT and the longer processing time, the creation of spectrograms for the training stage was calculated with STFT only.

In summary, the strategy to monitor the model performance during training involved splitting the dataset into training and testing sets, using a validation subset, implementing early stopping to avoid overfitting, and evaluating the model's performance using precision and recall relationships. The P-R curves were plotted to assess the model's predictive performance in the testing dataset, and the UMAP technique was used to reveal the variety and clustering of the representative samples.