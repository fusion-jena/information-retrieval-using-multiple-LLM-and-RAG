Answer:::

The criteria used to determine when training of a Convolutional Neural Network (CNN) is complete is based on the performance of the CNN on the training set and the validation set. Specifically, the training process is stopped when the performance on the validation set starts to diverge from the performance on the training set. This is because it indicates that the CNN is overfitting to the training set and becoming more specialized at predicting it, while becoming less able to predict the validation set, which is new data that the CNN has not seen before. This is referred to as the point where the CNN has reached its optimum number of iterations.

In the study, the training of the CNN took approximately 18 hours to complete 6000 iterations. The accuracy of the different CNNs and the effect of different confidence thresholds were measured and took several hours, but this process could be further automated. Predictions on the 58,148 images took approximately 10 hours. However, it is important to note that the duration of the training and prediction phases is largely dependent on the hardware used and may vary between users. Overall, the whole pipeline could be completed within one or two weeks once the analysts are familiar with it.

Additionally, the study mentions that they used a P100 GPU with 16 GB of VRAM memory and set the Colab notebook to "high RAM session" to avoid memory limitations that could interrupt the training process. They also modified some model parameters from the default configuration to balance the use of resources and training speed. They retained a resolution of 704 Ã— 704, batch size 64, 32 subdivisions and trained up to 6000 iterations. Other parameters were kept to default or set according to guidance by the developers. Manual annotations were used to generate training, validation and testing datasets.

In summary, the training of a CNN is determined to be complete when the performance on the validation set starts to diverge from the performance on the training set, indicating that the CNN is overfitting to the training set. This is typically measured by monitoring the validation loss, and training is stopped when the validation loss plateaus or begins to increase. The study also mentions that they used a P100 GPU with 16 GB of VRAM memory and set the Colab notebook to "high RAM session" to avoid memory limitations that could interrupt the training process. They also modified some model parameters from the default configuration to balance the use of resources and training speed.