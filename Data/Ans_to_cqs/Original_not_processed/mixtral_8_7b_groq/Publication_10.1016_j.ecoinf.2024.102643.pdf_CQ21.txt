Based on the provided context, there is no explicit information about the postprocessing steps taken after model training, such as generating saliency maps or calculating metrics like precision, recall, or creating a confusion matrix. However, the text does mention that the performance and accuracy of each model were evaluated using AUC (Area Under the Receiver Operating Curve) and TSS (True Skill Statistic).

The AUC metric is a common evaluation method for binary classification problems, measuring the model's ability to distinguish between positive and negative classes. The TSS metric, on the other hand, is a threshold-dependent measure of a model's performance, which takes into account both omission and commission errors.

It is important to note that the postprocessing steps can vary depending on the specific problem, data, and models used. Saliency maps, for instance, are useful for visualizing the importance of input features for a model's prediction. Metrics like precision, recall, and F1-score can provide a more comprehensive understanding of a model's performance, especially in imbalanced datasets. A confusion matrix is a table representation of the predicted and actual classes, which can help in calculating various performance metrics.

Given the context, the postprocessing steps might have involved calculating AUC and TSS, but there is no explicit information suggesting that other common postprocessing steps, such as generating saliency maps or calculating precision, recall, or creating a confusion matrix, were performed.