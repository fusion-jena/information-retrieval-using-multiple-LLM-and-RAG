The hyperparameters of the models were optimized using Bayesian optimization. This technique uses a Gaussian process model of the objective function to optimize different variables, such as network section depth, batch size, initial learning rate, momentum, and regularization strength. For this study, the network was optimized for batch size (between 1 and 32) and initial learning rate (between 1x10^-4 and 1x10^-2). The optimization was performed by employing a Bayesian optimization technique that uses a Gaussian process model of the objective function to find the optimal values for each of the six models. The models were trained using the transfer learning approach, where the weights for the first 10 layers for each pre-trained network were frozen, and the optimization of hyperparameters was performed using the Bayesian optimization. The individual models were trained for each dataset, and the classification accuracies for validation and testing data for UBD_45 and VP_200 datasets are presented in Fig. 4 and Fig. 5, respectively. The models performed well with a testing accuracy above 90% for the UBD_45 dataset, except for GoogleNet.