The context provided does not explicitly mention the specific deep learning frameworks (e.g., TensorFlow, PyTorch) used to build the models. However, it does give some insights into the types of models and techniques used.

The ViT (Vision Transformer) model, proposed by Dosovitskiy et al. in 2020, is used as part of the CA-Hybrid network for Cervidae classification. This model treats the image as a sequence of patches and applies a Transformer, a model typically used in natural language processing, to learn from these patches.

The ResNet (Residual Network) model, a type of Convolutional Neural Network (CNN), is also used in the CA-Hybrid network. The ResNet model is known for its residual structure, which connects different network layers via shortcuts, preserving input features and mitigating issues such as vanishing or exploding gradients. This structure improves the network's ability to learn features in the input image.

The Class Activation Mapping (CAM) technique, proposed by Woo et al. in 2018, is used in the CA-Hybrid network to help the model focus more on critical features, thereby improving the model's generalization ability.

As for the deep learning frameworks, both TensorFlow and PyTorch support the use of Transformers, CNNs, and CAM. Therefore, either of these frameworks could have been used to build the models described in the context. However, without explicit information, it's impossible to provide a definitive answer.