Based on the provided context, there is no direct information about the data augmentation techniques applied in a deep learning pipeline, such as flipping, rotating, or scaling. The context focuses on permafrost models and related parameters. Therefore, I cannot provide a specific answer to the query. However, I can mention that data augmentation techniques are commonly used in deep learning to increase the amount and diversity of training data, which can help improve model performance and prevent overfitting. Some popular data augmentation techniques include:

1. Flipping: Horizontal or vertical flipping of images, which can help the model generalize better and be more robust to changes in orientation.
2. Rotating: Rotating images by a certain angle, which can help the model handle objects at different angles and orientations.
3. Scaling: Changing the scale or zoom level of images, which can help the model handle objects at different distances and sizes.
4. Translation: Shifting images horizontally or vertically, which can help the model handle objects at different positions.
5. Cropping: Randomly cropping images, which can help the model focus on important parts of the image and prevent overfitting.
6. Color jittering: Changing the brightness, contrast, saturation, or hue of images, which can help the model handle images with different lighting conditions and color variations.

These techniques can be applied to the training data during the deep learning pipeline to create new variations of the original data, effectively increasing the size and diversity of the training set.