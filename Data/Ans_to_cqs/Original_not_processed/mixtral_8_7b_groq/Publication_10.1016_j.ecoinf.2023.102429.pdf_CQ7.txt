Based on the provided context, there is no information about the specific criteria used to split the data for deep learning model training (e.g., train, test, validation). However, I can provide some general criteria that are commonly used for splitting data in machine learning:

1. Holdout method: This is the simplest method of splitting the data into training and testing sets. The data is divided into two sets, where a certain percentage (usually 70-80%) is used for training, and the remaining percentage is used for testing.

2. K-fold cross-validation: In this method, the data is divided into 'k' subsets or folds. The model is trained on 'k-1' folds, and the remaining fold is used for testing. This process is repeated 'k' times, such that each fold is used once for testing. The average performance of the 'k' runs is then reported.

3. Stratified sampling: This method is used when the data is imbalanced or when there are categorical variables that need to be evenly distributed across the training and testing sets. The data is divided such that the distribution of the categorical variables is preserved in both sets.

4. Time-series data splitting: For time-series data, it is important to split the data in a way that preserves the temporal order. One common approach is to use the most recent data for testing and the older data for training.

5. Bootstrapping: This method involves randomly sampling the data with replacement to create multiple training sets. This can help reduce the variance of the model and improve its generalizability.

Without more information, it is difficult to determine which of these methods (or others) were used to split the data for the deep learning model training in the given context.