The provided context discusses a study using a Hidden Markov Model (HMM) for classifying blue whale vocalizations, but it does not explicitly mention the criteria used to split the data for deep learning model training. However, it does provide some insights into how the data might have been split based on common practices in machine learning.

In the study, the WT-HMM model was trained using varying dataset sizes over 10 runs, and the performance was compared between recording months. This suggests that the data was likely split into training and testing sets based on the recording months, with one subset used for training the model and the other used for testing its performance.

Furthermore, after training two HMMs independently, they were combined to form a larger HMM with 8 states and 4 mixture weights. This new HMM represented blue whale vocalizations in the first 4 states and noise signals in the last 4 states. The feature vectors extracted from the test datasets were then updated using the trained Gaussian parameters to produce refined feature vectors. This step suggests that a validation set may have been used to fine-tune the model's parameters and evaluate its performance before testing it on the final test set.

In general, when training deep learning models, it is common to split the data into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to fine-tune the model's parameters and evaluate its performance during training, and the testing set is used to evaluate the model's final performance.

Therefore, based on the provided context and common practices in machine learning, it can be inferred that the data was likely split into training, validation, and testing sets. However, the exact criteria used to split the data are not provided in the context.