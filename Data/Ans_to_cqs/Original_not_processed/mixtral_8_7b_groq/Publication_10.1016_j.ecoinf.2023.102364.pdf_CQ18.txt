Answer:::

To monitor the model performance during training, a combination of figures and tables were used. First, Figure 2(a) shows the survey location data for Short-billed Gulls during May and June 2014 and 2015, which were used as the model training data. This allowed for a visual understanding of the data distribution and potential patterns. Additionally, Figure 2(b) provides the same survey location data but distinguishes between presence and absence of Short-billed Gulls, offering a clearer picture of the data used to train the model.

Furthermore, Figure 3(a) displays the U.S. Census blocks and 80 survey location data for Short-billed Gulls during May 2013. This figure served as the external model assessment data, providing an independent dataset to evaluate the model's performance. Figure 3(b) then distinguishes between presence and absence of Short-billed Gulls in the same census blocks, enabling a more thorough assessment of the model's training.

Lastly, Table 3 provides the model diagnostics importance rank of predictors from the machine learning model. This table is crucial for understanding the relative importance of each predictor in the model, allowing for a more informed evaluation of the model's performance. The partial dependence plots in Figures 6, 7, and 8, as well as the 3D partial dependence plot in Figure 9, further illustrate the impact of the top-ranked predictors on the model's output. These visualizations help in identifying any potential issues or biases in the model's performance during training.

In summary, the strategy to monitor the model performance during training involved the use of survey location data, presence/absence data, external model assessment data, model diagnostics, and partial dependence plots. This comprehensive approach allowed for a thorough evaluation of the model's performance and identification of any potential issues.