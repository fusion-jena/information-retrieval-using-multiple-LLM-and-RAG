The pieces of context provided do not explicitly mention the specific hardware resources used for training the deep learning models. However, it is mentioned that the models are being trained and stored using an interface provided by a site and its computational resources. This implies that the training of these models is being done on some sort of remote server or cloud infrastructure, which typically would have access to high-end computational resources such as GPUs or TPUs.

For example, in the case study 1, the authors mention that they are creating task-specific classifiers on users' requests and the performance of such a classifier is presented. This suggests that the training of these classifiers is being done on a server or cloud infrastructure, as it would not be feasible for most users to train large deep learning models on their personal computers.

Additionally, some of the papers mentioned, such as "Towards intelligent and integrated pest management through an AIoT-based monitoring system" and "Deep learning object detection for image analysis of cherry fruit fly (Rhagoletis cerasi L.) on yellow sticky traps" are focused on developing real-world systems for pest management and crop monitoring, which would require the use of high-performance computational resources for training and deploying the models.

In conclusion, while the specific hardware resources used for training the deep learning models are not mentioned in the provided context, it can be inferred that they are being trained on remote servers or cloud infrastructure, which would have access to high-end computational resources such as GPUs or TPUs.