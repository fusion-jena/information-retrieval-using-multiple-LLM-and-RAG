The text provided does not give specific details about how the hyperparameters of the SVM model are optimized. However, it does mention that there are three kernels of SVM, and the choice of kernel can affect the performance of the model. The three kernels are linear kernel, polynomial kernel, and Gaussian kernel. The linear kernel is used for binary classification, while the Gaussian and polynomial kernels are used for multi-class classification.

In general, hyperparameter tuning is an important step in building machine learning models. Hyperparameters are parameters that are not learned from the data, but instead are set prior to training the model. Examples of hyperparameters include the learning rate, the number of hidden layers in a neural network, and the regularization parameter.

There are several methods for hyperparameter tuning, including grid search, random search, and Bayesian optimization. Grid search involves defining a grid of hyperparameter values and training the model for each combination of hyperparameters. Random search involves randomly sampling hyperparameter values from a defined range and training the model for each sampled set of hyperparameters. Bayesian optimization involves using a probabilistic model to guide the search for the best hyperparameters.

Without more information about the specific implementation of the SVM model in the text provided, it is not possible to give a specific answer about how the hyperparameters were optimized. However, it is likely that some form of hyperparameter tuning was performed to achieve the best performance of the model.