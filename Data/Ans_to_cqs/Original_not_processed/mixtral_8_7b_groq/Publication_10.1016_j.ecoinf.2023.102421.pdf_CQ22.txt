The provided context discusses the evaluation of machine learning models, specifically XGBoost and LightGBM, using various metrics such as RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), and R2 (coefficient of determination). However, it does not mention any deep learning models being used or evaluated.

Hyperparameter optimization is discussed, which is a process used to find the best set of hyperparameters for a machine learning model. This optimization can be done using various methods, including random or grid search, as well as Bayesian optimizers and Swarm-based algorithms.

The models used in the study are XGBoost and LightGBM, both of which are decision tree-based ensemble machine learning algorithms, not deep learning models. The models are trained using a tabulated dataset with 39 features, and their performance is evaluated using 10-fold cross-validation and mean RMSE as the objective function.

The Wilcoxon Signed-Rank test with paired samples is used to test the differences between the RMSEs of different models. The results show that the performance of XGBoost-TDO and LightGBM-TDO is the same.

Therefore, based on the provided context, there is no information on the evaluation metrics used for deep learning models.

Answer:::
The provided context does not mention any deep learning models being used or evaluated. Therefore, there is no information on the evaluation metrics used for deep learning models.