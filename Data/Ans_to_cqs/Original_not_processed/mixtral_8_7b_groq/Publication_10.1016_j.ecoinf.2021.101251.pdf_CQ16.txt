The provided context does not contain specific information about the criteria used to determine when training is complete for a machine learning or statistical model. The documents discuss various topics related to data management, scientific standards, and data collections in the fields of hydrology, biogeochemistry, and citizen science.

However, in general, there are several common criteria used to determine when training of a model is complete, such as:

1. Validation loss plateau: This is the most common criterion used to determine when training is complete. It refers to the point at which the loss function (e.g., mean squared error, cross-entropy) on a validation set stops decreasing or decreases very slowly, despite further training.
2. Early stopping: This is a regularization technique used to prevent overfitting. It involves stopping the training process before the validation loss starts to increase, based on a pre-specified number of epochs or patience parameter.
3. Learning rate schedule: This involves gradually decreasing the learning rate as the training progresses, based on a pre-specified schedule. This can help the model converge to a better minimum and prevent overshooting.
4. Model complexity: This involves monitoring the complexity of the model during training, such as the number of parameters or the norm of the weights. If the complexity starts to increase without a corresponding decrease in the validation loss, it may indicate overfitting.

These criteria are typically used in combination, and the choice of criterion depends on the specific problem, the model, and the data. It is important to carefully evaluate the performance of the model on a validation set to ensure that it generalizes well to new data.