The provided context does not contain information on the specific process followed to deploy a trained deep learning model. However, it does provide some insights into related topics such as pre-training language models and using pre-trained word embedding techniques.

For instance, the first reference is about BERT (Bidirectional Encoder Representations from Transformers), a pre-trained deep bidirectional transformers for language understanding. The paper mentions that the model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of NLP tasks. However, it does not provide information on how the fine-tuned model is deployed.

The second reference is about identifying wildlife observations on Twitter using NLP techniques. While the paper discusses data collection, pre-processing, and model training, it does not mention anything about deploying the trained model.

The third reference talks about harnessing artificial intelligence technology and social media data to support cultural ecosystem service assessments. The paper discusses data collection, pre-processing, and model training but again, there is no information on deploying the trained model.

The fourth reference introduces the tm text mining package in R, which can be used for text pre-processing and analysis. However, it does not discuss model deployment.

The fifth reference describes the pre-trained word embedding space called GÃ¼nther et al., 2015, which was created using the CBOW algorithm and contains vectors for 300,000 different words. However, it does not provide information on how the pre-trained model is deployed.

The sixth reference explains Word2vec, a widely known word embedding technique, and how it can be used for investigating Cultural Ecosystem Services (CES) from social media data. The paper mentions that pre-trained models can be used, but it does not provide information on how the pre-trained model is deployed.

Therefore, based on the provided context, it is not possible to answer the query regarding the process followed to deploy the trained deep learning model.