Answer:::

The context provided does not give specific information about how the hyperparameters of the models are optimized. It does not mention any techniques such as grid search, random search, or others. However, it does provide some insights into the optimization of models in general.

For instance, the study by Al Muksit et al. (2022) developed a robust fish detection model, YOLO-fish, to detect fish in underwater environments. While they do not explicitly mention hyperparameter optimization, they do discuss the importance of selecting appropriate parameters for the model's architecture, such as the number of convolutional layers and filters.

In another study, Albuquerque et al. (2019) developed a computer vision system for automatic live fingerlings counting. They optimized their model by adjusting parameters such as the number of Haar-like features, the cascade stages, and the minimum neighborhood size. However, they do not specify the method used for searching the optimal parameter values.

Bao et al. (2023) studied the trade-off between accuracy and inference speed in object detection models. They used various models, including LigObNet, YOLOv5, YOLOv6, YOLOv7, and YOLOv8, and trained them across four scales (n, s, m, and l). While they do not explicitly mention hyperparameter optimization, they do discuss the impact of changing the number of parameters on the model's performance.

Therefore, while the context does not provide specific information about hyperparameter optimization techniques, it does suggest that model optimization is achieved through adjusting various parameters, such as the number of layers, filters, and Haar-like features. However, the specific methods used for searching the optimal parameter values remain unclear.

Answer:::