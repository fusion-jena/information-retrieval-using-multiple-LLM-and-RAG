Based on the provided context, there is no explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it is mentioned that the dataset was split into 70% for training, 10% for testing, and 20% for validation. But the criteria or method used to determine this split are not specified.

Moreover, the given context mainly focuses on the description of an algorithm that appears to be a type of ensemble learning method, specifically a Random Forest Regressor, rather than a deep learning model. The algorithm involves drawing a bootstrap sample of the dataset, growing a decision tree from the bootstrap sample, and aggregating predictions from all the trees for the final prediction. The dataset is mentioned to be used for training Linear Regression, Lasso, and Ridge models, but not for a deep learning model.

Therefore, I cannot provide an answer to the query based on the given context. However, it is worth noting that for deep learning models, data splitting criteria are typically based on random sampling, where a portion of the data is used for training, another portion for validation, and the remaining for testing. The purpose of this split is to evaluate the model's performance, prevent overfitting, and ensure that the model generalizes well to unseen data.