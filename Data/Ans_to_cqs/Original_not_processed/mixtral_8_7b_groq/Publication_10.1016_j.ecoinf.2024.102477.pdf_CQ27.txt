Based on the provided context, there is no explicit information about the process followed to deploy the trained deep learning model. However, it can be inferred that the model was likely serialized and then deployed on a suitable platform for its intended application.

Model serialization is a common practice in deep learning, which involves saving the trained model's architecture, weights, and biases to a file, allowing it to be easily loaded and used for making predictions. The specific method used for serialization depends on the deep learning framework employed. For instance, in TensorFlow, models can be saved using the `save()` method, while in PyTorch, the `torch.save()` function can be used.

Once the model is serialized, it can be deployed on a suitable platform for its intended application. In the context of the provided information, the deep learning models were used for time-series prediction tasks related to air pollution and agricultural product sales. Therefore, the deployed platform could be a server or a cloud-based infrastructure that can handle real-time data processing and prediction requests.

Additionally, the deep learning models were compared with other statistical and machine learning models, indicating that a model selection process was carried out to determine the best-performing model for the given tasks. This process would have involved evaluating the models' performance using metrics such as Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) and selecting the model with the lowest error values.

In summary, while there is no explicit information about the process followed to deploy the trained deep learning model, it can be inferred that the model was likely serialized and deployed on a suitable platform for its intended application. Additionally, a model selection process was carried out to determine the best-performing model for the given tasks.