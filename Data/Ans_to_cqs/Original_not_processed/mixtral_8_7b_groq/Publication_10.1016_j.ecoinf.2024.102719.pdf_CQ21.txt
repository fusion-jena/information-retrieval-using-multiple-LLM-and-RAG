Based on the provided context, there is no explicit information about the postprocessing steps involved after the model training, such as generating saliency maps, calculating metrics, or creating confusion matrices. However, it does mention that for each model, the predictions on the testing dataset were averaged to obtain the main prediction, and the average loss, average bias, and average variance were then derived for each model.

In machine learning, postprocessing steps often include evaluating the model's performance using appropriate metrics and visualizations. Commonly used metrics include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC). Visualizations, such as confusion matrices, can provide additional insights into the model's performance, particularly in terms of false positives and false negatives.

Saliency maps are another postprocessing technique used to visualize the importance of input features in the model's prediction. However, the context does not mention any details about feature importance or saliency maps.

In summary, while the provided context does not explicitly mention the postprocessing steps involved after the model training, it is common practice to evaluate a model's performance using various metrics and visualizations. Saliency maps, confusion matrices, and other techniques can offer valuable insights into the model's behavior and help assess its generalizability.