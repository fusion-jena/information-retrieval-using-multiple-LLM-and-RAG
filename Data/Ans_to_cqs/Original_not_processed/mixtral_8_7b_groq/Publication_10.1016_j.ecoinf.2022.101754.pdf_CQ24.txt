Based on the provided context, there is no direct mention of strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, the context does provide information about a study that used machine learning methods, including a deep learning-based retrieval of forest biomass, to estimate aboveground biomass (AGB) from LiDAR and Landsat 8 data.

The study utilized a training-and-test approach with stratification splitting, where 100 different splits to the training-and-test set were given for each setting. Hyperparameter tuning was done on the training set for each set, followed by model training using an optimal setting of the hyperparameter. This process was repeated for four methods used to model forest AGB: AdaBoost, random decision forest (RF), multilayer neural network (NET), and Bayesian ridge regression (Bayes).

While the study does not explicitly mention the use of a random seed value, it does describe the use of multiple splits of the training and test sets, which can help to account for randomness in the data and reduce the impact of outliers. Additionally, the study's use of hyperparameter tuning and model training with an optimal setting of the hyperparameter may also help to reduce the impact of randomness on the model's performance.

In summary, while the provided context does not directly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value, it does describe the use of multiple splits of the training and test sets, hyperparameter tuning, and model training with an optimal setting of the hyperparameter. These strategies can help to account for randomness in the data and improve the model's performance.