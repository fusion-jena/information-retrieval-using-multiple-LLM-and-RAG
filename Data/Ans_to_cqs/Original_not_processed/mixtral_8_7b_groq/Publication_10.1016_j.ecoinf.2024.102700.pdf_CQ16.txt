Answer:::
The provided context does not contain specific information on the criteria used to determine when training is complete in the studies analyzed. However, it does mention that model validation was performed either in addition to internal validation strategies or as the sole validation method. It is possible that some studies used a validation loss plateau as a criterion for determining when training is complete, but this information is not explicitly stated in the context.

In general, a validation loss plateau is a common criterion used to determine when training is complete in machine learning models. This involves monitoring the performance of the model on a validation dataset during the training process. When the performance on the validation dataset stops improving or begins to degrade, even as the model continues to train on the training dataset, this indicates that the model is starting to overfit to the training data. At this point, the training process can be stopped to prevent overfitting and to ensure that the model generalizes well to new data.

It is worth noting that the context provided focuses on the use of machine learning models in the field of ecology, specifically for predicting cetacean abundance and marathon performance. Therefore, the criteria used to determine when training is complete may vary depending on the specific application and the data being analyzed. Other criteria that may be used to determine when training is complete include a specified number of training epochs, a minimum improvement threshold in model performance, or early stopping based on a combination of these factors.

Overall, while the provided context does not contain specific information on the criteria used to determine when training is complete, it is likely that some studies used a validation loss plateau as a criterion. This is a common practice in machine learning and can help ensure that the model generalizes well to new data.