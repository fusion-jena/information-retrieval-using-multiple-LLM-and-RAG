The metrics used to evaluate the performance of the deep learning model include mean Average Precision (mAP), precision, recall, and F-score.

mAP is the primary metric used to evaluate the model's performance, which is the average of the Average Precision (AP) for each class. The mAP value ranges from 0 to 1, where a value closer to 1 indicates better model performance. mAP is independent of the selected threshold for implementing the model, making it a robust evaluation metric.

Precision and recall are inversely related metrics that are used to assess the model's performance. Precision measures the proportion of true positive predictions out of all positive predictions, while recall measures the proportion of true positive predictions out of all actual positive instances. To achieve a balance between both metrics, a precision-recall curve (P-R curve) is plotted, which represents the model's performance across all possible threshold values.

The F-score is a metric that combines precision and recall into a single value, which is the harmonic mean of precision and recall. The F-score is calculated using the Fβ formula, where β is a coefficient that determines the weightage given to precision and recall. By decreasing the β coefficient, a higher weightage is given to precision than recall.

In the provided context, the authors used mAP, precision, recall, and F-score to evaluate the model's performance. They searched for an optimum threshold value (θ) for each class to balance precision and recall metrics by observing the highest measure of the harmonic mean (F1score) and the most general measure variations of the F-score. They plotted the P-R curves of all classes on the same graph to identify the best performance in the prediction, with the threshold θ associated with the point closest to the coordinate (1, 1).

Therefore, mAP, precision, recall, and F-score are the metrics used to evaluate the performance of the deep learning model.