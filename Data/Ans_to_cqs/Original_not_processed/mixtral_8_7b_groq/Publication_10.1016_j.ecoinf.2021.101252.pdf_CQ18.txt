Answer:::
The strategy implemented to monitor the model performance during training involves examining the progression of validation performance, which is measured using a holdout data partition referred to as Bv. The model's performance is monitored after each training epoch. If no increase in validation performance is observed after a certain number of epochs, in this case, 25 epochs, the training process is stopped. This approach helps prevent overfitting, which can occur when a model is trained for an excessive number of epochs. 

Additionally, the performance of the model having an 'optimal' number of training epochs is evaluated using a 'final' test data set, denoted as T. This provides the best estimate of the predictive performance of the model. 

In the context of the case studies, the model's training performance is measured during each epoch using the accuracy metric, which is the proportion of cases correctly classified. The classification performance on the validation data is measured using the area under the receiver operating characteristic curve (AUC), a metric that is not affected by differences in the prevalence of classes and is widely used in ecology. 

The processing time of all models is recorded from the onset of training of candidate models to the last training epoch evaluated for the selected model. This is done on two distinct systems: a 'desktop PC' and a high-end workstation. This information is used to understand the computational resources required for the model training process.