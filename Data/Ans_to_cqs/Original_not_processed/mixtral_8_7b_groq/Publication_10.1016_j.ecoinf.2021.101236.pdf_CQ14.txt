Based on the information provided, there is no explicit mention of how the hyperparameters of the model are optimized. Hyperparameter optimization is an essential step in machine learning model development, which can be done through various methods such as grid search, random search, Bayesian optimization, etc. Grid search involves evaluating a model for each combination of hyperparameters in a predefined grid. In contrast, random search randomly selects hyperparameters from a given distribution and evaluates the model.

The context provided focuses on the architecture of the model, which follows the Wide ResNet approach, and the dataset used for training, which consists of eBird checklist data and focal recordings. Although the context provides details on the architecture and data, it does not mention any specific method used for hyperparameter optimization.

Therefore, based on the given context, it is not possible to provide a specific answer to how the hyperparameters of the model are optimized.