The provided context does not give detailed information on the process followed to deploy the trained deep learning model. However, it does mention that transfer learning models were used and evaluated based on classification performance. Therefore, we can assume that the models were seriallyzed, which is a common practice in deep learning to save the trained model for later use or deployment.

Model serialization is the process of saving the architecture, weights, and other parameters of a trained deep learning model into a file. This file can then be used to recreate the exact same model without having to retrain it. This is useful for deploying the model in real-world applications, where retraining the model may not be feasible or necessary.

As for the platform selection, the context does not provide any information on where the models were deployed. It is possible that the models were deployed on a local machine, or they could have been deployed on a cloud platform such as Google Cloud, Amazon Web Services, or Microsoft Azure. The choice of platform would depend on various factors such as the required computational resources, cost, and ease of deployment.

In summary, while the provided context does not give detailed information on the process followed to deploy the trained deep learning model, it can be assumed that the models were seriallyzed for later use or deployment. The choice of platform for deployment is not specified in the context.