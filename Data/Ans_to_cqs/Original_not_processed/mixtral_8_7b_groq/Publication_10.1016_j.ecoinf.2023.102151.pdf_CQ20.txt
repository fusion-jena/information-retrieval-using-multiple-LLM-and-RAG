The pieces of context provided do not directly answer the query regarding the specific hardware resources used for training deep learning models. However, they do provide some insight into the broader field of computational methods used in various domains such as soil science, irrigation management, geography, and metro map drawing.

Deep learning models typically require significant computational power for training, often necessitating the use of specialized hardware like Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). GPUs are particularly well-suited for deep learning due to their ability to perform many computations simultaneously, which is ideal for the matrix and vector operations that form the basis of deep learning algorithms. TPUs, on the other hand, are custom-built by Google for machine learning tasks and offer even greater performance for certain types of computations.

While the pieces of context do not explicitly mention the use of GPUs, TPUs, or other specific hardware for deep learning, they do refer to various software tools and techniques that are often used in conjunction with such hardware. For example, the "overview and comparison of machine-learning techniques for classification purposes in digital soil mapping" piece discusses machine learning methods, which are typically implemented using deep learning models. Similarly, the "Architectural modelling of an olive tree" piece discusses generative tools for scientific visualization, which could involve the use of deep learning algorithms for tasks like image generation or 3D modeling.

In summary, while the pieces of context do not provide a direct answer to the query, they do suggest that deep learning models are likely used in the relevant fields, and that specialized hardware like GPUs or TPUs may be employed for training these models. However, further investigation would be required to provide a definitive answer.