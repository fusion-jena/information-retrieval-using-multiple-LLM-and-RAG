In the context provided, the specific criteria used to determine when training is complete for a deep learning (DL) model in the biodiversity monitoring application is not mentioned. However, it is mentioned that the DL models are usually trained in a supervised fashion using stochastic gradient descent, and that they output the relative probability that an event is from a specific data class.

In general, for deep learning models, training is often considered complete when the validation loss plateaus or stops decreasing significantly. This is because the goal of training a DL model is to minimize the difference between the model's predictions and the actual data, as measured by a loss function. The validation loss is calculated using a separate validation dataset, which is not used in the training process. This helps to ensure that the model is not overfitting to the training data.

Another common technique used to determine when training is complete is early stopping. This involves stopping the training process before the validation loss plateaus if the validation loss starts to increase. This can help to prevent overfitting and improve the model's generalization performance.

Additionally, it's also important to note that, in practice, the choice of the stopping criterion can depend on the specific problem and the specific DL architecture being used. In some cases, other factors such as the computational resources available or the amount of data may also be taken into account when determining when training is complete.

In summary, while the specific criteria used to determine when training is complete for the DL models used in the biodiversity monitoring application is not mentioned in the context provided, in general, training is often considered complete when the validation loss plateaus or stops decreasing significantly, and techniques such as early stopping can also be used to prevent overfitting.