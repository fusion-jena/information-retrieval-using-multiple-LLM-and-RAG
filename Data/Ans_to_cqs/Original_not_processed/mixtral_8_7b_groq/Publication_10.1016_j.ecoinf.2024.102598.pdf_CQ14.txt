The text does not explicitly mention the specific methods used to optimize the hyperparameters of the models, such as grid search or random search. However, it is stated that they "calibrated and validated each model after fitting each MLM with optimized parameters." This implies that some form of hyperparameter tuning was employed.

For the Random Forest model, they explicitly set the number of trees to 500, which is a hyperparameter. The choice of this specific value suggests some form of parameter optimization, as setting a high number of trees helps reduce the resulting model's bias.

Moreover, they used a 10-fold cross-validation design for each run of the cross-validation procedure. This method could be used for hyperparameter tuning, where different sets of hyperparameters are tried out in each fold of the cross-validation process. However, the text does not explicitly confirm this.

In conclusion, while the text suggests that some form of hyperparameter tuning was used, it does not provide enough details to definitively answer the question about the specific methods used, such as grid search or random search.