Answer:::

The training of deep learning models is completed before the maximum number of epochs (which is set to 100 in this case) based on the early stopping strategy. This strategy involves inspecting the validation accuracy after every epoch, and the training is stopped when the validation accuracy plateaus or stops improving.

Additionally, the learning rate is initially set to 1e-6 and is monitored after every epoch. The validation loss is used to adjust the learning rate, although the specific details of how this is done are not provided in the context.

It's worth noting that the datasets are divided into three parts for training, validation, and testing. Specifically, 60% of the data is used for training, 20% is used for validation, and the remaining 20% is used for testing. This allows for the models to be evaluated on unseen data and provides a more accurate estimate of their performance.

Furthermore, when training the models, all patches of images are resized to a resolution of 256x256 pixels. This is done to ensure that all images are of the same size and can be processed by the models.

After training, the models predict the class label for each patch of an image. Then, the important patches are selected using a specific approach, and the weighted majority voting technique is used to predict the class label of the image from the predicted labels.

In summary, the training of deep learning models is completed based on the early stopping strategy, which involves inspecting the validation accuracy after every epoch and stopping the training when the validation accuracy plateaus. Additionally, the learning rate is monitored and adjusted based on the validation loss. The datasets are divided into three parts for training, validation, and testing, and all patches of images are resized to a uniform size before training. After training, the models predict the class label for each patch of an image, and the important patches are selected to predict the class label of the image.