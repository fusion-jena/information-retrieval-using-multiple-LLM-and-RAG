The provided context discusses the training process and architecture of a deep learning model in the context of time series data forecasting, particularly for the case of DO (Dissolved Oxygen) prediction in the Shandong peninsula. However, it does not explicitly mention the preprocessing steps applied to the data before training the model.

Nonetheless, it is common practice in deep learning to apply various preprocessing techniques to the data before training. These techniques may include:

1. Normalization: This process involves scaling numeric data to a common range, often between 0 and 1. This can help the model converge faster during training and can improve the model's performance.

2. Scaling: Similar to normalization, scaling involves adjusting the range of features. This can be done using techniques such as min-max scaling, where each feature is scaled to a specific range (e.g., [-1, 1]).

3. Cleaning: This step involves handling missing values, outliers, and other forms of noise in the data. Techniques can include imputation (replacing missing values with statistical estimates), capping (limiting the maximum value of a feature), or simply removing instances with missing or invalid data.

4. Feature engineering: This process involves creating new features from existing ones, which can help the model capture more complex relationships in the data. This can include techniques such as polynomial features, interaction features, or using domain-specific knowledge to create new features.

Given the complexity of the model and the nature of the problem discussed in the context, it is likely that some or all of these preprocessing steps were applied to the data before training. However, the specific preprocessing steps are not mentioned in the provided context.