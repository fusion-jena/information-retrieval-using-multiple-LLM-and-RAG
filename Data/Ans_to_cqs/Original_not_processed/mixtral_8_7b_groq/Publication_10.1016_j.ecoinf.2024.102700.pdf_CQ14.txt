Based on the provided context, there is no explicit information given about how the hyperparameters of the models used in the study were optimized. The text mentions the use of specific modelling approaches, environmental variables, and validation methods, but it does not provide details on the optimization of hyperparameters.

Hyperparameter optimization is an important step in the development of machine learning models, as it can significantly impact the model's performance. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization.

Grid search involves systematically trying out different combinations of hyperparameters within a predefined range. Random search, on the other hand, involves randomly selecting hyperparameters within a defined range. Bayesian optimization uses a probabilistic model to select the next set of hyperparameters to try based on the performance of previous iterations.

Without more information, it is not possible to provide a specific answer to the query. However, it is important to note that hyperparameter optimization is a crucial step in model development and should be addressed in any rigorous modeling study.