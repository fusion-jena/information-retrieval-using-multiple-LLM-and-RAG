Based on the provided context, there is no explicit information about the process followed to deploy the trained deep learning model. However, we can infer that the model was likely serialized and then deployed on a suitable platform for testing and evaluation.

The study by Vu et al. (2022) analyzes the performance of various machine learning (ML) models, including deep learning models such as Recurrent Neural Networks (RNNs), on waste disposal rate estimation. The study uses the K-fold cross-validation method for training and testing the models. However, the specifics of the model deployment process are not discussed.

In general, when deploying a deep learning model, the trained model is first serialized, i.e., converted into a format that can be stored and loaded later. This is often done using model serialization libraries such as TensorFlow's SavedModel or PyTorch's TorchScript. Serialization allows the model to be easily deployed on different platforms and devices.

After serialization, the model is deployed on a suitable platform for testing and evaluation. This could be a local machine, a cloud-based platform, or an edge device, depending on the specific use case. The choice of platform depends on various factors such as computational resources, latency requirements, and data privacy considerations.

In the context of the study by Vu et al. (2022), it is likely that the serialized deep learning model was deployed on a local machine or a cloud-based platform for testing and evaluation. The study compares the performance of various ML models on waste disposal rate estimation and reports the Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) for each model. These metrics are commonly used to evaluate the performance of regression models.

Therefore, while the specifics of the model deployment process are not discussed in the study, it is likely that the trained deep learning model was serialized and deployed on a suitable platform for testing and evaluation.