Based on the provided context, there is no explicit information about how the hyperparameters of the model are optimized. The text discusses various methods for counting wildebeest in survey images, including citizen science and deep learning approaches such as YOLO (You Only Look Once), but it does not mention the specific techniques used for hyperparameter optimization.

Hyperparameter optimization is an essential step in training machine learning models to ensure good performance. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization. Grid search involves systematically trying different combinations of hyperparameters within a predefined range. Random search, on the other hand, randomly selects hyperparameters from a specified range, which can be more efficient than grid search. Bayesian optimization uses a probabilistic model to guide the search for optimal hyperparameters.

Without further information, it is not possible to provide a specific answer to how the hyperparameters of the model are optimized in this context. However, it is mentioned that the YOLO count is capable of producing highly accurate image counts, which suggests that the model's hyperparameters are likely optimized using one or more of the aforementioned methods.