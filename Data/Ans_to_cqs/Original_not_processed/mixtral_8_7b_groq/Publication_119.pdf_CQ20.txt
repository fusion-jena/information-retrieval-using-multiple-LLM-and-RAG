Based on the provided context, there is no explicit information given about the specific hardware resources used for training the deep learning models. The text focuses more on the implementation and optimization of the models, such as the use of a U-Net model with a ResNet-50 backbone pretrained on ImageNet, and the tuning of hyperparameters like learning rate, number of epochs, and batch size. However, it is generally common practice to use powerful computational hardware like Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) for training deep learning models, as they can significantly speed up the training process compared to using only CPUs. Therefore, while the context does not provide specific information, it is still likely that GPUs or TPUs were used for training the models in this case.