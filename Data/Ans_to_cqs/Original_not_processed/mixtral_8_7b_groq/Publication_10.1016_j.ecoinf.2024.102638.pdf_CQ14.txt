The context does not provide explicit information on the specific method used for hyperparameter optimization, such as grid search or random search. However, it does mention that the performance metrics of various models, including XGB, RF, SVR, GP, EN, KNN, MLP, Tree, and LR, were evaluated during the hyperparameter tuning process. The best regression parameter was then selected for each model based on this evaluation.

Furthermore, Table 4 includes details on the hyperparameters, parameters selected during 5-fold cross-validation, and the hyperparameters adjusted according to the selection criteria for each model. This suggests that some form of systematic search or optimization was performed to find the best hyperparameters for each model.

Therefore, while the exact method of hyperparameter optimization is not specified in the context, it is clear that a systematic approach was taken to tune the hyperparameters of each model, and the performance of these models was evaluated using the designated test set and the metrics detailed in Section 2.5.