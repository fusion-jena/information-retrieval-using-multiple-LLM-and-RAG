Based on the provided context, there is no explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context focuses on the performance evaluation of a deep learning model for fish biomass estimation, rather than the data splitting process.

However, it is common practice in machine learning and deep learning to split the dataset into three subsets: training, validation, and testing. This practice aims to ensure the model's generalization ability and evaluate its performance on unseen data.

1. Training set: This subset is used to train the model by adjusting the model's parameters to minimize the error on the training data.
2. Validation set: Also known as the development set, this subset is used during the training process to provide an unbiased evaluation of the model. It helps in tuning hyperparameters and preventing overfitting.
3. Testing set: This subset is used to evaluate the final model's performance. It is the first time the model encounters this data, providing an unbiased estimate of how the model will perform on new, unseen data.

In general, the data splitting ratio can vary depending on the dataset size and specific problem requirements. Commonly used ratios are 60-20-20 or 70-15-15 for training, validation, and testing sets, respectively.

In summary, while the provided context does not explicitly mention the criteria for splitting the data, it is a standard practice in deep learning to split the dataset into training, validation, and testing subsets to ensure the model's generalization ability and performance evaluation on unseen data.