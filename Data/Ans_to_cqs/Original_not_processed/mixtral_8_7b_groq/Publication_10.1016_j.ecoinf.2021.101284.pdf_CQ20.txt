Based on the provided context, there is no explicit information about the specific hardware resources used for training the deep learning model. However, it can be inferred that given the size of the data is in the order of terabytes, specialized hardware such as Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) were likely used to handle the computations efficiently. These hardware resources are commonly used for training deep learning models due to their ability to perform parallel processing, which is particularly useful for handling large datasets. Nonetheless, the text does not provide specific details on the hardware resources used in this case.