Based on the provided context, there is no explicit information about the specific criteria used to determine when training is complete for the machine learning models in Google Earth Engine (GEE). However, it can be inferred that the training process might be terminated based on hyperparameter tuning and validation data.

In the study, the validation data, which is 10% of the training data, was used for hyperparameter tuning for each model. This implies that the training process might involve monitoring the performance of the models on the validation data during the training phase. Consequently, the training could be stopped when the model's performance on the validation data stabilizes or shows no significant improvement over a certain number of iterations.

For instance, in the case of the Support Vector Machine (SVM) model, the 'shrinkage' and 'sampling rate' hyperparameters could be adjusted to minimize the validation loss. If the validation loss does not decrease significantly after a certain number of iterations, the training process could be stopped.

Similarly, for the Random Forest (RF) and Gradient Tree Boosting (GTB) models, the 'number of trees' hyperparameter could be adjusted. The training process might be terminated when the validation loss plateaus, indicating that increasing the number of trees does not lead to a significant improvement in the model's performance.

For the Classification and Regression Tree (CART) model, since there is no limit on the maximum number of nodes, the training process might be stopped based on a validation loss threshold or when the tree reaches a maximum depth.

In summary, while the provided context does not explicitly mention the criteria used to determine when training is complete, it can be inferred that the training process might be terminated based on the performance of the models on the validation data during the hyperparameter tuning phase.