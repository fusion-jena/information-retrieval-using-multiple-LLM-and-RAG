Answer:::

The hyperparameters used in the deep learning model, as described in the paper, include the following:

1. Learning rate: The learning rate is a constant value of 0.01.
2. Optimizer: The model optimizes cross-entropy loss via mini-batch stochastic gradient descent.
3. Dropout: Dropout is applied to the input of the last two layers with a probability of 0.5.
4. L2-regularization: L2-regularization is applied to the weights of the last two layers with a penalty factor of 0.001.
5. Number of epochs: The model is trained for 100 epochs.
6. Checkpointing: The model is checkpointed after each epoch.
7. Validation set: A validation set is used to identify the parameter setting (epoch) achieving the highest classification accuracy.

The CNN model is implemented in Python using Lasagne, and data stream multiplexing is implemented using Pescador.

References:
[17] J. Salamon and J. P. Bello, "Deep convolutional neural networks and data augmentation for environmental sound classification," IEEE Signal Processing Letters, In Press.
[26] Mini-batch stochastic gradient descent is a popular optimization algorithm used in machine learning.
[27] Dropout is a regularization technique used to prevent overfitting in neural networks.
[28] Lasagne is a lightweight library for building and training neural networks in Python.
[29] Pescador is a data stream multiplexing library for Python.