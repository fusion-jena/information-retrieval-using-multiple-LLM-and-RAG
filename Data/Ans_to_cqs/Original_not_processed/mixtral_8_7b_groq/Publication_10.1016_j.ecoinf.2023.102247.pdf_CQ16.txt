Answer:::

Based on the provided context, there is no explicit information about the criteria used to determine when training is complete for the models used in the study. However, it is mentioned that they employed cross-validation by using 70% of the dataset as training data to build the models and the other 30% as testing data to calculate the modelsâ€™ accuracy.

In the context of machine learning and model training, determining when training is complete often involves monitoring the performance of the model on a validation dataset during the training process. Commonly, training is considered complete when the performance on the validation dataset stops improving or plateaus, even if the performance on the training dataset continues to improve. This is because continued training on the training dataset alone can lead to overfitting, where the model becomes too specialized to the training data and performs poorly on new, unseen data.

In the study, four different models, including one regression-based model and three machine-learning models (MaxEnt, RF, and SVM), were used. The specific criteria used to determine when training is complete for each of these models are not provided in the context. However, it is mentioned that the Area Under the Receiving Operator Characteristics Curve (AUC) was used to specify the accuracy of the models. AUC is a scale that ranges from 0.5 to 1.0, where a higher AUC value indicates a more accurate model.

Therefore, while the specific criteria used to determine when training is complete for the models in the study are not provided, it can be inferred that the training process involved monitoring the performance of the models on a validation dataset and evaluating their accuracy using the AUC index.