Answer:

The strategy implemented to monitor the model performance during training is not explicitly mentioned in the provided context. However, it can be inferred that the performance of the classification models is evaluated using accuracy on the test set, which is a common approach to monitor model performance.

In section 5.2, it is mentioned that the datasets are divided into a training set and a test set with a ratio of 8:2. The classification models are built using the training set, and the accuracy on the test set is used as an indicator to evaluate the performance of the classification models. This suggests that the model performance is being monitored by comparing the predicted labels of the test set samples with their actual labels.

Furthermore, in section 5.2.3, it is mentioned that the proposed models combine features to build classification models with strong generalization performance. The performance of these models is evaluated using the same approach of calculating accuracy on the test set. Therefore, it can be inferred that the model performance is being monitored using the accuracy metric on the test set.

However, the context does not mention any other strategies such as using validation sets, early stopping, or learning rate schedules to monitor and improve the model performance during training. Therefore, it can be assumed that the monitoring strategy is limited to evaluating accuracy on the test set.