Based on the provided context, there is no explicit information about the process followed to deploy a specific trained deep learning model. However, there are some general insights that can be inferred about how deep learning models might be deployed, particularly in the context of event-stream processing and edge computing.

When discussing event-stream processing tools, the text mentions AWS Kinesis and Apache Kibana, which provide access to machine learning methods for processing event streams. These platforms likely have built-in capabilities for deploying trained models, such as model serialization and integration with their processing pipelines.

Edge computing, which involves processing data before sending it over the network, is another relevant concept. In this context, the text mentions that data streams are transformed to event streams at the edge of the cluster. This transformation process could potentially involve deploying a deep learning model for tasks such as feature extraction or anomaly detection. If sufficient processing power is available at the sensor, the model could be deployed directly on the sensor to reduce the amount of data to transmit.

In the context of deep learning frameworks, the paper by Kovalev et al. (2016) compares five popular deep learning libraries: Theano, Torch, Caffe, Tensorflow, and deeplearning4j. These libraries typically provide tools for model serialization, which involves saving the model's architecture and learned parameters to a file, allowing the model to be easily loaded and used for inference in different environments.

In summary, while there is no specific information about the process used to deploy a trained deep learning model in the provided context, it can be inferred that platforms like AWS Kinesis and Apache Kibana likely have built-in capabilities for deploying models. Additionally, in the context of edge computing and event-stream processing, models could be deployed directly on sensors or at the edge of the cluster for data transformation and processing. Deep learning frameworks typically provide tools for model serialization, allowing models to be easily loaded and used for inference in different environments.