Based on the provided context, there is no explicit information about specific postprocessing steps such as Saliency maps, Metrics calculation, or Confusion matrix. However, we can infer some general postprocessing steps from the information given about the data partitioning and model assessment.

After the model training, the performance and generalizability of the optimal model are evaluated using the test set, which is a part of the data partitioning process. The raw dataset was randomly shuffled and divided into training, validation, and test sets with a data partitioning ratio of 8:1:1. The training set was used to learn the parameters of the model during the training process, and the validation set was used to evaluate the modeling and tune its hyperparameters. The optimal model was obtained based on the R-value, which was maximized using the grid search method.

Moreover, the context provides information about the MLP model and model assessments, where the optimal model was obtained with an R-value of 0.76. Table 2 in the context shows the optimal MLP architecture and parameters, which can be used to calculate metrics such as accuracy, precision, recall, and F1-score. These metrics can be calculated to evaluate the performance of the model further.

Therefore, while the context does not explicitly mention postprocessing steps such as Saliency maps, Metrics calculation, or Confusion matrix, we can infer that general postprocessing steps include evaluating the model's performance using the test set and calculating metrics to assess the model's accuracy.