Based on the provided context, there is not enough information to explicitly determine the specific hyperparameters used in the deep learning model, such as the learning rate or the optimizer. However, we do know that a Convolutional Neural Network (CNN) was used in the study by Ma, L. et al. (2022) for pest hazard class classification.

In general, for a CNN model, common hyperparameters include:

1. Learning rate: This controls the size of the steps in the gradient descent process during training. A learning rate that is too high may cause the model to converge too quickly to a suboptimal solution, while a learning rate that is too low may cause the training process to be very slow.

2. Optimizer: This is the algorithm used to update the model's weights based on the gradient of the loss function. Common optimizers include Stochastic Gradient Descent (SGD), Adam, and RMSprop.

3. Number of layers and number of neurons per layer: These parameters control the complexity of the model. A model with more layers or more neurons per layer will generally be more powerful but also more prone to overfitting.

4. Regularization techniques: These are used to prevent overfitting by adding a penalty term to the loss function. Common regularization techniques include L1 and L2 regularization, and dropout.

5. Batch size: This is the number of samples used in each update of the model's weights. A larger batch size can lead to more stable gradients but may require more memory.

Without more specific information from the study, it is not possible to provide the exact hyperparameters used. However, based on general CNN practices, these are the hyperparameters that would typically be considered.