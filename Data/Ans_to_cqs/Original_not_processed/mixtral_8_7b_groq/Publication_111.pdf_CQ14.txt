Answer:::

The hyperparameters of the machine learning models used in the proposed system are optimized using a grid search approach. In this method, a systematic search is conducted over a grid of hyperparameter values, and the combination that results in the best performance is selected. This process is applied to each of the four models employed in the system: Linear Regression, Support Vector Regression (SVR), Decision Tree (DT), and Random Forest (RF).

For instance, in the case of SVR, several hyperparameters such as degree, kernel, epsilon, and gamma are adjusted to achieve the highest accuracy. Similarly, for RF, a grid search is performed to determine the optimal values for hyperparameters like max_depth, max_features, min_samples_leaf, and min_samples_split.

It is important to note that hyperparameter tuning is a compute-intensive procedure due to the large number of possible combinations that need to be tested and the computational resources required. In the proposed model, a distributed asynchronous approach is utilized to obtain the optimal model hyperparameters. Specifically, the Tree Parzen Estimator (TPE) method in the Hyperopt package is employed for parameter finding and optimization.

In summary, the hyperparameters of the machine learning models in the proposed system are optimized using a grid search approach, where a systematic search is conducted over a grid of hyperparameter values to find the combination that results in the best performance. Additionally, a distributed asynchronous approach is utilized to determine the optimal model hyperparameters.