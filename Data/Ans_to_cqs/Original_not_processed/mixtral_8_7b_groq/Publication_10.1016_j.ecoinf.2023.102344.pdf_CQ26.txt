Based on the provided context, there is no explicit mention of the techniques used to address data bias during the preprocessing of the deep learning pipeline. However, the text does discuss some preprocessing techniques used in the image-based pre-trained networks. These techniques include Principal Component Analysis-Neighbor Component Analysis (PCA-NCA) integration for feature extraction in Approach 1 and using the built-in architecture of pre-trained deep networks to extract millions of possible features in Approach 2.

Regarding data bias, the techniques commonly used to address this issue during preprocessing include:

1. Stratified splitting: This technique involves dividing the dataset into subgroups based on specific criteria (e.g., class labels) and then randomly splitting each subgroup into training, validation, and testing sets. This ensures that each set has a similar distribution of subgroups, reducing bias.
2. Oversampling: This technique involves increasing the number of instances of the minority class to balance the dataset. This can be done by randomly duplicating instances or using techniques like Synthetic Minority Over-sampling Technique (SMOTE) to generate new instances.
3. Undersampling: This technique involves reducing the number of instances of the majority class to balance the dataset. This can be done randomly or by using techniques like NearMiss to select instances based on their similarity to the minority class.
4. Diverse data collection: This technique involves collecting data from various sources and ensuring that the dataset is representative of the population. This can help reduce bias by ensuring that the dataset includes instances from all relevant subgroups.

Therefore, while the provided context does not explicitly mention these techniques, they are commonly used to address data bias during preprocessing in deep learning pipelines.