The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it is mentioned that the authors use Convolutional Neural Networks (CNNs) or Deep learning methods for ecoacoustic assessment. These methods typically include strategies to monitor model performance during training such as validation and testing datasets, and metrics like accuracy, loss, and precision.

In general, during the training of a deep learning model, a portion of the dataset is set aside as a validation set. The model's performance is evaluated on this validation set after each epoch (iteration) of training. This allows for the monitoring of the model's performance and the detection of overfitting, which occurs when the model performs well on the training data but poorly on new, unseen data.

Moreover, the authors mention that they use annotated training data to automatically extract features that discriminate different classes in the dataset. This suggests that they might also be using techniques like cross-validation, where the data is split into multiple folds, and the model is trained and evaluated on different subsets of the data. This can provide a more robust estimate of the model's performance.

In addition, deep learning models often have loss functions that are used to quantify the difference between the model's predictions and the actual values. Monitoring the loss function during training can provide insights into how well the model is learning and can help detect issues like overfitting or underfitting.

However, without more specific information from the provided context, it is not possible to give a definitive answer about the exact strategy used to monitor the model's performance during training.