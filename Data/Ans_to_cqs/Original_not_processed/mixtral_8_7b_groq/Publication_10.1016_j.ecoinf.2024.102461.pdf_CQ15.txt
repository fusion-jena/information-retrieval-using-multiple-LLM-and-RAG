The provided context does not directly discuss the optimization techniques used in deep learning pipelines such as Stochastic Gradient Descent (SGD) or Adam. However, it does mention the use of machine learning algorithms and artificial neural networks in the creation of fire risk maps.

Artificial neural networks (ANNs) are a type of deep learning model that can be optimized using techniques such as SGD and Adam. ANNs are composed of interconnected nodes or "neurons" that process input data and produce output predictions. During training, the weights and biases of these neurons are adjusted to minimize the difference between the predicted output and the actual output.

Optimization techniques like SGD and Adam are used to update the weights and biases of the neurons in an efficient and effective manner. SGD is a simple optimization algorithm that updates the weights and biases based on the gradient of the loss function with respect to the current weights and biases. Adam, on the other hand, is a more advanced optimization algorithm that adaptively adjusts the learning rate based on the historical gradient information.

In the context of fire risk mapping, machine learning algorithms such as Support Vector Machine, Multilayer Perceptron Neural Network, and Random Forests are used to classify fire risk into different categories. While the specific optimization techniques used in these algorithms are not mentioned, it is likely that they employ some form of gradient-based optimization to adjust the model parameters during training.

In summary, while the provided context does not directly discuss the optimization techniques used in deep learning pipelines, it does mention the use of machine learning algorithms and artificial neural networks in the creation of fire risk maps. Optimization techniques such as SGD and Adam are commonly used to train deep learning models, including ANNs, by adjusting the weights and biases of the neurons to minimize the loss function.