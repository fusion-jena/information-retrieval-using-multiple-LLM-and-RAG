Based on the provided context, there is no explicit mention of strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, there is a mention of data augmentation techniques used to increase the amount of tree species samples for training the deep learning network. These techniques include randomly rotating, mirroring, and flipping the tree samples in the form of patches. This process can be considered as a way to introduce controlled randomness in the data preparation phase, which can help improve the model's performance and reduce overfitting.

Additionally, the context indicates that the VGG16 network was employed at 140,000 iterations as the classification model for tree species prediction. Deep learning models like VGG16 often have stochastic components, such as random weight initialization and dropout regularization, which inherently introduce some level of randomness during training. However, the context does not provide information on whether a fixed random seed value was used to ensure reproducibility of the results.

In summary, while the provided context does not explicitly discuss strategies for handling randomness in the deep learning pipeline, such as using a random seed value, it does mention the use of data augmentation techniques and the inherent randomness in deep learning models like VGG16.