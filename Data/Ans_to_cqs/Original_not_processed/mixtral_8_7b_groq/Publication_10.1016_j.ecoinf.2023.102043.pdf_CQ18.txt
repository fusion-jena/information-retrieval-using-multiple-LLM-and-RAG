Answer:::

The strategy implemented to monitor the model performance during training involves the use of a validation set, which is a subset of the dataset that is separate from both the training and testing sets. Specifically, the dataset is divided into 70% for training, 10% for validation, and 20% for testing.

During the training process, the model's performance is evaluated on the validation set after each epoch, which is a complete pass through the entire training dataset. This allows for the monitoring of the model's performance in real-time and the ability to identify any issues, such as overfitting, that may arise during training.

Additionally, the use of a validation set allows for the adjustment of hyperparameters, such as the learning rate, to optimize the model's performance. This is done by evaluating the model's performance on the validation set for different hyperparameter values and selecting the values that result in the best performance.

Furthermore, the model's performance is also evaluated on the testing set, which is a separate subset of the dataset that has not been used in any way during the training process. This provides an unbiased evaluation of the model's performance on new, unseen data.

It's also worth noting that the model for extracting the embeddings is based on YAMNet, a pre-trained model available on Tensorflow, which has been fine-tuned on the specific task of goat vocalization detection. This approach allows to leverage the knowledge acquired by the pre-trained model on a large dataset and adapt it to the specific task, improving the model's performance.

In summary, the strategy implemented to monitor the model performance during training involves the use of a validation set for real-time performance monitoring, hyperparameter tuning, and the evaluation of the model's performance on a testing set. Additionally, the use of a pre-trained model for extracting the embeddings allows to improve the model's performance.