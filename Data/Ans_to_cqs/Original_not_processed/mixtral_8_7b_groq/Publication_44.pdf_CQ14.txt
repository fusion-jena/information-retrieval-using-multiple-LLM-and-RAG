Answer:::

The context does not provide specific information on how the hyperparameters of the models are optimized. However, it mentions that during the training of the Faster R-CNN model, a threshold was set for the Non-Maximum Suppression (NMS) method. This threshold was used to select the best performing model based on the validation loss at the end of the training process.

In addition, the context mentions the use of Atrous convolutions with different dilation rates in the DeepLabV3 model. The dilation rate is a hyperparameter that controls the expansion of the kernel without increasing the number of parameters. This implies that some form of hyperparameter tuning was performed to determine the optimal dilation rates for the Atrous convolutions.

Furthermore, the context mentions that the proposed method requires a large training sample to maintain a good performance. This suggests that the hyperparameters of the proposed method were optimized using a training dataset, although the specific method of optimization is not mentioned.

The context also mentions that the YOLOv5s model was used, but there is no information on how its hyperparameters were optimized.

In summary, while the context provides some information on the use of hyperparameters in the models, it does not explicitly mention the specific methods used for hyperparameter optimization.