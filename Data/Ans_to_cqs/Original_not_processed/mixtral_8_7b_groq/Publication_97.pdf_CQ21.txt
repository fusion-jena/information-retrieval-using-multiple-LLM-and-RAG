Based on the provided context, there is no explicit information about the postprocessing steps applied after the model training, such as saliency maps, metrics calculation, or confusion matrix. However, it is mentioned that the network training assessment was performed on sub-images generated from image #2, and images #4 and #6 were used for visualization and demonstration of the algorithm's eﬃcacy.

Additionally, the paper discusses several techniques used during the training phase, such as:

1. Data augmentation: Randomly cropping source images to 256 × 256 resolution and applying augmentation.
2. Batch normalization: A technique used to accelerate deep network training by reducing internal covariate shift (Ioﬀe & Szegedy, 2015).
3. Dropout: A simple way to prevent neural networks from overfitting (Srivastava et al., 2014).

These techniques are applied during the training phase to improve the model's performance and generalization.

In summary, while the context does not explicitly mention postprocessing steps like saliency maps, metrics calculation, or confusion matrix, it does discuss techniques applied during the training phase. For a comprehensive understanding of the postprocessing steps, additional context would be required.

Answer:::
(As mentioned earlier, there is no explicit information about postprocessing steps in the provided context. The answer above summarizes the techniques applied during the training phase.)