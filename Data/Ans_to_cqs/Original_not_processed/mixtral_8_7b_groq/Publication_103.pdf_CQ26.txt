Based on the provided context, there is no explicit mention of specific techniques such as stratified sampling, oversampling, undersampling, or diverse data collection being used for addressing data bias during the pre-processing phase of the deep learning pipeline. However, it is mentioned that certain measures were taken to avoid bias during the data separation for training and testing.

For herbarium datasets H255 and H1K, data was separated so that sheets of the same species collected by the same collector did not enter both the training and testing sets. For the CR dataset, data was separated so that images of different leaves from each specimen were present in either the training or the testing set, but not in both. For the PlantCLEF (PC) dataset, separation was done at the observation level, ensuring no same observation was present in both training and testing subsets. These measures aim to create more realistic and unbiased training/testing scenarios, even though they might lead to lower accuracy rates.

In summary, while the text does not explicitly mention the use of techniques like stratified sampling, oversampling, undersampling, or diverse data collection for addressing data bias during pre-processing, it does describe specific strategies for separating the data during training and testing to minimize bias.