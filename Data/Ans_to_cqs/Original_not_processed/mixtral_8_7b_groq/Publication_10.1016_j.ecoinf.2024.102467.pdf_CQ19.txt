The provided context does not give specific information about the deep learning frameworks used to build the model. However, it mentions several architectures and techniques that were used in its design.

The backbone of the model is designed to improve the training speed while ensuring detection accuracy and speed, based on a network where the speed is increased by 11 times and the number of parameters is reduced by 1/6.8 (Tan & Le, 2021).

The EfficientNetV2 network is used as an efficient, lightweight feature extraction network. The EfficientNetV2 series reduces the number of parameters and computations while preserving the accuracy of the model, leading to significant decreases in model training and inference duration (Tan & Le, 2021).

A bottleneck transformer, specifically BoTNet, is used to replace the 3 × 3 spatial convolutions in ResNet’s last three bottleneck blocks with multi-head self-attention (Srinivas et al., 2021).

The Neck section used in the study is based on the neck section of YOLOv5. The BottleneckCSP structure in the neck module plays a primary role in feature fusion, and the CBAM is used to enhance the network's ability to extract and strengthen important features.

Therefore, while the context does not provide information on the specific deep learning frameworks used, it does mention several architectures and techniques that were used in the design of the model.

References:
Srinivas, B., Rao, R. R., & Vasconcelos, N. (2021). Bottleneck Transformers for Visual Recognition.
Tan, M., & Le, Q. V. (2019). Efficientnet: Rethinking model scaling for convolutional neural networks.
Tan, M., & Le, Q. V. (2021). The EfficietNetV2: A New Baseline for Image Classification.