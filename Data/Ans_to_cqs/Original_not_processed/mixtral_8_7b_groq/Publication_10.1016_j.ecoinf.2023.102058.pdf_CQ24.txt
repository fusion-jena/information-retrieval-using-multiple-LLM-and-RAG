Answer:::

In the context provided, there is no direct mention of strategies employed to handle randomness in deep learning pipelines, such as setting a random seed value. However, there are some related discussions on the importance of certain parameters and techniques that could indirectly influence the management of randomness.

One such parameter is the number of trees (ntrees) in ensemble machine learning algorithms, such as Random Forests. In the study "Ensemble machine-learning-based framework for estimating total nitrogen concentration in water using drone-borne hyperspectral imagery of emergent plants: A case study in an arid oasis, NW China" (Environ. Pollut. 266, 115412), a grid search was used to find the best number of trees, which was 500. This process of tuning the number of trees could be seen as a way to manage randomness, as increasing the number of trees can improve model performance (Belgiu and Drăguţ, 2016) but also increases computation time.

In the context of hyperspectral data and machine learning algorithms for predicting water quality parameters, the study "This study evaluates the ability of EnMAP simulated data coupled with machine learning algorithms to predict two critical water quality properties for inland waters (i.e., Chl-a and TSS)" (EcologicalInformatics75(2023)1020589) discusses the importance of creating a representative dataset by considering the number and spatial distribution of samples. While not directly related to randomness, the creation of a robust dataset can help reduce the impact of randomness on model performance.

In the field of chemometrics, the paper "PLS-regression: a basic tool of chemometrics" (Wold, S., Sjöström, M., Eriksson, L., 2001) discusses the use of Partial Least Squares Regression (PLS-R), a technique that can handle collinearity in data, which is common in hyperspectral data. PLS-R decomposes data into orthogonal factors, which can help manage the randomness inherent in the data.

In conclusion, while the context does not directly mention strategies employed to handle randomness in deep learning pipelines, there are discussions on parameters and techniques (e.g., number of trees, creating a representative dataset, and using PLS-R) that can indirectly influence the management of randomness.