Answer:::
The strategy implemented to monitor the model performance during training involves using two distinct datasets, namely the train and test datasets. The models' performance is evaluated on both datasets to ensure that the models are not overfitting the training data. Overfitting occurs when a model learns the training data too well, including its noise, and performs poorly on unseen data.

The train dataset is used to fit the models, and the test dataset is utilized to assess the models' performance. This approach allows for the monitoring of how well the models generalize to new, unseen data. The test dataset serves as an independent dataset to validate the models' predictive capabilities.

The models' performance is evaluated using several metrics, including the coefficient of determination (R2), Root Mean Square Error (RMSE), relative Root Mean Square Error (rRMSE), and Mean Absolute Error (MAE). R2 measures the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R2 value indicates a better fit. However, R2 alone is not sufficient to evaluate model performance, especially for regression problems. Therefore, RMSE, rRMSE, and MAE are also used. RMSE measures the standard deviation of the prediction errors, while rRMSE expresses RMSE as a percentage of the observed variable's standard deviation. MAE measures the average magnitude of the errors. Lower RMSE, rRMSE, and MAE values indicate better model performance.

The models' performance on the test dataset is compared to their performance on the train dataset. If a model's performance on the test dataset is significantly worse than on the train dataset, it suggests that the model is overfitting the train data. To address overfitting, the hyperparameters of the models are tuned using grid search. The optimized hyperparameter values for each model are presented in Table 4.

For instance, the Elastic Net (Enet) model's hyperparameters Î± and l1_ratio are tuned to improve its performance. Similarly, for the Support Vector Machine (SVM) model, the cost (C), gamma, kernel, and epsilon parameters are optimized. The Random Forest (RF), Extreme Gradient Boosting (Xgboost), and Light Gradient Boosting Machine (LightGBM) models also have their hyperparameters optimized to enhance their performance and prevent overfitting.

In summary, the strategy to monitor the models' performance during training involves using a test dataset, comparing the models' performance on the train and test datasets, and tuning the models' hyperparameters using grid search to prevent overfitting.