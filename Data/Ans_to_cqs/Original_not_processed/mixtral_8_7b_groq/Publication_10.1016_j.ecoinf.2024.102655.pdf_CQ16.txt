Answer:::

The provided context does not give specific information about the criteria used to determine when training is complete in the study, such as when validation loss plateaus or other convergence criteria are met. However, it does provide details about the dataset splitting strategy and the evaluation measurements used to compare the performance of different machine learning models.

The study used a Best Training Subset (BTS) consisting of data from 2009 to 2015 (n = 409) and compared it with the full dataset (13 MS) including water quality data for the same period (n = 894). The complete set of sites covered data from 2016 to 2020 (n = 657) for validation, and the period from 2021 to 2022 and all site data were used for testing (n = 372). The evaluation measurements (RMSE, MSE, MAE, and R2) for ANFIS, ANN, and SVM models were calculated for each step (training, validation, and testing).

The study found that ANFIS models trained with the full dataset had significantly higher evaluation measurements compared to those trained with BTS, while ANN and SVM models trained with both the full dataset and BTS showed slight improvements when using the full dataset. The authors suggest that analyzing historical trends in water quality data can help select more variable and representative scenarios for machine learning model training, potentially improving predictive outputs.

In summary, while the provided context does not give specific information about the criteria used to determine when training is complete, it does offer insights into the dataset splitting strategy, evaluation measurements, and the performance of different machine learning models in the study.