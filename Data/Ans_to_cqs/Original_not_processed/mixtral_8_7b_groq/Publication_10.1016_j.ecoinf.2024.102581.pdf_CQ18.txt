Answer:::

The strategy implemented to monitor the model performance during training involves the use of two key metrics: accuracy and loss, which are plotted on graphs to visualize the model's performance over a specified number of iterations, known as epochs.

The accuracy graph measures the percentage of correct predictions made by the model, and the loss graph measures the error or discrepancy between the model's predictions and the actual values. Both graphs have two lines, one for the training results (in blue) and one for the validation results (in orange). These lines help to identify the trend and pattern of the model's performance during training.

By monitoring the accuracy and loss graphs, it is possible to determine if the model is improving or degrading in performance. Ideally, as the number of epochs increases, the accuracy curve should show that the model's classification performance improves, while the loss curve should decrease. However, if the accuracy curve starts to flatten or decrease, or if the loss curve starts to increase, it may indicate that the model is overfitting or underfitting the training data.

To prevent overfitting, a technique called dropout is used. Dropout involves randomly dropping out a proportion of neurons during training, which helps the model to reduce the gap between the training and validation results and improve its generalizability.

Additionally, the model's hyperparameters, such as the number of convolution layers, filters, filter size, number of neurons, batch size, and epochs, are explored within a specified range to find the optimal combination of hyperparameters that result in the best model performance.

In summary, the strategy implemented to monitor the model performance during training involves the use of accuracy and loss graphs, dropout, and hyperparameter tuning. These techniques help to ensure that the model is improving in performance, not overfitting, and has the optimal combination of hyperparameters for the best possible performance.