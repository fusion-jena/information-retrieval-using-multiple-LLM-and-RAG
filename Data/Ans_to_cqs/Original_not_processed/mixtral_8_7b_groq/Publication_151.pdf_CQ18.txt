Answer:::
The strategy implemented to monitor the model performance during training involves the use of a running average of the recent magnitude of the loss function to speed up training, as proposed by Tieleman and Hinton (2012). Specifically, the training loss is checked every 50 epochs, which are cycles of the algorithm through the entire training dataset. If the value of the loss function fails to decrease in two consecutive checks, the training is stopped. This approach allows for the early termination of the training process if the model is not improving, thereby saving computational resources. The model with the optimal objective function value, i.e., the lowest loss function value, is chosen as the final model. This strategy ensures that the model performance is continuously monitored during training, and the training process is stopped when the model is no longer improving, preventing overfitting and reducing training time.