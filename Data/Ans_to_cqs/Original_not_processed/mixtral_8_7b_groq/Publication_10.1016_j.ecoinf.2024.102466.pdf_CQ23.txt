Based on the information provided, it is not explicitly stated what measures were taken to ensure the generalizability of the deep learning model. However, there are some clues that suggest that some steps were taken to ensure the model's performance in complex, real-world ecological settings.

Firstly, the dataset used for training and validation is quite diverse, consisting of 12,612 instances of birds, which is a significant number for a single dataset. This diversity in the dataset can help the model to generalize better to new, unseen data.

Secondly, the authors have compared the performance of various models, including Cascade RCNN, FCOS, Sparse CNN, Faster CNN, and ATSS, among others. This comparison helps to ensure that the chosen model is not overfitting to the training data and can perform well on different types of models.

Thirdly, the authors have mentioned that they have evaluated the models' performance at different training stages. This evaluation can help to ensure that the model does not overfit to the training data and can perform well on new, unseen data.

Lastly, the authors have mentioned that they have used a suitable number of training times for different models, which can help to prevent overfitting and ensure the model's generalizability.

Therefore, while the text does not explicitly mention techniques such as cross-validation or stratified splitting, it does suggest that some steps were taken to ensure the generalizability of the deep learning model. These steps include using a diverse dataset, comparing the performance of different models, evaluating the models at different training stages, and choosing a suitable number of training times for different models.