The provided context does not contain direct information about strategies employed to handle randomness in the deep learning pipeline. However, it does discuss various topics related to machine learning and species distribution modeling.

In general, handling randomness in deep learning pipelines can be approached through various strategies, such as:

1. **Initialization of weights**: Deep learning models typically initialize weights randomly. Strategies like Xavier initialization (Glorot & Bengio, 2010) and He initialization (He et al., 2015) aim to ensure that the variance of the inputs to each layer is of a similar magnitude, which helps in training the model more efficiently.

2. **Regularization**: Techniques like dropout (Srivastava et al., 2014) and weight decay (also known as L2 regularization) are used to prevent overfitting and improve the generalization of deep learning models. Dropout randomly sets a fraction of the input units to zero during training, while weight decay adds a penalty term to the loss function to reduce the magnitude of the weights.

3. **Data shuffling and splitting**: To ensure that the model does not overfit or underfit specific patterns in the data, it is common practice to shuffle the dataset before splitting it into training, validation, and test sets. This process helps to randomize the order of the data and ensures that the model is exposed to different patterns during training.

4. **Batch normalization**: This technique (Ioffe & Szegedy, 2015) normalizes the inputs of each layer, which helps reduce internal covariate shift and improves the training process. Batch normalization introduces a small amount of randomness during training by sampling a mini-batch of data.

5. **Random seed**: Setting a random seed value ensures that the random processes in the deep learning pipeline, such as weight initialization, data shuffling, and dropout, are reproducible. This is useful for debugging, comparing different models, and tracking the progress of training.

Although the provided context does not discuss these specific strategies, they are commonly used in deep learning and machine learning to handle randomness and improve model performance.

References:
- Glorot, X., & Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, 249–256.
- He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. Proceedings of the IEEE International Conference on Computer Vision, 1026–1034.
- Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1), 1929–1958.
- Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. International Conference on Machine Learning, 379–387.