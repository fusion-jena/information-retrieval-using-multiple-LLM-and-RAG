Based on the provided context, there is no explicit information about how the hyperparameters of the model were optimized. The context includes several papers that discuss the use of deep learning models for various applications, such as image classification, game playing, and image super-resolution. However, none of these papers provide details about the hyperparameter optimization methods used.

Hyperparameter optimization is an important step in the development of machine learning models. It involves selecting the values of various parameters, such as learning rate, regularization strength, and number of layers, that can significantly impact the model's performance. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization.

Without specific information from the provided context, it is not possible to provide a definitive answer to the query. However, it is worth noting that some of the papers cited in the context use well-established deep learning frameworks, such as TensorFlow and Keras, which have built-in functions for hyperparameter optimization. Therefore, it is possible that the authors used these functions to optimize the hyperparameters of their models.

In summary, while the provided context does not contain explicit information about the hyperparameter optimization method used, it is possible that the authors used built-in functions in deep learning frameworks to optimize the hyperparameters of their models.