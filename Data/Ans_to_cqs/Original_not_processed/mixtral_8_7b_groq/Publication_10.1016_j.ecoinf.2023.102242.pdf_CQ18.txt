Based on the provided context, there is no explicit description of the strategy implemented to monitor the model performance during training. However, the context does discuss the classification method and data processing, as well as the kappa values, which can provide some insight into the model performance.

The kappa values, which range from 0.8458 to 0.9159, indicate good to excellent agreement between the predicted and actual values. Kappa is a statistical measure that is commonly used to assess the accuracy of classification models. It takes into account the possibility of the agreement occurring by chance, and provides a more robust measure of model performance than simple accuracy.

Additionally, the context mentions that future research should focus on refining the subsequent classification process to yield more reliable results. This suggests that the researchers are actively monitoring the model performance and looking for ways to improve it.

Overall, while there is no explicit description of the strategy used to monitor the model performance during training, the kappa values and the mention of refining the classification process suggest that the researchers are actively monitoring and evaluating the model performance. It is likely that they are using standard techniques such as cross-validation, monitoring the training and validation loss, and tracking other performance metrics to ensure that the model is performing well and not overfitting to the training data.