Based on the provided context, there is no information about the specific criteria used to split the data for deep learning model training. The context focuses on the use of a baseline model, the random forest, and the process of iterative model exploration. It explains the use of training scores and validation scores for numerical scores, but it does not mention deep learning models or the criteria used to split the data for such models.

In general, when training deep learning models, it is common to split the data into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and make decisions during the training process, and the testing set is used to evaluate the final model's performance.

The criteria used to split the data can vary. A common approach is to use a random split, where a certain percentage of the data is assigned to each set. For example, 70% of the data might be used for training, 15% for validation, and 15% for testing. Alternatively, a time-based split might be used, where earlier data is used for training and later data is used for testing. Stratified sampling can also be used to ensure that each set has a representative distribution of the target variable.

In conclusion, while the provided context does not give specific information about the criteria used to split the data for deep learning model training, it is common to use a random split, time-based split, or stratified sampling for this purpose.