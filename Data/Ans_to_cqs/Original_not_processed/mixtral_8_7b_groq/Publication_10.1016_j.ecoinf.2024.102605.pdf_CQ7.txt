Based on the provided context, there are no specific criteria mentioned for splitting the data into training, testing, and validation sets for deep learning model training. However, there are some general practices followed in the field of machine learning and deep learning for splitting the data.

In general, the data is split into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune the model's hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

The most common way to split the data is to use a 70-15-15 or 80-10-10 split for training, validation, and testing sets, respectively. This means that 70% or 80% of the data is used for training, 15% is used for validation, and the remaining 15% or 10% is used for testing.

Another way to split the data is using cross-validation, where the data is split into k folds, and the model is trained and validated k times, each time with a different fold as the validation set. The average performance of the k models is then used as the final performance measure.

In some cases, the data is split based on the temporal or spatial distribution of the data. For example, in time series forecasting, the data is usually split into training, validation, and testing sets based on time, where the training set contains data up to a certain time, the validation set contains data from the next period, and the testing set contains data from the most recent period.

In the context of the studies provided, there is no mention of how the data was split for training the deep learning models. However, based on general practices, it can be assumed that the data was split using one of the methods mentioned above.