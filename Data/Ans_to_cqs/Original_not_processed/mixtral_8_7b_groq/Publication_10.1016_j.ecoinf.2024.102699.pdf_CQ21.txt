Based on the provided context, there is no explicit information about the postprocessing steps applied after training the models. However, it does mention some details about the evaluation metrics that could be used to assess the model's performance.

In the context, it is mentioned that the models are trained for birdsong classification, and the training process includes data augmentation techniques such as pitch shifting, time stretching, mix up, Gaussian noise, and others. The models' performance is affected by these augmentation techniques, with an observed trend of increased or decreased classification capabilities.

To alleviate class imbalances, the focal loss was introduced to the training process. The augmentation techniques were applied to the training samples with a 50% probability factor, and future investigations should compare the differences in classification capabilities with different probability factors.

Additionally, the context provides information about the investigated ViT models, their parameterizations, and the training and testing times.

Considering common practices in machine learning model training and evaluation, we can infer some possible postprocessing steps that might have been applied:

1. Metrics calculation: After training and testing the models, various evaluation metrics could be calculated to assess the model's performance. These metrics might include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC).

2. Confusion matrix: A confusion matrix is a table that is often used to describe the performance of a classification model. It can provide information about true positives, true negatives, false positives, and false negatives, which can be used to calculate additional evaluation metrics.

3. Saliency maps: Saliency maps are a technique used to visualize the importance of input features for a model's prediction. While the context does not explicitly mention saliency maps, they can be a useful tool for understanding a model's decision-making process.

It is important to note that these are possible postprocessing steps based on common practices, but they are not explicitly mentioned in the provided context.