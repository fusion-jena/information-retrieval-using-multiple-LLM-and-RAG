The context provided does not give specific information about the hardware resources used for training the deep learning models. It mentions different types of Convolutional Neural Network (CNN) architectures such as ResNet, VGGish, MobileNetv2, and CNN-XC, which are often used for image-based and bioacoustic classification tasks. However, it does not specify the hardware used for training these models.

Training deep learning models like CNNs typically requires substantial computational resources, including Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). These hardware resources enable parallel processing, which significantly speeds up the training process compared to using a Central Processing Unit (CPU) alone.

In general, data scientists and researchers use cloud-based platforms like Google Colab, AWS SageMaker, or Microsoft Azure to access GPU or TPU resources for training deep learning models. These platforms provide preconfigured environments with accelerated hardware, making it easier for users to train and test their models without investing in expensive hardware.

In summary, while the context does not explicitly mention the hardware resources used for training the deep learning models, it is common practice to use GPUs or TPUs for training CNNs. Cloud-based platforms are popular choices for accessing these hardware resources.