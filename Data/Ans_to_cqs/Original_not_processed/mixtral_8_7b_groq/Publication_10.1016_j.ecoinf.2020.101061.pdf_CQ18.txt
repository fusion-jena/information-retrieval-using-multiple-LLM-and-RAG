Answer:::
The strategy implemented to monitor the model performance during training involves using a technique called ablation analysis. This method evaluates the model's performance by training it using different proportions of hand-annotated data. Specifically, the models were trained using 5%, 25%, 50%, and 75% of the total hand-annotations, and this process was repeated five times for each site to account for the random subsampling of annotations. The performance of these models was then compared to the full dataset for the within-site results for each site. Additionally, the evaluation plots for the pretraining model only (i.e. 0% hand-annotated data) were assessed to determine whether the addition of hand-annotated data improved the within-site pretraining.

The results of this analysis are presented in Figure 7, which shows the ablation curves of the proportion of hand-annotation training data for each site. The values in the figure represent the number of trees in the training dataset for each cutoff, and the shaded area represents the range of results from rerunning the analysis five times for each site. The exact number of trees will vary slightly due to the random sampling among runs, but the mean number of training trees for each threshold is shown for simplicity.

This strategy allows for the monitoring of model performance during training by evaluating the impact of different amounts of hand-annotated data on the model's performance. By using this approach, the researchers can determine the optimal amount of training data needed to achieve maximum performance, which is particularly useful in the context of airborne imagery where collecting a sufficient number of training samples can be a bottleneck.