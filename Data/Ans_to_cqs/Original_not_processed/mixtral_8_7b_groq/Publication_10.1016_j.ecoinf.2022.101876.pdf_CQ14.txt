Based on the provided context, there is no explicit information given about how the hyperparameters of the model are optimized. The text does not mention any techniques used such as grid search, random search, or any other optimization methods. Therefore, I cannot provide a specific answer to this question.

However, the context does provide a table (Table A2) that shows the performance measures of a model called "MegaDetector" with different detection thresholds (0, 25, 50, 75). It is possible that the authors used these threshold values as a way to tune the model's performance, but this is not explicitly stated.

In general, hyperparameter optimization is an important step in machine learning model development. It involves selecting the best set of hyperparameters for a given model to minimize the error or maximize the performance on a validation set. Common methods for hyperparameter optimization include grid search, random search, Bayesian optimization, and gradient-based optimization.

Therefore, while the provided context does not give a clear answer to how the hyperparameters of the model were optimized, it is still possible that the authors used some form of hyperparameter tuning to achieve the results presented in the text.