Answer:::

The data for deep learning model training in the study described was split using a 5-fold cross-validation method. In this approach, the entire dataset was divided into five subsets or folds. For each fold, 80% of the dataset, referred to as Trainingclips, was used to train the deep learning model, while the remaining 20% was used as the testing set to assess the model's performance.

The authors specifically mention that they could not split the data directly at the image level because images from the same videos were very similar, which could lead to a model with low generalization capacity. To avoid this, they ensured full independence between the training and testing sets by performing the split at the video level rather than the image level.

The deep learning models used in this study were based on the NASnet architecture with a Faster-rcnn backbone, implemented in Tensorflow2. The models were trained for 200,000 iterations with a batch size of 16 images per iteration. The training was conducted using a GPU-cluster equipped with 4 RTX8000, and it took 96 hours per model.

The authors used several criteria to evaluate the performance of their deep learning models, including recall, precision, and F-measure. However, the specific values for these criteria are not provided in the context.

In summary, the data for deep learning model training in this study was split using a 5-fold cross-validation method, with 80% of the dataset used for training and 20% used for testing. The split was performed at the video level to ensure full independence between the training and testing sets. The models were evaluated based on recall, precision, and F-measure, although the specific values are not provided.