Based on the provided context, there is no information about data augmentation techniques such as flipping, rotating, or scaling being applied in the described deep learning pipeline. The context focuses on the use of a Variational Autoencoder (VAE) for learning latent representations of a dataset. It describes how the dataset was recorded at a different location and gradually expanded, and how the VAE model's architecture was designed with a limited latent dimension for visualization purposes.

The context then goes on to explain the VAE model's architecture, including the probabilistic encoder and decoder, and the optimization objective of the VAE, which consists of a reconstruction term and a regularization term. The trade-off between these two terms and its impact on the VAE's performance is also discussed.

Therefore, based on the given context, I cannot provide information on the data augmentation techniques used in the described deep learning pipeline.