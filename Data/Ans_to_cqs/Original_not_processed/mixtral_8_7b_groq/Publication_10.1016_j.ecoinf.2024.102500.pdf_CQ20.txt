Based on the information provided, there is no direct mention of the specific hardware resources used for training a deep learning model. The context focuses primarily on the description of various machine learning models, including the Light Gradient Boosting Machine (LGBM) and Gradient Boosting (GB) models, along with their respective hyperparameters.

However, it is important to note that the text mentions the use of the Python library for hyperparameter selection. While the library itself does not provide hardware resources, it can be configured to utilize Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) when available, depending on the specific deep learning framework in use, such as TensorFlow or PyTorch.

To provide a more definitive answer, additional context or information about the deep learning model implementation is required. Nonetheless, it is reasonable to assume that GPUs or TPUs might have been used for deep learning model training, considering the capabilities of modern machine learning libraries and frameworks.

Answer:::
Based on the provided context, there is no explicit mention of the hardware resources used for training a deep learning model. However, considering the use of Python libraries for hyperparameter selection and the general capabilities of machine learning frameworks, it is plausible that GPUs or TPUs were utilized for deep learning model training.