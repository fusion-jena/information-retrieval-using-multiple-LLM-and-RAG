Based on the provided context, there is not enough information to determine the specific preprocessing steps taken before training a deep learning model. The context focuses on discussing a model for environmental flow riparian ecosystem wetland biodiversity maintenance (FERM) and its parameters, but it does not mention any preprocessing techniques.

However, generally, when training deep learning models, data preprocessing is crucial and often involves several steps, such as:

1. Data cleaning: Removing or correcting erroneous or missing data points.
2. Data normalization: Scaling numerical data to a common range, often between 0 and 1, to avoid features with larger value ranges dominating the learning process.
3. Data scaling: Adjusting the range and distribution of features to improve model performance, such as standardization (zero mean and unit variance) or robust scaling (based on interquartile range).
4. Feature engineering: Creating new features from existing ones, such as polynomial or trigonometric transformations, interaction terms, or one-hot encoding for categorical variables.
5. Data splitting: Dividing the dataset into training, validation, and testing sets to assess model performance and prevent overfitting.

In the context of the FERM model, the authors might have applied some of these preprocessing techniques, but without further information, it is impossible to provide a definitive answer.