Based on the provided context, the specific criteria used to split the data for training, testing, and validation of the deep learning model are not mentioned. However, I can provide some general information about common practices for splitting data in machine learning models.

In the context of Table 7, the results presented are from a Multi-Layer Perceptron (MLP) model, which is a type of deep learning model. The MLP model was trained using a dataset, and the performance of the model was evaluated based on the training and testing RMS and accuracy rate. However, the context does not provide information on how the dataset was split into training, testing, and validation sets.

In general, when training a deep learning model, it is common to split the dataset into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune the hyperparameters of the model, and the testing set is used to evaluate the performance of the final model.

The size of each subset can vary depending on the size of the dataset and the specific problem being addressed. However, a common practice is to use 60-70% of the dataset for training, 10-15% for validation, and 15-20% for testing. It is important to note that the data should be randomly split to ensure that each subset is representative of the entire dataset.

In the context of the study, the data used for training the MLP model may have been split based on the number of requested samples per class. As shown in Table 7, the requested samples per class is 1688, which may have been split into training, validation, and testing sets. However, this is only a hypothesis, and the specific criteria used to split the data are not provided in the context.

Therefore, while the specific criteria used to split the data for the MLP model training are not provided in the context, it is common practice to split the dataset into training, validation, and testing sets in deep learning models. The size of each subset can vary, but a common practice is to use 60-70% of the dataset for training, 10-15% for validation, and 15-20% for testing.