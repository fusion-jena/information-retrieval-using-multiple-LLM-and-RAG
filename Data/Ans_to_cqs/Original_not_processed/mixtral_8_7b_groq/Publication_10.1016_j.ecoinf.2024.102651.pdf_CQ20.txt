The context provided does not give information about the specific hardware resources used for training the deep learning model. It focuses more on the description of the deep learning model's architecture, its components, and its performance. Therefore, I cannot provide an accurate answer to this query. However, it is common practice to use Graphics Processing Units (GPUs) for training deep learning models due to their ability to perform parallel processing, which significantly speeds up the training process compared to using Central Processing Units (CPUs). Additionally, there are specific hardware resources designed for machine learning tasks, such as Tensor Processing Units (TPUs) developed by Google, which are optimized for tensor operations commonly used in deep learning models.