Answer:::
The provided context does not give detailed information about the deployment of the trained deep learning model. However, it does mention some steps related to the training and pre-processing of the model that can be inferred.

Firstly, the model is trained using convolutional neural networks (CNNs) for 150 epochs with a batch size of 128. Dropout and ADAM optimisation are used to make the training more stable and to find optimal weights, respectively. The model is trained to minimize the cross entropy loss between the network’s predictions and the pre-labelled data.

Secondly, the data is pre-processed by splitting it into larger blocks based on coordinates for cross-validation. These blocks are then split into smaller areas of 80 × 80 pixels due to limitations in the available amount of data.

After the training and pre-processing, some post-processing is required to transform the result of the CNN into an easy-to-access GIS-resource. This includes rounding the pixel predictions from the CNN, converting the raster representation into a vector representation, and minimizing storage space for easier distribution.

However, the context does not provide information on model serialization or platform selection for deployment. Model serialization involves saving the trained model in a format that can be loaded and used for making predictions on new data. Platform selection refers to choosing the hardware and software environment where the model will be deployed, such as a local machine, cloud server, or edge device.

Therefore, while the context provides details on the training and pre-processing of the deep learning model, it does not answer the query regarding the deployment process.