Based on the provided context, there is no information about the specific metrics used to evaluate the performance of a deep learning model. The text focuses on the land use/cover dataset for China, the methodology for analyzing the contribution rates of different land use/cover types to Gravity Survey Number (GSN) changes, and several related studies.

However, it is common in deep learning and machine learning research to use metrics such as accuracy, precision, recall, F1-score, and area under the curve (AUC) to evaluate the performance of models. These metrics can provide insights into how well the model is classifying or predicting the desired outcomes.

Accuracy is the ratio of the number of correct predictions to the total number of predictions. Precision is the ratio of true positives (correctly predicted positive instances) to the sum of true positives and false positives (incorrectly predicted positive instances). Recall is the ratio of true positives to the sum of true positives and false negatives (missed positive instances). F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics. AUC measures the entire two-dimensional area underneath the entire ROC curve (receiver operating characteristic curve), which plots true positive rate against false positive rate.

In summary, the provided context does not contain information on the metrics used to evaluate the performance of a deep learning model. However, common evaluation metrics for deep learning models include accuracy, precision, recall, F1-score, and AUC.