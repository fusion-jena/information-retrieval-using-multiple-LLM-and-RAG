Answer:::
The hyperparameters used in the deep learning model include the learning rate and the optimizer. However, the specific values or types of these hyperparameters are not provided in the context. The models were built using PyTorch and trained on an Nvidia V100 GPU. The model was pre-trained on the ImageNet dataset and then fine-tuned on the PAD Full and PAD Lite datasets. A five-fold subject-exclusive strategy was applied to ensure that the same subject did not appear in the training and testing sets simultaneously. The images were downscaled to a resolution of 224 Ã— 224 pixels before being fed into the model. Aggressive data augmentation was applied to avoid overfitting and imbalanced problems.

The models used in the study include VGG-11-BN and VGG-16-BN, which are variants of the VGG net with batch normalization. The last three fully connected layers of the original VGG model were replaced with one fully connected layer to reduce parameters. The loss function used in the study is cross-entropy loss, as shown in equation (4) of the context.

Overall, while the specific learning rate and optimizer used in the model are not provided, the context gives a detailed description of the other hyperparameters and techniques used in the study, such as pre-training, fine-tuning, data augmentation, and loss function.