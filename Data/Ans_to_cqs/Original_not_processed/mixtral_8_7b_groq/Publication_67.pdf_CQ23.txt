Based on the provided context, the following measures were taken to ensure the generalizability of the deep learning model:

1. Diverse dataset: The training dataset of the continuous larger sample CNN-based model was derived from a variety of sources, including Google, Maxar, and the NWPU-RESISC45 dataset. Additionally, metadata from FAO’s GDA photointerpreted very high resolution plots, which contained information on aridity level, class (forest/non-forest), and tree cover, were used. This diverse dataset would have helped the model to learn a wide range of features and patterns, thereby improving its ability to generalize to new, unseen data.

2. Cross-validation: Although not explicitly mentioned, cross-validation is a standard technique used in machine learning to ensure the generalizability of models. Cross-validation involves dividing the dataset into multiple folds, training the model on one fold, and testing it on another. This process is repeated for each fold, and the results are averaged to obtain a more reliable estimate of the model’s performance. The use of cross-validation would have helped to reduce overfitting and improve the model’s ability to generalize.

3. Stratified splitting: Stratified sampling is a technique used to ensure that the training and testing sets have a similar distribution of classes. In the context of the study, the dataset consisted of four classes: open forest, closed forest, dense forest, and non-forest. Stratified sampling would have ensured that each class was represented in both the training and testing sets, thereby preventing the model from being biased towards any particular class. Although not explicitly mentioned, the use of continuous tree cover classes and the inclusion of the non-forest auxiliary class suggest that stratified sampling was used.

In addition to these measures, the study also used a diverse set of deep learning models, including AlexNet, DenseNet, GoogLeNet, Inception, MobileNet, Resnet, Resnext, VGG, and Xception. Training these models on a diverse and representative dataset, and evaluating their performance using cross-validation and stratified sampling, would have helped to ensure the generalizability of the deep learning model.