Based on the provided context, there is no explicit information about the specific criteria used to determine when training is complete in the described cross-validation scheme for XGBoost. However, it does mention that they monitor the performance on the validation set by calculating the out-of-sample prediction accuracy and taking the median of k-1 folds. This suggests that they might be using a form of early stopping, where the training process is halted if the performance on the validation set does not improve for a certain number of iterations.

In the context of machine learning, early stopping is a form of regularization used to avoid overfitting. The idea is to stop the training process before the model starts to memorize the training data, which can lead to poor generalization to unseen data. Early stopping is typically used when training models with many parameters, such as in boosting methods like XGBoost.

Moreover, the text mentions that large ensemble sizes in XGBoost can cause overfitting due to the gradient technique focusing on the most difficult cases, which can be caused by noise. Thus, using early stopping in the training process would be a reasonable approach to prevent overfitting and ensure better generalization of the model.

In summary, while the provided context does not explicitly state the criteria used to determine when training is complete, it can be inferred that they might be using early stopping as a form of regularization to prevent overfitting in the XGBoost model.