Answer:::

The hyperparameters of the model are optimized by using a systematic search over a grid of candidate values. In the context provided, the specific hyperparameter that is being optimized is the regularization parameter λ in Equation 16. The optimization process involves repeating the iterative optimization of the objective function in Equation 16 for 100 discrete candidate values of λ, which are chosen from a vector of equidistant values. After this, the value of λ that minimizes the Bayesian information criterion (BIC) is selected as the optimal value.

The specific method used to search over the grid of candidate values is not specified in the context provided. Grid search is one possible method, where the parameter space is divided into a grid of evenly spaced values, and the model is evaluated at each point on the grid. Another possible method is random search, where the parameter values are chosen at random from a specified distribution.

In addition to λ, other hyperparameters may also be optimized in a similar manner. For example, the vector parameter θ in the GFR and RBF-GFR models is optimized using the maximum likelihood estimator, which involves finding the values of the model parameters that maximize the likelihood function L(θ, z, y).

It is worth noting that grid search and random search can be computationally expensive, especially when the number of hyperparameters and the size of the grid are large. Other optimization methods, such as Bayesian optimization or gradient-based optimization, may be more efficient in some cases. However, the specific optimization method used for the models in the provided context is not specified.