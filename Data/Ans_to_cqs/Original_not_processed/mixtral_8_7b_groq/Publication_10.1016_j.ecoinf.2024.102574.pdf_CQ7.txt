Based on the provided context, there are no specific criteria mentioned for splitting the data when training deep learning models for classification of LiDAR and UAV point clouds for DTM creation and flood risk mapping. However, there are some general practices followed in the field of machine learning for splitting the data into training, testing, and validation sets.

The most common approach is to randomly split the dataset into three subsets: training, validation, and testing. Typically, 70% of the data is used for training, 15% for validation, and 15% for testing.

The training set is used to train the model by adjusting the model parameters to minimize the error between the predicted and actual values. The validation set is used to tune the hyperparameters of the model and prevent overfitting. Overfitting occurs when the model learns the training data too well, including its noise, and performs poorly on unseen data. The testing set is used to evaluate the final model performance on unseen data.

In some cases, stratified sampling is used to split the data, especially when the data is imbalanced. Stratified sampling ensures that each subset has a similar distribution of classes as the original dataset.

In the context of remote sensing and GIS, the data splitting criteria can also depend on the study area and the research question. For example, in the study by Qin et al. (2022), the authors used a random sampling method to split the data into training and testing sets. They used 70% of the data for training and 30% for testing.

Therefore, while the provided context does not mention specific criteria for splitting the data, it is common practice to use a random split of the data into training, validation, and testing sets, with the exact proportions depending on the specific study and research question.