Answer:::
The type of deep learning model used in the pipeline is a Long Short-Term Memory (LSTM) network, which is a specific type of Recurrent Neural Network (RNN). This choice is based on the study presented in Casarotti (2021), where several configurations of LSTM architecture were tested and compared with other RNN architectures such as Multilayer Perceptron (MLP) and Gate Recurrent Unit (GRU). The LSTM model proved to have better results than the MLP, reducing Root Mean Square Error (RMSE) by 5.70% for NO and by 15.23% for NO2.

The LSTM model has one hidden layer of y neurons, where y is determined based on the number of training observations, input neurons, and output neurons, and a value of Î± usually between 5 and 10. The number of previous observations was set to 12 (i.e., 2 hours of observations) after evaluating 6, 12, 24, and 48 previous observations.

The training set is pre-processed using a MinMaxScaler that transforms each feature by scaling it to a [0-1] range. A dropout layer is added as a regularization method to avoid overfitting, which randomly excludes some inputs from activation and weight updates while training a network.

The LSTM model was chosen as a trade-off between reaching good performances and minimizing the dimension of the training data, since the co-location period needs to be as short as possible and deep learning models usually need many input data. However, in cases where the size of the training dataset is restricted, the performance of LSTM models may prove to be inadequate, and the VR + SVR can provide better performance than the LSTM.