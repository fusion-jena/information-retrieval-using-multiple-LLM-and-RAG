Based on the provided context, there is no explicit information about how the hyperparameters of the models are optimized. The text discusses the performance of various models such as DCT-PLS, ESTARFM, and SOWCEM in image fusion, but it does not mention any specific method for hyperparameter tuning.

Hyperparameter optimization is an essential step in machine learning model development, as it can significantly impact the model's performance. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization. Grid search involves systematically trying out different combinations of hyperparameters, while random search selects hyperparameters at random from a predefined range. Bayesian optimization, on the other hand, uses a probabilistic approach to select the most promising hyperparameters to try next.

Without further information, it is not possible to provide a specific answer to the query. However, it is recommended to use a systematic approach for hyperparameter tuning, such as grid search or random search, to ensure that the models are performing optimally. Hyperparameter tuning can be computationally expensive, but it can significantly improve the accuracy and generalizability of the models.

In summary, the provided context does not contain information on how the hyperparameters of the models are optimized. Hyperparameter tuning is an essential step in machine learning model development, and it is recommended to use a systematic approach such as grid search or random search.