The context provided does not give specific information about the hardware resources used for training the deep learning model. However, it does mention that the research involves using a cloud platform, which typically implies the availability of various hardware resources such as Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs). These types of hardware are commonly used for training deep learning models due to their ability to perform parallel processing, which is particularly useful for the computationally intensive tasks involved in deep learning.

For instance, the study by Bar et al. (Bar and Paridha, 2019) demonstrates the use of machine learning techniques for classifying fire-damaged monuments using high-resolution Sentinel-2 satellite images. Although the specific hardware used is not mentioned, the use of a cloud platform suggests that they may have utilized GPUs or TPUs for training their model.

Furthermore, the study by Goparaju et al. (2023) quantifies carbon emissions from forest fires using intricate influencing factors, which also likely involves the use of a deep learning model. The fact that the researchers were able to conduct extensive geospatial computations implies that they had access to significant computational resources, which could have included GPUs or TPUs.

Therefore, while the context does not provide explicit information on the hardware resources used for training the deep learning model, it is reasonable to infer that they may have utilized GPUs or TPUs available on a cloud platform.