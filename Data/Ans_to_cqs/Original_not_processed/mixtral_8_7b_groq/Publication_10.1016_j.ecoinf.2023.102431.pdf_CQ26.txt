Based on the provided context, it appears that the researchers used a predictor screening analysis and bootstrap forest partitioning to evaluate the contribution of predictors on the response object. This was done to identify variables with the greatest potential to discriminate between classes of objects, such as species or fisher sex. However, the context does not explicitly mention any of the techniques listed in the query, such as stratified splitting, oversampling, undersampling, or diverse data collection.

That being said, the context does mention that the researchers evaluated the dataset for two potential sources of bias: foot position bias and observer bias. To address foot position bias, the researchers recorded the foot position (left-front or right-front) of each track during the feature extraction process. To evaluate observer bias, they had three different observers manually mark the landmark points in the FIT interface, which is a somewhat subjective process.

While these steps do not directly address data bias during preprocessing of a deep learning pipeline, they do demonstrate an awareness of potential sources of bias and a proactive approach to addressing them. Additionally, the context mentions that the researchers used a simplified approach to the FIT process, which requires fewer landmark points and can be employed on tracks of varying quality. This could be seen as a form of diverse data collection, as it allows for the inclusion of a wider range of data.

In summary, while the provided context does not explicitly mention any of the techniques listed in the query, it does suggest that the researchers took steps to address potential sources of bias in their data. These steps include evaluating the dataset for foot position bias and observer bias, as well as using a simplified approach to the FIT process that allows for the inclusion of a wider range of data.