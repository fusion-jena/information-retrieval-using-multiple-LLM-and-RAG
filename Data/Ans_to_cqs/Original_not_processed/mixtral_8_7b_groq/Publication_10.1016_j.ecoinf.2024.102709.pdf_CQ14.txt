The context does not provide specific information on how the hyperparameters of the model were optimized. However, it does mention that k-fold cross-validation was used to determine the best training-test set for the model. This technique involves splitting the data into k different training-test sets and training the model on each split. This can help in identifying the best data split for the model, but it does not necessarily imply that grid search or random search was used for hyperparameter tuning.

Hyperparameter tuning is an important step in model training to ensure that the model is performing optimally. Grid search and random search are two common methods used for hyperparameter tuning. Grid search involves creating a grid of hyperparameter values and training the model with each combination. Random search, on the other hand, involves randomly selecting hyperparameter values and training the model with these values.

Therefore, based on the provided context, it is not possible to definitively answer how the hyperparameters of the model were optimized. It is possible that k-fold cross-validation was used in conjunction with grid search or random search for hyperparameter tuning, but the context does not provide enough information to confirm this.