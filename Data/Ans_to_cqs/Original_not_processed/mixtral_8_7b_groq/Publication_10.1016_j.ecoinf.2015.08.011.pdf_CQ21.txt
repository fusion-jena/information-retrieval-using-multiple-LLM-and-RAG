Based on the provided context, there is no explicit information about the postprocessing steps applied after the model training, such as saliency maps, metrics calculation, or confusion matrix. However, it does mention that an early stopping technique was used to avoid overfitting during the training process.

The early stopping technique involves splitting the dataset into two sets: a training set (80%) and a validation set (20%). The model training is stopped when the network begins to overfit the data, i.e., the error on the validation set starts to increase. This technique helps to ensure that the model has good generalization performance and can perform well on unseen data.

Moreover, the study used a trial-and-error method to determine the appropriate number of neurons and learning rate for the Artificial Neural Network (ANN). This method involves varying the number of nodes in the hidden layer and the learning rate, calculating the mean square error (MSE) between the model output and the measured data for each configuration, and selecting the optimal number of neurons and learning rate based on the MSE.

Therefore, while the context does not explicitly mention any postprocessing steps like saliency maps, metrics calculation, or confusion matrix, it does provide information about the early stopping technique used during the training process and the trial-and-error method used for model selection.