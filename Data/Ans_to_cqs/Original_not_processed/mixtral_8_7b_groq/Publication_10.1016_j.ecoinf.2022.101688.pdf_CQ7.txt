Answer:

The data for deep learning model training in the context provided is split based on two main criteria: time frames and random selection of entire audio files. Specifically, the data is divided into training and testing sets, with 60% of the data used for training and 40% for testing. This split is done by randomly selecting entire audio files, ensuring that the training audio files are mutually exclusive to the testing audio files. The testing files are generally recordings from different days to ensure a fair evaluation.

Additionally, the testing process involves using a sliding window of constant time duration to predict the entire testing file. The window is shifted by one second until the network has predicted on the entire file. The testing files are manually annotated.

It is worth noting that the data splitting criteria do not include a validation set, which is typically used for hyperparameter tuning and model selection. However, the context does mention a "consuming step" that involves exploring various neural network hyperparameters to obtain the most optimal model. It is possible that a validation set is used during this step, although it is not explicitly stated in the provided context.

In summary, the data for deep learning model training is split based on time frames and random selection of entire audio files, with a testing set used for final evaluation. However, the context does not explicitly mention the use of a validation set for hyperparameter tuning and model selection.