Answer:::

The criteria used to split the data for deep learning model training, such as selecting the train, test, and validation sets, are not explicitly stated in the provided context. However, it does mention that for each classification task, the best performing classifier is used to classify the whole dataset, and the relevant texts from these predictions are then used as data from which training, development, and testing sets are selected for the next classification task.

Additionally, the context discusses two specific strategies used for training classification tasks 2 and 3: a randomly selected sample and a balanced stratified sample. For the balanced stratified sample, data were grouped according to their initial exploitation-related query term (stemmed), resulting in 19 groups. From each of these groups, 110 texts for labeling were randomly selected, such that each query group was equally represented in the data. This approach effectively under-sampled texts that were more likely to be associated with COVID-19 related texts, allowing the classifier to be trained with the full breadth of topics within the dataset.

Furthermore, the context presents Figure 5, which shows the relationship between the number of texts in training data when data was selected randomly or using active learning. Classifiers were initialized with a random sample of 50 texts, after which point, different selection strategies were used to select the next 50 texts to include in the training set.

In summary, while the specific criteria used to split the data for deep learning model training are not explicitly stated in the provided context, it does mention that the best performing classifier is used to classify the whole dataset, and relevant texts are then used for the next classification task. Additionally, the context discusses two specific strategies used for training classification tasks 2 and 3: a randomly selected sample and a balanced stratified sample.