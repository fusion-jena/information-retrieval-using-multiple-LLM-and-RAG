Based on the provided context, there is no specific information about how the data was split for training a deep learning model (e.g., train, test, validation). However, I can provide some general suggestions for data splitting criteria that are commonly used in machine learning:

1. **Random sampling**: This is the simplest method for splitting the data, where records are randomly assigned to different subsets (train, test, validation). This method ensures that the subsets are representative of the entire dataset.

2. **Temporal splitting**: If the data is time-series or has a temporal component, it might be more appropriate to split the data based on time. For example, you could use the first few months for training, the next few months for validation, and the remaining months for testing. This method ensures that the model is tested on unseen data in terms of time.

3. **Stratified sampling**: If the data is imbalanced or has categorical variables, it might be beneficial to use stratified sampling. This method ensures that each subset has a similar distribution of classes or categories as the entire dataset.

4. **K-fold cross-validation**: This method involves dividing the data into 'k' subsets (folds). The model is trained on 'k-1' folds and tested on the remaining fold. This process is repeated 'k' times, each time with a different fold as the test set. The average performance across all 'k' trials is then used as the final performance metric.

Without more specific information about the dataset and the deep learning model, it's difficult to provide a more precise answer. However, the methods mentioned above are commonly used for splitting data in deep learning model training.