Answer:::

The text provided does not give explicit information about how the hyperparameters of the model were optimized. However, it does mention that different numbers of training steps were considered for the calibration of models used in classification challenges. Specifically, 4000 training steps were chosen as the optimum number for all challenges except Challenge 3, where 8000 training steps were found to be optimum. This suggests that some form of manual search or human-guided search was used to find the optimum number of training steps. The text does not mention the use of more systematic methods such as grid search or random search for hyperparameter optimization. Therefore, while we cannot be certain, it appears that hyperparameters may have been optimized through manual or human-guided search in this case.