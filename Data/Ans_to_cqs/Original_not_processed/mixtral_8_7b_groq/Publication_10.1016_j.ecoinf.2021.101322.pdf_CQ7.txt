Answer:

The context does not provide direct information on how the data was split for training the deep learning models. However, it does mention the use of test loss, mean squared error (MSE), mean average percentage error (MAPE), and accuracy as metrics to assess the performance of the CNN models. It also mentions the use of minibatch gradient descent during training.

In general, when training deep learning models, the data is typically split into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

Based on the context, it can be inferred that the data was likely split into training, validation, and testing sets, even though it is not explicitly stated. The test loss, MSE, MAPE, and accuracy metrics mentioned could have been calculated on the testing set to evaluate the final model's performance. Additionally, the early termination of training based on validation error mentioned in section 2.4 suggests the use of a validation set to tune hyperparameters and select the best model.

Therefore, while the context does not provide explicit information on how the data was split for training the deep learning models, it can be inferred that the data was likely split into training, validation, and testing sets, as is typical in deep learning model training.