Answer:::

After training the models in the study, there are several post-processing steps that were taken, although not all of them are explicitly mentioned in the provided context. However, I can identify some of these steps based on the information given.

Firstly, the best performing model was saved based on the validation loss at the end of the training process. This model was then used as the Faster R-CNN model for testing with a Non-Maximum Suppression (NMS) threshold of 0.7. NMS is a common post-processing step used in object detection to eliminate redundant bounding boxes that have a high overlap with each other.

Secondly, metrics calculation was performed to evaluate the performance of the models. The context provides Mean Absolute Error (MAE) and Mean Squared Error (MSE) for several features in the Faster R-CNN, YOLOv5s, and the proposed method. However, it does not explicitly mention the calculation of other metrics such as precision, recall, or F1-score.

Thirdly, the study used a single-leaf classifier that was trained on a dataset consisting of 881 intact individual leaves as positive training samples and 1015 negative samples. These negative samples were manually extracted from the segmentation model results. Although not explicitly mentioned, it can be inferred that a confusion matrix was used to evaluate the performance of the single-leaf classifier.

Lastly, the study used pre-processing techniques such as data augmentation and normalization before training the semantic segmentation model. However, these are not post-processing steps, and therefore, they do not directly answer the query.

In summary, the post-processing steps involved after model training in the study include saving the best performing model, using NMS for testing, calculating metrics such as MAE and MSE, and possibly using a confusion matrix for evaluating the single-leaf classifier.