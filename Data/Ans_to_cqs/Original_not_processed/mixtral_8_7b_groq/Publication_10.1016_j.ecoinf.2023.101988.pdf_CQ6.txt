In the context of training deep learning models, there are several preprocessing steps that are often involved, including normalization, scaling, and cleaning.

Normalization is a common preprocessing step that involves scaling numeric data to a range of values, often between 0 and 1. This is important because deep learning models are sensitive to the scale of the input features. If some features have much larger values than others, the model may weigh those features more heavily, even if they are not as important. Normalization ensures that all features are on a similar scale, allowing the model to learn more effectively.

Scaling is similar to normalization, but it involves scaling the data to a specific range, such as the range of values that a particular activation function can handle. For example, the sigmoid activation function can only handle input values between -5 and 5, so scaling the data to this range can help the model converge more quickly.

Cleaning is another important preprocessing step that involves removing or correcting errors, missing values, and outliers in the data. This is important because deep learning models are sensitive to noise and can learn incorrect patterns if the data is not clean. Cleaning the data can help improve the model's performance and prevent it from learning incorrect patterns.

In the context of the provided articles, normalization, scaling, and cleaning are not explicitly mentioned in relation to training deep learning models. However, these preprocessing steps are commonly used in deep learning and are likely to be used in any deep learning application.

For example, in the article "Modelling animal biodiversity using acoustic monitoring and deep learning" by Chalmers et al. (2021), the authors use deep learning models to classify animal sounds. While they do not explicitly mention normalization, scaling, or cleaning, they do preprocess the audio data by extracting features such as Mel-frequency cepstral coefficients (MFCCs) and spectral features. These features are likely to be normalized or scaled before being fed into the deep learning model.

Similarly, in the article "Unmanned aircraft systems in wildlife research: current and future applications of a transformative technology" by Christie et al. (2016), the authors discuss the use of unmanned aerial vehicles (UAVs) for wildlife research. While they do not explicitly mention deep learning, they do discuss the importance of preprocessing data collected by UAVs, such as cleaning and filtering noisy data.

Overall, while normalization, scaling, and cleaning are not explicitly mentioned in the provided articles in relation to deep learning, these preprocessing steps are commonly used in deep learning applications and are likely to be used in any deep learning project.