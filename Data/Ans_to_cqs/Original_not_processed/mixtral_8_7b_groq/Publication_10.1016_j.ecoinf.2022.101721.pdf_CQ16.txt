Based on the provided context, there is no specific information about the criteria used to determine when training is complete for a machine learning model. The text discusses a study that uses Bayesian algorithms for bat identification and mentions the use of a full sample of 10,000 observations, as well as the use of both uninformative and informative priors. The study also highlights the importance of including all observations in statistical modeling and the potential benefits of allowing users to interact with the software.

However, the context does not include any details about the training process or the specific criteria used to determine when training is complete. In general, there are several common methods for determining when training is complete, such as:

1. Validation loss plateau: This method involves monitoring the loss function on a validation set during training. When the loss function stops decreasing or begins to increase, it may be an indication that training should be stopped.
2. Early stopping: This method involves stopping training before the model has fully converged in order to prevent overfitting. This can be done by monitoring the performance of the model on a validation set and stopping training when the performance begins to degrade.
3. Fixed number of iterations: This method involves setting a fixed number of iterations or epochs for training and stopping training after that number has been reached.

Without more information about the specific training process used in the study, it is not possible to provide a definitive answer to the query.