Answer:::

The deep learning pipeline in the given context uses image data format. The study focuses on using Convolutional Neural Networks (CNNs) to make accurate predictions on new, unseen images. The images are used to detect alates on sorghum leaves. The images are split into training, validation, and testing sets in a ratio of 80:10:10, respectively. The images are at input resolutions of 640 × 640 pixels and 1280 × 1280 pixels. The authors used the Common Objects in Context (COCO) dataset for training.

Additionally, the authors used the YOLOv5 family of detection models, which are also designed to work with image data. The authors trained five different versions of the YOLOv5 model family, including YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x models, to detect alates on sorghum leaves. The trained models using images at 1280 × 1280 pixel input resolution performed higher than those using a 640 × 640 pixel input resolution based on the calculated metrics.

Therefore, the deep learning pipeline in this study uses image data format exclusively. There is no mention of using other data formats such as audio, video, or CSV.