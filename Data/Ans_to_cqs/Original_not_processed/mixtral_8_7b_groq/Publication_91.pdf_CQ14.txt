Based on the provided context, there is no explicit information about how the hyperparameters of the model, such as the learning rate or the decay factor, were optimized. The text mentions that the initial learning rate was 0.001 and was exponentially decayed every 3 epochs with a factor of 0.94, but it does not specify whether these values were determined through a hyperparameter optimization method such as grid search or random search.

Hyperparameter optimization is an important step in training machine learning models, as the choice of hyperparameters can significantly impact the model's performance. Grid search and random search are two common methods for hyperparameter optimization. Grid search involves systematically trying out different combinations of hyperparameter values within a predefined range, while random search involves randomly sampling hyperparameter values within a specified range.

Without more information, it is not possible to definitively answer how the hyperparameters of the model were optimized in this case. However, it is worth noting that the choice of hyperparameters can have a significant impact on the performance of a model, and it is generally recommended to perform hyperparameter optimization when training machine learning models.