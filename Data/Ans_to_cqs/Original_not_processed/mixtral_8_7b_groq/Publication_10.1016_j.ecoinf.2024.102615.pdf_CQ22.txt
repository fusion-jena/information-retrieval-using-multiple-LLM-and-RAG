The performance of the deep learning model in the study is evaluated using the correlation coefficient (R), root mean square error (RMSE), mean absolute error (MAE), coefficient of determination (R2), and mean relative error (MRE) metrics.

The correlation coefficient (R) measures the linear relationship between two variables, with values closer to 0 denoting a lesser correlation and indicating improved model performance. Its value varies between -1 and 1, where a value of 1 indicates a perfect positive correlation, a value of -1 indicates a perfect negative correlation, and a value of 0 indicates no correlation.

The root mean square error (RMSE) measures the difference between the predicted and actual values, with a lower value indicating better model performance. It is calculated as the square root of the mean of the squared differences between the predicted and actual values.

The mean absolute error (MAE) measures the average magnitude of the errors in the predictions, with a lower value indicating better model performance. It is calculated as the mean of the absolute differences between the predicted and actual values.

The coefficient of determination (R2) measures the proportion of the variance in the dependent variable that is predictable from the independent variable, with a higher value indicating better model performance. It is calculated as the ratio of the explained variance to the total variance.

The mean relative error (MRE) measures the relative error between the predicted and actual values, with a lower value indicating better model performance. It is calculated as the mean of the absolute relative differences between the predicted and actual values.

These metrics are used to evaluate the performance of the deep learning model on the validation set, and the optimal model was obtained with an R value of 0.76.