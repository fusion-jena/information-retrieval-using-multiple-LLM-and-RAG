Based on the provided context, there is no explicit mention of the techniques used for addressing data bias during the preprocessing of the deep learning pipeline. However, the text does discuss the issue of class imbalance and how it is handled during the fine-tuning stage of the model.

In the work by Belgith et al., 2018, the authors mention the presence of overrepresentation of ambient frames, which can lead to an imbalance in the contributing frames to each training batch. To address this issue, the model is fine-tuned using a small-scale model pre-trained on 40,000 frames. During fine-tuning, as the number of frames per class reaches 500, the model is able to learn to separate the noise from the patterns within each signal type across the two marine environments.

Furthermore, in the fine-tuning stage of the model, the authors use a dropout rate of 0.2 and DropConnect, which randomly discards the input of the hidden layer. These techniques can help prevent overfitting and improve the model's generalization performance.

While the context does not explicitly mention techniques such as stratified splitting, oversampling, or undersampling, the authors do discuss the importance of collecting diverse data. In the work by Oswald et al., 2003, the authors developed software for species identification of 26 delphinid whistles using passive acoustics. This involved collecting data from different species and environments, which can help ensure that the model is exposed to a diverse range of data and can improve its ability to generalize to new data.

Therefore, while the context does not provide a detailed description of techniques used for addressing data bias during preprocessing, it does highlight the importance of collecting diverse data and handling class imbalance during fine-tuning.