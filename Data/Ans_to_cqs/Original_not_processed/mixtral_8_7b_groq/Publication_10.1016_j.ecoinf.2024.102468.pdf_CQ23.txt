Answer:

The generalizability of the WT-HMM model was addressed through several measures, as can be inferred from the provided context. Firstly, the use of varying dataset sizes over 10 runs suggests a form of cross-validation, where the model's performance is tested under different conditions to ensure it can handle variability. This approach helps to assess the model's stability and ability to perform consistently, which are key aspects of generalizability.

Secondly, the emphasis on the importance of selecting appropriate sample sizes for effective model training resonates with the practice of using a diverse dataset. A diverse dataset, which seems to be the case here given the varying dataset sizes, can aid in the generalization of learned features and patterns by providing the model with more diverse examples. This is further supported by the findings that larger datasets consistently improve the accuracy and F1-score, indicating that the model benefits from the increased diversity.

However, the text does not explicitly mention the use of stratified splitting, which is a technique used to ensure that each subset of the data (e.g., training, validation, testing) contains a representative proportion of the classes in the original dataset. While not explicitly stated, the use of cross-validation with varying dataset sizes could indirectly serve a similar purpose, as it exposes the model to different subsets of the data, potentially balancing the class distribution.

In conclusion, while the text does not explicitly mention the use of stratified splitting, it does suggest that the generalizability of the WT-HMM model was addressed through the use of varying dataset sizes (implicitly similar to stratified splitting) and cross-validation, as well as the emphasis on using a diverse dataset.