Based on the provided context, the performance of the deep learning models is evaluated using two metrics: Area Under the Curve (AUC) and True Skill Statistic (TSS).

AUC is a metric commonly used to assess the performance of binary classifiers. It measures the entire two-dimensional area underneath the entire ROC curve (a plot of true positive rates vs. false positive rates). AUC ranges from 0.5 to 1, where 0.5 indicates a model that performs no better than random guessing, and 1 indicates a perfect classifier.

TSS, on the other hand, is a threshold-dependent measure of model performance. It is calculated as:

TSS = Sensitivity + Specificity - 1

where Sensitivity is the proportion of true positives correctly identified, and Specificity is the proportion of true negatives correctly identified. TSS values range from -1 to +1, where a value of +1 indicates a perfect fit, and a value of 0 indicates a model that performs no better than random guessing.

These two metrics, AUC and TSS, are used to compare the performance and accuracy of each model. The models are trained using 80% of the collected data, and their performance is evaluated using the remaining 20% of the data. To avoid sampling bias, pseudo-absence points are generated three times for each model and cross-validated per model using bootstrapping.

It is important to note that the provided context does not mention any other metrics commonly used to evaluate the performance of deep learning models, such as accuracy, precision, or recall. However, based on the context, it can be inferred that AUC and TSS are the primary metrics used to evaluate the models' performance.