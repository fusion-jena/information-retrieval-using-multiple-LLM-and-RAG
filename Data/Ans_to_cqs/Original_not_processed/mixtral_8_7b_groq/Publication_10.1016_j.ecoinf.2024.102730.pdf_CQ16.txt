Answer:::
The context provided does not give specific information on the criteria used to determine when training of the MLP models is complete. However, it does mention that the models were trained using an algorithm called backpropagation, which adjusts the weights of the connections between nodes to minimize the difference between the model's predictions and the actual outcomes. This process of weight adjustment typically continues until a specified number of iterations is reached or a certain level of convergence is achieved.

In addition, the context states that the data was divided into a training set (80% of the data) and a test set (20% of the data) before conducting the grid search. This suggests that cross-validation, where the model is trained and tested on different subsets of the data, may have been used to assess model performance and potentially inform the decision of when to stop training.

Furthermore, the context explains that the grid search focused on minimizing the mean squared error (MSE) as a metric for evaluating model performance. It is possible that the training of the MLP models was stopped based on a predetermined threshold for the MSE or when a specified number of iterations with no improvement in the MSE was reached.

However, without more specific information from the context, it is not possible to definitively answer the query.