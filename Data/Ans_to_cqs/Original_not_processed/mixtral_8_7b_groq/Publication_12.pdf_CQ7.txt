Answer:::

In the given text, the criteria used to split the data for deep learning model training are specified. The data was divided into a training dataset and a validation dataset. The training dataset consisted of 85% of the images (111,244 out of 130,858), while the validation dataset contained the remaining 15% (19,614 out of 130,858). This split was created using a Python script called "Making_dataset.py" in the Waveman software.

Additionally, specific measures were taken during the creation of these datasets. Firstly, to balance the image number for all species, an upper limit was provided for when a species had too much data. Secondly, a method was developed to increase the number of images for the rare species. This was achieved by rescaling signals exponentially and shifting the window slightly either side of the call to change background noise. These measures ensured that rare species with small image numbers would not be under-represented and under-classified relative to common species.

It's also worth noting that before splitting, the size of the images was reduced from 256*256 pixels to 64*64 pixels to save training time and reduce high memory graphics use.

Answer::: (400 words)