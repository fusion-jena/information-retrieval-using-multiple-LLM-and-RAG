The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does discuss the use of pre-trained models as a way to improve model performance and reduce overfitting.

In the context, the authors use four pre-trained models: AlexNet, VGG-19, ResNet-101, and DenseNet-201. These models were pre-trained on the ImageNet dataset, which contains over 1 million images and 1000 classes. By using pre-trained models, the authors are able to leverage the low-level features learned from the large ImageNet dataset and apply them to their specific problem of classifying leaf species. This is a form of transfer learning, which can help to reduce overfitting by providing a strong initial starting point for the model.

Additionally, the authors compare the performance of the models on both raw and pre-processed images. By evaluating the models on both types of images, they are able to assess the robustness of the models and ensure that they are able to generalize well to new data. This is another way to reduce overfitting and improve the performance of the deep learning pipeline.

While the context does not explicitly mention regularization methods such as dropout or L2 regularization, it does provide some insight into how the authors approached the problem of overfitting. By using pre-trained models and evaluating the models on both raw and pre-processed images, the authors were able to improve the performance and robustness of their deep learning pipeline.