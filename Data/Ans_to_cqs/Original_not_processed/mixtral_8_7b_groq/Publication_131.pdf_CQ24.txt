The provided context does not give specific information about the use of a random seed value or other strategies to handle randomness in the deep learning pipeline for this particular CNN model. However, it does mention that 80% of the samples were used for training and 20% for testing, which is a common strategy to enhance the generalization of a machine learning model and prevent overfitting. This strategy can be seen as a way to manage randomness, as it ensures that the model is exposed to a variety of data during training and that its performance can be evaluated on unseen data.

In general, the use of a random seed value is a common practice in deep learning to ensure reproducibility of results. By setting a specific seed value, the random number generator used in the training process will produce the same sequence of random numbers, which will result in the same initialization of weights and biases, and the same order of processing of the training data. This can be useful to compare the performance of different models or to replicate experiments.

Other strategies to handle randomness in deep learning include techniques such as dropout, which randomly sets a fraction of the outputs of a layer to zero during training, and data augmentation, which generates new training samples by applying random transformations to the existing data. These techniques can help to reduce overfitting and improve the generalization of the model by introducing some variability and randomness in the training process.

In summary, while the provided context does not give specific information about the use of a random seed value or other strategies to handle randomness in the deep learning pipeline for this particular CNN model, such strategies are commonly used in deep learning to ensure reproducibility, reduce overfitting, and improve the generalization of the model.