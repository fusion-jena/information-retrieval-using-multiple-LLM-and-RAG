Answer:::
The deep learning model in the study was trained using a remote Windows 11 Pro (64-bit) computational system, which was connected to Ubuntu 18.04.6 LTS (GNU/Linux 4.15.0â€“169-generic x86 64) running on an Intel Core i7-8565U CPU @ 1.80GHz with 16 GB memory. However, the primary hardware resource used for training the model was a NVIDIA GeForce GTX 1080 Ti graphics processing unit (GPU). The GPU was used for parallelization during the training process, and the study utilized CUDA 10.2 for GPU acceleration.

Answer:::