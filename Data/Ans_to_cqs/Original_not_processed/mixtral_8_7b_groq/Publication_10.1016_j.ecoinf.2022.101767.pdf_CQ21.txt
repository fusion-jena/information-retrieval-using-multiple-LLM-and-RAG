The provided context does not contain information about the specific postprocessing steps involved after model training. However, it does mention the use of a random forest analysis with a feature selection algorithm to identify significant explanatory factors for the number of views of certain videos. This suggests that some form of metrics calculation was likely involved in the analysis.

In general, after training a model, there are several common postprocessing steps that can be taken. These include:

1. Saliency maps: These are visualizations that highlight the parts of the input that the model is paying attention to when making a prediction. They can be useful for understanding how the model is making its decisions.
2. Metrics calculation: This involves calculating various metrics, such as accuracy, precision, recall, and F1 score, to evaluate the performance of the model.
3. Confusion matrix: This is a table that summarizes the predictions made by the model, showing the number of true positives, true negatives, false positives, and false negatives. It can be used to calculate various metrics, such as accuracy and precision.
4. Hyperparameter tuning: This involves adjusting the parameters of the model to improve its performance. This can be done using techniques such as grid search or random search.
5. Model interpretation: This involves trying to understand how the model is making its decisions. This can be done using techniques such as feature importance, partial dependence plots, and local interpretable model-agnostic explanations (LIME).

Without more information about the specific model and analysis that was performed, it is difficult to say which of these postprocessing steps were taken.