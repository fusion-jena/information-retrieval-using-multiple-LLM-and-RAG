Based on the provided context, there is no explicit information given about the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context focuses on the use of deep learning for wildfire event predictions, but it does not detail the data splitting process.

However, it is important to note that when developing a deep learning model, data splitting is a crucial step. Typically, the dataset is divided into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and make decisions during the model building process, and the testing set is used to evaluate the model's performance.

In the context of Halgamuge et al. (2020), they developed an algorithm to collect data automatically and analyzed six different optimizer models using deep learning technology. Still, they did not mention the data splitting process. Similarly, Dowdy (2020) focused on demonstrating a seasonal prediction system for wildfire event prediction in Australia, but there is no information about the data splitting process.

In the study by G. Charizanos and H. Demirhan (2023), they used a Bayesian modeling framework and considered model uncertainty. They implemented the BMA approach, but there is no information about the data splitting process.

Therefore, without further information, it is not possible to provide the specific criteria used to split the data for deep learning model training in the studies mentioned in the context.