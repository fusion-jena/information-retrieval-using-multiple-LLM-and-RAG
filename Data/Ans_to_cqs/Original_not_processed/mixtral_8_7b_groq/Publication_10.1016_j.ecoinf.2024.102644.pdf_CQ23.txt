Based on the provided context, there is no explicit information about the measures taken to ensure the generalizability of a deep learning model. However, there are some implicit indications that certain measures might have been taken.

Firstly, the use of large-scale repositories like GBIF and OBIS suggests that a diverse dataset was used. These repositories contain millions of records regarding speciesâ€™ observations across multiple decades and various geographical locations. Using such a diverse dataset can help to increase the generalizability of a deep learning model.

Secondly, the context mentions that species observation data from GBIF were "improved with reliable records we accurately and directly observed in the field." This statement implies that some form of data validation or cleaning was performed, which can also contribute to the generalizability of a model.

However, there is no explicit mention of cross-validation or stratified splitting, which are common techniques used to ensure the generalizability of machine learning models. Cross-validation involves dividing the dataset into multiple subsets, training the model on one subset, and testing it on another. This process is repeated for each subset, providing a more reliable estimate of the model's performance. Stratified splitting involves dividing the dataset in a way that ensures each subset has a similar distribution of data, which can be particularly important in imbalanced datasets.

Therefore, while there are some indications that a diverse dataset was used and some data validation was performed, there is no explicit information about the use of cross-validation or stratified splitting to ensure the generalizability of the deep learning model.