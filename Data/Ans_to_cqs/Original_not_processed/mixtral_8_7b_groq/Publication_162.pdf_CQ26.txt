Based on the provided context, there is no explicit mention of techniques used to address data bias during preprocessing of the deep learning pipeline, such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does mention that they normalize all input channels (red, green, blue, and depth) by subtracting the respective mean and dividing by the respective standard deviation over the whole dataset. This can help to ensure that the data is on a similar scale and can potentially help to reduce bias caused by differences in the scales of the different input channels.

Additionally, the authors restrict their evaluation of D-Mask R-CNN to instances of deer, which is the most common species in their RGB-D dataset. This could be seen as a form of oversampling of the deer class, but it is not explicitly stated that this is being done to address data bias.

It's also worth noting that the authors use a feature fusion module to combine the extracted features from both backbones using one 3 × 3 convolution per FPN scale and reduce the number of channels from 2 × 256 to 256. This allows them to use weights pre-trained on the Microsoft COCO dataset for the region proposal network (RPN) classifier and mask head. This could be seen as a way to increase the diversity of the data used in the training of the model, as the COCO dataset contains a wide variety of object classes.

In summary, while the text does not explicitly mention the use of techniques such as stratified splitting, oversampling, undersampling, or diverse data collection to address data bias during preprocessing, it does mention normalization of input channels, oversampling of the most common species, and use of pre-trained weights from a diverse dataset as potential methods that could help to reduce bias in the data.