Based on the provided context, there is no specific information about the hyperparameters used in a deep learning model for soil mapping or any other related application. The context includes various studies and sources that discuss different aspects of soil science, digital soil mapping, and visualization techniques, but none of them detail the hyperparameters of a deep learning model.

Hyperparameters are crucial configuration variables in machine learning models, including deep learning models. They can significantly impact the model's performance and need to be carefully selected and tuned. Common hyperparameters for deep learning models include:

1. Learning rate: The step size at each iteration while moving toward a minimum of a loss function.
2. Optimizer: The algorithm used to update the model's weights based on the gradient of the loss function. Examples include Stochastic Gradient Descent (SGD), Adam, and RMSprop.
3. Number of layers and neurons: The architecture of the deep learning model, including the number of layers and the number of neurons in each layer.
4. Activation functions: The functions applied to the output of each neuron, such as ReLU, sigmoid, or tanh.
5. Regularization techniques and strength: Methods to prevent overfitting, such as L1, L2, or dropout regularization, and the strength of the regularization.
6. Batch size: The number of samples processed before updating the model's weights.

Without specific information from the context, it is impossible to provide the exact hyperparameters used in a deep learning model for soil-related applications. However, researchers and practitioners working with deep learning models for soil mapping or other related tasks should consider the aforementioned hyperparameters and optimize them to achieve the best possible performance.