The context does not provide specific information on how the hyperparameters of the model were optimized. However, it is mentioned that different hyperparameters were explored to achieve the best results for training the final model. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization. Grid search involves testing a finite number of combinations in a grid-like pattern, while random search randomly selects hyperparameters to try within predefined ranges. Bayesian optimization uses a probabilistic model to make informed decisions about which hyperparameters to try next. Without further information, it is not possible to give a specific answer to this query.