Answer:::

In the context provided, there is no explicit information about the specific criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it is common practice in machine learning to split the dataset into three subsets: training, validation, and testing.

The training set is used to train the model, updating the model's parameters based on the error of the predictions. The validation set, also known as the development set, is used to provide an unbiased evaluation of the model during the training process. This set is used to tune hyperparameters and prevent overfitting. Overfitting occurs when the model learns the training data too well, including its noise, and performs poorly on unseen data. The testing set, finally, is used to provide an unbiased evaluation of the final model.

The splitting criteria can vary depending on the size of the dataset and the specific problem. A common approach is to use 60-20-20 or 70-15-15 splits for the training, validation, and testing sets, respectively. However, for smaller datasets, a more balanced split, such as 50-25-25, might be preferred.

In the context of the whale image classification example, the training dataset contains 700 annotated aerial images, but it is not specified how these images were split for training, validation, and testing. However, it is mentioned that data augmentation and transfer learning were used to boost the learning of CNNs on small datasets. Data augmentation increases the volume of the training dataset artificially by applying transformations to the images, such as rotation, scaling, and flipping. Transfer learning, on the other hand, starts the learning of the network from a prior knowledge rather than from scratch, using a pre-trained model as the starting point.

In summary, while the context provided does not give specific information about the criteria used to split the data for deep learning model training, it is common practice to use a training, validation, and testing split. The specific split criteria can vary depending on the size of the dataset and the specific problem. Additionally, techniques such as data augmentation and transfer learning can be used to improve the learning of CNNs on small datasets.