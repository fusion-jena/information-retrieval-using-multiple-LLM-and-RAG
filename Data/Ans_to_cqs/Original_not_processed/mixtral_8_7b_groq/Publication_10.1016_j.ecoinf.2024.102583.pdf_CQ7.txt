Answer:::

The provided context discusses various machine learning models and ensemble techniques used in landslide susceptibility modeling (LSM), but it does not explicitly mention the criteria used to split data for deep learning model training. However, it is well-established in machine learning and deep learning practice that data splitting is crucial for building robust models.

In general, data for deep learning model training is typically split into three sets: training, validation, and testing.

1. Training set: This is the portion of data used to train the model. The model learns patterns from this data and adjusts its parameters to minimize the loss function.

2. Validation set: This is a separate subset of data used during the training phase to provide an unbiased evaluation of the model. The validation set helps to tune hyperparameters and prevent overfitting. It provides an estimate of how well the model is generalizing to unseen data.

3. Testing set: After training and validating the model, the testing set is used to provide a final, unbiased evaluation of the model's performance. This set should be independent of both the training and validation sets.

The splitting ratio can vary depending on the dataset size and specific requirements. Commonly used splits include 60-20-20 or 70-15-15 for training, validation, and testing, respectively. However, there is no one-size-fits-all approach, and the optimal split can depend on the complexity of the model and the amount of available data.

In summary, while the provided context does not explicitly mention the criteria for splitting data in deep learning model training for LSM, it is a standard practice in deep learning to split data into training, validation, and testing sets to build robust models and evaluate their performance.