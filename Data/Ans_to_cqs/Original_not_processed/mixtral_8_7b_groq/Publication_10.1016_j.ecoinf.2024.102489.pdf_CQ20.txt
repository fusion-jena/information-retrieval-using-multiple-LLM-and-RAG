The provided context does not give information about the specific hardware resources used for training the deep learning model. It only mentions that Jamali et al. (2023) used deep neural networks to estimate leaf parameters, but it does not specify the computing hardware used for training these models.

However, it is common practice to use Graphics Processing Units (GPUs) for training deep learning models due to their ability to perform parallel computations, which significantly speeds up the training process compared to using Central Processing Units (CPUs). Tensor Processing Units (TPUs) are custom-built hardware by Google for machine learning tasks, particularly for training and inference of large-scale machine learning models. While the context does not explicitly mention the use of GPUs or TPUs, it is reasonable to assume that hardware with similar capabilities was used for training the deep learning models.