Answer:

The provided context does not give explicit information about the specific criterion used to determine when training is complete. However, it can be inferred that the training process might be stopping based on a validation loss plateau or perhaps other performance metrics.

In the experimental analysis section, it is mentioned that the models with the optimal hyperparameter values, resulting in the highest accuracy, are evaluated using the validation dataset. This implies that the validation dataset is being used to assess the performance of the models during the training process.

Furthermore, the context describes the usage of various hyperparameter optimization strategies, such as HHOS (Hyperband with early stopping), which is employed to identify the optimal values for the hyperparameters. Early stopping is a technique often used in machine learning to cease training when the model's performance on a validation set stops improving, typically when the validation loss plateaus.

Therefore, it can be deduced that the training process might be using a validation loss plateau as an indicator to determine when training is complete. However, the context does not explicitly confirm this, so it remains an inferred answer based on the provided information.