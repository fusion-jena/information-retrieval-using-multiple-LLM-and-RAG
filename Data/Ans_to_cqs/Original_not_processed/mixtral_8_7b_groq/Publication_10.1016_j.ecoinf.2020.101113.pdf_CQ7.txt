The criteria used to split the data for deep learning model training are not explicitly stated in the provided context. However, it can be inferred that the data was split into at least two sets: a training set and a validation soundscape set.

The training set was used to train the Convolutional Neural Network (CNN) model. The model required equally sized input images, so a time-frequency input window size of 2 seconds was chosen as it was near the mean and median template duration across target call types. Most call types have a duration below 1 second, and for those above 2 seconds, the signals were preprocessed through time stretching, pitch shifting, and adding Gaussian noise or noise from soundscapes.

The validation soundscape set was used to improve the model's performance. Specifically, adding background noise from the validation soundscapes to training samples significantly improved performance on the test soundscapes. This indicates that acoustic monitoring systems can benefit significantly from location-specific training data.

Therefore, it can be inferred that the data was split into a training set and a validation set, and possibly a separate test set as well. The training set was used to train the model, while the validation set was used to improve the model's performance by adding location-specific background noise to the training samples. However, the specific criteria used to split the data are not provided in the context.