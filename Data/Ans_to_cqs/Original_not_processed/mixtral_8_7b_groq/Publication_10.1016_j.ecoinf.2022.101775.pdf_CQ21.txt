Based on the provided context, the postprocessing steps involved after the model training include the calculation of performance metrics and the creation of a confusion matrix.

After training the DMF and state-of-the-art models using a batch size of 64 samples and 100 epochs with Adam as the optimization algorithm, the models' performance was evaluated using metrics computed on the test set. Specifically, a min-max scaler was used to preprocess the data during training, and the performance metrics were calculated on the unscaled test set data.

However, the context does not mention any other postprocessing steps, such as the creation of saliency maps or feature importance plots. Saliency maps are a popular technique for visualizing the importance of input features in a model's prediction. They highlight the parts of the input that the model considers most relevant for its decision. However, the context does not mention the use of saliency maps or similar techniques.

Similarly, the context does not mention the creation of a confusion matrix, which is a table that summarizes the performance of a classification model by comparing its predicted labels to the true labels. The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. From these values, other metrics, such as accuracy, precision, recall, and F1 score, can be calculated.

In summary, based on the provided context, the postprocessing steps involved after the model training include the calculation of performance metrics on the test set. Other postprocessing techniques, such as saliency maps and confusion matrices, are not mentioned.