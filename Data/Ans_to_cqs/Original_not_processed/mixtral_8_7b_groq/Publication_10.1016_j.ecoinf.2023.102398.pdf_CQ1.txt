The provided context does not give information about the methods used for collecting raw data in the deep learning pipeline. Therefore, I cannot provide an answer to this query based on the given context. However, I can provide some general information about data collection methods in deep learning.

In deep learning, raw data can be collected using various methods such as:

1. Surveys: Surveys are a common method for collecting data in various fields, including social sciences, healthcare, and marketing. Surveys can be conducted online or offline, and they can include various types of questions, such as multiple-choice, open-ended, or rating scales. Surveys can be used to collect data on people's opinions, behaviors, attitudes, or demographic information.

2. Sensors: Sensors are devices that measure physical or environmental quantities and convert them into signals that can be processed and analyzed. Sensors can be used to collect data on various phenomena, such as temperature, pressure, humidity, motion, light, sound, or chemical concentrations. Sensors can be wired or wireless, and they can be used in various applications, such as healthcare, transportation, agriculture, or manufacturing.

3. Public datasets: Public datasets are collections of data that are available for anyone to access and use. Public datasets can be found in various domains, such as science, education, government, or industry. Public datasets can be useful for deep learning applications, as they provide large and diverse datasets that can be used for training and testing models. Examples of public datasets include ImageNet, COCO, UCI Machine Learning Repository, or Kaggle.

4. Private datasets: Private datasets are collections of data that are owned or controlled by individuals or organizations. Private datasets can be used for deep learning applications, but they may require permission or payment to access and use. Private datasets can be useful for applications that involve sensitive or proprietary information, such as medical records, financial transactions, or intellectual property.

5. Web scraping: Web scraping is a method for extracting data from websites using automated scripts or tools. Web scraping can be used to collect data from various sources, such as social media, news articles, product reviews, or forums. Web scraping can be useful for deep learning applications, as it provides large and diverse datasets that can be used for training and testing models. However, web scraping may raise ethical or legal issues, as it involves accessing and using data without explicit permission.

Therefore, depending on the specific deep learning application, different data collection methods may be more or less appropriate. It is important to consider the ethical, legal, and practical aspects of data collection when designing and implementing a deep learning pipeline.