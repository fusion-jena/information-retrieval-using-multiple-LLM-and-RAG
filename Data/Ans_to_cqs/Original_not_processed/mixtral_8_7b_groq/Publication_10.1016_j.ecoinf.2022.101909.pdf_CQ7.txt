Answer: The data was split into three subsets for the deep learning model training: training, testing, and validation. During the training stage, 80% of the dataset was used for training, and 10% was used for validation. The validation subset was used to tune the model's hyperparameters and prevent overfitting. The early stopping method was employed, which halted the training process if the model's performance on the validation subset did not improve for five consecutive epochs. The training process was executed for 50 epochs, but the optimal training was achieved at the end of the ninth epoch.

For testing, a separate subset of the data was used, which was not utilized during the training stage. The model's performance was evaluated using typical indicator series, such as true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). The model provided probability values in the range of 0 to 1, and a decision threshold Î¸ was used to define a prediction as positive (presence) or negative (absence).

Furthermore, to reduce bias during the training, validation, and testing stages, samples were likely extracted from different audio files. In the semi-automatic labeling stage, the extraction of samples was limited to a maximum of three per file.

In summary, the data was split into three subsets: training, validation, and testing. The training subset consisted of 80% of the data, and the validation subset consisted of 10% of the data. The validation subset was used for hyperparameter tuning and preventing overfitting. The testing subset was used to evaluate the model's performance, and samples were extracted from different audio files to reduce bias during the training, validation, and testing stages.