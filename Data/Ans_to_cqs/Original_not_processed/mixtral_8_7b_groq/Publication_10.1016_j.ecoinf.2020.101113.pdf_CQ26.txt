The provided context discusses the training data preprocessing for a CNN model used in bioacoustic recognition, but it does not explicitly mention the techniques used to address data bias during preprocessing. However, it does touch upon some related concepts that can be used to address data bias.

One of the challenges identified for future research is the large variability in the size of target calls (i.e. templates). The text suggests introducing recurrent connections in the CNN or other architecture modifications to potentially reduce the negative effects of window size. This could be a way to address data bias caused by uneven distribution of call sizes.

The text also mentions data augmentation as a way to improve performance and increase the training data size for rare species. Data augmentation can help in creating a more diverse and balanced dataset, which can be useful in addressing data bias.

However, the context does not explicitly mention techniques such as stratified splitting, oversampling, or undersampling. Stratified splitting is a method used to ensure that the train and test sets have approximately the same percentage of samples of each target class as the complete set. Oversampling and undersampling are methods used to balance the class distribution in a dataset by either duplicating samples from the minority class (oversampling) or removing samples from the majority class (undersampling).

In summary, while the provided context does not explicitly mention the techniques used to address data bias during preprocessing, it does touch upon related concepts such as introducing recurrent connections, architecture modifications, and data augmentation that can be used to address data bias. The context does not mention techniques such as stratified splitting, oversampling, or undersampling.