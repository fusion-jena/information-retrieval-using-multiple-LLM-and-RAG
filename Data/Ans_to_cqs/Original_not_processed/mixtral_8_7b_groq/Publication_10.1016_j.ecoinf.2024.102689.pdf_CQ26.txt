The provided context discusses various applications and improvements of deep learning models, particularly in the field of fish recognition and aquaculture. However, it does not explicitly mention the techniques used to address data bias during preprocessing of the deep learning pipeline.

Nevertheless, I can provide some general techniques that are commonly used to address data bias:

1. Stratified splitting: This technique involves dividing the dataset into subgroups based on certain characteristics (strata) and then ensuring that each stratum is proportionally represented in both the training and testing sets. This can help maintain balance and avoid bias in the data.

2. Oversampling: When a particular class or group is underrepresented in the dataset, oversampling can be used to increase the number of instances from that class. This can be done either by duplicating existing instances or by generating synthetic instances using techniques like SMOTE (Synthetic Minority Over-sampling Technique).

3. Undersampling: Conversely, when a class or group is overrepresented in the dataset, undersampling can be used to reduce the number of instances from that class. This can help balance the dataset and reduce bias. However, it is important to note that undersampling may lead to loss of information.

4. Diverse data collection: Collecting data from various sources and ensuring that the dataset is representative of the entire population can help reduce bias. This includes collecting data from different geographical locations, demographic groups, and environmental conditions.

While these techniques are not explicitly mentioned in the provided context, they are commonly used in the preprocessing stage of deep learning pipelines to address data bias.