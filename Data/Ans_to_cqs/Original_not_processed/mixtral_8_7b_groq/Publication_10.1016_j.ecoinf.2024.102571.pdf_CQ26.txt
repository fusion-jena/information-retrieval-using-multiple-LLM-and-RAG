The provided context does not contain information about techniques used to address data bias during preprocessing of the deep learning pipeline. However, I can provide some common techniques used to address data bias in machine learning and data science in general:

1. Stratified sampling: This technique involves dividing the data into homogeneous subgroups (strata) and then randomly selecting a fixed number of samples from each subgroup. Stratified sampling ensures that the distribution of samples in the training, validation, and test sets is representative of the original dataset.

2. Oversampling: In cases where one class is underrepresented in the dataset, oversampling involves creating more instances of the minority class. This can be done by randomly duplicating instances or using techniques like Synthetic Minority Over-sampling Technique (SMOTE) to generate synthetic instances.

3. Undersampling: In contrast to oversampling, undersampling involves reducing the number of instances in the majority class to balance the dataset. This can be done randomly or by using techniques like Tomek links or Edited Nearest Neighbors (ENN) to remove instances that are close to the boundary between classes.

4. Diverse data collection: This technique involves collecting data from various sources and ensuring that the dataset is representative of the population. This can help reduce bias by ensuring that the data includes a diverse range of perspectives and experiences.

5. Data augmentation: This technique involves creating new instances by applying transformations to the existing data, such as rotation, scaling, or flipping. This can help increase the size of the dataset and reduce overfitting.

6. Reweighing: In some cases, it may be possible to reweigh instances in the dataset to reduce bias. For example, if one class is underrepresented, instances in that class can be given more weight during training.

7. Fairness-aware machine learning: This technique involves modifying the machine learning algorithm to ensure that it does not discriminate against certain groups. This can be done by adding constraints to the optimization problem or by using techniques like adversarial debiasing.

In summary, while the provided context does not contain information about techniques used to address data bias during preprocessing of the deep learning pipeline, common techniques used to address data bias in machine learning and data science include stratified sampling, oversampling, undersampling, diverse data collection, data augmentation, reweighing, and fairness-aware machine learning.