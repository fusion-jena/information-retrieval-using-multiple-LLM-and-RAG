Based on the provided context, there are several postprocessing steps mentioned after the model training phase. However, the text does not explicitly use the terms "Saliency maps" or "Confusion matrix." Here are the postprocessing steps mentioned in the context:

1. Metrics calculation: The models were evaluated based on several metrics, including Area Under the Curve AUC (Hanley and McNeil, 1982), True Skill Statistics TSS (Monserud and Leemans, 1992), Cohenâ€™s KAPPA (Allouche et al., 2006), point-biserial correlation COR (Elith et al., 2010), and Receiver Operator Characteristics ROC (Hanley and McNeil, 1982). These metrics were calculated to assess the model performance.

2. Threshold determination: For the model threshold, the sensitivity-specificity sum maximization technique was employed (Liu et al., 2005). This technique helps in determining the optimal threshold for classifying the data points into their respective categories.

3. Bootstrapping: Bootstrapping was used to provide unbiased predictive accuracy with a sufficiently low variance (Harrell et al., 2005; Lima et al., 2019). This technique involves resampling the data with replacement and then fitting the model to the resampled data. This process is repeated multiple times to estimate the model's performance.

4. Generation of ROC curves: ROC curves were generated after 10-fold bootstrapping. These curves help visualize the model's performance in predicting the presence and absence of the target variable.

5. Relative variable importance assessment: The context also mentions an assessment for relative variable importance. However, the specific method used for this assessment is not provided in the text.

In summary, the postprocessing steps involved after the model training phase include metrics calculation, threshold determination, bootstrapping, generation of ROC curves, and relative variable importance assessment. However, the text does not explicitly mention the use of saliency maps or confusion matrices.