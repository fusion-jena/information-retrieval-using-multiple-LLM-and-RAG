Based on the provided context, there is no explicit information about the preprocessing steps involved before training a deep learning model. However, some of the papers discuss data processing techniques that could be relevant in the context of deep learning preprocessing.

In the paper "Ecological risk assessment of Shan Xin mining area based on remote sensing and geography information system technology" by Li et al. (2018), the authors discuss the process of data collection and preprocessing for remote sensing data. They mention obtaining data from various sources, such as Resource Environment Science and Data Research Center Data Center, Geospatial Data Cloud, and Openstreetmap. After obtaining the data, they perform preprocessing steps, including data format unification, data cleaning, and data normalization. Data normalization is an essential step to ensure that different variables contribute proportionally to the model.

In the paper "Habitat quality assessment of mining cities based on InVEST model - a case study of Yanshan County, Jiangxi Province" by Li et al. (2022), the authors use the InVEST model for habitat quality assessment. The InVEST model requires input data, such as land use data, climate data, and biodiversity data. Before using these data, the authors preprocess them by ensuring data consistency, filling data gaps, and normalizing data.

In deep learning, data preprocessing is a crucial step before training a model. Some common preprocessing techniques include:

1. Data cleaning: Removing or correcting erroneous data points that could negatively impact the model's performance.
2. Data normalization: Scaling data to a similar range to ensure that different features contribute proportionally to the model.
3. Data augmentation: Increasing the size of the dataset by applying transformations, such as rotation, scaling, or flipping, to the existing data.
4. Feature scaling: Transforming features to have a similar scale, such as standardization or normalization.

Therefore, based on the provided context and general practices in deep learning, the preprocessing steps involved before training a deep learning model typically include data cleaning, normalization, and feature scaling.