Answer:::

The provided context discusses the training of deep neural network (DNN) models for bioacoustic applications, specifically for bird species classification. However, it does not explicitly mention the preprocessing steps taken before training the models. Nevertheless, based on common practices in machine learning and the information given, we can infer some preprocessing steps that were likely involved.

1. Normalization: This process involves scaling input features to a similar range to avoid any feature dominating the learning process. In the context of audio data, features like spectrograms or Mel-frequency cepstral coefficients (MFCCs) might be normalized. The Gupta et al. (2021) paper uses recurrent convolutional neural networks for large-scale bird species classification, which suggests that some form of normalization was applied to the input data.

2. Scaling: Similar to normalization, scaling involves changing the range of features. In the context of DNNs, scaling can help avoid numerical issues during training. The He et al. (2015) paper on deep residual learning for image recognition discusses the importance of proper scaling for effective training, which can be extrapolated to audio data for DNN training.

3. Cleaning: This step typically involves removing noise or unwanted parts from the audio data. For bird species classification, this might include removing background noise or segments without bird sounds. Although not explicitly mentioned, it is a common preprocessing step in machine learning and is likely to have been applied.

4. Feature Extraction: In the context of audio data, feature extraction involves converting the raw audio data into a more suitable format for DNN training. This might include generating spectrograms or MFCCs. The Gupta et al. (2021) paper mentions using MFCCs as input features, indicating that feature extraction was performed.

In summary, while the provided context does not explicitly mention the preprocessing steps taken before training DNN models, it is likely that normalization, scaling, cleaning, and feature extraction were performed, based on common practices in machine learning and the information given.