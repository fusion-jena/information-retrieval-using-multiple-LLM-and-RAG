Answer:::

The hyperparameters of the models are optimized using various methods such as grid search, random search, manual tuning, and Bayesian optimization. However, the specific method used for each of the nine grid search ML models with fivefold cross-validation listed in Table 2 is not mentioned in the context.

For the ET model, the hyperparameters were carefully tuned using a technique that tweaked many hyperparameters to maximize performance. The types of hyperparameters and their default ranges were considered during tuning. The n\_estimators, max\_depth, and random\_state parameters were used in this tuning process. Additionally, the min\_samples\_split parameter was set to the minimum amount of samples needed to split an internal node, and the min\_samples\_leaf argument was defined to better represent leaf nodes. The max\_features argument, which determines the best split, was carefully selected and adjusted to balance model complexity, convergence speed, and generalization to improve the ET model's performance.

For the RF model, extensive experimentation was conducted using varying numbers of trees for the optimal fit. However, the specific method used for hyperparameter tuning is not mentioned.

For the gradient boosting model, the context only mentions that it is tuned, but it does not specify the method used for hyperparameter optimization.

In general, hyperparameter tuning plays a crucial role in optimizing the performance of a model by improving its ability to predict observed and predicted ranges. The tuning process maximizes the models training and testing performance and controls overfitting or underfitting issues. There are many optimizing methods available, such as manual tuning, Bayesian optimization, and random grid search methods, but choosing the best method for specific data is challenging.

Therefore, while the context provides some information on how hyperparameters were tuned for specific models, it does not provide a comprehensive answer to the question of how the hyperparameters of the models were optimized.