Answer:::
In the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are not explicitly mentioned. However, there are several techniques commonly used in deep learning to prevent overfitting, such as L1 and L2 regularization, dropout, data augmentation, and early stopping.

L1 and L2 regularization are methods that add a penalty term to the loss function to prevent the model from learning overly complex patterns in the training data. L1 regularization adds a penalty equal to the absolute value of the model's weights, while L2 regularization adds a penalty equal to the square of the model's weights. These penalties encourage the model to learn smaller weights, which can help prevent overfitting.

Dropout is a technique that randomly sets a fraction of the model's neurons to zero during training. This helps prevent overfitting by reducing the co-adaptation of neurons and promoting the learning of more robust features.

Data augmentation is a method that generates new training examples by applying random transformations to the existing data. This can help prevent overfitting by increasing the size and diversity of the training data.

Early stopping is a technique that monitors the model's performance on a validation set during training and stops training when the performance starts to degrade. This helps prevent overfitting by stopping the training process before the model starts to learn overly complex patterns in the training data.

In the context provided, the authors used a combination of techniques to prevent overfitting, including data splitting, hyperparameter tuning, and model selection. They split the dataset into training, validation, and testing sets, and used a ratio of 80:10:10. They also conducted initial computational experiments with different combinations of epochs and batch sizes to determine the optimal hyperparameters for training. Finally, they trained five different versions of the YOLOv5 model family to detect alates on sorghum leaves. However, the specific regularization methods used are not mentioned.