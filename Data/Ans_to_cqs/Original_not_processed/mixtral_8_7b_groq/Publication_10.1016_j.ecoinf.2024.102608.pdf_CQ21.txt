Based on the provided context, there is no explicit information about the postprocessing steps involved after the model training. The text mainly focuses on the process of hyperparameter tuning using randomized grid search methods and the selection of hyperparameters that resulted in the minimum MAE and RMSE, as well as the highest R2, for each machine learning model.

However, it is common practice in machine learning to calculate various metrics and evaluate the performance of the model after training. Some of these postprocessing steps could include:

1. Metrics calculation: This involves calculating various evaluation metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), R-squared (R2), and others, depending on the problem and the data.
2. Confusion matrix: In case of classification problems, a confusion matrix can be used to evaluate the performance of the model. It provides information about the number of true positives, true negatives, false positives, and false negatives.
3. Saliency maps: Saliency maps are a way to visualize the importance of input features for a particular prediction. It can be useful for understanding the model's decision-making process and identifying any potential issues.
4. Model interpretation: This involves interpreting the model's output and understanding how it relates to the problem at hand. It can include techniques such as feature importance, partial dependence plots, and others.

It is important to note that the specific postprocessing steps may vary depending on the problem, the data, and the machine learning model used. In the provided context, there is no mention of any specific postprocessing steps, so it is not possible to provide a definitive answer.