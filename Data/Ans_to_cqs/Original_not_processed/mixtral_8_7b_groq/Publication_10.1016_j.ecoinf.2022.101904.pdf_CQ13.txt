Answer:::
The provided context does not give specific information about the hyperparameters used in the deep learning models. The focus of the text is on comparing the performance of various models for wetland mapping and discussing the computational cost of these models.

However, it is common practice in deep learning to use hyperparameters such as learning rate, optimizer, batch size, and number of epochs. The choice of these hyperparameters can significantly impact the performance of the model. Therefore, it is likely that the authors tuned these hyperparameters during their experiments.

For example, the learning rate determines the step size at each iteration while moving toward a minimum of the loss function. An optimizer is a method that updates the model's parameters based on the gradient of the loss function. The batch size determines the number of samples processed before the model's weights are updated. The number of epochs determines the number of times the learning algorithm will work through the entire training dataset.

In conclusion, while the provided context does not give specific information about the hyperparameters used in the deep learning models, it is common practice to use hyperparameters such as learning rate, optimizer, batch size, and number of epochs in deep learning. The authors likely tuned these hyperparameters during their experiments.