Answer:::
The deep learning model used in the study is a Multi-Layer Perceptron (MLP), which is a type of Artificial Neural Network (ANN). The MLP model implemented in this study has an input layer, three hidden layers, and an output layer. The hyperparameters used in this MLP model include:

1. Solvers: The solver is an optimization algorithm used to train the MLP model. The study tested four solvers, including Limited-Broyden–Fletcher–Goldfarb–Shanno (L-BFGS), Adam, Stochastic Gradient Descent (SGD) with a constant learning rate, and SGD with an adaptive learning rate.
2. Number of neurons in the hidden layers: The study tested the number of neurons in the hidden layers ranging from 1 to 100.
3. Regularization factor (alpha): The regularization factor, also known as L2 penalty, is used to prevent overfitting. The study used a regularization factor of 10.
4. Activation function: The activation function is used to introduce non-linearity in the model. The study tested four activation functions, including identity, logistic, tanh, and Rectified Linear Unit (ReLU).
5. Learning rate: The learning rate determines the step size at each iteration while training the model. The study tested three learning rates, including constant, invscaling, and adaptive.

In addition to the MLP model, the study also tested a Random Forest (RF) model. The hyperparameters used in the RF model include the number of decision trees in the forest, the maximum depth of the decision tree, the number of features considered by each tree when splitting a node, and the maximum number of levels in the decision tree.

The study used a grid search technique to compute the optimum values of hyperparameters for both the MLP and RF models. The performance of different hyperparameters was compared, and the configuration that optimized the performance of the model was adopted for analysis. The study selected the best model based on the performance scores of all possible combinations of hyperparameters.

In summary, the deep learning model used in the study is an MLP model with five hyperparameters, including solver, number of neurons in the hidden layers, regularization factor, activation function, and learning rate. The study used a grid search technique to compute the optimum values of hyperparameters and selected the best model based on the performance scores.