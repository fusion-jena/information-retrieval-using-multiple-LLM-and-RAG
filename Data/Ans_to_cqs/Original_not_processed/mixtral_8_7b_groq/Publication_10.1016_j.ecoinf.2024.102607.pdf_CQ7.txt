Based on the provided context, the specific criteria used to split the data for deep learning model training (e.g., train, test, validation) are not mentioned. However, it does discuss various sampling techniques used in land use and land cover (LULC) mapping for addressing the problem of unbalanced training data. These techniques include major category undersampling, minor category oversampling, and combinations of oversampling and under-sampling.

In the context of this article, the authors introduce a Space-Spectrum Array-Tile Probabilistic Random Forest (SSA-TPRF) model for LULC mapping. This model uses a hexagonal random-sampling strategy along with a tile model to improve the accuracy of LULC mapping in regions with highly heterogeneous landscapes. The tile model is used to partition the study area into multiple tiles, and the SSA-TPRF model is then applied to each tile.

The experimental group design (Table 4) mentions different tile sizes used in the SSA-TPRF model, but it does not explicitly mention how the data is split for training, testing, or validation purposes. It is important to note that the process of splitting data into training, testing, and validation sets is a common practice in machine learning to evaluate the model's performance and prevent overfitting.

In deep learning model training, data splitting criteria often include:

1. Train-Test Split: This is the simplest method of splitting the data, where a portion of the data (e.g., 70-80%) is used for training, and the remaining portion (e.g., 20-30%) is used for testing.

2. K-Fold Cross-Validation: In this method, the data is divided into 'K' subsets or folds. The model is then trained on 'K-1' folds, while the remaining fold is used for testing. This process is repeated 'K' times, with a different fold used for testing each time. The average performance across all 'K' runs is used as the final performance metric.

3. Stratified Sampling: In cases where the data is imbalanced or has a class distribution that needs to be maintained, stratified sampling can be used. This method ensures that each subset (train, test, or validation) has a similar distribution of classes as the original dataset.

In conclusion, while the provided context does not explicitly mention the criteria used for splitting data in deep learning model training, it is a common practice in machine learning and deep learning to split data into training, testing, and validation sets using methods such as train-test split, k-fold cross-validation, or stratified sampling.