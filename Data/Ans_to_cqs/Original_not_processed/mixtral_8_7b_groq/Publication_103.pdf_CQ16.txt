Answer:::
The criteria used to determine when training is complete in the context provided is not explicitly stated. However, based on common practices in machine learning, it is likely that the training process is determined by some form of validation loss plateau or convergence.

In the experiment described, the authors use cross-herbaria transfer learning, where a model trained on one herbarium (France) is fine-tuned on a different herbarium (Costa Rica). This method typically involves training the model on the new dataset until the performance on a validation set stops improving or reaches a satisfactory level.

The authors mention that they use "Top-1 accuracy" and "Top-5 accuracy" as performance metrics, which could be used to assess the model's performance during training. Specifically, if the Top-1 or Top-5 accuracy on the validation set does not improve for a certain number of epochs, the training process could be considered complete.

Furthermore, the authors use a technique called early stopping, which is a form of regularization used to avoid overfitting. Early stopping involves monitoring the performance of the model on a validation set during training and terminating the training process if the performance starts to degrade. This technique can help prevent the model from overfitting to the training data and improve its generalization performance.

Therefore, while the specific criteria used to determine when training is complete are not provided, it is likely that the authors use some form of validation loss plateau or convergence, possibly in conjunction with early stopping, to determine when to terminate the training process.