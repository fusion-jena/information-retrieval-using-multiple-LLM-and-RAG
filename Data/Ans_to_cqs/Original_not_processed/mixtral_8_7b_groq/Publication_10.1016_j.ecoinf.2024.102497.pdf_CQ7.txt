Based on the provided context, the question asks about the criteria used to split data for deep learning model training. However, the context does not provide information specific to deep learning models. Instead, it discusses CART (Classification and Regression Tree) and Random Forest Regression (RFR) models. Therefore, I will provide an answer based on these two algorithms.

In both CART and RFR, data splitting is an essential step. However, the context focuses more on the data preprocessing and model parameter tuning rather than the data splitting criteria. Generally, for any machine learning algorithm, including CART and RFR, data splitting is done using techniques like train-test splits or k-fold cross-validation.

1. Train-test split: In this method, the dataset is divided into two subsets: a training set and a test set. The training set is used to train the model, while the test set is used to evaluate the model's performance. The data split ratio can vary, but common choices are 70-30, 80-20, or 90-10 for the training-test split.

2. k-fold cross-validation: This technique is an extension of the train-test split method. The dataset is divided into 'k' subsets or folds. The model is trained on 'k-1' folds, and the remaining fold is used for testing. This process is repeated 'k' times, with each fold used once for testing. The average performance across all 'k' iterations is calculated to evaluate the model's performance.

In the context, the data is acquired from GF-6 (WFV) and preprocessed, including radiometric calibration, atmospheric correction, geometric correction, and image cropping. However, the specific data splitting criteria are not mentioned. It can be assumed that a data splitting technique, such as train-test split or k-fold cross-validation, was applied before training the CART and RFR models.

Answer:::
The provided context discusses CART and RFR models, but it does not offer specific information about the criteria used to split data for deep learning model training. However, in machine learning, data splitting techniques like train-test split and k-fold cross-validation are commonly used for model training and evaluation.