Answer:::

The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does discuss the methodology used for selecting the optimal model parameters in a species distribution modeling study.

In this study, various feature classes (L, Q, LQ, LQP) and regularization multipliers (from 0.5 to 5) were tested using delta.AICc as the metric to determine the best tuning parameters. The optimal model was the one with the minimum delta.AICc value (delta.AICc = 0), and a model with delta.AICc <2 was considered credible. Cross-validation was employed, and the threshold was derived from the average output of the five models.

For model evaluation, nine algorithms (Bioclim, Mahalanobis, Domain, GLM (gaussian), GLM (binomial), GLM (poisson), MaxEnt, Random Forest, and SVM) were assessed using AUC-ROC and Cohen's KAPPA metrics. MaxEnt emerged as the most suitable model, striking a balance between accuracy and robustness.

In the context of deep learning model training, data splitting is crucial for evaluating model performance and preventing overfitting. Common practices include dividing the data into training, validation, and test sets. The training set is used to train the model, the validation set is used for hyperparameter tuning and model selection, and the test set is used for final evaluation.

However, the specific criteria used for data splitting in the provided context are not mentioned. These criteria can vary depending on the dataset, problem, and deep learning architecture. Common approaches include random sampling, stratified sampling, or time-series splitting for temporal data.

Answer:::

In summary, the provided context discusses the methodology for selecting optimal model parameters and evaluating model performance in a species distribution modeling study. However, it does not explicitly mention the criteria used for splitting the data for deep learning model training. Common practices for data splitting in deep learning include dividing the data into training, validation, and test sets using methods such as random sampling, stratified sampling, or time-series splitting.