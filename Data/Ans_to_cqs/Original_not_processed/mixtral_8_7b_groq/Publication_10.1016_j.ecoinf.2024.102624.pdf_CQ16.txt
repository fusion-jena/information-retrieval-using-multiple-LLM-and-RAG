Based on the provided context, there is no explicit information about the specific criteria used to determine when training is complete in the mentioned studies. However, it is mentioned that in the model building phase, 10-fold cross-validation with three repetitions was applied to the training dataset. This approach helps find the best models with the largest overall accuracy (OA) and reflects the distribution of 30 OAs with minimums, maximums, quartiles, and medians. The smaller the range of possible model outcomes (OAs), the more reliable the prediction. This suggests that the training process might be complete when the range of possible model outcomes (OAs) becomes minimal or stabilizes, indicating that the model has reached its optimal performance on the training data.

Moreover, the context also mentions that training data augmentation was used to enhance the generalization capabilities. This technique involves extending the existing training data, which could imply that the training process is complete when the model's performance on the augmented training data reaches a satisfactory level or stops improving significantly.

In summary, while the provided context does not give explicit details about the criteria used to determine when training is complete, it can be inferred that the training process might be considered complete when the model's performance on the training data (OAs) stabilizes or when the model demonstrates satisfactory performance on extended or augmented training data. However, it is important to note that these are possible inferences based on the given information and may not apply to all machine learning scenarios.