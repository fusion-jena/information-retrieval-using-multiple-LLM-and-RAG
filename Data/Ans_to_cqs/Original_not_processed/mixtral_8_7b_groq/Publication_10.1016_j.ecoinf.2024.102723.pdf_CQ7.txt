Answer:

The data was split into three sets for training, validation, and testing of the deep learning models. A 60-20-20 splitting of the dataset was used, meaning that 60% of the data was used for training, 20% for validation, and the remaining 20% for testing. This splitting was done in a stratified manner, based on two factors: the year (2008-2010) and location (19 different stations). Stratified sampling ensures that the distribution of the data in the training, validation, and test sets is representative of the original dataset. This is important for the generalizability of the model, as it ensures that the model is exposed to the same distribution of data during training as it will encounter during deployment.

The purpose of the validation set is to provide an unbiased evaluation of the model during the training process. The model is trained on the training set, and its performance is evaluated on the validation set at regular intervals during training. This allows for the early stopping of the training process if the model's performance on the validation set starts to degrade, which helps to prevent overfitting.

The test set is used to evaluate the final performance of the trained model. It is the only set that the model has not seen during training, so it provides an unbiased estimate of how the model will perform on new, unseen data.

In summary, the criteria used to split the data for deep learning model training include a 60-20-20 splitting of the dataset, stratified sampling based on year and location, and the use of a validation set for unbiased evaluation during training and a test set for final performance evaluation.