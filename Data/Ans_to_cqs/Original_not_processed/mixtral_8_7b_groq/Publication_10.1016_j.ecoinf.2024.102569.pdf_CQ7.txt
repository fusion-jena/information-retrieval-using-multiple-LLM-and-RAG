Answer:
The provided context does not contain specific information about the criteria used to split the data for deep learning model training. However, it does discuss the Root Trimmed Mean Squared Prediction Error (RTMSPE) used for tuning parameters in a model. The RTMSPE is a measure of the difference between predicted and actual values, and it trims a certain proportion of observations with the highest squared residuals. This can be useful for reducing the impact of heterogeneous observations on the model.

In the context of deep learning, data splitting is typically done to create separate sets for training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model performance.

The criteria used to split the data can vary depending on the specific problem and dataset. One common approach is to randomly split the data into training, validation, and testing sets, ensuring that each set has a representative sample of the data. Another approach is to use time series data and split it into training, validation, and testing sets based on time, with the training set containing earlier data and the testing set containing later data.

In summary, while the provided context does not specifically mention the criteria used to split the data for deep learning model training, it does discuss a measure of prediction error that can be useful for tuning model parameters. The criteria used to split the data can vary depending on the specific problem and dataset, and common approaches include random splitting and time-based splitting.