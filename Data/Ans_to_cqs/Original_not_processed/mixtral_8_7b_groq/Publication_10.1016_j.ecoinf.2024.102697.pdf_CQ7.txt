Based on the provided context, there is no direct information about the criteria used to split the data for deep learning model training. However, it does mention that for machine learning models, a repeated nested k-fold cross-validation approach was employed. This approach involved an outer 10 k-fold cross-validation, which provided an initial division of the data into holdout data and data for model development. An inner 5 k-fold cross-validation was then used to minimize the bias caused by tuning of hyperparameters on training results.

In the context of deep learning, data splitting criteria typically include train, validation, and test sets. The train set is used for training the model, the validation set is used for tuning hyperparameters and model selection, and the test set is used for evaluating the final model performance.

However, the provided context does not mention any specific criteria for deep learning model data splitting. It is possible that a different data splitting approach was used for deep learning models, or that it was not specified in the given sections.

Therefore, based on the provided context, the criteria used to split the data for deep learning model training are not explicitly stated.