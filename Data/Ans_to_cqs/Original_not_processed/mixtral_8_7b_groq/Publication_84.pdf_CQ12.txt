Answer:::
The specific type of deep learning model used in the study mentioned is a Stacked Autoencoder (SAE). This information can be inferred from the abstract's statement "Autoencoder-based deep learning for remote-sensing image classification" and the comparison experiment conducted between SAE and SVM.

A Stacked Autoencoder (SAE) is a type of artificial neural network that is used for learning efficient codings of input data. It is called a "stacked" autoencoder because it is formed by stacking multiple layers of autoencoders. An autoencoder is a type of neural network that is trained to reconstruct its input data. It consists of two parts: an encoder, which maps the input data to a hidden representation, and a decoder, which maps the hidden representation back to the original input data.

SAEs are used for unsupervised pre-training of deep learning models. They are trained to reconstruct the input data, and the hidden representations learned by the encoder can be used as the initial weights for a supervised deep learning model. This pre-training step helps to overcome the problem of vanishing gradients, which is a common issue in training deep neural networks.

In summary, the study mentioned uses a Stacked Autoencoder (SAE) as the deep learning model in their pipeline. The SAE is used for unsupervised pre-training of a deep learning model for remote-sensing image classification.