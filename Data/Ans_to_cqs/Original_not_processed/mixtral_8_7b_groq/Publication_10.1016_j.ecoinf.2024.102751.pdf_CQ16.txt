Based on the provided context, there is no direct information about the specific criteria used to determine when training is complete in a machine learning model. However, it is common in statistical learning and machine learning to use a validation loss plateau as a criterion for determining when training is complete. This involves monitoring the performance of the model on a validation dataset during the training process. If the model's performance on the validation dataset stops improving or begins to degrade, even as the model continues to fit the training data better, this indicates that the model is starting to overfit the training data. At this point, the training process can be stopped to avoid overfitting.

In the context of the study mentioned, the model's accuracy was evaluated using Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and R-squared (R2) values. These metrics could also be used to monitor the model's performance during the training process. If the MAE, RMSE, or R2 values on the validation dataset stop improving or begin to degrade, this could be used as an indication that the model is starting to overfit the training data and the training process should be stopped.

Additionally, the study mentioned that exploring machine learning algorithms could further improve the predictive power of the model. This suggests that the authors may have experimented with different algorithms and tuned their hyperparameters to improve the model's performance. In this context, cross-validation could have been used as a technique to determine when training is complete. Cross-validation involves dividing the dataset into k folds, training the model on k-1 folds, and evaluating its performance on the remaining fold. This process is repeated k times, each time with a different fold used as the validation set. The average performance across the k folds can then be used to determine when training is complete.

In summary, while the provided context does not give specific information about the criteria used to determine when training is complete, it is common to use a validation loss plateau as an indication that the model is starting to overfit the training data. Other techniques such as cross-validation could also be used to determine when training is complete.