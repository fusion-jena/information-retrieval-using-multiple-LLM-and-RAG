Answer:::

The context provided does not give specific details about the criteria used to determine when training is complete. However, it does mention that the root mean squared error (RMSE) and the coefficients of determination (R2) were used as metrics for model evaluation. It is common practice in machine learning to use a validation set to monitor the performance of the model during training and to determine when to stop training. One common approach is to stop training when the validation loss plateaus or starts to increase, indicating that the model is overfitting to the training data.

In the context, it is mentioned that data was divided into training, validation, and testing subsets, and that models were evaluated using RMSE and R2 metrics on these subsets. Additionally, it is mentioned that efforts were made to avoid overfitting and that the training, validation, and testing performance were compared to avoid overfitting. This suggests that a validation set was used to monitor the performance of the model during training and to determine when to stop training.

It is also worth noting that the context mentions that a hyperparameter search was performed over two sites, considering the activation function, the optimizer, and the learning rate. This search was done to find the best-performing model, and it is likely that the validation set was used to evaluate the performance of the models during this search.

In summary, while the context does not provide specific details about the criteria used to determine when training is complete, it is likely that a validation set was used to monitor the performance of the model during training and to determine when to stop training, using a validation loss plateau or increase as an indicator of overfitting.