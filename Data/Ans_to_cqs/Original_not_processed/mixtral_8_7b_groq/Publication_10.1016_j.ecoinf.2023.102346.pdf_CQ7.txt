Answer:::

The provided context discusses the use of various machine learning algorithms for habitat suitability prediction and the evaluation of their performance, but it does not explicitly mention the criteria used to split the data for deep learning model training. However, it does discuss the evaluation of models using metrics such as AUC, ROC, TSS, KAPPA, and COR, which are commonly used for assessing the performance of machine learning models.

In general, when training deep learning models, it is common to split the data into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and evaluate the model during the training process, and the testing set is used to evaluate the final model's performance.

The criteria used to split the data can vary depending on the specific problem and dataset. However, there are some common practices for splitting the data. One common approach is to randomly split the data into training, validation, and testing sets, with a typical split being 70% for training, 15% for validation, and 15% for testing. This approach assumes that the data is independent and identically distributed (i.i.d.), which may not always be the case.

Another approach is to use stratified sampling when splitting the data. Stratified sampling ensures that each subset has approximately the same percentage of samples from each class in the case of a classification problem. This approach can be useful when the classes are imbalanced.

In some cases, it may be appropriate to use cross-validation, where the data is split into multiple folds, and the model is trained and evaluated on each fold. This approach can help reduce overfitting and provide a more robust estimate of the model's performance.

In summary, while the provided context does not explicitly mention the criteria used to split the data for deep learning model training, it is common to split the data into training, validation, and testing sets. The criteria used to split the data can vary depending on the specific problem and dataset, and common approaches include random splitting, stratified sampling, and cross-validation.