Answer: The strategy implemented to monitor the model performance during training involves several techniques to ensure the accuracy and prevent overfitting or underfitting. Firstly, the model is trained with different epoch values, specifically 100, 200, 250, and 150, to determine more accurate training results and observe the effect of epochs on the training result. The training summary for each of these epochs is presented in Tables 5, 6, and 7 for epochs 100, 200, and 250, respectively. The mAP values trends with increasing epochs are shown in Figs. 14 and 15.

Secondly, the size of the dataset used for custom training is sufficiently large, and the deep learning (DL) model used in this work is tuned with optimized hyperparameters. These hyperparameters are based on the optimized values for YOLOv5 COCO training from scratch. Overfitting and underfitting situations are prevented from occurring by avoiding the effort to over-train the model and adopting graded MSE convergence to fine-tune the model.

Thirdly, the model's performance is further monitored using various evaluation metrics, such as confusion matrix (Fig. 6), F1 curve (Fig. 7), P curve (Fig. 8), PR curve (Fig. 9), R curve (Fig. 10), and final training plots (Fig. 11). These metrics provide a comprehensive understanding of the model's performance during training.

Lastly, some training batch outputs are shown in Fig. 12, and validation outputs are shown in Fig. 13. These outputs provide a visual representation of the model's performance during training.

In summary, the strategy implemented to monitor the model performance during training involves training the model with different epoch values, using a sufficiently large dataset, tuning the model with optimized hyperparameters, monitoring the model's performance using various evaluation metrics, and providing visual representations of the model's performance during training.