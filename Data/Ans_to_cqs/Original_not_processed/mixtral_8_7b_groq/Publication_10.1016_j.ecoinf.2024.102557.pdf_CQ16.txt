Based on the provided context, there is no explicit information about the specific criteria used to determine when training is complete for the machine learning models. However, it is mentioned that environmental cross-validation with ten folds was performed to represent the new environment’s predictive error accurately. This process involves dividing the data into ten subsets, training the model on nine of the subsets, and testing it on the remaining subset. This process is repeated ten times, with a different subset used for testing each time. The root mean squared error (RMSE) of the predictions is used as a metric to evaluate the performance of the trained models.

In addition, Bayesian optimization was used to tune the hyperparameters of the species-specific models, with the goal of reducing the RMSE of the predictions. The search space of optimal hyperparameters was defined by the ranges of “mtry”, “min.node.size”, and “num.trees”. However, the context does not mention any specific criteria for determining when training is complete.

It is also worth noting that the authors mentioned that they evaluated the trained models according to their predictive accuracy and ecological interpretation of their predictors. They used Partial Dependence Plots (PDPs) to uncover patterns between model predictors and species-specific productivity, and evaluated the resulting PDPs using existing scientific knowledge to determine whether the patterns found were ecologically consistent.

In summary, while the context does not provide specific information on the criteria used to determine when training is complete, it does mention that environmental cross-validation and RMSE of the predictions were used to evaluate the performance of the trained models. Additionally, Bayesian optimization was used to tune the hyperparameters of the models, and the authors evaluated the trained models according to their predictive accuracy and ecological interpretation of their predictors.