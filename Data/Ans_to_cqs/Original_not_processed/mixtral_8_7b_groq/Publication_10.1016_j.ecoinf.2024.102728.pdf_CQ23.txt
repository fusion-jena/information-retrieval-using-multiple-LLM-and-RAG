Based on the provided context, there are no specific details about the measures taken to ensure the generalizability of the deep learning model mentioned in the Mohedano et al., 2017 study. However, there are some measures commonly used to ensure the generalizability of deep learning models, such as using a diverse dataset, cross-validation, and stratified splitting.

Using a diverse dataset is a crucial step in ensuring the generalizability of a deep learning model. The model should be trained on a dataset that covers a wide range of variations in the input data. In the context of the Mohedano et al., 2017 study, the dataset used for object retrieval with deep convolutional neural networks may have been diverse, but there is no explicit mention of this in the provided context.

Cross-validation is another technique used to ensure the generalizability of deep learning models. Cross-validation involves dividing the dataset into multiple subsets, training the model on one subset, and testing it on another. This process is repeated for all possible combinations of subsets, providing an estimate of the model's performance on unseen data. Again, the provided context does not mention whether cross-validation was used in the Mohedano et al., 2017 study.

Stratified splitting is a technique used to ensure that the training and testing datasets have similar distributions of classes. This is particularly important in cases where the dataset is imbalanced, meaning that some classes are overrepresented compared to others. The provided context does not mention whether stratified splitting was used in the Mohedano et al., 2017 study.

In summary, while the provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model used in the Mohedano et al., 2017 study, it is still possible that such measures were taken. However, without further information, it is not possible to provide a definitive answer.