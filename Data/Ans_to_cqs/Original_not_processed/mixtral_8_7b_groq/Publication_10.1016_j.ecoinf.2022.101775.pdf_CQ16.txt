Answer:::

The criteria used to determine when training is complete in the context provided is not explicitly stated. However, it can be inferred that a validation loss plateau or a similar condition is likely used. During the training of the algorithms, 10% of the data was reserved as a validation set to check for overfitting. This implies that the training process likely involved monitoring the performance of the model on the validation set after each epoch, or a number of epochs, to ensure that the model was not overfitting to the training data. If the performance on the validation set did not improve or plateaued after a certain number of epochs, the training process would have been considered complete.

Another possible criterion could be based on the convergence of the model's parameters. The algorithms were trained for 100 epochs using the Adam optimizer, which is an adaptive learning rate optimization algorithm designed to improve the training speed and convergence of stochastic gradient descent. It is possible that the training was considered complete when the model's parameters converged to a satisfactory level or when the improvement in the parameters became negligible.

However, without explicit information on the training stopping criterion, it is difficult to provide a definitive answer. It is also possible that a combination of these or other criteria was used to determine when the training should be stopped.