Answer: The performance of the deep learning model is evaluated using several metrics, including accuracy, recall, F1 score, and mAp (mean average precision). Accuracy is the ratio of correct predictions to the total number of predictions. Recall, also known as sensitivity, is the ratio of true positives (correctly predicted positive instances) to the sum of true positives and false negatives (instances that were not predicted as positive but should have been). The F1 score is the harmonic mean of precision and recall, providing a balanced assessment of both measures. Precision is the ratio of true positives to the sum of true positives and false positives (instances predicted as positive but should have been negative).

The mAp (mean average precision) is a more comprehensive metric that considers both accuracy and recall. It is calculated as the average of the AP (average precision) for all categories. The AP is the area under the PR (precision-recall) curve, which plots precision against recall. It is calculated as the integral of precision with respect to recall from 0 to 1.

In the study, the mAp was chosen as the major model evaluation metric, comprehensively analyzing the model's detection accuracy, recall, and F1 scores. The model proposed in the study outperforms other models, such as Centernet, Efficientdet, FasterRCNN, YOLOv4, YOLOv5, YOLOv7, and YOLOx, in terms of mAp and mAp50-95. For example, when compared to YOLOv7, the mAp of YWnet is increased by 15.5 mAp, and mAp50-95 is increased by 12.2 mAp50-95, and the number of parameters is only half that of YOLOv7.