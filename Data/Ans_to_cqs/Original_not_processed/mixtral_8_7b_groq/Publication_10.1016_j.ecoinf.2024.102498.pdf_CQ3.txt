The provided context discusses the use of deep learning techniques, specifically Convolutional Neural Networks (CNNs), for Land Use and Land Cover (LULC) classification. However, it does not explicitly mention the data annotation techniques used in the deep learning pipeline. Nonetheless, I can provide some general information about common annotation techniques for deep learning.

In the context of computer vision and image analysis, data annotation is the process of labeling or marking up images to train machine learning models. For deep learning, annotation techniques can vary depending on the task. Here are some common annotation techniques:

1. Image-level annotation: This is the simplest form of annotation where the entire image is labeled with a single class. For example, an image might be annotated as 'forest', 'urban', or 'water'. This technique is often used for image classification tasks.

2. Bounding box annotation: In this technique, bounding boxes are drawn around objects of interest in an image. Each box is labeled with the class of the object it contains. Bounding box annotation is commonly used for object detection tasks, where the goal is to locate and identify objects within an image.

3. Semantic segmentation: This is a more detailed form of annotation where each pixel in an image is labeled with a class. This technique is used for pixel-level classification, where the goal is to classify every pixel in an image. Semantic segmentation can be used for tasks like scene understanding, where the aim is to identify different types of surfaces and objects in a scene.

4. Instance segmentation: This is a further refinement of semantic segmentation, where each instance of an object is separately segmented and labeled. For example, in an image of a forest, each individual tree would be segmented and labeled as 'tree'. Instance segmentation is used for tasks like object counting and tracking.

5. Pixel-wise annotation: This is similar to semantic segmentation, but it involves annotating images at a much finer scale. Each pixel is annotated with not just the class, but also additional attributes like color, texture, and shape. Pixel-wise annotation is used for tasks like material recognition and image synthesis.

Without more specific information from the provided context, it is difficult to say which of these annotation techniques would be used in a deep learning pipeline for LULC classification. However, based on the mentioned use of patch-wise processing and sophisticated features extracted from satellite imagery, it is likely that some form of pixel-wise or semantic segmentation would be used.