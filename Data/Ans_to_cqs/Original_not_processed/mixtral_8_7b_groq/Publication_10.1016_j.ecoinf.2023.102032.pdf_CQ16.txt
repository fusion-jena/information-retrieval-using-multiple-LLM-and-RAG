Based on the provided context, there is no specific information about the criteria used to determine when training is complete, such as a validation loss plateau. The context discusses the use of machine learning for cloud detection, but it does not go into detail about the training process or the specific metrics used to assess training progress.

However, it does mention that the approach used for cloud detection was tested for robustness by moving the input period forward and backward in time and extending it to different durations. These tests likely involved some form of evaluation or validation, but the specific criteria used for these tests are not provided.

In general, when training a machine learning model, it is common to monitor the validation loss or other metrics to assess the progress of training. When the validation loss plateaus or stops decreasing, it may be an indication that training is complete or that further training is unlikely to improve the model's performance. Other criteria that may be used to determine when training is complete include the convergence of the training and validation loss, the performance of the model on a separate test set, or the achievement of a predetermined threshold for model performance.

Without more specific information from the provided context, it is not possible to give a definitive answer to the query. However, it is likely that some form of validation or evaluation was used to assess the training of the machine learning model for cloud detection.