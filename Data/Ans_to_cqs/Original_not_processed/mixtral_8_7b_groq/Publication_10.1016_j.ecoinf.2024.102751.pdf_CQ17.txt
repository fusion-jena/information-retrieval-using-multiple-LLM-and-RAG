The provided context does not contain specific information about the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention the potential use of machine learning and deep neural networks for increasing the accuracy of soil moisture prediction.

In general, overfitting is a common problem in machine learning and deep learning, where a model learns the training data too well, including its noise, and performs poorly on unseen data. Regularization methods are used to prevent overfitting by adding a penalty term to the loss function, which discourages the model from learning overly complex patterns in the training data.

Two common regularization methods used in deep learning are dropout and L2 regularization. Dropout is a technique where randomly selected neurons are dropped out during training, which helps to prevent over-reliance on any single neuron and encourages the model to learn more robust features. L2 regularization, also known as weight decay, adds a penalty term to the loss function that is proportional to the square of the magnitude of the model's weights. This encourages the model to have smaller weights, which can help to prevent overfitting by reducing the complexity of the model.

It is worth noting that the context discusses the use of machine learning and deep neural networks for estimating soil moisture, but it does not provide specific details about the implementation of these methods. Therefore, it is not possible to say for sure which regularization methods were used in this particular case. However, dropout and L2 regularization are two commonly used methods for preventing overfitting in deep learning pipelines.