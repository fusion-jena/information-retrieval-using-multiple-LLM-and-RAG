Based on the provided context, there is no explicit mention of the data augmentation techniques applied in the deep learning pipeline. However, it is generally common practice to use data augmentation techniques such as flipping, rotating, and scaling to increase the diversity of the training data and improve the robustness of the model.

Flipping refers to horizontally or vertically flipping the images in the dataset. This technique helps the model to learn symmetrical features and prevent overfitting.

Rotating involves rotating the images by a certain angle, which can help the model to learn features that are invariant to orientation.

Scaling involves changing the size of the images, which can help the model to learn features that are invariant to scale.

These techniques can be easily implemented using deep learning libraries such as TensorFlow and PyTorch.

Therefore, while the provided context does not explicitly mention the data augmentation techniques used, it is reasonable to assume that techniques such as flipping, rotating, and scaling were used to augment the training data.