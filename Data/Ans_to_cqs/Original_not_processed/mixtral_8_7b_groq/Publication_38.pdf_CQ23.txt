Based on the provided context, it is mentioned that deep learning networks were used for bat acoustic signal detection and outperformed other baselines. However, the specific measures taken to ensure the generalizability of the deep learning model are not explicitly stated in the text. However, I can provide some general measures that are typically used to ensure the generalizability of deep learning models.

Firstly, the diversity of the dataset is crucial to ensure that the model can perform well on various types of data. In the context of bat acoustic signal detection, the dataset may include signals from different bat species, recorded in various environments, and at different times of the day. A diverse dataset can help the model to learn robust features that can be applied to new, unseen data.

Secondly, cross-validation is a commonly used technique to assess the performance and generalizability of a model. In k-fold cross-validation, the dataset is divided into k subsets, and the model is trained and tested k times, each time using a different subset for testing and the remaining k-1 subsets for training. The performance of the model is then averaged across the k runs, providing a more reliable estimate of its generalizability.

Thirdly, stratified splitting is another technique that can be used to ensure the generalizability of a model. In stratified splitting, the dataset is divided into subsets in a way that preserves the distribution of important variables. For example, if the dataset includes signals from two bat species, a stratified split would ensure that each subset contains a similar proportion of signals from each species. This can help to ensure that the model is not biased towards one particular subset of the data.

In summary, while the specific measures taken to ensure the generalizability of the deep learning model for bat acoustic signal detection are not provided in the context, it is likely that a diverse dataset, cross-validation, and stratified splitting were used. These techniques are commonly used to ensure that deep learning models can perform well on new, unseen data.