Answer:

The data annotation techniques used in the deep learning pipeline are not explicitly stated in the provided context. However, it is mentioned that the raw images were manually annotated using Make Sense with a single "bug" class, fully containing the visible outline of the NBSB insects. This suggests that the annotation method could be a form of semantic segmentation, where each image is labeled as a whole rather than individual instances being marked.

Semantic segmentation is a process in which each pixel of an image is classified into a specific class, providing a detailed understanding of the image content. In this case, the class would be "bug," and the entire visible outline of the NBSB insects would be enclosed within the annotation.

Instance segmentation, on the other hand, involves not only classifying each pixel but also distinguishing individual instances of objects within the same class. Although the context does not explicitly mention instance segmentation, it is possible that the annotation process included this technique if multiple NBSB insects were present in a single image and needed to be differentiated.

Unfortunately, the provided context does not offer enough information to definitively determine whether bounding box annotation was used. This technique involves drawing a box around the object of interest, and it is commonly used in object detection tasks. However, the context only mentions that the annotations contain the visible outline of the NBSB insects, which could imply either semantic segmentation or instance segmentation but not necessarily bounding box annotation.

In summary, the data annotation techniques used in the deep learning pipeline include manual annotation with a single "bug" class, likely encompassing semantic segmentation or instance segmentation. The context does not provide enough information to confirm the use of bounding box annotation.