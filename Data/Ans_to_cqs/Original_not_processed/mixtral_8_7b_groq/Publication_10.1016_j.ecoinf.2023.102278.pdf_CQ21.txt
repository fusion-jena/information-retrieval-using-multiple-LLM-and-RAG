Based on the provided context, there is no explicit information about the specific postprocessing steps applied after the model training. However, we can infer some steps based on the context and common practices in machine learning model training.

Answer:
The postprocessing steps involved after the model training could include:

1. Metrics calculation: The context provides the average precision, recall, and F1-score for the trained ResNet50 and EfficientNetB3 models with multitask learning (MTL) and without MTL. These metrics are commonly used for evaluating the performance of classification models.

2. Confusion matrix: The context does not explicitly mention the calculation of a confusion matrix. However, it is a common practice to calculate a confusion matrix to get a better understanding of the model's performance in terms of false positives, false negatives, true positives, and true negatives.

3. Saliency maps: The context does not provide any information about the use of saliency maps. Saliency maps are used for visualizing the important regions in the input data that contribute to the model's prediction.

4. Overfitting analysis: The context provides information about observing overfitting after nine epochs, where the validation loss starts to increase. Analyzing overfitting is an essential postprocessing step for understanding the model's generalization capability.

5. Hyperparameter tuning analysis: The context provides information about the variation of 0.8% when training with different values of Î±. Analyzing the impact of hyperparameters on the model's accuracy is an essential postprocessing step for understanding the model's sensitivity to hyperparameters.

In conclusion, based on the provided context, the postprocessing steps involved after the model training could include metrics calculation, confusion matrix, overfitting analysis, hyperparameter tuning analysis, and possibly saliency maps. However, the context does not explicitly mention all of these steps.