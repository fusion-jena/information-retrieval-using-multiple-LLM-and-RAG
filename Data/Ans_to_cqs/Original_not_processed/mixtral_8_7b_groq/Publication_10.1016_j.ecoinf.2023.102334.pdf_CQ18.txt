Answer:

The strategy implemented to monitor the model performance during training involves comparing the introduced model with five other models while keeping the experimental method and environment unchanged. Each model was trained, and the training results were illustrated in Figure 11. The proposed model was distinguished by a low loss rate and high accuracy. The stability of the proposed model was evident from the reasonably smooth curves and small fluctuations during training and testing.

Moreover, the performance of the model was further evaluated by obtaining the results of each model under unchanged training methods and parameters. The VGG model had a lower recognition accuracy compared to the model in this work. Although the traditional DenseNet has fewer parameters and a greater identification accuracy than ResNet, its recognition rate is lower than that of the model in this work. The Swin Transformer was found to be somewhat more accurate than the other models due to its sliding window design. However, it has excessive parameters and model size, consuming too many memory resources.

The proposed model exhibited the greatest identification accuracy but needs some improvement in terms of the number of parameters. The strategy also involved implementing Module 2, as shown in Figure 4, which differentiates samples with the help of the addition of s. The network tends to differentiate more between simple samples and less to complex samples when the s value is smaller. This strategy ensures that the data is not just separable across classes in feature space but also compact within classes for data with a complicated distribution. By keeping the class compact, a more robust decision result for samples with large intra-class variation can be derived.