Based on the provided context, there is no explicit information about the specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adam used in the deep learning pipeline. However, it can be inferred that a randomized grid search method was used for hyperparameter tuning, which is a type of optimization technique used to find the best set of hyperparameters for a machine learning model.

In the context, it is mentioned that "randomly selecting a subset of the parameter grid to explore" and "generated various cases by combining hyperparameter values extracted from a uniform distribution and evaluated their performance" which implies that a form of random search was used for hyperparameter tuning. Randomized grid search is a method that involves randomly selecting a subset of the parameter grid to explore, instead of an exhaustive search through all possible combinations of hyperparameters. This method is used to reduce computational cost and has been shown to find equally or more optimal solutions than an exhaustive grid search, particularly when some hyperparameters are more influential than others.

Additionally, it is mentioned that the algorithms' performance and parameter settings were assessed using a training and test set approach, which is a common method used to evaluate the performance of machine learning models. This method involves splitting the data into a training set and a test set, where the model is trained on the training set and then evaluated on the test set to assess its ability to generalize to unseen data.

In summary, while the context does not provide explicit information about the specific optimization techniques used in the deep learning pipeline, it can be inferred that a randomized grid search method was used for hyperparameter tuning and a training and test set approach was used for model evaluation.