Answer:::
Based on the provided context, there is no clear information about how the hyperparameters of the Extreme Learning Machine (ELM) model are optimized. The text does not mention any specific methods such as grid search, random search, or others. In fact, it highlights that ELMs have an advantage over other methods because they do not require fine manipulations to determine their operating parameters. This suggests that ELM may use a different approach for setting hyperparameters compared to other machine learning algorithms.

ELMs randomly create hidden nodes or hidden level parameters before seeing the training data, and all hidden-layer parameters are independent from the activation functions and from the training data. This randomness in setting up the model could be a substitute for the traditional hyperparameter optimization methods.

Furthermore, the Online Sequential ELM (OSELM) is an alternative technique for large scale computing and machine learning, particularly when data becomes available in a sequential manner. OSELM only requires the number of hidden nodes to be specified and has no prior knowledge as to how many training observations will be presented. This sequential learning algorithm does not seem to involve grid search or random search for hyperparameter optimization either.

However, the text mentions that a mathematical basis has been provided for the understanding of ELM, which implies that there might be a systematic way of setting up the model and its hyperparameters. Nonetheless, the provided context does not offer enough information to determine the specific method used for optimizing ELM's hyperparameters.

Answer::: (363 words)