The provided context does not include specific details about the preprocessing steps taken before training the deep learning models. However, it is common practice in deep learning to perform certain preprocessing techniques on the data before training. These steps can include:

1. Normalization: This process involves scaling the data to a smaller range, such as 0 to 1, to improve the training process. This is especially important when using optimization algorithms that rely on gradient calculations, as large values can result in very small gradient updates, leading to slow convergence.

2. Scaling: Similar to normalization, scaling involves adjusting the range of the data, but it can also include adjusting the mean and variance. This can help to ensure that all features contribute equally to the model's predictions.

3. Cleaning: This step involves removing any noise or outliers from the data that may negatively impact the model's performance. This can include removing missing values, handling extreme values, or removing irrelevant features.

In the context provided, it can be inferred that some preprocessing was done to the data before training the models, as the input time series length varies for each model. However, the specific preprocessing steps are not mentioned.

It is also worth noting that the specific preprocessing steps required may depend on the nature of the data and the problem being solved. Therefore, it is important to carefully consider the data and the problem at hand when deciding on the appropriate preprocessing steps.