Based on the provided context, there is no explicit information about the specific postprocessing steps applied after the model training, such as saliency maps, metrics calculation, or confusion matrix. However, the text does mention that model performance was evaluated with and without additional pre-training with external sound data prior to fine-tuning with sound data from their study site.

The evaluation process involved using training and validation XC mel-spectrograms to adjust the weights of each of the three CNN models for the pre-trained models. Then, fine-tuning was applied to both the default CNN backbones and the XC pre-trained CNNs using the ROI training and validation mel-spectrograms. This fine-tuning process consisted of two stages: (1) model training on the classifier only (i.e., dense, fully-connected layer), freezing all other trainable parameters in CNN layers for 10 epochs, and (2) fine-tuning all layers with a reduced learning rate.

Although not explicitly stated, it is common practice in machine learning to calculate metrics such as accuracy, precision, recall, and F1-score during the evaluation process. Additionally, a confusion matrix could be constructed to visualize the performance of the models, particularly in multi-class classification tasks. However, without further information, it is not possible to confirm if these or other postprocessing steps were carried out in this specific study.