Based on the provided context, there is no specific information given about the criteria used to determine when training is complete, such as a validation loss plateau. The context mainly focuses on the performance metrics of image classification for different land cover types.

However, in general, training of machine learning models, including image classification algorithms, is often considered complete when the validation loss reaches a plateau or starts to increase, even if the training loss continues to decrease. This is because a decreasing training loss does not always indicate better generalization to unseen data, and overfitting can occur if training is continued beyond this point.

In the context of image classification for land cover types, the performance metrics provided include mean Intersection over Union (mIoU) and accuracy for each class, as well as overall. These metrics can be used to evaluate the performance of the algorithm-based image classification and compare it to manual image classification.

The mIoU metric measures the overlap between the predicted segmentation mask and the ground truth mask, and is a common evaluation metric for semantic segmentation tasks. The accuracy metric measures the percentage of pixels that are correctly classified.

The mIoU values for each class vary, with some classes such as lichen and "other moss" having notably low mIoU values. This could be due to the low frequency of occurrence of these classes, as mentioned in the context.

Overall, while the provided context does not give specific information about the criteria used to determine when training is complete, it does provide performance metrics that can be used to evaluate the performance of the image classification algorithm.