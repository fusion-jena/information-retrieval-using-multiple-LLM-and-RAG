Based on the provided context, there is not enough information to directly answer the query about the strategy implemented to monitor the model performance during training. However, I can provide some insights that might help infer a possible approach.

The text describes data processing and filtering steps for a database used in ecological informatics. It includes downloading records from GBIF and OBIS, data curation, taxonomic filtering, and deletion of data outside the native range. The final dataset contains 820,004 records.

However, there is no mention of any model, training process, or performance monitoring strategy in the provided context.

In general, when training machine learning models, monitoring performance involves tracking metrics like loss, accuracy, or F1-score throughout the training process. This can help identify issues like overfitting or underfitting and allow for adjustments to the model or training procedure. Common strategies include using validation sets, cross-validation, or early stopping to assess model performance and prevent overfitting.

Without more information about the specific model and training process used in this study, it is impossible to provide a detailed answer about the performance monitoring strategy. It is possible that such information is provided in other sections of the paper or that a standard approach was used without explicit mention in the given context.