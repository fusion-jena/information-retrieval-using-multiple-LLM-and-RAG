Answer:::

The data was split into training, validation, and testing sets using a 60-20-20 regime. This means that 60% of the data was used for training, 20% for validation, and the remaining 20% for testing. This split is common in machine learning tasks as it allows for the model to be trained on a portion of the data, while also holding back some data to validate and test the model's performance.

The data was split randomly, which means that each image had an equal chance of being assigned to any of the three sets. This is important to ensure that the data is representative of the overall population and that the model is not biased towards any particular subset of the data.

Additionally, the data was unbalanced, with some classes accounting for a larger percentage of the images than others. For example, the "ghost" class accounted for 40.15% of the images, while the "other" class accounted for only 5.2%. Despite this imbalance, the data was not adjusted using techniques such as SMOTE, oversampling, or class weights. These techniques will be considered in a future phase of the research.

Overall, the data was split using a random 60-20-20 regime, without adjusting for class imbalance. This split allowed for the model to be trained, validated, and tested on representative samples of the data.