I'm sorry for any confusion, but the provided context does not mention any deep learning models. The models mentioned are Light Gradient Boosting Machine (LGBM) and Gradient Boosting (GB) models. Therefore, I cannot provide information on the hyperparameters used in a deep learning model based on this context.

However, I can give you some general information about hyperparameters commonly used in deep learning models. Deep learning models, such as neural networks, typically have several hyperparameters that can be tuned to optimize their performance. Here are some examples:

1. Learning rate: This is a common hyperparameter in many optimization algorithms used in deep learning. The learning rate determines how much the weights in the model are adjusted during training. A learning rate that is too high may cause the model to converge too quickly to a suboptimal solution, while a learning rate that is too low may cause the training process to be extremely slow.
2. Optimizer: This is the algorithm used to update the weights in the model during training. Some common optimizers include stochastic gradient descent (SGD), Adam, and RMSprop. The choice of optimizer can have a significant impact on the training time and the final performance of the model.
3. Number of layers and number of neurons per layer: These hyperparameters determine the architecture of the neural network. A deeper network with more neurons per layer can potentially learn more complex patterns in the data, but it also requires more data and computational resources to train.
4. Regularization: Regularization techniques, such as L1 and L2 regularization, can help prevent overfitting by adding a penalty term to the loss function. The strength of the regularization term is controlled by a hyperparameter.
5. Activation function: The activation function determines the output of each neuron in the network. Common activation functions include the rectified linear unit (ReLU), sigmoid, and tanh functions.

I hope this information is helpful, even if it does not directly answer your question based on the provided context.