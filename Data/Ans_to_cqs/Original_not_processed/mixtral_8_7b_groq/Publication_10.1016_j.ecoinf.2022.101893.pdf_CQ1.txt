The provided context does not give specific information about how raw data is collected in the deep learning pipeline for birdsound classification. However, it does mention that researchers have used birdsound data from the Xeno-Canto website and the LifeCLEF bird recognition challenge. These sources likely provide pre-collected and publicly available birdsound data for researchers to use.

Additionally, the context mentions that Xie et al. used Chirplet transform, STFT (Short-Time Fourier Transform), and Mel cepstrum transform to obtain the spectrogram of birdsound. These transforms can be applied to raw birdsound data to extract features or to create a spectrogram, which can then be used as input to a deep learning model.

Therefore, it can be inferred that raw birdsound data for deep learning pipeline can be collected through various methods such as recording using sensors or microphones, obtaining from pre-existing datasets like Xeno-Canto or LifeCLEF, or even recorded through surveys. Further, the data can be pre-processed using transforms like Chirplet transform, STFT, and Mel cepstrum transform to extract features or create a spectrogram.