Answer:::
The deep learning models used in the study were trained using a GPU-cluster equipped with 4 RTX8000.

Justification:
The context mentions that the training of the models was completed in 96 hours per model using a GPU-cluster. Additionally, it specifies that the GPU-cluster consisted of 4 RTX8000, which are high-end GPUs commonly used for training deep learning models. No other hardware resources such as TPUs (Tensor Processing Units) are mentioned in the context, indicating that the models were trained using GPUs.