Answer:::

The context does not explicitly specify the method used to optimize the hyperparameters of the models. However, it mentions that tuning of the hyperparameter on the training set was done for each of the 100 different splits to the training-and-test set. This suggests that some form of hyperparameter optimization was performed, but the specific method is not provided. Hyperparameter optimization is crucial for improving the performance of machine learning models, and there are various methods available for this purpose, such as grid search, random search, and Bayesian optimization. Grid search involves testing all possible combinations of hyperparameters within a specified range, while random search selects a subset of these combinations at random. Bayesian optimization, on the other hand, uses Bayesian inference to select the most promising hyperparameters to test. Without further information, it is not possible to provide a specific answer to the query.