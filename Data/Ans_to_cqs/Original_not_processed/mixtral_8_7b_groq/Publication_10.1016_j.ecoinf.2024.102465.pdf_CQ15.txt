The provided context does not explicitly mention the optimization techniques used in the deep learning pipeline. However, it does mention the use of the XGBoost algorithm in the context of improving audit opinion prediction accuracy. XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable. It can be used with various optimization techniques such as Stochastic Gradient Descent (SGD) and Adam.

In addition, the context mentions the use of the ERNIE model, a pre-trained model developed by PaddlePaddle. While the specific optimization techniques used in ERNIE are not detailed, it is likely that standard optimization techniques were used during its training.

Furthermore, the context describes the use of HRNet for semantic segmentation of social media image data. HRNet is a high-resolution network that maintains high-resolution representations through the whole process. It is not specified which optimization technique was used for HRNet.

In summary, while the specific optimization techniques used in the deep learning pipelines are not explicitly mentioned in the provided context, it is likely that standard optimization techniques such as SGD and Adam were used. The XGBoost algorithm, ERNIE model, and HRNet all have the capability to use various optimization techniques.