Answer:::

The deep learning model was trained using the NVIDIA GeForce RTX 2080Ti GPU, which has 11G memory.

Reference(s):
"All evaluations were performed on the NVIDIA GeForce RTX 2080Ti GPU with 11G memory, and the software was Windows 10, Python 3.7, CUDA 10.2." (Tresson, P., Carval, D., Tixier, P., Puech, W., 2021)