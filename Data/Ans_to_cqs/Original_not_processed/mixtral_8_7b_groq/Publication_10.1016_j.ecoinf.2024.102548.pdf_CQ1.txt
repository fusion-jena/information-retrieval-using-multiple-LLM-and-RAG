Unfortunately, the provided context does not include information about the methods utilized for collecting raw data in the deep learning pipeline. The context focuses primarily on the deep learning techniques, materials, and methods used after the data acquisition process.

However, based on general knowledge and common practices in deep learning projects, there are several ways to collect raw data:

1. Surveys: Researchers can design and distribute surveys to gather specific data from a targeted population. Survey responses can be used as text data for natural language processing tasks or as structured data for other machine learning applications.

2. Sensors: Data can be collected using various sensors, such as temperature sensors, pressure sensors, or motion sensors. Sensor data can be time-series data, images, or other types of unstructured data, which can be used in deep learning models for tasks like anomaly detection, image recognition, or sequence prediction.

3. Public datasets: Researchers and practitioners often use publicly available datasets to train and test their deep learning models. These datasets can be found in data repositories like UCI Machine Learning Repository, Kaggle, or Google Dataset Search. Public datasets cover a wide range of domains, such as computer vision, natural language processing, speech recognition, and bioinformatics.

4. Web scraping: Data can be collected by scraping websites for specific information. Web scraping can be used to gather text data, images, or other types of data for deep learning tasks.

5. Collaborations and partnerships: Researchers can collaborate with other institutions, organizations, or companies to collect data for their deep learning projects. Collaborations can provide access to unique datasets that might not be publicly available or easily obtainable.

In summary, while the provided context does not offer specifics on the data collection methods, deep learning projects typically use surveys, sensors, public datasets, web scraping, and collaborations to gather raw data for further processing and modeling.