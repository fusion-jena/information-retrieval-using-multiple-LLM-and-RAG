The provided context discusses two main topics: training protocols and model bias, with data augmentation being a key part of the training protocols. However, it does not directly mention the preprocessing steps typically involved before training a deep learning model, such as normalization, scaling, or cleaning.

In general, preprocessing steps for deep learning models can include:

1. Normalization: This process involves adjusting the range of pixel intensity values in images or the range of numerical values in other datasets to a common scale, often between 0 and 1. This can help improve model performance by reducing the effect of outliers and making it easier for the model to learn relevant features.

2. Scaling: Similar to normalization, scaling adjusts the range of values, but it can be used to change the scale of the data to a specific range that is more suitable for the model. For example, if a model expects input values between -1 and 1, scaling can be used to transform the data to fit this range.

3. Data cleaning: This step involves removing or correcting erroneous, missing, or irrelevant data points from the dataset. This can help improve model performance by reducing noise and ensuring that the model focuses on relevant features.

Based on the context provided, it can be inferred that data augmentation is an essential preprocessing step in the training protocol for the specific deep learning models mentioned. Data augmentation techniques like random cropping, mosaicing, color distortions, scaling, rotation, and flipping are used to artificially increase the size of the dataset and help the model generalize better, making it more reliable on a wider range of input data.

However, the context does not explicitly mention other common preprocessing steps like normalization, scaling, or data cleaning. It is possible that these steps were performed but not mentioned in the provided text, or they might not have been necessary for this specific application. Nonetheless, it is important to consider these preprocessing steps when working with deep learning models to ensure optimal performance.