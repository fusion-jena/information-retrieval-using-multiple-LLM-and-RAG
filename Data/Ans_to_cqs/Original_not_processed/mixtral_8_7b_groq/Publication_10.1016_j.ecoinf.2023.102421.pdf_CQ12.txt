The provided context does not mention the use of any deep learning models such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), or Transformers in the described pipeline. Instead, the focus is on using machine learning models, specifically XGBoost and LightGBM, for estimating Aboveground Biomass (AGB) in a study area.

To optimize the hyperparameters of XGBoost and LightGBM, the study uses two types of optimization algorithms: Bayesian optimizers and Tree-structured Parzen Estimator (TPE) with a median pruning strategy (TDO). These optimizers aim to minimize the Root Mean Square Error (RMSE) during the training process.

XGBoost is a gradient boosting algorithm that is widely used for structured or tabular data due to its predictive efficiency, ability to handle large datasets, and reduced training time. LightGBM, on the other hand, is a gradient boosting framework that uses tree-based learning algorithms. It differs from other tree-based methods by implementing leaf-wise splits that create more complex trees, which are more efficient in reducing loss and result in higher accuracy.

In summary, the provided context discusses the use of machine learning models XGBoost and LightGBM, along with their hyperparameter optimization using Bayesian optimizers and TDO, for estimating AGB. However, it does not mention the use of any deep learning models such as CNNs, RNNs, or Transformers.

Answer:::
The provided context does not mention the use of any deep learning models like CNNs, RNNs, or Transformers. Instead, it focuses on using machine learning models XGBoost and LightGBM for estimating Aboveground Biomass (AGB) with hyperparameter optimization using Bayesian optimizers and TDO.