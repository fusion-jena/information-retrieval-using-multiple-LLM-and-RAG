Answer:::

The hyperparameters used in the deep learning models are as follows:

1. The deep learning architectures employed are Convolutional Neural Networks (CNNs) consisting of three types of layers: convolutional, pooling, and fully connected layers. Convolution and fully connected layers are usually followed by an element-wise, non-linear activation function.

2. All architectures were trained with stochastic gradient descent using a similar protocol.

3. The learning rate was initially set to 10−2 and was divided by 10 every 20 epochs until it reached 10−6.

4. A momentum of 0.9 was used.

5. The internal parameters of the employed CNN architectures were not changed regarding the originally proposed ones.

6. Neural networks do not perform well when trained with unbalanced data sets. In the case of "central-pixel labeling" architectures, it is possible to make balanced data sets with the initial pixels selection used for the learning. However, in the case of "semantic labeling," the composition of the images makes it more difficult to precisely control the number of pixels per class. The median frequency balancing method was used for all reported experiments.

It is important to note that the provided context does not mention any specific optimizer used in the deep learning models. Therefore, it cannot be confirmed which optimizer was used in the models.