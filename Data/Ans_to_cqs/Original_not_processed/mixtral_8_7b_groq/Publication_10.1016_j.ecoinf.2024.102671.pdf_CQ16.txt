Answer:::
The provided pieces of context do not contain specific information about the criteria used to determine when training is complete in the context of machine learning or ecological modeling. The texts mainly discuss ecological risk assessment, conservation planning, and carbon sequestration in ecosystems.

However, one of the texts mentions cross-validation as an essential approach for assessing the generalizability and robustness of ecological zoning models (Roberts et al., 2017). Cross-validation is a technique used to assess the performance of a machine learning model by dividing the data into training and validation sets and iteratively training and testing the model. In this context, one possible criterion for determining when training is complete could be when the model's performance on the validation set stops improving or plateaus, indicating that the model has learned the underlying patterns in the training data and is not overfitting.

Another possible criterion for determining when training is complete is based on the loss function, which measures the difference between the model's predictions and the actual values. During training, the model adjusts its parameters to minimize the loss function. One common approach is to stop training when the validation loss plateaus or starts increasing, indicating that further training is unlikely to improve the model's performance.

In summary, while the provided pieces of context do not contain specific information about the criteria used to determine when training is complete, it is common to use cross-validation and loss function plateaus or increases as criteria in machine learning and ecological modeling.