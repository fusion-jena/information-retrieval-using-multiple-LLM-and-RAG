Based on the provided context, there is no direct information about the criteria used to determine when training is complete in a machine learning model. However, one common method used in training models is to monitor the validation loss and stop training when the loss plateaus or starts to increase, indicating that the model is overfitting to the training data.

In the context of time series analysis, Dynamic Time Warping (DTW) is a technique used for aligning two time series by finding the least cost path through a cost matrix. The warping path, which is the lowest valley of the "landscape," represents the optimal alignment between the two time series. This technique can be used for training models by comparing the predicted time series with the actual time series and calculating the accumulative distance between them. The validation loss can then be calculated based on this accumulative distance.

In the context of R packages, the Kendall package provides a trend test that can be used for time series analysis. The documentation suggests using a block bootstrap when there is autocorrelation. This technique can be used for training models by accounting for the autocorrelation in the time series data, which can improve the accuracy of the validation loss calculation.

In summary, while the provided context does not directly answer the query, it suggests that monitoring the validation loss and stopping training when it plateaus or increases is a common method for determining when training is complete. In the context of time series analysis, DTW can be used for comparing the predicted and actual time series, and the Kendall package can be used for accounting for autocorrelation in the time series data.