Based on the provided context, there is no explicit information about the specific criteria used to determine when training is complete for the kNN and RF classification models. However, it can be inferred that cross-validation and validation datasets were used to assess the performance of the models during and after training.

For the kNN classification, the training process involved loading the training datasets using the "sp" vector package in R and allocating 80% of the data as test files and the remaining 20% as validation files. The test datasets were used to check optimal model parameters and initial model performance based on repeated cross-validation. Once the optimal parameters were determined, the final model accuracy was checked using the validation dataset. However, the context does not provide information on whether the training stopped based on a validation loss plateau or any other specific criterion.

Similarly, for the RF classification, the context does not provide explicit information on the training completion criterion. The accuracy assessment for the RF classification shows the overall accuracy and Kappa statistics for the models, but it does not mention how the training process determined when to stop.

In general, training of machine learning models can be stopped based on various criteria, such as:

1. Validation loss plateau: The training can be stopped when the validation loss stops decreasing or starts increasing, indicating that the model has learned the underlying patterns in the training data and further training may lead to overfitting.
2. Early stopping: This technique involves stopping the training if the performance on a validation set does not improve for a certain number of epochs or iterations.
3. Monitoring other metrics: Training can be stopped based on other metrics, such as precision, recall, or F1-score, depending on the specific problem and requirements.

In conclusion, while the provided context does not explicitly mention the criterion used to determine when training is complete for the kNN and RF classification models, it can be inferred that cross-validation and validation datasets were used to assess model performance during and after training. However, the specific criterion for training completion, such as validation loss plateau or early stopping, is not mentioned.