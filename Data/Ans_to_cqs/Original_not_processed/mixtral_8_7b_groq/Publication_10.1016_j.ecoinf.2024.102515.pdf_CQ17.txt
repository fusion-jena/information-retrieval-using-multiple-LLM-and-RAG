The provided context does not include information about the specific regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention the use of the twarc2 library to handle the data in JSON format returned by the Twitter API, and the use of the Google Cloud Vision API SafeSearch tool for filtering tweets.

Regularization methods are techniques used to prevent overfitting in machine learning models, including deep learning models. Overfitting occurs when a model learns the training data too well, to the point where it performs poorly on new, unseen data. Regularization methods help to prevent this by adding a penalty to the loss function, which discourages the model from learning overly complex patterns in the training data that may not generalize well to new data.

Two common regularization methods used in deep learning are dropout and L2 regularization. Dropout is a technique where randomly selected neurons are "dropped out" during training, which helps to prevent overfitting by making the model less reliant on any individual neuron. L2 regularization, also known as weight decay, adds a penalty to the loss function that is proportional to the square of the magnitude of the weights. This helps to prevent overfitting by discouraging the model from assigning too much importance to any individual weight.

In summary, the provided context does not include information about the specific regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention the use of the twarc2 library and the Google Cloud Vision API SafeSearch tool in the data processing pipeline. Regularization methods are techniques used to prevent overfitting in machine learning models, including deep learning models, and two common regularization methods used in deep learning are dropout and L2 regularization.