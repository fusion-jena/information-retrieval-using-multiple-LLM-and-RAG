Based on the provided context, there is no explicit information about the process followed to deploy a trained deep learning model. The context focuses on data publication processes, data usage rights, and data integration, but it does not include details about the deployment of machine learning models.

However, I can provide some general steps that are typically involved in deploying a trained deep learning model:

1. Model serialization: This step involves saving the trained model to a file so that it can be loaded and used later without having to retrain the model. Common formats for model serialization include HDF5, JSON, and Protocol Buffers.
2. Platform selection: The choice of platform for deploying the model depends on various factors such as the expected volume of requests, the required latency, and the available resources. Common deployment platforms for deep learning models include local servers, cloud services (e.g., AWS, Google Cloud), and edge devices (e.g., smartphones, IoT devices).
3. Model loading and optimization: Once the model is deployed on the selected platform, it needs to be loaded and optimized for serving requests. This step may involve preprocessing the input data, configuring the model for efficient inference, and setting up monitoring and logging systems.
4. Integration with the application: The deployed model needs to be integrated with the application that will use it for making predictions. This step may involve setting up APIs, designing user interfaces, and testing the overall system.

It's important to note that the specific steps and considerations for deploying a deep learning model can vary depending on the application and the deployment platform. Therefore, it's essential to have a good understanding of the deployment requirements and constraints before starting the deployment process.