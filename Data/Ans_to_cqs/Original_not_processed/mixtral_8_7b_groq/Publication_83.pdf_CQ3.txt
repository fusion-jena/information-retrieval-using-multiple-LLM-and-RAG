Based on the provided context, there is no explicit information about the data annotation techniques used in the deep learning pipeline for classifying bird sounds or acoustic scenes. However, it can be inferred that some form of audio annotation was done to label the bird species or acoustic scenes in the dataset used for training the deep learning models.

In the context of audio signal processing, data annotation techniques may differ from those used in computer vision tasks such as bounding box annotation or instance segmentation. Instead, audio annotation may involve tasks such as segmenting audio recordings into relevant time intervals and labeling those intervals with the appropriate class.

For instance, in the context of bird sound classification, the annotated data may consist of audio recordings of various bird species, with each recording segmented into intervals and labeled with the corresponding bird species. Similarly, for acoustic scene classification, the annotated data may consist of audio recordings of various acoustic scenes, such as a park, a beach, or a city street, with each recording segmented into intervals and labeled with the corresponding scene.

In summary, while the provided context does not explicitly mention the data annotation techniques used in the deep learning pipeline for classifying bird sounds or acoustic scenes, it can be inferred that some form of audio annotation was performed to label the audio data with the appropriate class.