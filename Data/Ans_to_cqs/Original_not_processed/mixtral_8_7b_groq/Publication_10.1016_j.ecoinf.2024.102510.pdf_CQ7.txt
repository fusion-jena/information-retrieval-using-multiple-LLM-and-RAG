Answer:::

In the context provided, the data is split for deep learning model training using three data split strategies: 60:40, 80:20, and 90:10. These strategies determine the proportion of data allocated to the training set and the validation set (also known as the test set).

For instance, in the 60:40 split strategy, 60% of the data is used for training the model, and the remaining 40% is used for validation. This approach allows the model to learn from a larger dataset while also providing a sufficient sample for evaluating its performance.

The authors use the Caltech-UCSD Birds-200-2011 (CUB 200â€“2011) dataset to evaluate the models. This benchmark dataset ensures a fair comparison between the models.

In addition to the data split strategies, the authors also employ hyperparameter optimization techniques to further enhance the models' performance. Specifically, they use a method that tests various combinations of hyperparameters identified in manual search and trains the selected models to achieve the maximum possible accuracy through multiple iterations.

The authors evaluate the performance of several deep learning models, including MobileNetV2, EfficientNetB0, GoogleNet, DenseNet201, InceptionV3, ResNet18, InceptionResNetV2, and NASNetMobile. They report the validation accuracy, precision, recall, and F1-score for each model.

In summary, the criteria used to split the data for deep learning model training include the 60:40, 80:20, and 90:10 data split strategies. These strategies determine the proportion of data allocated to the training and validation sets. Additionally, the authors employ hyperparameter optimization techniques to further enhance the models' performance.