Answer: The strategy implemented to monitor the model performance during training involves evaluating the total loss after each epoch and comparing it between the training and validation datasets. The best model with transfer learning was chosen based on the minimum total loss after nine epochs. Overfitting was observed after this point, as indicated by an increase in the validation loss, despite the bias still being low. This increase is shown by a higher difference between the training and validation loss, with bias being the loss evaluated on the training dataset.

Furthermore, the impact of changing the value of α was found to be minimal, with the largest variation being 0.6%, which is similar to the variation of 0.8% observed in previous experiments.

The performance of the models was also evaluated by calculating the average precision, recall, and F1-score for trained ResNet50 and EfficientNetB3 models modified for multitask learning (MTL) with transfer learning using pre-trained weights from ImageNet. These models were trained and validated on the TLm dataset. The ResNet50 and EfficientNetB3 models were also trained without MTL for comparison.

At the species level (3), ResNet50 had a higher standard deviation (0.32%) compared to EfficientNetB3. However, state-of-the-art models trained with transfer learning and without MTL had an F1-score of 96%, similar to models trained with MTL at the species level. The models trained with ResNet and EfficientNet outperformed the benchmark YOLOv5 model on the TL dataset.

In summary, the strategy to monitor model performance during training involves evaluating the total loss after each epoch, comparing it between the training and validation datasets, and observing overfitting. The impact of changing the value of α was found to be minimal, and the performance of the models was evaluated by calculating the average precision, recall, and F1-score for trained ResNet50 and EfficientNetB3 models modified for MTL with transfer learning using pre-trained weights from ImageNet.