Answer:::

The strategy implemented to monitor the model performance during training involves the use of evaluation metrics calculated for each species and two subsets of sites: a training set and a test set. The training set, consisting of 4781 sites, is used for fitting all models, while the test set, consisting of 400 sites, aims at testing models' generalization capacities. The performance metrics are then averaged over the 50 species.

One of the key performance metrics used is the Mean Loss, which is relevant regarding the ecological model and is the objective function minimized during model training. The Mean Loss of model m on species i and on sites 1, ..., K is calculated as the average of the log loss function over all sites.

The models' performance is evaluated for different architectures, including MAXENT, a classic loglinear model, a single hidden layer neural network (SNN), a six hidden layers neural network (DNN), and a convolutional neural network (CNN). These models take a vector of environmental variables xk as input, and the learning of model parameters is done through optimization of an objective function using stochastic gradient descent algorithms.

The training set is used to monitor the model's performance during training, while the test set is used to evaluate the model's generalization capacities. By comparing the performance metrics of the models on the training and test sets, it is possible to monitor the model's performance and detect any signs of overfitting or underfitting.

In summary, the strategy implemented to monitor the model performance during training involves the use of evaluation metrics calculated for each species and two subsets of sites, the training and test sets. The Mean Loss is used as a key performance metric, and the models' performance is evaluated for different architectures. The training set is used to monitor the model's performance during training, while the test set is used to evaluate the model's generalization capacities.