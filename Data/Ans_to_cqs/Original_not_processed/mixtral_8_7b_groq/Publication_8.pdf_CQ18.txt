Based on the provided context, there is no explicit information about the strategy implemented to monitor the model performance during training. The text mainly focuses on the model's performance evaluation after training, which involves manually annotating around 200 scans from a different un-annotated dataset based on the predicted bounding boxes.

However, it can be inferred that the model's performance was visually inspected after training on all the annotated scans. This visual inspection could be one way of monitoring the model's performance during training. Additionally, the use of average precision metrics like AP50 and AP75, along with the average precision for each type of organ, indicates that the model's performance was quantitatively evaluated after training.

In summary, while the context does not provide explicit details about the strategy used to monitor the model performance during training, it can be inferred that visual inspections and quantitative evaluations were conducted after training.