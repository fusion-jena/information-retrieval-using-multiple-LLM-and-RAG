Based on the provided context, the following measures were taken to ensure the generalizability of the deep learning model:

1. Diverse dataset: The model was trained on a large and diverse dataset, AT0, which contains 3458 natural thumbnails in average per species. This large and diverse dataset likely helped the model to learn a wide range of features and patterns, improving its ability to generalize to new data.
2. Cross-validation: Although not explicitly mentioned, cross-validation is a common technique used to ensure the generalizability of deep learning models. Based on the context, it seems likely that cross-validation was used to evaluate the performance of the model, as the results are reported as a mean accuracy and standard deviation.
3. Stratified splitting: The test dataset, T2, was likely obtained by stratified splitting, as the model's performance is reported for each species. Stratified splitting ensures that the test dataset contains a representative sample of each class, which helps to ensure that the model's performance is accurately evaluated.
4. Limited datasets: The model was also trained on limited datasets obtained by subsampling T0 to 250 and 500 images per class. Training the model on these limited datasets likely helped to improve its ability to generalize to new data, as it was forced to learn more with less data.
5. Baseline model: A classic DL algorithms architecture was trained with the biggest dataset AT0 as a baseline for the DL accuracy. Comparing the performance of the deep learning model to a baseline model helps to ensure that the deep learning model's performance is not due to chance or overfitting.

Overall, these measures suggest that the researchers took several steps to ensure the generalizability of the deep learning model. However, it would be helpful to have more information about the specific techniques used, such as the number of folds used in cross-validation and the details of the stratified splitting.