The provided context discusses the use of machine learning techniques, specifically the Random Forest algorithm, in the context of species distribution modeling. However, it does not directly address the criteria used to split data for deep learning model training.

In general, the process of splitting data into training, testing, and validation sets is an important step in the development of any machine learning or deep learning model. The purpose of this split is to ensure that the model can generalize well to new, unseen data, and to prevent overfitting to the training data.

There are several common strategies for splitting data in machine learning and deep learning:

1. Random sampling: This involves randomly splitting the data into training, testing, and validation sets. This is a simple and commonly used method, but it may not be suitable for all types of data, especially if there are underlying patterns or structures that could be lost in the random split.
2. K-fold cross-validation: In this method, the data is split into k equally sized folds. The model is then trained on k-1 folds, while the remaining fold is used for testing. This process is repeated k times, with a different fold used for testing each time. The advantage of this method is that it provides a more robust estimate of the model's performance, as each data point is used for testing at least once.
3. Time series split: If the data is collected over time, it may be more appropriate to split the data into training, testing, and validation sets based on time. For example, the training set could consist of data from the earlier time periods, while the testing and validation sets consist of data from later time periods. This ensures that the model is trained on data that is representative of the past, and tested on data that is representative of the future.
4. Holdout method: In this method, a portion of the data is set aside as a validation set, while the remaining data is split into training and testing sets. The validation set is used to tune hyperparameters and select the best model, while the training and testing sets are used to evaluate the model's performance.

The choice of splitting strategy depends on the specific characteristics of the data and the goals of the modeling exercise. It is important to carefully consider the splitting strategy and ensure that it is appropriate for the data and the research question.