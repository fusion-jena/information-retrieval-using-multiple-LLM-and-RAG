The provided context discusses the use of TensorFlow, a deep learning platform, for automated identification of Chagas disease vectors. However, it does not explicitly mention the methods used for collecting raw data in the deep learning pipeline. Therefore, I cannot provide a definitive answer based on the given context.

However, I can provide some general information about common methods for collecting raw data in deep learning pipelines. These methods can include:

1. Surveys: Researchers can conduct surveys to collect data, such as images or other relevant information. For example, in the context of Chagas disease, researchers might conduct surveys to collect images of potential vectors in their natural habitats.

2. Sensors: Sensors can be used to collect data automatically. For instance, sensors might be used to capture images of insects in a specific area or to collect other relevant data.

3. Public datasets: Publicly available datasets can be used as raw data for deep learning pipelines. These datasets might be created by researchers or organizations and made available for others to use. For example, in the context of automated species identification, there might be publicly available datasets of images of various species.

In the context of the provided text, it is likely that some combination of these methods was used to collect the raw data used in the deep learning pipeline. However, without more information, it is impossible to say for sure.