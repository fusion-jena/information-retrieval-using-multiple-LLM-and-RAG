Answer:

The provided context does not explicitly mention the criteria used to split the data for deep learning model training into subsets such as train, test, and validation. However, it does mention that the models were trained and validated on butterfly specimen data sets, and that they performed well in their own validation set.

From general practices in deep learning model training, data is typically split into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model performance.

In the context of the provided information, it can be inferred that the data was split in a way that allowed for training and validation of the MG and MO models on butterfly specimen data sets. The experiments were performed on a small-size dataset without data augmentation, and the number of units in the third fully connected layer (fc3) was changed according to the number of classes of training data. This suggests that the data was likely split based on the number of classes or categories of butterfly specimens.

Furthermore, the context mentions that the models perform well in their own validation set, which implies that there was a separate validation set used for model selection and hyperparameter tuning. However, the specific criteria used for splitting the data is not provided in the context.

Therefore, while the provided context does not explicitly state the criteria used for splitting the data, it can be inferred that the data was likely split based on the number of classes or categories of butterfly specimens, and that there was a separate validation set used for model selection and hyperparameter tuning.