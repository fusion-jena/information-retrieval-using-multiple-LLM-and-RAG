Answer:::

The hyperparameters used in the deep learning model include those related to the different types of layers, such as convolutional or recurrent layers. These hyperparameters define the properties of the network and remain static during the training process. Examples of these hyperparameters include the number of layers, the size of the layers, and the type of activation function used.

In addition to these, there are also hyperparameters related to the training process itself. These include the learning rate, which determines the step size during gradient descent, and the choice of optimizer, which determines how the parameters of the model are updated during training. Other examples of training-related hyperparameters include the batch size, the number of epochs, and the regularization parameters.

The hyperparameters of the model are optimized using the HyperBand algorithm, which is a combination of initial random search and a "successive halving" strategy. This algorithm allows for an efficient search of the hyperparameter space, particularly when computational resources are limited. The HyperBand algorithm explores several configurations in parallel, allocating more training resources to promising configurations while eliminating those that show inferior performance.

During the training of the model, the data is standardized, and one of the datasets is defined as a training base, on which the standardization parameters are calculated and applied to the other two datasets considered as test bases.

It's important to note that the specific hyperparameters used in the model are not specified in the context provided. The number of convolution layers in the network is lower than that given in the article, the network has two convolution layers, but their size and the associated max-pooling will be determined in the following interval for each.

In summary, the hyperparameters used in the deep learning model include those related to the types of layers and the training process. The HyperBand algorithm is used to optimize these hyperparameters, and the data is standardized during the training of the model. However, the specific hyperparameters used in the model are not provided in the context.