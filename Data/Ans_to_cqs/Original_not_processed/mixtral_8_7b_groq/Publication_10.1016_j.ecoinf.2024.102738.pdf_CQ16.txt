Answer:::

The provided context does not give specific information about the criteria used to determine when training is complete in the study. However, it does mention that the training and testing samples were defined using Chuvieco (2020) as a reference, who argues that at least 196 test points should be considered for categorical variables. 

In the context of machine learning, training is typically considered complete when the model's performance on a validation set stops improving or when the validation loss plateaus. This is often determined using early stopping, a technique where training is halted when the validation loss does not improve for a certain number of epochs. 

In the study, the authors used the Landscape Fragmentation Tool (LFT) in ArcGIS 10.5 software to generate fragmentation maps. They also used Google Earth Engine (GEE) for sampling and validation. However, the specific criteria used to determine when training is complete are not provided. 

Therefore, while it can be inferred that some form of validation-based early stopping was likely used, the specific criteria cannot be determined from the provided context.