Answer:

Based on the provided context, there is no explicit information given about the strategy implemented to monitor the model performance during training. However, we can infer some possible strategies that might have been used based on the given information.

Firstly, the authors mention that they designed a backbone to improve the training speed of the model while ensuring detection accuracy and reducing the number of parameters. This implies that they might have used validation data to monitor the model's performance during training. By setting aside a portion of the training data as validation data, they could have evaluated the model's performance on this validation set after each epoch or a certain number of epochs. This would have allowed them to ensure that the model's accuracy was not significantly decreasing even as they increased the training speed and reduced the number of parameters.

Secondly, the authors mention that they conducted experiments on an RTX 3090 with a specific training environment and epoch. They also mention the video memory usage and training time for both the original YOLOv5 algorithm and their own algorithm. This suggests that they might have monitored the computational complexity of their algorithm during training to ensure that it was reducing the consumption of computing resources as intended. By monitoring the video memory usage and training time, they could have identified any issues with the computational complexity of their algorithm and made adjustments as necessary.

Lastly, the authors mention that their algorithm is more suitable for deployment in agricultural embedded devices due to its smaller model size and faster inference time. This implies that they might have monitored the model size and inference time during training to ensure that they were meeting their desired specifications for deployment on embedded devices.

In summary, while there is no explicit information given about the strategy implemented to monitor the model performance during training, we can infer that the authors might have used validation data, monitored the computational complexity, and monitored the model size and inference time to ensure that their algorithm was meeting its intended specifications for detection accuracy, training speed, and deployment on agricultural embedded devices.