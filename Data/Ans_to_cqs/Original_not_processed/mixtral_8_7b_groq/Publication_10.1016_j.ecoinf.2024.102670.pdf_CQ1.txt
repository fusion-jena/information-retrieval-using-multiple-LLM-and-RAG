Answer:::

The text provided does not offer a direct answer to the query, as it focuses more on the use of deep learning methods for image analysis and the sources of ground truth data rather than the raw data collection methods in the deep learning pipeline. However, based on general knowledge of deep learning pipelines, there are a few common methods for collecting raw data.

Deep learning pipelines typically involve collecting large datasets to train models. These datasets can come from various sources, such as:

1. Surveys: In some cases, researchers may collect raw data through surveys, especially when dealing with text data or structured data. Surveys can be conducted online or offline and can involve a wide range of participants.

2. Sensors: For image, audio, or other sensor-based data, researchers often use sensors to collect raw data. These sensors can include cameras, microphones, or other specialized equipment designed to capture specific types of data.

3. Public datasets: There are many public datasets available for researchers to use, which can be a valuable resource for deep learning projects. These datasets cover a wide range of domains, from images and text to audio and sensor data.

4. Private datasets: Researchers may also collect their own raw data through experiments or other data collection methods. These datasets may be specific to a particular project or domain and may not be publicly available.

In the context of the text provided, the focus is on the use of crowd-sourcing for obtaining manual annotation of karyotyping images of chromosomes. This method involves non-expert users in the data annotation process, helping to create a ground truth dataset for training and evaluating deep learning models. However, the original source of the raw karyotyping images is not specified in the text.

In summary, while the provided text does not directly answer the query, common methods for collecting raw data in deep learning pipelines include surveys, sensors, public datasets, and private datasets.