Answer:::

The provided context discusses various aspects of predictive modeling and map evaluation, but it does not directly mention criteria for determining when training is complete. However, in the context of machine learning, a common approach for determining when training is complete is to monitor the performance on a validation set during the training process. When the performance on the validation set stops improving or starts to degrade, even if the training loss is still decreasing, the training process is typically stopped. This is because the model may be starting to overfit to the training data, and the validation set serves as a proxy for the unseen test data.

In the context of the paper, the focus is on the testing phase of the modeling process, specifically assessing the accuracy of a thematic map produced by a calibrated statistical prediction method. The authors propose alternative methods for evaluating the accuracy of the map when data availability is limited and a separate test set cannot be afforded.

In summary, while the provided context does not directly answer the query, in general, monitoring the performance on a validation set during the training process is a common approach for determining when training is complete in machine learning.