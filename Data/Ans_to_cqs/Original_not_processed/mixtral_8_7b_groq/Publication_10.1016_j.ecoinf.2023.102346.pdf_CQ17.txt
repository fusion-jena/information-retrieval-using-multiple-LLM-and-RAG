The provided pieces of context do not specifically mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, they do discuss various machine learning algorithms and techniques used for predictive modeling and habitat suitability prediction.

Machine learning algorithms, such as Generalized Linear Model (GLM), Support Vector Machine (SVM), Multivariate Adaptive Regression Spline (MARS), Random Forest (RF), Flexible Discriminant Analysis (FDA), Classification and Regression Trees (CART), Generalized Boosting regression Model (GBM), and Maximum-Entropy learning (MAXENT), are used for predictive modeling. Among these, MAXENT is used for habitat suitability prediction.

Regularization methods, such as dropout and L2 regularization, are commonly used in deep learning pipelines to prevent overfitting. Dropout is a regularization technique used in neural networks where randomly selected neurons are ignored during training, which helps to prevent over-dependence on any single neuron and thus reduces overfitting. L2 regularization, also known as weight decay, adds a penalty term to the loss function, which discourages large weights and helps to prevent overfitting.

Therefore, while the provided context does not specifically mention the use of dropout or L2 regularization in the deep learning pipeline, these are common regularization methods used to prevent overfitting in deep learning pipelines.