The provided context does not give specific information about data splitting criteria for deep learning model training. However, it does discuss the validation methods used in a specific study related to spatial predictions of soil properties.

In the study, the leave-one-out cross-validation method was used to check the accuracy of the spatial predictions. This method involves training the model on all data except one point and making a prediction for that point. The root mean square error (RMSE) was then used to evaluate the model.

While this method is a type of cross-validation, it is different from the more common practice of splitting data into training, validation, and test sets in deep learning. In this approach, a portion of the data is set aside as a test set, and the remaining data is split into training and validation sets. The model is trained on the training set and validated on the validation set to tune hyperparameters and prevent overfitting. Once the model is finalized, it is evaluated on the test set to estimate its generalization performance.

Therefore, while the context provides insight into validation methods used in spatial prediction studies, it does not specifically answer the query regarding data splitting criteria for deep learning model training. Common data splitting criteria include random sampling, stratified sampling, and time-series splitting, among others, depending on the specific use case and data availability.