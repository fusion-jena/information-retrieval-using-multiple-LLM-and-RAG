Answer:::

To monitor the model performance during training, the researchers employed a strategy involving the use of different datasets at various stages of the training process. First, they pre-trained the model using auxiliary XC data, which is a large dataset consisting of over 740,000 recordings and over 10,500 species. This pre-training step helped improve the final models, leading to better evaluation metrics.

Next, they fine-tuned the pre-trained models using Region of Interest (ROI) data from their study site. The ROI data were divided into training, validation, and test sets. The training set consisted of the remaining ROIs with species presence after setting aside a held-out test set of 50 ROIs per species for accuracy assessment. The validation set was formed by randomly sampling 100 ROIs per species from the training set, while the remaining ROIs formed the training set. On average, the training set had 887 ROIs per species, with a minimum of 349 and a maximum of 3094.

To ensure that the model's performance was not affected by temporal autocorrelation or overlapping ROIs, the researchers placed any overlapping ROIs in the training set. They also expanded ROIs that were less than 2 seconds in duration to 2 seconds by equally padding the start and stop times.

The use of these different datasets at various stages of the training process allowed the researchers to monitor the model's performance and make necessary adjustments. By pre-training the model using a large and diverse dataset, they were able to improve the model's performance, which was further fine-tuned using ROI data from their study site. The use of a validation set and a held-out test set also allowed them to evaluate the model's performance and ensure that it was not affected by issues such as temporal autocorrelation or overlapping ROIs.