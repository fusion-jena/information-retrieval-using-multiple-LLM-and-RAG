Based on the provided context, there is no specific information about the criteria used to determine when training is complete in the study by Wisz et al., 2008. The study focuses on comparing the performance of different species distribution modeling (SDM) methods and a new sampling bias effect correction method. It does not provide details about the training process or the criteria used for training completion.

In general, the training of SDM methods can be stopped using various criteria, such as:

1. Validation loss plateau: The training process can be stopped when the loss function on a validation set does not decrease significantly for a certain number of iterations. This indicates that the model has learned the underlying patterns in the data and further training is unlikely to improve its performance.

2. Early stopping: This technique involves monitoring the performance of the model on a validation set during the training process. If the performance starts to degrade, the training is stopped to prevent overfitting.

3. Monitoring other metrics: In some cases, the training can be stopped based on other metrics, such as the area under the ROC curve (AUC), precision, recall, or F1 score. The training is stopped when these metrics reach a satisfactory level or do not improve significantly for a certain number of iterations.

4. Fixed number of iterations: In some cases, the training can be stopped after a fixed number of iterations, regardless of the performance on the validation set. This can be useful when computational resources are limited or when there is a risk of overfitting.

Without more specific information from the study, it is not possible to provide a definitive answer to the query. However, the criteria mentioned above are commonly used to determine when training is complete in SDM methods and machine learning algorithms in general.