Answer:::

The hyperparameters used in the deep learning models include the Stochastic Gradient Descent (SGD) optimizer with an initial learning rate of 0.01 for all models except MansNet, which was initially set at 0.1. The learning rate was reduced by a factor of 10 after steps of 30 epochs. Batch normalization was also used, and the models were trained for 150 epochs using Nvidia Tesla K80 or P100 GPUs.

Answer:::