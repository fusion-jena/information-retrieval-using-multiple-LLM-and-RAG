The provided context does not include specific information on the criteria used to split data for deep learning model training (e.g., train, test, validation). However, it does mention the use of machine learning methods, such as artificial neural networks, random forest, and maximum entropy modeling (Maxent), for managing ecological data.

In general, for deep learning model training, data splitting is a crucial step to evaluate the model's performance and prevent overfitting. The most common criteria for splitting the data are:

1. Random splitting: This method randomly splits the data into training, validation, and testing sets. It is a simple and widely used method, but it may not guarantee a balanced representation of the data.

2. Stratified splitting: This method ensures a balanced representation of the data by preserving the distribution of classes in the training, validation, and testing sets. It is particularly useful when dealing with imbalanced datasets.

3. Time-series splitting: This method is used for time-series data, where the data is split based on time. The training set consists of data from the past, while the validation and testing sets consist of more recent data.

4. K-fold cross-validation: This method involves dividing the data into 'k' subsets or folds. The model is trained on 'k-1' folds, while the remaining fold is used for validation. This process is repeated 'k' times, with each fold serving as the validation set once. The average performance of the 'k' runs is then calculated.

The choice of splitting criteria depends on the nature of the data and the specific problem at hand. In the context of ecological informatics, the choice of splitting criteria may depend on the distribution of the data, the availability of historical data, and the specific research question being addressed.

In summary, while the provided context does not mention specific criteria for splitting data for deep learning model training, it is a crucial step in the machine learning process. The choice of splitting criteria depends on the nature of the data and the specific problem at hand. Common criteria include random splitting, stratified splitting, time-series splitting, and k-fold cross-validation.