Based on the provided context, there are several postprocessing steps that were carried out after the model training. However, the text does not explicitly mention saliency maps. Here are the postprocessing steps that are mentioned:

1. **Metrics calculation:** After training the models using Random Forest, Artificial Neural Network, and Support Vector Machine, the performance of these models was evaluated using three error statistics: R-squared (R2), Mean Absolute Error (MAE), and Root Mean Square Error (RMSE). These metrics were calculated to compare the accuracies of the models.

2. **Confusion matrix:** Although not explicitly mentioned, a confusion matrix can be inferred as one of the postprocessing steps. This is because the text mentions that a stratified sampling method was used for model evaluation, where 70% of the samples were allocated to the training dataset and the remaining 30% to the validation dataset. This method is typically used to create a confusion matrix, which is a table that is often used to describe the performance of a classification model.

3. **Extrapolation of the models:** After evaluating the models, they were then extrapolated for the entire region. This step involves applying the models to make predictions for the entire study area, beyond the samples used for training and validation.

4. **Optimization of the Support Vector Machine model:** To address the issue of overfitting in the Support Vector Machine model, a parameter (c) was used to optimize the line fit and penalize the number of samples inside the margin. This step can be considered as part of the postprocessing because it involves adjusting the model parameters to improve its performance.

In summary, the postprocessing steps involved after the model training include metrics calculation, confusion matrix (implied), extrapolation of the models, and optimization of the Support Vector Machine model.