Answer:::
The training of the models is completed after 300 epochs, as mentioned in the context. However, there is no explicit information about using validation loss plateau or any other specific criterion to determine when the training is complete. Therefore, based on the provided context, we cannot definitively answer the query.

However, it is important to note that using a fixed number of epochs for training is a common practice, but monitoring the validation loss or other metrics to determine when training should be stopped is a more robust approach. Techniques like early stopping or setting a patience parameter can help avoid overfitting and ensure better generalization of the model.

In the given context, the models' performance is evaluated on the validation set after each epoch, but it is not clear if this information is used to influence the training process or decide when to stop training. It is possible that the authors used a separate criterion or method to determine when training should be completed, but this information is not provided in the context.

Answer:::
In summary, the provided context does not contain specific information about using validation loss plateau or any other criterion to determine when the training of the models should be complete. The training is carried out for a fixed number of epochs, and the validation set is used for performance evaluation after each epoch. Still, the decision to stop training is not explicitly linked to the validation loss or any other metric.