Based on the provided context, there is no explicit information about the measures taken to ensure the generalizability of the deep learning model used in the study by Huang et al. (2019) for monitoring ecosystem service change in the City of Shenzhen. However, there are some measures commonly used to enhance the generalizability of deep learning models that are worth mentioning.

Firstly, using a diverse dataset is crucial for improving the generalizability of deep learning models. A diverse dataset contains a wide variety of samples, including those from different geographical locations, time periods, and environmental conditions. Using such a dataset can help the model learn the underlying patterns in the data more effectively and make more accurate predictions for new, unseen data.

Secondly, cross-validation is a commonly used technique to evaluate the performance of deep learning models and ensure their generalizability. Cross-validation involves dividing the dataset into multiple subsets, training the model on one subset, and testing it on another subset. This process is repeated for all the subsets, and the final performance of the model is calculated as the average performance across all the subsets. Cross-validation can help reduce overfitting, which occurs when the model performs well on the training data but poorly on new, unseen data.

Thirdly, stratified splitting is another technique used to ensure the generalizability of deep learning models. Stratified splitting involves dividing the dataset into subsets based on some predefined criteria, such as the class labels or the distribution of some important variables. This technique can help ensure that each subset contains a representative sample of the entire dataset, including rare or underrepresented classes.

In conclusion, while the provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model used in the study by Huang et al. (2019), using a diverse dataset, cross-validation, and stratified splitting are some commonly used techniques that can help improve the generalizability of deep learning models.