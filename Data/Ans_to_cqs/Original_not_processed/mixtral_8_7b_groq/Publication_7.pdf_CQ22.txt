The text provided does not give explicit information about the specific metrics used to evaluate the performance of the deep learning model. However, it does mention that the deep learning model is used for image classification, and it is trained and fine-tuned on various datasets.

In the context of image classification, some common metrics used to evaluate the performance of a model include:

1. Accuracy: This is the ratio of the number of correct predictions to the total number of input samples. It gives an overall idea of the model's performance.
2. Precision: This is the ratio of true positive predictions (correctly labeled positive samples) to the total predicted positive samples. It is useful when the cost of a false positive is high.
3. Recall (Sensitivity): This is the ratio of true positive predictions to the total actual positive samples. It is useful when the cost of a false negative is high.
4. F1-score: This is the harmonic mean of precision and recall, and provides a balance between the two metrics.
5. Area Under Curve (AUC): This metric is used for ROC curves, which plot the true positive rate against the false positive rate. AUC measures the entire two-dimensional area underneath the entire ROC curve (from (0,0) to (1,1)).

Given the nature of the problem and the techniques used (deep learning, image classification, and feature extraction), it is likely that the authors used one or more of these metrics to evaluate the performance of their model. However, without explicit information, it is not possible to provide a definitive answer.