The provided context does not directly mention the methods used for collecting raw data in the deep learning pipeline. However, it does mention that the study involves the use of observed data to predict means, standard deviations, and population sizes, and that the data comes from a full sample of 10,000 using both uninformative and informative priors.

One possible interpretation of this is that the data was collected through a survey or census of some kind, as these are common methods for gathering large samples of data. Additionally, the use of both uninformative and informative priors suggests that the data may have been collected through a method that allows for the inclusion of existing knowledge or assumptions about the population being studied.

Another possibility is that the data was collected through the use of sensors or other automated data collection methods. This is suggested by the fact that the data is presented in a figure and stored as a .csv file, which could indicate that it was collected and processed electronically.

It is also possible that the data was obtained from public datasets. This would be consistent with the use of both uninformative and informative priors, as public datasets often contain a mix of structured and unstructured data that can be used to inform predictions.

In summary, while the provided context does not explicitly state the methods used for collecting raw data in the deep learning pipeline, it suggests that the data may have been collected through a survey or census, sensors or other automated methods, or public datasets.