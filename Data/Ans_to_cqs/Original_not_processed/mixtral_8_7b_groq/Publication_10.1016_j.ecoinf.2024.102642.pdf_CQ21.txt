After the model training process, there are several postprocessing steps involved, including the calculation of evaluation metrics, generating saliency maps, and creating confusion matrices.

Evaluation metrics are crucial for assessing the performance of the models. In this context, the study uses two evaluation metrics: Area Under the Curve (AUC) and mean Average Precision (mAP). The AUC measures the entire two-dimensional area underneath the entire ROC curve (a plot of true positive rates vs. false positive rates), providing an aggregate measure of performance across all possible classification thresholds. The mAP is a measure of the average precision at various intersections of recall and precision curves. These metrics are used to compare the performance of models trained with annotations from experts and novices.

Saliency maps are another postprocessing step used to visualize the regions of input data that are most important for the model's prediction. Saliency maps highlight the areas of the input data that contribute the most to the model's output, providing insights into the model's decision-making process. However, the context does not explicitly mention the use of saliency maps.

Confusion matrices are also used in the postprocessing step to evaluate the performance of the models. A confusion matrix is a table that summarizes the predictions made by a classification model, comparing them to the actual classes. The matrix shows the number of true positives, true negatives, false positives, and false negatives, allowing for a detailed analysis of the model's performance. However, the context does not explicitly mention the use of confusion matrices.

In summary, the postprocessing steps involved after the model training include the calculation of evaluation metrics such as AUC and mAP, generating saliency maps (although not explicitly mentioned), and creating confusion matrices (also not explicitly mentioned). These steps provide insights into the model's performance and decision-making process, enabling researchers to make informed decisions about the suitability of the models for their intended applications.