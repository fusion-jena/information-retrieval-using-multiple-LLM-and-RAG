Based on the provided context, it is not explicitly stated which measures were taken to ensure the generalizability of the deep learning model. However, there are some indications that suggest some steps were taken to ensure the model's performance is not overfitted to the specific data used in the study.

Firstly, the study used transfer learning, which involves using a pre-trained model on a different dataset (ImageNet in this case) and fine-tuning it on the specific dataset. This approach can help improve the model's generalizability, as it has already learned features from a larger and diverse dataset.

Secondly, the study used a batch size of 20 samples and hid all labels from the classifier at first, incrementally revealing them for each batch of samples queried by the sampling methods. This approach can help prevent overfitting, as the model is not trained on the entire dataset at once, and it is exposed to new data incrementally.

Thirdly, the study used a combination of sampling strategies, including uncertainty and diversity-based methods. This approach can help ensure that the model is exposed to a diverse set of samples, reducing the risk of overfitting to specific classes or regions of the input space.

Lastly, the study evaluated the model on focal and citizen-science datasets, which can help ensure that the model's performance is not overfitted to the specific dataset used in the study.

Therefore, while the context does not provide explicit details on the measures taken to ensure the model's generalizability, there are some indications that suggest that steps were taken to prevent overfitting and ensure the model's performance on new and diverse datasets.