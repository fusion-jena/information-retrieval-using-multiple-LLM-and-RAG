Based on the provided context, there is no explicit information about the measures taken to ensure the generalizability of a deep learning model. However, the text mentions some strategies used to improve the performance of SDMs (Species Distribution Models) in general, which could also be applicable to deep learning models.

One such strategy is the integration of multiple observational datasets collected by different sampling designs. This approach could potentially increase the diversity and size of the training dataset, thereby reducing overfitting and improving the model's ability to generalize to new data.

Another strategy mentioned in the context is spatial extrapolation using models trained with sufficient observational data for external areas. This technique could be useful for deep learning models as well, as it would allow them to make predictions in areas with limited or no training data.

The text also mentions the use of cross-validation in the training settings and hyperparameters used for each SDM. Cross-validation is a commonly used technique to assess the performance and generalizability of machine learning models, including deep learning models. It involves dividing the dataset into multiple folds, training the model on one fold, and testing it on the remaining folds. This process is repeated for each fold, and the overall performance of the model is estimated by averaging the performance across all folds.

However, it is important to note that the specific measures taken to ensure the generalizability of the deep learning model are not mentioned in the provided context. Therefore, it is not possible to provide a definitive answer to this query without additional information.