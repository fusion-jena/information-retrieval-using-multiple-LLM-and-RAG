Answer:::
The context provided does not give detailed information on the process followed to deploy the trained deep learning models. However, it does mention that the models were trained using a deep transfer-learning strategy based on fine-tuning, and their performances on the IP102 dataset are listed in Table 2. 

The models' parameters were initialized using a pre-trained model, and a fully connected layer was added to the end for classification, aligning its output dimension with the number of classes in the target dataset. Subsequently, all parameters across the layers were fine-tuned on the target dataset.

As for the deployment process, model serialization is a crucial step where the trained model is saved in a format that can be loaded and used for making predictions. Common model serialization formats include JSON, XML, and Protocol Buffers. However, the context does not specify the format used for the models in this case.

Platform selection is another important aspect of deep learning model deployment. The context does not provide information on where or how these models were deployed. Common platforms for deep learning model deployment include local servers, cloud services like AWS SageMaker or Google Cloud AI Platform, and edge devices.

Therefore, while the training process for the models is described, the context does not provide enough information to answer the query about the process followed to deploy the trained deep learning models.