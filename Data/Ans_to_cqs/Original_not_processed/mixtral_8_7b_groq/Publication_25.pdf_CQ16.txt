Based on the provided context, there is no specific information given about the criteria used to determine when training is complete, such as a validation loss plateau. The context focuses on the use of hand-annotated training samples and validation data to improve models, as well as the potential benefits of using a semi-supervised framework.

In the first piece of context, it is mentioned that the contribution of high-quality annotations can be compared to the self-supervised model or the full model combining both self-supervision and hand-annotation data. This suggests that the training process may involve comparing the performance of different models at various stages of training.

The second piece of context describes how the hand-annotated data can be used solely or in combination with labeled data in a semi-supervised framework. This implies that there may be different training strategies used depending on whether hand-annotated data is being used by itself or in combination with other data.

The third piece of context discusses the removal of boxes with low confidence scores during the training process. This indicates that there may be some criteria used to evaluate the quality of the model's predictions during training.

However, none of the provided context specifically mentions the use of a validation loss plateau or any other criteria for determining when training is complete. Therefore, based on the given context, it is not possible to provide a definitive answer to this query.