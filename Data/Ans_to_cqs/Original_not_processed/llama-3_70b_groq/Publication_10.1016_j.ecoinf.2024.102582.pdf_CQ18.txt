Answer:::

The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the model performance was evaluated using metrics such as user's accuracy (%), total accuracy (%), and Kappa coefficient, as these metrics are reported for each year from 1985 to 2020.

Additionally, the context mentions that the samples were randomly divided into training and validation datasets at a 7:3 ratio, which suggests that the model was trained and validated using these datasets. This implies that the model performance was evaluated on the validation dataset during training, but the specific strategy or metrics used to monitor the performance are not mentioned.

It is also worth noting that the context mentions post-classification processing was applied to the images, which involved manual visual interpretation to correct misclassifications between forest and mangroves. This suggests that the model performance was also evaluated through visual inspection and manual correction, but again, the specific strategy used to monitor the performance is not explicitly stated.