Answer:::

Based on the provided context, it does not explicitly mention any techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on the creation of metadata files, training data description, and test data description. It does not provide information on how data bias was addressed.

However, it can be inferred that the authors attempted to minimize preprocessing to demonstrate the power of human-machine teaming. This approach might have helped reduce the risk of introducing bias during preprocessing. Additionally, the fact that the authors split the data into training and test sets (80% and 20% respectively) could be seen as a form of stratified splitting, which can help mitigate bias. However, this is not explicitly stated as a technique used to address data bias.

In conclusion, based on the provided context, it is not possible to determine the specific techniques used to address data bias during preprocessing.