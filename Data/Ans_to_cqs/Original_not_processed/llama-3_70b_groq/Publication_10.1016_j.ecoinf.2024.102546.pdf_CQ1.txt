Answer:::

Based on the provided context, it appears that the method utilized for collecting raw data in the deep learning pipeline is through a systematic search of public weed datasets in major databases, including Google Scholar, ScienceDirect, Web of Science, IEEE Xplore, and arXiv. The search keywords used include "weed dataset", "weed database", "agriculture", "machine vision", and "computer vision". Additionally, the Python library "scholarly" was employed to automatically retrieve publication records.

It is also mentioned that the collected datasets include metadata such as camera, date, and capture time. Furthermore, the datasets seem to be collected from various sources, including controlled indoor settings and possibly real-world field scenes.

However, it is not explicitly stated whether surveys or sensors are used for collecting raw data. The context only mentions the collection of existing datasets from public sources. Therefore, it is unclear whether surveys or sensors are utilized in the deep learning pipeline.

In summary, the method used for collecting raw data is through a systematic search of public weed datasets in major databases, but it is unclear whether surveys or sensors are used in the pipeline.