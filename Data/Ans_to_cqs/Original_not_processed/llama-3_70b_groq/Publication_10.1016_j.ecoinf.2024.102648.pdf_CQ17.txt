Answer:::
The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that "the penalty method was employed within the framework of ANN models" to address the inclination of neural networks to overfit data. Additionally, early stopping was enabled to prevent the model from overfitting the predicted percent CLCuD. Therefore, it can be inferred that the penalty method and early stopping were used as regularization techniques to prevent overfitting, but the specific methods (e.g., dropout, L2 regularization) are not mentioned.