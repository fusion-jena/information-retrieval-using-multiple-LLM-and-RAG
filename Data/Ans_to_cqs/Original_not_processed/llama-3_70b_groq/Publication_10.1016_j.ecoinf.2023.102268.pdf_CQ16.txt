Answer: 

The provided context does not explicitly mention the criteria used to determine when training is complete. However, it does mention that 50% of the training data were held-out for validation, which suggests that validation loss or accuracy might be used as a criterion to evaluate the model's performance during training. 

Additionally, the context mentions the use of 10-fold cross-validation to define the score-to-posterior-probability transformation function, which implies that the model's performance is evaluated using cross-validation. However, it does not specify whether a plateau in validation loss or a specific threshold in accuracy is used to determine when training is complete.

Therefore, based on the provided context, it is not possible to determine the exact criteria used to determine when training is complete.