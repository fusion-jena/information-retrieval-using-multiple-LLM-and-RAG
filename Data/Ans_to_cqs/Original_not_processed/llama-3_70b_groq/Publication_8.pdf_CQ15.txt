Answer:::

Unfortunately, the provided context does not explicitly mention the optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The text focuses on the architecture of the Convolutional Neural Network (CNN), the use of transfer learning, and the training process, but it does not specify the optimization algorithm used to update the model's parameters during training.

Therefore, I don't know the answer to this question based on the provided context.