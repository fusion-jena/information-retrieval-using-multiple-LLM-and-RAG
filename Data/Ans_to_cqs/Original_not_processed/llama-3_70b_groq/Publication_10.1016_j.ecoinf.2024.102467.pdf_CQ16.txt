Answer: 

Unfortunately, the provided context does not explicitly mention the criteria used to determine when training is complete. The context appears to be a collection of research papers and articles from various fields, including neural networks, aquaculture, and ecology. While some of the papers discuss neural network architectures and training methods, none of them explicitly state the criteria for determining when training is complete.

However, it is common in machine learning and deep learning to use certain criteria to determine when to stop training a model. Some common criteria include:

* Validation loss plateau: When the validation loss stops improving or reaches a plateau, it may indicate that the model has converged, and training can be stopped.
* Convergence of metrics: Monitoring metrics such as accuracy, precision, recall, or F1-score, and stopping training when they converge or reach a desired threshold.
* Early stopping: Stopping training when the model's performance on the validation set starts to degrade, indicating overfitting.
* Maximum number of epochs: Stopping training after a fixed number of epochs, regardless of the model's performance.

These criteria are not mentioned in the provided context, but they are common practices in machine learning and deep learning.