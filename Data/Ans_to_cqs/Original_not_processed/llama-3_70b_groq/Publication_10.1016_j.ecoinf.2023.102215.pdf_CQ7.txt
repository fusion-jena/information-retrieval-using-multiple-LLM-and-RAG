Answer: 

Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the architecture and training of a specific model, TrunkNet, and its comparison with other state-of-the-art models. It discusses the model's design, loss function, and performance metrics, but it does not provide information on data splitting criteria.

In general, the criteria for splitting data into training, testing, and validation sets can vary depending on the specific problem, dataset, and model. Common practices include random splitting, stratified splitting, and k-fold cross-validation. However, without specific information about the dataset and experiment design, it is impossible to determine the exact criteria used in this particular case.

Therefore, I don't know the answer to this query based on the provided context.