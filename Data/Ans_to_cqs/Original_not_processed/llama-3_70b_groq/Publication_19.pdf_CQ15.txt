Answer::: 
Answer: According to the provided context, the optimization technique applied in the deep learning pipeline is Stochastic Gradient Descent (SGD). This is mentioned in the text as "Stochastic Gradient Descent (SGD) was used as the optimizer for all four models." There is no mention of Adam or any other optimization techniques being used.