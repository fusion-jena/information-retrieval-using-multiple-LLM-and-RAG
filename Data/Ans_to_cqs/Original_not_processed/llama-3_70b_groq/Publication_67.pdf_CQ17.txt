Answer:::
Answer: The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention some techniques that can be related to regularization, such as data augmentation, which can help reduce overfitting by increasing the size of the dataset. Additionally, the context mentions the use of RMSProp as an optimization algorithm, which can help with convergence and stability, but it is not a regularization method per se. 

It is worth noting that the context cites some papers that discuss deep learning architectures and techniques, such as Inception and ResNet, which often employ regularization methods like dropout and L2 regularization. However, these methods are not explicitly mentioned in the provided context.

In summary, based on the provided context, I don't know the specific regularization methods used to prevent overfitting in the deep learning pipeline.