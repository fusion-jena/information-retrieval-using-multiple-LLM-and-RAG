Answer:::

Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. The context primarily focuses on the experiment's methodology, model selection, and references to various studies. It does not provide detailed information about the preprocessing steps.

However, it is common practice in deep learning to perform certain preprocessing steps before training a model. These steps may include normalization, scaling, cleaning, tokenization, and feature extraction, depending on the specific problem and dataset. But without explicit information, it is impossible to determine the exact preprocessing steps used in this particular experiment.

If you need more information about preprocessing steps, I recommend consulting general resources on deep learning or the specific documentation of the models used in the experiment, such as ERNIE, LSTM-CNN, and HRNet.