Answer::: 

Based on the provided context, the regularization method used to prevent overfitting in the deep learning pipeline is batch normalization. This is mentioned in the text as "Batch normalization: Accelerating deep network training by reducing internal covariate shift" (reference 20). Additionally, the architecture of the CNN model described in the text also includes batch normalization after each convolutional layer.

It is worth noting that dropout and L2 regularization are not explicitly mentioned in the provided context. However, batch normalization is a regularization technique that helps to reduce overfitting by normalizing the inputs to each layer, which can help to prevent the model from relying too heavily on any single neuron or feature.