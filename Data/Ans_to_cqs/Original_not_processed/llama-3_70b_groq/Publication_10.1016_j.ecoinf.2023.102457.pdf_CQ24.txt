Answer:::

The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The context primarily focuses on comparing the performance of different feature extraction methods (MFCCs, BirdNET, VGGish, Wav2Vec2, and acoustic indices) for classifying gibbon calls.

However, it is mentioned that the authors used 20 iterations of cross-validation to evaluate the performance of the supervised classification methods. This suggests that they may have employed some form of randomization or shuffling of the data during the cross-validation process, but the specific strategy used to handle randomness is not explicitly stated.

Therefore, I don't know the specific strategy employed to handle randomness in the deep learning pipeline, as it is not mentioned in the provided context.