Answer: 

Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed values. The context primarily focuses on various deep learning models, their applications, and performance metrics, but it does not delve into the specifics of handling randomness.

However, it is a common practice in deep learning to use techniques such as:

1. Fixing the random seed: This involves setting a fixed random seed value to ensure reproducibility of results.
2. Data shuffling: Shuffling the training data can help reduce the impact of randomness in the model's performance.
3. Ensemble methods: Combining the predictions of multiple models trained with different random seeds can help reduce the effect of randomness.
4. Hyperparameter tuning: Performing hyperparameter tuning using techniques such as grid search or random search can help find the optimal hyperparameters that are less sensitive to randomness.

These strategies are commonly used in deep learning pipelines, but they are not explicitly mentioned in the provided context.