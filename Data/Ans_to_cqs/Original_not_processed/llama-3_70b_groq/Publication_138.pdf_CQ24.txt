Answer: Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed values. The context appears to be focused on the results of various deep learning algorithms and their performance on a specific task, rather than discussing the handling of randomness.

However, it is common practice in deep learning to employ strategies such as:

1. Fixing the random seed value to ensure reproducibility of results.
2. Using techniques like dropout and batch normalization to reduce overfitting and improve model robustness.
3. Implementing data augmentation to increase the size and diversity of the training dataset.
4. Averaging model predictions over multiple runs with different random seeds to reduce the impact of randomness.

These strategies are not mentioned in the provided context, and therefore, I cannot provide a more specific answer based on the given information.