Answer: 

The provided context mentions two regularization methods used to prevent overfitting in the deep learning pipeline: L2 regularization and dropout.

L2 regularization is mentioned in the context of ridge regression, where the objective function to be minimized is given by the equation: `min_w ‖Xw - y‖2 + α ‖w‖2`, where `α` is the regularization parameter that controls the strength of the L2 term.

Dropout is not explicitly mentioned in the provided context, but it is mentioned that additional dropout and dense layers were added at the end of the Inception model as part of the Deep Otolith Inception-V3 model.

It is worth noting that the context also mentions the use of an auxiliary classifier as a regularizer in the Inception-V3 architecture, but this is not a traditional regularization method like L2 regularization or dropout.

No other regularization methods, such as dropout, are explicitly mentioned in the provided context.