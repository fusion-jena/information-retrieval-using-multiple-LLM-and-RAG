Answer::: 

The optimization technique applied in the deep learning pipeline is Stochastic Gradient Descent (SGD). This is explicitly mentioned in the context as "For optimization we utilize the Stochastic Gradient Descent (SGD)" in the action recognition section. There is no mention of Adam or any other optimization technique being used.