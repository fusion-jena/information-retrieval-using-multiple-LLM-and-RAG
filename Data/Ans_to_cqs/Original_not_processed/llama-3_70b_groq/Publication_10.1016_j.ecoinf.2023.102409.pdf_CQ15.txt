Answer: According to the provided context, the optimization technique applied in the deep learning pipeline is SGD (Stochastic Gradient Descent). This is mentioned in the text as "utilized SGD optimizer". There is no mention of Adam or any other optimization techniques in the provided context.