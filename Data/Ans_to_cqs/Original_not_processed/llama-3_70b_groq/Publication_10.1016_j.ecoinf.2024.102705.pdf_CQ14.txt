Answer:::
The provided context does not explicitly mention how the hyperparameters of the model are optimized. It only mentions the use of optimization algorithms such as Stochastic Gradient Descent (SGD), Adaptive Gradient (AdaGrad), Root Mean Square Prop (RMSProp), and Adam to assess each parameter's contribution to the loss values during the training process. However, it does not specify whether grid search, random search, or any other method is used to optimize the hyperparameters. Therefore, I don't know the answer to this query based on the provided context.