Answer::: 

The hyperparameters used in the deep learning model are mentioned in the provided context. Specifically, for Model-2, which uses the EfficientNet-B5 feature extractor, the optimizer used is the Adam optimizer with a learning rate of 0.001. Additionally, the batch size used for training is 8. 

For Model-K, which is a regression model based on VGG16, the optimizer used is the Stochastic Gradient Descent (SGD) optimizer, and the loss function used is the Mean Squared Error (MSE) loss function. However, the learning rate is not specified for Model-K.

No other hyperparameters are mentioned in the provided context.