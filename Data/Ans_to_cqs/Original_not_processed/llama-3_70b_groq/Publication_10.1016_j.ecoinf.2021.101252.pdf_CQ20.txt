Answer::: 

The query asks about the hardware resources used for training the deep learning model. According to the provided context, the answer is GPUs (Graphics Processing Units) and 'tensor processing units'. Additionally, the context also mentions the use of large-resourced cloud computing services and distributed computing for scalable model implementations. However, it does not explicitly state that TPUs (Tensor Processing Units) were used for training the deep learning model in the specific case studies mentioned.