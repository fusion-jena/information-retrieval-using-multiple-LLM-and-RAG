Answer: 

The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the model performance is evaluated using four criteria: coefficient of determination (R2), Nash-Sutcliffe efficiency (NSE), Kling-Gupta efficiency (KGE), and correlation coefficient (COR). These criteria are used to assess the performance of both statistical and machine learning models.

Additionally, the context provides a table (Table 5) that presents the model performance statistics for the training and testing datasets. This suggests that the model performance is monitored and evaluated during both the training and testing phases.

However, the specific strategy or approach used to monitor the model performance during training is not explicitly mentioned. It is possible that the models are trained using a hold-out method, where a portion of the data is set aside for testing, and the model performance is evaluated on this testing data. Alternatively, the models may be trained using cross-validation, where the data is split into multiple folds, and the model performance is evaluated on each fold. Without more information, it is difficult to determine the exact strategy used to monitor the model performance during training.