Answer: 

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention the use of batch normalization and Leaky-ReLU activation functions in the network architecture, which can help with stability and preventing overfitting to some extent. 

Additionally, the context discusses the use of adversarial loss, L1 loss, and perceptual loss functions, which can also help with regularization. However, it does not specifically mention dropout or L2 regularization, which are common regularization techniques used to prevent overfitting.

Therefore, based on the provided context, it is not possible to determine the specific regularization methods used to prevent overfitting in the deep learning pipeline.