Answer: 

Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context primarily focuses on the application of convolutional neural networks in land use and land cover classification, and it does not delve into the specifics of regularization techniques.

While the context discusses the training process and the optimization of filter weights based on a given loss function, it does not provide information on the regularization methods used to prevent overfitting. Therefore, I cannot provide a specific answer to this query based on the given context.

However, it is worth noting that dropout and L2 regularization are common regularization techniques used to prevent overfitting in deep learning models. Dropout randomly drops out neurons during training to prevent the model from relying too heavily on any single neuron, while L2 regularization adds a penalty term to the loss function to discourage large weights. However, these techniques are not mentioned in the provided context.