Answer:::

Unfortunately, the provided context does not explicitly mention the strategy implemented to monitor the model performance during training. The context discusses the dataset, annotation, and exploration, as well as the model architecture and results on goat vocalization detection. However, it does not provide information on how the model performance is monitored during training.

It can be inferred that the model is trained using a 70%-10%-20% split for training, validation, and testing, respectively, which suggests that the model's performance is evaluated on the validation set during training. However, the specific strategy or metrics used to monitor the model's performance are not mentioned.

Therefore, I don't know the exact strategy implemented to monitor the model performance during training based on the provided context.