Answer::: 

To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the data was divided into training, validation, and testing sets with a percentage ratio of 5.4:0.6:1. This split helps to evaluate the model's performance on unseen data. 

Secondly, 10-fold cross-validation was used to divide the training and validation set. In each fold, nine parts were used for training and one part was used for validation. This technique helps to reduce overfitting and ensures that the model is not biased towards a particular subset of the data.

Additionally, the input data underwent batch normalization to address the large differences in distribution between different batches of training data and between the training set and the test set. This normalization step helps to reduce the impact of these differences on the model's performance.

However, there is no mention of using a diverse dataset or stratified splitting in the provided context.