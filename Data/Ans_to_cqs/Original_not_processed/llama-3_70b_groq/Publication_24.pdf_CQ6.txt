Answer:::

Based on the provided context, it appears that the preprocessing steps involved before training a deep learning model include normalization. Specifically, the text mentions that "methods for preprocessing spectrograms before they are used in ML" were applied, and that "different normalisation strategies" were used to preprocess the input data. Additionally, the text mentions that "subtraction of mean values along each frequency bin" was also used as a preprocessing step.

It is also mentioned that the input to the network consisted of a 32 × 21 × 4 tensor, suggesting that the input data had multiple channels, which were likely preprocessed separately before being fed into the network.

However, it is not explicitly mentioned whether other preprocessing steps such as scaling or cleaning were involved. The text does mention that the authors applied different normalization strategies, but it does not provide further details on other preprocessing steps.

Therefore, based on the provided context, it can be concluded that normalization was one of the preprocessing steps involved, but it is unclear whether other steps such as scaling or cleaning were also applied.