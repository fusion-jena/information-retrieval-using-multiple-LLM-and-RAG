Answer: The strategy implemented to monitor the model performance during training is the use of k-fold cross-validation. Specifically, the dataset is split into k-2 folds for training (tuning set) and 1 fold for validation. The model is trained on the tuning set and its performance is evaluated on the validation set using the out-of-sample R2 metric. This process is repeated for each of the k-1 folds, and the median of the out-of-sample R2's is calculated for each number of iterations. This allows the selection of the best number of iterations for the model. Additionally, the use of 10-fold cross-validation is mentioned in the context of pruning the tree in the RF model.