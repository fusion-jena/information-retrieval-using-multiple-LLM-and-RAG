Answer: 

Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context appears to be related to a study on bird song recognition using machine learning models, but it does not provide information on how the data was split for training, testing, and validation.

However, it can be inferred that the study used a test set (Test_S2 and Test_S3) and a target set (with 32,640 unvalidated recordings) in the experiment. The study also mentions manual validations of S2 and S3 songs with varying numbers of samples (30, 50, 100, 200, 300, and 400). These samples might have been used for training and validation, but the exact criteria for splitting the data are not specified.

In general, common criteria for splitting data into training, testing, and validation sets include random sampling, stratified sampling, or k-fold cross-validation. However, without explicit information, it is impossible to determine the specific criteria used in this study.