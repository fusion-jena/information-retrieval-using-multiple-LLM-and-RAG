Answer:::
Answer: The hyperparameters used in the deep learning model are as follows: the optimizer used is the Adam optimizer, and the initial learning rate is 0.0001, decaying by a factor of 0.001*learning rate. The batch size is 32. The model was trained for 50 epochs without mixing up augmentations and for 100 epochs with mixing up augmentations. Additionally, early stopping was introduced to prevent overfitting when no further improvement was observed.