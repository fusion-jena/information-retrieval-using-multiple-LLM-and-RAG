Answer: The hyperparameters used in the deep learning models are provided in Table 1. The learning rates used are 1e-4 for ResNet-50, 2e-3 for ViT-S/16, 1e-5 for Volo-d1, and 5e-4 for ViP-Small/7. The optimizer used is AdamW with beta values of 0.9 and 0.999. The schedulers used are cosine schedulers. The batch sizes are 128 for ResNet-50, ViT-S/16, and Volo-d1, and 64 for ViP-Small/7. The weight decays are 5e-4 for ResNet-50, 1e-8 for ViT-S/16, 4e-6 for Volo-d1, and 5e-2 for ViP-Small/7. The input sizes are 224 Ã— 224 for all models. The number of epochs is 210 for ResNet-50, 64 for ViT-S/16, 8e-6 for Volo-d1, and 2e-3 for ViP-Small/7.