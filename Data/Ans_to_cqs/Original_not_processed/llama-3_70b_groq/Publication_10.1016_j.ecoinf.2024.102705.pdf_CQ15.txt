Answer: According to the provided context, the optimization techniques applied in the deep learning pipeline mentioned are:

1. Stochastic Gradient Descent (SGD) (Herbert and Sutton, 1951)
2. Adaptive Gradient (AdaGrad) (Duchi et al., 2011)
3. Root Mean Square Prop (RMSProp) (Tieleman and Hinton, 2012)
4. Adam (Kingma and Ba, 2014)

Specifically, in the implementation details section, it is mentioned that the AIP-OD model was trained using the Adam optimizer.