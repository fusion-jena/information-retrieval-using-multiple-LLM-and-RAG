Answer: 

Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The context appears to be focused on specific deep learning models, such as Mask R-CNN, U-Net, and FastFCN, and their applications in image segmentation tasks. It also provides details on the implementation of these models, including the use of specific libraries, versions, and hyperparameters.

However, in general, handling randomness in deep learning pipelines is crucial to ensure reproducibility and consistency of results. Some common strategies employed to handle randomness include:

1. Setting a fixed random seed value: This ensures that the same sequence of random numbers is generated every time the code is run, making the results reproducible.
2. Using deterministic algorithms: Some algorithms, such as those used in certain neural network layers, can be designed to be deterministic, eliminating the need for random number generation.
3. Controlling random number generation: Libraries like NumPy and TensorFlow provide mechanisms to control random number generation, allowing developers to set a seed value or use a specific random number generator.

While these strategies are not explicitly mentioned in the provided context, they are essential in deep learning pipelines to ensure reproducibility and consistency of results.