Answer:::

The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The context primarily focuses on the hyperparameter settings and training procedures for different deep learning models.

However, it is worth noting that the context mentions that the annotated dataset is split "randomly (but fixed for all experiments and all networks)" into a train set, validation set, and test set. This suggests that the randomness in the dataset splitting process is controlled, ensuring that the same split is used for all experiments and networks.

Beyond this, the context does not provide information on how randomness is handled in other aspects of the deep learning pipeline, such as weight initialization, data augmentation, or shuffling of training data. Therefore, it cannot be determined from the provided context what strategies are employed to handle randomness in the deep learning pipeline.