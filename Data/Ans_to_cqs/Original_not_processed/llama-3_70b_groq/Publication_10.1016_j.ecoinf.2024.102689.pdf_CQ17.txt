Answer: 

Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context primarily focuses on fish individual recognition, underwater image resolution enhancement, and model compression techniques such as knowledge distillation and quantization. 

However, it does mention pruning techniques for simplifying deep neural networks (Pasandi et al., 2020; Pattanayak et al., 2021) and model compression via distillation and quantization (Polino et al., 2018). These techniques can be used to reduce overfitting, but they are not traditional regularization methods like dropout or L2 regularization.

Therefore, I cannot provide a specific answer to the query based on the given context.