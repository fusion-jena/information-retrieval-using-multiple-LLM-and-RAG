Answer: 

The provided context does not explicitly mention the hyperparameters used in a deep learning model. However, it does mention some hyperparameters used in specific models. 

For the Multilayer Perceptron Neural Network (MLPNN), the optimal learning rate is 0.01, momentum is 0.18, and the number of training iterations is 500. 

For the Extreme Gradient Boosting (XGBoost) model, the hyperparameters mentioned are ntree, tree node size, and gradient boosting iteration. However, the specific values for these hyperparameters are not provided.

No other deep learning model hyperparameters are mentioned in the provided context.