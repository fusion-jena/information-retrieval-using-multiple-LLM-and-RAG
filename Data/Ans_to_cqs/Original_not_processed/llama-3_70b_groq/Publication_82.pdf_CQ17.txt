Answer:::

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention that the first two fully connected layers (fc{6, 7}) have a dropout layer associated with them, with a dropout ratio of 0.5. This suggests that dropout is one of the regularization methods used to prevent overfitting.

Additionally, the context mentions the use of weight decay with a value of 0.0005, which is a form of L2 regularization.

No other regularization methods are explicitly mentioned in the provided context. Therefore, I cannot provide a comprehensive list of regularization methods used to prevent overfitting in the deep learning pipeline.