Answer: The optimization technique applied in the deep learning pipeline is AdamW. This is mentioned in the context as "the proposed model is trained for 100 epochs with optimizer AdamW". Additionally, the learning rate is set to 0.002 and the batch size is set to 32.