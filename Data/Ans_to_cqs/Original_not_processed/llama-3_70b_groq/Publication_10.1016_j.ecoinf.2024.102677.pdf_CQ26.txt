Answer:::

Based on the provided context, it appears that stratified splitting is used to address data bias during preprocessing of the deep learning pipeline. The text states, "To ensure the stability of the proposed models, we randomly divided the dataset into three parts: training (60%), validation (20%), and testing (20%) (Meng et al., 2022). This division was performed in a stratified manner to maintain class proportions across all of the parts." This suggests that the authors used stratified splitting to maintain class balance and reduce bias in the dataset.

There is no mention of oversampling, undersampling, or diverse data collection in the provided context. Therefore, it is unclear whether these techniques were used to address data bias.