Answer: 

The provided context does not mention specific optimization techniques applied in the deep learning pipeline, such as SGD or Adam. The context primarily focuses on Hyperband, a method for efficient hyperparameter tuning, and its components, including random search, successive halving, and partial training. It also discusses the architecture of a specific neural network, including convolutional neural networks (CNNs) and recurrent highway networks (RHNs), but does not mention optimization techniques. Therefore, I don't know the answer to this query based on the provided context.