Answer:::
Answer: The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the performance of the models (GLM and RF) is evaluated using various metrics such as Area Under the ROC Curve (AUC), Percent Correctly Classified (PCC), sensitivity, specificity, and True Skill Statistic (TSS) on a separate validation dataset. For the non-bootstrapped models, the validation dataset consists of 20% of the camera trap locations retained from the training dataset. For the bootstrapped GLM, the validation metrics are calculated for each of the 100 iterations using the data retained from the model training, and the final metrics are obtained by averaging the results of these iterations.