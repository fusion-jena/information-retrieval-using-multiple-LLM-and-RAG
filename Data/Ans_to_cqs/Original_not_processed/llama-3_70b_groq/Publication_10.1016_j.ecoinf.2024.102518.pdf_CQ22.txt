Answer::: 

The query asks about the metrics used to evaluate the performance of the deep learning model. However, the provided context does not mention a deep learning model. Instead, it discusses species distribution models, and the evaluation metrics used are different from those typically used in deep learning.

According to the context, the metrics used to evaluate the performance of the species distribution models are:

1. Delta.AICc (Akaike minimum information criterion) to determine the best tuning parameters.
2. AUC-ROC (Area under the Receiver Operating Characteristic curve) to evaluate the model's performance.
3. CBI (Continuous Boyce Index) to evaluate the model's performance, especially when obtaining true absences is challenging.
4. Cohen's KAPPA metrics, which were used in addition to AUC-ROC to evaluate the performance of the nine algorithms compared in the study.

There is no mention of accuracy, precision, or recall, which are common metrics used in deep learning model evaluation.