Answer:::

Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the performance of different CNN architectures, hyperparameter tuning, and the results of the experiments.

However, it is common practice in machine learning to split the data into training, validation, and testing sets to evaluate the model's performance and prevent overfitting. Typically, the data is split into:

* Training set (e.g., 60-80% of the data): used to train the model
* Validation set (e.g., 15-20% of the data): used to tune hyperparameters and evaluate the model's performance during training
* Testing set (e.g., 5-20% of the data): used to evaluate the model's performance on unseen data after training is complete

But, without explicit information, I cannot determine the specific criteria used in this particular study.