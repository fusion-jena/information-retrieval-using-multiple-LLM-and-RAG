Answer: Unfortunately, the provided context does not explicitly mention the optimization techniques used in the deep learning pipeline, such as SGD or Adam. The context discusses hyperparameter optimization, transfer learning, and image classification using various CNN models, but it does not specify the optimization algorithms used during training. The table provided in the context describes various hyperparameters, including the learning rate, learning rate drop factor, and learning rate scheduling method, but it does not mention the specific optimization techniques used. Therefore, I don't know the answer to this query based on the provided context.