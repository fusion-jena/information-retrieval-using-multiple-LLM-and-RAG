Answer: 

Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the development of a deep learning model for hummingbird ecology using time-lapse cameras and its application in the Ecuadorian Andes. It discusses the model's architecture, training process, and evaluation metrics, but it does not provide information on how the data was split for training, testing, and validation.

However, it is common practice in deep learning to split the data into training, testing, and validation sets to evaluate the model's performance and prevent overfitting. Typically, the data is split into 60-80% for training, 15-20% for testing, and 5-10% for validation. But without explicit information, it is impossible to determine the exact criteria used in this specific case.

In summary, the provided context does not provide the necessary information to answer this query.