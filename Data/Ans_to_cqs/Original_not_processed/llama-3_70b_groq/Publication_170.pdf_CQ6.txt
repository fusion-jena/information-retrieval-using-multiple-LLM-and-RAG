Answer:::

Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. The context primarily focuses on the model architecture, training modes, and performance comparisons. It does mention that Yousif et al. (2019) had more complex preprocessing, but it does not specify what those preprocessing steps are.

However, it is worth noting that the context does mention Local Response Normalization (LRN) processing and Rectified Linear Unit (ReLU) activation function processing in the DCNN model architecture. These are not typically considered preprocessing steps, but rather components of the model architecture.

In general, common preprocessing steps for deep learning models may include normalization, scaling, cleaning, data augmentation, and feature extraction. However, without more specific information, it is impossible to determine the exact preprocessing steps used in this particular study.

Therefore, I do not have enough information to provide a definitive answer to this query.