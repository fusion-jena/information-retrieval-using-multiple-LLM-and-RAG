Answer: 

The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does mention the use of data augmentation to increase the size of the training dataset. 

Data augmentation involves applying random variations and manipulations to the data, such as flipping, cropping, contrast shifting, translating, and rotating images. These augmentations are applied in a random order, which introduces randomness into the training process. 

While this does not directly address the question of handling randomness in the deep learning pipeline, it suggests that the authors are aware of the importance of considering randomness in their approach. However, the specific strategy used to handle randomness in the pipeline is not mentioned. Therefore, I don't know the exact answer to this question based on the provided context.