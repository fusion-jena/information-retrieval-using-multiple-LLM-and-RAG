Answer: 

The provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context appears to be focused on a specific method for selecting tuning parameters and performing variable selection, rather than discussing data splitting for deep learning model training.

However, it does mention cross-validation as a recommended approach to obtain the RTMSPE (root trimmed mean squared prediction error), which is a metric used to evaluate the model's performance. Cross-validation is a common technique used to split data into training and testing sets to evaluate a model's performance and prevent overfitting.

In general, the criteria used to split data for deep learning model training typically include:

* Random splitting: dividing the data randomly into training, testing, and validation sets.
* Stratified splitting: dividing the data into training, testing, and validation sets while maintaining the same proportion of classes in each set.
* Time-based splitting: dividing the data into training, testing, and validation sets based on time, such as using historical data for training and recent data for testing.

However, these criteria are not explicitly mentioned in the provided context.