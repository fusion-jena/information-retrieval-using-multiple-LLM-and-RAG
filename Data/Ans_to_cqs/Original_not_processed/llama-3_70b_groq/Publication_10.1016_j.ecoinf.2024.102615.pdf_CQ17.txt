Answer: 

Based on the provided context, the regularization method used to prevent overfitting in the deep learning pipeline is dropout. This is mentioned in the context as one of the hyperparameters to be optimized, specifically the percentage value of the dropout layers. Dropout is a regularization technique that randomly drops out neurons during training to prevent the model from relying too heavily on any single neuron, thus reducing overfitting. 

There is no mention of L2 regularization in the provided context. It is possible that other regularization methods may be used in the pipeline, but based on the provided information, dropout is the only regularization method mentioned.