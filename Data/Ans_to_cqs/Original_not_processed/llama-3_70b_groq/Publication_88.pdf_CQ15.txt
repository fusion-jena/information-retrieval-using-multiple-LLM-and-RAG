Answer::: 

According to the provided context, the optimization technique applied in the deep learning pipeline is the Adam optimizer. This is mentioned in the text as follows: "Adam optimizer was selected empirically with weight decay equal to 0.9 and learning rate equal to 10âˆ’3." There is no mention of other optimization techniques such as SGD in the provided context.