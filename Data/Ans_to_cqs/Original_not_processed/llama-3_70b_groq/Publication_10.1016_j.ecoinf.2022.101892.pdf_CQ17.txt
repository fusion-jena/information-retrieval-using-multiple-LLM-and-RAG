Answer: 

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention that "aggressive data augmentation" was applied to avoid overfitting and imbalanced problems. Additionally, it mentions the use of Batch Normalization (BN) to accelerate the training of networks. Batch Normalization can also help in reducing overfitting by normalizing the input data for each layer. 

It does not mention other regularization methods such as dropout or L2 regularization. Therefore, based on the provided context, we can only conclude that data augmentation and Batch Normalization were used to prevent overfitting, but we cannot determine if other regularization methods were used.