Answer: 

Based on the provided context, specifically Table 7, the hyperparameters used in the deep learning model (MLPnn-MC) are:

* Start learning rate: 0.0008
* End learning rate: 0.0001
* Momentum factor: 0.5
* Sigmoid constant: 1.0
* Iterations: 10,000
* Acceptable RMS: 0.01

The optimizer used is not explicitly mentioned, but based on the context, it can be inferred that the backpropagation (BP) or reverse method of automatic differentiation is used, which is a common optimization algorithm used in MLP neural networks.

Note that the other parameters mentioned in Table 7, such as the number of input layer neurons, hidden layer nodes, output layer neurons, and requested samples per class, are related to the architecture of the MLP model rather than the hyperparameters.