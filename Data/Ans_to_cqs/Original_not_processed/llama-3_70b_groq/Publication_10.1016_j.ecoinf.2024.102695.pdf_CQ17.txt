Answer: 

The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention an "early stopping strategy" in the training process, which is a regularization technique used to prevent overfitting. 

Early stopping is a technique where the training process is stopped when the model's performance on the validation set starts to degrade, indicating that the model is overfitting to the training data. This prevents the model from learning the noise in the training data and improves its generalizability.

The context does not mention other regularization methods such as dropout, L2 regularization, or others. Therefore, it is not possible to determine if these methods were used in the deep learning pipeline.