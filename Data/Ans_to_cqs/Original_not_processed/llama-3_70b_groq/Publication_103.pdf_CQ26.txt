Answer:::

The provided context does not explicitly mention techniques such as stratified splitting, oversampling, undersampling, or diverse data collection to address data bias during preprocessing of the deep learning pipeline. However, it does mention measures taken to avoid biases in the experiments.

To avoid biases, the datasets were separated in a special way for training and testing. For herbarium datasets H255 and H1K, data was separated so that sheets of the same species that were collected by the same collector were not permitted to enter both the training and testing sets. For the CR dataset, images of different leaves from each specimen were present in either the training or the testing set, but not in both. For the PlantCLEF (PC) dataset, this was done at the observation level, ensuring that no same observation was present in both training and testing subsets. These measures led to more realistic and unbiased training/testing scenarios, although they also led to lower accuracy rates.

While these measures are not traditional techniques to address data bias, they do help mitigate bias by ensuring that the training and testing sets are representative of the data and do not contain duplicate or highly correlated samples.