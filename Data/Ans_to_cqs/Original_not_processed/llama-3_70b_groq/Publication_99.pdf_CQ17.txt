Answer::: 

Based on the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are dropout and batch normalization. 

In the classification model, a dropout layer with a dropout ratio of 0.5 is used as a network regularizer. This is mentioned in the section 3.3.3. Classification. 

Additionally, the PConv network uses batch normalization layer in the encoder part, which is frozen during training. This is mentioned in the section describing the PConv network. 

There is no mention of L2 regularization being used in the provided context.