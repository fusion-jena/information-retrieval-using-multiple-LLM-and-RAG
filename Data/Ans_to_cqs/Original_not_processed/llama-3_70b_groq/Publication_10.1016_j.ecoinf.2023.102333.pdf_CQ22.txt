Answer::: 

The metrics used to evaluate the performance of the deep learning model are Overall Accuracy (OA), Producer Accuracy (PA), User Accuracy (UA), and the kappa coefficient of agreement. Additionally, errors of omission and commission are also calculated for each class to assess the model's performance. 

Overall Accuracy (OA) is the ratio of the sum of correctly classified pixels to the total number of pixels in the test dataset. Producer Accuracy (PA) refers to the accuracy from the point of view of the mapmaker, while User Accuracy (UA) represents the probability that a pixel classified in each category corresponds to the actual category on the ground. The kappa coefficient of agreement is used to evaluate the performance of the final DNN model, with a value of 93.4% indicating an almost perfect agreement. 

Errors of omission and commission are also used to assess the model's performance for each class. Errors of omission represent the proportion of reference data pixels that the model incorrectly classifies, while errors of commission correspond to the proportion of model-predicted pixels that were incorrectly classified according to the reference data. These metrics provide a more comprehensive understanding of the model's performance and can help identify areas for improvement.