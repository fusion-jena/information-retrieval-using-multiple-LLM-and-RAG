Answer:::
The provided context does not mention the use of deep learning or any optimization techniques commonly used in deep learning pipelines, such as SGD (Stochastic Gradient Descent) or Adam. The context appears to be focused on Gradient Boosting Regression Trees (GBRT) and Generalized Additive Models (GAM), which are different machine learning approaches.

The context does mention "steepest descent" and "line search" in the context of gradient boosting, but it does not specify the use of SGD or Adam. Steepest descent is a general optimization technique that can be used in various machine learning algorithms, including GBRT.

Therefore, based on the provided context, I don't know what optimization techniques are applied in a deep learning pipeline, as deep learning is not mentioned at all.