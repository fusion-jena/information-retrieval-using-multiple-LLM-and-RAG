Answer: The provided text focuses on the applications and development of convolutional neural networks (CNNs) and doesn't delve into specific criteria for determining the completion of training. 

However,  it does mention that training a CNN on a small dataset can be improved by data augmentation and transfer learning. 

Generally, training is considered complete when a model achieves a satisfactory performance on a validation set, which is a separate dataset used to evaluate the model's ability to generalize to unseen data. 

Some common criteria for determining training completion include:

* **Validation loss plateau:** If the loss on the validation set stops decreasing or increases, it might indicate that the model is overfitting to the training data.
* **Achieving a target accuracy:**  Setting a desired accuracy on the validation set can serve as a stopping point.
* **Maximum number of epochs:**  Limiting the number of training iterations (epochs) can prevent overfitting and save computational resources.


It's important to note that the optimal stopping criteria depend on the specific task, dataset, and model architecture. 

