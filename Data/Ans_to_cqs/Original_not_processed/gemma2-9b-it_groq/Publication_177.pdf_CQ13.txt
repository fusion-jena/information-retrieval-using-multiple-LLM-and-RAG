Answer: The text states that the hyperparameters optimized for the deep learning models were:

* **Batch size:** between 1 and 32
* **Initial learning rate:** between 1×10-4 and 1×10-2 

The optimization technique used was Bayesian optimization, which minimizes the loss on the validation dataset. The optimizer used for training was stochastic gradient descent with momentum ('sgdm'). 
