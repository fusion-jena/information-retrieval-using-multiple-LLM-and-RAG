Answer:::
The provided text focuses on Knowledge Discovery in Databases (KDD) and data mining techniques like the Apriori algorithm. It doesn't offer information about data splitting criteria for deep learning models. 


To answer your query about splitting data for deep learning, here's a general explanation:

Deep learning models are typically trained using a split of the available data into three main sets:

* **Training set:** This is the largest portion of the data used to train the model. The model learns patterns and relationships within this data.
* **Validation set:** This set is used to evaluate the model's performance during training. It helps in tuning hyperparameters and preventing overfitting (where the model performs well on training data but poorly on unseen data).
* **Test set:** This set is held out entirely from the training process and is used only once at the end to provide an unbiased evaluation of the final model's performance.

The exact proportions of these splits can vary depending on the size of the dataset and the specific problem. A common split is 70% for training, 15% for validation, and 15% for testing. 

