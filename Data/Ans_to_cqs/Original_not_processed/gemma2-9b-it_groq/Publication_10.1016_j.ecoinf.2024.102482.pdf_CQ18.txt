Answer:::
The provided text describes the model's architecture, training procedure, and performance metrics but doesn't explicitly state the strategy used to monitor performance *during* training.  

We know the following:

* **Training and Testing Data:** The model is trained on a training dataset and evaluated on a separate test dataset.
* **Performance Metrics:** Accuracy, recall, precision, and F1-score are used to evaluate performance.
* **Dropout:** A dropout rate of 50% is applied during training, which is a regularization technique to prevent overfitting.

Based on this, we can infer that performance is likely monitored on a subset of the training data (perhaps a validation set) during each training epoch. This allows for early detection of overfitting and adjustment of hyperparameters like the dropout rate. 

However, the exact strategy for monitoring performance during training is not detailed in the text. 
