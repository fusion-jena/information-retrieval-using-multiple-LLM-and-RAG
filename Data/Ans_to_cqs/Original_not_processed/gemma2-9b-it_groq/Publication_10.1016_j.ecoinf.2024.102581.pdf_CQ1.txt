Answer:::

The provided text focuses on a specific deep learning application (plant leaf classification) and the optimization of a CNN model. It doesn't offer details about the methods used for collecting raw data in a general deep learning pipeline. 

To answer your query, here are some common methods for collecting raw data in deep learning:

* **Surveys:**  Used for gathering structured information from individuals, often in the form of questionnaires or interviews.
* **Sensors:**  Physical devices that collect data about the environment, such as temperature, pressure, sound, or images.
* **Public Datasets:**  Collections of data made available by organizations or researchers for use in machine learning projects. These can cover a wide range of domains, from images and text to financial data and sensor readings.
* **Web Scraping:**  Automated extraction of data from websites.
* **APIs:**  Application Programming Interfaces allow developers to access and retrieve data from software applications and services.


Let me know if you have any other questions. 
