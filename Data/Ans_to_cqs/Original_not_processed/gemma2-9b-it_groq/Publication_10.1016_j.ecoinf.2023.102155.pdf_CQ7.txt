Answer:::
The provided text focuses on ecological informatics and model performance evaluation, particularly for species distribution prediction. It doesn't offer details about data splitting strategies for deep learning models. 

To answer your query about data splitting criteria for deep learning, here's a common approach:

* **Training Set:** The largest portion of the data (e.g., 70-80%) is used to train the deep learning model. The model learns patterns and relationships within this data.
* **Validation Set:** A smaller portion (e.g., 10-15%) is used to evaluate the model's performance during training. This helps in tuning hyperparameters and preventing overfitting (where the model performs well on training data but poorly on unseen data).
* **Test Set:**  A separate, unseen portion (e.g., 10-15%) is reserved for final evaluation of the trained model's performance on data it hasn't encountered before. This provides a realistic estimate of how well the model will generalize to new data.

The specific split ratios can be adjusted based on the dataset size and the complexity of the deep learning task. 



