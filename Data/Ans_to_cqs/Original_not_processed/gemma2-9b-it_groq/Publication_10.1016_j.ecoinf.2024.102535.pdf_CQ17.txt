Answer:::
The provided text mentions the use of **dropout** as a regularization method to prevent overfitting. 

Specifically, it states: "Dropout refers to the number of neurons randomly turned off during each training inference."  

The text does not mention any other regularization methods like L2 regularization. 


