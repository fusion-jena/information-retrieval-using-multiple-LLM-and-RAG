Answer:::
The model performance was monitored by tuning the number of training epochs and then examining the model outputs and error outcomes for signs of overfitting.  

Overfitting occurs when a model focuses too much on fitting the training data and starts to memorize the noise in the data instead of learning the general underlying patterns. This can lead to poor performance on unseen data. 

The authors observed that the model performance converged to its most accurate state after only 10-30 epochs, which is significantly fewer than the typical 70-250 epochs.  

They also noted that further training did not improve performance and even led to a decrease in performance on held-out test data. This indicated that the model was overfitting to the training data. 
