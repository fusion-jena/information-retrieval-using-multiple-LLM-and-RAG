Answer:::
The provided text focuses on the performance evaluation and variable selection for a random forest model, but it doesn't explicitly state the criteria used to determine when training is complete. 

The text does mention:

* **Parameter optimization:** The optimal number of input variables (M) and the number of trees (Nt) were determined by minimizing the model error.
* **Validation loss:** While not directly named, the process of analyzing model error on a validation set likely serves as a proxy for validation loss.

Based on common machine learning practices, it's reasonable to assume that training would continue until:

* **Validation loss plateaus:**  This indicates that further training is unlikely to significantly improve the model's performance on unseen data.
* **Training loss starts to increase:** This could signal overfitting, where the model learns the training data too well and performs poorly on new data.


However, without explicit statements in the text, we cannot definitively say what criteria were used to determine training completion. 
