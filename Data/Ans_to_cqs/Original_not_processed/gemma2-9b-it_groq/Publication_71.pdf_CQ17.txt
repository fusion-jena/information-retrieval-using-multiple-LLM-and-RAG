Answer:::
The provided text mentions dropout as a regularization method used to prevent overfitting in the deep learning model.  

Specifically, it states: "We added a dropout layer for each convolutional layer with a dropout rate of ‘0.1’ to mitigate overfitting [43] after observing that ‘0.1’ dropout value performed better than two other dropout values, which are ‘0.05’ and ‘0.2’." 


The text does not mention other regularization methods like L2 regularization. 
