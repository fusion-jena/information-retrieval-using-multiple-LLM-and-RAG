Answer:::
The provided text focuses on describing Random Forests and Artificial Neural Networks for modeling net growth in the Atlantic Forest, but it doesn't specify the criteria used to split data for training, testing, and validation in deep learning. 

To answer your query generally, data splitting for deep learning typically involves these common practices:

* **Training Set:** The largest portion of the data (e.g., 70-80%) is used to train the deep learning model. The model learns patterns and relationships within this data.
* **Validation Set:** A smaller portion of the data (e.g., 10-15%) is used to evaluate the model's performance during training. This helps monitor overfitting (when the model performs well on training data but poorly on unseen data) and tune hyperparameters.
* **Test Set:**  A separate, held-out portion of the data (e.g., 10-15%) is used *only once* at the end of training to provide an unbiased estimate of the model's performance on unseen data. 

The choice of splitting ratios can vary depending on the size and nature of the dataset. 
