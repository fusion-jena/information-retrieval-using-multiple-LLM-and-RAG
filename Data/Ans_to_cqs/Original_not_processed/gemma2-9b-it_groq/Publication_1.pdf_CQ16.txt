The provided text doesn't specify the exact criteria used to determine when training is complete for the described deep learning models.  

It does mention that these models are typically trained using "stochastic gradient descent" in a supervised fashion, meaning the algorithm is given labeled data and adjusts its parameters to minimize the difference between its predictions and the actual labels. 

Common criteria for determining training completion in deep learning include:

* **Validation loss plateau:**  Monitoring the loss function on a separate validation dataset. Training stops when the validation loss stops improving or starts increasing.
* **Achieving a target accuracy:**  Setting a desired accuracy level on the validation set and stopping training when it's reached.
* **Maximum number of epochs:**  Specifying a limit on the number of times the entire training dataset is passed through the model.
* **Early stopping:**  Monitoring a performance metric (like validation loss or accuracy) and stopping training if it doesn't improve for a certain number of epochs. 


