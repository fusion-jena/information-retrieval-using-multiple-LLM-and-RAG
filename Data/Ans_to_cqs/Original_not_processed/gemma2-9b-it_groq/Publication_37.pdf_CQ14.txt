Answer:::
The text states that the model optimizes cross-entropy loss via mini-batch stochastic gradient descent. It also mentions using a constant learning rate of 0.01 and applying dropout and L2-regularization.  

However, it does **not** specify how the hyperparameters (like the learning rate, dropout probability, and L2 regularization factor) were initially chosen or if any search methods (like grid search or random search) were used. 
