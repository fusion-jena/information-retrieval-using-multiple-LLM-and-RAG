Answer:::
The model performance was monitored using Out-Of-Bag (OOB) error.  

This technique involves training the model on bootstrapped data, where each iteration uses a random subset of the data. The portion of data not included in each iteration (the "out-of-bag" data) serves as validation data to calculate the generalization error. This process is repeated for each tree in the random forest, and the average OOB error across all trees provides an estimate of the overall model performance. 


The OOB error was used to tune two hyperparameters: the number of covariates randomly selected before growing each tree (mtry) and the number of trees (ntree) in the forest. 
