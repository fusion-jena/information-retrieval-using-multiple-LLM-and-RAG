Answer:::
The provided text mentions several post-processing steps used to evaluate the model's performance:

* **Accuracy:** A standard metric to measure the overall correctness of the model's predictions.
* **F1-score:**  A metric that combines precision and recall, providing a balanced measure of the model's performance, especially useful when dealing with imbalanced datasets.
* **Confusion Matrix:**  A visual representation that shows the number of correct and incorrect classifications made by the model for each class. This helps identify specific areas where the model might be struggling.
* **Graphical Visualizations:**  The text states that performance estimations will be presented using figures, suggesting the use of charts or graphs to illustrate the model's accuracy, F1-score, and potentially other metrics.

The text does not explicitly mention saliency maps. 



