Answer:::
The provided text describes the model performance assessment strategy, not the monitoring strategy during training. 

To evaluate the model's performance, the authors used a leave-one-out cross-validation procedure. This method involves iteratively training the model on all data points except one and then evaluating its performance on the left-out data point. This process is repeated for each data point in the dataset.

The performance of the model was measured using several metrics:

* Coefficient of determination (R2)
* Mean Absolute Error (MAE)
* Root Mean Square Error (RMSE)
* Relative Root Mean Square Error (RRMSE) 


The text does not mention any specific strategies used to monitor the model's performance *during* training. 

