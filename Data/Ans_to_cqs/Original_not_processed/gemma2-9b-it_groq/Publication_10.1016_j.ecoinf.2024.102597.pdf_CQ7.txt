Answer:::
The provided text focuses on ensemble learning methods like Random Forest, GBDT, LightGBM, XGBoost, and CatBoost for estimating Chla concentration and turbidity. It doesn't discuss criteria for splitting data in deep learning models. 

To answer your query about data splitting for deep learning, here's a common approach:

* **Training Set:** The largest portion of the data (e.g., 70-80%) is used to train the deep learning model. The model learns patterns and relationships within this data.
* **Validation Set:** A smaller portion of the data (e.g., 10-15%) is used to evaluate the model's performance during training. This helps in tuning hyperparameters and preventing overfitting (where the model performs well on training data but poorly on unseen data).
* **Test Set:**  A separate, unseen portion of the data (e.g., 10-15%) is reserved for final evaluation of the trained model's performance. This provides an unbiased estimate of how well the model generalizes to new data.

Data is typically split randomly to ensure representativeness. 



