The text describes the dataset as containing "cropped frames of videos" and "thumbnails" where each thumbnail "contains only one labeled-fish".  

It also mentions adding a class for the "background" which is constituted with "random thumbnails of the background which were randomly selected in frames and specific background thumbnails which were taken around the fish thumbnails".

Based on this, we can infer that the primary data annotation technique used is **bounding box annotation**. Each fish in the thumbnail is likely enclosed in a bounding box, indicating its location. 


