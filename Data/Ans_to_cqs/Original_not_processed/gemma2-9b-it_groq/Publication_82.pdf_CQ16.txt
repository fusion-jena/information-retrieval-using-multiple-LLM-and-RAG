Answer:::
The text states that the training is run for a total of 30 epochs. One epoch is defined as the number of training iterations in which the neural network completes a full pass of the whole training set.  The choice of 30 epochs was based on the observation that the learning always converged well within 30 epochs. 

It does not mention any specific criteria like validation loss plateau for determining the completion of training. 
