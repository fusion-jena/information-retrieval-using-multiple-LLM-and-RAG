The provided text focuses on the architecture of a deep learning model called ICSNet and doesn't contain information about data splitting criteria for training.  

To answer your question:

Data for deep learning models is typically split into three sets:

* **Training set:** This is the largest portion of the data used to train the model. The model learns patterns and relationships within this data.
* **Validation set:** This set is used to evaluate the model's performance during training. It helps to tune hyperparameters and prevent overfitting (where the model performs well on training data but poorly on unseen data).
* **Test set:** This set is held out entirely from the training process and is only used to evaluate the final model's performance on unseen data. It provides an unbiased estimate of how well the model will generalize to new examples. 

The typical split ratios are 70% for training, 15% for validation, and 15% for testing. However, these ratios can be adjusted depending on the size and nature of the dataset. 
