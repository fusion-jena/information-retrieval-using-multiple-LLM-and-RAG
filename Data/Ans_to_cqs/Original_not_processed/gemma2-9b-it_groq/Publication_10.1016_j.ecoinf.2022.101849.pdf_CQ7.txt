Answer:::
The provided text focuses on weakly supervised learning and doesn't contain information about data splitting criteria for deep learning models.  

To answer your query about data splitting for deep learning, here's a common approach:

* **Training Set:** This is the largest portion of the data (typically 70-80%) used to train the deep learning model. The model learns patterns and relationships within this data.

* **Validation Set:** A smaller portion of the data (around 10-15%) used to evaluate the model's performance during training.  The model's parameters are adjusted to improve performance on this set.

* **Test Set:**  A separate, unseen portion of the data (around 10-15%) used *only once* at the end of training to provide an unbiased estimate of the model's ability to generalize to new data. 

The goal is to train a model that performs well not only on the training data but also on unseen data (the test set). 
