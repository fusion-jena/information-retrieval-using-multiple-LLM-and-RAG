Answer: The provided text mentions the use of Stochastic Gradient Descent (SGD) as the optimizer. It also states that the learning rate is denoted by α.  The momentum weight is represented by µ.  

The text does not specify the exact values used for these hyperparameters. 
