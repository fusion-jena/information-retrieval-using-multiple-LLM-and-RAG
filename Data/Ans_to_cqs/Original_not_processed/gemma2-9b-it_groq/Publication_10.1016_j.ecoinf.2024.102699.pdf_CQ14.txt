Answer:::
The provided text does not specify the exact hyperparameter optimization technique used (e.g., grid search, random search).  It only mentions the following hyperparameters and their values:

* **Optimizer:** Adam
* **Learning rate:** 0.0001, decaying by a factor of 0.001
* **Batch size:** 32
* **Epochs:** 50 (without mixing up augmentations) and 100 (with mixing up augmentations) 


Therefore, based on the information given, we cannot determine how the hyperparameters were optimized. 
