Answer:::
The model performance was monitored during training by tracking two key metrics: **loss** and **accuracy**. 

* **Loss** served as a measure of how far the model's predictions deviated from the actual class labels. A lower loss value indicated better performance.

* **Accuracy** represented the percentage of correctly classified tiles. 

Both loss and accuracy were calculated for both the **training set** and the **validation set**. The validation set, which was held separate from the training data, was used to evaluate the model's performance on unseen data and to prevent overfitting. 

By comparing the training and validation loss and accuracy curves, the researchers could assess the model's learning progress and identify potential issues such as overfitting. 


