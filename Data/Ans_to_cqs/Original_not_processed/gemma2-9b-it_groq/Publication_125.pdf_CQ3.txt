The provided text describes the dataset used for training a CNN model, but it doesn't specify the exact data annotation techniques used to create it. 

We know the dataset was created through semantic segmentation, where each image was divided into blocks representing different land cover classes (urban, bare soil, vegetation, and road).  The text states that "the resulting images each contain both the real value of pixels of the extracted class and zero for the values of the other classes." 

While this describes the final dataset structure, it doesn't detail how the initial images were annotated to create these class labels. 
