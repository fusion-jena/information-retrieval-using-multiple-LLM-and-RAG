Answer:::
The text states that the authors used early stopping to avoid overfitting.  

Early stopping is a technique where training is halted when the model's performance on a validation set stops improving.  

The specific implementation involved a "patience" parameter set to 10. This means training would continue for a maximum of 10 epochs without improvement in the validation loss before the process was stopped. 


