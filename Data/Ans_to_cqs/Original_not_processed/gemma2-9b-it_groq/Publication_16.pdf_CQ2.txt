Answer: The provided text states that the audio files are segmented into 15-second windows and that MFCC (Mel-frequency cepstral coefficients) is used to extract features from these audio samples.  

Therefore, the deep learning pipeline uses **audio** data. 
