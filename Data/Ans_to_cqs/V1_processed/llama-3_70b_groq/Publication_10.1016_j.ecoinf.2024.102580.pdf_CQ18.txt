The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the model's performance was monitored using various metrics such as training loss, mean Average Precision, and Generalized Intersection-over-Union (IoU) loss, as shown in Fig. 3. These metrics were likely used to evaluate the model's performance on the validation set during training. Additionally, the context mentions that a confidence threshold was established by plotting Precision and Recall against the threshold on the validation set, which suggests that the model's performance was monitored and evaluated on the validation set during training.