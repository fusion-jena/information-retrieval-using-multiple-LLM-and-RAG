Based on the provided context, it appears that the preprocessing step involved before training a model is feature scaling. Specifically, the context mentions that feature scaling refers to preprocessing the input features so that they each have a range of [0,1] but retain the shape of the original distribution. This is done through min-max scaling, as shown in the equation xscaled = (x - min(x)) / (max(x) - min(x)).

There is no mention of other preprocessing steps such as normalization, cleaning, or any specific steps related to deep learning models. The context primarily focuses on Bayesian models, including Bayesian logistic regression and Bayesian GAM, and does not provide information on deep learning models.

Therefore, the answer is limited to feature scaling through min-max scaling, but it is unclear if this is the only preprocessing step or if other steps are involved.