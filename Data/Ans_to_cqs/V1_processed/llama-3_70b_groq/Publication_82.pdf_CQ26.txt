Based on the provided context, it appears that the authors have used a technique called "dataset type variation" to address data bias during preprocessing of the deep learning pipeline. Specifically, they have experimented with three versions of the dataset: color, gray-scale, and leaf-segmented. This approach can be seen as a form of diverse data collection, where the same dataset is presented in different formats to reduce the impact of biases associated with lighting conditions, data collection methods, and apparatus.

However, it does not seem that the authors have used techniques like stratified splitting, oversampling, or undersampling to address data bias. The context does not mention these specific techniques, and the authors' focus appears to be on varying the dataset type and training-testing set distribution to mitigate bias.

It is worth noting that the authors have also experimented with different training-testing set distributions (e.g., 80-20, 60-40, 50-50, 40-60, and 20-80) to evaluate the performance of their models on new unseen data and to detect overfitting. This approach can help identify biases in the data, but it is not a direct technique for addressing bias during preprocessing.

In summary, the authors have used dataset type variation as a technique to address data bias, but it is not clear if they have used other techniques like stratified splitting, oversampling, or undersampling.