To ensure the generalizability of the deep learning model, the authors took several measures. One of the measures was stratified splitting of the dataset into training (60%), validation (20%), and testing (20%) sets. This was done to maintain class proportions across all the parts, which helps to prevent overfitting and ensures that the model is trained and evaluated on a representative sample of the data.

Another measure was the use of a random division of the dataset, which helps to reduce bias and increase the model's ability to generalize to new, unseen data. However, it is not explicitly mentioned whether cross-validation was used. 

Additionally, the authors evaluated the performance of five different network models (ResNet50, ResNet101, Inceptionv3, etc.) on the validation and test sets, which helps to identify the best-performing model and reduce overfitting.

It is not explicitly mentioned whether a diverse dataset was used, but the fact that the authors were able to classify different types of landscapes in the case study area suggests that the dataset may have included a variety of landscapes. However, more information is needed to confirm this.

Overall, the authors took several measures to ensure the generalizability of the deep learning model, including stratified splitting, random division of the dataset, and evaluation of multiple models. However, more information is needed to determine whether a diverse dataset was used and whether cross-validation was employed.