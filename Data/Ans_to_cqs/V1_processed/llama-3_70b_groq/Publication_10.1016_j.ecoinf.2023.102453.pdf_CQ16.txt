Unfortunately, the provided context does not explicitly mention the criteria used to determine when training is complete, such as validation loss plateau. The context primarily focuses on hyperparameter optimization, model training, and evaluation, but it does not provide specific information on the stopping criteria for training.

However, it is a common practice in deep learning to use various criteria to determine when to stop training, such as:

* Validation loss plateau: When the validation loss stops improving or reaches a plateau, it may indicate that the model has converged, and further training may not lead to significant improvements.
* Early stopping: This involves stopping the training process when the model's performance on the validation set starts to degrade.
* Maximum number of epochs: Training can be stopped after a fixed number of epochs, regardless of the model's performance.

These criteria are not mentioned in the provided context, and therefore, I cannot provide a specific answer based on the given information.