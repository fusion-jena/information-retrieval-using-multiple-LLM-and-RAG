Unfortunately, the provided context does not explicitly mention the postprocessing steps involved after model training. The context primarily focuses on the introduction of transformer-like and MLP-like models, their architectures, and their applications in computer vision tasks. It also provides information about the hyperparameters used for training different models and their performance on the IP102 dataset.

However, based on general knowledge, common postprocessing steps involved after model training may include:

1. Metrics calculation: This involves calculating various performance metrics such as accuracy, precision, recall, F1-score, etc. to evaluate the model's performance.
2. Confusion matrix calculation: A confusion matrix is a table used to evaluate the performance of a classification model. It provides a summary of correct and incorrect predictions made by the model.
3. Saliency maps generation: Saliency maps are visualizations that highlight the most relevant input features contributing to the model's predictions.
4. Model interpretation and explainability: This involves techniques such as feature importance, partial dependence plots, and SHAP values to understand how the model is making predictions.
5. Model evaluation on a test set: The trained model is evaluated on a separate test set to estimate its performance on unseen data.

Please note that these are general postprocessing steps and may not be specific to the context provided.