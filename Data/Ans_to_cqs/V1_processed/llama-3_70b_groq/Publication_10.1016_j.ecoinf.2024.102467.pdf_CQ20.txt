Based on the provided context, it is mentioned in the text that the algorithm was trained on an RTX 3090 for 6 hours, and the video memory usage was 12 G. This suggests that the hardware resource used for training the deep learning model is an NVIDIA RTX 3090 GPU.