Unfortunately, the provided context does not mention preprocessing steps involved before training a deep learning model, such as normalization, scaling, or cleaning. The context appears to be related to metadata templates for measurement data, including installation details, measurement settings, and data file descriptions. It discusses the importance of transparent processing approaches and flexibility in data assimilation, but it does not provide information on specific preprocessing steps for deep learning models.

Therefore, I don't know the answer to this query based on the provided context.