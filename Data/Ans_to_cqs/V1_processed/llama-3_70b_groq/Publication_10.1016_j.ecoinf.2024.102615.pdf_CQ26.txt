The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention data partitioning, where the raw dataset is randomly shuffled and divided into training, validation, and test sets with a ratio of 8:1:1. This random partitioning is repeated ten times to reduce the influence of random splitting while ensuring converged performance.

While this approach can help reduce the impact of data bias, it does not specifically address data bias. The context does not mention techniques such as stratified splitting, oversampling, undersampling, or diverse data collection, which are commonly used to address data bias.

Therefore, based on the provided context, it is not possible to determine the specific techniques used to address data bias during preprocessing of the deep learning pipeline.