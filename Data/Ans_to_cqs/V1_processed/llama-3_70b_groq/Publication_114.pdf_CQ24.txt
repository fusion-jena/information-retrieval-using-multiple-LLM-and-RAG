The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. However, it does mention data augmentation as a technique used to increase the amount of tree species samples for training of the deep learning network. This involves rotating, mirroring, and flipping the tree samples randomly to avoid the distinction of identical textures only differing from each other by orientation changes. This technique can help reduce overfitting and improve the robustness of the model to random variations. 

However, it does not provide information on how randomness is handled in terms of random seed value or other aspects of the deep learning pipeline. Therefore, I don't know the specific strategies employed to handle randomness in the deep learning pipeline based on the provided context.