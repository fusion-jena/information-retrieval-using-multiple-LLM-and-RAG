Based on the provided context, one regularization method used to prevent overfitting in the deep learning pipeline is Dropout. This is mentioned in [7] and also applied in the architecture of the Mobile App (Fig. 4) with a dropout rate of 0.2 to reduce overfitting of the model.

Additionally, the context mentions that overfitting can be prevented using "overfitting prevention techniques" but does not explicitly mention L2 regularization. However, it does not provide an exhaustive list of regularization methods, so it is possible that L2 regularization might be used in other contexts.

It is worth noting that the context focuses more on the application of transfer learning to overcome the challenge of limited training samples, rather than exploring a comprehensive list of regularization methods.

In summary, based on the provided context, Dropout is one regularization method used to prevent overfitting, but it does not provide an exhaustive list of regularization methods.