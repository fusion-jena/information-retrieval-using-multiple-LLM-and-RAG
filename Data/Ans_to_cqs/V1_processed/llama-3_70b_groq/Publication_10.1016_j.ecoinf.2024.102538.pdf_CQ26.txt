The context mentions several techniques used to address data bias during preprocessing of the deep learning pipeline. 

One of the techniques mentioned is stratified sampling, which is used to divide the datasets into three exclusive groups: 80% for training, 10% for validation, and 10% for testing. This ensures that the class distribution is maintained in each group.

Another technique used is data augmentation, which is employed to enhance the datasets and attain data diversity. This includes two random mutations: (a) a random spectrogram mixup, and (b) a random tanh distortion. Additionally, separate random data augmentation techniques are used to address the issue of a long-tailed distribution of the data for rare and endangered bird species. These techniques include (c) adding background noise and (d) random clipping and splicing.

There is no mention of oversampling or undersampling in the provided context. However, the use of data augmentation techniques can be seen as a way to artificially increase the size of the minority class, which is similar to oversampling.

It can be inferred that diverse data collection is also used, as files from "BirdsOnly" are incorporated for all bird audio recordings. This helps to increase the diversity of the dataset.

In summary, the techniques used to address data bias during preprocessing of the deep learning pipeline include stratified sampling, data augmentation (random spectrogram mixup, random tanh distortion, adding background noise, and random clipping and splicing), and diverse data collection.