Based on the provided context, it appears that the authors are using a simple augmentation strategy to address data bias during preprocessing. Specifically, they are flipping the patches horizontally and vertically with a 50% probability. This technique is a form of data augmentation, which can help to increase the diversity of the training data and reduce overfitting.

However, it does not seem that the authors are using techniques such as stratified splitting, oversampling, or undersampling to address data bias. There is no mention of these techniques in the provided context.

It's also worth noting that the authors are using a non-publicly available dataset, which may have its own biases and limitations. Without more information about the dataset, it's difficult to say whether the authors are taking steps to address data bias at the data collection phase.

In summary, the authors are using a simple data augmentation technique to address data bias, but it's unclear whether they are using other techniques such as stratified splitting, oversampling, or undersampling.