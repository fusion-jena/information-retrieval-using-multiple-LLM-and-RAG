The strategy implemented to monitor the model performance during training is not explicitly mentioned in the provided context. However, it can be inferred that the authors used a grid search to identify the optimal set of hyperparameters, which suggests that they might have used a performance metric such as Mean Squared Error (MSE) to evaluate the model's performance during training. Additionally, the authors divided their data into a training set (80% of the data) and a test set (20% of the data) to assess the model's ability to generalize to new, unseen data accurately. This implies that they might have used a cross-validation strategy to monitor the model's performance during training, but this is not explicitly stated.