To ensure the generalizability of the deep learning model, IUC-NN, several measures were taken. Firstly, the data set was randomly split into a training set (90% of the entries) and a test set (10%) to evaluate the model's performance on unseen data. Additionally, 20% of the training set was used for validation. This splitting of the data helps to prevent overfitting and ensures that the model is not biased towards the training data.

Furthermore, cross-validation was performed by shifting the validation set 5 times to quantify the average validation cross-entropy loss and accuracy. This technique helps to evaluate the model's performance on different subsets of the data and provides a more robust estimate of its generalizability.

However, it is not explicitly mentioned whether the splitting of the data was stratified or not. Stratified splitting ensures that the class distribution is maintained in both the training and test sets, which is important when dealing with imbalanced datasets. 

It is also not mentioned whether the dataset is diverse or not. A diverse dataset with a wide range of species and occurrence records would help to ensure the generalizability of the model. However, the use of different groups of features, such as geographic, climatic, biome, and anthropogenic, might help to capture different aspects of the data and improve the model's generalizability.