The provided context does not specifically mention the criteria used to split the data for deep learning model training. However, it does discuss cross-validation, which is a method for evaluating the performance of a machine learning model. In cross-validation, the dataset is split into K equally-sized parts called folds. In each iteration, (K-1) folds are used for training, and the remaining fold is used for testing. 

The context also mentions stratified cross-validation, which is a variant of cross-validation where each fold contains a balanced number of instances for each class. This is used to address class imbalance issues in the dataset.

However, it does not provide information on how to split the data into training, testing, and validation sets for deep learning model training. Typically, the data is split into three parts: training set (used to train the model), testing set (used to evaluate the model's performance), and validation set (used to tune the model's hyperparameters). The criteria for splitting the data into these sets can vary depending on the specific problem and dataset.