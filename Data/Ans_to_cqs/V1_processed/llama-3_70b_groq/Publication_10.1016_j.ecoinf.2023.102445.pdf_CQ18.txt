The strategy implemented to monitor the model performance during training is not explicitly mentioned in the provided context. However, it can be inferred that the model performance is evaluated using certain evaluation indices such as average accuracy, mAP50-95, and time metric. These indices are calculated using formulas (8)-(11) provided in the context. 

The average accuracy is calculated at an IoU threshold of 0.5, and mAP50-95 represents the average accuracy across all classes at different IoU thresholds, spanning from 0.5 to 0.95 in increments of 0.05. The time metric is calculated by summing the runtimes for the preprocessing, network inference, and post-processing stages.

Although the strategy for monitoring model performance during training is not explicitly stated, it can be inferred that the model performance is evaluated using these indices, which provide insights into the model's accuracy and speed.