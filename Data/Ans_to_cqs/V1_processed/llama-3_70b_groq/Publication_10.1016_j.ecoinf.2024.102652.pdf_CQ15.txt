According to the provided context, the optimization technique applied in the deep learning pipeline is Adam processing. This is mentioned in the training process section, which states that "The optimizer used Adam processing, and the learning ratio varied with group based on the cosine functionâ€™s law, often in the range between 0.0 and 1.0." There is no mention of other optimization techniques such as SGD in the provided context.