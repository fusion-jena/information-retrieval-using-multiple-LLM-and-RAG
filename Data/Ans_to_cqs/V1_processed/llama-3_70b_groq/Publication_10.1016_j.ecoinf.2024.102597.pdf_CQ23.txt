The provided context does not mention the use of deep learning models. In fact, it is mentioned that "the limited number of samples was not conducive to deep learning". Therefore, it is not possible to determine what measures were taken to ensure the generalizability of a deep learning model, as no deep learning model was used in this study.

However, the context does mention the use of ensemble learning (EL) models, including Random Forest (RF), Gradient Boosting Decision Tree (GBDT), LightGBM, XGBoost, and CatBoost. The performance of these models was evaluated using the same dataset, and hyperparameter optimization was performed using both random grid search and Bayesian optimization methods. 

It is not explicitly stated what measures were taken to ensure the generalizability of these EL models. However, the use of hyperparameter optimization and evaluation on the same dataset may suggest that some form of cross-validation was used, but this is not explicitly stated.