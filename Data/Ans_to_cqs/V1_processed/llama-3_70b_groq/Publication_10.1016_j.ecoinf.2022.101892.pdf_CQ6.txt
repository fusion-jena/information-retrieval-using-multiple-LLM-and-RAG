Based on the provided context, it appears that the preprocessing steps involved before training a deep learning model include downsampling the image resolution to 224 Ã— 224 pixels and aggressive data augmentation. The data augmentation involves randomly applying horizontal flipping to the training sets. There is no mention of normalization, scaling, or cleaning as preprocessing steps. However, it is worth noting that the models were pre-trained on the ImageNet dataset and then fine-tuned on the PAD Full and PAD Lite datasets, which may have involved some preprocessing steps, but these are not explicitly mentioned.