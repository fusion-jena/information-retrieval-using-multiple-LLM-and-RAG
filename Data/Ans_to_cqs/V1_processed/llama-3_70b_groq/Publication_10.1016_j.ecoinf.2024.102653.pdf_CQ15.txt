According to the provided context, the optimization technique applied in the deep learning pipeline is ADAM (Kingma and Ba, 2017). This is mentioned in Table 1, which lists the hyperparameters utilized for training the Recurrent Neural Network model. The optimizer used is specified as ADAM, with a learning rate of 0.003.