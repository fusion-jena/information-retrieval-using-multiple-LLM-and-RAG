The provided context does not explicitly mention the postprocessing steps involved after the model training. It discusses the performance of the models trained with different annotation sets, the importance of clear task description and task difficulty estimation in an annotation campaign, and the consistent hyperparameters used across all training instances. 

However, it does mention the evaluation metrics used, which are AUC (Area Under the Curve) and mAP (mean Average Precision). These metrics are used to evaluate the performance of the models trained with different annotation sets. 

There is no mention of postprocessing steps such as saliency maps, confusion matrix, or other metrics calculation. Therefore, I don't know the specific postprocessing steps involved after the model training.