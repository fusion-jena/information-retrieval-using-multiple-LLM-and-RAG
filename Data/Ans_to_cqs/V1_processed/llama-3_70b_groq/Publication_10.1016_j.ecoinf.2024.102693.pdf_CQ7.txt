Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the hyper-parameters used for training different models, their performance on the IP102 dataset, and the proposed ensemble methods. 

However, it is common practice in deep learning to split the data into training, validation, and testing sets. The typical split ratio is 80% for training, 10% for validation, and 10% for testing. The training set is used to train the model, the validation set is used to tune the hyper-parameters, and the testing set is used to evaluate the model's performance. 

But, without explicit information, I cannot provide the specific criteria used in this particular context.