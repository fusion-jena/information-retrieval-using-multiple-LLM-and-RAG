According to the provided context, the optimization technique applied in the deep learning pipeline is Adam. This is mentioned in the description of the MCD network architecture, which states that "the optimizer is Adam and the starting learning rate is set to 0.001." There is no mention of other optimization techniques such as SGD being used in the pipeline.