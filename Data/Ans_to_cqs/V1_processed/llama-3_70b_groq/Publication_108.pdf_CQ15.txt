Based on the provided context, it is mentioned in reference 31 that "Adam: A Method for Stochastic Optimization" is used. This suggests that the Adam optimization technique is applied in the deep learning pipeline. There is no mention of SGD (Stochastic Gradient Descent) or any other optimization techniques in the provided context.