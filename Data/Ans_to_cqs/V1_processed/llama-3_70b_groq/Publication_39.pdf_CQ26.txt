The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention that the annotated dataset is split randomly into a train set, validation set, and test set, with 20% of the video clips of each class in the test set, 20% of the remaining clips in each class in the validation set, and the remaining clips in the training set. This suggests that stratified splitting is used to ensure that each class is represented proportionally in the train, validation, and test sets.

There is no mention of oversampling, undersampling, or diverse data collection techniques being used to address data bias. The context primarily focuses on data augmentation techniques, such as horizontal flip, adding/subtracting intensity, Gaussian blur, additive Gaussian noise, and fog simulation, to prevent overfitting and improve generalization.