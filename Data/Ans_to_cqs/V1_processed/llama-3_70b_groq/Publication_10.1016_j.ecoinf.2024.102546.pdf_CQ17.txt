Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context discusses dataset curation, data augmentation techniques such as jitter, mosaic, random crop, and scale augmentation, and model training details like batch size and number of epochs. However, it does not provide information about regularization methods like dropout or L2 regularization.

Therefore, I don't know the answer to this query based on the provided context.