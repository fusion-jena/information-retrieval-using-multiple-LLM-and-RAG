The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context discusses the importance of identifying an optimal number of training epochs to avoid underfitting or overfitting, and the use of AutoML to automate the process of selecting hyperparameters, including the number of epochs. It also mentions the use of residual networks (ResNet) to allow for deeper models, but it does not discuss regularization methods.

Therefore, I don't know the specific regularization methods used to prevent overfitting in the deep learning pipeline based on the provided context.