The context does not explicitly mention the use of a random seed value to handle randomness in the deep learning pipeline. However, it does mention that each network was trained and executed three times, each time with a different (random) initialization of the trainable parameters and with a different data fold. This suggests that the authors are using a form of randomization to introduce variability in the training process, which can help to reduce overfitting and improve the robustness of the models.

Additionally, the use of data augmentation techniques such as 90Â° rotation and vertical and horizontal flips can also be seen as a way to introduce randomness in the training data, which can help to improve the model's ability to generalize to new, unseen data.

It is worth noting that the context does not provide explicit information on how the random initialization of the trainable parameters is implemented, or whether a fixed random seed value is used to ensure reproducibility.