Based on the provided context, it is mentioned that "learning and L2 regularization" are used, but it does not explicitly state that L2 regularization is used to prevent overfitting. However, it is a common practice in deep learning to use L2 regularization as a regularization method to prevent overfitting.

Additionally, the context does not mention dropout as a regularization method used to prevent overfitting. It only discusses the use of Vision Transformers, feature normalization, and the need to enhance the dataset to generate more data to solve the overfitting issue.

Therefore, based on the provided context, the only regularization method mentioned is L2 regularization, but it is not explicitly stated that it is used to prevent overfitting.