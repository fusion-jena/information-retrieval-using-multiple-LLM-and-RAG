Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the Mask R-CNN model, its architecture, and the training process, but it does not provide information on data splitting criteria.

However, in general, common practices for splitting data in deep learning include:

1. Random Split: Dividing the data randomly into training, validation, and testing sets, usually in a ratio of 80:10:10 or 70:15:15.
2. Stratified Split: Splitting the data in a way that maintains the same proportion of classes in each set as in the original dataset.
3. K-Fold Cross-Validation: Dividing the data into k folds, using k-1 folds for training and one fold for validation, and repeating this process k times.

Without further information, it is impossible to determine the specific criteria used in this particular context.