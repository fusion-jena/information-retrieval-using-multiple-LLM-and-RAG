The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does mention that a five-fold cross-validation was conducted to explore the patterns between the outputs of the base learners and the target. This suggests that the data was split into folds for cross-validation, but the specific criteria or proportions for splitting the data into training, testing, and validation sets are not mentioned.

In general, the criteria for splitting data into training, testing, and validation sets can vary depending on the specific problem and dataset. Common practices include splitting the data into 60-80% for training, 15-20% for validation, and 5-20% for testing. However, this information is not provided in the given context.

Therefore, I don't know the specific criteria used to split the data for deep learning model training in this particular study.