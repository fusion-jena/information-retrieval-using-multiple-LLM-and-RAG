The provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context discusses the differences between XGBoost and deep learning models, their computational requirements, interpretability, and performance on small datasets. However, it does not provide information on how to split the data for deep learning model training.

The context does mention that for XGBoost, the training and validation sets were divided in an 80:20 ratio, but this is specific to XGBoost and not deep learning models. Therefore, I don't know the answer to this question based on the provided context.