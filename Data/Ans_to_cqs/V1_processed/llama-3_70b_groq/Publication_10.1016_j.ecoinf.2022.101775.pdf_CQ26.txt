The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention that the data sets with removed data are kept for use with all methods to avoid bias generated by random data removal. This suggests that the authors are aware of the potential issue of bias and are taking steps to mitigate it, but the specific techniques used are not mentioned.

The context focuses more on the use of matrix factorization and deep learning techniques, such as Deep Matrix Factorization (DMF), to recover missing information and adapt to data generated by Wireless Sensor Networks (WSNs). It also discusses the use of embedding layers in deep neural networks for natural language processing and collaborative filtering problems.

Therefore, I don't know the specific techniques used to address data bias during preprocessing in this context, as it is not mentioned.