The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does mention the use of 10-fold cross-validation in Table 6, which implies that the data is split into 10 folds, with 9 folds used for training and 1 fold used for validation in each iteration.

In general, the common practice in deep learning is to split the data into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune the hyperparameters and evaluate the model's performance during training, and the testing set is used to evaluate the model's performance on unseen data.

The criteria for splitting the data can vary depending on the problem and the dataset. Some common methods include:

* Random splitting: The data is randomly divided into training, validation, and testing sets.
* Stratified splitting: The data is divided into training, validation, and testing sets while maintaining the same proportion of classes in each set.
* Time-based splitting: The data is divided into training, validation, and testing sets based on time, with the most recent data used for testing.

Without more information, it is difficult to determine the specific criteria used to split the data in this particular context.