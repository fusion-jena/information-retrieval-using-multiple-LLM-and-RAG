The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does mention that in section 4.2.3, the data was divided into 4 non-overlapping subsites to maximize the independence between the training and testing sets. This suggests that the data was split in a way that ensures the training and testing sets are independent and do not overlap. 

Additionally, the context mentions that the common practice of randomly dividing a single data set into training and testing sets may lead to overestimating practical performance. This implies that random splitting is a common approach, but it may not be the best approach in all cases.

In general, the criteria for splitting data into training, testing, and validation sets can vary depending on the specific problem and dataset. Common approaches include random splitting, stratified splitting (to ensure class balance), and time-based splitting (e.g., using older data for training and newer data for testing). However, the specific criteria used in this case are not explicitly stated in the provided context.