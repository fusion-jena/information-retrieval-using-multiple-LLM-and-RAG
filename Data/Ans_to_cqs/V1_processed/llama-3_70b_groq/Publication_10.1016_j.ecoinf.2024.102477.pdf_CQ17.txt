The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention regularization in the context of Support Vector Regression (SVR). In SVR, the regularization parameter C is used to control model complexity and prevent overfitting. 

Although the context does not provide information on regularization methods specific to deep learning, it is worth noting that dropout and L2 regularization are commonly used techniques to prevent overfitting in deep learning models. Dropout randomly drops out neurons during training to prevent the model from relying too heavily on any single neuron, while L2 regularization adds a penalty term to the loss function to discourage large weights.

It is possible that the SLSTM and SGRU models mentioned in the context may use these or other regularization methods, but this information is not provided.