Based on the provided context, the criteria used to split the data for deep learning model training is stratified sampling. The dataset was randomly divided into four mutually exclusive folds through stratified sampling. This method ensures that the class distribution is maintained in each fold, which is essential when dealing with imbalanced datasets.

In this specific study, the data was split into four folds, where each fold served as the validation set, and the remaining three folds constituted the training set for model training. This process was iterated four times with distinct validation folds, resulting in four different prediction arrays. These arrays were then consolidated to provide predictions for the entire dataset.

It's worth noting that the context does not explicitly mention the splitting criteria for the test set. However, it can be inferred that the test set is not used in this study, as the focus is on the validation phase using the K-fold cross-validation technique.