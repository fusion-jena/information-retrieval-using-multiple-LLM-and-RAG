Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The context primarily focuses on the application of deep learning models to analyze land use and land cover changes (LUCC) and does not delve into the specifics of handling randomness in the deep learning pipeline.

However, it is worth noting that the context does mention batch normalization, which is a technique used to normalize the input data and reduce the impact of internal covariate shift during training. This technique can help reduce the effect of randomness in the input data, but it is not directly related to handling randomness in the deep learning pipeline.

In general, strategies to handle randomness in deep learning pipelines may include setting a random seed value, using techniques such as dropout and data augmentation, and employing ensemble methods. However, these strategies are not mentioned in the provided context.