Based on the provided context, it appears that the authors employed stratified sampling to divide the feature set into four mutually exclusive folds for K-fold cross-validation. This approach helps to maintain the same class distribution in each fold, which can help mitigate the effects of randomness in the data.

Additionally, the authors applied random under-sampling (RUS) to the training set to address imbalances in the data. This technique involves randomly removing samples from the majority class to balance the class distribution.

However, there is no explicit mention of strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. It is possible that the authors may have used a specific random seed value or other techniques to ensure reproducibility, but this information is not provided in the given context.