The measures taken to ensure the generalizability of the deep learning model include cross-validation, data augmentation, and stratified splitting. 

The authors employed a cross-validation approach, where the dataset was split into three regions (A, B, and C), and each region was used as a testing region once. The remaining two regions were used for training and validation, with 70% of the samples used for training and 30% for validation. This approach helps to ensure that the model is not overfitting to a specific region and can generalize well to new, unseen data.

Data augmentation techniques were also applied to increase the diversity of the training dataset. This helps to prevent overfitting and improve the model's ability to generalize to new data. However, the specific data augmentation techniques used are not mentioned in the provided context.

Additionally, the authors used a stratified splitting approach, where the samples were split into training, validation, and testing sets while maintaining the same proportion of classes in each set. This helps to ensure that the model is not biased towards a specific class and can generalize well to new data.

Overall, the authors have taken several measures to ensure the generalizability of the deep learning model, including cross-validation, data augmentation, and stratified splitting.