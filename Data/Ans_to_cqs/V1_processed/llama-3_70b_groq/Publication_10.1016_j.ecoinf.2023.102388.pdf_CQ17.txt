Based on the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are batch-norm, weight decay, and dropout. These methods are mentioned in the context as techniques used to reduce the overfitting level in the no-overfitting setting. Specifically, batch-norm and dropout are mentioned as techniques used to prevent overfitting, and weight decay is mentioned as a regularization method. Additionally, the context cites a survey on regularization methods for convolutional neural networks, which suggests that there are other regularization methods available, but it does not specify what they are.