The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention data augmentation as a technique used to artificially increase the size of the dataset, which can help reduce the risk of overfitting and make models more reliable on a wider range of input data. This can be seen as a way to address data bias, but it is not one of the specific techniques mentioned in the query (Stratified splitting, oversampling, undersampling, Diverse data collection). 

The context does not provide information on how data bias is addressed during preprocessing. It focuses more on the training parameters, model architecture, and data augmentation techniques used. Therefore, I don't know the specific techniques used to address data bias during preprocessing in this particular pipeline.