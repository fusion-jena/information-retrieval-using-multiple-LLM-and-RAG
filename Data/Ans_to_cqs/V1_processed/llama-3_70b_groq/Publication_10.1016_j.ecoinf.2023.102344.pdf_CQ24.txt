Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. The context primarily focuses on the architecture and training of various deep learning models, including EfficientNet-B0, ResNet101, MobileNetV2, and InceptionV3, as well as their applications in image analysis and other fields.

However, it is worth noting that the context does mention the use of an "every-epoch shuffle technique" in the training configuration, which may be related to handling randomness in the data. Additionally, the use of stochastic gradient descent (SGDM) as the optimization algorithm may also involve some form of randomness. Nevertheless, the context does not provide explicit information on how randomness is handled in the deep learning pipeline.

Therefore, I don't know the specific strategies employed to handle randomness in the deep learning pipeline, as this information is not provided in the given context.