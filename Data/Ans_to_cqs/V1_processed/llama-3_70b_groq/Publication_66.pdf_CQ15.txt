The provided context does not explicitly mention the optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. However, it does mention that a "random hyperparameter search was conducted to determine the optimum model structure." This suggests that the authors used a hyperparameter tuning approach to find the best combination of hyperparameters for their deep learning model, but the specific optimization technique used is not specified.