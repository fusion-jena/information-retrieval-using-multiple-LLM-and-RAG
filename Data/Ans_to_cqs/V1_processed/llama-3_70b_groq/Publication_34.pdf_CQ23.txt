To ensure the generalizability of the deep learning model, the authors took several measures. Firstly, they worked with a high number of randomly chosen species to avoid bias towards a particular category of species. From the initial 7626 species, they selected species with more than 300 observations and then randomly selected subsets of 1000, 200, and 50 species to constitute ensembles E1000, E200, and E50, respectively. This approach helped to increase the diversity of the dataset.

Additionally, the authors used different versions of the CNN model (CNN50, CNN200, CNN1000) to evaluate its performance on different scales. This approach can be seen as a form of cross-validation, where the model is tested on different subsets of the data to ensure its generalizability.

However, it is not explicitly mentioned in the provided context whether stratified splitting or other cross-validation techniques were used. Therefore, it cannot be confirmed whether these specific measures were taken to ensure the generalizability of the model.

Overall, the authors' approach to working with a large and diverse dataset, as well as evaluating the model on different scales, contributes to the generalizability of the deep learning model.