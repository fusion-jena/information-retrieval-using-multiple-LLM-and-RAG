The strategy implemented to monitor the model performance during training is the use of a validation set. The validation set provides an unbiased evaluation of the model fit on the training set while tuning model hyperparameters. This helps to avoid overfitting, where the model perfectly fits the training data but fails to fit the test or validation data. Additionally, k-fold cross-validation is used to further avoid overfitting, where the training set is generated with different combinations of k groups as the training and validation sets. The model is then fit by using (k-1) folds and evaluated using the remaining kth fold, and the process is repeated until every k-fold is used as the test set. Furthermore, the performance of the trained models is evaluated using three standard metrics: true positive (TP), true negative (TN), false positive (FP), and false negative (FN).