To ensure the generalizability of the deep learning model, several measures were taken. Firstly, a diverse dataset was created by introducing variations in color through random saturation adjustments during the augmentation phase. This increased the number of outputs per example to two, contributing to a more comprehensive and robust training dataset.

Additionally, the dataset was split into three sets: training, validation, and testing. The training set, comprising 82% of the data, was used to train the model and adjust its parameters. The validation set, consisting of 13% of the data, was utilized during training to fine-tune hyperparameters and assess the model's performance on unseen data, helping to prevent overfitting and ensuring generalization. The testing set, which included 5% of the data, served as an independent evaluation of the model's performance on completely unseen data, providing a reliable measure of its real-world effectiveness and ability to generalize.

However, there is no mention of cross-validation or stratified splitting in the provided context.