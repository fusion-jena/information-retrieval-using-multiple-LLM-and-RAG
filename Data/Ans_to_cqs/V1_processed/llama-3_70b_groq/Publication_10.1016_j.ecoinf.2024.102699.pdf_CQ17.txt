The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention early stopping as a method to prevent overfitting. Early stopping is a technique where the training process is stopped when the model's performance on the validation set starts to degrade, indicating that the model is overfitting to the training data. 

Additionally, the context mentions the use of focal loss and scaled focal loss to alleviate the effects of class imbalance, which can also help prevent overfitting to some extent. However, it does not provide information on other regularization methods that might be used.