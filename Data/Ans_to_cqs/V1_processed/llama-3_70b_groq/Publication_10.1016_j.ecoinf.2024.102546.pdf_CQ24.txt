Based on the provided context, I couldn't find a direct answer to the query about strategies employed to handle randomness in the deep learning pipeline, such as random seed value. The context primarily focuses on weed datasets, domain randomization, and deep learning applications in agriculture, but it doesn't explicitly discuss handling randomness in the deep learning pipeline.

However, I can provide some general information on handling randomness in deep learning. Randomness can be introduced in various stages of the deep learning pipeline, such as data augmentation, initialization of model weights, and random shuffling of training data. To handle this randomness, strategies like fixing the random seed, using reproducible random number generators, and employing techniques like dropout and batch normalization can be employed. Additionally, techniques like ensemble methods and cross-validation can help reduce the impact of randomness on model performance.

But, I must emphasize that these are general strategies and not specifically mentioned in the provided context. If you're looking for specific answers related to the context, I'm afraid I don't know the answer.