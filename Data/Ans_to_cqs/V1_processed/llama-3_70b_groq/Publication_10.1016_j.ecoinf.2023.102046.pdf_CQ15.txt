According to the provided context, the optimization techniques applied in the deep learning pipeline are Adam and AdamW. Specifically, AdamW was used as the optimizer for Hugging Face models, which is the default optimizer in the transformers library by Hugging-Face. For Inception-V3, Adam was used as the optimizer, which was the optimizer used in previous work, and AdamW is not available in Keras.