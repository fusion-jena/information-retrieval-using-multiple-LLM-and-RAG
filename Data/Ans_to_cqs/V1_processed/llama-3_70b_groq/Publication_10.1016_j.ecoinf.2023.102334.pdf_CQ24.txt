Based on the provided context, it appears that the authors employed several strategies to handle randomness in the deep learning pipeline. 

Firstly, the authors randomly generated the image data in an 8:2 ratio for the training and test sets. This suggests that they used random sampling to split the data into training and testing sets.

Secondly, the authors used data augmentation techniques such as random cropping, vertical flipping, and horizontal flipping to enlarge the training dataset and avoid overfitting. This implies that they introduced randomness in the data augmentation process to increase the diversity of the training data.

However, the context does not explicitly mention the use of a random seed value to handle randomness in the deep learning pipeline. It is possible that the authors used a fixed random seed value to ensure reproducibility of the results, but this is not explicitly stated.

In summary, the authors employed random sampling and data augmentation techniques to handle randomness in the deep learning pipeline, but the use of a random seed value is not explicitly mentioned.