The hyperparameters used in the deep learning model are:

* For CNN-BiGRU:
	+ CNN Layers: 2
	+ Filters: 64
	+ Kernel size: [1,4]
	+ BiGRU Layers: 1
	+ BiGRU neurons: 30
	+ Optimizer: Adam
	+ Activation function: 'relu'
	+ Epochs: 43 (or 1000)
	+ Batch size: 32
	+ Learning rate: 0.000455 (or 0.0015)
	+ Dense: 100
* For KELM:
	+ Regularization coefficient: 3E+05 (or 9E+06)
	+ Kernel parameter: 7000 (or 9E+05)
* For RVFL:
	+ Num nodes: 20 (or 50)
	+ Regular para: 0.2 (or 0.9)
	+ Weight random range: [(cid:0) 1,1]
	+ Bias random range: [0,1]
* For CNN-BiRNN:
	+ CNN Layers: 2
	+ Filters: 64
	+ Kernel size: [1,4]
	+ BiRNN Layers: 1
	+ BiRNN neurons: 30
	+ Optimizer: Adam
	+ Activation function: 'relu'
	+ Epochs: 200
	+ Batch size: 32
	+ Learning rate: 0.0002
	+ Dense: 100