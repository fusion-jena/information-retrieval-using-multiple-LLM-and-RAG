The provided context does not explicitly mention how the hyperparameters of the model are optimized. It only mentions the configuration of the optimizer and learning rate used for training the EMViT-Net framework, which is AdamW with a learning rate of 0.002 and a batch size of 32. However, it does not provide information on how these hyperparameters were chosen or optimized. Therefore, it is not possible to determine whether grid search, random search, or any other method was used to optimize the hyperparameters.