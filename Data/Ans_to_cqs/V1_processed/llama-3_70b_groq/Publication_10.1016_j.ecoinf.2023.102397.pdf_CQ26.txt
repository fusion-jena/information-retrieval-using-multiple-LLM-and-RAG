The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on the effects of sample size and network depth on deep learning approaches to species distribution modeling, acoustic indices as proxies for bird diversity, and the importance of evaluating the quality and uncertainty of algorithmic automatizations.

However, it can be inferred that the context acknowledges the importance of addressing biases in data processing and analysis. For instance, it mentions that "new biases may arise depending on the specificities of the choice of the feature extraction" and that "a continuous evaluation of the quality and uncertainty of these processes is paramount."

Unfortunately, the context does not provide specific techniques used to address data bias during preprocessing of the deep learning pipeline, such as stratified splitting, oversampling, undersampling, or diverse data collection. These techniques are commonly used in machine learning and deep learning pipelines to mitigate data bias, but they are not mentioned in the provided context.

Therefore, I don't know the specific techniques used to address data bias during preprocessing of the deep learning pipeline based on the provided context.