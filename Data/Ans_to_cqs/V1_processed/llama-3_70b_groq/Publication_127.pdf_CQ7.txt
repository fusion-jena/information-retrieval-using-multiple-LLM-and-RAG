Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context appears to be a list of references and a table describing different deep learning architectures, along with some information about training methods and hyperparameters. However, it does not provide specific information on how to split the data for training, testing, and validation.

In general, the criteria for splitting data into training, testing, and validation sets can vary depending on the specific problem, dataset, and model. Common practices include:

* Random splitting: dividing the data randomly into training, testing, and validation sets
* Stratified splitting: dividing the data into sets while maintaining the same class distribution as the original dataset
* Time-based splitting: dividing the data into sets based on time, such as using older data for training and newer data for testing
* K-fold cross-validation: dividing the data into k sets and using each set as a validation set once

Without more specific information, it is difficult to provide a definitive answer to this question.