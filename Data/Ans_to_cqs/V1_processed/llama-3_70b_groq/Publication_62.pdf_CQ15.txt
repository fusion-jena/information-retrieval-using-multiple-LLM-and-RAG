Unfortunately, the provided context does not mention specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on the architecture of the convolutional neural networks (CNNs) and their applications to digitized natural history collections. It provides details on the layers and tensor/vector shapes used in the CNNs, but it does not discuss optimization techniques. Therefore, I don't know the answer to this query based on the provided context.