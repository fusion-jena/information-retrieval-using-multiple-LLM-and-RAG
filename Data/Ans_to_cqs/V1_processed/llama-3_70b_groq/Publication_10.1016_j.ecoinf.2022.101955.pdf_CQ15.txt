The provided context does not mention specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context only discusses the use of a backpropagation learning algorithm during the training phase of the MLP ANN model, but it does not provide information about the optimization techniques used to update the model's parameters. Therefore, I don't know the answer to this question based on the provided context.