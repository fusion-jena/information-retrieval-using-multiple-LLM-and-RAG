Based on the provided context, there is no explicit mention of postprocessing steps involved after the model training, such as saliency maps, metrics calculation, or confusion matrix. The context primarily focuses on the active learning pipeline, model training, and evaluation.

However, it can be inferred that the model's performance is evaluated based on its overall accuracy, which is mentioned to be 93.2% after the first 30,000 active queries. Additionally, the context mentions that more detailed results are available in Table S3, but the contents of this table are not provided.

Therefore, it can be concluded that the postprocessing steps involved after the model training are not explicitly mentioned in the provided context.