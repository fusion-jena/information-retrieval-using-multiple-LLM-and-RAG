The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does mention some techniques used to prevent overfitting, which is related to handling randomness.

One technique mentioned is the use of batch normalization (BNorm) layers behind the 22 convolutional layers to prevent overfitting. This is done to ensure that the model generalizes well to both "known" and "unknown" datasets, rather than maximizing performance on the "known" datasets.

Another technique mentioned is setting a large batch size (equal to 128) to limit the number of images trained in each iteration. This can help reduce the impact of randomness in the training process.

While these techniques are not directly related to setting a random seed value, they do help mitigate the effects of randomness in the deep learning pipeline. However, the context does not provide a specific answer to the question of how to handle randomness through strategies like setting a random seed value.