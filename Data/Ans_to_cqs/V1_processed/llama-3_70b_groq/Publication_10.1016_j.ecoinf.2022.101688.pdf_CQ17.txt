The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily focuses on the use of pre-trained CNN feature extractors, transfer learning, and fine-tuning for acoustic classification tasks. It discusses the advantages of using pre-trained models, including reduced complexity, less hyperparameter tuning, and accessibility to practitioners.

However, the context does mention overfitting as a potential issue when training CNNs on acoustic datasets with limited examples. It highlights the importance of obtaining additional data to prevent overfitting, but it does not provide specific regularization methods to address this issue.

Therefore, I don't know the answer to this specific query based on the provided context.