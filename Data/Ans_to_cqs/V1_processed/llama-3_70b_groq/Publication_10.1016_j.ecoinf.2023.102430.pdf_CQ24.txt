Based on the provided context, it appears that the authors employed a strategy of repeating the training-testing process 10 times for each algorithm, using the same training and testing picture subsets. This is referred to as "pseudo-replicate runs". This approach helps to gauge performance consistency and accounts for some of the randomness in the deep learning pipeline.

However, there is no explicit mention of using a specific random seed value or any other strategy to handle randomness in the deep learning pipeline. It is possible that the authors relied on the default settings of the stochastic gradient descent with momentum optimizer in MATLAB, but this is not explicitly stated.

Therefore, I cannot provide a definitive answer to the query, as the context does not provide sufficient information on the strategies employed to handle randomness in the deep learning pipeline.