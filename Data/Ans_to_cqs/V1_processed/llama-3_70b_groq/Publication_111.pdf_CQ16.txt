According to the provided context, the criteria used to determine when training is complete is the early stopping strategy. This strategy is used to cease training when the generalization performance starts to degrade for a number of epochs. In other words, the training process is stopped when the validation loss starts to increase or plateaus, indicating that the model is no longer improving its performance on the validation set.

This is mentioned in the context as: "one possible solution to the DL-based modelâ€™s over/underfitting concerns is to apply the early stopping strategy [44], which is used to cease training when generalisation performance starts to degrade for a number of epochs."

Therefore, the criteria used to determine when training is complete is the degradation of generalization performance on the validation set, which is typically measured by the validation loss.