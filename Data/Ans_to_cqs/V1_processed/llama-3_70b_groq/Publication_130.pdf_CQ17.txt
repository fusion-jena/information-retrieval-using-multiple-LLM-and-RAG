Based on the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are:

1. Dropout: One dropout layer was added just before the first dense layer to limit overfitting by randomly ignoring units of the CNN (i.e., neurons) during the training process.

No other regularization methods, such as L2 regularization, are mentioned in the provided context. It is also worth noting that the authors decided not to freeze any of the layers of the network, which is another approach to prevent overfitting. Additionally, the authors used data augmentation and oversampling to increase the size of the training dataset, which can also help to prevent overfitting.