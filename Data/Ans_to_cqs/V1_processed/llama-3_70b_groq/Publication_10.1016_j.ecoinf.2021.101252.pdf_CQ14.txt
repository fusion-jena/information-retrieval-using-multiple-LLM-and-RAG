The hyperparameters of the model are optimized through a random search process. According to the provided context, the AutoML procedure starts by generating a set of candidate models with architectures and hyperparameters (e.g., number of layers, learning rate) selected at random from a prespecified range of values. Each candidate model is then trained using a small subset of the data during a small number of epochs, and their performance is compared using a left-out validation data set. The selected candidate model is then trained on the full training data. This process implies that the hyperparameters are optimized through a random search, where multiple combinations of hyperparameters are tried, and the best-performing model is selected. There is no mention of a grid search or any other optimization method in the provided context.