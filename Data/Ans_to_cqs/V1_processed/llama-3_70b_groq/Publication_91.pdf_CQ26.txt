The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention that the dataset was split into three sets for training, validation, and testing in the proportions 80:10:10, which is a common practice to prevent overfitting. Additionally, the context mentions that the images in the training set were augmented in various ways, such as flipping, adjusting brightness, saturation, contrast, and hue, to gain a more robust and better generalizing classifier. This augmentation can be seen as a way to increase diversity in the data and reduce bias. However, it does not explicitly mention stratified splitting, oversampling, or undersampling. Therefore, it cannot be concluded that these techniques were used to address data bias.