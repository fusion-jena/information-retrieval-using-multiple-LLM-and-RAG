Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context primarily focuses on camera trap images, ecological surveys, and deep learning models for image classification. It discusses image augmentation techniques such as shifts, horizontal flips, rotations, zooms, and shears, but it does not mention specific regularization methods like dropout or L2 regularization. 

However, it is worth noting that the context does mention the use of a one-cycle learning rate policy with a minimum learning rate of 0.000001 and a maximum learning rate of 0.001, which can help prevent overfitting to some extent. Additionally, the context cites a paper on Adam optimization, which is a stochastic optimization method that can help with convergence and prevent overfitting. 

In summary, the provided context does not explicitly mention regularization methods like dropout or L2 regularization, but it does discuss other techniques that can help prevent overfitting.