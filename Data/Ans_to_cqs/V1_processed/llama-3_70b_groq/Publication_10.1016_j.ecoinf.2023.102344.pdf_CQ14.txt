The provided context does not explicitly mention how the hyperparameters of the model are optimized. It only mentions that the pre-trained models under Approach 1 converged the training after 1000 epochs with stochastic gradient descent with momentum (SGDM) as the optimization algorithm. However, it does not provide information on how the hyperparameters were tuned or optimized. 

It is possible that the authors may have used a specific method for hyperparameter tuning, such as grid search or random search, but this information is not provided in the given context. Therefore, I don't know the answer to this query based on the provided information.