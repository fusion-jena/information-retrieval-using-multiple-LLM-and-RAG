The provided context does not specifically mention regularization methods used to prevent overfitting in deep learning pipelines, such as dropout or L2 regularization. However, it does mention some techniques used to prevent overfitting in machine learning models, particularly in gradient boosting models.

In the context, it is mentioned that subsamples reduce overfitting, and min_child_samples control local pattern sensitivity. Additionally, reg_lambda is used to prevent overfitting. These techniques are specific to gradient boosting models and are used to control the complexity of the model and prevent overfitting.

It does not provide information on regularization methods used in deep learning pipelines. Therefore, I do not know the answer to this specific question based on the provided context.