The criteria used to split the data for deep learning model training are not explicitly mentioned in the context for deep learning models. However, the context does provide information on the data splitting approaches used for machine learning models.

Two data splitting approaches are mentioned: randomly splitting individual observations and splitting based on the year of capture (RY approach). The RY approach groups individual observations by year of capture and randomly selects years for inclusion in the train and test datasets. This approach may introduce systematic differences between the test and train datasets but ensures that the model is tested on previously unseen combinations of explanatory variables.

Additionally, the context mentions a three-part split, where the validation set is used to tweak model parameters and feature engineering. The final test set is used to evaluate the best model only once.

It is not clear if these approaches are applicable to deep learning models, as the context primarily focuses on machine learning models. Therefore, I do not know the specific criteria used to split data for deep learning model training based on the provided context.