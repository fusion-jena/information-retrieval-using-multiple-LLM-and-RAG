To ensure the generalizability of the deep learning model, several measures were taken. Firstly, cross-validation was used with 5 folds, which helps to evaluate the model's performance on unseen data and reduces the risk of overfitting. Additionally, data augmentation techniques were applied during training, which artificially increases the size of the dataset by creating new samples from the existing ones. This helps the model to generalize better and reduces the risk of overfitting, especially when dealing with limited data. Furthermore, the models were trained with the same parameters, which helps to reduce the variability in the results and ensures that the models are not overly dependent on the specific training data.