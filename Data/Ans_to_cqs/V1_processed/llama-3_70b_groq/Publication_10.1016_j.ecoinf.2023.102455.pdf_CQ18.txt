Based on the provided context, it appears that the strategy implemented to monitor the model performance during training is the use of evaluation metrics such as the Correlation Coefficient (R), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). These metrics are commonly used to evaluate the performance of machine learning models, particularly in the context of time series forecasting and regression tasks.

The context provides tables with values for these metrics during both training and testing phases, suggesting that the model's performance is being monitored and evaluated during training using these metrics. This allows the model to be fine-tuned and adjusted to improve its performance.

Additionally, the context mentions "Machine learning tuning" which further supports the idea that the model's performance is being monitored and adjusted during training.

However, it is not explicitly stated what specific strategy is being used to monitor the model performance during training, such as early stopping, learning rate scheduling, or batch normalization.