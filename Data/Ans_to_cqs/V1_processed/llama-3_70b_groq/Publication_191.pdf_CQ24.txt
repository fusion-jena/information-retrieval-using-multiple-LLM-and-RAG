Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. The context primarily focuses on deep learning concepts, plant identification, and dataset comparisons.

However, it is worth noting that the context does mention "randomly subsample some of the feature maps/channels in each layer" in Section 4, which implies the use of randomness in the feature visualization process. But this is not directly related to handling randomness in the deep learning pipeline.

In general, handling randomness in deep learning pipelines often involves techniques such as:

1. Fixing random seeds for reproducibility
2. Using techniques like dropout and batch normalization to reduce overfitting
3. Ensemble methods to average out random variations
4. Hyperparameter tuning to find optimal settings

But these strategies are not explicitly mentioned in the provided context. Therefore, I cannot provide a more specific answer based on the given information.