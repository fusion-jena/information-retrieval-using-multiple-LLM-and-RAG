The provided context does not explicitly mention the specific hardware resources used for training the deep learning model, such as GPUs or TPUs. However, it does mention that feature extraction of the fixed inception layers was completed in 1 hour and 26 minutes on 15 CPUs, and training of the new layers was completed in 27 minutes on a single CPU. Additionally, model evaluation on the 70 test videos was completed in 4 hours and 38 minutes on 30 CPUs.

It can be inferred that CPUs were used for training and evaluation, but there is no mention of GPUs or TPUs. It is also mentioned that Google Cloud DataFlow was used to extract feature vectors for the frozen layers in parallel, which suggests that cloud computing resources were utilized. However, the specific hardware resources used in the cloud environment are not specified.