The provided context does not mention any specific data augmentation techniques applied in the deep learning pipeline, such as flipping, rotating, or scaling. The context primarily focuses on the audio data processing steps, including converting the audio to a monophonic channel, resampling at 16 kHz, extracting spectrograms, and calculating Mel spectrograms. It also discusses the use of YAMNet, a pre-trained deep neural network, for extracting embeddings. However, it does not provide information on data augmentation techniques used in the pipeline. Therefore, I don't know the answer to this query based on the provided context.