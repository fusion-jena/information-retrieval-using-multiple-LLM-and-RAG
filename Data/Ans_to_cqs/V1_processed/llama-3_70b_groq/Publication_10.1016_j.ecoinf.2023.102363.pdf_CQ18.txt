The strategy implemented to monitor the model performance during training is through validation. The models are validated during training by combining the original base model validation set with 100 frames per class from the labelled December 3rd 2019 training set, randomly pooled per experiment. This allows the model's performance to be assessed across both environments simultaneously. Additionally, early stopping is set to deploy if the validation loss does not improve within 10 epochs. This means that the model training will stop if the validation loss does not decrease within 10 epochs, preventing overfitting and ensuring that the model is not over-trained.