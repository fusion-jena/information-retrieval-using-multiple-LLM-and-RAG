Unfortunately, the provided context does not mention any specific data augmentation techniques applied in the deep learning pipeline, such as flipping, rotating, or scaling. The context primarily focuses on the mini-batch size, its limitations, and the challenges of using deep learning. It discusses the importance of selecting an appropriate mini-batch size, the limitations imposed by the available GPU memory, and the need for trial and error in setting training options. However, it does not provide information on data augmentation techniques. Therefore, I don't know the answer to this specific question based on the provided context.