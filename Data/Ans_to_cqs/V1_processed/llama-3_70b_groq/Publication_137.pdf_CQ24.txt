Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The context primarily focuses on the SPG framework for tree species segmentation, discussing the pipeline, experimental results, and the impact of hyperparameters like batch size, voxel size, and regularization strength on the model's performance.

However, it is worth noting that the context does mention the use of a deep neural network and the adjustment of hyperparameters to improve the model's performance. This implies that the authors may have employed certain strategies to handle randomness, but these are not explicitly stated.

In general, common strategies to handle randomness in deep learning pipelines include setting a fixed random seed value, using reproducible random number generators, and employing techniques like dropout and data augmentation to reduce overfitting. However, without further information, it is impossible to determine which specific strategies were used in this particular context.