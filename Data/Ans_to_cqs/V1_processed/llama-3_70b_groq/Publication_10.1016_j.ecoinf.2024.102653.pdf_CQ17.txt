According to the provided context, the regularization method used to prevent overfitting in the deep learning pipeline is dropout regularization. Specifically, it is mentioned in section 2.1 that "Following each BiLSTM layer, dropout regularization is incorporated to mitigate the risk of overfitting. Specifically, this regularization method entails the random deactivation of 50% of the neural connections." 

There is no mention of L2 regularization or any other regularization method in the provided context. Therefore, it can be concluded that dropout regularization is the only regularization method used to prevent overfitting in this deep learning pipeline.