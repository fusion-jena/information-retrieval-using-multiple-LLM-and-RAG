Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context discusses the loss function used, which is a combination of binary cross-entropy and Dice coefficient-related loss, and the optimizer used, which is RMSprop with an initial learning rate of 0.0001. However, it does not mention any regularization techniques such as dropout or L2 regularization. Therefore, I don't know the answer to this question based on the provided context.