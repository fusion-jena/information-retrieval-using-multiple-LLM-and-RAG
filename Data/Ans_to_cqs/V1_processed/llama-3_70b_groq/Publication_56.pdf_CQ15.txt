Unfortunately, the provided context does not mention specific optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on interpretability and explainability of deep learning models in agricultural applications, discussing methods like gradient-based sensitivity analysis, Layer-wise Relevance Propagation, and class activation maps. It does not delve into optimization techniques used during the training process.

Therefore, I don't know the answer to this specific question based on the provided context.