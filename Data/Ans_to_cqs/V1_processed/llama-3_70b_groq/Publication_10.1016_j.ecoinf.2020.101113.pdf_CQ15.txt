Unfortunately, the provided context does not mention specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The text only discusses the model architecture, pre-training, and feature extraction layers, but it does not provide information about the optimization techniques used during training. Therefore, I don't know the answer to this question based on the provided context.