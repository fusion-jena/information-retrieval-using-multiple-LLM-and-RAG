Based on the provided context, it appears that the deep learning pipeline primarily deals with image data, specifically RGB-D images (which include depth information). This is evident from the mention of "input channels (red, green, blue, and depth)" being normalized. Additionally, the context mentions the use of camera traps and stereoscopic depth cameras, which further supports the idea that image data is being used.

There is no explicit mention of audio or video data being used in the pipeline. However, it's possible that other data formats like CSV might be used for storing or processing metadata related to the images, but this is not explicitly stated in the provided context.

In summary, the primary data format used in the deep learning pipeline appears to be image data, specifically RGB-D images.