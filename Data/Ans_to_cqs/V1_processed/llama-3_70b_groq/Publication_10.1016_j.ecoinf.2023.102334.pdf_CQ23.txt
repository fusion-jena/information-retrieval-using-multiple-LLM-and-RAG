Unfortunately, the provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model. There is no mention of a diverse dataset, cross-validation, or stratified splitting. The context primarily focuses on the architecture of the Vision Transformer (ViT) model, its self-attention mechanism, and the importance of tokenization in image processing. It also discusses the limitations of the model, such as overfitting and the need for more data. However, it does not provide information on the measures taken to ensure the model's generalizability. Therefore, I don't know the answer to this query based on the provided context.