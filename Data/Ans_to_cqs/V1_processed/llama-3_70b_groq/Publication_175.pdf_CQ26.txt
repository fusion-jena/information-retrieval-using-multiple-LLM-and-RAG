Based on the provided context, it appears that data augmentation is used to address data bias during preprocessing of the deep learning pipeline. This is mentioned in the paper by Wong et al. (2016) titled "Understanding data augmentation for classification: when to warp ?". Data augmentation involves artificially increasing the size of the training dataset by applying transformations to the existing data, such as rotation, flipping, and cropping. This helps to reduce overfitting and improve the model's robustness to different conditions.

However, it is worth noting that the context does not explicitly mention other techniques such as stratified splitting, oversampling, undersampling, or diverse data collection. These techniques are commonly used to address data bias, but they are not mentioned in the provided context.

Therefore, the answer is that data augmentation is used to address data bias, but it is not clear if other techniques are used as well.