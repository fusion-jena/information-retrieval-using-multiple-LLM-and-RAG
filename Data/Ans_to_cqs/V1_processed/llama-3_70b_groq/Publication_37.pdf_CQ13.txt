The hyperparameters used in the deep learning model are as follows: 

* Learning rate: 0.01 (constant)
* Optimizer: Mini-batch stochastic gradient descent
* Dropout: Applied to the input of the last two layers with a probability of 0.5
* L2-regularization: Applied to the weights of the last two layers with a penalty factor of 0.001
* Number of epochs: 100
* Checkpointing: After each epoch
* Validation set: Used to identify the parameter setting (epoch) achieving the highest classification accuracy