The hyperparameters used in the deep learning model are as follows:

* Solver type: Stochastic Gradient Descent
* Base learning rate: 0.005
* Learning rate policy: Step (decreases by a factor of 10 every 30/3 epochs)
* Momentum: 0.9
* Weight decay: 0.0005
* Gamma: 0.1
* Batch size: 24 (in case of GoogLeNet), 100 (in case of AlexNet)

These hyperparameters were standardized across all the experiments to enable a fair comparison between the results of all the experimental configurations.