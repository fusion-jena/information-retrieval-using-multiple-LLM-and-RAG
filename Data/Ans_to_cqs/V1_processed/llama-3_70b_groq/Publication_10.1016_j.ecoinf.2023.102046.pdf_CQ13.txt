The hyperparameters used in the deep learning models are as follows:

For Hugging Face models (ViT), the optimizer used is AdamW, with a learning rate of 10^(-5) and a batch size of 16.

For Inception-V3, the optimizer used is Adam, with a learning rate of 4 Ã— 10^(-5) and a batch size of 16.

For Deep Otolith ResNet, the optimizer used is AdamW, with a learning rate of 10^(-4) and a batch size of 16.

Note that these hyperparameters are specific to the fine-tuning experiments mentioned in the context.