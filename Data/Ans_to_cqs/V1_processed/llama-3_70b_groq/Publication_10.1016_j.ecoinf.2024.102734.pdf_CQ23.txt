Based on the provided context, it appears that the dataset used to train and evaluate the deep learning models has an 80/20% training-validation split. This suggests that the authors have used a hold-out validation set to evaluate the model's performance during training. However, there is no explicit mention of cross-validation or stratified splitting.

The dataset itself is described as containing 3000 5-second segments, with a representative distribution of target features to non-target features, which suggests that the dataset may be diverse. Additionally, each segment has been manually reviewed by a human, which could help to ensure the quality and consistency of the labels.

However, without further information, it is unclear whether the dataset is diverse in terms of other factors that could affect the model's generalizability, such as the environment, recording conditions, or variability in the possum vocalizations.

Therefore, while some measures have been taken to ensure the quality and diversity of the dataset, it is unclear whether the authors have used cross-validation or stratified splitting to further ensure the generalizability of the model.