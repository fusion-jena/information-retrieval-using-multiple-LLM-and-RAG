The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention that "Data augmentation of random flips and translations was tested and found to have little effect on the final score." This suggests that data augmentation was explored as a means to prevent overfitting, but its impact was minimal. There is no mention of other regularization methods such as dropout or L2 regularization.