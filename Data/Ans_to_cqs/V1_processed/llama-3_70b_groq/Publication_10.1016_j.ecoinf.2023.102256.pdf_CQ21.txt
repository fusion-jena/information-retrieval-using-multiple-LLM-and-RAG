The provided context does not explicitly mention the postprocessing steps involved after the model training. It discusses the architecture of the model, the training process, and the use of metadata, but it does not provide information about the specific postprocessing steps.

However, it can be inferred that the model outputs probabilities for 8,836 species, and only the 22 species involved in the study are kept and multiplied with the corresponding outputs of the baseline model. This suggests that some form of filtering or selection is performed after the model training, but the exact postprocessing steps are not specified.

Therefore, I don't know the specific postprocessing steps involved, such as the calculation of metrics, creation of confusion matrices, or generation of saliency maps, as this information is not provided in the context.