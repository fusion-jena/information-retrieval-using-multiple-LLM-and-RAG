The provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the holdback trials and partitioning tests to determine the optimal number of footprint trails required for the algorithm training set and test sets to provide an accurate population estimate.

However, it can be inferred that the data is split into training and test sets based on the number of trails, with varying ratios of test to training set sizes being explored (e.g., 32:12, 20:24, 36:08). The goal of this splitting seems to be to evaluate the robustness of the model and determine the optimal size for the algorithm training and test sets.

It is not clear from the provided context whether a validation set is used or what criteria are used to split the data into these sets. Therefore, a definitive answer to the query cannot be provided based on the given information.