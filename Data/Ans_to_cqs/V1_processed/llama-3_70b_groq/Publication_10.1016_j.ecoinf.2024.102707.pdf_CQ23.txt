Unfortunately, the provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model. The context primarily focuses on the model's performance, citing F1 scores and other metrics, but it does not provide information on the dataset, cross-validation, or splitting strategies used.

However, it can be inferred that the model was tested on different datasets, including training, validation, and testing data, as well as on unseen locations ("test-over_location"). This suggests that the model was evaluated on diverse data, which could contribute to its generalizability. Nevertheless, without explicit information, it is impossible to determine the specific measures taken to ensure generalizability.

In summary, the context does not provide sufficient information to answer this query, and further details about the model's development and evaluation would be necessary to determine the measures taken to ensure generalizability.