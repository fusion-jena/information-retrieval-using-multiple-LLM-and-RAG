The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that the "nnet" package was used to implement the MLP ANN model, and that "size" and "decay" were used to define the primary model tuning parameters. 

It can be inferred that the "decay" parameter might be related to weight decay, which is a form of L2 regularization. However, this is not explicitly stated, and it is unclear whether other regularization methods, such as dropout, were used.

Therefore, based on the provided context, it is not possible to provide a definitive answer to the query.