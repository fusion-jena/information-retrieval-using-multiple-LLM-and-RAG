The provided context does not explicitly mention preprocessing steps such as normalization, scaling, or cleaning. However, it does mention that the training set was enhanced by various methods, including:

* Flipping the images and labels along the X or Y axis
* Exchanging between multiple image channels while keeping the labels unchanged
* Randomly rotating the images and labels by 90 degrees
* Randomly adding noise to the images while maintaining the labels unchanged

These methods can be considered as data augmentation techniques to increase the diversity of the training dataset. However, it does not provide information about other preprocessing steps.

Therefore, based on the provided context, I don't know what other preprocessing steps, such as normalization, scaling, or cleaning, were involved before training the DeepLabV3+ model.