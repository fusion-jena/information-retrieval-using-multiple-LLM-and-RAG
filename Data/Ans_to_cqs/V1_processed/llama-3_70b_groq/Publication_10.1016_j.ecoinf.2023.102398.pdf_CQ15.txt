According to the provided context, the optimization function used in the deep learning pipeline is Stochastic Gradient Descent (SGD). This is mentioned in section 4.1, where it is stated that "Optimization Function- Stochastic Gradient Descent (SGD) (Bottou, 2012) is used for training." There is no mention of other optimization techniques such as Adam in the provided context.