Based on the provided context, it appears that data augmentation techniques are used to address data bias during preprocessing of the deep learning pipeline. Specifically, the text mentions that "Data augmentation of random flips and translations was tested and found to have little effect on the final score." This suggests that the authors attempted to use data augmentation to increase the diversity of the training data and reduce bias, but it did not have a significant impact on the model's performance.

There is no mention of other techniques such as stratified splitting, oversampling, or undersampling being used to address data bias. Additionally, the context does not provide information on diverse data collection techniques being used to address bias.

It's worth noting that the context focuses more on the use of pretraining data, hand-annotated data, and transfer learning to improve the model's performance, rather than addressing data bias specifically.