I don't know.

The provided context does not mention specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context focuses on the model selection procedure, architecture types, and hyperparameters for classical machine learning models, but it does not provide information about the optimization techniques used in the deep learning pipeline.