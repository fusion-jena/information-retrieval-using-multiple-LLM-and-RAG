The hyperparameters used in the deep learning model are as follows: 

* Batch size (B): 64
* Base learning rate (α): 10^(-4)
* Learning rate reduction factor: 0.1 (reduced when validation loss has not improved for 15 consecutive epochs)
* Weight decay: 10^(-3) (inversely proportional to the hyperparameter λ from Eq. (1))
* Optimizer: Adam
* Adam optimizer hyperparameters:
	+ β1: 0.9
	+ β2: 0.999
	+ ε: 10^(-8)