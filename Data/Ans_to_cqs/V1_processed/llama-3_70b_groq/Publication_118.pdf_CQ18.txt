Unfortunately, the provided context does not explicitly mention the strategy implemented to monitor the model performance during training. The context primarily focuses on the methodology, dataset, and results of the experiment, but it does not provide information on how the model performance was monitored during training.

The context does mention the evaluation of the feature representation produced by the auto-encoder, but it does not specify how this evaluation was performed during the training process. It only mentions that the extensive annotation of the dataset allowed for easy evaluation and training on a higher proportion of non-silent audio clips.

Therefore, I don't know the answer to this query based on the provided context.