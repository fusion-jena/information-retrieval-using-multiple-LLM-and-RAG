Based on the provided context, it appears that data augmentation is used to address data bias during preprocessing of the deep learning pipeline. Specifically, the text states that "Performing data augmentation on training datasets is a widely used technique in deep learning, including sound classification applications, to regularize models and provide more robust features." The data augmentation technique used in this case involves splitting the merged .wav training file for each species in half and then adding these two halves sample-wise. This augmented .wav file is then split into 2-s increments and mel-spectrograms are computed.

It is not explicitly mentioned in the provided context whether stratified splitting, oversampling, undersampling, or diverse data collection are used to address data bias. However, it is mentioned that the dataset was increased by 50% after data augmentation, which suggests that the goal of data augmentation is to provide more robust features and regularize models, which can help mitigate data bias.

In summary, based on the provided context, data augmentation is used to address data bias during preprocessing of the deep learning pipeline, but it is not clear whether other techniques such as stratified splitting, oversampling, undersampling, or diverse data collection are used.