The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that a common remedy to overfitting is the use of validation data, which are set aside while training, yet their annotations by the models are monitored. This helps to limit the training duration, thereby reducing the risk of overfitting.

It can be inferred that the authors used validation data as a partial remedy to overfitting, but the specific regularization methods used are not mentioned. Therefore, I don't know the specific regularization methods used in this deep learning pipeline.