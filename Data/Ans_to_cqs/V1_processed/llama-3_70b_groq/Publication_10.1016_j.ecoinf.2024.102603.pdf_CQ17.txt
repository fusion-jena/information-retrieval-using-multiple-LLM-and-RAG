I don't know.

The provided context does not mention regularization methods used to prevent overfitting in deep learning pipelines, such as dropout or L2 regularization. The context primarily focuses on the differences between XGBoost and deep learning models, including their computational requirements, interpretability, and performance on small datasets. It does not provide information on specific techniques used to prevent overfitting in deep learning models. Therefore, I cannot provide an answer to this query based on the given context.