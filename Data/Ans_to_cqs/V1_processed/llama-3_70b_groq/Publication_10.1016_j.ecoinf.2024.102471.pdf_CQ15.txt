According to the provided context, the optimization technique applied in the deep learning pipeline is Adam. This is mentioned in section 4.4, where it is stated that "Adam is used as optimizer with initial learning rate of order 10e-5 is appropriate for small weight updates throughout the network while fine-tuning."