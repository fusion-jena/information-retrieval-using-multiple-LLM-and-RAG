Based on the provided context, it appears that the methods utilized for collecting raw data in the deep learning pipeline include:

1. Citizen science platforms: The context mentions that data can be collected from citizen science platforms, which suggests that volunteers or citizens contribute data that can be used for deep learning applications.

2. Social media platforms: The text also mentions that data can be collected from social media platforms, which implies that online data shared by users can be utilized for deep learning purposes.

3. API (Application Programming Interface): The context states that data can be collected through an API, which is a set of defined rules that enable different applications to communicate with each other and exchange data.

4. Web scraping methods: The text mentions that data can be collected through web scraping methods, which involve extracting data from websites, online platforms, or social media platforms.

It is essential to note that the context does not explicitly mention the use of surveys, sensors, or public datasets as methods for collecting raw data in the deep learning pipeline. However, it highlights the potential of leveraging online digital data, including images, for environmental monitoring and invasive alien plant detection using deep learning algorithms.