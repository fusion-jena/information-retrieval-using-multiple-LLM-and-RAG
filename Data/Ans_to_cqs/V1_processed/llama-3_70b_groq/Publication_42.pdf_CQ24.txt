The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The text focuses on the architecture and performance of CNN models for moth species classification, hyperparameter tuning, and the challenges of collecting a sufficient dataset.

However, it is worth noting that the text does mention the use of dropout probability (0.3) after the second-to-last hidden layer, which is a regularization technique to prevent overfitting. Dropout can be seen as a way to introduce randomness in the model during training, but it is not directly related to handling randomness in the pipeline.

In general, setting a random seed value is a common practice in deep learning to ensure reproducibility of results. This is not mentioned in the provided context, and it is unclear whether the authors employed this strategy or not.

In summary, the provided context does not provide information on strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value.