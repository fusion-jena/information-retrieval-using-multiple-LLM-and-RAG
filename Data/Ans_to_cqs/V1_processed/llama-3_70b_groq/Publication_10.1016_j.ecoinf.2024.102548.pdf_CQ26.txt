The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention data augmentation as a technique used to enhance the performance and generalization capability of deep learning models. Data augmentation involves artificially generating variations of the training dataset to increase its size and diversity. This can help mitigate data bias to some extent, but it is not a direct technique for addressing bias.

The context also mentions dataset splitting, where the dataset is divided into training, testing, and validation sets. However, it does not specify whether stratified splitting is used to ensure that the class distribution is maintained in each split.

Other techniques like oversampling, undersampling, and diverse data collection are not mentioned in the provided context. Therefore, it cannot be determined whether these techniques are used to address data bias during preprocessing of the deep learning pipeline.

In summary, while data augmentation is mentioned as a technique to enhance model performance, the context does not provide information on specific techniques used to address data bias during preprocessing.