Based on the provided context, the criteria used to split the data for deep learning model training is k-fold cross-validation. Specifically, k-fold cross-validation with k = 5 was used to determine the best training-test split for the model. This means that the data was split into 5 different training-test sets, and the model was trained on each training split separately. The split with the highest mAP50 value (0.987) was chosen as the ideal split for the prediction of the model.

It's worth noting that the context does not explicitly mention a validation set, but it's common in machine learning to use k-fold cross-validation to evaluate the model's performance on unseen data and to tune hyperparameters. The test set is used to evaluate the final performance of the model after training and hyperparameter tuning.

In this specific case, the test set appears to be similar to the training data, consisting of images of extracted clusters without further processing. The goal of the study is to train a digit recognition model, and the data split is used to evaluate the model's performance on unseen data.