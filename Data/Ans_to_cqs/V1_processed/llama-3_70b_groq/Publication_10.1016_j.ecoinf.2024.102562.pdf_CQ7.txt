Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context discusses the importance of dataset size, annotating dataset images, and using a partially trained model to annotate new data. It also mentions the use of a validation set to assess the efficacy of the deep learning recognition model. However, it does not provide specific information on how the data was split for training, testing, and validation.

The context does provide some information on the dataset, such as the number of training images (540) and validation images (141) in the self-annotation dataset, but it does not explain how these numbers were determined or what criteria were used to split the data. Therefore, I don't know the answer to this query based on the provided context.