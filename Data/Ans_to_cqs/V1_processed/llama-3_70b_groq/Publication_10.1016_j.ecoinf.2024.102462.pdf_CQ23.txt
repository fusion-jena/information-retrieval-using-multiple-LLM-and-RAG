According to the provided context, the measure taken to ensure the generalizability of the deep learning model was dividing the data into 4 non-overlapping subsites to maximize the independence between the training and testing sets. This was done to assess the generalization power of the networks studied. Additionally, it is mentioned that the common practice of randomly dividing a single data set into training and testing may lead to overestimating practical performance, and that using data augmentation or building datasets that better reflect real percentages could have ameliorated the high variation in class distribution between training and testing sets. However, it does not mention other measures such as diverse dataset, cross-validation, or stratified splitting.