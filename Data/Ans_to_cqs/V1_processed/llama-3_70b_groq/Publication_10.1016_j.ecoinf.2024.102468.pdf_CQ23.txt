The provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model, specifically the WT-HMM. However, it can be inferred that the model was tested on different dataset sizes, which suggests that the model's performance was evaluated on varying amounts of data. This could be seen as a form of robustness testing, but it is not explicitly stated as a measure to ensure generalizability.

Additionally, the context mentions that the experiments were performed over 10 runs, which suggests that some form of repetition or iteration was used to capture the variability introduced by random factors such as random initialization of weights in ANN or random sampling during training. This could be seen as a form of internal validation, but it is not explicitly stated as a measure to ensure generalizability.

There is no mention of cross-validation, stratified splitting, or the use of a diverse dataset in the provided context. Therefore, it cannot be determined from the provided information what specific measures were taken to ensure the generalizability of the WT-HMM model.