The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on data augmentation as a method to overcome the problem of limited data and improve model performance. It discusses various audio-specific augmentation techniques, such as changing the frequency, pitch, and volume of audio signals, shifting, rotating, and zooming in the time and/or frequency domains of spectrograms, and adding additional noise. 

However, it does not mention techniques specifically used to address data bias, such as stratified splitting, oversampling, undersampling, or diverse data collection. Therefore, I don't know the answer to this question based on the provided context.