According to the provided context, one strategy employed to handle randomness in the deep learning pipeline is the use of a specific integer seed to randomly initialize the model's weights. This ensures consistent reproducibility of results. Additionally, the train_test_split function from the scikit-learn library is used to facilitate randomized shuffling and division of datasets into distinct training and testing subsets. This function is used to divide the dataset into training and testing sets, as well as training and validation sets, with a random selection of 70% of the data for training and 30% for testing/validation. However, the context does not provide information on other strategies that may be employed to handle randomness in the deep learning pipeline, such as random shuffling of data or random initialization of other model components.