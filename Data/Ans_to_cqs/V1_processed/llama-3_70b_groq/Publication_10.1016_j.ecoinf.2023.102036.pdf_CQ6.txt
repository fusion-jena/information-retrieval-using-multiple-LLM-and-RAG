Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. The context primarily focuses on the optimization of model training parameters, such as learning rate, momentum, and input size, and the use of TensorBoard for performance visualization. It also mentions the limitation of the dataset size and the exploitation of deep learning techniques in combination with statistical fundamentals to overcome this limitation. However, it does not provide information on preprocessing steps like normalization, scaling, or cleaning. Therefore, I don't know the answer to this query based on the provided context.