The optimization techniques applied in the deep learning pipeline mentioned in the context are RMSProp, Adam, and SGD. These are used as optimizers in the convolutional neural network (CNN) deep learning model. The learning rates used in conjunction with these optimizers are 0.001 and 0.01.