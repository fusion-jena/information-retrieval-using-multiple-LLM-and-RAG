Unfortunately, the provided context does not mention the specific criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily discusses model validation strategies, internal and external validation methods, and screening processes for a systematic review of ecological informatics studies. It does not provide information on data splitting criteria for deep learning models.

However, it is worth noting that the context does mention some data splitting methods, such as "simple sample splitting" and "cross-validation" (including k-fold, bootstrap, leave-one-out CV, and repeated split sampling), but these are discussed in the context of internal validation strategies, not specifically for deep learning model training.

In summary, the provided context does not provide the answer to the query, and I don't know the specific criteria used to split the data for deep learning model training.