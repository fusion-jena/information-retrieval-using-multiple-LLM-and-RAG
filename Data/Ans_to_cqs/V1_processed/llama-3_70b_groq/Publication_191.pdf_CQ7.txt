Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on discussing the limitations of existing plant datasets, comparing their sizes and number of categories, and describing the training process and parameter settings for a deep learning model.

However, in general, the common practice in deep learning is to split the data into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune the hyperparameters and evaluate the model's performance during training, and the testing set is used to evaluate the model's performance on unseen data.

The criteria for splitting the data can vary depending on the specific problem and dataset. Some common methods include:

* Random splitting: dividing the data randomly into training, validation, and testing sets
* Stratified splitting: dividing the data into sets while maintaining the same class distribution as the original dataset
* K-fold cross-validation: dividing the data into k folds, using k-1 folds for training and one fold for validation, and repeating the process k times

Without more specific information, it is difficult to determine the exact criteria used in this particular context.