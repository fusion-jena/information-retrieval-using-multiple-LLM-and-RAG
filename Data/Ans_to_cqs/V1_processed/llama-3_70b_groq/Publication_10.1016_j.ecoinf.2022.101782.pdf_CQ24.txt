The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. However, it does mention some aspects of the deep learning model training process.

In the context, it is mentioned that image augmentation was applied in the form of horizontal flip, 0.2 degree counter-clockwise shear, and a random zoom between 0 and 0.2. This suggests that some randomness is introduced in the data augmentation process to increase the diversity of the training data.

Additionally, the context mentions the use of an ADAM optimizer with a learning rate of 10, and the model training process took roughly 4 days. The best model was selected based on minimal validation loss, which occurred at epoch 448.

However, there is no explicit mention of how randomness is handled in the deep learning pipeline, such as setting a random seed value to ensure reproducibility of the results. Therefore, it cannot be determined from the provided context what strategies are employed to handle randomness in the deep learning pipeline.