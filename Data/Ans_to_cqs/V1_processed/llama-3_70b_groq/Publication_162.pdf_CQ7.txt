Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context discusses various aspects of deep learning models, such as part detector discovery, species classification, and object detection, but it does not provide information on data splitting criteria.

However, it is common practice in machine learning to split the data into training, testing, and validation sets. The training set is used to train the model, the testing set is used to evaluate the model's performance, and the validation set is used to tune the model's hyperparameters. The typical split ratio is 80% for training, 10% for validation, and 10% for testing, but this can vary depending on the specific problem and dataset.

In the provided context, it is mentioned that a retained test set of images annotated manually is used for evaluation, but the criteria for splitting the data into training, testing, and validation sets are not specified.

Therefore, I don't know the specific criteria used to split the data for deep learning model training based on the provided context.