Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. The context primarily focuses on the application of deep learning approaches to wildfire response using multispectral LiDAR data and synthetic data. It discusses the methodology, results, and discussion related to fuel model retrieval and wildfire spread prediction.

However, it is common practice in deep learning to employ strategies to handle randomness, such as:

1. Fixing the random seed value to ensure reproducibility of results.
2. Using techniques like dropout and batch normalization to reduce overfitting.
3. Implementing data augmentation to increase the size and diversity of the training dataset.
4. Performing multiple runs with different random seeds and averaging the results.

Since these strategies are not mentioned in the provided context, I cannot provide a specific answer related to the deep learning pipeline used in this study.