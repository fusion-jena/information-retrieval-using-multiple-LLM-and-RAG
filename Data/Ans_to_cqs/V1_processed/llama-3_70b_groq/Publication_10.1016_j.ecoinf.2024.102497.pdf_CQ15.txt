The provided context does not mention any optimization techniques applied in a deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily discusses CART (Classification and Regression Trees) and RFR (Random Forest Regression) models, which are traditional machine learning techniques, not deep learning techniques. 

The context mentions fine-tuning model parameters, such as 'max_depth', 'min_samples_leaf', and 'max_leaf_nodes' for CART, and 'n_estimators' for RFR, to prevent overfitting and minimize cross-validation error. However, it does not mention any optimization techniques commonly used in deep learning pipelines.