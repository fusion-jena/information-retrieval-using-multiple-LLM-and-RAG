To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the labeled dataset was split into training and testing datasets in a 70:30 ratio. This is a common practice to evaluate the model's performance on unseen data. Additionally, 50% of the training data was held out for validation, which helps in model selection and parameter optimization. 

Furthermore, a 10-fold cross-validation was used to define the score-to-posterior-probability transformation function. This technique helps to reduce overfitting and improves the model's ability to generalize to new data. 

Although the context does not explicitly mention the use of a diverse dataset or stratified splitting, the use of cross-validation and holding out a portion of the training data for validation suggests that the authors have taken steps to ensure the model's generalizability.