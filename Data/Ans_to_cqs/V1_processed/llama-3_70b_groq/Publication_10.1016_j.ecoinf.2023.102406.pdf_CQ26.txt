The provided context does not specifically mention techniques used to address data bias during preprocessing of a deep learning pipeline. The context appears to be discussing species distribution modeling and the use of various classifiers, such as general linear models, MaxEnt, and random forests. It mentions sample thinning, which is not a technique typically used to address data bias, but rather a method to reduce the number of samples.

The context does mention data splitting, where 25% of the samples are used as testing data, but this is not specifically mentioned as a technique to address data bias. It is a standard practice in machine learning to split data into training and testing sets to evaluate model performance.

Therefore, I don't know the answer to the query based on the provided context. The query asks about specific techniques used to address data bias, such as stratified splitting, oversampling, undersampling, and diverse data collection, which are not mentioned in the context.