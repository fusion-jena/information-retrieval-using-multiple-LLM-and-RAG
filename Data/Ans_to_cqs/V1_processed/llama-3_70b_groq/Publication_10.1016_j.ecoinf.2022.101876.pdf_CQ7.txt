Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context discusses the process of training and testing a model, but it does not provide specific details on how the data is split.

However, it is common practice in machine learning to split the data into training, testing, and validation sets. The training set is used to train the model, the testing set is used to evaluate the model's performance, and the validation set is used to tune the model's hyperparameters.

In general, the criteria for splitting the data may vary depending on the specific problem and dataset. Some common practices include:

* Random splitting: dividing the data randomly into training, testing, and validation sets
* Stratified splitting: dividing the data into sets while maintaining the same class distribution as the original dataset
* Time-based splitting: dividing the data into sets based on time, such as using older data for training and newer data for testing

Without more information, it is difficult to determine the specific criteria used in this context.