Based on the provided context, the regularization method used to prevent overfitting in the deep learning pipeline mentioned is dropout. In Table 3, which describes the CNN architecture, a dropout layer is included with a dropout rate of 0.4. This suggests that dropout is used as a regularization technique to prevent overfitting in this particular model.

However, L2 regularization is not explicitly mentioned in the provided context. It is possible that other regularization methods may be used in the deep learning pipeline, but they are not mentioned in the given text.

It is worth noting that the context provides information about various deep learning models, including ResNet, Xception, and VGG16, but it does not provide a comprehensive list of regularization methods used in these models. Therefore, it is possible that other regularization methods, such as L1 regularization, early stopping, or batch normalization, may be used in these models, but they are not mentioned in the provided context.