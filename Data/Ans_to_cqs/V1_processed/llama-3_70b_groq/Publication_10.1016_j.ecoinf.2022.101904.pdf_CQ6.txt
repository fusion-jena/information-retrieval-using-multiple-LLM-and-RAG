Unfortunately, the provided context does not mention the preprocessing steps involved before training a deep learning model. The context primarily focuses on the application of transformers in natural language processing and computer vision, specifically in remote sensing and wetland mapping. It discusses the performance of various deep learning models, including Vision Transformer, Swin Transformer, CoAtNet, and 3DUNetGSFormer, but does not provide information on preprocessing steps such as normalization, scaling, or cleaning. Therefore, I don't know the answer to this query based on the provided context.