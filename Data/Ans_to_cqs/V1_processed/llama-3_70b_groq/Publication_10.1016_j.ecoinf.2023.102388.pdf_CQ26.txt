The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on the challenges of generalization in deep learning, overfitting, and its implications on privacy attacks. It discusses the importance of avoiding overfitting and mentions techniques such as batch normalization, weight decay, and dropout to reduce overfitting. However, it does not provide information on addressing data bias during preprocessing.

Therefore, I don't know the answer to this specific query based on the provided context. The mentioned techniques like stratified splitting, oversampling, undersampling, and diverse data collection are commonly used to address data bias, but they are not mentioned in the provided context.