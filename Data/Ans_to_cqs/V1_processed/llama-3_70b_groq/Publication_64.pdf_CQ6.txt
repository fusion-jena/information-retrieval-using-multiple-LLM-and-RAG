Based on the provided context, the preprocessing steps involved before training a deep learning model are:

* Data augmentation: standard data augmentation techniques such as shear, translation, and mirror are applied to the images so that the network never sees the same image.
* Downsizing: the images are downscaled to the ResNet standard 224x224 input size.

There is no mention of normalization, scaling, or cleaning in the provided context. However, it is worth noting that the authors mention that they automatically retrieve images from Google Image Search, which might result in some minor mislabeled or corrupt examples in the dataset. They try to minimize the presence of mislabeled images by choosing only the most popular labels and retrieving the top results.