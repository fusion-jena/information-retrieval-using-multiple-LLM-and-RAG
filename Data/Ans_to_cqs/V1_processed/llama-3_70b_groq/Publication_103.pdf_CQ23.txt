The provided context does not explicitly mention measures taken to ensure the generalizability of the deep learning model, such as diverse dataset, cross-validation, or stratified splitting. However, it can be inferred that the model was trained on a large dataset (dataset A) and then fine-tuned on a smaller, domain-specific dataset (dataset B), which is a form of transfer learning. This approach can help improve the model's generalizability by adapting to new, unseen data.

Additionally, the context mentions data augmentation techniques, such as simple crop and resize, which were used with the default settings of the Caffe framework. Data augmentation can help increase the diversity of the training data and improve the model's robustness to different image variations.

However, there is no mention of cross-validation or stratified splitting, which are common techniques used to evaluate and improve the generalizability of machine learning models. Therefore, it is unclear whether these measures were taken to ensure the generalizability of the deep learning model.