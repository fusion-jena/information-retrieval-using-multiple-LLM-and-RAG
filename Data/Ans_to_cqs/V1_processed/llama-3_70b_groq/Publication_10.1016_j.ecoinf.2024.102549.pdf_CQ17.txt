Based on the provided context, the regularization method used to prevent overfitting in the deep learning pipeline is dropout regularization. This is mentioned in the text as "dropout regularization techniques" which is one of the practical strategies that contribute to the effectiveness of the AlexNet architecture. There is no mention of L2 regularization in the provided context.