Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context discusses the training process, model architecture, and dataset summary, but it does not provide information on how the data was split for training, testing, and validation.

However, it can be inferred that the dataset was split into training and validation sets, as the context mentions that the best-performing model based on the validation loss was saved and used for testing. This implies that the model was trained on a training set and evaluated on a validation set, and then the best model was selected and used for testing. But the exact criteria or ratio used for splitting the data is not provided.

Therefore, I don't know the exact criteria used to split the data for deep learning model training, and further information would be required to determine this.