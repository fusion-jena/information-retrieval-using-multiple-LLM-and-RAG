The provided context does not explicitly mention the optimization techniques used in the deep learning pipeline, such as SGD, Adam, or others. The text focuses on the architecture of the modified GoogleNet model, batch normalization, and the implementation details using the Caffe framework. It mentions the learning rate of 0.0075, but it does not specify the optimization algorithm used.

Therefore, I don't know the answer to this question based on the provided context.