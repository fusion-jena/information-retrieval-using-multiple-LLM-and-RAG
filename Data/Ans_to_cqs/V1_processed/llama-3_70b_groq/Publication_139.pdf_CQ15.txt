The optimization technique applied in the deep learning pipeline is Adam. This is mentioned in the context as "The optimizer Adam was selected with an initial learning rate of (cid:0) 7 and early stopping was used to prevent overfitting".