According to the provided context, the metric used to evaluate the performance of the deep learning model is the weighted F1 score. The F1 score is a harmonic mean of precision and recall, providing a balanced measure of both the false positives and false negatives in the classification results. The weighted F1 score is used to account for the class imbalance in the dataset. The F1 score is calculated using the true labels and predicted majority classes for each transect from the aggregated data, and the confusion matrix is computed using the Python Scikit-learn library.