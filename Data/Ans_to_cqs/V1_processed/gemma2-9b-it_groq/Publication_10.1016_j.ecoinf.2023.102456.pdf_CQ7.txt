The provided text focuses on a specific deep learning application related to forest fire modeling and doesn't delve into the general criteria for splitting data in deep learning. 

To answer your query about data splitting for training, testing, and validation sets, here's a common approach:

* **Training Set:** This is the largest portion of the data (typically 70-80%) used to train the deep learning model. The model learns patterns and relationships within this data.

* **Validation Set:** A smaller portion of the data (around 10-15%) is reserved for validation. This set is used during the training process to evaluate the model's performance on unseen data. It helps in tuning hyperparameters and preventing overfitting (where the model performs well on training data but poorly on new data).

* **Test Set:**  The remaining data (around 10-15%) is held out as the test set. This set is used only once, at the end of the training process, to provide an unbiased evaluation of the final model's performance on completely unseen data. 

The goal is to select representative subsets of the data for each purpose, ensuring that the model generalizes well to new, unseen data.