The text states that two metrics are used to assess the model's performance: precision and recall.  

These are calculated using a bounding box marked as a true positive if its intersection-over-union (IoU) with the visually annotated crowns is greater than 0.5. Intersection-over-union is the ratio of the overlapping area to the total area of the predicted and annotated bounding boxes. 

The text also mentions Average Precision (AP) as a metric used for comparison between different generalization approaches. AP is the area under the precision-recall curve, calculated at 11 fixed intervals between 0 and 1.