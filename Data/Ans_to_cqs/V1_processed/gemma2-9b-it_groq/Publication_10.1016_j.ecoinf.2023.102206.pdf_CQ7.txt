The provided text focuses on transfer learning techniques and doesn't specify the criteria used to split data for deep learning model training (train, test, validation). 

To answer your query generally:

Data splitting for deep learning typically involves these sets:

* **Training set:** The largest portion of data used to train the model, allowing it to learn patterns and relationships.
* **Validation set:** A subset used during training to evaluate the model's performance on unseen data. This helps prevent overfitting (where the model performs well on training data but poorly on new data).
* **Test set:** Held out entirely during training and used only once at the end to provide a final, unbiased evaluation of the model's performance.

Common splitting ratios are 70% for training, 15% for validation, and 15% for testing. 

The specific criteria for splitting can vary depending on the dataset size, complexity of the task, and the desired level of accuracy.