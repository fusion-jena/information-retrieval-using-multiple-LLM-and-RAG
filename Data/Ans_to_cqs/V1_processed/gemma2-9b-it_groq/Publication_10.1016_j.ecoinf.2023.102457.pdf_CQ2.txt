The provided text describes a deep learning pipeline that uses **audio** data. 

Specifically, the pipeline takes sound files (waveforms) as input and converts them into Mel-spectrograms. These Mel-spectrograms are then used as input to the deep learning models (VGGish, BirdNET, Wav2Vec 2.0).