The provided text mentions data augmentation techniques like scaling, panning, rotation, color transformation, and mosaic to prevent overfitting.  

It also states that the models were trained for 300 epochs and evaluated on the validation set after each epoch, which is a common practice to monitor and control overfitting during training. 

However, the text does not explicitly list specific regularization methods like dropout or L2 regularization.