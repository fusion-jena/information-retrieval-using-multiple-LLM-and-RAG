The provided text describes the training process and results of a model, but it doesn't explicitly list the post-processing steps taken after training. 

However, based on the mentioned figures and common practices in model evaluation, we can infer some post-processing steps likely involved:

* **Metrics Calculation:**  The text refers to "mAP values" and "graded MSE convergence," suggesting the calculation of metrics like mean Average Precision (mAP) and Mean Squared Error (MSE) to evaluate the model's performance.

* **Confusion Matrix:** Figure 6 mentioned as a "confusion matrix" indicates that this visualization tool was used to analyze the model's classification accuracy and identify potential areas of misclassification.

* **Visualization of Outputs:** Figures 12 and 13 show training and validation outputs, respectively, with bounding boxes and class names. This suggests post-processing steps to generate these visualizations from the model's raw predictions.

It's possible that other post-processing steps were also employed, such as:

* **Saliency Map Generation:**  While not explicitly mentioned, saliency maps could have been generated to understand which parts of the input images the model focuses on when making predictions.
* **Thresholding:**  Adjusting the confidence threshold for bounding box predictions to control the trade-off between precision and recall.
* **Non-Maximum Suppression (NMS):**  A technique used to remove redundant bounding boxes that overlap significantly, ensuring only the most confident prediction is retained.



It's important to note that this is an inference based on the provided context. A complete list of post-processing steps would require access to the full research paper or code implementation.