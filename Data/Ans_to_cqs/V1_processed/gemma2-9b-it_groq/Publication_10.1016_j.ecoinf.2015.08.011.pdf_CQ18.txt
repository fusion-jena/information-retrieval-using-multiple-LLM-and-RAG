To monitor model performance during training, the researchers employed an early stopping technique.  

They split the dataset into two parts: 80% for training and 20% for validation. The training process was halted when the model started to overfit the training data, as indicated by an increase in error on the validation set. This helps prevent the model from memorizing the training data and ensures it can generalize to new, unseen data.