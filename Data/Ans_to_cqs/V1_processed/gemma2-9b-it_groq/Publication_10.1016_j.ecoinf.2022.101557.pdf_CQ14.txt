The provided text does not describe the specific method used to optimize the model's hyperparameters (e.g., grid search, random search).  It only mentions the learning rate used in the ADAM optimization algorithm (0.0001) and the dropout rate (0.3).