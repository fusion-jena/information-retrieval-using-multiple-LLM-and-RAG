The provided text focuses on the history and development of deep learning, particularly mentioning the breakthrough of overcoming limitations on the number of layers in neural networks.  It doesn't delve into specific regularization methods used to prevent overfitting. 

Therefore, I cannot answer your query about regularization methods like dropout and L2 regularization based on the given context.