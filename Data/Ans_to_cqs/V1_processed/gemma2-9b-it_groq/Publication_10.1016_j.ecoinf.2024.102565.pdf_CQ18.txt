The provided text describes the model evaluation strategy using K-fold cross-validation, but it doesn't explicitly state how model performance was monitored *during* training. 

We know the following:

* **K-fold cross-validation:** The model was trained and tested multiple times, with different folds of the data used for training and validation.
* **Metrics:** Performance was evaluated using R2, RMSE, MAE, and MBE.

However, the text doesn't mention any specific techniques used to track performance *during* each training epoch (e.g., plotting loss curves, using early stopping).