The text states that the hyperparameters were tuned using an Optuna-based hyperparameter optimization procedure.  It also mentions that the AdamW optimizer was used for training the models.