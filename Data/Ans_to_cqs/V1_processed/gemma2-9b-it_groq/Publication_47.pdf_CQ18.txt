The text states that cross-validation was used to monitor the model's performance.  Specifically, the training data was split into a training set (90%), a validation set (20% of the training set), and a test set (10%). 

The validation set was shifted 5 times during training to calculate the average validation cross-entropy loss and accuracy. This process allowed the researchers to evaluate the model's ability to generalize to unseen data and select the model with the lowest cross-entropy loss for final predictions.