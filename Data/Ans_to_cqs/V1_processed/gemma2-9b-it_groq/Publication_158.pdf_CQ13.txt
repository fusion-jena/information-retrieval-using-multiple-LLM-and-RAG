The provided text states that the Adam optimizer was used with 500 epochs and categorical-cross entropy loss function. The batch size was set to 64.  It does not mention the learning rate.