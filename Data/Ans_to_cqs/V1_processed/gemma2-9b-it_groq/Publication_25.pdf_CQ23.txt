The provided text doesn't specify the exact measures taken to ensure the generalizability of the deep learning model.  

It mentions that the model could be improved with:

* **Better validation data:** This suggests that the initial validation dataset might not have been sufficiently diverse or representative.
* **More hand-annotated training samples:**  A larger and more diverse training dataset is generally crucial for better generalization.
* **Customization to a local geographic area:** This implies that the initial training data might not have covered a wide range of geographic locations. 

The text also discusses the use of "self-supervised learning" to generate training data from unlabeled sources. While this can be helpful in addressing data limitations, it doesn't inherently guarantee generalizability. 

Therefore, based on the information given, we cannot definitively say what specific techniques (like cross-validation or stratified splitting) were used to improve the model's generalizability.