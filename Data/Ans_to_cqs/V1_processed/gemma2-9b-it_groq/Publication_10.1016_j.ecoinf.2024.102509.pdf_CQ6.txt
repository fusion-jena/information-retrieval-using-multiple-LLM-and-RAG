The provided text focuses on the application of artificial neural networks (ANNs) for prediction tasks and doesn't delve into the specific preprocessing steps involved in training deep learning models. 

However, based on general knowledge of deep learning, here are some common preprocessing steps:

* **Data Cleaning:** This involves handling missing values (imputation or removal), identifying and removing outliers, and correcting inconsistencies in the data.

* **Normalization/Scaling:**  Scaling features to a similar range (e.g., 0 to 1 or -1 to 1) can improve the training process of deep learning models. Common techniques include min-max scaling and standardization.

* **Feature Engineering:**  Creating new features from existing ones can sometimes enhance model performance. This might involve combining features, transforming them (e.g., taking logarithms), or encoding categorical variables.

* **Encoding Categorical Variables:**  Converting categorical data into numerical representations that deep learning models can understand is crucial. Techniques like one-hot encoding or label encoding are commonly used. 



Keep in mind that the specific preprocessing steps will depend on the nature of the data and the deep learning model being used.