The text provides four quality metrics used to evaluate the performance of the deep learning models:

* **Overall Accuracy (OA):**  Calculated by summing the diagonal elements of the confusion matrix.

* **Producer Accuracy (PA):**  Represents the proportion of correctly classified instances of a particular class out of all instances of that class. It's calculated as the number of well-ranked individuals divided by the sum of the column in the confusion matrix.

* **User Accuracy (UA):**  Represents the proportion of correctly classified instances of a particular class out of all instances predicted as belonging to that class. It's calculated as the number of well-ranked individuals divided by the sum of the line in the confusion matrix.

* **F1-score:**  The harmonic mean of precision and recall. It provides a balanced measure that considers both the ability of the model to correctly identify positive instances (precision) and the ability to capture all positive instances (recall).