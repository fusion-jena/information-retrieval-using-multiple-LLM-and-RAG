The model performance was monitored during training using early stopping.  

The authors set a patience of 20 epochs, meaning that if the validation loss did not improve for 20 consecutive epochs, the training process would be stopped. This strategy helps prevent overfitting by terminating training when the model's performance on the validation set starts to plateau or decline.