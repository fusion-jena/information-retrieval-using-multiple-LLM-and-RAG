The provided text describes the process of selecting and evaluating machine learning models, but it doesn't explicitly state a strategy for monitoring model performance *during* training. 

The text mentions:

* **Training on subsets:** Each model was trained on 100 different subsets of the original training data using the bootstrap method.
* **Hyperparameter optimization:** The TPE algorithm was used to find the optimal hyperparameters for each model.
* **Performance evaluation:** The performance of each model was evaluated on a testing dataset, and metrics like average loss, bias, and variance were calculated.

However, it doesn't describe any techniques for monitoring performance *within* a single training run.