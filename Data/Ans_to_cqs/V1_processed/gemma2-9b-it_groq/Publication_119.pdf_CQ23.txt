The provided text mentions that dropout and batch normalization layers were added to the deep learning model to reduce overfitting and improve generalization on testing data.  It also states that the hyperparameters (learning rate, number of epochs, and batch size) were tuned to optimize testing accuracy and kappa. 

However, the text does not specify if a diverse dataset was used, cross-validation was employed, or stratified splitting was applied.