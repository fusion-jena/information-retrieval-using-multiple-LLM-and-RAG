The provided text describes the process of training MLP models but doesn't specify the exact criteria used to determine when training is complete. 

It mentions that the training process involves adjusting the weights of the connections between neurons to minimize the difference between the model's predictions and the actual outcomes. This minimization is achieved using an algorithm called backpropagation.

The text also states that the grid search focused on minimizing the Mean Squared Error (MSE) to identify the optimal set of hyperparameters.  It's possible that training was stopped when the MSE on a validation set plateaued or reached a predefined threshold. 


However, without further information from the source material, we cannot definitively say what criteria were used to determine the completion of training.