The provided text focuses on the architecture and training of deep learning models, particularly in the context of computer vision. It doesn't delve into the specific preprocessing steps involved before training. 

However, based on general knowledge of deep learning, here are some common preprocessing steps:

* **Normalization:** Scaling pixel values to a specific range (e.g., 0 to 1 or -1 to 1) helps improve model training stability and convergence.

* **Scaling:**  Similar to normalization, scaling adjusts the range of input features to a standard scale.

* **Cleaning:** This involves handling missing values, removing duplicates, and correcting inconsistencies in the data.

* **Data Augmentation:**  Artificially increasing the size and diversity of the training dataset by applying transformations like rotations, flips, crops, and color adjustments. This helps improve the model's robustness and generalization ability. 


Keep in mind that the specific preprocessing steps will vary depending on the nature of the data and the chosen deep learning model.