The provided text does not describe the specific strategy used to monitor model performance during training. 

It does mention the use of a training set (first eight days of data) and a validation set (last two days of data) to evaluate the performance of different models.  The text lists metrics such as R-squared (R2), Mean Squared Error (MSE), and Mean Absolute Error (MAE) used to compare the models' performance on both the training and validation sets. 


However, it doesn't explain how these metrics were tracked during the training process itself (e.g., using a learning curve, early stopping, etc.).