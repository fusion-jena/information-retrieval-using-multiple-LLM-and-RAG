The provided text focuses on the application of deep learning for plant biodiversity analysis and doesn't delve into specific strategies for handling randomness within the deep learning pipeline. 

However, it does mention that the approach used is probabilistic, with the network predicting the probability of each plant species being present in each pixel. This probabilistic nature inherently incorporates some randomness.

Generally, to address randomness in deep learning, techniques like:

* **Setting a fixed random seed:** This ensures reproducibility by initializing random number generators with a specific value, leading to the same random choices during each run.
* **Data augmentation:**  Artificially increasing the size and diversity of the training data by applying random transformations (e.g., rotations, flips, crops) to existing images. This helps the model generalize better and be less sensitive to minor variations.
* **Dropout:** Randomly "dropping out" (ignoring) a percentage of neurons during training. This prevents overfitting by forcing the network to learn more robust features.

These strategies are commonly used to mitigate randomness and improve the stability and reliability of deep learning models.