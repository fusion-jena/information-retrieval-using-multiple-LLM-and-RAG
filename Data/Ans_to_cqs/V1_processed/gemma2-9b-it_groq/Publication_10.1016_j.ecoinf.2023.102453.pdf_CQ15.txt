The provided text focuses on neural architecture search (NAS) and hyperparameter optimization for deep learning models, but it doesn't specify the exact optimization techniques used during the training process (e.g., SGD, Adam).