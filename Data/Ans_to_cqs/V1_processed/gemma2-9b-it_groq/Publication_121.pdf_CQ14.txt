The provided text doesn't describe the specific hyperparameter optimization technique used (e.g., grid search, random search). It only mentions the optimizer (SGD with a learning rate of 0.5 and momentum of 0.9) and the number of training epochs (10 to 100 for initial training and 10 for fine-tuning).