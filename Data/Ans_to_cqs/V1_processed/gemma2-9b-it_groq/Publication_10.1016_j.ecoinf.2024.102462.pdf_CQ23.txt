The text states that to assess the generalization power of the deep learning models, the data was divided into four non-overlapping subsites. This was done to maximize the independence between the training and testing sets.  

The authors also mention that the common practice of randomly dividing a single dataset into training and testing sets may lead to overestimating practical performance. They suggest that using data augmentation or building datasets that better reflect real-world percentages could have further improved the results. 


However, the specific techniques used for data splitting (e.g., stratified splitting) are not explicitly mentioned in the provided text.