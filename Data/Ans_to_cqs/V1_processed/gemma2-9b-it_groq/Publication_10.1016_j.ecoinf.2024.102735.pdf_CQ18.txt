The provided text describes the data splitting strategy (80% training, 20% testing) and the use of a validation set within the training data for hyperparameter optimization. 

However, it doesn't explicitly state the specific strategy used to monitor model performance *during* training.  

It mentions using the Optuna package for hyperparameter tuning, which often involves evaluating performance on a validation set after each hyperparameter update. This suggests a likely strategy of monitoring performance on the validation set during the training process.