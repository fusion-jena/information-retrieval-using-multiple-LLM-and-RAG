The provided text describes the model evaluation process after training, not the monitoring strategy during training.  

It states that a benchmark model with default parameters was established to evaluate the impact of hyperparameter adjustments. Hyperparameter optimization was performed using GridSearchCV and Hyperopt, and the best parameters for each model were selected and compared. 

The text also mentions the use of metrics like R2, RMSE, MAE, and Slope to assess the performance of the models. However, it doesn't specify how these metrics were used to monitor performance during the training process itself.