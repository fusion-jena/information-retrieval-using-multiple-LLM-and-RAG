The provided text describes the optimal hyperparameters (400 epochs with a batch size of 8) determined through computational experiments but doesn't specify the exact criteria used to determine when training is complete. 

It does mention using a validation set (243 images at 640x640 pixels and 255 images at 1280x1280 pixels)  which is a common practice.  

In deep learning, training is often stopped when:

* **Validation loss plateaus:**  If the model's performance on the validation set stops improving or starts degrading, training may be stopped to avoid overfitting.
* **A maximum number of epochs is reached:**  As stated in the text, 400 epochs were found to be optimal.

The text focuses on the hyperparameter optimization process rather than the specific stopping criteria.