The provided text focuses on comparing different deep learning models for a specific task and dataset (IP102). It doesn't offer details about the preprocessing steps involved in training these models. 

However, common preprocessing steps for deep learning models generally include:

* **Data Cleaning:** This involves handling missing values, removing duplicates, and correcting inconsistencies in the data.

* **Normalization:** Scaling features to a common range (e.g., 0 to 1 or -1 to 1) can improve model performance.

* **Feature Scaling:** Techniques like standardization (subtracting the mean and dividing by the standard deviation) can help features with different scales contribute equally to the model.
* **Encoding Categorical Features:** Converting categorical variables into numerical representations (e.g., one-hot encoding) is necessary for most deep learning algorithms.

* **Data Augmentation:**  Artificially increasing the size and diversity of the training data by applying transformations like rotations, flips, and crops can enhance model robustness. 


Remember that the specific preprocessing steps will depend on the nature of the data and the chosen deep learning model.