The text states that the Adam optimizer was used for updating the trainable parameters of the deep convolutional neural network.