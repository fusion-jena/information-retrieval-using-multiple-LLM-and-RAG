The provided text doesn't describe a specific strategy for monitoring model performance during training. 

It mentions:

* **Precision and recall trade-offs:** This is a metric used to evaluate the overall effectiveness of a model, but not a strategy for monitoring performance *during* training.
* **Hard negative mining:** This is a technique used to improve training, but it doesn't directly address performance monitoring.
* **Trade-off between detection accuracy and performance:** This refers to the balance achieved by using smaller feature maps, but doesn't explain how performance is tracked.
* **Trials and errors:** This suggests an iterative approach to model development, but doesn't specify how performance is measured in each trial. 


Therefore, based on the given context, I cannot answer what strategy is implemented to monitor model performance during training.