The provided text does not specify the exact optimization techniques used in the deep learning pipeline.  While it mentions the use of MATLAB for model crafting and assessment, it doesn't delve into the specific algorithms employed for training the neural networks. 

Common optimization techniques used in deep learning include Stochastic Gradient Descent (SGD) and its variants (like Adam), but without further information from the text, we cannot confirm which ones were applied in this particular study.