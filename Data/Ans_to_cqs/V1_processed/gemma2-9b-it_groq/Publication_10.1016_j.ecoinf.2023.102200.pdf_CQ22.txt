The provided text mentions the following metrics for evaluating the performance of the deep learning model:

* **Precision:**  Measures the proportion of correctly predicted positive instances out of all instances predicted as positive.
* **Recall:**  Measures the proportion of correctly predicted positive instances out of all actual positive instances.
* **F1-score:**  The harmonic mean of precision and recall, providing a balanced measure of both. 


The text also refers to **True Positives (TP)**, **False Negatives (FN)**, and **False Positives (FP)**, which are commonly used in calculating precision, recall, and the F1-score.