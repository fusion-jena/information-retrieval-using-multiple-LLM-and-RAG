The provided text focuses on the application of Convolutional Neural Networks (CNNs) for bird call classification and doesn't delve into specific strategies for handling randomness in the deep learning pipeline. 

However, it's common practice in deep learning to address randomness through techniques like:

* **Setting a random seed:**  Initializing the random number generator with a specific seed ensures reproducibility. Different runs with the same seed will produce identical results.

* **Data shuffling:** Randomly shuffling the training data before each epoch prevents the model from learning patterns based on the data order.

* **Dropout:** This regularization technique randomly "drops out" (ignores) a percentage of neurons during training. This prevents overfitting and introduces stochasticity.

* **Batch normalization:** This technique normalizes the activations within each layer, reducing the internal covariate shift and stabilizing training.

To get a more detailed answer about specific strategies used in the context of this research, you would need to consult the full research paper or contact the authors.