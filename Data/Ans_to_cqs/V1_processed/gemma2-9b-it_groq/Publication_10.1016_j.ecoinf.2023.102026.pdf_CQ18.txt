The text describes two strategies for monitoring model performance during training:

1. **For Generalized Linear Models (GLM):**

   -  **Non-bootstrapped GLM:** Performance was evaluated using Area Under the ROC Curve (AUC), Percent Correctly Classified (PCC), sensitivity, specificity, and True Skill Statistic (TSS) on a held-out 20% of the camera trap locations.

   - **Bootstrapped GLM:**  For each of 100 iterations, performance metrics (AUC, PCC, sensitivity, specificity, TSS) were calculated using the data retained from the model training (80% presence and absence locations). The final metrics were obtained by averaging the results across these iterations.

2. **For Random Forest (RF):**

   -  The text focuses on scale optimization and covariate selection for RF, but doesn't explicitly detail performance monitoring strategies during training. It mentions using "Out-Of-Bag (OOB) error" for univariate RF to select the most representative scale for each covariate.