The text mentions dropout as a regularization method used to prevent overfitting.  

Specifically, it states: "All of the best results corresponded to the conÔ¨Åguration when the number of layers was equal to 64, and dropout was applied." 

The text also discusses augmentation techniques like random changes of RGB channels and random vertical and horizontal flips as methods to improve network performance and reduce overfitting.