The provided text focuses on the performance and development of a wetland mapping deep learning model (3DUNetGSFormer) and doesn't explicitly detail the specific measures taken to ensure its generalizability. 

The text mentions using a pilot site for evaluation (Avalon, Grand Falls-Windsor, and Gros Morne National Park) and  discusses the impact of varying training data ratios (10% to 90%) on accuracy. However, it doesn't describe techniques like:

* **Diverse dataset:**  Information about the dataset's diversity (e.g., geographical coverage, wetland types, seasons) is lacking.
* **Cross-validation:**  The text doesn't mention using cross-validation techniques to assess model performance on unseen data.
* **Stratified splitting:**  There's no information about whether the data was split into training and testing sets using stratified sampling to maintain class proportions. 


Therefore, based on the provided context, we cannot definitively say what measures were taken to ensure the model's generalizability.