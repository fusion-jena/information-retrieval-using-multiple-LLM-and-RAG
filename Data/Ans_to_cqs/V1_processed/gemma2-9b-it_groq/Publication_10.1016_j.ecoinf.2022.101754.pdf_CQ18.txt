The provided text describes the use of a training-and-test approach with stratification splitting to evaluate model performance. 

Specifically, for each setting, 100 different splits of the data into training and test sets were created. Hyperparameter tuning was performed on the training set for each split.  

The text then goes on to describe the four regression models used (AdaBoost, random decision forest, multilayer neural network, and Bayesian ridge regression) and how the models were evaluated using various metrics like accuracy, root mean squared error, R-squared, and average angle deviation. 

However, it doesn't explicitly state the specific strategy used to *monitor* model performance *during* training.