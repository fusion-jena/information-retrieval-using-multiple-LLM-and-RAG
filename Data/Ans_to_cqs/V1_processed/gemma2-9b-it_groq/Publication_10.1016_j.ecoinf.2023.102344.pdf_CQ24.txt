The provided text focuses on describing different CNN architectures (like ResNet, MobileNetV2, and InceptionV3) and their applications in image analysis, particularly for plant species identification and bivalve traceability. It doesn't delve into strategies for handling randomness in the deep learning pipeline. 

To answer your query about handling randomness in deep learning, here are some common strategies:

* **Setting a fixed random seed:** This ensures that the random number generator starts from the same point each time you run your code, leading to reproducible results.

* **Using deterministic algorithms:** Some algorithms, like certain optimization methods, have deterministic implementations that don't rely on randomness.

* **Data augmentation:** While introducing some randomness, data augmentation techniques (like rotations, flips, and crops) are carefully designed to create variations that help the model generalize better.

* **Dropout:** This regularization technique randomly "drops out" (ignores) a percentage of neurons during training, preventing overfitting and introducing some randomness in the network's structure.



Let me know if you have any other questions about CNN architectures or image analysis.