The provided text focuses on the design and optimization of a lightweight deep learning model called SIAlex, drawing inspiration from the AlexNet architecture.  

While it highlights the importance of model depth and the techniques used to improve efficiency (like merging convolution layers), it doesn't mention specific measures taken to ensure the generalizability of the model. 

The text doesn't discuss:

* **Dataset diversity:**  Whether the training data represented a wide range of examples.
* **Cross-validation:**  Techniques used to evaluate the model's performance on unseen data.
* **Stratified splitting:**  Methods for ensuring balanced representation of different classes in the training and testing sets. 


Therefore, based on the given information, I cannot answer what measures were taken to ensure the generalizability of the deep learning model.