The provided text focuses on genetic programming and wavelet signal analysis for modeling and forecasting, and doesn't offer information about data splitting criteria for deep learning. 

To answer your query, here are common criteria used to split data for deep learning model training:

* **Percentage Split:** The most common approach is to divide the data into three sets:

    * **Training set:**  Used to train the model (e.g., 70-80% of the data).
    * **Validation set:** Used to tune hyperparameters and evaluate the model's performance during training (e.g., 10-15% of the data).
    * **Test set:** Used for a final evaluation of the trained model's performance on unseen data (e.g., 10-20% of the data).

* **Time-Based Split:**  For time-series data, the data is split based on time.  Earlier data points are used for training, while later data points are used for validation and testing.

* **Stratified Split:**  If the data has imbalanced classes, stratified sampling ensures that each class is proportionally represented in each split.


The specific split percentages and methods may vary depending on the dataset size, complexity of the problem, and the goals of the project.