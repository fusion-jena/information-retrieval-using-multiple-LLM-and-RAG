The provided text states that Stochastic Gradient Descent (SGD) was used as the optimizer with a momentum of 0.9.  It does not mention the learning rate used.