To address concerns about overfitting and the model's ability to generalize to unseen data, the authors employed 5-fold cross-validation.  

The dataset was divided into five subsets. In each round of training, one subset served as the validation set, while the remaining four subsets were used for training. This process was repeated five times, with each subset taking turns as the validation set.  

The resulting accuracy curve from this 5-fold cross-validation is shown in Figure 10. This approach ensured that each sample in the dataset was both trained on and validated against different subsets of the data, promoting a more robust and generalizable model.