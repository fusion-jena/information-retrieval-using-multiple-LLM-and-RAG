The provided text describes the use of a Random Forest (RF) model for prediction but doesn't explicitly state the strategy used to monitor model performance *during* training. 

However, it does mention the following:

* **Parameter optimization:** The optimal number of variables to try (M) at each split was determined using the `TuneRF` function, which calculates the minimum Out-of-Bag (OOB) error rate. This suggests that OOB error was used as a performance metric during the parameter tuning process.
* **10-fold cross-validation:**  After model training, the performance was evaluated using 10-fold cross-validation on independent test data. This provides a measure of the model's generalization ability and stability.

Based on this information, it's likely that the OOB error rate was monitored during training to guide the parameter optimization process.