The provided text focuses on hyperparameter tuning for Gradient Boosting Regression Trees (GBRT) models and doesn't discuss optimization techniques used in a deep learning pipeline.  Therefore, I cannot answer your query about optimization techniques like SGD or Adam from this context.