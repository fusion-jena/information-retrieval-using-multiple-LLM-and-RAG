The text states that the Adam optimizer is used for training the model.  It also specifies a Momentum of 0.9 and a Batch size of 16.