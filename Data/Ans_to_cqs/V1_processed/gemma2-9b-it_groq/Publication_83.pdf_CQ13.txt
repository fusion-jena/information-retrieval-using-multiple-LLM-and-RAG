The text states that the network is trained using the Adam optimizer with a learning rate of 10<sup>-4</sup>. The batch size is 64 samples and the network is trained with 200 epochs. The categorical cross entropy is utilized as the loss function.