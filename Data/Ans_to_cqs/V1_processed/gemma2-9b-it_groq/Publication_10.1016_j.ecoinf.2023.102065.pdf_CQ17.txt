While the provided context discusses various aspects of deep learning and its applications in bird song recognition, it doesn't explicitly mention specific regularization methods used to prevent overfitting. 

However, based on general knowledge of deep learning, common regularization techniques to combat overfitting include:

* **Dropout:** Randomly "dropping out" (ignoring) a percentage of neurons during each training step. This prevents the network from relying too heavily on any single neuron and encourages the learning of more robust features.

* **L2 Regularization (Weight Decay):** Adds a penalty term to the loss function that is proportional to the square of the magnitude of the model's weights. This discourages the weights from becoming too large, effectively preventing overfitting.

Other regularization methods exist, such as L1 regularization and early stopping, but these two are most commonly used.