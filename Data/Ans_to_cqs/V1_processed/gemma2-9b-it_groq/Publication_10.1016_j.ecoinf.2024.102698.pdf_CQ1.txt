The provided context focuses on synthetic data generation and doesn't describe methods for collecting raw data used in deep learning pipelines.  

To answer your query, here are some common methods for collecting raw data used in deep learning:

* **Surveys:**  Structured questionnaires used to gather information from individuals.
* **Sensors:** Devices that collect data from the physical environment, such as temperature, pressure, or motion.
* **Public Datasets:** Collections of data made available by organizations or researchers for public use. These can cover a wide range of domains, from images and text to financial and medical data.
* **Web Scraping:**  Automatically extracting data from websites.
* **APIs:** Application Programming Interfaces allow developers to access and retrieve data from software applications and services. 


Let me know if you have other questions.