The provided text focuses on the training process of a Mask R-CNN model and details the loss functions used during training.  It doesn't specify the exact metrics used to evaluate the model's performance after training. 

Common metrics for evaluating object detection models like Mask R-CNN include:

* **Precision:**  Measures the proportion of correctly identified objects out of all objects predicted as positive.
* **Recall:**  Measures the proportion of correctly identified objects out of all actual objects.
* **mAP (mean Average Precision):**  A harmonic mean of precision and recall across different Intersection over Union (IoU) thresholds. It provides a more comprehensive evaluation of the model's performance. 
* **IoU (Intersection over Union):**  Measures the overlap between the predicted bounding box and the ground truth bounding box.


Let me know if you have other questions about the training process or Mask R-CNN.