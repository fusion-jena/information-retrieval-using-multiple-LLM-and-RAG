The text states that the training was completed in 96 hours per model using a GPU-cluster equipped with 4 RTX8000.  

Therefore, the hardware resource used for training the deep learning model is a GPU-cluster with RTX8000 GPUs.