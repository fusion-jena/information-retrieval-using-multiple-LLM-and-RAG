The text states that the model uses the Adam optimizer and trains for 100 epochs.  It also mentions using standard data augmentation techniques like shear, translation, and mirroring, but doesn't specify learning rate.