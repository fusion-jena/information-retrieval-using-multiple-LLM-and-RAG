The provided text mentions the following hyperparameters used in the deep learning model:

* **Learning rate:** 0.01
* **Momentum:** 0.18
* **Training iterations:** 500 


It also states that the XGBoost model allows tuning through hyperparameters like:

* **ntree:**  The number of decision trees.
* **Tree node size:** The minimum number of observations required to be at a terminal node.
* **Gradient boosting iteration:** The number of times the model iteratively increases or decreases weights in the training dataset. 


The text does not specify the optimizer used in the deep learning model.