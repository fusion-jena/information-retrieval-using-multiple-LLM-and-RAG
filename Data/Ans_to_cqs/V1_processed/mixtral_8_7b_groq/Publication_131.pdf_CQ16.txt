The criteria used to determine when training is complete for the Convolutional Neural Network (CNN) used in the classification of five types of sound is not explicitly stated in the provided context. However, it can be inferred that the training process for the two networks was carried out for a fixed number of epochs, which is a common criterion for determining the end of training.

The first network was trained for 16 epochs, and the second network was trained for six epochs. An epoch is defined as one complete pass through the entire training dataset. Additionally, a batch size of 32 was used for both networks, which refers to the number of samples utilized in one training iteration.

Moreover, the initial learning rate with 0.001 and the "adam" optimizer were used for the training process of both networks. The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. The "adam" optimizer is an optimization algorithm that can be used to update the weights of the neural network based on the estimated error.

Furthermore, the performance of the CNN was evaluated based on the success rate for both the training and test data. The training data had a success rate of 94.54%, while the test data had a success rate of 96.2%. The confusion matrix obtained for the test data showed that the errors were distributed among the five different classes, with the highest error percentage of 9.09% for the Epidalea calamita class with amplexus vocalization.

Therefore, while the specific criteria used to determine when training is complete for the CNN is not explicitly stated in the provided context, it can be inferred that the training process was carried out for a fixed number of epochs, and the performance of the CNN was evaluated based on the success rate for both the training and test data.