Based on the provided context, there is no explicit information about the optimization techniques used in a deep learning pipeline, such as Stochastic Gradient Descent (SGD) or Adam. The text mainly discusses text mining methods associated with social media, including topic modeling and emotional analysis.

Topic modeling techniques like Latent Dirichlet Allocation (LDA) and social network analyses are mentioned. LDA is a traditional topic modeling algorithm, while social network analyses help capture potential interrelationships between different keywords and divide them into closely related communities. However, these techniques pertain more to natural language processing and text mining rather than optimization techniques in deep learning pipelines.

In the context of deep learning, optimization techniques are crucial for minimizing the loss function and finding the best set of weights and biases during training. Common optimization techniques include Stochastic Gradient Descent (SGD), Adam, RMSprop, and Adagrad. These methods are used to update the parameters of the model based on the gradient of the loss function.

In conclusion, while the provided context offers valuable insights into text mining methods associated with social media, it does not mention any optimization techniques used in deep learning pipelines, such as SGD or Adam.