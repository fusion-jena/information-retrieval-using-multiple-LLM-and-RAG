The text provided gives some insight into the measures taken to ensure the generalizability of the deep learning model, but it does not explicitly mention the techniques of cross-validation or stratified splitting. However, it does mention the creation of a diverse dataset as a measure taken to improve the model's ability to generalize.

To address the issue of an imbalanced training dataset, the researchers ensured that the dataset contained a diverse range of images for each class. For instance, for the sociable weavers, over 350 pictures were used for the majority of the individuals, while 1,600 images were used for each zebra finch. This oversampling of the minority class helps to prevent the model from over-generalizing to the majority class.

Furthermore, the researchers used a small batch size during training, which has been shown to improve a model's generalization capability. Specifically, if there was no increase in loss for more than 10 consecutive epochs, the training would stop, and the model that achieved the lowest loss would be retrained with a SGD optimizer and a learning rate 10 times smaller.

Additionally, the researchers suggest continuously collecting training pictures and routinely retraining the CNN using updated training data. This approach allows the model to learn from new data, which can help improve its generalizability to new, unseen data.

Finally, the researchers mention the importance of photographing animals across different times of the day and in various conditions to capture the broad range of contexts that the CNN is required for. This approach helps ensure that the training dataset contains sufficient variation to capture the range of contexts that the model will encounter in the real world.

In summary, while the text does not explicitly mention cross-validation or stratified splitting, it does mention the use of a diverse dataset, oversampling of the minority class, small batch sizes, continuous data collection and retraining, and the importance of capturing a broad range of contexts in the training dataset. These measures can help improve the generalizability of the deep learning model.