The provided context does not specify the exact metrics used to evaluate the performance of the deep learning model. However, it does mention that the model is used for forecasting ecological water demand and scenario analysis of oasis NDVI, which implies that the model's performance could be evaluated using metrics relevant to those tasks.

For instance, in the context of time series forecasting, common evaluation metrics include Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). These metrics measure the difference between the predicted and actual values, with RMSE being a popular choice due to its sensitivity to large errors.

In the context of scenario analysis or classification tasks, metrics such as accuracy, precision, recall, and F1 score may be used. Accuracy measures the proportion of correct predictions, while precision measures the proportion of true positives among all positive predictions. Recall, on the other hand, measures the proportion of true positives among all actual positives. The F1 score is the harmonic mean of precision and recall, providing a balanced assessment of both.

It's also worth noting that the context mentions the use of SHAP (SHapley Additive exPlanations) values for model interpretability analysis. While SHAP values themselves are not performance evaluation metrics, they can be used to gain insights into the feature importance and contributions to the model's predictions.

In summary, while the provided context does not explicitly state the performance evaluation metrics used for the deep learning model, it can be inferred that metrics relevant to time series forecasting, scenario analysis, or classification tasks could be used. Common metrics include MAE, MSE, RMSE, accuracy, precision, recall, and F1 score.