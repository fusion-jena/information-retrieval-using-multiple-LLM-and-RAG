In the context provided, two main strategies are mentioned for determining when training of a neural network model is complete: early stopping and monitoring validation loss.

The early stopping strategy involves tracking the generalization performance of the model during training. This is done by separating the training data into two sets: a training set and a validation set. Training is stopped when the generalization performance, as measured by the validation loss, starts to degrade for a number of epochs. This strategy helps to prevent overfitting, which occurs when the model performs well on the training data but poorly on unseen data.

Monitoring validation loss is another common approach for determining when training is complete. In this method, training continues until the validation loss plateaus or starts to increase, indicating that the model is no longer improving its performance on the validation set. This approach is based on the assumption that if the model's performance on the validation set stops improving, further training is unlikely to lead to better performance on unseen data.

It is important to note that the choice of criteria for determining when training is complete depends on the specific problem and dataset being used. In some cases, other criteria, such as training loss or performance on a separate test set, may be more appropriate. Ultimately, the goal is to find the right balance between training the model long enough to learn the underlying patterns in the data, while avoiding overfitting and wasting computational resources.

Another technique mentioned in the context for preventing overfitting is dropout, which is a regularization strategy that trains neural networks with alternative topologies in parallel by randomly dropping out a certain proportion of layer neurons. This helps to prevent overfitting by introducing noise into the model during training, which in turn helps to improve its generalization performance.

In summary, the criteria used to determine when training is complete include early stopping and monitoring validation loss. These strategies help to prevent overfitting and improve the model's generalization performance. Additionally, dropout is another technique that can be used to prevent overfitting and improve the model's performance.