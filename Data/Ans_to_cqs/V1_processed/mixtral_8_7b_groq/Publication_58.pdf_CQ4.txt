Based on the provided context, there is no explicit mention of specific data augmentation techniques such as flipping, rotating, or scaling that were applied in the deep learning pipeline. Data augmentation is a common technique used to increase the size and diversity of training datasets in deep learning, and it can include methods like flipping, rotating, and scaling images. However, the context does not provide information on whether these specific techniques were used.

The context does mention that the neural networks were trained using stochastic gradient descent with a momentum of 0.9 and an initial learning rate of 10âˆ’2, which was then gradually decreased every 20 epochs. It also mentions that the data was preprocessed by masking clouds and shadows in the satellite images.

In addition, the context discusses the use of balanced datasets for training the neural networks, particularly in the case of "central-pixel labeling" architectures. However, it does not mention any data augmentation techniques that were used to create these balanced datasets.

Therefore, while data augmentation is a common technique used in deep learning, the specific data augmentation techniques used in this study are not mentioned in the provided context.