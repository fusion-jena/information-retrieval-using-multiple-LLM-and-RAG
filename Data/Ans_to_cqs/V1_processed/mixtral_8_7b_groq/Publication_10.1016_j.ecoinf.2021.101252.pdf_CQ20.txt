The specific hardware resources used for training the deep learning models in the case studies provided are not explicitly mentioned. However, it is suggested that faster hardware, such as GPUs (Graphics Processing Units), TPUs (Tensor Processing Units), and large-resourced cloud computing services, could be employed to handle the computational demands and expenses of deep learning, particularly when applied to image data. This implies that these types of hardware were potentially used or at least considered for training the deep learning models discussed in the case studies.