The provided context does not give specific information about the criteria used to split the data for training the deep learning model. However, it can be inferred that the data was split into a training set and a validation set, as the model's performance was monitored and validated on a portion of the dataset during the experiments.

In general, when training deep learning models, it is common to split the data into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune the hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

The splitting criteria can vary depending on the size and nature of the dataset. A common approach is to use 60-20-20 or 70-15-15 splits for the training, validation, and testing sets, respectively. However, it is important to ensure that the splits are representative of the entire dataset and do not introduce bias.

In some cases, cross-validation may be used to further improve the model's performance and reduce the risk of overfitting. Cross-validation involves splitting the data into multiple folds, training the model on one fold, validating it on another fold, and repeating the process for all the folds. The final performance is then averaged across all the folds.

Overall, while the provided context does not give specific details on the data splitting criteria used in this study, it is a common practice in deep learning to split the data into training, validation, and testing sets to ensure the model's generalization and performance.