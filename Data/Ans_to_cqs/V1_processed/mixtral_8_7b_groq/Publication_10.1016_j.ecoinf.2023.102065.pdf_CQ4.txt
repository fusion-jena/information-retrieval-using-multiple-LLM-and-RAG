Based on the provided context, the data augmentation technique applied in the deep learning pipeline involves splitting the merged .wav training file for each species in half and then adding these two halves sample-wise. This augmented .wav file was then sliced into 2-second increments, and mel-spectrograms were computed.

The context does not explicitly mention other common data augmentation techniques such as flipping, rotating, or scaling, which are typically used for image data. In the case of sound data, time and frequency manipulations are more common for data augmentation. The technique described here, splitting the .wav file in half and adding the halves, can be considered a form of time-stretching or pitch-shifting, as it changes the duration of the original sound while keeping its pitch constant.

The authors chose this technique to regularize the model and provide more robust features, given the limited training data available. They also aimed to explore different network sizes in conjunction with pre-training with additional acoustic reference data from outside of their audio domain, followed by fine-tuning with ROI data from their study site.

In summary, the data augmentation technique applied in the deep learning pipeline involves time-stretching or pitch-shifting by splitting the .wav file in half and adding the halves. Other common data augmentation techniques such as flipping, rotating, or scaling, which are typically used for image data, are not mentioned in the context.