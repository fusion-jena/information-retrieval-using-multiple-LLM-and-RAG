The pieces of context provided do not directly answer the query regarding the optimization techniques applied in the deep learning pipeline. However, they do mention some studies and resources related to deep learning and remote sensing.

In the context of deep learning, Cohen and Shashua (2017) discussed the inductive bias of Deep Convolutional Networks through Pooling Geometry, but they did not mention any optimization techniques. Similarly, Petrovska et al. (2020) used deep learning for feature extraction in remote sensing, but they did not specify the optimization techniques used in their deep learning pipeline.

In general, optimization techniques such as Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), and others are commonly used in deep learning to minimize the loss function and improve the model's performance. These techniques are used to update the model's parameters during the training process.

Therefore, while the provided context does not answer the query directly, it is safe to assume that optimization techniques such as SGD, Adam, and others are used in the deep learning pipeline for training deep learning models.