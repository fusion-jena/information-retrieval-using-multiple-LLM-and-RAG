The provided context explains that for training a deep-learning classifier used in remote sensing, the convergence of training is determined by monitoring the validation data across training epochs. Specifically, the network weights with the best performance are kept, and early stopping criteria are applied if no improvement is found in 50 epochs. This suggests that a validation loss plateau is used as a criterion to determine when training is complete.

In addition, a systematic approach is used to generate samples for training, verification, and final independent testing. The verification sample is used to determine training convergence, while the test sample is used for independent assessment. The sample sets are created by collecting samples following a grid of sample blocks with a specific spacing, and assigning blocks as training, validation, and test. The majority of the samples are focused on training and verification to maximize model performance.

For random forest classifier development, a random search and grid-search are used to identify an optimal parameter set. Three-fold cross validation is used to compare 100 sets of parameters, and the results are refined using a grid-search with specific parameter ranges. However, the context does not provide information on how training convergence is determined for the random forest classifier.

In summary, the provided context suggests that for deep-learning classifier training in remote sensing, a validation loss plateau is used as a criterion to determine when training is complete. However, the context does not provide information on how training convergence is determined for the random forest classifier.