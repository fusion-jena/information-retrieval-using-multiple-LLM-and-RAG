The code repository for the deep learning pipeline was not explicitly mentioned in the provided context. However, it is mentioned that some model parameters were modified from the default configuration for training a deep learning model, and the training was done up to 6000 iterations. It is also mentioned that the annotations for training, validation, and testing datasets were generated manually using Biigle annotations. Therefore, it can be inferred that some form of code or script was used to perform these tasks.

The context mentions a GitHub link (<https://github.com/AlexeyAB/darknet>) which provides guidance by the developers. However, it is not clear if the code repository for the specific deep learning pipeline used in this study is available in this GitHub link.

Additionally, the context mentions that the study was conducted using Google Colaboratory, which is a free cloud service with GPU support for machine learning and deep learning tasks (Bisong, 2019). Therefore, it is possible that the code for the deep learning pipeline is stored in a Google Colab notebook, which may not be publicly available.

In conclusion, while the exact location of the code repository for the deep learning pipeline is not explicitly mentioned in the provided context, it is possible that it is available in a GitHub link or a Google Colab notebook. However, further information is required to confirm the location of the code repository.