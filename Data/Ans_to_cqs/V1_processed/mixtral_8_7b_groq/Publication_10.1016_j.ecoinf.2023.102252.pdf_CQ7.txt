Based on the provided context, there is no direct information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, I can provide some general insights into common practices for splitting data in machine learning.

In machine learning, it is common to split the dataset into three subsets: training, validation, and testing. These splits help ensure that the model can generalize well to unseen data and provide an unbiased estimation of the model's performance.

1. Training set: This is the portion of the data used to train the model. The model learns patterns from this data and adjusts its parameters accordingly.
2. Validation set: This set is used during the model training process to tune hyperparameters and prevent overfitting. Overfitting occurs when the model learns the training data too well, including its noise, and performs poorly on unseen data.
3. Testing set: After training and hyperparameter tuning, the testing set is used to evaluate the model's performance on unseen data. This evaluation provides an unbiased estimate of how well the model will perform on new, real-world data.

In the context of the provided text, the authors present the FERM output and validation data for 2009, which could be interpreted as a form of data splitting. They use 2009 data for validation, likely comparing the model's output to actual measurements or expected conditions. However, this specific instance does not necessarily reflect the general practices for splitting data in deep learning model training.

In summary, the provided context does not contain specific information on the criteria used to split the data for deep learning model training. However, common practices in machine learning include splitting the dataset into training, validation, and testing subsets for training, hyperparameter tuning, and performance evaluation, respectively.