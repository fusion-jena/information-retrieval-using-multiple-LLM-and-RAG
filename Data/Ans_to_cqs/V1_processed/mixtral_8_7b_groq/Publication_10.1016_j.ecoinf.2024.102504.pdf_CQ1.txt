The methods used for collecting raw data in the deep learning pipeline for air quality studies can include the use of sensors, satellite images, and public datasets.

In the study by Navares and Aznarte (2020), the authors used a deep learning Long Short-Term Memory (LSTM) model to predict air quality. They used public datasets consisting of air quality measurements collected by ground-based sensors. These sensors measure various air pollutants such as nitrogen dioxide (NO2), particulate matter (PM), and ozone (O3) at different locations and times.

Neckel et al. (2023) used a combination of self-made passive samplers and Sentinel-3b SYN satellite images to collect data on air pollution in Budapest. The passive samplers were used to measure the concentration of pollutants such as NO2, while the satellite images provided information on aerosol optical depth (AOD) and other atmospheric variables.

Ogen (2020) assessed the relationship between NO2 levels and COVID-19 fatality using public datasets of NO2 concentrations from ground-based sensors and COVID-19 mortality data.

In addition to ground-based sensors and satellite images, public datasets are also a valuable source of raw data for air quality studies. For example, the Copernicus Sentinel-5 Precursor satellite provides vertical column density (VCD) products for various air pollutants, including SO2, NO2, O3, HCHO, and CO (Costa et al., 2014). These VCD products can be used as input to deep learning models for air quality prediction.

Overall, the methods used for collecting raw data in the deep learning pipeline for air quality studies can include ground-based sensors, satellite images, and public datasets. The choice of method depends on the specific research question and the availability of data.