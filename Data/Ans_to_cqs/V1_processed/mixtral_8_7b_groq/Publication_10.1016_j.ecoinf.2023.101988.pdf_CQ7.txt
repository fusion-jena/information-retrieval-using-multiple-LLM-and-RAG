Based on the provided sources, there is no specific information given on the criteria used to split the data for deep learning model training (e.g., train, test, validation) in the context of unmanned aircraft systems, animal biodiversity modeling, or acoustic monitoring.

However, in general, there are common practices for splitting data in machine learning tasks, including deep learning. The data set is typically split into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

The exact criteria for splitting the data can vary depending on the specific use case, dataset size, and other factors. Common methods for splitting the data include:

1. Random splitting: The data is randomly divided into the three subsets with a predefined ratio (e.g., 70% for training, 15% for validation, and 15% for testing).
2. Stratified splitting: When the data is imbalanced or there are specific class distributions, the data can be split while preserving the same proportion of classes in each subset.
3. Time-based splitting: In time-series data, the data can be split based on time, using the earliest data for training, the middle part for validation, and the latest for testing.
4. K-fold cross-validation: The data is divided into 'k' subsets (folds). The model is trained 'k' times, each time using a different fold as the validation set and the remaining 'k-1' folds as the training set. The average performance across the 'k' runs is then calculated.

In the context of the provided sources, it is possible that any of these methods or a combination of them has been used for splitting the data. However, without specific information, it is not possible to provide a definitive answer.