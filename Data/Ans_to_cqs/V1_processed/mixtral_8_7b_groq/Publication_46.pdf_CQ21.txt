Based on the provided context, there are some details about the model validation process, but there is no explicit information about post-processing steps such as saliency maps or confusion matrix calculation after the model training. However, it is mentioned that the AUC (Area Under ROC Curve) is used for performance evaluation of species probability distribution.

The ROC curve is a plot of the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings [67]. The AUC provides a measure of the model's ability to distinguish between positive and negative classes. An AUC of 1 indicates a perfect classifier, while an AUC of 0.5 indicates a classifier no better than random guessing.

Therefore, based on the given context, it can be inferred that the post-processing steps involved after the model training include:

1. Model validation: The model's performance is evaluated using the AUC metric.
2. Threshold assessment: The ROC curve is used to assess the model performance at various discrimination thresholds.


After training the model for species distribution, the post-processing steps involved include model validation using the AUC (Area Under ROC Curve) metric and threshold assessment using the ROC curve. However, there is no explicit information about other post-processing steps such as saliency maps or confusion matrix calculation.