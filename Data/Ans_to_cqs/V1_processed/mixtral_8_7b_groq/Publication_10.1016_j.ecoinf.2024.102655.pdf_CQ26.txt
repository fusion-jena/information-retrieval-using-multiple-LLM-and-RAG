Based on the provided context, there is no explicit mention of the techniques used to address data bias during the pre-processing of a deep learning pipeline. The text describes the use of outlier detection and artificial data replacement in the pre-processing stage. However, these techniques are not directly related to addressing data bias.

In outlier detection, unusual data points that deviate significantly from the rest of the data are identified and replaced with artificial data. This process can help improve the quality of the data by removing or correcting erroneous measurements. However, it does not necessarily address data bias.

Data bias can occur when the data used to train a machine learning model is not representative of the population the model is intended to make predictions about. This can lead to inaccurate or biased predictions. To address data bias, techniques such as stratified splitting, oversampling, undersampling, and diverse data collection can be used.

Stratified splitting involves dividing the data into subgroups based on certain characteristics, such as age, gender, or race, and then randomly sampling from each subgroup to ensure that the training and testing sets are representative of the overall population.

Oversampling and undersampling are techniques used to adjust the class distribution in imbalanced datasets. In oversampling, instances of the minority class are duplicated to match the number of instances in the majority class. In undersampling, instances of the majority class are removed to achieve a balanced class distribution.

Diverse data collection involves collecting data from a variety of sources and ensuring that the data is representative of the population. This can help reduce data bias by ensuring that the training data is diverse and includes a wide range of characteristics.

In summary, while the provided context does not explicitly mention the techniques used to address data bias during pre-processing, techniques such as stratified splitting, oversampling, undersampling, and diverse data collection can be used to address data bias in a deep learning pipeline.