The strategy implemented to monitor the model performance during training in the study is five-fold cross-validation. This strategy involves dividing the dataset into five subsets or folds, where four folds are used for training the model, and the remaining fold is used for testing the model. This process is repeated five times, with each of the five folds used once as the test set. The performance of the model is then evaluated based on the average performance across the five folds.

In addition to cross-validation, the study also used several other techniques to monitor the model performance during training. These techniques include using two optimization techniques, transfer learning, and data augmentation. Transfer learning involves using a pre-trained model as a starting point for training the model on a new dataset. Data augmentation involves increasing the size of the dataset by applying various transformations to the existing images, such as rotation, scaling, and flipping. These techniques help to reduce the requirement of a large dataset for model training and improve the performance of the CNN-based models.

Furthermore, the study used the F1-measure as a metric to evaluate the model performance during training. The F1-measure is a harmonic mean of precision and recall, which takes into account both false positives and false negatives. This metric is particularly useful for imbalanced datasets, where one class may have significantly more samples than the other class.

Overall, the study implemented a comprehensive strategy to monitor the model performance during training, including cross-validation, optimization techniques, transfer learning, data augmentation, and F1-measure. These techniques helped to ensure that the model was accurately estimating the tree cover in drylands.