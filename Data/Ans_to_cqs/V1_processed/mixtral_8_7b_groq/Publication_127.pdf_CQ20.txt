The context provided does not include specific information about the hardware resources used for training the deep learning models. However, it is common in deep learning training to use Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) to accelerate the computations. These specialized hardware components are designed to handle the massive parallelism required in deep learning algorithms, making the training process faster and more efficient than using only CPUs. Therefore, while the text does not explicitly mention the use of GPUs or TPUs, it is safe to assume that they were used during the training of the deep learning models mentioned in the table.