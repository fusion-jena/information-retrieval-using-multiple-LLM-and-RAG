The provided context does not explicitly mention the data annotation techniques used in the deep learning pipeline. However, it discusses a deep learning-based framework for point cloud data processing and semantic segmentation.

In this framework, the initial step is to compute the geometric partition of the point cloud data. This partitioning is based on hand-crafted rules, creating partitions that are then converted into superpoints. These superpoints serve as the input for a PointNet network, which performs superpoint embedding and segmentation.

The context discusses the impact of the geometric partition on the semantic segmentation results. Different partition results can lead to varied superpoint graphs, influencing the neural network input. However, it does not specify the data annotation techniques used.

The annotation techniques for point cloud data can include:

1. Point-wise annotation: Labeling each point in the point cloud with a class label.
2. Semantic segmentation: Segmenting the point cloud into regions belonging to different classes.
3. Instance segmentation: Segmenting the point cloud into individual objects or instances, assigning a class label to each instance.
4. Object detection: Identifying and locating objects within the point cloud using bounding boxes or other shape representations.

Based on the provided context, it can be inferred that the deep learning pipeline involves semantic segmentation of point cloud data. However, the specific data annotation techniques are not mentioned.