The context provided does not explicitly mention the criteria used to split the data for training the deep learning model. However, it does mention the use of K-fold cross-validation for evaluation. In K-fold cross-validation, the dataset is divided into K subsets or folds. The model is trained on K-1 folds while one fold is held back for validation. This process is repeated K times, each time with a different fold used for validation. The final result is the average of the results from the K iterations. This method is used to make better use of the available data and to reduce the risk of overfitting. However, it does not replace the need for a separate test set to evaluate the model's performance on unseen data. Therefore, it can be inferred that the data was likely split into training, validation, and test sets, but the specific criteria are not provided in the context.