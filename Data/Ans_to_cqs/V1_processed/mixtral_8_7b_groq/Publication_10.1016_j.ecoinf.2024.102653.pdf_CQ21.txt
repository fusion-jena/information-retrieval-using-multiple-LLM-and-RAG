Based on the provided context, there are several postprocessing steps that are conducted after the model training. However, the text does not explicitly mention saliency maps. Therefore, I will focus on the other postprocessing steps.

First, the model's performance is evaluated using various metrics. These metrics include accuracy, recall, precision, F1-score, Cohen Kappa, and the area under the ROC curve. The confusion matrix is also used, which is a table that is often used to describe the performance of a classification model. It summarizes the number of false positives, false negatives, true positives, and true negatives.

The model's hyperparameters are manually tuned to achieve optimal performance. The selected hyperparameters include the optimizer (ADAM), learning rate (0.003), batch size (32), epochs (100), dropout rate (0.5), and loss function (Binary Cross Entropy).

The model's weights are randomly initialized using a specific integer seed to ensure consistent reproducibility of results.

Two distinct validation methodologies are implemented. The first method involves partitioning the dataset into training and validation sets, with 70% of the data designated for training and 30% for validation. This division is performed through random selection. The second method involves assessing the number of recordings necessary to yield satisfactory classification metrics. The model is trained using varying disjoint subsets of the dataset, which correspond to different time steps (5, 10, 15, 20, and 25 days of flight activity recordings). Subsequent experiments include training the model with various combinations of datasets (1, 2, 3, or all four datasets combined).

Therefore, the postprocessing steps involved after the model training include the calculation of various performance metrics, manual tuning of hyperparameters, random initialization of weights, and validation using distinct methodologies.