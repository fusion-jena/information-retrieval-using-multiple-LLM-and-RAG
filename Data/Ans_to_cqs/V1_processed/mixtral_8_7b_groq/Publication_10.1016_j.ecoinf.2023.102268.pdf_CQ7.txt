The labeled dataset was split into training and testing datasets in a 70/30 ratio for the deep learning model. Additionally, 50% of the training data was held-out for validation purposes. This process is known as train-test-validation split, which is a common practice in machine learning to assess the performance and generalization of the model. The training dataset is used to train the model, the validation dataset is used to fine-tune the model's parameters and prevent overfitting, and the test dataset is used to evaluate the model's performance on unseen data.

In the given context, the labeled dataset was used to train a Support Vector Machine (SVM) classifier with a cubic polynomial kernel. The ResNet-50 fc1000 activations of the full training dataset were used as features for the SVM classifier. A 10-fold cross-validation was then used to define the score-to-posterior-probability transformation function, which provides a basis for estimating the posterior probability for new observations.

The data splitting criteria are not explicitly mentioned in the provided context, but it can be inferred that the dataset was split randomly as there is no mention of any specific criteria for splitting the data. Random splitting of the data is a common practice in machine learning to ensure that the model is not biased towards any particular subset of the data.

Therefore, it can be concluded that the data was split randomly in a 70/30 ratio for training and testing, and 50% of the training data was held-out for validation purposes.