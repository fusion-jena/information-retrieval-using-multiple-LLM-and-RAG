The provided context does not give specific information about the methods used for collecting raw data in the deep learning pipeline. However, it mentions that digitization efforts are being made to compile specimen data and images in natural history collections (NHCs), which are then used in conjunction with deep convolutional neural networks (CNNs) for image classification.

In general, raw data for deep learning pipelines can be collected through various methods, including but not limited to:

1. Surveys: Collecting data through questionnaires or interviews to gather information from a large number of people or organizations.
2. Sensors: Using sensors to collect data from the environment, such as temperature, humidity, or pressure sensors.
3. Public datasets: Using publicly available datasets, such as those provided by government agencies or research institutions, to train deep learning models.
4. Private datasets: Collecting data through proprietary means, such as through a company's internal data collection processes or through partnerships with other organizations.

In the context of NHCs, raw data might include images of specimens, as well as metadata such as the specimen's taxonomic classification, geographic location, and collection date. These data would then be used to train a deep learning model, such as a CNN, to classify new specimen images based on their features.

It's worth noting that the process of collecting and preparing raw data for deep learning can be time-consuming and resource-intensive. Data preprocessing steps, such as cleaning, normalization, and augmentation, are often necessary to ensure that the data are in a suitable format for training a deep learning model. Additionally, ethical considerations, such as obtaining informed consent from survey participants or ensuring the privacy and security of sensitive data, must be taken into account when collecting raw data for deep learning.