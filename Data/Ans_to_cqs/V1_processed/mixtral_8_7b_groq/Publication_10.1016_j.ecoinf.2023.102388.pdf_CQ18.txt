In the given context, the strategy to monitor the model performance during training is not explicitly stated. However, it can be inferred that the performance of the target model is evaluated using two separate sets: the validation set and the target test set.

During the training process, the target model is trained using the training set, Dtrain, and the learning algorithm A. Concurrently, an attack model is trained using a separate attack dataset, DS, which is drawn from the same data distribution as the training samples in Dtrain. The attack model is trained to mimic the behavior of the target model.

Once the training of the target model is complete, its performance is evaluated using the validation set. The validation set is used to validate the hyper-parameters of the target model. This step helps to ensure that the model is not overfitting to the training data, which is a common issue in machine learning models. Overfitting occurs when the model performs well on the training data but generalizes poorly on unseen samples, and it can make the model more vulnerable to privacy attacks.

Furthermore, the target model's performance is also assessed using the target test set, which is composed of non-member individuals never seen before by Dtrain and DS. This step provides an unbiased estimate of the model's performance on unseen data, which is crucial for evaluating the model's ability to generalize to new data.

Therefore, while the specific strategy to monitor the model performance during training is not mentioned, it can be inferred that the validation and target test sets are used to evaluate the model's performance and prevent overfitting.