Based on the provided context, there is no explicit information about the specific postprocessing steps applied after the model training process. However, it does mention that the performance of the models was evaluated using metrics such as Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and R-squared (R2). It also mentions the use of a confusion matrix through the Wilcoxon Signed-Rank test with paired samples, which was used to test the differences between the RMSEs of different models.

In general, postprocessing steps in machine learning models can include various methods for evaluating model performance, interpreting model results, and gaining insights into the model's decision-making process. Some common postprocessing steps include:

1. Metrics calculation: This involves calculating various metrics such as accuracy, precision, recall, F1 score, RMSE, MAE, R2, etc., to evaluate the performance of the model.
2. Confusion matrix: This is a table that is often used to describe the performance of a classification model. It summarizes the number of false positives, false negatives, true positives, and true negatives.
3. Saliency maps: These are visualizations that highlight the important features in the input data that the model used to make its predictions.
4. Model interpretability: This involves gaining insights into the model's decision-making process, understanding which features are most important, and identifying any biases or weaknesses in the model.

Based on the context provided, it seems that the postprocessing steps in this study primarily involved calculating metrics such as RMSE, MAE, and R2, and using a confusion matrix to test the differences between the RMSEs of different models. However, there is no explicit mention of saliency maps or model interpretability.