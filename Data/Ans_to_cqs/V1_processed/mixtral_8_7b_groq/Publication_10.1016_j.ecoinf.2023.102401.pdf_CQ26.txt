The provided context does not include specific information about techniques used to address data bias during preprocessing in the deep learning pipeline. It discusses the architecture of YWnet, including the backbone, SPPF block, CRFPN, and head portions, as well as data augmentation techniques used to expand the dataset.

Data augmentation techniques, such as HSV adjustment, rotation, scaling, cropping, flipping, and mosaicking, are mentioned in the context. However, these techniques are mainly used to increase the size and diversity of the training dataset, rather than addressing data bias.

To directly answer the query, the following techniques can be used to address data bias during preprocessing:

1. Stratified splitting: This technique involves dividing the dataset into subgroups based on specific criteria (e.g., class labels) and then ensuring that each subset is proportionally represented in the training, validation, and test sets. This helps maintain the balance and representation of various classes in the dataset.

2. Oversampling: When certain classes are underrepresented in the dataset, oversampling can be used to increase the number of instances from these classes. This can be done by duplicating existing instances or generating synthetic samples using techniques like SMOTE (Synthetic Minority Over-sampling Technique).

3. Undersampling: Conversely, when certain classes are overrepresented in the dataset, undersampling can be used to reduce the number of instances from these classes. This can be done by randomly selecting a subset of instances from the majority class or using more advanced techniques like Tomek links or Edited Nearest Neighbors.

4. Diverse data collection: Collecting a diverse dataset with balanced representation from various sources, demographics, and scenarios can help minimize data bias. This involves being mindful of potential sources of bias during data collection and ensuring that the dataset is representative of the target population.

In summary, the provided context does not discuss techniques used to address data bias during preprocessing. However, strategies like stratified splitting, oversampling, undersampling, and diverse data collection can be employed to tackle data bias in deep learning pipelines.