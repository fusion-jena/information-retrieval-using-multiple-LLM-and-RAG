The criteria used to determine when training is complete in machine learning models is often based on the validation loss plateauing or stopping to decrease significantly. This means that the model has reached a point where additional training is not improving its ability to accurately predict or classify new data.

In the context of insect classification on sticky plate images, the researchers validate their model's performance by splitting the data on the sticky plate level. This means that individual insects that belonged to the same sticky plate image are kept together in the same dataset (training, validation, or testing). This approach allows the model to predict a class for any given object it detects on unseen sticky plate images, emulating the way the model will be used in practice.

The researchers emphasize the importance of using a strong validation procedure, such as data splitting on the sticky plate level, to avoid overestimating the model's performance. They have previously shown that model performance can be highly overestimated when weak validation procedures, like random data splitting, are used.

When it comes to determining when training is complete, the researchers likely monitor the validation loss throughout the training process. If the validation loss stops decreasing or plateaus, even if it is still higher than the training loss, this is an indication that the model has learned enough from the training data and further training is unlikely to improve its performance.

It's important to note that the provided context does not explicitly mention the criteria used to determine when training is complete. However, based on common practices in machine learning, it can be inferred that the researchers likely use the validation loss plateauing as an indicator that training is complete.