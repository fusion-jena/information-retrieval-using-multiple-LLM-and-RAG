Based on the information provided, while the specific method of hyperparameter optimization (such as grid search or random search) is not explicitly mentioned, we can infer that a manual hyperparameter search was performed for both the Support Vector Classification (SVC) model and the ridge regression model.

For the SVC model, the C value was explored in the interval [0.001, 1], and the hyperparameter value chosen was C = 0.1. This search resulted in a hyperparameter value that led to a model with a high level of performance.

Similarly, for the ridge regression model, α values were explored in the interval [0.1, 19.6]. The performance of the model was found to be robust for α values in the range of 5 to 15, and a value of α = 6.0 was chosen for the experiments.

In addition, for the linear regression model, L2 regularization values (α) were considered in the range {0.1, 0.6, 1.1, ..., 19.1, 19.6}. The resulting accuracy of the model was observed to be stable for α values in the interval [5.0, 15.0].

Lastly, for the classification model, C values (regularization parameter) were considered in the range {0.001, 0.006, 0.011, ..., 0.996, 1.001}. The resulting accuracy of the model was presented, but the specific method of hyperparameter optimization was not specified.

In conclusion, while the specific method of hyperparameter optimization is not explicitly stated, it can be inferred that a manual hyperparameter search was performed for both the SVC and ridge regression models.