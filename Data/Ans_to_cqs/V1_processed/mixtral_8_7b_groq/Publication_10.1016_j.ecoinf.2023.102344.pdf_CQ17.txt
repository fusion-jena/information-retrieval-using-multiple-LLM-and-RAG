Based on the provided context, there are no specific regularization methods such as dropout or L2 regularization mentioned in relation to preventing overfitting in the deep learning pipeline. However, the context does discuss the use of pre-trained models, which can help mitigate overfitting by providing a good starting point for learning from a limited amount of data.

In Approach 2, all pre-trained models underwent training for 1000 epochs using the Stochastic Gradient Descent with Momentum (SGDM) optimization algorithm. While the context does mention that Adaptive Moment Estimation (ADAM) was initially used but subsequently discarded due to converging on a sharp minimum resulting in negligible accuracy, this is not a regularization method.

Therefore, based on the provided context, no specific regularization methods to prevent overfitting in the deep learning pipeline are mentioned.