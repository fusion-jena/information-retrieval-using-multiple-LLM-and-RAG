The hyperparameters used in the deep learning model are as follows:

1. Fine-tuning of the pretrained CNN backbone was performed using the Adam optimizer. The learning rate for the Adam optimizer was initialized to 0.0001, and a weight decay of 0 was used.
2. The experiments were conducted in Pytorch on 8 NVIDIA GeForce RTX 2080 Ti GPUs.
3. Fine-tuning was performed on the entire model for 100 epochs, with one epoch corresponding to 500 episodic tasks.
4. Two episodic tasks were constructed from the training set with 5 way-1 shot and 5 way-5 shot tasks.
5. The latent space representations were finally extracted from the backbone of the model to evaluate their capacity to improve the quality of clustering.

These are the hyperparameters that were used during the fine-tuning of the pretrained CNN backbone. The optimizer used was Adam with a learning rate of 0.0001 and a weight decay of 0. The experiments were conducted on 8 NVIDIA GeForce RTX 2080 Ti GPUs for 100 epochs, where each epoch consisted of 500 episodic tasks. The episodic tasks were constructed from the training set with 5 way-1 shot and 5 way-5 shot tasks. The latent space representations were then extracted from the backbone of the model for evaluating the quality of clustering.