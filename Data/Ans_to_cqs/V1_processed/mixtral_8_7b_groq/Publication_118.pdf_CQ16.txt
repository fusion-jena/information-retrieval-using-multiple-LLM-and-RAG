The provided context does not give specific information about the criteria used to determine when training is complete in the study. However, it is mentioned that the research involves training auto-encoders, and one of the figures shows the structure of an auto-encoder. In general, for auto-encoders and other neural networks, training is often stopped when the validation loss plateaus or stops decreasing, indicating that the model has learned the underlying patterns in the training data and is not overfitting. This is typically determined using a validation set that is separate from the training set. Additionally, early stopping techniques can be used to halt training if the validation loss does not improve for a certain number of epochs. However, without access to the full study, it is not possible to provide a definitive answer.