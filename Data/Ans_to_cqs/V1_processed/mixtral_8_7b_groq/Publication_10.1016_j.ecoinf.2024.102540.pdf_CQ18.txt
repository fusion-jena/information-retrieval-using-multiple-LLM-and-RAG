The strategy implemented to monitor the model performance during training involves the use of evaluation metrics, specifically precision, mean average precision (mAP@0.5), recall, and mean percent error of misdetection. These metrics are common in evaluating detector models. Precision is the percentage of correct positive predictions, mAP@0.5 measures the accuracy of object detection models using an Intersection-over-union measure set to 0.5, recall shows how successfully a model can make correct detection predictions out of all the predictions it should make, and the mean percent error of misdetection provides an overall measure of the model's performance. 

In addition, the training process involves splitting the dataset into three parts: training, validation, and testing sets, with a ratio of 80:10:10 respectively. This ratio was chosen due to prior evidence of exceeding performances in detecting small insects and diseases using deep learning models. The training dataset consisted of 1543 images for the 640 × 640 pixels input resolution and 1637 images for the 1280 × 1280 pixels input resolution. 

The model's performance was monitored throughout the training process, which consisted of 400 epochs, determined as the optimal number after computational experiments with different combinations of epochs and batch sizes. The batch size, defined as the number of samples to be worked through before moving on to update the internal model parameters, was set to 8. The epoch number used in training determines the number of times the detection model processes the dataset dedicated to training the model. 

The training was conducted using five different versions of the YOLOv5 model family, including YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x models, to detect alates on sorghum leaves. The model's performance was evaluated after each epoch, and the best model was selected based on the evaluation metrics. 

Furthermore, a web application was created and deployed to allow researchers and stakeholder users to interact and use the best trained model to detect alates on sorghum leaves. This application allows a user to upload images of sorghum leaves, and the model processes the images within the backend of the application. The model's performance is monitored in real-time through the application, providing users with accurate and reliable results.