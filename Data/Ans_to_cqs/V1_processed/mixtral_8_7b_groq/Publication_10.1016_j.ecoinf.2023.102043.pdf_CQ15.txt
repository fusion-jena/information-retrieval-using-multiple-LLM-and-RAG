The provided context does not give specific information about the optimization techniques used in the deep learning pipeline with YAMNet. However, it is mentioned that the YAMNet model is a pre-trained deep neural network that follows the MobileV1 convolution architecture and is trained on the AudioSet-YouTube corpus. The model is used for extracting embeddings from audio data that has been preprocessed and passed through a sequential and reduce mean layer mapping to the classes of interest.

Therefore, it can be inferred that the optimization techniques were applied during the initial training of the YAMNet model on the AudioSet-YouTube corpus. Common optimization techniques used in deep learning include Stochastic Gradient Descent (SGD), Adam, RMSprop, and Adagrad. It is likely that one or more of these techniques were used during the training of YAMNet. However, the specific optimization technique used is not mentioned in the provided context.