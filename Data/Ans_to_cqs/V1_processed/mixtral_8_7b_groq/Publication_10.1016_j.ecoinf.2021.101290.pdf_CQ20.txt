Based on the provided context, the specific hardware resources used for training the deep learning model are not explicitly mentioned. However, it is mentioned that off-the-shelf components like PCs and graphics cards were used to build the system. Given that deep learning models typically require significant computational power, it is reasonable to assume that the PCs used in the system were equipped with GPUs (Graphics Processing Units) or possibly TPUs (Tensor Processing Units), which are specialized hardware for machine learning tasks.

Moreover, the paper by Kovalev et al. (2016) compares different deep learning frameworks in terms of speed and accuracy, implying that the authors have considered the computational performance of deep learning models. Therefore, it is plausible that the system described in the paper includes hardware resources optimized for deep learning training.

In summary, while the specific hardware resources used for training the deep learning model are not explicitly stated in the provided context, it can be inferred that the system likely includes GPUs or TPUs due to the computational demands of deep learning models and the authors' consideration of computational performance.