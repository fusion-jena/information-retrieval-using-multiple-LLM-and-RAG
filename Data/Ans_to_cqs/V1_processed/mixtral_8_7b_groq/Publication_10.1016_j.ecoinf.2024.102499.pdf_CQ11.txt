Unfortunately, the provided context does not include information about the data repository link of the deep learning pipeline. The text describes the methods used to create and train the deep learning models, including the NASnet architecture, Faster-rcnn backbone, Tensorflow2 implementation, and the use of the COCO dataset for pre-training. It also mentions that two types of datasets were assembled, one of which is annotated with the number of annotations per species and details on the number of frames and video clips in which each species appeared. However, there is no information about where these datasets or the deep learning pipeline can be found or accessed. Therefore, I cannot provide a specific link to a data repository such as Zenodo, Figshare, Dryad, or GBIF.