The hyperparameters used in the deep learning models for Finnmark and Yamal are as follows:

1. Model Architecture: The ResNet-50 architecture, a convolutional neural network that is 50 layers deep, was used to train the models.

2. Number of Epochs: The models were trained with 55 epochs, which is the number of times the algorithm goes through the entire training data set.

3. Batch Size: The batch size was set to 64, which is the number of samples worked through before updating model parameters.

4. Learning Rate: A one-cycle learning rate policy was used with a minimum of 0.000001 and a maximum of 0.001. The learning rate is a hyperparameter that controls the model's response to the estimated error each time the model weights are updated.

5. Optimizer: Although not explicitly mentioned, the "caret" R package definitions suggest that the models might have been optimized using a binary cross-entropy loss function, which is typically used for two-class classification problems.

It is important to note that separate two-class models were trained for Finnmark and Yamal, as preliminary trials showed that region-specific models performed better. The performance of these models on the test data is presented in Table 5, with precision, recall, and F1 score metrics calculated for both 'Bad' and 'Good' image categories in each location.