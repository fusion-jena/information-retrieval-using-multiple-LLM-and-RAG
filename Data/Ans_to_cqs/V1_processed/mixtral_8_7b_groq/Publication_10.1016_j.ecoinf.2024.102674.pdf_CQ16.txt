The provided context does not give specific information about the criteria used to determine when training is complete for the models mentioned. However, it does give details about the models used, such as Random Forests (RFs), Gradient Boosting Machines (GBMs), Generalized Additive Models (GAMs), and Artificial Neural Networks (ANNs).

In general, machine learning models require a stopping criterion to prevent overfitting and ensure optimal performance. Common methods include:

1. Validation Loss Plateau: Training stops when the validation loss (e.g., cross-entropy or mean squared error) does not decrease for a certain number of epochs or iterations.

2. Early Stopping: Training stops when the performance on a validation set starts to degrade, even if the training loss is still decreasing.

3. Monitoring Other Metrics: Training can be stopped based on other metrics, such as accuracy, precision, or recall, if they reach a satisfactory level or stop improving.

4. Patience: Training stops if the model does not improve for a predetermined number of iterations, regardless of the specific metric.

For RFs, training typically stops when the specified number of trees is reached. However, some implementations might include an optional early stopping criterion based on out-of-bag error.

For GBMs, the context specifies using a maximum of 10,000 trees with shrinkage and interaction parameters set to 0.01 and 1, respectively. However, it does not mention a specific stopping criterion. In practice, GBMs can be stopped based on a validation set's performance or when the improvement in performance is below a predetermined threshold.

For GAMs and ANNs, the context does not provide enough information to determine the specific stopping criterion. In general, GAMs can be stopped based on the F statistics of the predictors, while ANNs can use various early stopping techniques based on validation set performance.

In summary, while the provided context does not explicitly mention the criteria used to determine when training is complete, it is common practice to use validation loss plateau, early stopping, monitoring other metrics, or patience as stopping criteria for machine learning models.