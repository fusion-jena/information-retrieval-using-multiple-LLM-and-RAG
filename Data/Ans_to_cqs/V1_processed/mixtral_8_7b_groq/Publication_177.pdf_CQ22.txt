The performance of the deep learning models in the study was evaluated using several metrics, including accuracy, sensitivity, specificity, precision, and F1-score. These metrics are based on the number of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions made by the models.

Accuracy is the ratio of the number of correct predictions to the total number of predictions made by the model. However, since one of the datasets used in the study was imbalanced, accuracy alone would not be a sufficient metric for evaluating the model's performance. Therefore, other metrics were also used.

Sensitivity, also known as recall, is the ratio of the number of true positive predictions to the total number of actual positive instances in the dataset. It measures the model's ability to correctly identify positive instances.

Specificity is the ratio of the number of true negative predictions to the total number of actual negative instances in the dataset. It measures the model's ability to correctly identify negative instances.

Precision is the ratio of the number of true positive predictions to the total number of positive predictions made by the model. It measures the model's accuracy in predicting positive instances.

F1-score is the harmonic mean of precision and recall, which provides a balanced measure of the model's performance in predicting both positive and negative instances.

These evaluation metrics are represented by equations 1-5 in the study, where TP is the number of true positive predictions, TN is the number of true negative predictions, FP is the number of false positive predictions, and FN is the number of false negative predictions.

The deep learning models used in the study were initialized with pre-trained ImageNet weights and fine-tuned to the datasets. The optimization of network hyperparameters was performed using Bayesian optimization, which optimized the network for batch size and initial learning rate.

The performance metrics for all models for both UBD_45 and VP_200 datasets are presented in Tables I and II, respectively. The specificity values for all models for both datasets were found to be above 99%, indicating that the models were able to highly correctly identify negative instances.

Therefore, the study used a range of evaluation metrics to assess the performance of the deep learning models, taking into account the imbalanced nature of one of the datasets. The optimization of network hyperparameters using Bayesian optimization helped to further improve the models' performance.