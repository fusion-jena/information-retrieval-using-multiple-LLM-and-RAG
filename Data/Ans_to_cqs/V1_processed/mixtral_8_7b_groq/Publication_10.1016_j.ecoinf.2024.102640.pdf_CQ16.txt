The context does not provide specific information about the criteria used to determine when training is complete for the EPDNet model. However, it mentions that the R2 metric is used to assess the model's fit to the observed data after training, and the value of R2 is 0.95, indicating a good fit.

In general, training of deep learning models is often stopped based on validation loss plateau or convergence. That is, if the model's performance on a validation set stops improving or remains consistent for a certain number of epochs, training is stopped to prevent overfitting. Additionally, early stopping can be used to halt training if the validation loss starts to increase, indicating that the model is overfitting to the training data.

Moreover, learning rate scheduling can also be used to adjust the learning rate during training, allowing the model to converge to a better minimum. The learning rate can be reduced by a certain factor when the validation loss does not improve for a certain number of epochs.

In the case of EPDNet, the training used the Mean Squared Error (MSE) loss function and the Adam optimizer with a learning rate of 0.0001. However, the context does not provide information on whether validation loss plateau or convergence was used as a criterion to determine when training was complete.