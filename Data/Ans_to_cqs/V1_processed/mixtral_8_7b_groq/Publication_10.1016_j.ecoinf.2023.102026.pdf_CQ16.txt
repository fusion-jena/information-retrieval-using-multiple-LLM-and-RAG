Based on the provided context, there is no specific information about the criteria used to determine when the training of the models is complete, such as a validation loss plateau. However, the text does provide details about how the models were evaluated, which can give us some insight into how the training process might have been monitored.

For the non-bootstrapped Generalized Linear Models (GLMs), the performances were evaluated using metrics like Area Under the ROC Curve (AUC), Percent Correctly Classified (PCC), sensitivity, specificity, and True Skill Statistic (TSS). These metrics were calculated using the 20% camera traps retained from the training dataset.

For the bootstrapped GLMs, the training data was bootstrapped, meaning it was randomly subsampled with replacement. For each of the 100 iterations, AUC, PCC, sensitivity, specificity, and TSS were calculated using the data retained from the model training. The final metrics were obtained by averaging the results of these 100 validation iterations.

For the Random Forest models, the text mentions that bootstrapping the training data can increase models' precision by providing a combination of models, which reduces stochastic errors in estimation. This suggests that the training process might have involved monitoring the performance of the models over multiple iterations to ensure that the models were not overfitting the data.

In general, when training machine learning models, it is common to monitor the performance of the models on a validation dataset that is separate from the training dataset. The training process might be considered complete when the performance on the validation dataset stops improving or plateaus, indicating that the model is not learning any more useful information from the training data.

Therefore, while the specific criteria used to determine when the training was complete for the models in the provided context is not specified, it is likely that the training process involved monitoring the performance of the models on a validation dataset.