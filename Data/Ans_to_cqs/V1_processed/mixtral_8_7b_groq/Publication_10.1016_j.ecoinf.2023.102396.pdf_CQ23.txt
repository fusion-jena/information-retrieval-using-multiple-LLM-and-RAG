Based on the provided context, there is no direct information about the measures taken to ensure the generalizability of a deep learning model. However, the context does provide information about two papers by G. Wang and X. Shan related to ecological informatics, published in 2024. These papers might discuss the methods used to ensure the generalizability of their deep learning models, but the abstracts or methodology sections are not provided.

In general, there are several common techniques used to ensure the generalizability of deep learning models:

1. Diverse dataset: Training a deep learning model on a diverse dataset can help ensure that the model can handle a variety of inputs and make accurate predictions for new, unseen data.
2. Cross-validation: Cross-validation is a technique used to assess the performance and generalizability of a model by dividing the dataset into multiple subsets, training the model on one subset and testing it on another, and repeating this process for all possible combinations of subsets. This helps to ensure that the model is not overfitting to the training data.
3. Stratified splitting: Stratified splitting is a technique used to divide a dataset into training and testing subsets in a way that preserves the distribution of important variables. This can help to ensure that the model is not biased towards certain subsets of the data.

Without more information, it is not possible to say for certain which of these techniques were used in the studies by G. Wang and X. Shan. However, it is common practice to include information about the methods used to ensure the generalizability of a model in the methodology section of a research paper.