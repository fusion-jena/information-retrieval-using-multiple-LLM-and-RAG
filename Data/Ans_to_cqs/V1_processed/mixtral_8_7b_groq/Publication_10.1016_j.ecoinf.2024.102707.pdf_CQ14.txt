Based on the provided context, there is no explicit information given about how the hyperparameters of the model were optimized. The text only mentions the performance of the model, such as achieving high F1 scores on training, validation, and testing data.

However, it is common to optimize hyperparameters using methods such as grid search, random search, or Bayesian optimization. Grid search involves systematically trying out different combinations of hyperparameters, while random search randomly selects hyperparameters from a given range. Bayesian optimization, on the other hand, uses a probabilistic model to make informed decisions about which hyperparameters to try next.

Without further information, it is not possible to provide a specific answer to how the hyperparameters of the model were optimized in this case. It would require checking the original study or contacting the authors for more details.


The provided context does not give information on how the hyperparameters of the model were optimized. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization. However, without further details, it is not possible to provide a specific answer to this query.