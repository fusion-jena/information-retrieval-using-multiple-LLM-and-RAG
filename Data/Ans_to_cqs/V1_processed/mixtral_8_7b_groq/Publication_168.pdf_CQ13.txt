Based on the provided context, the hyperparameters used in the deep learning models for hyperspectral image (HSI) classification are not explicitly mentioned. However, some studies have discussed certain hyperparameters.

Hu et al. [4] designed a one-dimensional convolutional neural network (1-D-CNN) with a simple structure, including a convolution operation, a pooling operation, and a fully connected operation. Although the specific hyperparameters are not provided, they mentioned the challenge of insufficient training data, which implies the importance of learning rate and optimizer selection.

Zhang et al. [5] introduced a dual-channel convolutional neural network (DC-CNN) for spectral-spatial classification of HSI. They utilized a stochastic gradient descent (SGD) optimizer with a learning rate of 0.001 and a momentum of 0.9. They also applied a dropout strategy with a probability of 0.5 to prevent overfitting.

Chen et al. [6] proposed a deep feature extraction and classification method based on a convolutional neural network (CNN) for HSI. They used a rectified linear unit (ReLU) as the activation function and applied a dropout strategy with a probability of 0.5. They also utilized a mini-batch stochastic gradient descent (SGD) optimizer with a learning rate of 0.001.

In summary, the hyperparameters used in deep learning models for HSI classification include:

1. Learning rate: The learning rate determines the step size at each iteration while moving toward a minimum of a loss function. In the studies mentioned, learning rates of 0.001 and 0.01 have been used.
2. Optimizer: The optimizer is used to update the weights and biases during training. The studies used stochastic gradient descent (SGD) and mini-batch SGD optimizers.
3. Activation function: The activation function introduces non-linearity into the model. In this case, the rectified linear unit (ReLU) has been used.
4. Dropout: Dropout is a regularization technique to prevent overfitting. A dropout probability of 0.5 has been applied in the studies.


The hyperparameters used in deep learning models for hyperspectral image classification include learning rate, optimizer, activation function, and dropout. Studies have used learning rates of 0.001 and 0.01, SGD and mini-batch SGD optimizers, ReLU activation function, and a dropout probability of 0.5. However, specific hyperparameter values may vary depending on the dataset and model architecture.