Based on the provided context, there is no direct information about the criteria used to determine when training is complete, such as a validation loss plateau. However, the text does discuss the evaluation of a model's accuracy in the context of wildfire detection.

In the study, the authors use a binary classification system of ‘burned’ and ‘unburned’ values, and they evaluate the performance of their model using the kappa coefficient, which is selected to comprehensively evaluate the detection accuracy for different indices and parameter sets. They note that the user's accuracy is always higher than the producer's accuracy, which means that the model tends to have a larger omission error than commission error. In other words, unburned pixels are less likely to be mistakenly identified as burned.

The authors also mention that higher MS (maximum number of segments used for fitting) is needed to better capture the index response to wildfire. They find that compared to the default parameters, the overall accuracy and kappa of optimized parameters can improve by up to 8.4% and 36.8%, respectively.

While this information does not directly answer the query about training completion criteria, it does suggest that the authors are using accuracy metrics to evaluate their model's performance. It is possible that they use a validation loss plateau or other training completion criteria in conjunction with accuracy metrics to determine when training is complete. However, without further information, it is not possible to say for sure.