The context provided does not give specific information about the criteria used to determine when training is complete for the models. However, it does mention that a 60-20-20 train/validate/test regime was used to split the data into training, validation, and testing sets. This suggests that validation loss or accuracy may have been monitored to assess the performance of the models during training.

In the context, it is mentioned that the best performing model was Inception-V3 with a macro Average F1 score of 0.93, and the smallest size of 175 MB. This model was then converted to TensorFlow Lite, resulting in a reduced size of 87 MB, but with a slightly reduced accuracy of 92% and a macro average F1-score of 0.90.

It can be inferred that the training of the models was likely stopped based on a combination of factors such as the number of epochs, training loss, and validation loss or accuracy. The specific criteria used to determine when training is complete are not provided in the context.