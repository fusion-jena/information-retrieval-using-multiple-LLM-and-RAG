Based on the provided context, there is no explicit information given about how the hyperparameters of the TrunkNet model are optimized. The text does not mention any specific techniques such as grid search, random search, or Bayesian optimization.

However, it is mentioned that the TrunkNet model is trained using the Adam optimizer with default hyperparameters: betas=(0.9, 0.999) and eps=1.0 x 10^-8. The initial learning rate is set to lr=1.0 x 10^-3. These hyperparameters are commonly used default values in many deep learning applications, but they are not necessarily the optimal values for this specific task.

Additionally, the text mentions that the model is trained from scratch with a batch size of 12 for approximately 11.5 hours. This suggests that some form of hyperparameter tuning may have been performed, as the number of training iterations and batch size can significantly affect the model's performance and training time.

Overall, while the specific method of hyperparameter optimization is not mentioned in the provided context, it is possible that some form of manual tuning or default value selection was used to determine the optimal hyperparameters for the TrunkNet model.