The provided context does not explicitly mention the specific methods used for hyperparameter optimization, such as grid search or random search. However, it does mention that the segmentation step of the input image involves manually optimizing a set of non-dimensional parameters. These parameters include the scale parameter, shape versus color parameter, and compactness versus smoothness parameter. The user must manually adjust these parameters to control the average image segment size, prioritize homogeneity in color versus shape or texture, and prioritize compactness over smoothness during the segmentation process.

Furthermore, the context mentions that the network weights can be randomly initialized if the network is trained from scratch. However, this is suitable only when a large labeled training-set is available. To overcome this limitation, previous studies have shown that data-augmentation and transfer learning help. These techniques can be seen as hyperparameter optimization methods, as they involve adjusting the way the model is trained, rather than adjusting the model's parameters directly.

In summary, the provided context suggests that the hyperparameters of the model are optimized through manual adjustment and potentially through techniques such as data-augmentation and transfer learning. However, it does not explicitly mention the use of specific optimization methods such as grid search or random search.