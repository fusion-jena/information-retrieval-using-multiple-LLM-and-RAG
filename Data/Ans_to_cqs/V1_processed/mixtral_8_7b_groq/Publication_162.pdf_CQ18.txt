The strategy implemented to monitor the model performance during training involves the use of a feedback mechanism and active learning. At certain intervals, the system forwards images to humans for annotation. After the annotation, these images are used to train a classifier iteratively. The evaluation is carried out with a retained test set of manually annotated images. This approach allows for the user to be involved in the optimization of the system while minimizing the manual labeling effort. Additionally, novelty detection is implemented to detect species that are unknown for the recognition system.

Furthermore, the system aims at applying and improving lifelong learning algorithms for the identification of wildlife animal species that occur in the images from the camera traps. This enables updates of the classification models once new data is available, which is crucial for the AMMOD stations that should operate for a longer period of time.

The performance of the model is also evaluated on an annotated set of recorded data, which is split into training and test sets, as well as on publicly available datasets for fine-grained recognition in the computer vision community.

In summary, the strategy for monitoring the model performance during training includes the use of active learning, feedback mechanism, novelty detection, and lifelong learning algorithms. These methods allow for the system to improve its performance over time and adapt to new data while minimizing manual labeling effort and involving the user in the optimization process.