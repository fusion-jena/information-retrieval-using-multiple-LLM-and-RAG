The provided context does not explicitly mention which deep learning framework was used to build the model. However, it can be inferred that the models were built using a deep learning framework compatible with Stochastic Gradient Descent (SGD), batch-norm, dropout, and fine-tuning techniques. Both TensorFlow and PyTorch are popular deep learning frameworks that support these techniques.

TensorFlow is a widely-used open-source library for machine learning and artificial intelligence developed by Google Brain Team. It provides a comprehensive ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML-powered applications. TensorFlow supports SGD, batch-norm, dropout, and fine-tuning techniques, making it a suitable choice for building the deep learning models described in the context.

PyTorch is another popular open-source machine learning library based on the Torch library developed by Facebook's AI Research lab. It provides tensor computation with strong GPU acceleration and deep neural networks built on a tape-based autograd system. PyTorch also supports SGD, batch-norm, dropout, and fine-tuning techniques, making it a possible candidate for building the models.

Therefore, based on the provided context, it can be concluded that the deep learning models were built using either TensorFlow or PyTorch, as both frameworks support the required techniques. However, the specific framework used is not explicitly mentioned in the context.