The provided context does not contain specific information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it does provide some insights into the methods used for data analysis and model selection in related studies.

In the study by Broennimann et al. (2012), the authors measured ecological niche overlap from occurrence and spatial environmental data, but they did not mention any data splitting criteria for model training. Similarly, the study by Assis et al. (2018) extended marine data layers for bioclimatic modeling, but they also did not provide information on data splitting for deep learning models.

The studies by Et al. (2014) and Ballard et al. (2017) focused on the presence data and natural history museum-led citizen science, respectively, but they did not discuss deep learning models or data splitting criteria.

In the context, the authors used the Akaike Information Criterion (AICc) for model selection, which compares the goodness-of-fit and complexity of different models. The model with the lowest AICc value is considered the best model, and all models with Î”AICc <2 are generally considered to have substantial support. However, this information is related to model selection, not data splitting for model training.

Therefore, based on the provided context, we cannot determine the specific criteria used to split the data for deep learning model training.