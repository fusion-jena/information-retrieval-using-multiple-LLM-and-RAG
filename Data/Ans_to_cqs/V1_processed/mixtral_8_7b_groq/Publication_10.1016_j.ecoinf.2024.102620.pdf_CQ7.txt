Based on the provided context, there is no explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). The text focuses on describing the PLUS model, which is a land use change simulation model that utilizes a transformed specification mining framework based on the land expansion analysis strategy (LEAS) and a cellular automata (CA) model based on a multi-type random patch seed mechanism (CARS). The LEAS module employs the random forest algorithm to obtain the development probabilities of each land use type based on two periods of land use data. However, it does not mention how the data is split for training, testing, or validation.

The context does provide information on the data sources and preprocessing steps, such as obtaining NDVI data from the MOD13Q1.006 dataset, vegetation type data from Google Earth Engine, DEM data from the Resource and Environmental Science and Data Center of the Chinese Academy of Sciences, and meteorological data from ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-lite/ and https://cds.climate.copernicus.eu/. The NDVI data is updated every 16 days with a spatial resolution of 250 m, and its NDVI value is the monthly maximum value synthesized by the maximum value synthesis method. The vegetation type data is reclassified into nine categories, and the DEM data is resampled from its original spatial resolution of 1.875 to a finer resolution.

However, none of this information pertains to the criteria used to split the data for deep learning model training. Therefore, I cannot provide an answer to this query without additional information.