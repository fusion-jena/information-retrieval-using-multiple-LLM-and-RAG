The provided context discusses two techniques used to address data bias during the preprocessing of a text classification pipeline: stratified data splitting and oversampling.

Stratified data splitting is a technique used to ensure that the training and testing datasets contain a representative proportion of each class. In the context provided, the authors found that stratification of training data for classification tasks 2 and 3 improved the recall of relevant texts within stratified testing sets. This suggests that stratified data splitting can help to mitigate the impact of data imbalance on classifier performance.

Oversampling is another technique used to address data imbalance. In the context provided, the authors mention that oversampling of the minority class can help to alleviate the issue of poor classification performance when the target class makes up a small proportion of the training data. However, they note that this technique was not applied in their pipeline.

The context does not explicitly mention undersampling or diverse data collection as techniques used to address data bias during preprocessing. Undersampling is a technique that involves reducing the number of instances in the majority class to balance the dataset. While the context does not mention this technique, it is possible that it could be used in conjunction with oversampling or stratified data splitting to further address data imbalance.

Diverse data collection involves collecting data from a variety of sources to ensure that the dataset is representative of the population. While this technique is not explicitly mentioned in the context, it is an important consideration for addressing data bias in any machine learning pipeline. By collecting data from a diverse range of sources, researchers can help to ensure that their dataset is representative of the population and reduce the risk of bias.

In summary, the provided context discusses two techniques used to address data bias during preprocessing of a text classification pipeline: stratified data splitting and oversampling. While the context does not explicitly mention undersampling or diverse data collection, these techniques are also important considerations for addressing data bias in machine learning pipelines.