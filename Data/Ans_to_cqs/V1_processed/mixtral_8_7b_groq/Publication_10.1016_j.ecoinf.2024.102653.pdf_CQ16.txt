The context provided discusses the methodology used for training a Recurrent Neural Network (RNN) model, including the hyperparameters selected and the validation methods implemented. However, it does not explicitly mention the specific criterion used to determine when training is complete.

However, based on common practices in machine learning, it can be inferred that the training process likely stopped when the validation loss plateaued or started to decrease. This is a common approach to prevent overfitting, which occurs when the model learns the training data too well, to the point where it performs poorly on unseen data.

In the provided Figure 4, the accuracy of both the training and validation datasets is plotted, which could be used to monitor the performance of the model during training. If the validation accuracy starts to decrease while the training accuracy continues to increase, this could indicate overfitting, and the training process should be stopped.

Moreover, the context mentions that the model was trained for a fixed number of epochs (100). While this does not necessarily mean that early stopping was not used, it suggests that the training process was not adaptively adjusted based on the performance on the validation set.

In summary, while the context does not explicitly state the criterion used to determine when training is complete, it can be inferred that the training likely stopped when the validation loss plateaued or started to decrease, based on common practices in machine learning.