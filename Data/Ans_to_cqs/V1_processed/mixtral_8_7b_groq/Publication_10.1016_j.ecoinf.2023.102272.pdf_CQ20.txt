Based on the provided context, there is no explicit information given about the specific hardware resources used for training the deep learning models. The text focuses more on the model selection procedure, the architecture types of the models, and their performance evaluation.

However, it is mentioned that deep learning models are complex artificial neural networks composed of a large number of trainable parameters. These models are known for their ability to perform complex tasks with high performance, such as computer vision and natural language processing, which often require significant computational resources.

Given the complexity of deep learning models and the tasks they are designed to perform, it is plausible to assume that they were trained using hardware accelerators like Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). These types of hardware are commonly used to train deep learning models due to their ability to perform parallel computations, which significantly speeds up the training process.

In conclusion, while the text does not explicitly mention the hardware resources used for training the deep learning models, it is highly likely that GPUs or TPUs were used given the complexity of the models and the nature of the tasks they were designed to perform.


Deep learning models are complex artificial neural networks that require significant computational resources due to their large number of trainable parameters. Although the provided context does not explicitly mention the hardware resources used for training the models, it is highly likely that GPUs or TPUs were used given the complexity of the models and the tasks they were designed to perform.