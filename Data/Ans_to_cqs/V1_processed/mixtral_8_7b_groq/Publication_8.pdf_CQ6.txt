In the context provided, there is no explicit mention of specific preprocessing steps such as normalization, scaling, or cleaning. However, it is mentioned that transfer learning is used to initialize the model weights pre-trained on the ImageNet dataset. This implies that the images from the herbarium scan dataset were likely preprocessed to some extent to be compatible with the ImageNet dataset.

In general, preprocessing steps for training deep learning models can include:

1. Image normalization: This involves scaling the pixel values to a range between 0 and 1. This is done by dividing each pixel value by 255, assuming the pixel values are 8-bit integers.
2. Image resizing: Deep learning models typically require a fixed input size. Therefore, images may need to be resized to match the input size of the model.
3. Data augmentation: This involves applying random transformations to the images, such as rotation, flipping, and zooming, to increase the size of the training dataset and improve the model's ability to generalize.
4. Data cleaning: This involves removing any corrupted or irrelevant images from the dataset.
5. Data labeling: For supervised learning tasks, each image needs to be labeled with the corresponding class or object of interest.

In the case of the herbarium scan dataset, it is likely that the images were preprocessed by normalizing the pixel values, resizing the images to match the input size of the model, and possibly applying data augmentation techniques. However, without explicit mention in the context, this is only an educated guess.