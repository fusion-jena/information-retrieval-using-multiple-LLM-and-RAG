Based on the provided context, there is no specific information given about the hardware resources used for training the deep learning model. The context mainly focuses on the analysis of input set characteristics, data splitting, and the performance evaluation of machine learning algorithms for predicting waste disposal rates and heavy metals in soil.

However, it is generally common practice to use Graphics Processing Units (GPUs) for training deep learning models due to their ability to perform parallel processing, which significantly speeds up the training process compared to using Central Processing Units (CPUs) alone. Some organizations and researchers also use Tensor Processing Units (TPUs), which are custom-built hardware accelerators developed by Google for machine learning tasks, particularly for large-scale deep learning models.

In the paper "Analysis of input set characteristics and variances on k-fold cross validation for a recurrent neural network model on waste disposal rate estimation" by Vu et al. (2022), they mention using a Recurrent Neural Network (RNN) model but do not provide information about the hardware resources used for training. Similarly, in the paper "Application of VNIR and machine learning technologies to predict heavy metals in soil and pollution indices in mining areas" by Wang et al. (2022), they discuss various machine learning algorithms, including deep learning models, but there is no mention of the hardware resources used for training.

Therefore, without specific information in the provided context, it is not possible to accurately answer the query regarding the hardware resources used for training the deep learning model.