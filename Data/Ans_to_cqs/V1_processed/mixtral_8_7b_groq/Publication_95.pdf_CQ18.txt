The strategy implemented to monitor the model performance during training involves the use of the average training loss. Specifically, after every iteration, the loss value is calculated and averaged over the entire training dataset. This average training loss is then used to determine when to stop the training. The authors chose to train the YOLOv3 model for 22,000 iterations, as the training loss was observed to have stabilized after this number of iterations. This approach allows for a more data-driven and systematic way of determining when the model has learned enough from the training data.

Additionally, the authors also used a validation set to further monitor the model's performance. The validation set is a separate dataset that is used to test the model during the training process. This allows the authors to evaluate the model's performance on unseen data and ensure that the model is not overfitting to the training data.

Furthermore, the authors also provided a figure (Figure 8) that shows the recall of the ResNet50V2 models on the validation set as a function of the annotation size relative to image size. This figure provides additional insights into the model's performance on the validation set and can help identify any potential issues or biases in the model's predictions.

Overall, the strategy implemented by the authors to monitor the model performance during training involves the use of average training loss, validation set, and recall metric. This allows for a comprehensive evaluation of the model's performance and helps ensure that the model is learning effectively from the training data.