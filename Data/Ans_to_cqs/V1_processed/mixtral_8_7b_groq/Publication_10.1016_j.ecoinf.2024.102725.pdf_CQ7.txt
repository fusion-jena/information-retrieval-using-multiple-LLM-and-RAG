The provided context does not give specific details about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it is common practice in machine learning to split the data into three sets: training, validation, and testing.

The training set is used to train the model, that is, to adjust the model's parameters to minimize the error on the training examples.

The validation set is used during the training process to provide an unbiased evaluation of the model's performance. It helps to tune the hyperparameters of the model and prevent overfitting.

The testing set, also called the hold-out set, is used to evaluate the final performance of the trained model. It provides an unbiased estimate of how the model would perform on new, unseen data.

The splitting of the data into these three sets can be done randomly, but there are also other strategies such as time series cross-validation, where the data is split based on time, or k-fold cross-validation, where the data is split into k subsets, and the model is trained and evaluated k times, each time using a different subset as the testing set.

In the context of the Wang et al. study, it is likely that they used a similar approach to split their data into training, validation, and testing sets, but the specific criteria are not provided in the text.