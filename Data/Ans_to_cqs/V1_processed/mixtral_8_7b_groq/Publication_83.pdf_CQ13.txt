The deep learning model used for bird sound classification employs a VGG style network architecture, as described in [24] and previously used for acoustic scene classification in [5]. The model is trained using the Adam optimizer, with a learning rate of 1e-4. The categorical cross entropy is utilized as the loss function. The batch size is set to 64 samples, and the network is trained for 200 epochs.

In addition to these hyperparameters, the feature learning part of the proposed model follows the aforementioned VGG style network architecture. This network is trained with a specific configuration, including the Adam optimizer, a learning rate of 1e-4, categorical cross entropy as the loss function, a batch size of 64 samples, and 200 epochs for training.

It is important to note that the model's input features are not limited to Mel-spectrograms. Other input features, such as harmonic-component based spectrogram, percussive-component based spectrogram, and SubSpectralNet with Mel-spectrogram as input, are also used. These variations in input features, along with the fusion of different CNN-based models, contribute to the improved classification performance.

The hyperparameters mentioned above are specific to the VGG style network architecture. The SubSpectralNet architecture, which can be regarded as a filter with different configurations, has its own set of hyperparameters. However, the provided context does not include detailed information about the SubSpectralNet's hyperparameters.