The provided context does not give specific details about the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it does mention that they calibrated models for classification challenges using different numbers of training steps, and considered two factors to find optima for training TensorFlow: correct identification rate and processing time.

In general, when training deep learning models, it is common to split the data into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

The splitting criteria can vary depending on the specific use case and the amount of available data. A common approach is to use a 60-20-20 or 70-15-15 split, where 60% or 70% of the data is used for training, 20% for validation, and 20% for testing. Another approach is k-fold cross-validation, where the data is split into k subsets, and the model is trained and validated k times, each time using a different subset for validation and the remaining k-1 subsets for training.

In the context of the study, it seems that they used a single training set with different numbers of training steps to find the optimal number of steps for each classification task. They then evaluated the model's performance using a confusion matrix, which shows the number of correct and incorrect classifications for each species.

It is worth noting that the study also mentions some caveats for future consideration, such as single notes per species and limited sample sizes for rare species or those with reduced detection probabilities. These factors could affect the data splitting criteria and the model's performance.

Therefore, while the provided context does not give specific details about the data splitting criteria used in the study, it is common to use a training, validation, and testing split when training deep learning models, and the criteria can vary depending on the specific use case and available data.