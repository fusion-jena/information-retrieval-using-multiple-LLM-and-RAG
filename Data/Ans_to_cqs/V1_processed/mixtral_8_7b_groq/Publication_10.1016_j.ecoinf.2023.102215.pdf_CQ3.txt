The data annotation techniques used in the deep learning pipeline for the study mentioned in the context involve pixel-wise salient object annotations. This method of annotation involves manually segmenting all salient trunks in each image at a pixel level to obtain high-quality binary ground-truth masks representing salient trunks.

Before annotation, each image was resized to 512 Ã— 512 pixels, and during the process, a small fraction of images were discarded due to their trunks being too blurry and obscure even for the human eye. Each result was examined one by one, and poor-quality annotations were re-labeled to ensure high-quality annotations.

The annotation method used in this study is different from other annotation techniques such as bounding box annotation or instance segmentation. Bounding box annotation involves drawing a box around the object of interest, while instance segmentation involves separating each instance of an object in an image into individual segments. In contrast, pixel-wise salient object annotations involve segmenting the object of interest at a pixel level, providing a more precise annotation of the object.

The study also provides information on the diversity of the dataset, including the size of the salient tree trunks. The sizes of the salient objects range from 0.39% to 97.8%, with an average of 34.53%, indicating a diverse range of tree trunk sizes in the dataset.

In summary, the data annotation technique used in the deep learning pipeline for the study mentioned in the context involves pixel-wise salient object annotations, which provides a precise and high-quality annotation of the salient trunks in each image. The dataset also features good diversity in terms of tree trunk sizes, which is beneficial for training and evaluating the performance of SOD models.