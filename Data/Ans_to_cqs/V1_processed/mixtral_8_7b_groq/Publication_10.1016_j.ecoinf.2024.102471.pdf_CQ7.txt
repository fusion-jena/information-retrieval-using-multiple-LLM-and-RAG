The dataset is split into training and testing sets with various ratios such as 70:30, 80:20, and 90:10 for strong performance analysis of the Wav2Vec model. The specific criteria used for splitting the data are not mentioned in the provided context. However, it is mentioned that the dataset is split for supervised fine-tuning and pre-training phases of the Wav2Vec model. In the supervised fine-tuning phase, the labeled dataset is used for training the model to predict particular words or phonemes. In contrast, in the pre-training phase, the model learns to recognize whether two different types of transformations of the input are the same or not. The two transformations used in the Wav2Vec model are the context representation from the context network and the final quantization vectors. The pre-training phase comprises four important elements: feature encoder, context network, quantization module, and pre-training objective. The training and testing split ratios used in the Wav2Vec model are 90:10, 80:20, and 70:30, and the classification metrics like precision, recall, and F1-score are calculated for each bird species with respect to these different training-testing splits. The proposed transfer learning using Wav2Vec achieves better results in the 90:10 training-testing ratio with very little deviation among the bird species compared to the baseline models.