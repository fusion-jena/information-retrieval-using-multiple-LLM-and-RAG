Based on the information provided, there are no specific details about the data augmentation techniques applied in the deep learning pipeline. However, data augmentation is a common technique used in deep learning to increase the size and variability of the training dataset, which can improve the model's ability to generalize to new data.

Data augmentation techniques typically involve applying random transformations to the training images, such as flipping, rotating, scaling, and translating. These transformations can help the model learn to recognize features that are invariant to certain types of transformations, which can improve its performance on new data.

In the context of the tables provided, it is likely that some form of data augmentation was applied to the UBD_45 and VP_200 datasets, as the performance of the models varies across different runs. However, without further information, it is not possible to say for sure which data augmentation techniques were used.

In the paper "A survey of the recent architectures of deep convolutional neural networks" [32], the authors discuss various techniques for improving the performance of deep convolutional neural networks, including data augmentation. They note that data augmentation can help reduce overfitting and improve the model's ability to generalize to new data. However, they do not provide specific details about the data augmentation techniques used in their survey.

In the paper "A novel ensemble method for classification in imbalanced datasets using split balancing technique based on instance hardness (sBal_IH)" [33], the authors focus on developing a new ensemble method for classification in imbalanced datasets. While they do not discuss data augmentation specifically, they note that balancing the dataset can help improve the performance of machine learning algorithms, which could be achieved through data augmentation.

Therefore, while there is no specific information about the data augmentation techniques used in the deep learning pipeline in the provided context, it is likely that some form of data augmentation was applied to the datasets to improve the model's ability to generalize to new data.