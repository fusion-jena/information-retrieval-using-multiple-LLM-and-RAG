Based on the provided context, the specific metrics used to evaluate the performance of the deep learning model are not explicitly stated. However, it can be inferred that the out-of-sample prediction accuracy and R2 DEV are used to assess the performance of the models being compared.

The out-of-sample prediction accuracy is a metric used to evaluate the performance of a model by calculating the median of k-1 folds for each number of iterations. This metric is used in the nested k-fold cross-validation scheme to monitor the performance on the validation set and avoid overfitting in XGBoost.

R2 DEV is another metric used to evaluate the performance of the models. It is a modified score based on the residual deviance and is preferred for species abundance counts. R2 DEV is used to calculate the out-of-sample predictive performance in the datasets, as shown in Fig. S9 in Supplement A.9.

It is important to note that the context does not mention any other metrics commonly used in deep learning, such as accuracy, precision, recall, or F1 score. Therefore, based on the provided context, it can be concluded that the out-of-sample prediction accuracy and R2 DEV are the metrics used to evaluate the performance of the models being compared.