Based on the provided context, there is no explicit mention of strategies employed to handle randomness in the deep learning pipeline, such as using a random seed value. However, the text does mention the use of batch normalization in the deep learning module. Batch normalization is a technique used to normalize the inputs of each batch in a deep learning model, which can help reduce internal covariate shift and improve the training process. It involves calculating the mean and variance of each channel in the current batch and normalizing the inputs using these statistics.

Additionally, the deep learning method is used to model complex spatiotemporal dependencies and derive probability maps for land use/cover change (LUCC) simulations. The probability maps are based on the distribution probability of a variety of LU types in a spatial unit, rather than determining the existence of a specific LU type at a certain time. This suggests that the deep learning model may be using a probabilistic approach to handle the randomness and uncertainty associated with LUCC.

Furthermore, the deep learning module uses a training set consisting of grid units with neighborhood features from six different years. The use of a training set with multiple years of data may help reduce the impact of randomness and variability in the input data, as the model can learn from a larger and more diverse dataset.

Overall, while the text does not explicitly mention strategies for handling randomness in the deep learning pipeline, it does suggest the use of batch normalization, probabilistic approaches, and multiple years of data in the training set as potential strategies for improving the deep learning model's performance and robustness.