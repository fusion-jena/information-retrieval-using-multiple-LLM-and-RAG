The provided context discusses the use of the LASSO (Least Absolute Shrinkage and Selection Operator) model, which is a type of regularization method used for variable selection and statistical regularization to enhance the prediction accuracy of the model. However, the context does not mention any deep learning techniques such as dropout or L2 regularization to prevent overfitting.

LASSO model is used to investigate the multicollinearity between the variables and shrinks less important variables' coefficients to zero, thus performing variable selection and allowing for the identification of the most relevant variables. This model used environmental factors (pH, water temperature), nutrients (TP, TN, NH4-N, and NO3--N), and phytoplankton (Chl-a) as predictors with Fn355 as the response variable.

On the other hand, dropout and L2 regularization are commonly used regularization techniques in deep learning to prevent overfitting. Dropout is a technique where randomly selected neurons are ignored during training, which helps to make the network more robust and less prone to overfitting. L2 regularization, also known as weight decay, adds a penalty term to the loss function that is proportional to the square of the norm of the weights, which helps to reduce the size of the weights and prevent overfitting.

Therefore, the regularization methods used in the provided context to prevent overfitting are not dropout or L2 regularization, but instead, the LASSO model, which is a type of regularization method used for variable selection and statistical regularization.