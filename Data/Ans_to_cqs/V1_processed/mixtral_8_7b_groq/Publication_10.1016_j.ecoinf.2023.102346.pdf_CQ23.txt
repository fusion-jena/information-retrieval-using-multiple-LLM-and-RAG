Based on the provided context, there is no explicit mention of a deep learning model. However, the text does describe several measures taken to ensure the generalizability of the machine learning models that were used.


The measures taken to ensure the generalizability of the machine learning models include:

1. **Diverse dataset:** Eight different machine learning algorithms were tested to generate predictive models, which suggests that a diverse set of methods was used to account for variation in performance, accuracy, key parameters, and sensitivity for prediction.

2. **Cross-validation:** The prediction power with machine learning algorithms was tested using the package “sdm” and “biomod2” for ensemble modeling. Model mean performances for AUC, ROC, TSS, KAPPA, and COR values were extracted using “shiny” packages in RStudio. Additionally, 10 K-fold cross-validation was performed for all models.

3. **Bootstrapping:** To verify the model’s validity, 30% of each taxon’s data records were utilized as testing data, while the remaining 70% were used as training data. After 10 K-fold cross-validation and 10-fold bootstrapping, all models were assessed based on the mean values for Area Under the Curve AUC, True Skill Statistics TSS, Cohen’s KAPPA, point-biserial correlation COR, and Receiver Operator Characteristics ROC. Bootstrapping was used to provide unbiased predictive accuracy with a sufficiently low variance.

4. **Model threshold:** The sensitivity-specificity sum maximization technique was employed for the model threshold. According to this evaluation criterion, species distribution can be accurately predicted.

It is important to note that these measures were applied to machine learning models, not deep learning models. Deep learning models have specific techniques to ensure generalizability, such as using large and diverse datasets, data augmentation, regularization, early stopping, and ensemble methods.