The text provided does not give specific details about the process followed to deploy the trained deep learning model. However, it does mention that the model was trained on a machine with an NVIDIA GeForce 1080 GPU, and that a custom LeNet-5 network was used for cactus recognition.

Based on common practices in deep learning model deployment, it can be inferred that the training process likely included model serialization, which is the process of saving the trained model to disk so that it can be loaded and used later. This is typically done using a specific format, such as HDF5 or Tensorflow's SavedModel format.

Additionally, the platform for deployment would have been selected based on the requirements of the application. For example, if the model was to be deployed in a web application, a platform such as Tensorflow.js or ONNX.js could be used to run the model in a web browser. If the model was to be deployed in a mobile application, a platform such as Tensorflow Lite could be used to run the model on a mobile device.

It's also important to note that, the model might have been converted to a format that is compatible with the deployment platform, and the model might have been optimized for the deployment platform, for example, quantization, pruning, etc.

In summary, while the text provided does not give specific details about the process followed to deploy the trained deep learning model, it can be inferred that the process likely included model serialization and platform selection based on common practices in deep learning model deployment. However, the specifics of the process are not provided.