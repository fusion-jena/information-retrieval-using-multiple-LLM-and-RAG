The provided article does not explicitly mention the techniques used to address data bias during the preprocessing of the deep learning pipeline. However, it does discuss the data augmentation technique of horizontal flipping used during the training phase of their deep learning model. Data augmentation is a strategy that can help reduce overfitting and improve model performance, but it does not directly address data bias.

The article also mentions the use of external training data through transfer learning as a method to improve the performance of their deep learning model, as they had limited training data available for plant cover estimation. Transfer learning involves training the model on larger datasets first, followed by fine-tuning it on the target task. This approach can help reduce data bias by leveraging a more diverse and representative dataset during the initial training phase.

In addition, the authors compare their deep learning model's performance with a simpler approach, an ImageNet baseline model. This comparison helps ensure that the proposed model's performance is not due to chance or overfitting and provides a benchmark for evaluating the effectiveness of their approach.

While the article does not explicitly discuss techniques such as stratified splitting, oversampling, undersampling, or diverse data collection, the use of transfer learning and external training data can help mitigate data bias and improve model performance.