Based on the provided context, there is no explicit information given about the criteria used to split the data for deep learning model training (e.g., train, test, validation). The text discusses the data platform's structure, data sources, integration, enrichment, validation, and loading processes, but it does not mention any specific details about the data splitting criteria.

However, it is essential to split the data when training deep learning models. Commonly, the dataset is divided into three subsets: training, validation, and testing. This practice allows for the evaluation of the model's performance and the prevention of overfitting.

Here are some possible common criteria for splitting the data:

1. Random splitting: The data is randomly divided into three subsets, ensuring each set has a similar distribution of classes or labels.
2. Time-based splitting: If the data is time-series or has a temporal component, you can split the data based on time. For example, use data from the past for training, the recent past for validation, and the most recent data for testing.
3. Event-based splitting: If the data is associated with specific events, you can split the data based on these events. For instance, use data from one set of events for training, another set for validation, and the last set for testing.

The choice of the splitting criteria depends on the specific problem, data characteristics, and the deep learning model being used. It is essential to carefully consider the splitting strategy and ensure that the resulting subsets are representative of the overall dataset.

In conclusion, the provided context does not mention the specific criteria used for splitting the data for deep learning model training. However, it is a common practice to split the data into training, validation, and testing subsets using various splitting strategies based on the problem, data, and model characteristics.