Based on the provided context, there is no explicit mention of optimization techniques such as Stochastic Gradient Descent (SGD) or Adam used in the deep learning pipeline. However, the context does discuss other aspects of the deep learning models used for image classification and object detection.

The first model described is a classification network that uses convolutional layers, pooling layers, dropout layers, and dense layers for image classification. The dropout layer is used to mitigate overfitting, which can be considered an optimization technique to improve the model's generalization. However, the specific optimization algorithm used for training the model is not mentioned.

The second model discussed is Faster RCNN, an object detection network that consists of two main modules: a Region Proposal Network (RPN) and a Fast RCNN model. The RPN proposes regions containing objects, while the Fast RCNN model processes these regions for object classification and localization. Faster RCNN uses anchors for generating bounding boxes and comparing them with ground-truth bounding boxes using the Intersection over Union rate. Again, the context does not mention any specific optimization algorithms used for training Faster RCNN.

The third model mentioned is YOLOv5, an object detection model that incorporates a C3 module, a new SPP module named SPP Fast, and the SiLU activation function. YOLOv5 is compared with other methods like YOLOv4, Faster RCNN, and Faster RCNN with Overlap Sampler. While the context provides a comparison of their performance metrics, it does not mention the optimization algorithms used for training YOLOv5 or the other models.

In conclusion, the provided context does not explicitly mention the optimization techniques (e.g., SGD, Adam) used in the deep learning pipeline. However, it does discuss other aspects of deep learning models, such as convolutional layers, pooling layers, dropout layers, and dense layers, as well as the use of anchors and the Region Proposal Network for object detection.