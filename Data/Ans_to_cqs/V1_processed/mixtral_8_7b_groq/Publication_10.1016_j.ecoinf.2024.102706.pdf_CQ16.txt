The context provided does not give specific information about the criteria used to determine when training is complete for the machine learning models. However, it is mentioned that a 5-fold cross-validation grid search strategy was implemented to tune hyperparameters within the training dataset for all machine learning models. This suggests that the training process might involve monitoring the performance of the models on the validation set during the cross-validation process and stopping the training when a certain condition is met, such as a validation loss plateau or when there is no significant improvement in the model's performance.

In general, there are several common criteria used to determine when training is complete in machine learning models. One common approach is to monitor the performance of the model on a validation set during the training process. If the performance on the validation set stops improving or starts getting worse, it might indicate that the model is starting to overfit to the training data, and the training process can be stopped.

Another common approach is to set a maximum number of iterations or epochs for the training process. This ensures that the training process will stop even if the performance on the validation set has not plateaued.

In the context of boosting models like XGBoost and LightGBM, the training process involves adding multiple decision trees to the model in an iterative manner. The training process can be stopped when the improvement in the model's performance is below a certain threshold or when a maximum number of trees has been reached.

Overall, while the specific criteria used to determine when training is complete are not provided in the context, it is common to monitor the performance of the model on a validation set and set a maximum number of iterations or epochs to prevent overfitting and ensure that the training process stops at an appropriate time.