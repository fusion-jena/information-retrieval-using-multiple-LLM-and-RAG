The criteria used to split the data for deep learning model training, based on the provided context, involves dividing the data into three sets: training, validation, and testing.

First, the data is divided into a training set and a testing set. This is done manually by removing a portion of the data to be used for testing. The size and composition of the testing set are not specified in the context.

Next, during the training process, 10% of the training data is used as the validation set. The validation set is used to check for overfitting, which occurs when the model performs well on the training data but poorly on new, unseen data. By using a validation set, the model can be evaluated on a separate set of data while training, helping to ensure that it is not overfitting to the training data.

The training of the algorithms is done using a batch size of 64 samples and training for 100 epochs. An epoch is one complete pass through the entire training dataset. The batch size is the number of samples that are processed before the model's weights are updated.

The context also mentions the use of a min-max scaler, which is used to revert the scaling of the performance metrics at the end. Scaling the data is a common preprocessing step in machine learning, where the data is transformed to have a mean of 0 and a standard deviation of 1. This helps to ensure that all features are on a similar scale and can be important for the performance of some algorithms.

Finally, the models are implemented in Pytorch and trained and tested in Google Colaboratory.

In summary, the criteria used to split the data for deep learning model training, based on the provided context, involves dividing the data into a training set, a validation set, and a testing set. The training set is used to train the model, the validation set is used to check for overfitting, and the testing set is used to evaluate the model's performance on new, unseen data. The training is done using a batch size of 64 samples and training for 100 epochs, and a min-max scaler is used to revert the scaling of the performance metrics at the end.