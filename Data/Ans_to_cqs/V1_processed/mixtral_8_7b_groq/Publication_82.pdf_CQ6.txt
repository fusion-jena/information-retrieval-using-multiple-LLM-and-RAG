The provided context does not include specific details about the preprocessing steps applied to the data before training the deep learning models. However, it does mention that the experiments were conducted using a fork of Caffe, a deep learning framework. Caffe has built-in support for data preprocessing, and it is likely that some preprocessing steps were applied to the data before training.

Common preprocessing steps for training deep learning models include:

1. Normalization: This involves scaling the input data to a range of values that the model can handle. In the context of image data, this often involves scaling the pixel values to a range of 0-1 or -1 to 1.
2. Scaling: Similar to normalization, scaling involves changing the range of the input data. However, scaling does not necessarily involve changing the mean and standard deviation of the data.
3. Data cleaning: This involves removing or correcting erroneous data points that may negatively impact the model's performance.
4. Data augmentation: This involves artificially increasing the size of the training set by applying transformations to the existing data. Common transformations include rotation, scaling, and flipping.

In the context of the provided paper, it is likely that some preprocessing was applied to the data before training. However, without additional information, it is impossible to say for sure which preprocessing steps were taken. It is possible that the authors applied their own preprocessing pipeline or used the default preprocessing options provided by Caffe.

In summary, while the provided context does not include specific details about the preprocessing steps applied to the data, it is likely that some preprocessing was done before training the deep learning models. Common preprocessing steps include normalization, scaling, data cleaning, and data augmentation.