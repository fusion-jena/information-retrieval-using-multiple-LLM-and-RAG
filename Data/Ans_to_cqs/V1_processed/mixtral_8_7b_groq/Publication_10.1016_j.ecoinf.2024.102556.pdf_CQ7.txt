In the context provided, the criteria used to split the data for deep learning model training involves the use of k-fold cross-validation, specifically 5-fold cross-validation. This technique is used to address challenges such as overfitting, uneven data distribution, and the inability to assess the model's generalization ability. 

In k-fold cross-validation, the entire dataset is divided into 'k' subsets. In this case, k is 5. During the training phase, a single subset is used as the validation set, while the remaining four subsets are used as the training set. This process is repeated 'k' times, ensuring that each sample in the dataset is used as both a training and validation sample. 

The accuracy curve graph resulting from the 5-fold cross-validation model reveals that this approach yields a prediction rate closer to 1, indicating that the model optimally uses all the samples in the dataset. 

However, the context does not provide information on why 5-fold cross-validation was chosen over other methods such as 10-fold cross-validation or a fixed train-test split. The choice of k in k-fold cross-validation can depend on various factors, including the size of the dataset and the computational resources available. 

In summary, the criteria used to split the data for deep learning model training in the provided context involves the use of 5-fold cross-validation, where the dataset is divided into 5 subsets, and each subset is used as a validation set while the remaining subsets are used as the training set. This process is repeated 5 times to ensure that each sample in the dataset is used as both a training and validation sample.