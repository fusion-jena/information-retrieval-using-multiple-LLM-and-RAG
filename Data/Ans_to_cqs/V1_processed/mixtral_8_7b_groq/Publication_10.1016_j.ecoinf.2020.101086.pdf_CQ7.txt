Based on the provided context, there is no specific information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, I can provide some general practices for splitting data in machine learning, which may also apply to deep learning.

In machine learning, it is common to split the dataset into three subsets: training, validation, and testing. These subsets are used for different purposes:

1. Training set: This subset is used to train the model. The model learns patterns from this data and adjusts its parameters to minimize the error on the training data.
2. Validation set: This subset is used during the model training process to provide an unbiased evaluation of the model. The validation set helps to tune hyperparameters, prevent overfitting, and ensure the model generalizes well to unseen data.
3. Testing set: This subset is used to evaluate the final model performance. It provides an unbiased estimate of how the model will perform on new, unseen data.

When splitting the data, it is crucial to follow some best practices:

1. Randomization: Split the data randomly to ensure each subset is representative of the entire dataset.
2. Stratification: If the data contains class imbalance, consider stratified sampling to ensure each subset has a similar distribution of classes.
3. Size: Typically, the training set is the largest subset, followed by the validation and testing sets. The exact sizes can vary, but a common practice is to use 70% of the data for training, 15% for validation, and 15% for testing.

In the context of Species Distribution Models (SDMs), the provided information focuses on the transformation of model input data and the impact of sample size and bias on model performance. However, it does not discuss data splitting criteria for deep learning or other machine learning techniques.