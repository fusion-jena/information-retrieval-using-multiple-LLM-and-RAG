The provided context discusses the use of a deep learning model, specifically a multilayer perceptron (MLP), for predicting soil organic carbon stock (SOCS) based on environmental covariates. However, the context does not explicitly mention the metrics used to evaluate the performance of the deep learning model.

In general, there are several evaluation metrics commonly used to assess the performance of deep learning models, including accuracy, precision, recall, and F1 score.

Accuracy is the ratio of the number of correct predictions to the total number of predictions made. It is a common metric used to evaluate the overall performance of a model.

Precision, also known as positive predictive value, is the ratio of true positive predictions (correctly predicted positive instances) to the total number of positive predictions (both true positives and false positives). It is a useful metric for evaluating the performance of a model when the cost of false positives is high.

Recall, also known as sensitivity, is the ratio of true positive predictions to the total number of actual positive instances in the data. It is a useful metric for evaluating the performance of a model when the cost of false negatives is high.

The F1 score is the harmonic mean of precision and recall, and provides a balanced evaluation of a model's performance in terms of both metrics.

Without specific information from the context, it is not possible to determine which of these metrics, if any, were used to evaluate the performance of the deep learning model in this study. However, it is common practice to report multiple evaluation metrics to provide a comprehensive assessment of a model's performance.