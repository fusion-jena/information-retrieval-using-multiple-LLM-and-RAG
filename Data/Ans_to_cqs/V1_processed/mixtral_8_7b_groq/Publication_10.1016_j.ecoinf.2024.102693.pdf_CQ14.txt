The context does not provide explicit information about how the hyperparameters of the models are optimized, such as whether grid search, random search, or another method is used. However, it does give specific values for the learning rate, optimizer, scheduler, batch size, weight decay, input size, and epochs for each of the four basic models (ResNet-50, ViT-S/16, Volo-d1, and ViP-Small/7). These hyperparameters could have been determined through various methods, including manual tuning based on prior knowledge, empirical testing, or more systematic approaches like grid or random search. Nonetheless, the specific method of hyperparameter optimization is not specified in the context.