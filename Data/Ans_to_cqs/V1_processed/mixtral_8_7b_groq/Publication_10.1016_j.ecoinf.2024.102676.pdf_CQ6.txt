The provided context discusses the use of missing value imputation as part of the data preprocessing pipeline for the Footprint Identification Technique (FIT), but it does not explicitly mention other preprocessing steps such as normalization, scaling, or cleaning. However, it is reasonable to assume that these steps could also be involved in the preprocessing pipeline, as they are commonly used in machine learning and deep learning.

Data normalization is the process of scaling numeric data to a common range, often between 0 and 1. This can help ensure that all features contribute equally to the model's learning and improve the model's performance. Data scaling is similar to normalization, but it involves transforming the data to have a specific mean and standard deviation.

Data cleaning involves identifying and handling missing or invalid data. In the context of FIT, missing value imputation is used to fill in missing footprint data, which can improve the accuracy of the model's predictions. Other data cleaning techniques may also be used, such as removing outliers or handling incorrect labels.

While the provided context does not explicitly mention these preprocessing steps, it does reference a study that used deep learning models to classify three sympatric otter species. In this study, it is likely that the researchers used preprocessing techniques such as normalization, scaling, and cleaning to prepare the data for training the deep learning models.

Therefore, while the provided context does not give a definitive answer to the query, it is reasonable to assume that preprocessing steps such as normalization, scaling, and cleaning are commonly used in deep learning and may be involved in the preprocessing pipeline for FIT.