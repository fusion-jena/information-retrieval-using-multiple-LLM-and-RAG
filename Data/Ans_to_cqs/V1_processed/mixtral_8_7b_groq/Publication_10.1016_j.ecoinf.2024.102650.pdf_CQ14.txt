Based on the provided context, there is no explicit information about how the hyperparameters of the LDA model, such as the Dirichlet priors α and β, are optimized. The text focuses on the explanation of the LDA model and the use of the pyLDAvis library for topic modeling and visualization.

However, it is common practice to optimize hyperparameters in topic modeling using techniques such as grid search, random search, or Bayesian optimization. These methods involve searching for the best set of hyperparameters by trying different combinations and evaluating the model's performance using a validation set or cross-validation.

In the case of LDA, the hyperparameters α and β control the sparsity of the topic-word distributions and the text-topic distributions, respectively. Fine-tuning these hyperparameters can significantly impact the quality of the topic modeling results.

Therefore, while the provided context does not specify the exact method used for hyperparameter optimization, it is reasonable to assume that some form of hyperparameter tuning was performed to obtain the best possible topic modeling results.