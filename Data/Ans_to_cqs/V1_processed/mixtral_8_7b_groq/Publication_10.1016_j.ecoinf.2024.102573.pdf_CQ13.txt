The hyperparameters used in the deep learning model, as mentioned in the provided context, include the Adam optimizer (Kingma and Ba, 2017) with default hyperparameters. The learning rate is managed by a cosine decay scheduler. The loss function employed is cross-entropy, which is typical for multi-class single-label classification tasks. The models were trained for 100 epochs. The macro-averaged F1-score on the validation set was used to monitor the model's convergence. This scoring method gives equal importance to all classes, regardless of the number of data points in each one.