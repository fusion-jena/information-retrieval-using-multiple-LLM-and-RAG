The context does not provide specific information on how the data was split for deep learning model training. However, it does mention that a training set and a test set were used for accuracy assessment of the classification model.

The training set consisted of 2361 vegetation points, 1456 iceplant points, and 1625 non-vegetation points, totaling 5442 points. The test set consisted of 1000 vegetation points, 478 iceplant points, and 625 non-vegetation points, totaling 2103 points.

Additionally, the context mentions that the training dataset was created to be reasonably balanced, with 38% iceplant points and 62% other vegetation points. This balance was achieved without discarding, repeating, or creating synthetic data points.

In the absence of specific information on the data splitting criteria for deep learning model training, it can be inferred that the data was likely split using a common method such as random sampling or stratified sampling. Random sampling involves randomly selecting a subset of data points for each class to use as the training set, while stratified sampling involves dividing the data into strata based on class distribution and then randomly selecting a subset of data points from each stratum for the training set.

It is also possible that a validation set was used in addition to the training and test sets for hyperparameter tuning and model selection. However, this is not explicitly mentioned in the context.

In summary, while the specific criteria used to split the data for deep learning model training are not provided in the context, it can be inferred that a balanced training set was created and a test set was used for accuracy assessment. Common data splitting methods such as random sampling or stratified sampling were likely used.