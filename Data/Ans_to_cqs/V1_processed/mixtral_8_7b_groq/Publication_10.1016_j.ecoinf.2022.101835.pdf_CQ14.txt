The hyperparameters of the machine learning models were optimized using Optuna 2.10.0, an automatic hyperparameter optimization software. Optuna is a versatile tool that allows users to define their own optimization strategies, but in this case, the study did not specify the exact method used. However, based on the information provided, it can be inferred that Optuna was used to search for the best hyperparameters within a defined range of values.

For the Random Forest (RF) and Artificial Neural Network (ANN) models, Optuna was used to search for the best structure and hyperparameters from a set of candidates. The candidates for the RF model included the number of trees (n\_estimators), the maximum depth of the tree, and the minimum number of samples required to split an internal node. For the ANN model, Optuna searched for the number of middle layers, the number of nodes in the input and middle layers, the activation function, and the optimizer.

For the LightGBM models, Optuna's LightGBM Tuner was used for hyperparameter fitting. The LightGBM Tuner is a specialized tuner for LightGBM models that can search for the best hyperparameters within a defined range. The candidates for the LightGBM model included the maximum tree leaves for base learners, L1 and L2 regularization, a subset of features on each iteration (tree), the frequency for bagging, the minimum number of data in one leaf, and the learning rate.

In summary, the hyperparameters of the machine learning models were optimized using Optuna, an automatic hyperparameter optimization software. The study did not specify the exact optimization strategy used, but it can be inferred that Optuna was used to search for the best hyperparameters within a defined range of values.