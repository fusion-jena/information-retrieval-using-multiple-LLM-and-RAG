The context provided does not give information on how the hyperparameters of the models were optimized. Hyperparameter optimization is an essential step in training machine learning models, as it can significantly impact the model's performance. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization.

Grid search involves defining a range for each hyperparameter and training the model with all possible combinations of hyperparameters. Random search, on the other hand, involves randomly selecting hyperparameters within a defined range and training the model multiple times. Bayesian optimization uses a probabilistic approach to select hyperparameters that are likely to result in good model performance.

Without information on how the hyperparameters were optimized, it is difficult to evaluate the effectiveness of the model selection and training process fully. It is possible that the models' performance could be further improved by optimizing the hyperparameters using one of the methods mentioned above. Therefore, it is recommended that future work includes a description of the hyperparameter optimization process.