The provided context does not give specific details about the techniques used to address data bias during the preprocessing of the deep learning pipeline. However, it does mention that the data was split into three datasets: training, validation, and test. Typically, in a deep learning pipeline, the training data is used to optimize the neural network, while the validation dataset is used to assess the performance during the training process. The test dataset is used to assess the performance of the final optimized neural network. The context also states that each orthophoto of size 10,000 × 10,000 pixels was divided into 1525 tiles of 256 × 256 pixels. This process of dividing the data into smaller tiles could be a form of data augmentation, which can increase the power of generalization of the model. However, it is not explicitly mentioned as a technique to address data bias.

Additionally, the context states that the training data was used for optimizing the neural network, while the validation dataset was used to assess the performance during the training process. This process of using a validation dataset to assess the performance during the training process can help to prevent overfitting of the model to the training data, which can be a form of data bias.

In summary, the provided context does not give specific details about the techniques used to address data bias during the preprocessing of the deep learning pipeline, but it does mention the use of a validation dataset to assess the performance during the training process and the process of dividing the data into smaller tiles which could be a form of data augmentation.