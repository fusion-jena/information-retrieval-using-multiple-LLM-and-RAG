The strategy to monitor model performance during training involves a combination of automated metrics and manual checks. First, the model's performance is evaluated on a validation data set and an out-of-sample test data set. The performance is measured using accuracy, precision, recall, and F1 score for each class. Accuracy is the number of correct predictions divided by the total number of images. Precision is the number of true positives divided by the sum of true positives and false positives. Recall is the number of true positives divided by the sum of true positives and false negatives. The F1 score is the harmonic mean of precision and recall.

In addition to these automated metrics, manual classification is also performed on a subset of the training images, validation images, and out-of-sample test images. This manual classification is done to ensure the quality of the data and to provide a ground truth against which the model's performance can be measured.

To improve the model's performance, the strategy includes retraining the model with new training images. These new training images are selected based on the model's output from the original model. For example, if the model had problems identifying a certain species, more images of this species can be included in the training data set. However, all training images should be reviewed manually to avoid misclassified training images.

The strategy also involves the use of a cloud service with specific computational resources for training the models. The models were trained on a cloud service with 1 GPU, 4 CPUs, and 16 GB RAM provided by Sigma2 - the National Infrastructure for High Performance Computing and Data Storage in Norway.

In summary, the strategy to monitor the model performance during training involves the use of automated metrics and manual checks. The model's performance is evaluated on a validation data set and an out-of-sample test data set. Manual classification is performed on a subset of the training images, validation images, and out-of-sample test images. To improve the model's performance, new training images are selected based on the model's output and are manually reviewed. The models are trained on a cloud service with specific computational resources.