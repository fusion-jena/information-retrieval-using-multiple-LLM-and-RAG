The provided context discusses the use of a ResNet-50 deep convolutional neural network (CNN) for classifying sounds in a spectrogram image dataset. However, it does not explicitly mention the techniques used to address data bias during preprocessing of the deep learning pipeline.

That being said, there are several common techniques used to address data bias during preprocessing of a deep learning pipeline, including:

1. Stratified splitting: This technique involves dividing the dataset into subgroups based on certain characteristics (such as class labels), and then ensuring that each subgroup is proportionally represented in both the training and testing datasets.
2. Oversampling: This technique involves increasing the number of instances of the minority class in the dataset, either by duplicating existing instances or by generating new instances using techniques such as SMOTE (Synthetic Minority Over-sampling Technique).
3. Undersampling: This technique involves decreasing the number of instances of the majority class in the dataset, either by randomly selecting a subset of instances or by using techniques such as Tomek links to remove instances that are close to instances of the minority class.
4. Diverse data collection: This technique involves collecting data from a wide variety of sources and ensuring that the dataset is representative of the population being studied.

While the provided context does not mention the use of any of these specific techniques, it does mention that the dataset was split 70/30 into training and testing datasets, and that 50% of the training data were held out for validation. This suggests that some effort was made to ensure that the dataset was representative of the population being studied. However, without further information, it is impossible to say for sure whether any specific techniques were used to address data bias during preprocessing of the deep learning pipeline.