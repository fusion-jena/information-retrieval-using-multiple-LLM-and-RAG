The provided context does not explicitly mention the data formats used in the deep learning pipeline. However, it can be inferred that the data used is in a text format.

The pipeline is designed to classify texts based on their relevance to a specific criterion. The initial figure (Fig. 1) shows a graphical representation of the full classification pipeline, which involves three binary classification tasks. At each step, irrelevant texts are filtered out, and the remaining relevant texts are used to generate training data for the next classification task. Figure 2 represents the different data types collected from online searches, which are further processed for text classification.

Additionally, the context describes the creation of training, development, and testing sets through manual annotation of 2000 randomly selected data points. The data points are randomly split into datasets using a 60â€“20-20 ratio. This process further supports the inference that the data format used is text, as manual annotation is typically used for text data.

Therefore, while the context does not explicitly mention the data format, it can be inferred that the data format used in the deep learning pipeline is text.