The provided context discusses some preprocessing steps taken before training a deep learning model, specifically a semantic segmentation algorithm using a deep convolutional neural network (DCNN). However, it does not explicitly mention normalization, scaling, or cleaning.

The context does mention the use of data augmentation strategies to increase the training set size. These strategies include horizontal flipping, Gaussian noise addition, and contrast reduction. The contrast reduction strategy was specifically motivated by the expectation of shadows in the images, which simulates areas of low lighting.

Additionally, the context mentions that a class-imbalance issue was encountered due to the deep learning method's loss function being biased toward overrepresented classes. This issue was specific to the study, which had few images and high class-imbalance. However, the text does not provide details on how this issue was addressed during preprocessing.

The context also mentions the use of the transfer learning framework, but it does not specify any preprocessing steps related to it.

Therefore, based on the provided context, the preprocessing steps involved before training the deep learning model include data augmentation strategies such as horizontal flipping, Gaussian noise addition, and contrast reduction. However, it does not explicitly mention normalization, scaling, or cleaning.