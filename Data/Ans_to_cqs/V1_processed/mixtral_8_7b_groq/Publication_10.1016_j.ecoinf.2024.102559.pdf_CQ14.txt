The provided context does not give specific information on how the hyperparameters of the model were optimized. There is no mention of techniques such as grid search, random search, or any other method for hyperparameter tuning.

However, the context does provide detailed accuracy metrics for different models used for land use and land cover classification. These models seem to use various features and entropy values within a window across multiple window sizes. The accuracy metrics include Producer’s Accuracy, User’s Accuracy, Counts per class (n), and Overall Accuracy for the classes of interest: Iceplant and Other Vegetation.

While the process of hyperparameter optimization is not explicitly stated, it can be inferred that the authors conducted multiple experiments with different window sizes, feature sets, and entropy calculations. By comparing the accuracy metrics of these models, they likely selected the model with the highest overall accuracy for their specific task.

In general, hyperparameter optimization is an essential step in machine learning model development, as it helps to find the best set of parameters for a given model and dataset. Grid search, random search, and Bayesian optimization are common methods for hyperparameter tuning. Grid search exhaustively searches through a manually specified subset of the hyperparameter space, while random search randomly selects hyperparameters to try within a defined range. Bayesian optimization uses probabilistic modeling to make informed suggestions for the next set of hyperparameters to try.

In summary, although the provided context does not explicitly mention the method used for hyperparameter optimization, it can be inferred that the authors compared multiple models with different settings to find the best-performing one. However, the specific hyperparameter optimization technique remains unknown.