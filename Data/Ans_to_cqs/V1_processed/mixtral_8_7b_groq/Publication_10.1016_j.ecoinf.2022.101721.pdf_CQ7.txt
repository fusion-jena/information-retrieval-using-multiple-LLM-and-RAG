The provided context does not directly discuss the criteria used to split data for deep learning model training. However, it does mention the importance of evaluating the performance of software that incorporates machine learning algorithms not just through training and testing data sets, but also through the number of correct classifications using real-world examples.

In the context of deep learning, data splitting is typically done to create separate sets for training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to evaluate the final performance of the model.

The criteria used to split the data can vary depending on the specific problem and dataset. One common approach is to randomly split the data into a training set (e.g., 70%), a validation set (e.g., 15%), and a testing set (e.g., 15%). However, for some applications, it may be more appropriate to use a stratified sampling approach to ensure that each set has a representative distribution of the target variable.

Another consideration when splitting the data is the size of each set. Having a larger training set can help the model learn more patterns in the data, but it may also require more computational resources and take longer to train. On the other hand, having a larger testing set can provide a more reliable estimate of the model's performance, but it may also limit the amount of data available for training.

In addition to the size and sampling approach, the number of times the data is split can also impact the performance of the model. Cross-validation is a technique that involves splitting the data into multiple folds and training the model on different subsets of the data. This can help reduce the variance of the model's performance estimate and improve its generalizability.

Overall, while the provided context does not directly discuss the criteria used to split data for deep learning model training, it highlights the importance of evaluating the performance of machine learning algorithms using real-world examples in addition to training and testing data sets. When splitting the data for deep learning, it is important to consider the size, sampling approach, and number of splits to ensure that the model is trained and evaluated effectively.