Based on the provided context, there is no explicit information given about the criteria used to determine when training is complete for the hand-crafted feature extraction experiment. The text mainly focuses on describing the dataset, the architecture of the neural network, and the distribution of data for training and testing.

However, in general, when training a neural network, there are several common criteria used to determine when training should be stopped. These criteria include:

1. Validation loss plateau: Training is typically stopped when the validation loss stops decreasing or starts increasing, indicating that the model is overfitting to the training data.
2. Early stopping: This technique involves stopping training when the performance on a validation set stops improving for a certain number of epochs.
3. Patience: This is a hyperparameter that specifies the number of epochs to wait before stopping training if the validation loss does not improve.
4. Monitoring other metrics: In addition to validation loss, other metrics such as accuracy or F1 score can be monitored to determine when training should be stopped.

Without more information about the specific training procedure used in the hand-crafted feature extraction experiment, it is difficult to provide a definitive answer to the query. However, it is likely that one or more of the above criteria were used to determine when training was complete.