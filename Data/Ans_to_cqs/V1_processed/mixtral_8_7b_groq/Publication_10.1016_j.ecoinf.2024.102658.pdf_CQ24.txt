The provided context discusses the use of random forests in a study, but it does not directly mention strategies employed to handle randomness in a deep learning pipeline. However, it does describe how randomness is used in the random forest algorithm.

In the random forest algorithm, randomness is introduced in several ways. First, each tree in the forest is grown from a bootstrap sample of the training data, which means that a different subset of the data is used to train each tree. This introduces variability in the trees that make up the forest.

Second, when splitting nodes in the tree, only a random subset of features is considered. This is known as feature randomness, and it helps to decorrelate the trees in the forest and reduces overfitting.

The study mentioned in the context used two different feature sets, "random-CV" and "spatial-CV," selected through different cross-validation processes. These feature sets were used to fit random forest models, and the final models were selected based on their performance.

However, the context does not mention any strategies used to handle randomness in a deep learning pipeline, such as setting a random seed value. A random seed value is used to ensure reproducibility in deep learning models by controlling the randomness of the initialization of weights and biases in the model.

In summary, while the context provides information on how randomness is used in the random forest algorithm, it does not mention any strategies employed to handle randomness in a deep learning pipeline.