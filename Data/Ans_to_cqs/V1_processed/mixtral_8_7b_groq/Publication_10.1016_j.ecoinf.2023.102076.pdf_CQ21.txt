Based on the provided context, there is no explicit information about specific postprocessing steps such as saliency maps or calculating metrics like precision or recall. However, it does mention that after training the best-performing classifier on the whole dataset, the relevant texts from these predictions are used as data for the next classification task. This suggests that some form of postprocessing is taking place to extract relevant information from the model's predictions.

In the context of machine learning, common postprocessing steps after model training include:

1. **Model Evaluation**: This involves calculating various metrics such as accuracy, precision, recall, and F1 score to assess the performance of the model. A confusion matrix can also be created to visualize the performance of the model.

2. **Feature Importance**: Techniques like Saliency Maps can be used to identify which features the model is focusing on when making predictions. This can provide insights into the model's decision-making process.

3. **Prediction Extraction**: In the context provided, the relevant texts from the model's predictions are used for the next classification task. This suggests a step where the model's predictions are parsed or filtered to extract the most relevant information.

Given the nature of the tasks described in the context (text classification for online wildlife trade analyses), it's plausible that the postprocessing steps include extracting relevant texts or phrases from the model's predictions. However, without more specific information, it's not possible to provide a definitive answer.