The context does not provide specific information on how the hyperparameters of the LASSO model were optimized. Hyperparameters are parameters that are not learned from the data but are set prior to training the model. In the case of the LASSO model, an example of a hyperparameter is the strength of the penalty applied to the coefficients.

There are several methods for hyperparameter optimization, including grid search, random search, and Bayesian optimization. Grid search involves specifying a range of possible values for each hyperparameter and then training the model with all possible combinations of these values. Random search, on the other hand, involves randomly selecting values for the hyperparameters from a specified range and training the model with these values. Bayesian optimization uses a probabilistic model to make informed suggestions for the next set of hyperparameters to try, based on the performance of previous sets of hyperparameters.

Without more information, it is not possible to say for certain which method was used to optimize the hyperparameters of the LASSO model in this study. However, it is mentioned that the LASSO model was used for variable selection and statistical regularization to enhance the prediction accuracy of the model. It is possible that the hyperparameters were optimized using one of the aforementioned methods in order to find the best combination of hyperparameters for improving the model's prediction accuracy.