After training the model, there are several postprocessing steps that can be involved, such as the calculation of metrics, generation of confusion matrices, and the use of saliency maps.

First, metrics calculation is an important step in evaluating the performance of the model. In the given context, the best accuracy on the validation set was obtained using data augmentation, with scores of 0.98 and 0.95 for the train and validation sets respectively. This indicates that the model is performing well in terms of overall accuracy.

Additionally, the non-normalized and normalized confusion matrices were examined to gain a better understanding of the model's performance. The non-normalized confusion matrix showed that the false positives for the cactus class were almost twice the false positives for the non-cactus class, due to the imbalanced classes. However, the normalized confusion matrix showed that the false positives for both classes had the same value, indicating that the errors were equally distributed among the classes.

Another postprocessing step that can be used is the generation of saliency maps. While the context does not specifically mention the use of saliency maps, they can be a useful tool for visualizing the features that the model is paying attention to when making predictions. In the context, the first layer's filters that were learned by the network are presented, along with the feature maps for a cactus example. These feature maps show that the first and second kernels of the CNN highlight some features such as vertical edges, while the third and fourth kernels perform noise removal, and the fifth kernel sharpens features.

Overall, after training the model, postprocessing steps such as metrics calculation, confusion matrix analysis, and saliency map generation can be used to gain a better understanding of the model's performance and the features that it is using to make predictions.