The strategy implemented to monitor the model performance during training involves comparing the predicted test set size with the actual test set size. Specifically, data validation was performed on a captive Amur tiger dataset to determine the optimal number of footprint trails required for the algorithm training set and test sets. A holdback trial partitioning test was conducted on training sets for 44 captive Amur tigers, with the analysis iterated 10 times for each combination of test/training size, and randomly selected trails to examine how the predicted outcome compared with the known test set size.

The results showed that when the test set size was smallest relative to the training set, the optimal classification accuracy was obtained. However, even when the test to training set ratio was 32:12, the predicted value was close to the expected value, demonstrating the robustness of the model. Furthermore, it was observed that when the test set size comprised trails from 4 tigers, and the test/training set size comprised trails from 04/40 tigers, the predicted test set sizes were very similar across a range of partitioning trials. However, when the test set size was 36 tigers, and the test/training ratio was 36/08 tigers, there was a wider range of predicted test set sizes.

Therefore, it can be inferred that the strategy to monitor the model performance during training involved comparing the predicted test set size with the actual test set size, and iterating the analysis multiple times with randomly selected trails to ensure the robustness of the model. The test set size was found to be optimal when it was smallest relative to the training set, and even when the test to training set ratio was higher, the predicted value was close to the expected value, indicating the reliability of the model.