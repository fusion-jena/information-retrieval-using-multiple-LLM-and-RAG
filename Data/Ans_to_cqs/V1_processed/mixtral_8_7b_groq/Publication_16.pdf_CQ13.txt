The hyperparameters used in the deep learning model include a filter size of 2 in the MLP, Backpropagation as the learning algorithm, and Adam as the optimizer. A dropout value of 50% was used in the first three layers to improve generalization and reduce overfitting. The first three layers of the model consist of 256 nodes, while the final layer has a number of nodes equal to the number of classes in the dataset. The model was trained for 100 epochs, and the performance of the trained model was measured using Sensitivity, Specificity, Precision, and Accuracy. The Sensitivity describes the true positive rate, and Specificity describes the true negative rate. Precision is used to show the number of correctly classified species. The learning rate was not explicitly mentioned in the provided context.