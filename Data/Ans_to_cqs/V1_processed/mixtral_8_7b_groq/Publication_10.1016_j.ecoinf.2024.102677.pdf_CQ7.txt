The dataset used for training the deep learning models was divided into three parts: training, validation, and testing. This division was performed in a stratified manner, meaning that the class proportions were maintained across all the parts. The dataset consisted of a total of 4799 images, which were divided into 2880 images for training, 961 images for validation, and 958 images for testing. 

The training set was used to train the models, the validation set was used to evaluate the model performance during training, and the testing set was used to guide the final decision. The learning rate, batch size, and number of epochs were set to 0.0001, 8, and 30, respectively, after parameter tuning. The models were trained on an NVIDIA 3090 GPU with a 256 Ã— 256 image input size.

The validation set was continuously used to assess the model accuracy during training, and the performance of the testing set was used to make the final decision. The learning curves illustrated a reduction in training losses as the number of epochs increased, and all the models converged within a reasonable number of epochs. The ResNet architecture, especially ResNet50 and ResNet101, outperformed the other models. ResNet50 had the best F1-scores for four categories, except for the RRP, and was therefore selected for the case validation.