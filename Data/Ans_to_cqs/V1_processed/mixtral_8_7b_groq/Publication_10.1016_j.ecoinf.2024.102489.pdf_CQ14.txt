The hyperparameters of the Random Forest (RF) model used in the study to evaluate gross primary productivity are optimized using a grid search method. Specifically, the study used GridSearchCV based on out-of-bag (OOB) error and five-fold cross-validation to search for the optimal parameters of the model.

The hyperparameters that were tuned in the study include the number of trees (n\_estimators), minimum number of leaves (minleaf), and number of randomly selected node-split feature variables (max\_features). The n\_estimators were spaced at 50 intervals, ranging from 100 to 1000. The minleaf was set to 2, 5, 10, 20, and 50. The max\_features were spaced at intervals of 1, ranging from 1 to k, where k is the number of characteristic variables.

Grid search is a systematic approach to search for the best combination of hyperparameters in a model. It involves specifying a range of possible values for each hyperparameter and then evaluating the model's performance for every possible combination of these values. The combination that results in the best performance is selected as the optimal set of hyperparameters.

GridSearchCV is a function provided by the scikit-learn library in Python that implements grid search for a given estimator. It performs cross-validation for each combination of hyperparameters, which helps to reduce overfitting and provides a more reliable estimate of the model's performance.

In summary, the hyperparameters of the RF model used in the study were optimized using a grid search method based on out-of-bag error and five-fold cross-validation. The hyperparameters that were tuned include the number of trees, minimum number of leaves, and number of randomly selected node-split feature variables. Grid search is a systematic approach to search for the best combination of hyperparameters, and GridSearchCV is a function provided by scikit-learn that implements grid search for a given estimator.