Based on the provided context, there are no explicit mentions of traditional data augmentation techniques such as flipping, rotating, or scaling that are commonly used in deep learning pipelines. However, there is a description of a specific data manipulation process that involves subsetting background points in the training data to create three different datasets.


In the described procedure, the data augmentation technique applied is background points subsetting. This technique consists of creating three different subsets of background points from the training dataset: "1x", "10x", and "10K". The "1x" selection includes the same number of background points as presences in the training dataset, the "10x" selection includes ten times the number of presences, and the "10K" selection includes 10,000 background points. This approach aims to maintain consistency across background points used to train each model, ensuring there is no variation in model results due to variation in the response variable.

This method differs from traditional deep learning data augmentation techniques like flipping, rotating, or scaling, which create new synthetic samples by applying transformations to the input data. In this case, the background points subsetting technique focuses on creating different subsets of the existing background points in the training dataset, without applying any transformations to the input data.