Based on the provided context, the deep learning pipeline is used for the classification of man-made underwater objects in optical and SAS (Side-Scan Sonar) data. Therefore, the data formats used in this pipeline are related to these types of data.

The paper "Feature set for classification of man-made underwater objects in optical and SAS data" by Abu and Diamant (2022) describes the development of a deep learning model for the classification of man-made underwater objects using optical and SAS data. Optical data refers to images captured by cameras, while SAS data refers to sonar data that provides information about the seafloor.

The paper does not explicitly mention the format of the data used in the deep learning pipeline. However, it is mentioned that the images are processed automatically in an array queue, which suggests that the data format is image-based. Additionally, the paper includes figures showing examples of underwater objects, which are presented as images.

Therefore, it can be concluded that the data format used in the deep learning pipeline described in the paper is image-based, specifically optical images captured by cameras. Other data formats, such as audio or video, are not mentioned in the provided context.