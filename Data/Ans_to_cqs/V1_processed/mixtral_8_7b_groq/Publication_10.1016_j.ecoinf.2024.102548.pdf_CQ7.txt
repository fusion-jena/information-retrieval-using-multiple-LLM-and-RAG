The provided context does not include specific information about the criteria used to split the data for deep learning model training. However, it is common practice in machine learning and deep learning to split data into three sets: training, validation, and testing.

The training set is used to train the model, updating the model's parameters based on the error or loss calculated from the training data. The validation set, also known as the development set, is used during the training process to provide an unbiased evaluation of the model. This set helps to tune hyperparameters and prevent overfitting by providing a means to assess the model's performance on unseen data. Lastly, the testing set, or hold-out set, is used to evaluate the final model's performance. This set is the most unbiased assessment of the model's ability to generalize to new data.

The splitting of data into these sets can be done randomly, stratified, or using other techniques. A common approach is to use 60-20-20 or 70-15-15 splits for the training, validation, and testing sets, respectively. Stratified sampling ensures that the distribution of labels remains similar in each set, which can be important for classification tasks.

In summary, while the provided context does not explicitly mention the criteria used to split the data for deep learning model training, it is standard practice to use a training set, validation set, and testing set. The splitting can be done randomly or stratified, and the proportions of data allocated to each set can vary.