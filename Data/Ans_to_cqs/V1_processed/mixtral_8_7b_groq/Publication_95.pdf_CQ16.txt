The criteria used to determine when training is complete in the given context is the stabilization of the average training loss. The training was stopped after 22,000 iterations when the training loss was no longer decreasing significantly. The specific point at which the training loss was considered stabilized is not mentioned in the context.

Validation loss plateau, which is a common criterion for determining training completion, is not mentioned in this context. Instead, the number of iterations was predetermined based on the recommendation of Redmon and Farhadi, and the training was stopped after this number of iterations regardless of the validation loss.

It's worth noting that monitoring validation loss is still important for evaluating the model's performance and preventing overfitting. Although validation loss was not used as a criterion for training completion in this case, it was likely used to evaluate the model's performance during and after training.