The context provided does not give specific information about the hardware resources used for training the deep learning models mentioned, such as SLSTM, LSTM, and SGRU. However, it is common practice to use Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) for training deep learning models due to their ability to perform parallel processing, which significantly speeds up the training process compared to using a Central Processing Unit (CPU) alone. GPUs and TPUs are specialized hardware designed to handle the computational requirements of machine learning algorithms more efficiently. Therefore, while the text does not explicitly mention the use of GPUs, TPUs, or CPUs, it is highly likely that one of these hardware resources was used for training the deep learning models in this study.