Based on the provided context, the specific metrics used to evaluate the performance of the deep learning model have not been mentioned. The text discusses the formulation of a model called FERM (Flow-based Ecological Reserve Model), which calculates condition scores for ecological targets based on wet spell duration and other parameters.

However, the text does mention an evaluation metric for FERM: the Root Mean Square Error (RMSE). The RMSE score measures the difference between the predicted and actual values, providing a measure of the model's accuracy. It is calculated as the square root of the average of the squared differences between the predicted and actual values.

As for the deep learning model, the context does not provide enough information to determine the specific evaluation metrics used. Common evaluation metrics for deep learning models include accuracy, precision, recall, F1 score, and area under the ROC curve (AUC-ROC), among others. These metrics are used to assess the model's performance in various aspects, such as correctly classifying positive and negative instances, handling imbalanced datasets, and evaluating the model's overall discriminative power.

In summary, while the context provides information on the evaluation metric for the FERM model (RMSE), it does not specify the evaluation metrics for the deep learning model. Common evaluation metrics for deep learning models include accuracy, precision, recall, F1 score, and AUC-ROC.