The provided context does not give specific details about the criteria used to split the data for training a deep learning model. However, it does mention that the clustering performance of a specific model, the dynamic β-VAE, is evaluated on a labelled test set. This implies that the data was likely split into training, validation, and test sets during the model training process.

In general, there are several common strategies for splitting data in machine learning and deep learning. A common approach is to split the data into a training set, which is used to train the model, and a test set, which is used to evaluate the model's performance. Additionally, a validation set can be used during the training process to provide an unbiased evaluation of the model's performance on unseen data. This can help to prevent overfitting, which occurs when the model performs well on the training data but poorly on new, unseen data.

The specific criteria used to split the data can vary depending on the problem and the available data. For example, the data might be split randomly, or it might be split based on certain characteristics of the data, such as time or location. In some cases, the data might be split stratifiedly, in which case the distribution of labels or other important variables is maintained across the different sets.

In the context of the provided information, it is likely that the data was split using one or more of these strategies, although the specific details are not provided. It is also worth noting that the dynamic β-VAE model is a variational autoencoder (VAE) with a dynamic β parameter, which is used to balance the reconstruction loss and the regularization loss during training. This model is used for semi-supervised clustering, which suggests that the data was labeled to some extent, and that the model was trained to optimize a relevant loss function using a small subset of labeled data.