The context does not provide specific information on how the hyperparameters of the models were optimized, such as whether a grid search, random search, or some other method was used. However, it does mention that manual tuning was used for the training of both neural networks. This suggests that someone with expertise in the field likely adjusted the hyperparameters manually based on their knowledge and experience, rather than using an automated optimization method.

Hyperparameters are important for the performance of machine learning models, and finding the optimal set of hyperparameters can be a challenging task. There are various methods for hyperparameter optimization, including grid search, random search, Bayesian optimization, and more. Grid search involves systematically trying out different combinations of hyperparameters within a predefined range, while random search involves randomly selecting hyperparameters within a defined range. Bayesian optimization, on the other hand, uses Bayesian inference to make informed decisions about which hyperparameters to try next based on previous runs.

In summary, while the context does not provide specific information on how the hyperparameters of the models were optimized, it does mention that manual tuning was used. Manual tuning is a process where an expert adjusts the hyperparameters based on their knowledge and experience. Other methods for hyperparameter optimization include grid search, random search, and Bayesian optimization.