The performance of deep learning models in image classification or object detection tasks is commonly evaluated using various metrics, including accuracy, precision, and recall. In the context of evaluating models for image classification or object detection, these terms have specific meanings:

1. Accuracy: It is the ratio of the total number of correct predictions to the total number of samples. However, accuracy alone might not be a sufficient metric for imbalanced datasets.
2. Precision: Precision refers to the ratio of correctly classified positive samples (True Positives) to the total number of classified positive samples (either incorrectly or correctly). In other words, it measures the proportion of true positive predictions out of all positive predictions made by the model.
3. Recall: Recall, also known as sensitivity or true positive rate, is the ratio between the number of positive samples (True Positives) correctly classified as positive to the total number of positive samples. It measures the proportion of true positive predictions made by the model out of all actual positive samples.

In the given context, the researchers used mean average precision (mAP) as the primary performance evaluation metric for detecting seagrass meadows. mAP is a composite metric that combines precision, recall, and mean values. It is calculated by taking the average of precision values at different recall levels.

For instance, Noman et al. (2021b) used mAP to compare the performance of Faster R-CNN with the NASNet model and the Faster R-CNN with Inception V2 for detecting H. ovalis in the ECUHO-1 and ECUHO-2 datasets. They achieved higher mAP values for the proposed model, indicating better overall performance.

In summary, accuracy, precision, and recall are common metrics used to evaluate the performance of deep learning models. However, in the provided context, the researchers used mAP as the primary evaluation metric for seagrass meadow detection.