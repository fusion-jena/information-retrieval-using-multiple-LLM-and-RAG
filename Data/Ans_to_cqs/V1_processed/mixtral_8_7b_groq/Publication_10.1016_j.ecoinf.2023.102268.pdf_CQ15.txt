The provided context does not give explicit information about the optimization techniques used in the deep learning pipeline. However, it can be inferred that some form of optimization would have been used during the training of the ResNet-50 deep convolutional neural network (CNN). This is because the network was pre-trained using millions of labeled images, and it's common practice to use optimization techniques like Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), or others to train deep learning models effectively.

The context also mentions that a Support Vector Machine (SVM) classifier was used after extracting features from the ResNet-50's fully connected layer. Although this is not directly related to the optimization techniques used in training the CNN, it's worth noting that the SVM model would have been optimized using techniques appropriate for SVM training, such as grid search for parameter optimization.

In summary, while the specific optimization techniques used in the deep learning pipeline are not mentioned in the provided context, it's reasonable to assume that standard optimization techniques were used during the training of the ResNet-50 CNN.