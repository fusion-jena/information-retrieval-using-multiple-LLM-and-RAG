Based on the provided context, there is no explicit information about the postprocessing steps applied after training the models. However, it is common practice in machine learning to calculate various metrics and create visualizations to evaluate the performance of trained models.

Some possible postprocessing steps for the given context could be:

1. Metrics calculation: Common evaluation metrics for regression tasks include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared. For classification tasks, metrics like accuracy, precision, recall, F1-score, and Area Under the Curve (AUC) are often calculated.

2. Confusion matrix: In the context of classification problems, a confusion matrix is a table that is often used to describe the performance of a classification model. It can provide insights into the types of errors made by the model, such as false positives and false negatives.

3. Saliency maps: Saliency maps are a technique used to visualize the importance of input features for a given model prediction. They can help in understanding which features the model is focusing on and can be useful for interpretability and debugging purposes.

4. Visualizations: Visualizing the predictions and ground truth data can provide insights into the model's performance. This can be done using various plots like scatter plots, box plots, or histograms.

It is important to note that the specific postprocessing steps depend on the problem at hand and the model's objective. In the provided context, the models are used for regression tasks, so metrics like MSE, RMSE, or MAE would be relevant. However, without further information, it is not possible to provide a definitive answer.