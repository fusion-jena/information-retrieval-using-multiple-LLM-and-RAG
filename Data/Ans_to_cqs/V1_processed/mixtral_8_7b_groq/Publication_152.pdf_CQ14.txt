Based on the provided context, there is no explicit information about how the hyperparameters of the model were optimized, such as through methods like grid search or random search. However, the text does mention that different learning rates were tried for the Stochastic gradient descent (SGD) optimizer and Adam, ranging from 10−2 until 10−8. It is possible that this was done manually, by trying different learning rates and observing the results, rather than through a systematic hyperparameter optimization method. The focus of the text is more on the techniques used to improve the model's performance in identifying the invasive vegetation, such as the use of a custom loss function and an Inverse Euclidean Distance Transform (I-EDT), rather than on the specifics of hyperparameter optimization.