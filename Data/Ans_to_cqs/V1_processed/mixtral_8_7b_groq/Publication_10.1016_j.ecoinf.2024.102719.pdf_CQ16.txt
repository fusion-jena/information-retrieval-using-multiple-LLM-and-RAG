The pieces of context provided do not give specific information about the criteria used to determine when training is complete. However, they do mention that the models were optimized using a validation set, which suggests that some form of validation-based early stopping may have been used. In machine learning, it is common to monitor the performance of a model on a validation set during training and stop training when the performance stops improving or begins to degrade. This can help prevent overfitting and improve the model's generalization ability. The specific implementation of this approach may vary depending on the model and the training algorithm used. For example, some training algorithms may use a patience parameter to specify the number of epochs to wait before stopping if the validation performance does not improve. Other algorithms may use a more sophisticated approach, such as monitoring the performance on a sliding window of the most recent epochs. Without more specific information about the training process used in this study, it is not possible to give a more precise answer.