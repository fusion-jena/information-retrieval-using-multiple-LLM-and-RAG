Based on the provided context, there is no explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it is mentioned that the Random Forest (RF) model was used to examine the relative importance of environmental and anthropogenic variables on invasive plant species richness and abundance separately. The RF modeling approach is a bagging technique that can help to reduce overfitting and improve the model's performance.

In general, when it comes to deep learning model training, data splitting is an essential step to evaluate the model's performance and prevent overfitting. The most common practice is to split the data into three sets: training, validation, and testing.

The training set is used to train the model, and the validation set is used to tune the hyperparameters and prevent overfitting. The testing set is used to evaluate the model's performance on unseen data.

There are different strategies to split the data, such as random sampling, stratified sampling, or time-series splitting. The choice of the splitting strategy depends on the data's nature, size, and the problem's requirements.

In summary, while the provided context does not explicitly mention the criteria used to split the data for deep learning model training, it is a crucial step in deep learning model development. The most common practice is to split the data into training, validation, and testing sets using a suitable strategy based on the data's nature and the problem's requirements.