The text provided does not give explicit information about the deep learning frameworks used to build the models. However, it is mentioned that the models are based on DenseNet-161, ResNet-50, and different variants of Vision Transformers (ViT). 

DenseNet-161 was introduced in the paper "Densely Connected Convolutional Networks" by Huang et al., 2017, but the specific framework used to implement it is not mentioned. ResNet-50 is a model that originated from the paper "Deep Residual Learning for Image Recognition" by He et al., 2016a, 2016b, and it is often implemented using frameworks like TensorFlow or PyTorch.

ViT models, introduced in the paper "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" by Dosovitskiy et al., 2021, and further explored in the paper "MAE: A Simple and Efficient Framework for Pretraining Vision Transformers" by Steiner et al., 2022, are also typically implemented using deep learning frameworks like TensorFlow or PyTorch.

Given the common usage of TensorFlow and PyTorch in the research community and the lack of information pointing to another direction, it is reasonable to assume that these frameworks were used to build the models. However, this is an assumption based on the general context and not on explicit information provided in the text.