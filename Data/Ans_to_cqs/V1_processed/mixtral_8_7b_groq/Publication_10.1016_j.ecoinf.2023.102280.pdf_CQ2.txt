Deep learning-based denoising methods in audio processing, particularly in bioacoustics, commonly use raw waveform data as input. This format consists of a one-dimensional array of numerical values representing the pressure variations of sound waves over time. While some methods may initially convert this data into a time-frequency representation like a spectrogram using a Fast Fourier Transform (FFT), state-of-the-art techniques have demonstrated the potential of directly processing the raw waveform data. This approach eliminates errors introduced during the transformation process and preserves phase information.

In the context of the provided text, deep learning models for noise reduction in bioacoustics often use a U-net architecture, which consists of an encoder and decoder section. The encoder takes the raw waveform data and compresses it into a latent space representation, while the decoder then uses this compressed representation to reconstruct the denoised waveform.

It is important to note that the raw waveform data format is different from other data formats commonly used in deep learning, such as images, videos, or CSV files. Images and videos are typically represented as two- or three-dimensional arrays of numerical values, while CSV files contain tabular data organized into rows and columns.

In summary, deep learning pipelines for audio denoising in bioacoustics primarily use raw waveform data as input. This format allows for more accurate processing and better performance compared to methods that rely on transformed representations like spectrograms.