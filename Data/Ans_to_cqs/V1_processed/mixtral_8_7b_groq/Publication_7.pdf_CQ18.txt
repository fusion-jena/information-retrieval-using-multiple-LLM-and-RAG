The text does not provide explicit information about the strategy implemented to monitor the model performance during training. However, it does mention that they conducted three experiments to evaluate their classifier, which involves training and testing on different subsets of the data. These experiments could serve as a way to monitor the model's performance, as they would provide insights into how well the model generalizes to unseen data. Additionally, they mentioned using patch sizes of 28x28, 224x224, and 448x448, and selecting the patch sizes that give the best classification accuracy. This process also helps to monitor the model's performance by identifying the optimal scale for feature extraction. Furthermore, they fine-tuned the weights of a pre-trained VGGnet using the Benthoz15 dataset. The process of fine-tuning a pre-trained model can also be used to monitor the model's performance, as it allows for the adjustment of the model's parameters to better fit the specific task and dataset.