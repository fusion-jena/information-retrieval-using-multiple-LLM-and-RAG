Based on the provided context, the criteria used to split the data for deep learning model training (e.g., train, test, validation) are not explicitly mentioned. However, the text describes a process of clustering freshness data into classes using a clustering method, and evaluating the clustering results internally using Silhouette and Calinski-Harabasz methods. This process does not seem to involve splitting the data into training, testing, and validation sets for a deep learning model.

In general, when building a deep learning model, it is common to split the data into three subsets: training, testing, and validation. The training set is used to train the model, the testing set is used to evaluate the model's performance on unseen data, and the validation set is used to fine-tune the model's hyperparameters.

The criteria for splitting the data can vary depending on the specific problem and dataset. One common approach is to randomly split the data into training, testing, and validation sets with a ratio such as 70-15-15 or 80-10-10. Another approach is to use stratified sampling to ensure that each subset has a similar distribution of classes or labels.

In some cases, the data may be split based on other factors, such as time or location. For example, in a time series forecasting problem, the data might be split into training, testing, and validation sets based on time, with the training set containing data from the past, the testing set containing data from the recent past, and the validation set containing data from the immediate past or present.

Overall, while the provided context does not directly answer the query about the criteria used to split the data for deep learning model training, it is important to note that data splitting is a crucial step in building a deep learning model, and the criteria for splitting the data should be carefully considered based on the specific problem and dataset.