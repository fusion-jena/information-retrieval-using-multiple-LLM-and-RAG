The criteria used to determine when training is complete for the CNN model in the study is not explicitly stated in the provided context. However, it is mentioned that the model is trained for 100 epochs and checkpointed after each epoch. A validation set is used to identify the parameter setting (epoch) achieving the highest classification accuracy. This suggests that the training process may be monitoring the performance on the validation set after each epoch, and stopping the training when a pre-defined number of epochs have been reached or when the classification accuracy on the validation set stops improving.

Additionally, it is mentioned that during training, the model optimizes cross-entropy loss via mini-batch stochastic gradient descent. This means that the training process is likely also monitoring the loss on the validation set, and may stop the training if the loss on the validation set stops decreasing or plateaus.

It is also worth noting that the study uses a constant learning rate of 0.01, applies dropout to the input of the last two layers with probability 0.5, and applies L2-regularization to the weights of the last two layers with a penalty factor of 0.001. These techniques are used to prevent overfitting and improve the generalization of the model.

In summary, while the exact criteria used to determine when training is complete for the CNN model in the study is not specified, it is likely that the training process is monitoring the classification accuracy and loss on the validation set after each epoch, and stopping the training when a pre-defined number of epochs have been reached or when the classification accuracy or loss on the validation set stops improving.