In the context of deep learning, particularly in the training phase of deep neural networks (DNNs), the available data is often split into different subsets to evaluate the performance of the model and prevent overfitting. The most common data subsets are the training data set, the test data set, and the validation data set (also known as the development set).

The training data set is used to optimize the connection weights between neurons in the DNN by minimizing the prediction error over the training data. The test data set, which consists of data not used during training, is utilized to gauge the accuracy of predictions for new input data. The validation data set, on the other hand, is employed to fine-tune the model's hyperparameters and select the best-performing network architecture.

The criteria used to split the data into these subsets can vary depending on the specific application and the amount of available data. A common approach is to allocate a fixed percentage (e.g., 70-80%) of the data for training, another fixed percentage (e.g., 10-20%) for testing, and the remaining portion for validation. For instance, if you have a dataset of 10,000 samples, you might use 7,000 samples for training, 1,000 samples for testing, and 2,000 samples for validation.

Another approach is to use k-fold cross-validation, where the data is divided into k equal-sized subsets (folds). The model is then trained on k-1 folds and tested on the remaining fold. This process is repeated k times, with each fold serving as the test set once. The average performance across all k runs is then calculated to provide a more robust estimate of the model's performance.

It is important to note that the specific criteria used to split the data can impact the prediction accuracy of the DNN. Factors such as the size of the network, the selection of layer types, and the parameters of the training process can all influence the optimal split ratio. Additionally, the distribution of the data and the presence of any class imbalance should also be taken into account when determining the split criteria.

In summary, the criteria used to split the data for deep learning model training typically involve allocating a portion of the data for training, testing, and validation. The specific split ratio can vary depending on the application and the amount of available data, with common approaches including fixed percentage splits and k-fold cross-validation. The distribution of the data and the model's hyperparameters should also be considered when determining the optimal split criteria.