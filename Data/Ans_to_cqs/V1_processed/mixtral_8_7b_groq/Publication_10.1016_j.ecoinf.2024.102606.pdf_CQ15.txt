The deep learning pipeline in the context provided employs the Adam optimization technique. This information is derived from the statement that mentions the use of the Adam optimizer with specific beta1 value of 0.937 during the training of the models. No other optimization techniques like SGD are explicitly mentioned in the provided context.