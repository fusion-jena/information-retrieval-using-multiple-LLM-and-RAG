The strategy implemented to monitor the model performance during training involves the use of various metrics such as accuracy, precision, recall, and F1 score. These metrics are calculated at each fold of the k-fold cross-validation process, which is used to evaluate the algorithms and models. The k-fold cross-validation involves dividing the dataset into k folds, where k-1 folds are used for training and the remaining fold is used for testing. This process is repeated k times, with a different fold used for testing in each iteration. The average of the metrics calculated over the k folds is used to evaluate the model performance.

Additionally, the relation between the min-batch size and accuracy of the algorithm is also monitored during training. The min-batch size refers to the number of samples in one batch, and it is found that the accuracy of the algorithm is highest when the min-batch size is 128. Furthermore, the larger the min-batch size, the larger the number of epochs required for convergence, which in turn increases the consumed time. Therefore, the min-batch size is adjusted during training to optimize the model performance and convergence time.

Moreover, the pooling operator is used after a layer to extract the main features of a certain area, reduce the number of parameters, and prevent the model from overfitting. The maximum pooling with a 2 × 2 window and 2 strides is used in this layer, resulting in a pooling result with a size of 56 × 56 × 64. After pooling, the LRN (Local Response Normalization) is used to normalize the local response, which enhances the larger response value and reduces the smaller response value, thereby improving the generalization of the model. The output result of the LRN also has a size of 56 × 56 × 64.

Overall, the strategy implemented to monitor the model performance during training involves the use of various metrics, adjusting the min-batch size, and using pooling and LRN to prevent overfitting and improve generalization. These strategies help ensure that the model is performing well and converging efficiently during training.