In the context provided, the data is split for deep learning model training using an 80/20% training-validation split for each class. This means that 80% of the data is used for training the model, and the remaining 20% is used for validation. This split is maintained automatically by the system when assigning samples to training or validation sets.

Additionally, a separate test set containing 500 segments is used to evaluate the model's performance. This test set includes 187 possum vocalizations and 313 noise samples, and its distribution of target features to non-target features is representative of the true distribution post-segmentation.

The test set is used to compare the model's performance to three different sample orderings: model samples (red line), randomly ordered samples (blue line), and active learning using high-certainty samples (yellow line). The baseline accuracy is calculated using a 2-shot, 2-way test accuracy without fine-tuning.

Overall, the data is split for deep learning model training using a combination of a training-validation split and a separate test set. This approach allows for the model's performance to be evaluated accurately and reliably.