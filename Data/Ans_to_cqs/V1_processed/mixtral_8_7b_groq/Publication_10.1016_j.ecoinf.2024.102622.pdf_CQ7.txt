Based on the provided context, there is no explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it does mention the use of a training dataset and a validation set in the context of machine learning models such as Random Forest (RF), Support Vector Machine (SVM), and others.

For instance, in the context of estimating rice canopy coverage in Qian Gorlos irrigation district, the authors used Sentinel-2 data and split the dataset into a training set and a validation set for each modeling method (MLR, RF, SVM, XGboost, and MLP) (Table 4). The training set was used to train the model, while the validation set was used to evaluate the model's performance.

However, the criteria used to split the data into training and validation sets are not specified. Commonly, data can be split randomly or based on certain characteristics such as time or location. For instance, a random split of data can be done using a 70-30 or 80-20 ratio, where 70% or 80% of the data is used for training, and the remaining 30% or 20% is used for validation. Alternatively, a temporal or spatial split can be used, where data from a certain time period or location is used for training, and data from a different time period or location is used for validation.

In summary, while the provided context does not explicitly mention the criteria used to split the data for deep learning model training, it does mention the use of a training dataset and a validation set in the context of machine learning models. Commonly, data can be split randomly or based on certain characteristics such as time or location.