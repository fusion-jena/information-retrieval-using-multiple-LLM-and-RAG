The provided context discusses the application of deep learning methods in species distribution modeling (SDMs) and improvements achieved in this field, but it does not explicitly mention specific data annotation techniques used in the deep learning pipeline. However, based on general practices in deep learning, I can provide some common annotation techniques.

In computer vision tasks, data annotation techniques include:

1. Image-level annotation: In this method, an image is labeled as a whole, indicating the presence or absence of a particular object or class. This technique is useful for simple image classification tasks.

2. Bounding box annotation: This method involves drawing a bounding box around an object of interest in an image. It is commonly used for object detection tasks, where the goal is to locate and classify objects within an image.

3. Semantic segmentation: This technique involves labeling each pixel in an image with a corresponding class. It is useful for tasks requiring pixel-level accuracy, such as scene segmentation or object segmentation.

4. Instance segmentation: Similar to semantic segmentation, instance segmentation labels each pixel in an image with a corresponding class. However, it also differentiates between individual instances of the same class. This method is particularly useful for tasks like counting objects or tracking individual objects in a video sequence.

5. Pixel-level annotation: This technique involves annotating specific pixels in an image with additional information, such as depth or surface normals. It is used in tasks like 3D reconstruction or view synthesis.

In the context of ecological research and SDMs, annotation techniques may include point annotations for presence-only datasets, polygon annotations for habitat boundaries, or line annotations for tracking species movements.

It is important to note that the context provided focuses on advancements in deep learning for SDMs and does not explicitly discuss data annotation techniques.