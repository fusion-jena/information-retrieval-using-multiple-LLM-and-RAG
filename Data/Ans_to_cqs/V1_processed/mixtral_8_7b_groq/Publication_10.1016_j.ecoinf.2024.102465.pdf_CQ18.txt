The text does not provide explicit information about a strategy implemented to monitor the model performance during training. However, it can be inferred that the performance of the LSTM-CNN model was evaluated through a comparative analysis with other models such as Rostcm 6.0, Simple Bayesian Networks, and Convolutional Neural Networks in pre-tests. This suggests that the model's performance was compared and assessed relative to other models, implying a form of performance monitoring.

Additionally, the SHAP method was used to interpret the XGBoost model's calculations. SHAP (SHapley Additive exPlanations) is a method to explain the output of any machine learning model. It provides insight into how each feature in the data contributes to the final prediction. This can be seen as a way to monitor the model's performance by understanding how well the features are being used in the model's decision-making process.

However, these methods do not directly answer the query about monitoring the model performance during training. For a more comprehensive understanding of the model's performance, it would be beneficial to have information about strategies used to monitor the model's performance during the training phase, such as validation strategies, learning curve analysis, or early stopping techniques. Unfortunately, the provided text does not contain such details.