Based on the provided context, there are several postprocessing steps that can be involved after the model training, such as calculating metrics, generating saliency maps, and creating confusion matrices. However, the specific steps mentioned in the context are related to calculating metrics.

In the context, the models are trained to classify tiles as either "deforestation" or "no-deforestation" classes. After training, the performance of the models is evaluated using several metrics, including Overall Accuracy (OA), F1-Score, and Alarm Area (AA).

Overall Accuracy (OA) is a global metric that indicates the percentage of samples correctly classified in relation to the total samples. It is defined as the sum of true positives (tp) and true negatives (tn) divided by the sum of total positives (P) and total negatives (N) in the equation: OA = (tp + tn) / (P + N) x 100%.

F1-Score is a harmonic mean of precision and recall, where precision is the proportion of true positives among all positive predictions, and recall is the proportion of true positives among all actual positives. F1-Score is a better metric than accuracy when dealing with imbalanced classes.

Alarm Area (AA) is a metric used to evaluate the model's ability to flag areas as potentially deforested. It is defined as the proportion of total deforestation concentrated in the areas indicated by the classifier.

Therefore, after training the models, the postprocessing steps would involve calculating these metrics for each model and comparing them to evaluate the models' performance. However, there is no mention of generating saliency maps or creating confusion matrices in the provided context.

In summary, the postprocessing steps involved after the model training include calculating Overall Accuracy (OA), F1-Score, and Alarm Area (AA) metrics to evaluate the models' performance.