Based on the provided context, there is no specific strategy mentioned for monitoring the model performance during training. However, it does mention that active learning sample selection strategies are used to reduce the number of required annotations to achieve model convergence. This implies that the model's performance is being monitored indirectly through the process of active learning. 

In active learning, the model's performance is evaluated on a subset of the data, and the next batch of data to be annotated is selected based on this performance. This process continues iteratively, with the model's performance improving with each batch of annotated data. Therefore, the model's performance is being continuously monitored and evaluated throughout the training process, although not in the traditional sense of tracking metrics like loss or accuracy over each epoch.

The context also mentions that class labels are available for all samples used in the study, but are hidden from the classifier at first and incrementally revealed by the sampling methods. This suggests that the model's performance is being evaluated against the true class labels, allowing for an accurate assessment of the model's performance as it is being trained.

In summary, while there is no specific strategy mentioned for monitoring the model performance during training, the use of active learning sample selection strategies implies that the model's performance is being continuously monitored and evaluated throughout the training process.