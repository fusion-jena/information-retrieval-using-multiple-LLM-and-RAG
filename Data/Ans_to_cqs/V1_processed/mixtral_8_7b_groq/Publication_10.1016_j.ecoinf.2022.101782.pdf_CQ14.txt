The provided context does not give information on how the hyperparameters of the model are optimized. Hyperparameter optimization is an essential step in machine learning model development, where the best set of hyperparameters is determined for a given model and dataset. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization. Grid search exhaustively tries all combinations of predefined hyperparameter values, while random search randomly selects hyperparameter values to try. Bayesian optimization uses a probabilistic model to make informed decisions about which hyperparameters to try next. However, the provided text does not mention which method, if any, was used for hyperparameter optimization in the red kite classification model.