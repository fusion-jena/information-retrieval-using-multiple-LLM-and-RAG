The data was split for deep learning model training using specific criteria to create the training, validation, and testing sets. For each dialect class, the first 70% of songs were used as the training set, the next 10% as the validation set, and the last 20% as the test set. This approach reduces variability between tests and ensures that the models are trained and validated on 80% of the full dataset.

The validation set was employed to tune the hyperparameters of the Convolutional Neural Network (CNN), while the k-Nearest Neighbors (k-NN) model only required tuning the value of k, which was set to 4, as it yielded the best performance after testing several values. Both the training and validation sets were used directly to fit the k-NN. Therefore, the CNN spectrogram classifier and the k-NN location classifier were trained and validated using 80% of the full data set.

The remaining 20% of the data set was reserved for testing the two systems' ability to classify songs correctly. This test set consisted of all Foreign Out of Vocabulary (FOFU) and Limited Out of Vocabulary (LODU) songs and 20% of the other dialect classes. By using this split strategy, the deep learning models were trained and validated on a diverse and representative subset of the data, ensuring that the models can generalize well to unseen data and provide accurate classifications.