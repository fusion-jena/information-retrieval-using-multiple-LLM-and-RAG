Based on the provided context, there is no explicit mention of how randomness is handled in the deep learning pipeline, such as through the use of a random seed value. However, there are some discussions about strategies used in specific steps of the pipeline.

In the first step of the pipeline, a pre-trained detector model is run on images. The specific detector model used is MegaDetector, but there is no information about how randomness is handled during its training.

In the second step, an embedding model (a deep neural network) is learned on a large dataset and then fine-tuned on the target dataset. The context does not provide information about how randomness is managed during the training of this embedding model. Common practices in deep learning include setting a random seed value to ensure reproducibility of results. However, the text does not mention if such a strategy was employed.

In the third step, an active learning procedure is run. The paper describes an algorithm for this procedure, but it does not mention the use of a random seed value or any other method to handle randomness. The algorithm starts with a small, randomly selected labelled subset of data, but it is unclear if a fixed random seed value was used for this initial selection.

The paper also discusses different query selection strategies for active learning, comparing them to random selection. These strategies include confidence, margin, entropy, and least confidence. While these strategies aim to improve the active learning pipeline's performance, they do not directly address the handling of randomness.

In summary, the provided context does not contain explicit information about how randomness is handled in the deep learning pipeline, such as through the use of a random seed value. However, it is possible that common deep learning practices, like setting a random seed value, were employed but not mentioned in the text.