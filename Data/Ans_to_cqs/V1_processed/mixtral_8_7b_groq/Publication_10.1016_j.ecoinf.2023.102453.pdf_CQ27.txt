The process followed to deploy the trained deep learning model involves several steps, including model serialization and platform selection. 

Once the deep learning model has been trained and validated, it needs to be serialized, or converted into a format that can be deployed to a target platform. In this particular study, the model is converted to the TensorFlow Lite format, which reduces its size but may also reduce its accuracy. This format is used for deploying the model to an edge device, such as a Raspberry Pi (RPi).

The selection of the platform for model deployment depends on the specific requirements of the application. In this case, the model is deployed to an edge device for image classification. The RPi or similar edge devices can be used to run XAI techniques such as Grad-CAM for generating visualizations through heatmaps.

It's important to note that the model deployment process may also involve optimizing the model for size or latency, depending on the application requirements and the edge device specifications.

Therefore, the process followed to deploy the trained deep learning model involves model serialization, platform selection, and optional optimization for size or latency.