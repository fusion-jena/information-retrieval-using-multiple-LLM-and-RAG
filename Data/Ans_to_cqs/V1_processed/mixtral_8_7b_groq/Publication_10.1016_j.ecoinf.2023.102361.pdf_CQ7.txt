In the research, the dataset was split into three parts for training, validation, and testing. Specifically, 60% of the data was used for training the deep learning models, 20% was kept for validating the models, and the remaining 20% data was used to evaluate the performance of the models. This splitting approach is a common practice in deep learning to ensure that the model is trained, validated, and tested on different data to prevent overfitting and to assess the model's ability to generalize.

Furthermore, the dataset was divided into patches of images to predict the class label of each patch. After selecting the important patches, the model predicted the class label for each patch. A weighted majority voting technique was then used to predict the class label of the image from the predicted labels. This patch-based approach can help the model focus on specific features of the image and improve the accuracy of the predictions.

The deep learning models used in the research include Resize GAN, Change GAN, MobileNetV2, VGG16, VGG19, ResNet-50, Inception-V3, Inception-ResNetV2, Xception, DenseNet121, DenseNet169, and DenseNet201. The performance of each model was evaluated based on precision, recall, and F1 score. These metrics are commonly used in machine learning to assess the accuracy and balance between false positives and false negatives.

In summary, the criteria used to split the data for deep learning model training include randomly dividing the dataset into three parts for training, validation, and testing, using 60% of the data for training, 20% for validation, and 20% for testing. Additionally, the dataset was divided into patches of images for predicting the class label of each patch, and a weighted majority voting technique was used to predict the class label of the image from the predicted labels. The performance of each model was evaluated based on precision, recall, and F1 score.