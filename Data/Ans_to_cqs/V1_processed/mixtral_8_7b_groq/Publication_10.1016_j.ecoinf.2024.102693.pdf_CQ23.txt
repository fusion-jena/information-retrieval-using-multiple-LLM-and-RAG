The text provided does not give explicit information about the measures taken to ensure the generalizability of the deep learning model. However, there are some implicit indications that suggest certain strategies were used.

Firstly, the models were trained using a deep transfer-learning strategy based on fine-tuning. This approach often enhances the model's ability to generalize, as it initializes the model parameters with a pre-trained model, which has already learned features from a large dataset. This initial learning can be considered as a form of implicit regularization, which can help improve the model's ability to generalize.

Secondly, the models were tested on the IP102 dataset, which is a different dataset from the one used for pre-training. This is a form of external validation, which can also help assess the model's ability to generalize.

Thirdly, the text mentions ablation experiments, but it does not provide details about how these experiments were conducted. If these experiments included techniques like cross-validation or stratified splitting, they could have contributed to ensuring the model's generalizability.

However, without explicit information, it is not possible to provide a definitive answer. It is recommended to refer to the original research paper for more detailed information.