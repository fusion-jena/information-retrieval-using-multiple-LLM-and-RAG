In the provided context, the data is split for deep learning model training using geographical stripes of width 900 pixels (9.0 km) for each ALS project. Specifically, the northernmost 5.4 km of each stripe is assigned to the training set, the next 1.8 km is allocated to the validation set, and the southernmost 1.8 km is used as the test set. This approach ensures that the different regions and modalities in each ALS area are evenly distributed between the three sets.

The total data set consists of 105,022,419 pixels (10,502 km2) of ALS reference data, which is divided into 64,487,551 training pixels (6449 km2), 20,784,407 validation pixels (2078 km2), and 19,750,461 test pixels (1975 km2). This follows the '60-20-20' ratio commonly used in machine learning studies, where 60% of the data is used for training, 20% for validation, and 20% for testing.

It is important to note that the deep learning models are implemented in PyTorch and trained with a batch size of 64 and a base learning rate of 10âˆ’4. The learning rate is automatically reduced by a factor of 0.1 when the validation loss has not improved for 15 consecutive epochs. Weight decay is applied to control the strength of the unit Gaussian prior, with an empirically chosen magnitude of 10âˆ’3 that is inversely proportional to the hyperparameter ğœ† from Eq. (1). The Adam optimizer is used with hyper-parameters ğ›½1 = 0.9, ğ›½2 = 0.999, and ğœ– = 10âˆ’8. Each neural network was trained on a single Nvidia RTX2080Ti GPU for approximately 14 days.