The provided context does not explicitly mention how the hyperparameters of the surrogate model are optimized. However, it does mention that surrogate models need to be built carefully, with optimized parameters to balance variance and bias. Common methods for hyperparameter optimization include grid search, random search, and Bayesian optimization.

Grid search involves defining a range of possible values for each hyperparameter and then testing all possible combinations of these values. While exhaustive, grid search can be computationally expensive, especially for models with many hyperparameters.

Random search, on the other hand, involves randomly selecting values for each hyperparameter within a defined range. This method is less computationally expensive than grid search and can still find good hyperparameter combinations.

Bayesian optimization is a more sophisticated method that uses Bayesian inference to iteratively select hyperparameter values that are likely to result in good model performance. This method can be more efficient than grid or random search, especially for models with many hyperparameters.

Without further information, it is unclear which of these methods (if any) are used to optimize the hyperparameters of the surrogate models mentioned in the provided context. However, it is clear that careful hyperparameter optimization is an important step in building effective surrogate models.