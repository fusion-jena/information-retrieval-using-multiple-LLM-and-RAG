Based on the provided context, there is no explicit information given about the specific criteria used to determine when training of the classifier model is complete. However, it is mentioned that for model selection and parameter optimization, 50% of the training data were held-out for validation. This implies that the training process might include monitoring the performance on the validation set as part of the criteria to determine when to stop the training.

In the context of machine learning, common stopping criteria include:

1. Validation loss plateau: Training is stopped when the validation loss does not improve for a certain number of epochs, indicating that the model is overfitting to the training data.
2. Early stopping: A form of regularization where training is halted as soon as the validation loss begins to increase, preventing overfitting.
3. Monitoring other metrics: In addition to loss, other metrics like accuracy, precision, or recall can be monitored to determine when to stop training.

In this specific case, the final classification model is a SVM with a cubic polynomial kernel. The training process for SVMs typically involves solving a quadratic programming problem, and it does not inherently include early stopping or validation loss plateau monitoring. However, in the context of this study, it is possible that the authors implemented custom stopping criteria based on the validation set performance.


Although the specific criteria are not mentioned in the provided context, it can be inferred that the training process might include monitoring the performance on a held-out validation set as part of the determination for when to stop the training. Common criteria include validation loss plateau, early stopping, and monitoring other metrics.