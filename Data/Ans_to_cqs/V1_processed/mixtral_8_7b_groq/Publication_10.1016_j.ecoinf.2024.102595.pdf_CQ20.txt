The provided text does not offer explicit information about the specific hardware resources used for training the deep learning model. However, it is mentioned that both deep learning algorithms and traditional machine learning approaches were employed in the study, with hyper-parameter tuning performed via GridSearchCV with cross-validation.

Typically, when dealing with computationally intensive tasks such as deep learning model training, researchers and developers utilize specialized hardware to accelerate the process. Commonly used hardware for this purpose includes Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs). GPUs are particularly well-suited for parallel processing, making them a popular choice for deep learning tasks. TPUs, on the other hand, are custom-built by Google for machine learning and offer even greater performance for specific types of tensor operations.

Given the general nature of the text and the lack of specific details regarding the hardware resources used, it is reasonable to assume that GPUs or similar accelerators were employed for training the deep learning model. However, without more concrete information, it is impossible to provide a definitive answer.