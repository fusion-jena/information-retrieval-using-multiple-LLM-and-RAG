The strategy implemented to monitor the model performance during training involves separating the training data into two groups: a training group and a validation group. This approach is used in the proposed model to track the generalization performance of the deep learning (DL)-based model. By doing so, it is possible to cease the training when the generalization performance starts to degrade for a certain number of epochs. This strategy is known as the early stopping strategy.

In addition to the early stopping strategy, the dropout approach is also implemented to deal with the overfitting problem. Dropout is a regularization strategy that allows training neural networks with alternative topologies in parallel by randomly dropping out a certain proportion of layer neurons. This approach helps to prevent overfitting by introducing randomness during the training process.

The use of these strategies is crucial in ensuring the successful training of the predictive model. The optimal configuration of hyperparameter values has a direct effect on the model's performance and the tested dataset. Hyperparameter tuning is a compute-intensive procedure due to the large number of possible combinations to test and the computational resources required. However, by implementing strategies such as early stopping and dropout, it is possible to monitor the model performance during training and prevent overfitting, thereby ensuring a successful ML application.