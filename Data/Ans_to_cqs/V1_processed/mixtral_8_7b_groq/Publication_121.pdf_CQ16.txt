The criteria used to determine when training is complete is not explicitly stated in the provided context. However, it can be inferred that the training process is evaluated based on the training and validation accuracies, as well as the losses of the training samples in each epoch. The models were validated using sparse categorical cross-entropy loss and the performances were evaluated by calculating accuracies and losses. The training was likely continued until a satisfactory level of accuracy and loss was achieved, or until overfitting became a concern.

In Figure 2, the training accuracy of the MobileNetV2-based model reaches up to 97% and the validation accuracy up to 84%. Similarly, the training accuracy of the MobileNetV3-Large-based model reaches up to 94% and the validation accuracy up to 87%. After fine-tuning, as shown in Figure 3, the training accuracy of the MobileNetV2-based model is improved to 97%, and the validation accuracy remains at 86%. The training accuracy of the MobileNetV3-based model is improved to up to 96%, and the validation accuracy up to 89% after 10 epochs.

It can be noted that the gap between training and validation curves for the MobileNetV3-based model is less than the MobileNetV2-based model, indicating that the MobileNetV3-based model may be less prone to overfitting. This suggests that the training of the MobileNetV3-based model may have been stopped closer to the point of optimal generalization.

In conclusion, while the exact criteria used to determine when training is complete are not specified, it can be inferred that the training process is evaluated based on the training and validation accuracies and losses. The models were likely trained until a satisfactory level of accuracy and loss was achieved, or until overfitting became a concern.