Based on the provided context, it is not explicitly stated which measures were taken to ensure the generalizability of the deep learning model. However, there are some indications that the researchers might have considered certain techniques to enhance the model's ability to generalize.

Firstly, the paper by Yang et al. (2022a) discusses transfer learning, which is a technique where a pre-trained model is fine-tuned on a new dataset. This can help improve the model's performance, especially when the new dataset is small. In this context, the authors have fine-tuned several pre-trained models, including MobileNetV2, GoogleNet, DenseNet201, InceptionV3, ResNet18, InceptionResNetV2, and NASNetMobile. This suggests that they might have used transfer learning to enhance the generalizability of their models.

Secondly, the authors have used a 60:40 split for training and testing data, as reported in Table 8 of the paper. While this is not a stratified splitting or cross-validation, it still provides a way to evaluate the model's performance on unseen data. However, it is important to note that the dataset used may not fully capture the diverse range of bird populations present in the wild, as mentioned in the text. This could potentially impact the accuracy and generalization ability of the model.

Lastly, the paper by Snoek et al. (2015) discusses scalable Bayesian optimization using deep neural networks. While this is not directly related to the current study, it shows that the authors are aware of advanced techniques for hyperparameter optimization and model selection. This suggests that they might have employed similar methods to ensure the generalizability of their deep learning model.

In conclusion, while the provided context does not explicitly state which measures were taken to ensure the generalizability of the deep learning model, there are indications that the authors might have used techniques such as transfer learning, training-testing splitting, and advanced hyperparameter optimization methods. However, it is important to acknowledge the limitations and potential biases of the training dataset when interpreting the results.