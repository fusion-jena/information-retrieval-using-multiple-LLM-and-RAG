The context provided does not give specific information about the hardware resources used for training the deep learning model. It mainly focuses on the data preprocessing, training scheme, and input selection for the CNN model used in the study.

However, it is common practice to use Graphics Processing Units (GPUs) for deep learning model training due to their ability to perform parallel processing, which significantly speeds up computations compared to using CPUs. Training large neural networks on CPUs would be time-consuming and not practical. Therefore, it is reasonable to assume that GPUs were used for training the deep learning model in this study, but this information is not explicitly stated in the context.

Additionally, there are other hardware accelerators available for deep learning model training, such as Tensor Processing Units (TPUs) developed by Google. TPUs are custom-built ASICs (Application-Specific Integrated Circuits) designed specifically for machine learning tasks. They are optimized for high-performance tensor operations, which are fundamental to deep learning model training. However, the context does not mention anything about using TPUs for model training.

In summary, the context does not provide information on the hardware resources used for training the deep learning model. However, it is common practice to use GPUs for deep learning model training, and it is reasonable to assume that GPUs were used in this study. There is no mention of using TPUs or other hardware accelerators in the context.