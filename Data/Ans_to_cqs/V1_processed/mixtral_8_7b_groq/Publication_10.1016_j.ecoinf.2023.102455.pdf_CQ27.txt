Based on the provided context, the process followed to deploy the trained deep learning model seems to involve training different models, testing them, and comparing their performance. However, specific details about model serialization or platform selection are not provided. Here's a summary of what we know:

1. **Model Selection and Training:** The deep learning models used include CNN-BiGRU, RVFL, KELM, and CNN-BiRNN. For each model, a training phase is followed by a testing phase. This process is repeated multiple times, as indicated by the recurring pattern of "Training" and "Testing" in the context.

2. **Performance Evaluation:** The performance of each model is evaluated using metrics such as R (coefficient of determination), RMSE (Root Mean Squared Error), and MAPE (Mean Absolute Percentage Error). These metrics are calculated for each testing phase.

3. **Hyperparameter Tuning:** The context suggests that hyperparameters were tuned for some models. For instance, the CNN-BiGRU model has specific configurations for the number of CNN layers, filters, kernel size, BiGRU layers, BiGRU neurons, optimizer, activation function, epochs, batch size, learning rate, and Dense. Similarly, the RVFL and KELM models have their own sets of hyperparameters.

4. **Comparative Analysis:** Four complementary models are created using MVMD (Multivariate Variational Mode Decomposition) with each of the four base models (MVMD-CNN-BiGRU, MVMD-RVFL, MVMD-KELM, and MVMD-CNN-BiRNN). These models are likely used for a comparative analysis.

However, the context does not provide information on how the trained models were deployed, such as whether they were serialized and how they were integrated with a platform. Therefore, a definitive answer to the query cannot be provided based on the given context.