The context provided does not give explicit information about the specific criterion used to determine when training is complete. However, it can be inferred that the training process might be stopping based on a validation loss plateau or perhaps an epoch limit, as is common in machine learning tasks.

In the given context, there are several figures comparing training accuracy, validation accuracy, training loss, and validation loss across different models. These comparisons suggest that the training process might be evaluating the performance on both the training set and a separate validation set to assess convergence and generalization. 

Moreover, the context introduces the concept of model training time, which is defined as the time required for a neural network to converge to a predefined accuracy or loss threshold. This implies that there is indeed a threshold being used in the training process, which could be related to either accuracy or loss.

Additionally, the authors mention that each model underwent training for 10 epochs, which could also indicate a possible epoch limit for the training process. Nonetheless, without explicit information, it is not possible to definitively state the exact criterion used to determine when training is complete.