The generalizability of the deep learning model was ensured through various measures, including data preprocessing, cross-validation, and the selection of the best set of hyperparameters.

Firstly, the variables were scaled before being passed to the model by removing the mean and scaling to unit variance. This step was taken to avoid the effect that the different scale of the variables could have on the results.

Secondly, cross-validation was used to evaluate the performance of the model and ensure its generalizability. During the cross-validation process, there were no discrepancies among the three metrics used, and generally, the best model for each set of variables was optimal regarding the three metrics or the differences were less than 1%. In case of small discrepancies, the model with the highest AUC was chosen.

Thirdly, the selection of the best set of hyperparameters was made according to three commonly used metrics: binary accuracy, recall calculated as TP/(TP + FN), and the area under the ROC curve (AUC). The initial hyperparameters space was defined and explored with the original variables to avoid an exhaustive search that could consume a lot of time.

Lastly, the model's generalizability was ensured by using a binary variable that stores the existence of stratification or not as the target, while the independent variables were defined as the predictors. The binary variable was added to the dataset as a new categorical binary variable that stored the existence of stratification or not, taking the value of 0 when the reservoir was not stratified and 1 when it was stratified.

Therefore, the generalizability of the deep learning model was ensured through data preprocessing, cross-validation, the selection of the best set of hyperparameters, and defining the binary variable as the target while the independent variables were defined as the predictors.