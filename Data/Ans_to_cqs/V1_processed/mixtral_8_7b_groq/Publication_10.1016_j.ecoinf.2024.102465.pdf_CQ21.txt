Based on the provided context, there is no explicit information about the postprocessing steps involved after the model training. However, it does mention the use of the "ERNIE" model, which is a pre-trained model, so some postprocessing may have been done during its development.

In general, after training a model like the LSTM-CNN used in this study, there are several common postprocessing steps. One such step is to calculate various metrics to evaluate the model's performance. These metrics can include accuracy, precision, recall, and F1 score, among others. The confusion matrix, which is a table showing the number of true positives, true negatives, false positives, and false negatives, can be used to calculate these metrics.

Another postprocessing step is to generate saliency maps, which are visualizations that show which input features the model is paying the most attention to when making its predictions. Saliency maps can be useful for understanding how the model is making its decisions and for identifying any potential biases in the data.

In the context of this study, it's possible that the authors calculated metrics such as accuracy or F1 score to evaluate the performance of their LSTM-CNN model. However, without more information, it's impossible to say for sure. Similarly, while the study does not explicitly mention saliency maps, it's possible that the authors used them or a similar technique to understand the model's decision-making process.

In summary, while the provided context does not give specific information about the postprocessing steps used in this study, common postprocessing steps for trained models like the LSTM-CNN used here include calculating metrics to evaluate performance and generating saliency maps to understand the model's decision-making process.