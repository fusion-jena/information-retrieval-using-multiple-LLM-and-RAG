The criteria used to split the data for deep learning model training typically include creating separate sets for training, validation, and testing. However, the provided context does not explicitly mention the specific criteria used for splitting data in the context of deep noise reduction techniques for bioacoustics.

In general, the data splitting criteria are as follows:

1. Training set: This is the portion of the data used to train the model. The model learns patterns from this data and adjusts its parameters to minimize the difference between the predicted and actual values.

2. Validation set: This is a subset of the data used to validate the model during the training phase. The validation set helps to tune hyperparameters and prevent overfitting. The model is evaluated on the validation set after each epoch (or a specified number of epochs) to assess its performance. If the performance on the validation set starts to degrade, even if the training loss is still decreasing, it may indicate overfitting, and the training process should be stopped or adjustments should be made to the model or training procedure.

3. Testing set: This is the final portion of the data used to evaluate the model's performance after training. The testing set is used to provide an unbiased estimate of the model's ability to generalize to new, unseen data. The model should ideally be tested on data that is representative of the real-world use cases it is designed to handle.

In the context of deep noise reduction techniques for bioacoustics, the provided context suggests that data splitting might not be a primary concern. This is because, in many cases, collecting clean recordings is infeasible, and generating synthetic noisy and clean pairs for training is already a challenge. Additionally, data augmentation techniques such as superimposing noise samples should be considered due to the abundance of noise features in bioacoustics applications.

However, if data splitting is required for these techniques, a common approach is to use 70-80% of the data for training, 10-15% for validation, and the remaining 10-15% for testing. These percentages can be adjusted based on the size and complexity of the dataset and the specific requirements of the project.