The text provided does not give specific details about how the data was split for the deep learning experiment. However, it does mention that there was no segmentation applied to the data and that it was resized to 224x224 pixels before running the network on the data. This suggests that the data was not split using any specific criteria related to the content of the images, but rather was simply divided into training and test sets.

In general, when training a deep learning model, it is common to split the data into three subsets: a training set, a validation set, and a test set. The training set is used to train the model, the validation set is used to tune hyperparameters and make decisions during the training process, and the test set is used to evaluate the final performance of the model.

In the context of the hand-crafted feature extraction experiment described in the text, the data was split into training and test sets by taking 70% of the data for training and 30% for testing. However, this approach was considered biased because it did not take into account the fact that all images of a given species were either used for training or for testing. To avoid this bias, the authors suggest splitting the data at the specimen level, so that all images of a given specimen are either used for training or for testing.

It is possible that a similar approach was used for the deep learning experiment, but the text does not provide enough information to confirm this.