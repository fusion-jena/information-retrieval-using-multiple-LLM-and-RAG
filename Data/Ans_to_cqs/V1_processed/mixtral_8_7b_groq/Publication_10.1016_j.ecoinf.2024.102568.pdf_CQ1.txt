The context provided does not give specific information about the data collection methods used in the deep learning pipeline. However, it does mention the use of air quality sensors and legal stations for collecting air quality data.

In the Hafner (2014) paper, the Air Sensor Guidebook published by the US Environmental Protection Agency is discussed. This guidebook provides information on various types of air sensors and their applications. It is likely that such sensors were used for data collection in the deep learning pipeline.

The Zaytar and Amrani (2020) paper discusses machine learning methods for air quality monitoring. While they do not explicitly mention data collection methods, they do discuss the use of air quality data in their machine learning models.

The Zimmerman et al. (2018) paper presents a machine learning calibration model using random forests to improve sensor performance for lower-cost air quality monitoring. Again, while they do not explicitly mention data collection methods, they do discuss the use of raw measurements of pollutants, air temperature, and humidity in their model.

The Costa and Pitoura (Eds.) (n.d.) paper discusses the database structure for storing air quality sensor and legal station information. The database is implemented following the standard "ISO 19156:2011 Geographic information - Observations and Measurements" and the TAQE model defined for Traffic and Air Quality Applications in Smart Cities. The database is a PostgreSQL database with PostGIS extension to handle geospatial data and Timescale extension to make SQL scalable for time-series data. This suggests that the data was collected through sensors and legal stations and stored in a database for further analysis.

Therefore, based on the provided context, it can be inferred that air quality sensors and legal stations were used for data collection in the deep learning pipeline. However, the specific data collection methods used are not explicitly mentioned.