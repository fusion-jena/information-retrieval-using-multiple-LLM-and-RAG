The text does not provide explicit information about how the raw audio data was collected in the deep learning pipeline. However, it does mention that the data was collected over a year and then segmented into 8-second-long clips. This suggests that some form of continuous audio recording was used, such as sensors or recording devices placed in the environment.

The fact that the data was collected in an ecological study also suggests that the raw data was collected through field surveys or monitoring. The study's focus on bioacoustic data, specifically the cardinal bird's song sequence and the siren call, further supports this hypothesis.

It is also possible that some of the data was obtained from public datasets, although the text does not mention this specifically. However, the use of the Librosa python package for data processing suggests that the data was in a digital format and could have been obtained from various sources.

In summary, while the text does not provide explicit information about how the raw data was collected, it suggests that some form of continuous audio recording, such as sensors or recording devices placed in the environment, was used. Additionally, the study's focus on bioacoustic data and the use of the Librosa python package suggest that the data was in a digital format and could have been obtained from various sources, including field surveys, monitoring, or public datasets.