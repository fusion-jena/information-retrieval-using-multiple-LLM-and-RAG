Based on the provided context, there is no explicit mention of measures such as diverse dataset, cross-validation, or stratified splitting to ensure the generalizability of the deep learning model. However, there are some actions taken that might have contributed to the model's generalizability indirectly.

Firstly, the research team used the original data without forcing the number of samples of various forest types to be the same. This approach allowed the model to learn from the natural distribution of the data, which could help improve its ability to generalize to new, real-world data.

Secondly, the team applied data augmentation techniques such as image rotation and overlapping plots. Data augmentation can increase the size and diversity of the training set, which can help improve the model's ability to generalize to new data.

Lastly, the study used two different network architectures, VGG19 and ResNet50, and tested them under various numbers of bands and data formats. This approach could help ensure that the model's performance is not dependent on a specific architecture or data format, thereby improving its generalizability.

However, it is important to note that these actions do not explicitly ensure the generalizability of the model. To further improve the model's generalizability, the team could have considered techniques such as cross-validation, stratified splitting, or using a diverse dataset from different sources or regions.