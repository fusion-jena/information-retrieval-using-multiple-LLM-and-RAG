The hyperparameters used in the deep learning models, as mentioned in the provided context, are as follows:

1. Unet Model:
   - Initial Learning Rate: The model's initial learning rate was set to 0.01.
   - Optimizer: The Stochastic Gradient Descent (SGD) optimizer was used.
   - Activation Function: The ReLu activation function was utilized.
   - Loss Function: The Dice loss function was used.
   - Number of Iterations: The number of iterations was 150.
   - Batch Size: The batch size was 4.
   - Downsampling Multiplier: The downsampling multiplier was set at 8.

2. Deeplabv3+ Model:
   - Initial Learning Rate: The model's initial learning rate was set to 0.0001.
   - Optimizer: The Adam optimizer was used.
   - Activation Function: The ReLu activation function was utilized.
   - Loss Function: The Dice loss function was used.
   - Number of Iterations: The number of iterations was 150.
   - Batch Size: The batch size was 2.

3. Pspnet Model: The provided context does not include specific information about the hyperparameters used in the Pspnet model. Therefore, I cannot provide an answer for this model.

Please note that these hyperparameters were determined through iterative testing to optimize the performance of the models.