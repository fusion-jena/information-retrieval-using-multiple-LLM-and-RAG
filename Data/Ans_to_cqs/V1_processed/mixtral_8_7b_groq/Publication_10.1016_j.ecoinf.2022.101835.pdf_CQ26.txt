Based on the provided context, there is no information about the specific techniques used for addressing data bias during the preprocessing of the deep learning pipeline. However, the context does mention that a part of the data is randomly selected without resampling, which is referred to as "Randomly select a part of data without resampling" in the given options. This technique can help in reducing bias to some extent by ensuring that each instance in the dataset has an equal chance of being selected for each iteration.

Moreover, the context also describes the use of Optuna for optimizing the structure and hyperparameters of the machine learning models. Optuna is a hyperparameter optimization framework that uses Bayesian optimization, which can help in reducing bias by intelligently exploring the hyperparameter space and avoiding local optima.

However, it is important to note that addressing data bias is a critical aspect of building fair and unbiased machine learning models. Therefore, it is likely that the authors have employed some techniques to address data bias during the preprocessing stage, but they are not mentioned in the provided context.

Some common techniques for addressing data bias during preprocessing include:

1. Stratified splitting: This technique involves dividing the dataset into strata based on the sensitive attribute (e.g., gender, race, age) and then randomly sampling instances from each stratum to ensure that the training and test sets have a similar distribution of the sensitive attribute.
2. Oversampling: This technique involves increasing the number of instances in the minority class to balance the class distribution.
3. Undersampling: This technique involves decreasing the number of instances in the majority class to balance the class distribution.
4. Diverse data collection: This technique involves collecting data from diverse sources to ensure that the dataset is representative of the population.

Therefore, it is recommended to consider these techniques when preprocessing the dataset to ensure that the machine learning models are fair and unbiased.