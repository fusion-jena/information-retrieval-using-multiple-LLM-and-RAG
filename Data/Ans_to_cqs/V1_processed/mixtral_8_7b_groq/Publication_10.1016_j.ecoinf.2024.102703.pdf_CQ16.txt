In the context provided, there is no specific information about the criteria used to determine when the training of the artificial neural network is complete. However, it does mention that the maximum training times were set to 10,000. This means that the training would stop either when the training error reaches 0.001 or after 10,000 training iterations, whichever comes first. 

In general, when training a neural network, several criteria can be used to determine when training is complete. One common method is to stop training when the validation loss stops decreasing, even if the training loss is still decreasing. This is based on the idea that if the network is overfitting to the training data, the training loss will continue to decrease while the validation loss increases or plateaus. 

Another criterion is to set a maximum number of training iterations, as was done in the context provided. This can help prevent overfitting by ensuring that the network does not train for too long. 

Additionally, early stopping can be used, which is a form of regularization where training is stopped as soon as the validation loss starts to increase. 

In some cases, a combination of these criteria may be used. For example, training could be stopped when either the validation loss plateaus or the maximum number of training iterations is reached. 

In conclusion, while the context provided does not give specific information about the criteria used to determine when training is complete, in general, criteria such as validation loss plateau, maximum number of training iterations, and early stopping can be used.