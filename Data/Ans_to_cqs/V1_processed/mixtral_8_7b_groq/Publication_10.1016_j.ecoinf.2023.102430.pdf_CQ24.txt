The text provided discusses a study where five different algorithms, including a deep learning model (AN), were trained and tested on a dataset of 6570 pictures. To account for randomness, the training and testing process was repeated 10 times for each algorithm, using the same training and testing subsets for all five algorithms in each replicate run. This approach helps gauge the performance consistency of the algorithms and accounts for variability that may arise due to the randomness in the training process.

For the deep learning model (AN), the stochastic gradient descent with momentum optimizer was used with a specified initial learning rate of 0.001 and a maximum number of epochs of 15. These settings were determined after preliminary tests, suggesting that the choice of hyperparameters can influence the training process and help manage randomness.

Furthermore, a 'replicate' random effect was included in the models to account for the variability arising from the repeated training and testing runs. This random effect helps capture the variation due to the randomness in the training process and provides a more robust assessment of the model's performance.

In summary, the strategies employed to handle randomness in the deep learning pipeline in this study include:

1. Repeated training and testing (10 times) to gauge performance consistency.
2. Specifying initial learning rate and maximum number of epochs for the deep learning model.
3. Including a 'replicate' random effect in the models to account for variability due to the randomness in the training process.

These strategies help ensure that the deep learning model's performance is robust and consistent, despite the randomness inherent in the training process.