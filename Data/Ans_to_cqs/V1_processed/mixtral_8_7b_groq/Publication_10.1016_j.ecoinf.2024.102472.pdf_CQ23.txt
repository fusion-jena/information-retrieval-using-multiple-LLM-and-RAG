Based on the provided context, there are no explicit details about the measures taken to ensure the generalizability of a deep learning model. However, there are some implicit indications of techniques that may have been used.

Firstly, the use of a "validation data" is mentioned, which suggests that the data was divided into separate sets for training and validation. This is a common practice in machine learning to assess the model's performance and avoid overfitting.

Secondly, the hyperparameters of the network were tuned using a grid search method. Grid search involves systematically trying different combinations of hyperparameters to find the best set of parameters that yield the best performance. This technique can help in finding a good generalized model by avoiding underfitting or overfitting.

Thirdly, the artificial neural network (ANN) model was compared with an XGBoost model and a Boruta model. Comparing the results of different models can provide insights into the generalizability of the model. If a model performs well across different datasets or models, it is more likely to be generalizable.

Lastly, the study by Domingues et al. (2020) used artificial neural networks on integrated multispectral and SAR data for high-performance prediction of eucalyptus biomass. Although this study is not directly related to the query, it provides an example of how ANN models can be used for predicting biomass, which may involve techniques to ensure generalizability.

In conclusion, while there is no explicit mention of measures taken to ensure the generalizability of the deep learning model, the use of validation data, hyperparameter tuning, and model comparison suggest that some steps were taken to prevent overfitting and improve the model's generalizability. However, without further information, it is difficult to provide a definitive answer.