The context does not provide specific information about which deep learning frameworks, such as TensorFlow or PyTorch, were used to build the deep learning models. The focus of the provided context is on the different types of Convolutional Neural Network (CNN) architectures and input representations used for bird sound classification, as well as the methods used to handle varying length audio data.

The first CNN-based model uses a VGG style network, which was trained using the Adam optimizer, categorical cross entropy as the loss function, and a batch size of 64 samples for 200 epochs. The second model employs a SubSpectralNet architecture, which has been used in [19] for classifying acoustic scenes. However, the specific framework used for implementation is not mentioned.

In summary, while the context provides details about the CNN architectures, input representations, and data handling methods used for bird sound classification, it does not specify the deep learning framework used for building the models. Therefore, the answer to the query is:


The provided context does not offer information on the deep learning frameworks used for building the models.