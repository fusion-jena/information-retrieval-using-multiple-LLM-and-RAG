In the context provided, there is no explicit information given on the specific criteria used to determine when training is complete. However, it is mentioned that deep learning algorithms such as VGG16, ResNet50, and AlexNet are used for image classification, and these models typically use validation loss or accuracy as a criterion to determine when training should be stopped.

For instance, in the context of deep learning, training is often stopped when the validation loss plateaus or starts to increase, even if the training loss continues to decrease. This is because a model that performs well on the training data may not generalize well to unseen data, and a plateauing or increasing validation loss is an indicator that the model is starting to overfit to the training data.

In the tables provided, there are several metrics reported, such as user's accuracy (UA), producer's accuracy (PA), F1-Score, overall accuracy (OA), and Kappa coefficient. While these metrics are useful for evaluating the performance of a model, they do not provide information on the specific criteria used to determine when training is complete.

In summary, while the specific criteria used to determine when training is complete are not provided in the context, it is common practice in deep learning to use validation loss or accuracy as a criterion to determine when training should be stopped.