The text provided does not give explicit information about the criteria used to determine when the training of the model is complete. However, it does mention that data from 2016 to 2018, comprising 72 data points, were reserved for testing and validation purposes. This suggests that some form of validation was used to assess the model's performance during the training process. 

In the context of machine learning and neural networks, it is common to use validation data to monitor the model's performance during training. One common approach is to observe the validation loss (or another performance metric) and stop the training when the validation loss stops decreasing, or starts increasing, indicating that the model is starting to overfit the training data. This is sometimes referred to as "early stopping".

Moreover, the text mentions that the number of neurons in the hidden layer was incrementally adjusted to determine the optimal configuration that yields the best results. This process, known as model selection or hyperparameter tuning, often involves training the model multiple times with different configurations and selecting the one that performs best on a validation set.

Therefore, while the text does not provide explicit details, it is reasonable to infer that some form of validation-based criteria was used to determine when the training of the model was complete.