Based on the provided context, there is no explicit information given about the strategy implemented to monitor the model performance during training. However, it is mentioned that the research design is outlined in Fig. 2, so it is possible that the monitoring strategy is presented there.

The context does mention that the auto-encoder's feature representation outperforms acoustic indices and has a comparable execution time to MFCC. This information suggests that the model's performance is being evaluated in terms of its accuracy and computational efficiency.

Additionally, the authors mention that their approach is flexible and could be used in scenarios where annotated training data is not available. This implies that the model's performance may be evaluated using unsupervised learning techniques or other methods that do not require labeled data.

The limitations section of the context also mentions that the auto-encoder architecture used in the study has some constraints, such as the assumption of time invariance. This suggests that the model's performance may be evaluated in terms of its ability to handle time-varying data.

Overall, while there is no explicit information given about the strategy used to monitor the model's performance during training, it is clear that the authors are evaluating the model's accuracy, computational efficiency, and ability to handle time-varying data.