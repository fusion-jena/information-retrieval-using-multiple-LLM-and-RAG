The pieces of context provided do not directly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, I can provide some general information about common regularization techniques.

Regularization is a crucial approach to prevent overfitting in deep learning models. It introduces a penalty on the model's complexity, encouraging the model to learn more generalized features. Two common regularization techniques are dropout and L2 regularization.

1. Dropout: Dropout is a regularization technique introduced by Srivastava et al. (2014). During training, dropout randomly sets a fraction of input units to 0, effectively preventing units from co-adapting. This leads to a more robust model by promoting the learning of redundant representations. Dropout can be applied to any layer in the deep learning model, but it is most commonly used in fully connected layers.

2. L2 Regularization: L2 regularization, also known as weight decay, adds a penalty term to the loss function, which is proportional to the sum of the squares of all model weights. This encourages the model to learn smaller weights, reducing the risk of overfitting. L2 regularization is applied to all learnable parameters in the model, including weights and biases.

While the context does not mention any specific regularization techniques, it does provide information about the SGD optimizer and the Dice loss function. The Stochastic Gradient Descent (SGD) optimizer is a popular choice for training deep learning models. However, it does not inherently include regularization. Dice loss, on the other hand, is a loss function often used in segmentation tasks. It measures the similarity between the predicted and ground truth segmentation masks, encouraging the model to learn better boundaries.

In summary, the provided context does not mention any specific regularization techniques. However, dropout and L2 regularization are two common methods used to prevent overfitting in deep learning models. Dropout randomly sets a fraction of input units to 0 during training, while L2 regularization adds a penalty term to the loss function, encouraging the model to learn smaller weights.