The criteria used to split the data for deep learning model training, such as train, test, and validation sets, are not explicitly stated in the provided context. However, it does mention the use of an 80-20 split for model training and validation. In this context, 80% of the data was used for model training, which involves computing the gradient and updating network parameters like weights and biases. The remaining 20% of the data was used for model testing or validation, which involves testing the model error.

Additionally, the concept of early stopping is mentioned as a technique to avoid overfitting. Early stopping involves monitoring the model's performance on the validation set during the training process. If the model starts to overfit, meaning its error on the validation set begins to increase, the training process is stopped early. This helps to ensure that the model generalizes well to new, unseen data.

It's also worth noting that the data splitting method can vary depending on the specific requirements of the deep learning model and the nature of the data. For instance, in some cases, a separate validation set might not be used, and the data might be split into training and test sets only. In other cases, cross-validation, where the data is split into multiple folds and the model is trained and validated on each fold, might be used.

In conclusion, while the specific criteria for splitting the data are not provided in the context, it does mention the use of an 80-20 split for model training and validation, and the concept of early stopping to avoid overfitting. The specific data splitting method can vary depending on the deep learning model and the data.