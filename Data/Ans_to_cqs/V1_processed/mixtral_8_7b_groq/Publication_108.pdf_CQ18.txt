The strategy implemented to monitor the model performance during training involves the use of TensorBoard and the tracking of both training and validation losses. Specifically, it was observed that the validation loss was consistently lower than the training loss before the overfitting point. This behavior can be attributed to the effect of dropout layers, which randomly drop some neurons during training, causing the feed-forward network to perform worse. However, during validation, dropout is deactivated, and all neurons are kept, leading to a better performance on the validation set. Additionally, the performance of the neural network was assessed using several evaluation metrics, including a custom implementation of the intersection over union (IoU) metric and the overall accuracy. These metrics were computed during the forward pass and were used as performance indicators to optimize the hyperparameters of the model.