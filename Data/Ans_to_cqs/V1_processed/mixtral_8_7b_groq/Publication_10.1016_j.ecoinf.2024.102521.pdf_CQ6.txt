The provided context does not give specific details about the preprocessing steps involved before training a deep learning model in the STARdbi system. However, it is mentioned that users can manually label some of their images, which suggests that there might be a step for image annotation or cleaning.

In general, when training deep learning models for computer vision tasks such as image classification, several preprocessing steps are often involved. These can include:

1. Image normalization: This involves scaling the pixel values of the image to a range between 0 and 1. This helps to ensure that all images have similar brightness and contrast levels, which can improve the model's ability to learn relevant features.
2. Image augmentation: This involves applying random transformations to the images, such as rotation, scaling, flipping, or cropping. This helps to increase the size of the training dataset and can improve the model's ability to generalize to new images.
3. Data cleaning: This involves removing any irrelevant or corrupted images from the dataset. This can help to improve the model's performance by reducing the amount of noise in the training data.
4. Data balancing: If the dataset is imbalanced, where some classes have significantly more samples than others, this can affect the model's performance. Techniques such as oversampling the minority class or undersampling the majority class can help to balance the dataset.
5. Feature extraction: This involves extracting relevant features from the images, such as color histograms, texture features, or shape descriptors. These features can be used as input to the deep learning model, instead of the raw pixel values.

It is important to note that the specific preprocessing steps used can vary depending on the dataset and the task at hand. Therefore, it is often necessary to experiment with different preprocessing techniques to find the ones that work best for a particular problem.