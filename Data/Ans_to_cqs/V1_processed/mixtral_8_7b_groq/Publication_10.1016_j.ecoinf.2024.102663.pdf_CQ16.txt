The context provided does not give specific information about the criteria used to determine when training is complete for the models mentioned. However, it does suggest a few possibilities.

One potential criterion could be a validation loss plateau. This is a common method for determining when training should be stopped in machine learning models. Essentially, training is stopped when the validation loss stops decreasing, indicating that further training is unlikely to improve the model's performance.

Another possibility is that the training duration itself was used as the criterion for completing training. The context states that both models underwent 50 complete iterations of processing the full dataset. This could suggest that the training was simply set to run for a fixed number of iterations, regardless of the model's performance.

The context also provides some information about the different models' performance measures, such as variance, R2 score, and Mean Absolute Error (MAE). It's possible that these measures were used to determine when training was complete, although this is not explicitly stated.

In summary, while the context does not provide specific information about the criterion used to determine when training is complete, it suggests a few possibilities, such as a validation loss plateau or a fixed number of training iterations.