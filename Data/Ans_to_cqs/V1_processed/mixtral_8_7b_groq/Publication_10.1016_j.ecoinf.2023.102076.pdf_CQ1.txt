Based on the provided context, the text classification pipeline discussed in the study does not focus on the specific methods used for collecting raw data. Instead, it focuses on addressing the issues of imbalanced datasets and the need for large training datasets in the text classification process. The study uses an example data collection scenario to demonstrate and evaluate the pipeline, but it does not provide details on how the raw data was collected.

However, the context does mention that the pipeline can be applied to different forms of textual data, such as social media posts, web articles, and even listings from E-commerce platforms. Therefore, it can be inferred that the raw data for this pipeline could come from various sources, such as:

1. Surveys: Researchers could use surveys to collect textual data from a specific group of people.
2. Sensors: In the context of IoT devices, sensors could collect textual data in the form of logs or error messages.
3. Public datasets: Researchers could use publicly available datasets, such as those provided by social media platforms or government agencies, to collect textual data.

Moreover, the context also mentions that the study focused on collecting social media posts and web articles. In such cases, the raw data could be collected using web scraping techniques or through APIs provided by social media platforms.

In summary, while the provided context does not explicitly mention the methods used for collecting raw data in the deep learning pipeline, it can be inferred that the pipeline can be applied to textual data collected from various sources, such as surveys, sensors, and public datasets.