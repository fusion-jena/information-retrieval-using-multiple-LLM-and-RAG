The text provided does not give specific information about the metrics used to evaluate the performance of the deep learning model. However, it does mention that during the training stage, the model was selected based on its performance on the validation set, and that the fine-tuning process is described in section 2.5.2. It is possible that the metrics used are specified in that section.

In general, when evaluating the performance of a deep learning model for image classification or object detection tasks, common metrics include:

* Accuracy: the proportion of correct predictions out of all predictions made.
* Precision: the proportion of true positive predictions (i.e., correct identification of a object) out of all positive predictions made.
* Recall: the proportion of true positive predictions out of all actual positive instances in the data.
* F1 score: the harmonic mean of precision and recall, which gives equal weight to both measures.
* Intersection over Union (IoU): a measure of the overlap between the predicted bounding box and the ground truth bounding box, often used in object detection tasks.

These metrics can be used individually or in combination to evaluate the performance of a deep learning model. It is important to consider the specific problem and data at hand when choosing which metrics to use.