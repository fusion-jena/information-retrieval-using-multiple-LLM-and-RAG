The provided context does not directly mention the methods used for collecting raw data in the deep learning pipeline. However, it does mention the use of datasets for training and validating deep learning models.

In the context, the authors used ResNet-50, a deep learning model pre-trained on the ImageNet database, to extract features from image backgrounds for classification. ImageNet is a large-scale image recognition dataset that contains over 14 million images and 21,841 categories. Therefore, it can be inferred that the authors used a public dataset for training and validating their deep learning model.

Furthermore, the authors mention the use of "standard visual information and low-level image features" for image segmentation, image classification, and object detection. These features can be collected using various techniques such as surveys, sensors, or other public datasets.

For instance, surveys can be used to collect visual information about a particular subject or scene. Sensors such as cameras, lidar, or radar can be used to collect image data in real-time. Public datasets, such as COCO, PASCAL VOC, or Cityscapes, can also be used for collecting raw data for deep learning tasks.

In summary, while the provided context does not explicitly mention the methods used for collecting raw data in the deep learning pipeline, it can be inferred that public datasets, surveys, and sensors can be used for this purpose.