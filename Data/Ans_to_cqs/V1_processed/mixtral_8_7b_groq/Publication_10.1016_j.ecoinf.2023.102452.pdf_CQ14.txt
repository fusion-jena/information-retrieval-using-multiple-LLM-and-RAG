The text provided does not give specific information about how the hyperparameters of the Genetic Programming (GP) model are optimized. However, it is mentioned that the Eureka Pro software is used for GP modeling, which was developed by Cornell Universityâ€™s Data Science Order and released in 2009. This software likely has built-in methods for hyperparameter tuning, but the specific methods are not mentioned in the text.

In general, there are several methods for hyperparameter tuning, including grid search, random search, and Bayesian optimization. Grid search involves specifying a range of possible values for each hyperparameter and testing all possible combinations. Random search involves randomly selecting values for each hyperparameter within a specified range. Bayesian optimization involves using a probabilistic model to suggest the most promising values to try next, based on the results of previous trials.

It is also possible that the authors of the text used a manual search process to optimize the hyperparameters of the GP model. This would involve trying different values and observing the performance of the model, then adjusting the hyperparameters based on those observations.

Without more information, it is not possible to give a definitive answer to this question. However, it is clear that some method of hyperparameter tuning was used in the GP modeling process described in the text.