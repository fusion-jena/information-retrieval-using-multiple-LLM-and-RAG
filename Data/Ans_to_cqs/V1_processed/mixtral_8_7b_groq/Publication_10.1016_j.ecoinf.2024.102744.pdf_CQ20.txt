The deep learning models in the experiments are trained on a server equipped with an Intel® Core™ i7-8700 CPU and an NVIDIA GeForce RTX 3070 GPU. Specifically, the methods utilizing YOLOv5 undergo training for 300 epochs, while those employing Faster RCNN are trained with 90 thousand iterations. The fundamental parameters for both training types are similar, with the learning rate set to 0.02, weight decay at 0.001, and momentum at 0.9.

For the YOLOv5 training, each epoch involves training the model on all data once, while for Faster RCNN, each iteration trains the model on a batch of images. The Global Average Pooling layer is used in the model, which summarizes features and generates input for the fully connected layer, facilitating the visualization of regions relied upon by the network for predictions.

It is worth noting that the hardware resources for evaluating the performance of the object detection models differ from the training server. The evaluation is conducted on a server equipped with an Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz and an NVIDIA GeForce GTX 1080 Ti GPU.

In summary, the deep learning models are trained on a server with an Intel® Core™ i7-8700 CPU and an NVIDIA GeForce RTX 3070 GPU, while the performance evaluation is carried out on a separate server with an Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz and an NVIDIA GeForce GTX 1080 Ti GPU.