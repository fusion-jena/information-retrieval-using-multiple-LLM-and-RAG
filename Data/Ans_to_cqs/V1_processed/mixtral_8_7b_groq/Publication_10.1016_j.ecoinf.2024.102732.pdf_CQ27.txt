The provided context does not contain information on the specific process followed to deploy a trained deep learning model. However, it does contain details about model training and evaluation.

For instance, one of the papers (Strandberg & Låås, 2019) compares the performance of neural networks, Lasso regularized logistic regression, and gradient boosted trees in modeling binary sales. The neural network model used in this study was a multi-layer perceptron (MLP) trained using the backpropagation algorithm. The authors used 10-fold cross-validation to evaluate the models, and report the Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) as performance metrics.

Another paper (Su et al., 2020a) compares machine learning and geostatistical approaches for estimating aboveground biomass in Chinese subtropical forests. The machine learning models used in this study include random forest, support vector regression, and artificial neural networks. The authors used the random forest model with the best performance, and report the MAE and RMSE as performance metrics.

The parameters of the machine learning models used in these studies include the regularization parameter (C), bandwidths (Sigma), maximum depth of a tree (max_depth), learning rate (eta), and number of trees (n_estimators).

As for the deployment of the trained deep learning model, the following general steps can be taken:

1. Model serialization: The trained deep learning model can be saved in a file format that can be easily loaded and used for making predictions. Common file formats for model serialization include JSON, XML, and HDF5.
2. Platform selection: The deployed deep learning model can be hosted on a local machine or on a cloud platform. Cloud platforms provide scalability, reliability, and ease of deployment. Common cloud platforms for deep learning model deployment include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP).
3. Model serving: The deployed deep learning model can be served through an API (Application Programming Interface) that allows other applications to make predictions using the model. Common API frameworks for deep learning model serving include TensorFlow Serving, TorchServe, and ONNX Runtime.

Therefore, while the provided context does not contain specific information on the process followed to deploy a trained deep learning model, the general steps for model deployment can be applied.