The provided context discusses a crawling tool used for gathering data from different SRS products, specifically focusing on the data acquisition process. However, it does not directly mention any preprocessing steps involved before training a deep learning model such as normalization, scaling, or cleaning.

Preprocessing data before training a deep learning model is crucial for improving model performance and ensuring convergence during training. Common preprocessing steps include:

1. Normalization: This process involves scaling numerical data to a specific range, often between 0 and 1. This helps to prevent any single feature from dominating the learning process due to its large range of values.

2. Scaling: Similar to normalization, scaling involves adjusting the range of numerical data. However, scaling does not necessarily restrict the range to between 0 and 1. Instead, it can be adjusted based on the specific needs of the model or dataset.

3. Cleaning: This step involves removing or correcting any errors or inconsistencies in the data. This can include handling missing values, removing outliers, or correcting inconsistent formatting.

Without more specific information related to the dataset or deep learning model in question, it is difficult to provide a more detailed answer. However, it is important to note that the crawling tool described in the context is focused on data acquisition and does not directly relate to the preprocessing steps mentioned in the query.