The performance of the deep learning model is evaluated using the metrics of precision, recall, and the confusion matrix. The precision is the ratio of true positive predictions (correctly labeled goat vocalizations) to the total predicted goat vocalizations. The recall is the ratio of true positive predictions to the total actual goat vocalizations in the data. The confusion matrix is a table that summarizes the performance of the classifier by comparing the actual labels to the predicted labels. The matrix shows the number of true positives, true negatives, false positives, and false negatives. In this case, the confusion matrix is presented in Table 1, where the highest rates are emboldened. The matrix shows that the YAMNet-based classifier correctly identified 98.1% of the actual goat vocalizations, with a low rate of false positives (2.2%) and false negatives (1.3%). These metrics provide a comprehensive evaluation of the model's performance, highlighting its strengths and weaknesses.