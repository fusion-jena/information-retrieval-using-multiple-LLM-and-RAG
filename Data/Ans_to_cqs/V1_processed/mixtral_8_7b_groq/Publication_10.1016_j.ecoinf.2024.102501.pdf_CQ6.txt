Before training a deep learning model, several preprocessing steps can be involved, such as normalization, scaling, and cleaning. These steps aim to prepare the data and reduce the impact of differences in dimension and magnitude values of various parameters.

In the context of predicting dissolved oxygen (DO) concentration in water, one study normalized the data using Eq. (1) to reduce the impact of large differences in the data. The normalization formula is expressed as: 

â€² =

Yi

Yi (cid:0) Ymin
Ymax (cid:0) Ymin

where Yi is the i-th sample value, Ymax is the maximum value, Ymin is the minimum value, and Yi' is the normalized value of the i-th sample (Chen et al., 2020).

Additionally, data cleaning can be an essential step in preprocessing. For instance, when predicting DO concentration in canals, Areepalli and Naik (2024) used an IoT-enabled system to analyze water contamination and remove any outliers or errors in the data.

Scaling is another preprocessing technique that can be used before training a deep learning model. Scaling involves transforming the data to a common range or distribution, which can help improve the model's performance. For example, Arepalli and Naik (2024) used scaling to transform the data to a range between 0 and 1.

In summary, before training a deep learning model, data preprocessing steps such as normalization, scaling, and cleaning can be involved. These steps aim to reduce the impact of large differences in the data and improve the model's performance. In the context of predicting DO concentration in water, normalization and scaling have been used to prepare the data for training deep learning models.