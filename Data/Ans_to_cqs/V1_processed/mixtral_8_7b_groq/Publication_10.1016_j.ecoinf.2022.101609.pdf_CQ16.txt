In the context provided, the training of a model is considered complete when the validation loss plateaus. This is demonstrated in Figure 12, which illustrates the model training and validation losses after 20,000 epochs. The training loss gradually decreases as the number of epochs increases, while the validation loss drops significantly after 2500 epochs and then becomes steady for the remaining training epochs. The final Mean Absolute Error (MAE) and exponential Root Mean Square Error (RMSE) after training are 0.350 and 1.591 respectively.

The validation loss plateauing indicates that the model has learned enough from the training data and further training would not significantly improve the model's performance. This is because the model's predictions on the validation set, which it has not seen during training, have reached a level of accuracy that is not likely to improve by continuing to train on the same data.

It is also worth noting that the validation set is used to select the model that works best after verification using the test data. This is an important step in the model training process as it helps to ensure that the model is not overfitting to the training data and will generalize well to new, unseen data.

In summary, the criterion used to determine when training is complete in the provided context is the validation loss plateauing, which indicates that the model's predictions on the validation set have reached a level of accuracy that is not likely to improve by continuing to train on the same data.