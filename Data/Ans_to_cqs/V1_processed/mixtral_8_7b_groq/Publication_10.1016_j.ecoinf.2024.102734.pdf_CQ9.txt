The context provided does not give information about the data repository of the deep learning pipeline. It includes details about various techniques used in the pipeline, such as transductive propagation, active learning, transfer learning, and prototypical learning. The data used in the pipeline is segmented into 5-second spectrograms and converted into 527-dimensional embedding vectors. The pipeline uses a pre-trained feature extraction model and fine-tunes it using a subset of 500 training samples. The models used in the pipeline include ResNet-50, Audio Spectrogram Transformer (AST), and HuBERT, which operate on spectrograms and 1-D waveform, respectively.

However, the context does not mention where the data repository is available. Therefore, I cannot provide an answer to the query. It would be best to contact the authors or look at the paper's supplementary materials for more information on the data repository.