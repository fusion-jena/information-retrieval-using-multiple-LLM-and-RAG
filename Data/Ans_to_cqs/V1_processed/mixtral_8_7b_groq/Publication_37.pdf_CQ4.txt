The data augmentation techniques applied in the deep learning pipeline for bird species classification using flight calls are not the traditional image augmentation techniques such as flipping, rotating, or scaling. Instead, they are audio deformations that modify the audio signal while maintaining the semantic validity of the recording's label.

The following augmentations are applied: adding background noise, dynamic range compression, pitch shifting, and time stretching. The background noise is added from four different field recordings captured at night containing geophony. Dynamic range compression is applied using four parameterizations: music, film, speech, and radio. Pitch shifting is done by conservative values of -0.5, -0.25, 0.25, and 0.5 semitones, and by less conservative values of -2, -1, 1, and 2 semitones. Time stretching is applied by four ratios: 0.81, 0.93, 1.07, and 1.23. These augmentations are applied using the MUDA library, and the reader is referred to it for further details about the implementation of each audio deformation.

These data augmentation techniques are used to increase the size of the training set and improve the performance of the Convolutional Neural Network (CNN) model. The CNN model, combined with data augmentation, significantly outperformed the MFCC baseline (0.85) with a mean classification accuracy of 0.94.

In summary, the data augmentation techniques used in the deep learning pipeline for bird species classification using flight calls are adding background noise, dynamic range compression, pitch shifting, and time stretching. These techniques help to increase the size of the training set, improve the performance of the CNN model, and yield new biological insights and conservation applications for birds that vocalize during migration.