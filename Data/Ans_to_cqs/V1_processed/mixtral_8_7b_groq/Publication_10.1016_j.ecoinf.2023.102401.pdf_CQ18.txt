During the training of the model, several strategies were implemented to monitor and evaluate its performance. The metrics used to assess the model's efficacy include accuracy, recall, F1 score, mean average precision (mAp), and average mean accuracy. Among these, mAp was chosen as the major evaluation metric to comprehensively analyze the model's detection accuracy, recall, and F1 scores.

The true positive (TP), false positive (FP), true negative (TN), and false negative (FN) were used to calculate the aforementioned metrics. The F1 score is the harmonic mean of precision and recall, providing a single metric that encapsulates both. Precision is the ratio of true positives to the sum of true positives and false positives, while recall is the ratio of true positives to the sum of true positives and false negatives. The mAp is calculated as the average precision over recall values, providing a comprehensive measure of the model's performance.

The model's performance was monitored throughout the training process, and adjustments were made to the model's parameters and structure based on the evaluation results. This iterative process of training and evaluation continued until a satisfactory level of performance was achieved.

In addition, the experimental setup included the use of the PyTorch framework, Python 3.7, CUDA 11.7, a GeForce RTX 3060 12G GPU, and an Intel(R) Xeon(R) E5â€“1620 v3 CPU @ 3.50 GHz for training the datasets. The SGD optimizer was used with a batch size of 8, a momentum of 0.937, and a training epoch of 300.

Furthermore, the performance of different attention modules, such as SE, CA, and CBAM, was evaluated. The results showed that the CBAM module performed the best in terms of mAp, precision, recall, and F1 score.