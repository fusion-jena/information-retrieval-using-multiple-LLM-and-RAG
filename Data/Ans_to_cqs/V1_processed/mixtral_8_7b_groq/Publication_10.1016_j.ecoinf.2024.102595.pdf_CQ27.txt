The text provided does not give specific details about the process followed to deploy the trained deep learning model. However, it does mention that predictive models were constructed using deep learning algorithms as part of the development stage.

In general, deploying a trained deep learning model involves several steps. First, the model is usually saved or serialized, which means converting the model into a format that can be stored and loaded again. This is often done using libraries like TensorFlow or PyTorch, which provide functions to save and load models.

Once the model is serialized, it can be deployed on a platform for making predictions. The choice of platform depends on various factors such as the required computational resources, the need for real-time predictions, and the intended users of the model.

For instance, if the deep learning model is to be used for real-time predictions in a resource-constrained environment, a lightweight platform such as a mobile device or a Raspberry Pi might be chosen. On the other hand, if the model is to be used for batch predictions on large datasets, a powerful server or a cloud-based platform might be more suitable.

In addition, the model might need to be integrated with other systems or applications for seamless use. This could involve creating APIs or web services that allow other programs to access the model's predictions.

Overall, while the text does not provide specific details about the deployment process for the deep learning model, it is clear that the model was constructed as part of a larger predictive system for oil palm yield prediction.