Based on the provided context, there is no explicit information given about the process followed to deploy the trained deep learning model. However, it can be inferred that the model was likely serialized, which is the process of saving the model architecture and learned parameters to a file, allowing it to be loaded and used for making predictions on new data. This is a common practice in machine learning and deep learning, as it enables the model to be easily shared and deployed in different environments.

As for the platform selection, the context does not provide any details about where or how the model was deployed. It is possible that the model was deployed on a local machine, a server, or a cloud-based platform. The choice of platform would depend on various factors such as the intended use case, the volume of data to be processed, and the required computational resources.

In summary, while the provided context does not give specific details about the process followed to deploy the trained deep learning model, it can be inferred that the model was likely serialized for sharing and deployment, and the choice of platform would depend on various factors.