The criteria used to split the data for deep learning model training, as described in the provided context, are into training, validation, and testing sets. However, the specific proportions used in the splitting process are not explicitly stated in the context for deep learning models.

In the first piece of context, the authors use the bootstrap method to generate 100 different subsets from the original training sets for each machine learning model, including deep learning models. The number of samples in each subset equals the number of samples in the original training data. The predictions of the trained models on the testing dataset are averaged to obtain the main prediction. The average loss, average bias, and average variance are then derived for each model. The noise is assumed as 0 following previous studies.

In the second piece of context, the authors use the same data splitting approach for all machine learning models, including deep learning models. The entire dataset is randomly divided into a training set (60%), a validation set (20%), and a testing set (20%). Each machine learning model is trained on the training set, optimized on the validation set, and evaluated on the testing set.

Therefore, while the context does not explicitly state the criteria used to split the data for deep learning model training, it can be inferred that the data splitting approach involves a training set, a validation set, and a testing set. The specific proportions used in the splitting process are not provided, but the authors use a 60-20-20 split for other machine learning models.