Based on the provided context, there is no explicit mention of techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, the text does discuss the use of simulated data sets for evaluating the DEPP method, which can help to mitigate data bias by providing a controlled and balanced data set for training and testing the model.

The authors also mention the importance of having a diverse and representative training set for the deep learning model to perform well on novel query sequences. They note that both DEPP and EPA-ng outperform APPLES+JC when the query sequences are novel, indicating the importance of a diverse training set.

Furthermore, the authors discuss the challenge of fixed embedding size in their supervised learning formulation, which may not guarantee the correctness of embeddings after addition of new data. They suggest that having one less dimension may have a minimal practical impact, but they do not explicitly mention any techniques used to ensure diversity or balance in the embedding space.

In summary, while the provided context does not explicitly mention techniques used to address data bias during preprocessing, it does highlight the importance of having a diverse and representative training set for the deep learning model to perform well on novel query sequences.