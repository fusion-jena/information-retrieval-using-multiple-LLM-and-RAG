The text provided does not give specific details about the criteria used to split the data for training the deep learning model. However, it does mention that the model segmented 1195 objects on the validation dataset, which implies that there was a separate validation dataset.

In general, when training deep learning models, it is common to split the data into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

The text does provide some information about the training process, such as the use of binary cross-entropy and Dice coefficient-related loss, the RMSprop optimizer with an initial learning rate of 0.0001, and training for 300 epochs with 24 images per batch. However, it does not mention how the data was split into training, validation, and testing sets.

Therefore, while we can infer that there was a separate validation dataset, we cannot provide specific details about the criteria used to split the data for deep learning model training based on the information given.