The context provided does not give specific details on the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it does mention that the model training and prediction procedures were executed on Microsoft Azure using a specific instance type, and the algorithm scripts are available in Supporting Information B. Therefore, it can be inferred that the data splitting criteria could be detailed in the algorithm scripts or related documentation. It is a common practice in machine learning to split the data into three subsets: training set, validation set, and test set. The training set is used to train the model, the validation set is used to tune the model's hyperparameters, and the test set is used to evaluate the model's performance. The criteria used to split the data can vary depending on the specific use case and the amount of available data. For example, a 60-20-20 split, where 60% of the data is used for training, 20% for validation, and 20% for testing, is a common choice. Another approach is k-fold cross-validation, where the data is split into k subsets, and the model is trained and validated k times, each time using a different subset for validation and the remaining k-1 subsets for training. Ultimately, the choice of data splitting criteria will depend on the specific requirements of the problem and the available data.