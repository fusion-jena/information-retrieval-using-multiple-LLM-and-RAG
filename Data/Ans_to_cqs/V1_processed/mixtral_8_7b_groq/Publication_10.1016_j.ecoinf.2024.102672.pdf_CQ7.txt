In the context provided, the data was split into training and test sets to train and evaluate the deep learning models. The first 4 years (2018-2021) of the data were used as the training set, and the last year (2022) was used as the test set. This split corresponds to approximately 80-20%, which is a common rule of thumb in machine learning.

In addition to this split, k-fold cross-validation was performed on the training set to find the optimal combination of hyperparameters and avoid overfitting. The training set was divided into k fractions, with one fraction used as a validation set and the remaining k-1 fractions used as the training set. This process was repeated k times, with a different validation set each time. The value of k was chosen to be 4, so that each validation fraction corresponded approximately to one year.

It is important to note that the data split was performed once, and the same training and test sets were used throughout the model selection and hyperparameter tuning process. The k-fold cross-validation was used to evaluate the performance of the models on different subsets of the training data, but the models were always trained on the same training set and tested on the same test set.

The criteria used to split the data in this case were based on the time series nature of the data, where the first 4 years of data were used for training and the last year was used for testing. Additionally, k-fold cross-validation was used to evaluate the models on different subsets of the training data.