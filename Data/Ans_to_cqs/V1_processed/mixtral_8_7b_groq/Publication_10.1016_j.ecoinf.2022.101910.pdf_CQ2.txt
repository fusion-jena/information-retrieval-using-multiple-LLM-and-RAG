Based on the provided context, the deep learning pipeline in the BirdNET project involves processing sound recordings to automatically detect and classify bird vocalizations. Therefore, the primary data format used in this pipeline is audio.

In more detail, the BirdNET project uses deep neural networks to process audio recordings and identify bird species (Kahl et al., 2021; Wood et al., 2021). The project can identify over 3000 bird species (Wood et al., 2021), and it uses a developed deep neural network for this task (Kahl et al., 2021).

The audio recordings used in the BirdNET project likely need to be preprocessed before they can be fed into the deep neural network. While the specific preprocessing steps are not mentioned in the provided context, other studies have used techniques such as converting audio recordings to spectrograms (Towsey et al., 2018) or using deep audio embeddings (Tolkova et al., 2021) as part of their preprocessing pipelines.

It is also possible that additional data formats are used in the BirdNET project, although this is not explicitly mentioned in the provided context. For example, the project may use CSV files to store metadata about the audio recordings or the bird sightings. However, based on the available information, the primary data format used in the BirdNET deep learning pipeline is audio.

Another project that uses deep learning for audio processing is the Parsing birdsong with deep audio embeddings project (Tolkova et al., 2021). This project also uses audio recordings as its primary data format and converts them to deep audio embeddings as part of its preprocessing pipeline.

In summary, the provided context suggests that the BirdNET project primarily uses audio recordings as its data format in its deep learning pipeline. Other projects that use deep learning for audio processing may also use audio as their primary data format.