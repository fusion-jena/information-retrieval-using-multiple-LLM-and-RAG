The provided context does not include a direct link to the data repository of the deep learning pipeline used in the study. However, it does mention that the second approach to extract embeddings was from the pre-trained BirdNET model. The BirdNET model was trained on audio data of bird vocalizations. The study suggests that training a model with data input of gibbon vocalizations might result in better performance for individual gibbon discrimination. 

The context also mentions that recent advances in deep learning technology have revolutionized the field of bioacoustics, with many applications targeting the automated detection and classification of acoustic signals. These deep learning approaches can also be used as a feature extraction method, where features extracted from deep learning algorithms are referred to as "embeddings". 

Therefore, while the specific data repository link is not provided in the context, it can be inferred that the data used in this study involves audio recordings of gibbon vocalizations and possibly other relevant audio data, which were used as input to train the BirdNET model and extract embeddings.