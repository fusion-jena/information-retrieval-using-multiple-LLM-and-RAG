The hyperparameters of the model were optimized using a standard machine learning hyperparameter search. Specifically, a small grid search was performed to find the best combination of hyperparameters. The hyperparameters that were considered in this search include the activation function (ReLU, sigmoid, or elu), the optimizer (RMSprop or adam), and the learning rate (0.1, 0.001, 0.0001, and 0.00001).

The decision to use a grid search over other methods, such as random search, was based on computational cost. The search was conducted over two sites, and an exhaustive search was performed for the fully connected architecture for all mono-site and multi-site models. To ensure that the models did not suffer from overfitting, the training, validation, and testing performance were compared for each set of hyperparameters.

The dataset was divided into three subsets: training (60%), validation (20%), and testing (20%). Data augmentation was only applied to the training data to avoid overlapping the same data in different partitions. The models were evaluated using the coefficients of determination (R2) and the root mean squared error (RMSE) metric.

It is important to note that the practical applicability of the model search is constrained. When labeled data is available in regions targeted for information transfer, it is generally more prudent to incorporate it into the model calibration and testing processes.

In summary, the hyperparameters of the model were optimized using a standard machine learning hyperparameter search with a small grid search. The activation function, optimizer, and learning rate were considered in the search, and the training, validation, and testing performance were compared to avoid overfitting. The dataset was divided into three subsets, and the models were evaluated using the R2 and RMSE metrics. However, it is important to consider the practical applicability of the model search when labeled data is available in regions targeted for information transfer.