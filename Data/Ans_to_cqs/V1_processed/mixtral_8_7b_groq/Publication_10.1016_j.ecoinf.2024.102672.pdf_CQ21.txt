Based on the provided context, the postprocessing steps involved after the model training include the calculation of metrics such as Mean Absolute Error (MAE) and percentile loss, as well as the creation of a confusion matrix.

In the process of developing a model to detect thermal stratification in a reservoir, a classification model was designed. After training this model, the performance was evaluated by calculating the MAE and percentile loss for the training set. These metrics were chosen to assess the accuracy of the model in predicting the presence or absence of stratification.

Additionally, a confusion matrix was constructed to further evaluate the performance of the classification model. A confusion matrix is a table that is often used to describe the performance of a classification model. It compares the predicted classes with the true classes, allowing for a visual representation of the model's performance.

In this case, the confusion matrix would compare the predicted classes of stratified or not-stratified with the true classes, providing information on the number of true positives, true negatives, false positives, and false negatives. This information can be used to calculate other metrics, such as precision, recall, and the F1 score, which provide additional insights into the performance of the classification model.

It is important to note that the provided context does not mention the use of techniques such as saliency maps or feature importance analysis. These methods can be used to gain a better understanding of the features that are most important in the model's decision-making process. However, based on the given information, the postprocessing steps primarily involve the calculation of metrics and the creation of a confusion matrix.