Based on the provided context, there is no explicit information given about how the hyperparameters of the model are optimized, such as through methods like grid search or random search. The text focuses on the use of Elastic Net, a regularization technique that combines L1 and L2 norms, to improve the performance of the proposed model for DNA barcode sequence classification.

The Elastic Net regularization is introduced to enhance the generalization ability of the model and reduce training time by adding constraints to reduce the weight of useless features. The L1-norm, also known as Lasso regression, contributes to generating a sparse matrix. The structure of the Elastic Net-Stacked Autoencoder (EN-SAE) model is shown in Figure 3, and it treats L1-norm and L2-norm as penalties for the loss function to restrict some parameters during the training process.

However, the context does not mention any specific techniques for hyperparameter optimization, such as grid search, random search, or Bayesian optimization. Hyperparameter optimization is an essential step in deep learning model development to achieve better performance. It involves searching for the best set of hyperparameters, such as learning rate, batch size, number of layers, and number of units in each layer, to minimize the validation loss and improve the model's generalization ability.

Therefore, based on the provided context, we cannot determine how the hyperparameters of the model are optimized.