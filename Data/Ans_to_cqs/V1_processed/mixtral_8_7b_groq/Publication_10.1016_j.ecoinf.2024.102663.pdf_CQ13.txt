The hyperparameters used in the deep learning model for fish biomass estimation in turbid environments, as described in the research article, include the number of epochs, learning rate, cosine learning rate scheduler, optimizer, and initial learning rate.

The number of epochs is the number of times the learning algorithm will work through the entire training dataset. The research compares the output metrics when the number of epochs is changed from 10 to 50.

The learning rate is a hyperparameter that determines how much an algorithm adjusts the weights of the network with respect to the loss gradient. The research compares the output metrics for different final learning rates of 0.005, 0.01, and 0.02.

The cosine learning rate scheduler is a technique used to adjust the learning rate during training. The research compares the output metrics for cos\_lr set to False (no cosine curve) and True (using a cosine curve).

The optimizer is a method used to update the weights and biases in the network. The research compares the output metrics for three different optimizers: RMSProp, SGD, and AdamW.

The initial learning rate is the starting point for the learning rate. The research compares the output metrics for different initial learning rates of 0.005, 0.01, and 0.02.

These hyperparameters were tested and compared to determine the best combination for fish biomass estimation in turbid environments. The results showed that the potential improvement in performance from using certain hyperparameters may warrant the investment of additional effort, despite longer training times. The efficient and precise estimation of fish biomass is crucial for the fisheries and aquaculture industries, and deep learning can provide a cost-effective solution.