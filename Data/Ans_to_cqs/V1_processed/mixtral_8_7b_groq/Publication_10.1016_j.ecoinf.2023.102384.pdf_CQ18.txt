The strategy implemented to monitor the model performance during training involves using a subset of the PST dataset for the supervised learning step concerning the pest counting module PCtheta. Specifically, the training subset of the PST dataset is used to assess the counting ability of the proposed approaches. This is done using counting golden standard evaluators, which investigate the counting performance of the pipeline considering only the pest counting module PCtheta.

Furthermore, the model's performance is evaluated on the test split of the PST dataset, which contains the remaining eight images after the training subset has been used. This allows for an independent evaluation of the model's counting performance.

It is important to note that the PST dataset is not publicly available, which means that the performance of the model cannot be replicated or verified by external parties using the same dataset.

Additionally, the model's performance is evaluated not only in terms of count error but also in terms of the estimated raw locations of the insects. This is done using hybrid metrics that consider both the count error and the estimated raw locations of the insects. This allows for a more comprehensive evaluation of the model's performance, considering both the accuracy of the count and the precision of the location estimates.

Finally, it is worth noting that the dataset contains a variety of challenges, such as the presence of other insect species and contaminants on the sticky traps. These challenges must be accounted for in the model's performance evaluation, as deep learning models should not count the latter insect species or be confused by contaminants.