The data augmentation techniques applied in the deep learning pipeline include image scaling, horizontal and vertical flip, perspective distortion, and adding color jitter for brightness, contrast, and saturation. These techniques were used to increase the diversity of the training data and mitigate overfitting during the training of the models.

Image scaling involves resizing the input images to a larger or smaller size, which helps the model to generalize better and be more robust to variations in image size. Horizontal and vertical flip refers to flipping the input images along the horizontal or vertical axis, which helps the model to be more invariant to the orientation of the objects in the images. Perspective distortion involves randomly changing the perspective of the input images, which helps the model to be more robust to variations in camera angle and distance. Adding color jitter involves randomly changing the brightness, contrast, and saturation of the input images, which helps the model to be more invariant to variations in lighting conditions.

These techniques were applied to the input images during the training of the models, and were found to be effective in improving the accuracy of the models on the training and validation datasets. The training was performed using a batch size of 20, and the accuracy of the models was computed after each epoch.

It is worth noting that these data augmentation techniques are applied to the training data only, and not to the validation or test data. This is because the goal of data augmentation is to increase the diversity of the training data, and not to alter the true distribution of the data.

In summary, the data augmentation techniques used in the deep learning pipeline include image scaling, horizontal and vertical flip, perspective distortion, and adding color jitter for brightness, contrast, and saturation. These techniques were applied to the training data to increase its diversity and mitigate overfitting, resulting in improved accuracy of the models on the training and validation datasets.