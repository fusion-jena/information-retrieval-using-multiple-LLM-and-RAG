The deep learning pipeline in the study discussed uses audio data formats as input. More specifically, the audio data are stored as FLAC files at a sampling rate of 44.1 kHz for the solar-powered bioacoustic recorders and WAV files at a 32 kHz sampling rate for the Audiomoth recorders. These audio files are then processed and prepared for the convolutional neural network (CNN) model.

In the data pre-processing stage, a frequency bandwidth of 1.5 MHz to 5 MHz is chosen to ensure the dominant frequency of the target call is included within the frame, while avoiding excess noise at lower and higher frequencies. This frequency bandwidth typically includes a fundamental harmonic and/or a higher harmonic of the dominant frequency. The processed frames are then used as input into the CNN.

Therefore, the deep learning pipeline in this study works primarily with audio data formats (FLAC and WAV files), and the pre-processing steps are applied to these audio files before they are fed into the CNN model.