The criteria used to split the data for deep learning model training typically include creating separate sets for training, validation, and testing. However, the specific criteria or ratios for splitting the data are not specified in the provided context. Here is a general explanation of these sets:

1. Training set: This is the portion of the data used to train the model. The model learns patterns from this data and adjusts its parameters to minimize the difference between its predictions and the actual values.

2. Validation set: This set is used during the training process to validate the model's performance and tune hyperparameters. The model's predictions on the validation set are compared to the actual values, and the differences (e.g., loss or error) are used to adjust the model's hyperparameters. This process is called early stopping if the model's performance on the validation set stops improving after a certain number of epochs.

3. Testing set: This set is used to evaluate the model's performance after training. The model's predictions on the testing set are compared to the actual values, providing an unbiased estimate of the model's performance on unseen data.

In some cases, the data might be split using an 80-20 or 70-30 ratio for training and testing, or a 60-20-20 ratio for training, validation, and testing. The exact split ratio can depend on the size of the dataset and the specific requirements of the project.

In the provided context, there is no information on how the data was split for the models mentioned in the papers. However, it is common practice in deep learning to use a separate validation set during training for hyperparameter tuning and model selection, and a separate testing set for final performance evaluation.