The provided context does not give specific details about the preprocessing steps taken before training the deep learning models. However, it does mention that the models were built using a customized CNN and a pre-trained ResNet152V2 architecture.

In general, preprocessing steps for deep learning models can include:

1. Normalization: This involves scaling the input data to a range that is suitable for the model. In the context of images, this could mean scaling pixel values to a range of 0-1 or -1 to 1.
2. Data augmentation: This involves artificially increasing the size of the training set by applying transformations such as rotation, scaling, and flipping to the existing images. This can help improve the model's ability to generalize to new data.
3. Noise reduction: This involves removing noise from the input data. In the context of audio data, this could mean removing background noise or filtering out frequencies that are not relevant to the task at hand.
4. Feature extraction: This involves extracting relevant features from the input data. In the context of images, this could mean extracting features such as edges, corners, and textures.
5. Data cleaning: This involves removing outliers or incorrect data from the training set.

Without more specific information from the context, it is difficult to say which of these steps were taken before training the models in question. However, it is mentioned that the models were built using a customized CNN and a pre-trained ResNet152V2 architecture, so it is likely that some form of preprocessing was done before training.