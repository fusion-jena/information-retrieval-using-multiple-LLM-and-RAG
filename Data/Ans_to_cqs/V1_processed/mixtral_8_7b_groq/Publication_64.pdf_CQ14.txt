Based on the provided context, there is no explicit information about how the hyperparameters of the ResNet50 model were optimized. The text does not mention any specific techniques such as grid search, random search, or Bayesian optimization.

However, it is mentioned that the ResNet50 model outperforms another public plant classification algorithm. This implies that some hyperparameter tuning was done to achieve these results. It is common practice to optimize hyperparameters by trying different values and selecting the ones that give the best performance on a validation set.

Additionally, the use of data augmentation parameters during training and smaller data augmentation parameters during evaluation suggest that some level of hyperparameter optimization was performed. Data augmentation is a technique used to increase the size of the training set by applying random transformations to the images, such as rotation, scaling, and flipping. The choice of data augmentation parameters can have a significant impact on the performance of the model.

In summary, while the specific method used to optimize the hyperparameters of the ResNet50 model is not mentioned in the provided context, it is likely that some form of hyperparameter tuning was performed, as evidenced by the comparison with another public plant classification algorithm and the use of data augmentation.