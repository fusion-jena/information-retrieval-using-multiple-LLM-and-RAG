The process followed to deploy the trained deep learning model involved several steps, including model serialization and platform selection. 

First, the base models were frozen, and their weights were trained on the ImageNet dataset. A dropout layer was added to reduce overfitting, and a softmax layer was added for predicting the class for an input image. The models were then compiled and optimized using either the Adam optimizer or gradient descent. 

The trained models were then serialized, which involved saving the model architecture and weights to a file. This allowed the models to be easily loaded and used in other applications. 

For the app development, Android Studio was used, and the saved models were converted into the TensorFlow Lite version using the TensorFlow Lite converter. TensorFlow Lite is a set of tools to perform deep learning on smartphone and IoT devices. 

The architecture of the mobile app includes a leaf detection module that contains a TensorFlow Lite interpreter for the TensorFlow Lite model. The app is developed using the Java programming language. 

The size of the models based on MobileNetV3-Large and MobileNetV3-Small is 4.88 MB and 1.99 MB, respectively, which are lightweight compared to AlexNet (227.5 MB). 

For testing the application, Android studio comes with built-in phone emulators, or the app could be deployed to an actual device. 

Therefore, the process followed to deploy the trained deep learning model involved serializing the model, converting it into a TensorFlow Lite version, and integrating it into a mobile app developed using Android Studio. The app can then be tested using built-in phone emulators or deployed to an actual device.