The provided context discusses the parameter tuning of a machine learning model, specifically a Random Forest (RF) model, and not a deep learning model. Therefore, I cannot provide an answer directly related to the criteria used to split data for deep learning model training. However, I can tell you that in general, for both machine learning and deep learning models, the data splitting process often involves creating separate sets for training, validation, and testing.

In the context provided, the data splitting approach for the RF model involves a stratified random sampling technique. This method ensures that the training/testing dataset accurately represents the distribution of AGB (Above Ground Biomass) values within the LiDAR-derived AGB maps. Specifically, half of the pixels are randomly selected for the training and testing split, with the 'seed' parameter used to ensure reproducibility.

For deep learning models, similar data splitting strategies can be employed. A common approach is to split the dataset into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance on unseen data.

In deep learning, especially when dealing with large datasets, k-fold cross-validation can be a useful technique. This method involves dividing the dataset into 'k' subsets or folds. The model is then trained on 'k-1' folds while one fold is held out for validation. This process is repeated 'k' times, with each fold used once for validation. The average performance across all 'k' runs is used as the final evaluation metric.

In summary, although the provided context discusses the RF model and not a deep learning model, the data splitting process generally involves creating separate sets for training, validation, and testing. Common strategies include simple random sampling, stratified sampling, and k-fold cross-validation. The choice of strategy depends on the specific use case, dataset size, and model complexity.