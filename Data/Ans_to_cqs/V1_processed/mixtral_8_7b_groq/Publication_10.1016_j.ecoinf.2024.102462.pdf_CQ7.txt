In the context provided, there is information about how the data was split to assess the generalization power of the deep learning (DL) networks. The data was divided into four non-overlapping subsites to maximize the independence between the training and testing sets. This approach was taken to ensure a more realistic evaluation of the DL model's performance, as randomly dividing a single dataset into training and testing might lead to overestimating practical performance.

However, the text does not explicitly mention other common data split criteria, such as the validation set. The validation set is often used during the model training process to fine-tune hyperparameters and prevent overfitting. In a typical scenario, the dataset is divided into three parts: training, validation, and testing. The training set is used to adjust the model's parameters, the validation set helps in selecting the best model and hyperparameters, and the testing set is used to evaluate the final model's performance on unseen data.

In this specific context, the authors focused on the importance of using independent data subsites to assess the model's generalization power. However, it does not mean they did not use a validation set for hyperparameter tuning or model selection. The provided context simply does not contain information about these aspects of the data splitting process.

In summary, the criteria used to split the data for DL model training typically include a training set, a validation set, and a testing set. In the provided context, the authors emphasized the use of independent data subsites for training and testing to assess the model's generalization power. Still, they did not explicitly mention the use of a validation set for hyperparameter tuning or model selection.