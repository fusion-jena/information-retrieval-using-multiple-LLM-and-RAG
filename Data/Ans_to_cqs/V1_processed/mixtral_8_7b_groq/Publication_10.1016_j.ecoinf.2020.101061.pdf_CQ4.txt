The data augmentation techniques applied in the deep learning pipeline, as described in the given context, include random flips and translations. However, it was found that these techniques had little effect on the final score. Other data augmentation techniques such as rotation and scaling were not mentioned in the provided context.

The study performed a sensitivity study by training models using different proportions of training data, including 5%, 25%, 50%, and 75% of the total hand-annotations, as well as running the evaluation plots for the pretraining model only (i.e. 0% hand-annotated data) to assess whether the addition of hand-annotated data improved the within-site pretraining.

It is also mentioned that for pretraining, a LiDAR-based unsupervised algorithm was used to generate predicted trees which were overlaid on RGB imagery. This pretraining data generation approach allows for the collection of virtually unlimited pretraining data, making NEON sites an ideal training source for RGB tree models that could be applied to other data types.

In summary, the data augmentation techniques applied in the deep learning pipeline, as described in the given context, include random flips and translations, but it was found that these techniques had little effect on the final score. Other data augmentation techniques such as rotation and scaling were not mentioned in the provided context.