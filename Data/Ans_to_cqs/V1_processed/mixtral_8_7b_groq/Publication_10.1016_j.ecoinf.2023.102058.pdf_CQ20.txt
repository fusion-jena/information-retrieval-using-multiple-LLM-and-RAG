The provided articles do not explicitly mention the specific hardware resources used for training the deep learning models. However, it is generally known that deep learning models often require substantial computational power for training, which is typically provided by specialized hardware such as Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). These hardware resources can perform the large number of matrix and vector operations required for training deep learning models more efficiently than traditional Central Processing Units (CPUs). Therefore, while the specific hardware used in the studies described in the articles is not mentioned, it can be inferred that they likely used some form of specialized computational hardware for training their deep learning models.