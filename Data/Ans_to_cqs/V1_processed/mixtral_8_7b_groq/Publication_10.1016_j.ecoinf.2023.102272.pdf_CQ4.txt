Based on the provided context, there is no explicit information about the data augmentation techniques applied in the deep learning pipeline. Data augmentation is a common technique used in deep learning to increase the size and variability of the training dataset by generating modified versions of the existing data. Common data augmentation techniques include flipping, rotating, and scaling. However, these specific techniques are not mentioned in the context.

The context provides information on the performance of deep learning models for predicting the number of eggs in a bird's clutch, with the best validation accuracies achieved by a Deep Convolutional Long Short-Term Memory (DeepConvLSTM) model. The model selection procedure involved generating five models for each of the four available deep-ANN architecture types and training each one with a small subset of the training data for four epochs. The accuracy of the candidate models was then compared using a left-out validation data set, and the model with the highest performance was selected for training on the full training data for up to 30 epochs.

The context also includes a table with parameters tested and values for each classical machine learning model used and each test year. However, there is no information about data augmentation techniques applied in the deep learning pipeline.

Therefore, based on the provided context, it is not possible to answer the query regarding the data augmentation techniques applied in the deep learning pipeline.