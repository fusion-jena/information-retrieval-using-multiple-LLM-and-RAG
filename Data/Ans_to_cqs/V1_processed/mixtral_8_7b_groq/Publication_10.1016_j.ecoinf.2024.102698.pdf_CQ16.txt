Based on the provided context, there is no direct information about the criteria used to determine when training is complete for the decision support tool mentioned. However, it is mentioned that the tool uses synthetic data for training and evaluates the success of the model in predicting ecological outcomes.

In general, there are several common criteria used to determine when training is complete in machine learning models, including:

1. Validation loss plateau: This is the most common criterion used to determine when training is complete. It involves monitoring the loss function on a validation set during training and stopping the training process when the loss function stops decreasing or starts increasing, indicating that the model has reached a plateau and further training is unlikely to improve performance.
2. Early stopping: This is a regularization technique used to prevent overfitting by stopping the training process before the validation loss starts increasing. It involves setting a threshold for the number of epochs or iterations to train the model, and stopping the training process if the validation loss does not improve within that threshold.
3. Patience: This is a variation of early stopping that involves setting a patience parameter, which specifies the number of epochs or iterations to wait before stopping the training process if the validation loss does not improve.
4. Learning rate decay: This involves gradually decreasing the learning rate during training to improve convergence and prevent overshooting the minimum of the loss function.

Without more specific information about the decision support tool mentioned, it is difficult to determine which of these criteria are used to determine when training is complete. However, it is mentioned that the tool uses synthetic data for training and evaluates the success of the model in predicting ecological outcomes, so it is possible that a combination of these criteria are used to ensure that the model is trained to an acceptable level of performance.