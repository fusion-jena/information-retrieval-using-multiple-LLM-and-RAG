Based on the provided context, there are no specific criteria mentioned for splitting the data into training, testing, and validation sets for deep learning model training. However, it is a common practice in deep learning to split the data into these three sets to ensure the model's generalization and prevent overfitting.

In the context of LiDAR data and CHM (Canopy Height Model) generation, the data splitting criteria could depend on various factors, such as the number of available data points, the spatial distribution of the data, and the desired level of accuracy.

For instance, in the study by Jin et al. (2018), the authors used 70% of the data for training, 10% for validation, and 20% for testing the deep learning model for individual maize segmentation from terrestrial LiDAR data. This split was arbitrary and did not rely on specific criteria.

In another study by Martins et al. (2021), the authors used a 70-15-15 split for training, validation, and testing, respectively, for tree canopies segmentation in urban areas using machine learning and SLIC (Simple Linear Iterative Clustering) algorithms.

In general, the data splitting criteria for deep learning model training could be based on various methods, such as random sampling, stratified sampling, or clustering. Random sampling involves randomly selecting a portion of the data for each set, while stratified sampling ensures that each set has a representative sample of the data distribution. Clustering involves grouping similar data points together and then selecting a portion of each group for each set.

In conclusion, while the provided context does not mention specific criteria for splitting the data for deep learning model training, it is a common practice to use a portion of the data for training, validation, and testing. The splitting criteria could depend on various factors, such as the data distribution, the desired level of accuracy, and the specific deep learning algorithm used.