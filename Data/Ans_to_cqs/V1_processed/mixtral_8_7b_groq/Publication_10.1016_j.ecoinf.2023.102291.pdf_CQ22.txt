The performance of the deep learning model is evaluated using several metrics, including accuracy, precision, recall, and specificity. Accuracy is the proportion of all correct predictions out of all predictions made. Precision, also known as positive predictive value, is the number of true positives divided by the sum of true positives and false positives. Recall, also known as sensitivity, is the number of true positives divided by the sum of true positives and false negatives. Specificity is the number of true negatives divided by the sum of true negatives and false positives. These metrics are used to assess the model's ability to detect sounds with a signal-to-noise ratio (SNR) greater than 1. Additionally, the F1 score is used, which is the harmonic mean of precision and recall, providing a single metric that encapsulates both. The selection of the best model was based on the validation accuracy and precision obtained during training. The model training and prediction procedures were executed on Microsoft Azure using instance NV12s v3 with 12 vCPUs and 112 GB RAM. The CNNs were implemented using TensorFlow and Python 3. The Ubuntu 20.04 operating system was used, obtained via the Ubuntu 20.04 Data Science Virtual Machine on Microsoft Azure. The algorithm scripts are available in Supporting Information B.