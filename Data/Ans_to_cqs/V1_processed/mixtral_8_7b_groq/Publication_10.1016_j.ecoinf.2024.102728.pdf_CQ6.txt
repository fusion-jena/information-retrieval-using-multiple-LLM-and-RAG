In the contexts provided, there are no specific details about preprocessing steps for training a deep learning model. However, based on common practices in the field of deep learning, there are several preprocessing steps that are typically involved before training a deep learning model. These steps include:

1. Data cleaning: This involves removing any irrelevant or missing data from the dataset. Irrelevant data can include outliers or data points that are not relevant to the problem at hand. Missing data can be handled in several ways, such as imputation or removal of the data point.
2. Data normalization: This involves scaling the data to a common range, such as between 0 and 1. Normalization is important because deep learning models are sensitive to the scale of the input data. By normalizing the data, we can ensure that all features contribute equally to the model's learning.
3. Data augmentation: This involves artificially increasing the size of the dataset by applying transformations to the existing data. For example, in image recognition tasks, data augmentation can involve rotating, flipping, or zooming in on existing images to create new ones.
4. Feature extraction: This involves selecting a subset of features from the dataset that are relevant to the problem at hand. Feature extraction can be done manually or using automated techniques such as principal component analysis (PCA).
5. Data splitting: This involves dividing the dataset into training, validation, and testing sets. The training set is used to train the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to evaluate the model's performance.

In the context of the Mohedano et al. (2017) paper, it is likely that the authors applied some of these preprocessing steps to their dataset before training their deep convolutional neural network for object retrieval. However, the specific details of their preprocessing pipeline are not provided in the paper. Similarly, in the Cohen and Shashua (2017) paper, the authors describe a new inductive bias method for deep convolutional networks, but they do not provide details about the preprocessing steps used for their experiments.

In summary, while the provided contexts do not specifically mention the preprocessing steps involved before training a deep learning model, it is common practice to perform data cleaning, normalization, augmentation, feature extraction, and splitting before training a deep learning model.