The provided context does not give specific information about the criteria used to split the data for deep learning model training (e.g., train, test, validation) since it focuses on comparing MTMI-SMF and Random Forest classification approaches for remote sensing. However, it does provide details about how the Random Forest model was implemented for the comparison.

In the Random Forest implementation, the data was split using 5 K-fold cross-validations. This means that the entire dataset was divided into five subsets or "folds." Four of these folds were used for training, and the remaining fold was used for testing. This process was repeated five times, with a different fold being used for testing each time. The results from the five iterations were then combined to provide a more robust estimation of the model's performance.

For each iteration, the random forest algorithm was calculated using 80% of the data. This implies that 80% of the samples in the training folds were used for training the model, while the remaining 20% of the samples in the training folds were not used during that iteration. This approach helps to reduce overfitting and improves the model's ability to generalize to new, unseen data.

In summary, the provided context does not explicitly mention the criteria used for splitting the data for deep learning model training. However, it does reveal that the Random Forest model was trained using 5 K-fold cross-validations, with 80% of the training folds' samples being used for training and the remaining 20% being used for testing during each iteration.