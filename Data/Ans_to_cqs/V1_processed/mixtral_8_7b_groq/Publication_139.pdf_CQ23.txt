The generalizability of the deep learning model was ensured through several measures, including the use of a diverse dataset, cross-validation, and normalization of the prediction record.

Firstly, the dataset used for training the model was diverse, consisting of annotated clips of sound recordings. However, the specific details of the diversity of the dataset are not provided in the context.

Secondly, cross-validation was used to train and test the model's performance. Specifically, five-fold cross-validation was employed, where the assembled database of annotated clips was divided into five parts, and the model was trained and tested on each of these parts in turn. The results reported are the average of these five runs.

Thirdly, to prevent overfitting, early stopping was used during training. This technique involves monitoring the model's performance on a validation dataset during training and stopping the training process once the model's performance on this validation dataset ceases to improve.

Fourthly, the prediction record was normalized by the number of 8-s intervals actually recorded during that hour. This normalization was done to account for the possibility that missing audio data would render a given prediction record artificially low.

Lastly, the network performance was tested on a validation dataset consisting of six validation days. The average classification accuracy was reported as 84.9%, with the lowest and highest accuracies being 81.7% and 88.6%, respectively.

Therefore, the generalizability of the deep learning model was ensured through the use of a diverse dataset, cross-validation, normalization of the prediction record, early stopping, and testing on a validation dataset.