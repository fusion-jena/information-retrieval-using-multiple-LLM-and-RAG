Based on the provided context, there is no explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context discusses the use of Random Forests (RFs), Gradient Boosting Machines (GBMs), Generalized Additive Models (GAMs), and Artificial Neural Networks (ANNs) for modeling, but it does not mention the data splitting approach.

However, it is common practice in machine learning, including deep learning, to split the data into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final model's performance.

In the context of this study, the authors used cross-validation for model evaluation. Cross-validation is a technique where the data is split into 'k' subsets, and the model is trained on 'k-1' subsets, with the remaining subset used for testing. This process is repeated 'k' times, with a different subset used for testing each time. The average performance across all 'k' trials is then reported.

While cross-validation is a useful technique for model evaluation, it does not provide a clear answer to the question about the criteria used to split the data for deep learning model training. Therefore, without further information, it is not possible to provide a definitive answer to this query.