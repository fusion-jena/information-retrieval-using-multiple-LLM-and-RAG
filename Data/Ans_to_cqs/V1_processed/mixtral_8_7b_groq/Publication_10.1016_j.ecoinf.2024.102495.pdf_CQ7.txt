The context provided does not give specific information about how the data was split for training the deep learning model. However, it is mentioned that a stratified 10-fold cross-validation was used to evaluate the model performance. This suggests that the data was divided into 10 subsets, and for each subset, a model was trained on the remaining 9 subsets and tested on the selected subset. This process was repeated 10 times, with a different subset used for testing in each iteration. This approach allows for a more robust evaluation of the model's performance as it reduces the risk of overfitting and provides a more reliable estimate of the model's generalization ability.

Moreover, the use of cross-validation implies that the data was not split into separate training, validation, and test sets. Instead, the entire dataset was used for both training and testing, with the test set varying in each iteration of the cross-validation process. This approach is commonly used in deep learning when the amount of available data is limited, as it allows for more efficient use of the data and can lead to better model performance.

In summary, while the context does not provide explicit information on how the data was split for training the deep learning model, it can be inferred that a stratified 10-fold cross-validation was used for model evaluation, and the entire dataset was used for both training and testing.