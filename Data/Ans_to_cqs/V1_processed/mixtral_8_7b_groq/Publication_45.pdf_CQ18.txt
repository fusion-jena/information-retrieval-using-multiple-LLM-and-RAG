In the training phase of the deep neural network (DNN) model, a strategy to monitor the model's performance during training is implemented by splitting the full data set into a training data set and a test data set. The training data set is used to update the connection weights between neurons, while the test data set is used to gauge the accuracy of predictions for new input data. This approach allows for an evaluation of the model's performance on data that it has not seen before, providing a better understanding of how well the model will generalize to new data.

The training process involves iteratively updating the connection weights between neurons to minimize the prediction error over the training data set. The details of the network architecture, such as the size of the network, the selection of specific layer types, and the parameters of the training process, strongly determine the prediction accuracy of the network. These parameters are usually problem-specific, and their optimization is crucial for the model's performance.

To optimize the model's performance, the hyper-parameters, such as network capacity (number of layers and neurons per layer), applied regularization techniques, the used loss function, and optimizer, are evaluated iteratively. The training of the individual candidate networks is stopped when the accuracy of the network on the test dataset does not increase further. This approach ensures that the model's performance is monitored during training, and the risk of overfitting is minimized.

In summary, the strategy implemented to monitor the model performance during training involves splitting the data set into a training data set and a test data set, evaluating the hyper-parameters iteratively, and stopping the training when the accuracy of the network on the test dataset does not increase further. This approach ensures that the model's performance is monitored during training, and the risk of overfitting is minimized, leading to a better understanding of how well the model will generalize to new data.