The strategy implemented to monitor the model performance during training involves several steps and techniques. First, the model's weights were randomly initialized using a specific integer seed to ensure consistent reproducibility of results. Then, meticulous manual tuning of hyperparameters was conducted to achieve optimal model performance. The selected hyperparameters, which yielded the best performance metrics, include the ADAM optimizer with a learning rate of 0.003, a batch size of 32, 100 epochs, a dropout rate of 0.5, and the binary cross-entropy loss function.

To monitor the model's performance during training, a confusion matrix, accuracy, recall, precision, F1-score, Cohen Kappa, and the area under the ROC curve were used as performance metrics. These conventional metrics were chosen based on Johnson and Khoshgoftaar (2019).

Additionally, the study implemented two distinct validation methodologies. The first method involved partitioning the dataset into training and validation sets, with 70% of the data designated for training and 30% for validation. This division was performed through random selection using the train_test_split function from the scikit-learn library (version 1.2.2). The recurrent neural network (RNN) model was designed to incorporate three primary input parameters: the bee's age, the daily number of flights, and the total time spent outside daily. Following data preparation, labels for both training and testing datasets underwent one-hot encoding using the OneHotEncoder function from the scikit-learn library.

The accuracy of the training and validation datasets was plotted in Figure 4, which shows the accuracy of models for each previously published dataset, accuracy of models trained with 1-4 data sets combined, and accuracy of models trained with a maximum of 5, 10, 15, 20, and 25 days of records per bee (all four datasets combined). The final validation accuracy is indicated at the bottom of the graphs.

Overall, the strategy implemented to monitor the model performance during training involves using conventional performance metrics, manual tuning of hyperparameters, and two distinct validation methodologies, including random selection and one-hot encoding. The accuracy of the training and validation datasets was plotted to visualize the model's performance during training.