Based on the provided context, there is no explicit information about the methods used for collecting raw data in the deep learning pipeline for coral reef fish detection and recognition in underwater videos. However, it can be inferred that the raw data consists of underwater videos, which are then processed to extract frames or thumbnails for further analysis.

The context does mention that the study added three classes to their initial thumbnail database: "Random/specific background," "Part of Fish," and "Fish." These classes likely contain labeled thumbnails extracted from the underwater videos. The "Random/specific background" class contains 116,820 thumbnails with random backgrounds and 91,247 thumbnails with specific backgrounds. The "Part of Fish" class contains 55,848 thumbnails, and the "Fish" class contains 970 thumbnails.

The context also mentions that the study used a deep neural network (DNN) with convolutional layers to both create feature vectors and classify them. This implies that the raw data (underwater videos) undergo some preprocessing to extract frames or thumbnails, which are then used to train the DNN.

In summary, while the context does not provide explicit information about the methods used for collecting raw data, it can be inferred that the raw data consists of underwater videos, which are processed to extract frames or thumbnails for further analysis.