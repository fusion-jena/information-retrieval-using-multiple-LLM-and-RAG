The provided context discusses the use of machine learning algorithms, including deep learning, for water quality parameter quantification and mapping. However, it does not explicitly mention techniques used to address data bias during the preprocessing of the deep learning pipeline. Therefore, I cannot directly answer the query using the given context.

However, I can provide some general techniques used to address data bias in machine learning and deep learning preprocessing:

1. Stratified splitting: This technique involves dividing the dataset into subgroups based on specific criteria (like class labels) and then ensuring that each subset is proportionally represented in the training, validation, and testing sets. This method helps maintain the original data distribution and avoid bias in the learning process.

2. Oversampling: When the dataset is imbalanced, with one class having significantly more instances than another, oversampling can be used to increase the minority class instances. This can be done by randomly duplicating instances from the minority class or using more advanced techniques like Synthetic Minority Over-sampling Technique (SMOTE).

3. Undersampling: Alternatively, undersampling can be used to balance the dataset by reducing the number of instances in the majority class. However, this technique may result in loss of valuable information.

4. Diverse data collection: Collecting data from various sources, locations, and conditions can help ensure that the dataset is representative and less biased. This can help improve the model's ability to generalize and perform well on unseen data.

5. Data augmentation: This technique involves artificially increasing the size of the dataset by applying transformations (e.g., rotation, scaling, flipping) to the existing data. This can help improve model robustness and reduce overfitting.

While these techniques are not explicitly mentioned in the provided context, they are commonly used in the preprocessing of deep learning pipelines to address data bias.