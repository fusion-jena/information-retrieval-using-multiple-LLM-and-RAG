The provided context does not give specific information about the hardware resources used for training a deep learning model. However, it does mention the use of XGBoost, a scalable tree boosting system, in one of the studies. XGBoost is an implementation of gradient boosting machines (GBMs) that is optimized for performance and efficiency. It supports various types of computation, including CPUs and GPUs.

Chen and Guestrin (2016) describe XGBoost as a system that "is designed to be highly efficient, flexible and portable. It supports various computational platforms, including central processing units (CPUs), graphics processing units (GPUs), and distributed environments." This suggests that XGBoost can be used with GPUs, which are specialized hardware designed to accelerate computations for machine learning and deep learning.

However, the context does not provide information on whether GPUs or other hardware resources were used in the specific studies mentioned. Therefore, it is not possible to give a definitive answer to the query based on the provided information.


The provided context does not give specific information about the hardware resources used for training deep learning models. It only mentions the use of XGBoost, a scalable tree boosting system that supports various computational platforms, including CPUs and GPUs. Therefore, it is not possible to answer the query without additional information.