The provided context does not give specific information about the criteria used to split the data for training a deep learning model. However, it does mention that data analysis was conducted using R 4.0.5 and that gaping data were averaged over 5 minutes in the Venice Lagoon and over 1 minute in the Wadden Sea. Additionally, daily curves of gaping for each sensor were used as input in the analysis, yielding 1286 daily curves for the Venice Lagoon and 203 daily curves for the Wadden Sea.

In general, when training a deep learning model, it is common to split the data into three subsets: training, validation, and testing. The training set is used to train the model, the validation set is used to tune the model's hyperparameters and prevent overfitting, and the testing set is used to evaluate the model's performance on unseen data.

There are various ways to split the data, and the choice of splitting criteria depends on the specific problem and dataset. Some common methods include random sampling, stratified sampling, and time-series splitting. For time-series data, it is important to consider the temporal dependencies and split the data in a way that preserves the temporal order.

Without more information about the dataset and the specific deep learning model being used, it is difficult to provide a more specific answer. However, it is recommended to split the data in a way that ensures the model's performance can be accurately evaluated and that prevents overfitting.