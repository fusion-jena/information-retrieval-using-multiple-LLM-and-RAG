The provided context does not include specific information about the criteria used to split the data for deep learning model training. However, it does mention the use of cross-validation in the context of Support Vector Machine (SVM) model training, which is a technique also used in deep learning for assessing model performance and preventing overfitting.

In cross-validation, the data is typically split into k subsets or "folds," where k-1 folds are used for training and the remaining fold is used for validation. This process is repeated k times, with a different fold used for validation each time. The resulting validation errors are then averaged to provide an estimate of the model's performance.

In deep learning, data splitting is often done using a similar approach, where a portion of the data is reserved for training, another portion for validation, and a final portion for testing. The training set is used to train the model, the validation set is used to tune hyperparameters and prevent overfitting, and the test set is used to evaluate the final model performance.

The specific criteria for splitting the data can vary depending on the problem and the available data. Common approaches include random sampling, stratified sampling (where the splits are made proportional to the class distribution), and time-series splitting (where the data is split based on time order).

In summary, while the provided context does not explicitly mention the criteria used for data splitting in deep learning, it does mention the use of cross-validation, which is a common technique for assessing model performance and preventing overfitting. In deep learning, data splitting is typically done using a portion of the data for training, another portion for validation, and a final portion for testing, with the specific criteria for splitting depending on the problem and available data.