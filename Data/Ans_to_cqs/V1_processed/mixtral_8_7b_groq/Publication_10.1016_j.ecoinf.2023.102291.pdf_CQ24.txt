The text does not directly mention strategies used to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does provide information about the use of a convolutional neural network (CNN) for detecting humpback whale songs, and the training and prediction procedures employed.

In the context of this study, randomness could potentially arise in various stages of the deep learning pipeline, such as when initializing weights in the CNN, shuffling data during training, or splitting data into training, validation, and testing sets. While the text does not explicitly discuss strategies to handle randomness, it does provide details about the methodology and tools used, which could offer some insights.

The CNN architecture was customized, and the smallest model comprised 3900 images for transfer learning. The training process involved choosing the most suitable architecture based on the best validation accuracy and precision. The training and prediction procedures were executed on Microsoft Azure using a specific instance with designated vCPUs and RAM. The CNNs were implemented using TensorFlow, a popular open-source machine learning framework known for its robust handling of randomness in deep learning pipelines.

TensorFlow allows users to control randomness through various mechanisms, such as setting a random seed value for reproducibility. Although the text does not explicitly mention the use of a seed value, it is plausible that the authors employed such strategies to ensure the stability and reproducibility of their results.

In summary, while the text does not directly discuss strategies to handle randomness in the deep learning pipeline, it does provide information about the tools and methodologies used, which could imply the use of standard practices to manage randomness, such as setting a random seed value in TensorFlow.