Based on the provided context, there is no explicit information about the measures taken to ensure the generalizability of the deep learning model. However, I can provide some possible measures that are commonly used to ensure the generalizability of a deep learning model. These measures include:

1. Diverse dataset: Using a diverse dataset that covers various scenarios, outliers, and edge cases can help the deep learning model to generalize better. The dataset should be representative of the problem and should cover all possible variations.
2. Cross-validation: Cross-validation is a technique used to evaluate the performance of a deep learning model. In cross-validation, the dataset is divided into multiple folds, and the model is trained and tested on each fold. This process helps to ensure that the model is not overfitting to a particular subset of the data.
3. Stratified splitting: Stratified splitting is a technique used to divide the dataset into training, validation, and testing sets. In stratified splitting, the dataset is divided in such a way that each subset has a similar distribution of classes or labels. This technique helps to ensure that the model is not biased towards a particular class or label.
4. Regularization: Regularization is a technique used to prevent overfitting in deep learning models. Regularization adds a penalty term to the loss function, which discourages the model from learning overly complex patterns in the data.
5. Early stopping: Early stopping is a technique used to prevent overfitting in deep learning models. In early stopping, the training process is stopped when the model's performance on the validation set starts to degrade.

Based on the context provided, it can be inferred that the authors developed a three-layer feedforward back-propagation neural network with a 30â€“20-10 architecture. The activation functions used were tansig, tansig, and purelin. The input factors were population size and GDP, and the predicted output was GHGdwts. The dataset was divided into 70% for training, 15% for validation, and 15% for model testing. However, there is no explicit information about the measures taken to ensure the generalizability of the deep learning model.