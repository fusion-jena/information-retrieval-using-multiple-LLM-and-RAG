Based on the provided context, there is no explicit information given about the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it can be inferred that the model was trained for 350 epochs and evaluated using various scores such as precision, recall, F1, GIoU, and mAP, which are calculated from model validation data consisting of 321 image tiles. This suggests that a validation set was used during the training process to calculate the evaluation scores at different iteration stages.

Furthermore, it is mentioned that the data set used in this project is relatively small in the context of deep learning. The authors created their own data set due to the lack of existing quality data, and they tested the model under difficult circumstances and complex backgrounds, which still yielded good detection capabilities. This implies that the data set was likely split into training, testing, and validation sets to train and evaluate the model's performance. However, the specific criteria or ratios used for splitting the data are not provided in the context.

In summary, while the provided context does not explicitly state the criteria used to split the data for deep learning model training, it can be inferred that a validation set was used during the training process for evaluation. The specific criteria or ratios used for splitting the data, however, are not mentioned in the context.