The strategy implemented to monitor the model performance during training involves the use of a stochastic gradient descent with momentum optimizer, with a manually set initial learning rate of 0.001 and a maximum number of epochs of 15. This approach allows for the tracking of the model's performance as it iterates through the training data multiple times. Additionally, the training process was repeated 10 times for each algorithm, using the same training and testing picture subsets in each run. This allowed for the assessment of performance consistency and the calculation of observed accuracy results, which are provided in Supplementary Tables S1–S6. The full raw data is also available in Supplementary Dataset S1.

It is important to note that the 'classical' machine-learning algorithms (AB, GB, HB, and LD) were run in Python using the scikit-learn toolbox, with hyperparameters left at default values except for the learning rate of GB and HB (which were set to 0.15) and the tolerance threshold value for LD (set to 1 × 10). This additional level of monitoring and adjustment further ensured the accurate assessment of model performance during training.

In summary, the strategy for monitoring model performance during training includes the use of a stochastic gradient descent with momentum optimizer, the repetition of the training-testing process 10 times for each algorithm, and the adjustment of hyperparameters for the 'classical' machine-learning algorithms. These measures allowed for the consistent and accurate tracking of model performance throughout the training process.