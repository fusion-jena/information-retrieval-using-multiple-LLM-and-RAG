The provided context does not give specific information about the criteria used to determine when training is complete for the CityNet algorithms. However, it mentions that the analyses were conducted using scikit-learn, a machine learning library that provides various stopping criteria for training, such as early stopping based on validation loss convergence. It is possible that one of these criteria was used, but the specific criterion is not mentioned in the provided text.

In general, training of machine learning models is complete when the model's performance on a validation set stops improving or when a pre-determined number of training iterations has been reached. One common stopping criterion is early stopping, which involves monitoring the model's performance on a validation set after each training iteration, and stopping the training when the performance on the validation set stops improving or starts getting worse. This helps to prevent overfitting, which occurs when the model performs well on the training data but poorly on new, unseen data.

Another criterion is to set a maximum number of training iterations or epochs. This ensures that the training process will terminate after a certain number of iterations, even if the validation loss has not plateaued. This can be useful in cases where the training process is very time-consuming or computationally expensive.

In addition, some optimization algorithms used for training have an in-built stopping criterion, for example, some optimizers have a learning rate schedule that decreases the learning rate after a certain number of iterations, and eventually stops the training when the learning rate becomes too small.

In conclusion, the provided context does not give specific information about the stopping criterion used for the CityNet algorithms, but it is likely that one of the common criteria such as early stopping, maximum number of iterations or an in-built stopping criterion in the optimization algorithm was used.