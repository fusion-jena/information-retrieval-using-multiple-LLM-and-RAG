The criteria used to determine when training is complete are not explicitly stated in the provided context. However, it is mentioned that the models are trained with hyperparameters tuned to optimize performance. This suggests that some form of validation or monitoring of the training process is likely being used.

In the context of machine learning, one common criterion for determining when training is complete is when the validation loss plateaus or stops decreasing significantly. This means that the model's performance on a separate validation dataset is not improving even as the model continues to train on the training dataset. At this point, further training is unlikely to improve the model's performance and may even lead to overfitting, where the model becomes too specialized to the training data and performs poorly on new, unseen data.

Another criterion that could be used is early stopping, where training is halted before the validation loss plateaus if it is observed that the validation loss has started to increase. This can help prevent overfitting and save computation time.

It is also possible that other criteria are being used in the provided context, such as a maximum number of training epochs or a patience parameter that determines how many epochs to wait before stopping training if the validation loss does not improve. However, without further information, it is difficult to say for certain what criteria are being used to determine when training is complete.