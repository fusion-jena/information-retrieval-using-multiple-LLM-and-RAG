The context provided does not give a specific method for optimizing the hyperparameters of the model in general. However, it does mention some specific values that were used for the hyperparameters in a particular experiment.

In the experiment described in subsection 3.3, the MF model was tuned using a grid search. Specifically, the regularization parameter Î» was set to 0.1, the number of factors k was set to 360, and the number of iterations was set to 100.

For the DMF4 model used in the same experiment, the context does not specify the method used to optimize its hyperparameters. It only mentions the configuration of the DMF4 model and its training in the experiment.

In addition, the context mentions the use of the Scikit-learn library for machine learning in Python, which provides various methods for hyperparameter tuning such as grid search and random search. However, it does not specify whether these methods were used to optimize the hyperparameters of the models in the given study.

Therefore, while the context provides some information on the specific values used for hyperparameters in a particular experiment, it does not give a general answer to the query about how the hyperparameters of the model are optimized.