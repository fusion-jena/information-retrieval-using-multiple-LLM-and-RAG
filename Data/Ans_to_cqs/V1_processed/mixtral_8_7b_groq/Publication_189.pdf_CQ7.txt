In the context provided, there is no explicit information given about the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it is mentioned that for training and evaluating the Mask R-CNN model, 20 epochs with 500 steps each are being used for training images and 100 steps for validation images. This suggests that a portion of the data is set aside for validation during the training process.

In general, there are several common approaches to splitting data for deep learning model training. One common method is to randomly split the data into a training set, a validation set, and a test set. The training set is used to train the model, the validation set is used to tune hyperparameters and make decisions during the training process, and the test set is used to evaluate the final performance of the trained model. The exact proportions used for each set can vary, but a common split is 60% for training, 20% for validation, and 20% for testing.

Another approach is to use k-fold cross-validation, where the data is split into k equal-sized subsets. The model is then trained on k-1 of the subsets, and the remaining subset is used for validation. This process is repeated k times, with a different subset used for validation each time. The advantage of this approach is that it provides a more robust estimate of the model's performance, since each data point is used for validation multiple times.

The choice of data split approach depends on various factors, such as the size of the dataset, the variability of the data, and the specific goals of the modeling process. It is important to carefully consider these factors when deciding how to split the data for deep learning model training.