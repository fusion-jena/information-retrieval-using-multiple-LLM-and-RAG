The hyperparameters used in the deep learning model include an ADAM optimizer and a learning rate of 10. Image augmentation techniques such as horizontal flip, 0.2 degree counter clock wise shear, and random zoom between 0 and 0.2 were also applied, resulting in 224 Ã— 244 pixel RGB input tensors. The data was normalized to ImageNet mean values and the pixel values were rescaled in the range of [0, 1]. The model was trained for roughly 4 days with a batch size of 64, passing over the entire training set 950 times. The best model was selected based on minimal validation loss that occurred at epoch 448. This model showed a training loss of 0.256, a training accuracy of 0.899, a validation loss of 0.298, and a validation accuracy of 0.891.