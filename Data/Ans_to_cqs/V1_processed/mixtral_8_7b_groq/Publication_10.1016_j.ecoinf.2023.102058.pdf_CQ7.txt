In the context provided, there is no specific information about the criteria used to split the data for deep learning model training. However, in general, there are standard methods for splitting data into training, testing, and validation sets in machine learning and deep learning.

One common approach is to randomly split the dataset into a training set (e.g., 70% of the data), a validation set (e.g., 15% of the data), and a test set (e.g., 15% of the data). The training set is used to train the model, the validation set is used to tune hyperparameters and make decisions during the training process, and the test set is used to evaluate the final model performance.

Another approach is to use time series data and split it chronologically, where the most recent data is used for testing, the middle portion for validation, and the oldest data for training. This approach is useful when dealing with temporal data and can help ensure that the model is able to generalize well to unseen data in the future.

In some cases, stratified sampling may be used to ensure that the splits are representative of the overall dataset, especially if there are class imbalances or other important factors to consider.

It's worth noting that the specific criteria used to split the data can depend on the problem at hand, the size of the dataset, and other factors. Ultimately, the goal is to create a robust and unbiased model that can generalize well to new data.