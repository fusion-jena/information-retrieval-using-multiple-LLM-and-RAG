In the context provided, the data annotation techniques used in the deep learning pipeline involve using a pre-trained object detection model, specifically YOLO v7, to label images preliminarily. This model is used for bird detection in camera trap images. After the preliminary labeling, the data annotations are further processed using LabelImg, a tool that facilitates adjustments to the boundaries and classes of bird species based on the labels detected by YOLO v7.

The specific data annotation techniques mentioned are bounding box annotation and class labeling. The pre-trained YOLO v7 model is used to predict the frames and analyze the structure of the images to identify the positions of potential birds, which is done through bounding box annotation. This technique involves drawing a box around the object of interest (in this case, birds) in the image. After the preliminary labeling, human annotators use LabelImg to manually adjust the detection coordinates and delete incorrect identifications, which also involves bounding box annotation.

Instance segmentation, which involves separating an object from the background and other objects in the image, is not explicitly mentioned in the context provided. However, it is possible that instance segmentation was used in the pre-trained YOLO v7 model for bird detection.

In summary, the data annotation techniques used in the deep learning pipeline for bird detection in camera trap images involve preliminary labeling using a pre-trained object detection model (YOLO v7) for bounding box annotation, followed by manual adjustments to the detection coordinates and class labels using LabelImg.