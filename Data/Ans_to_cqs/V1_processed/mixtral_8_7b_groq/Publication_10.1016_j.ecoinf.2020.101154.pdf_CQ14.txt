The hyperparameters of the model were optimized using two methods: manual tuning and grid search. Manual tuning was employed to set the initial learning rate as low as possible and the number of iterations as high as computationally feasible. This was done to determine the contribution of each tree to the model and the degree of interaction in the model. For the two-part split, hyperparameters were tuned using grid search, which performs an exhaustive search over specified parameter values for an estimator. Grid search takes a set of possible values for each hyperparameter that should be tuned and evaluates a model trained on each element of the Cartesian product of the sets. This algorithm automatically generates the validation sets internally, so there is no need to generate a validation set to select the best model. For the RI models, the same initial parameters were set for the analysis of the CS and NW datasets, then a grid search was performed on both datasets with a two-part split to give hyperparameters with the highest level of accuracy. These were a learning rate of 0.05 and a maximum tree depth of 4 for both the CS and the NW models. The early stopping technique was used to determine when to stop the model training to avoid overfitting. For the RY models, the best performing models (based on MSE) were models with a slow learning rate of 0.005. Additionally, the NW model had a very shallow tree (tree depth of 2). The number of iterations was kept at 500. The tuned hyperparameters of the final models are shown in Table 2.

In summary, the hyperparameters of the model were optimized using manual tuning and grid search. Manual tuning was used to set the initial learning rate and number of iterations, while grid search was used for the two-part split to find the hyperparameters with the highest level of accuracy. The early stopping technique was used to avoid overfitting, and the number of iterations was kept at 500 for the RY models.