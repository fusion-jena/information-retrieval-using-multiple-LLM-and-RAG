Based on the provided context, the text does not explicitly mention the data augmentation techniques applied in the deep learning pipeline. However, data augmentation is a common practice in deep learning to increase the size and diversity of the training dataset, which can help improve the model's performance and prevent overfitting.

Some common data augmentation techniques for image data include:

1. Flipping: This technique involves flipping the image horizontally or vertically, which can help the model learn symmetrical features.
2. Rotation: Rotating the image by a certain angle can help the model learn to recognize features from different perspectives.
3. Scaling: Scaling or zooming the image can help the model learn to recognize features at different scales.
4. Translation: Translating the image horizontally or vertically can help the model learn to recognize features in different positions.
5. Color jittering: Changing the brightness, contrast, saturation, or hue of the image can help the model learn to recognize features under different lighting conditions.

The context mentions that the authors fine-tuned several state-of-the-art CNN architectures using a training dataset, but it does not specify whether they applied any data augmentation techniques. However, it is likely that they used some data augmentation techniques to increase the size and diversity of their training dataset.

Therefore, while the text does not provide specific information on the data augmentation techniques used in the deep learning pipeline, it is a common practice in deep learning to use techniques such as flipping, rotation, scaling, translation, and color jittering to augment the training dataset.