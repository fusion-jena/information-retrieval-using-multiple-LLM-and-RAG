Based on the provided context, the data was split into training and testing sets for the ensemble model that incorporates Random Forest (RF) and Support Vector Machine (SVM) components. However, there is no specific mention of a validation set or criteria used to split the data for deep learning model training.

In general, when it comes to splitting data for machine learning models, there are several common approaches. One such approach is to split the data into a training set and a test set, where the training set is used to train the model, and the test set is used to evaluate the model's performance. This approach is often used when the dataset is large enough to allow for a sufficient amount of data to be set aside for testing.

Another approach is to split the data into a training set, a validation set, and a test set. The training set is used to train the model, the validation set is used to tune the model's parameters and select the best model, and the test set is used to evaluate the final model's performance. This approach is often used when the dataset is smaller, or when the model has many hyperparameters that need to be tuned.

In the context of deep learning, data splitting criteria can include random sampling, stratified sampling, or time-series sampling. Random sampling involves selecting data points randomly from the dataset, while stratified sampling involves dividing the dataset into subgroups based on certain criteria (such as class labels) and then randomly selecting data points from each subgroup. Time-series sampling involves splitting the dataset based on time, where the training set contains data from earlier time periods, and the test set contains data from later time periods.

Based on the provided context, it is unclear which of these approaches was used to split the data for the ensemble model. However, it is clear that 80% of the data was used for training, and the remaining 20% was used for testing.