In the provided context, there is no explicit information about the criteria used to split the data for deep learning model training into subsets such as train, test, and validation. However, it does mention that active learning experiments are conducted using a portion of the data (5% of the samples), and class labels are hidden from the classifier at first, with labels incrementally revealed for each batch of samples queried by the sampling methods. This suggests that some form of data splitting is taking place, but the specific criteria are not provided.

In general, there are several common strategies for splitting data in deep learning model training:

1. Random sampling: This involves randomly splitting the data into train, test, and validation sets. This is a simple and unbiased method, but it may not accurately reflect the distribution of the data in real-world scenarios.

2. Time-based splitting: In this method, the data is split based on time. For example, the oldest data may be used for training, while the most recent data is used for testing. This can help ensure that the model is able to generalize to new, unseen data.

3. Stratified sampling: This involves splitting the data based on specific criteria, such as class labels. For example, if the data contains two classes, the train, test, and validation sets may be split such that each set contains an equal number of samples from each class. This can help ensure that the model is able to learn from a diverse set of data.

4. K-fold cross-validation: In this method, the data is split into k subsets, or "folds". The model is trained on k-1 folds, while the remaining fold is used for testing. This process is repeated k times, with a different fold used for testing each time. The results are then averaged across all k runs. This can help reduce the variance of the model and improve its generalization performance.

Without more information from the provided context, it is difficult to say which of these methods (if any) are being used to split the data for deep learning model training.