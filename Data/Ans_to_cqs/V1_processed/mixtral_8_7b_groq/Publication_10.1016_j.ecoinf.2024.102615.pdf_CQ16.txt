The context provided does not give specific information about the criteria used to determine when training is complete. However, it does mention that the validation set's R value is used as a performance indicator during the optimization process. This suggests that the training process might involve monitoring the validation set's performance and stopping the training when a certain criterion based on the validation set's performance is met.

One common criterion to determine when training is complete is when the validation loss plateaus or stops decreasing significantly. This means that the model's performance on the validation set has stabilized, and continuing to train the model may not result in improved performance or may even lead to overfitting.

Another possible criterion could be based on the number of epochs, which is the number of times the learning algorithm will work through the entire training dataset. The training process could stop after a predetermined number of epochs, or if the improvement in the validation set's performance is below a certain threshold.

The context also mentions that the data partitioning ratio between the training, validation, and test sets is set as 8:1:1, and the random partition is repeated ten times. This suggests that cross-validation might be used, in which case the training process could be determined complete when the performance on the combined validation sets from all ten partitions has stabilized.

Overall, while the context does not provide specific information on the criterion used to determine when training is complete, it is likely that some form of performance monitoring on the validation set is used, and the training process is stopped when the validation set's performance has stabilized or reached a predetermined threshold.