Based on the provided context, there is no explicit information about how the hyperparameters of the model were optimized. Hyperparameter optimization techniques such as grid search, random search, or Bayesian optimization are commonly used to find the best set of hyperparameters for a machine learning model. However, the text does not mention any of these techniques being used.

The VGG19 CNN architecture was used with weights pre-trained on the ImageNet dataset. The learning rate was reduced by a factor of 10 when retraining the model that achieved the lowest loss. A stochastic gradient descent (SGD) optimizer was used, but the learning rate and other hyperparameters were not specified.

The model was trained for 11 epochs, and then retrained if there was no decrease in loss for more than 10 consecutive epochs. The number of epochs can be considered a hyperparameter, but the optimization method for choosing this value is not mentioned.

In summary, while the context provides details about the dataset, the VGG19 architecture, and the training procedure, it does not explicitly mention any hyperparameter optimization techniques. Therefore, it is not possible to answer this query without additional information.