Based on the provided context, there is no explicit information about the postprocessing steps involved after the model training, such as Saliency maps, Metrics calculation, or Confusion matrix. However, the context does provide some insights into the analysis performed after model training.

The context discusses the predicted intensity maps (Figs. 3 to 6) generated using the best-performing methods across performance measures (knn, LoopT) with 80% hidden observations. These intensity maps are likely a part of the model evaluation process.

Additionally, the ppmlassoMixEngine and ppmlassoLoopEngine functions are mentioned, which return elements presented by the ppmMixEngine function in Guilbault et al. (2021). However, the context does not provide information on what these elements are or how they are used in postprocessing.

Furthermore, the ppmlasso package is used, which has several parameters, such as sp.scale, cov.bias, kVal, and n.fits. These parameters are likely used during the model training process, but the context does not provide information on their role in postprocessing.

Therefore, while the context provides some insights into the analysis performed after model training, it does not explicitly mention any postprocessing steps such as Saliency maps, Metrics calculation, or Confusion matrix.


The provided context does not explicitly mention the postprocessing steps involved after the model training, such as Saliency maps, Metrics calculation, or Confusion matrix. However, the context discusses the predicted intensity maps generated using the best-performing methods after model training and the elements returned by the ppmlassoMixEngine and ppmlassoLoopEngine functions. However, the context does not provide information on what these elements are or how they are used in postprocessing. Therefore, the specific postprocessing steps remain unclear based on the provided context.