Based on the provided context, there is no specific information about the criteria used to determine when training is complete for the bat call detection models. The text mainly focuses on the evaluation of the models using precision-recall curves and the comparison of human annotators' performance.

However, generally, in machine learning model training, determining when to stop training can be based on several criteria, such as:

1. Validation loss plateau: This is the most common criterion. Training is stopped when the validation loss (loss calculated on a separate validation dataset, not used for training) stops decreasing or starts increasing, indicating that the model is starting to overfit to the training data.

2. Early stopping: This is a regularization technique where training is stopped when the performance on a validation dataset stops improving for a certain number of epochs. This helps to prevent overfitting.

3. Monitoring other metrics: Sometimes, training can be stopped based on other metrics like accuracy, F1-score, or AUC-ROC, depending on the problem and the business objective.

4. Training time or computational budget: Training can also be stopped based on a predefined training time or computational budget.

Without more specific information from the text, it is not possible to provide an exact answer. However, it can be inferred that the models' performance is evaluated using precision-recall curves, and human annotators' performance is compared based on precision. These evaluations could be used to determine when training is complete, but the exact criteria are not specified.