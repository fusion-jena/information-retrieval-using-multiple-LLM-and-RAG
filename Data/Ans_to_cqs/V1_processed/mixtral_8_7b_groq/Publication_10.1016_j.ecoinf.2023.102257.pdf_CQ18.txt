The text provided does not give a detailed description of the strategy implemented to monitor the machine learning (ML) model performance during training. However, it does mention that the ML model was used to examine the influence of ML performance on tagging efficiency. It can be inferred that the model's performance was likely evaluated based on its ability to accurately predict and assist with data tagging. The text also mentions that incorrect ML predictions, such as false positives and false negatives, can slow down the tagging process. This suggests that the model's performance was monitored for these types of errors during training. Additionally, the text mentions that several open-source species-level classification models have been released, which can be used in tandem with human tagging to improve tagging efficiency. It is possible that these models were also evaluated for their performance during training. However, the specific strategy for monitoring the model performance during training is not provided in the text.