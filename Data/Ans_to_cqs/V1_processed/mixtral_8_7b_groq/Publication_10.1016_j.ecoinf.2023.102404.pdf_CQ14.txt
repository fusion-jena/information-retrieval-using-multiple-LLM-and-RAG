In the study, the hyperparameters of the machine learning model were optimized using a grid search approach. This method involves defining a range of potential values for each parameter based on prior knowledge and literature review. The grid search then exhaustively tests all possible combinations of these values and evaluates the model’s performance using cross-validation techniques. 

The specific hyperparameters that were tuned include ‘numberOfTrees’, ‘minLeafPopulation’, ‘bagFraction’, and ‘seed’. The ‘numberOfTrees’ represents the number of decision trees in the ensemble, and the grid search explored different values to determine the ideal number of trees that balances model complexity and predictive performance. 

‘minLeafPopulation’ refers to the minimum number of samples required to form a leaf node in each tree. The study experimented with various values to find the optimal setting that prevents overfitting while capturing meaningful patterns in the data. The ‘bagFraction’ indicates the proportion of the training dataset used to train each individual tree, and the search for the best value aimed to enhance model diversity and generalization.

Lastly, ‘seed’ is a random number seed used to ensure randomly selected half of the pixels for the training and testing split. This strategic sampling technique was chosen to capture the full distribution of AGB values within the LiDAR-derived AGB maps accurately. The use of a stratified random sampling approach was crucial in ensuring that the training/testing dataset accurately represented the distribution of AGB values within the LiDAR-derived AGB maps.

By employing the grid search method, the study aimed to optimize the model’s hyperparameters and enhance its ability to generalize well to new, unseen data, making it a robust and effective tool for the regression task. The winning parameters are as follows: numberOfTrees: 150, minLeafPopulation: 3, bagFraction: 1, and seed: 123.