Based on the provided context, there is no explicit mention of the data augmentation techniques applied in the deep learning pipeline. However, it is mentioned that the training dataset could be pre-processed, which includes image resizing. Therefore, I cannot definitively answer the query with the given context.

However, data augmentation techniques like flipping, rotating, and scaling are commonly used in deep learning pipelines to increase the size of the training dataset and improve model performance by providing data variance. These techniques can help reduce overfitting and improve the generalization ability of the model.

Flipping involves horizontally or vertically flipping the images in the dataset. This can help the model learn symmetrical features and improve its ability to handle different orientations.

Rotating involves rotating the images in the dataset by a certain angle. This can help the model learn features that are invariant to rotation and improve its ability to handle images taken at different angles.

Scaling involves changing the size of the images in the dataset. This can help the model learn features that are invariant to scale and improve its ability to handle images of different sizes.

Therefore, while the provided context does not explicitly mention the data augmentation techniques used, it is common practice to use techniques like flipping, rotating, and scaling in deep learning pipelines.