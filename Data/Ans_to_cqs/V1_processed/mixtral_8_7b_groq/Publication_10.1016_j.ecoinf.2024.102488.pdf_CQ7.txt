The provided context does not give specific information about the criteria used to split the data for deep learning model training. However, it does mention the use of training samples, validation samples, and cross-validation in the context of machine learning model training and evaluation.

In machine learning, it is common to split the available data into different subsets for training, validation, and testing. The training set is used to train the model, the validation set is used to tune hyperparameters and select the best model, and the test set is used to evaluate the final model performance.

In the given context, the training samples are used as input into five base models to generate prediction results. These training samples are then used as training data for a meta-model using the RF algorithm with 5-fold cross-validation. The validation samples are used to obtain prediction results using the same five base models. These validation samples are then used to obtain classification results by voting.

Additionally, Recursive Feature Elimination and Cross-Validation (RFECV) is used to select the optimal features that can reduce redundancy caused by multi-source feature datasets and improve model performance. RFECV is a wraparound approach to feature selection based on cross-validation.

Therefore, while the provided context does not explicitly mention the criteria used to split the data for deep learning model training, it does suggest the use of cross-validation in the training and validation of machine learning models.