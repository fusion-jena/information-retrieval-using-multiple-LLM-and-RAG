The criteria used to split the data for deep learning model training, such as train, test, and validation sets, are not specified in the provided context. However, the context does provide information on how data was split for a random forest (RF) model, which is a type of machine learning algorithm.

In the study by Ranta et al. (2021), the RF model was trained using 34 ground data points and the total number of samples used for validation was 8. The RF generates an internal estimate of the generalization error by the "out-of-bag" (OOB) samples, which are those not included in the training subset.

Additionally, the study by Ramoelo et al. (2015) used Sentinel-2 spectral configuration to assess rangeland quality and they used a training dataset of 250 samples and a validation dataset of 150 samples.

In general, for deep learning models, it is common to split the data into three subsets: training, validation, and test. The training set is used to train the model, the validation set is used to tune the model's hyperparameters and make decisions during the training process, and the test set is used to evaluate the model's performance on unseen data. The split ratio can vary, but a common practice is to use 60-70% of the data for training, 10-20% for validation, and 10-20% for testing.

It's important to note that the split criteria can depend on the specific use case, the size of the dataset, and the goals of the analysis. Proper splitting of the data is crucial for the model's performance and generalization.