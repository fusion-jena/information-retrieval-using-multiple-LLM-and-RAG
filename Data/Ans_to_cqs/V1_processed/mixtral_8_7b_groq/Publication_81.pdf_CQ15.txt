Based on the provided context, there is no explicit mention of optimization techniques such as Stochastic Gradient Descent (SGD) or Adam used in the deep learning pipeline for fish classification. However, it does mention the use of Elastic Net for solving the overfitting problem and improving the generalization ability of the model.

Elastic Net is a regularization technique that is a linear combination of L1 and L2 regularization, which can be expressed as the sum of the absolute value and the square of the magnitude of the model coefficients, respectively. The Elastic Net regularization term is added to the loss function of the model, which helps in reducing the complexity of the model and preventing overfitting.

In addition, the context also mentions the use of Kernel Density Estimation (KDE) for selecting a threshold based on the outgroup scores and classifying fish from different families. KDE is a non-parametric method for estimating the probability density function of a random variable. In this case, KDE is used to estimate the distribution of the outgroup scores and select a threshold that maximizes the classification performance.

Therefore, while the context does not explicitly mention optimization techniques such as SGD or Adam, it does describe the use of Elastic Net for regularization and KDE for threshold selection, which are important components of the deep learning pipeline.