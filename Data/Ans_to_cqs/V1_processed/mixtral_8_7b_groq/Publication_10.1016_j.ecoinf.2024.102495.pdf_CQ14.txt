The text does not provide explicit information about the method used to optimize the hyperparameters of the model, such as grid search or random search. However, it does mention that some model parameters or hyperparameters were varied to evaluate the performance of the given model. Specifically, the optimization algorithm or optimizer, learning rate, and dropout layer were the parameters that were varied. This suggests that a manual search or a simple systematic search may have been used to find the optimal combination of hyperparameters. The text also provides a table (Table 4) with the standard deviation values for each performance metric, which suggests that multiple runs were performed for each configuration, which is a common practice in hyperparameter tuning. However, the specific method used to search the hyperparameter space is not mentioned in the text. Therefore, the specific method used to optimize the hyperparameters of the model cannot be determined with certainty based on the provided context.