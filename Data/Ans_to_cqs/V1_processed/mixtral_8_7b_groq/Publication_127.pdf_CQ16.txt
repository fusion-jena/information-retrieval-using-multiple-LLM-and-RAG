The context does not provide specific information on the criteria used to determine when training is complete for the deep learning models used in the study. However, it is mentioned that the models achieved a classification accuracy of over 95.8% on the task of assigning labels to capture events in camera trap images. The VGG model achieved the best accuracy of 96.8%.

The training set contained 1.4 million images, and the test set contained 105,000 images. The models were trained using various architectures, training methods, preprocessing steps, and hyperparameters, which are detailed in the SI Appendix.

It is also mentioned that the code and the final DNNs trained on the camera trap images are being made available as open-source code, which would allow other researchers to replicate the findings and use the models for their own projects.

Therefore, while the specific criteria used to determine when training is complete are not mentioned in the context, it is clear that the models were trained and evaluated using established deep learning techniques and achieved high accuracy on the task of assigning labels to capture events in camera trap images.