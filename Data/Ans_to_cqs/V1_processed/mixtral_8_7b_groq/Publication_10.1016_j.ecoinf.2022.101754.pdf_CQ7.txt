The provided context does not give specific details about the criteria used to split the data for deep learning model training. However, it does mention that the study utilized a training-and-test approach with stratification splitting for each setting, with 100 different splits to the training-and-test set given. This was followed by tuning of the hyperparameter on the training set for each set and model training using an optimal setting of the hyperparameter. Therefore, it can be inferred that the data was split using a stratified sampling method, where the original sample is divided into subgroups or strata that are similar to the population with respect to the variable of interest. This method was likely used to ensure that each subset of the data (training, test, or validation) had a similar distribution of the target variable (aboveground biomass) as the original sample.

Additionally, it is mentioned that the input predictors were independent of the machine learning algorithm used in the training. This suggests that the data split was done prior to selecting the machine learning algorithm and was not dependent on the specific algorithm used.

It is important to note that the specific criteria used for data splitting can have a significant impact on the performance of the deep learning model. Factors such as the size of the training and test sets, the method of splitting (random, stratified, etc.), and the number of splits can all affect the model's ability to generalize to new data. Therefore, it is crucial to carefully consider these factors when training a deep learning model.

In summary, while the provided context does not give specific details about the criteria used to split the data for deep learning model training, it can be inferred that a stratified sampling method was used. It is important to carefully consider the data splitting criteria when training a deep learning model to ensure its ability to generalize to new data.