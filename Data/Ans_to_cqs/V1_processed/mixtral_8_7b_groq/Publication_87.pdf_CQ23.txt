The text does not provide explicit information about measures taken to ensure the generalizability of the deep learning model such as creating a diverse dataset, using cross-validation, or stratified splitting. However, it does mention that the model was trained and validated using a dataset of labeled images, and then used to make predictions on a new dataset of unlabelled images. This suggests that some steps were taken to assess the model's ability to generalize to new data.

In addition, the text mentions that a Resnet18 architecture was used for the sake of illustration, but a Resnet50 was used to obtain the full results presented in the main text. This suggests that the authors may have also explored the effects of different model architectures on the model's ability to generalize.

The text also states that the model was trained for 2 epochs for the sake of illustration, but 20 epochs were used to obtain the full results presented in the main text. This could indicate that the authors explored the effects of different levels of training on the model's ability to generalize.

It is also worth noting that the authors mention that they saved the model after each epoch for later use, this could indicate that they might have used those saved models to evaluate the model's performance on unseen data, which is a way to check the model's ability to generalize.

In conclusion, while the text does not provide explicit information about measures taken to ensure the generalizability of the deep learning model, it does suggest that the authors took some steps to assess the model's ability to generalize, such as training and validating the model on different datasets, exploring different model architectures and levels of training, and saving the model after each epoch for later use.