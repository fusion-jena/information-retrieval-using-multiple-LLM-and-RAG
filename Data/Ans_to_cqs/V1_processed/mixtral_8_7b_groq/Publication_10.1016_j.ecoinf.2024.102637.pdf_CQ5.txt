The datasets used in the deep learning pipeline for the study are Birdsdata and UrbanSound, which are publicly available on Kaggle at <https://www.kaggle.com/datasets/llll00/birdsdata> and <https://www.kaggle.com/datasets/llll00/urbansound8k>. These datasets were used to conduct experiments and demonstrate the significant advantages of the proposed SIAlex model in terms of accuracy and inference time compared to other methods.

The Birdsdata dataset contains bird vocalization sounds, and the UrbanSound dataset contains urban sound recordings. These datasets were used to train and test the SIAlex model, which is a lightweight deep learning model that utilizes AlexNet as the backbone and employs a method of cascading multiple activation functions to improve gradient propagation and nonlinear expression of learning features.

The study compares the performance of the SIAlex model with other methods, such as VGG-16 and ResNet, on these datasets. The experimental data show that the SIAlex network on the Birdsdata dataset improves the accuracy to 93.66%, and the inference time for a single data is only 2.466 ms. The accuracy of the UrbanSound8k dataset reaches 96.04%, and the inference time for a single data is 3.031 ms.

Therefore, the Birdsdata and UrbanSound datasets are the primary datasets used in the deep learning pipeline for this study. These datasets are relevant to the study's focus on sound classification and demonstrate the effectiveness of the proposed SIAlex model in achieving a balance between speed and accuracy while reducing computational complexity and deployment costs.