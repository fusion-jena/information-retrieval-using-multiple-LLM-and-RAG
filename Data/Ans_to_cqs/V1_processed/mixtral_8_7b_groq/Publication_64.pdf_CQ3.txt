The provided context does not give specific details about the data annotation techniques used in the deep learning pipeline. However, it does mention that images are automatically retrieved from the Google Image Search engine for the "Google Search Image" dataset. These images are likely not manually annotated with techniques such as bounding box annotation or instance segmentation, but rather automatically labeled based on the search query.

For the "Portuguese Flora" and "iNaturalist" datasets, the context does not provide information on how the images were obtained or annotated. It is possible that these datasets were manually annotated with more precise annotation techniques, but there is no explicit mention of this in the provided context.

In general, data annotation techniques for deep learning in computer vision tasks can include:

1. Image-level labeling: where each image is assigned a single label corresponding to the object class present in the image.
2. Bounding box annotation: where a bounding box is drawn around each instance of an object in an image.
3. Instance segmentation: where each pixel in an image is assigned a label corresponding to the object it belongs to.
4. Semantic segmentation: where pixels are grouped into regions based on the object they belong to, but the regions do not necessarily correspond to individual object instances.

The choice of data annotation technique depends on the specific task and the level of detail required for the model to make accurate predictions. For plant classification, image-level labeling or bounding box annotation may be sufficient, while instance or semantic segmentation may be required for more complex tasks such as plant part segmentation or disease detection.