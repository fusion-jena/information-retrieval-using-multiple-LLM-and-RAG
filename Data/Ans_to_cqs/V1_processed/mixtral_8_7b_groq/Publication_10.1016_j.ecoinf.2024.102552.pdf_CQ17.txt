The provided context does not include information about the specific regularization methods used to prevent overfitting in the deep learning pipeline. The text discusses the use of machine learning tools for image classification, including the importance of quality inputs for successful classification. However, it does not go into detail about the techniques used to prevent overfitting.

Regularization methods, such as dropout and L2 regularization, are commonly used in deep learning to prevent overfitting by adding a penalty to the loss function, which helps to reduce the complexity of the model and improve its generalization performance. Dropout randomly sets a fraction of the input units to zero during training, which helps to prevent co-adaptation of feature detectors. L2 regularization adds a penalty equal to the square of the magnitude of the model weights to the loss function, which encourages the model to learn smaller weights and avoid overfitting.

In summary, while the provided context discusses the use of machine learning for image classification, it does not mention the specific regularization methods used to prevent overfitting in the deep learning pipeline.