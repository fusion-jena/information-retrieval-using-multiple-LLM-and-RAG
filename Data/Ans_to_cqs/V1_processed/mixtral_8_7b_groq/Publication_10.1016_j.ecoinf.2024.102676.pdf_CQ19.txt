The provided context does not explicitly mention which deep learning frameworks, such as TensorFlow or PyTorch, were used to build the model. However, it does mention the use of "state-of-the-art machine learning" and "imputation techniques" in the context of enhancing endangered species monitoring. It is also noted that OpenAI's ChatGPT was used for spell checking, grammar checking, and debugging in code during the preparation of the work.

It is possible that the authors used one of the popular deep learning frameworks like TensorFlow or PyTorch to implement the machine learning model, but without further information, it is not possible to provide a definitive answer.