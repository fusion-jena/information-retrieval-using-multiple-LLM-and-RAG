The strategies employed to handle randomness in the deep learning pipeline include the use of a fixed random seed value, data augmentation, and dropout.

A fixed random seed value ensures that the same initial weights are used each time a model is trained, allowing for reproducibility of results. This is important for scientific research and model development, as it enables researchers to compare results across different experiments and to build upon previous work.

Data augmentation is a technique used to increase the size of a training dataset by applying random transformations to the existing data. These transformations can include rotations, translations, and flips, and can help to improve the generalization of a model by providing it with a more diverse set of training examples. By randomly transforming the data, a degree of randomness is introduced into the training process, which can help to prevent overfitting and improve the robustness of the model.

Dropout is a regularization technique used in deep learning to prevent overfitting. During training, dropout randomly sets a fraction of the input units to zero, effectively removing them from the network. This forces the network to learn to function without certain inputs, which helps to prevent it from becoming too reliant on any one feature. By introducing randomness into the network in this way, dropout helps to improve the model's ability to generalize to new data.

In addition to these strategies, other techniques such as batch normalization and early stopping can also be used to handle randomness in the deep learning pipeline. Batch normalization normalizes the inputs to each layer of the network, which can help to reduce the impact of random weight initializations. Early stopping involves monitoring the performance of a model on a validation dataset during training, and stopping the training process when the model's performance begins to degrade. This can help to prevent overfitting and improve the model's ability to generalize to new data.

References:
Chalmers, C., Fergus, P., Wich, S., Longmore, S.N., 2021. Modelling animal biodiversity using acoustic monitoring and deep learning. In: ’Proceedings of the 2021 International Joint Conference on Neural Networks (IJCNN), pp. 1–7. https://doi.org/10.1109/IJCNN52387.2021.9534195.

Christie, K.S., Gilbert, S.L., Brown, C.L., Hatfield, M., Hanson, L., 2016. Unmanned aircraft systems in wildlife research: current and future applications of a transformative technology. Front. Ecol. Environ. 14, 241–251. https://doi.org/10.1002/fee.1281.

Civil Aviation Safety Authority, 2019. Advisory Circular AC 101–01 v3.0. Australian Government, Canberra, Australia.

Corcoran, E., Denman, S., Hamilton, G., 2021. Evaluating new technology for biodiversity monitoring: are drone surveys biased? Ecol. Evol. 11, 6649–6656. https://doi.org/10.1111/2041-210X.13581.

Patykowski, J., Cowie, I., Cuff, N., Chong, C., Nano, C., Jobson, P., Lewis, D., 2021. Can sampling for vegetation characterisation surrogate for species richness? Case studies from the wet–dry tropics of northern Australia. Aust. J. Bot. 69, 375–385. https://doi.org/10.1071/BT20158.

Staben, G., Lucieer, A., Scarth, P., 2018. Modelling LiDAR derived tree canopy height from Landsat TM, ETM+ and OLI satellite imagery—a machine learning approach. Int. J. Appl. Earth Obs. Geoinf. 73, 666–681. https://doi.org/10.1016/j.jag.2018.08.013.

Sunbird Images, 2019. Bird Song Id Australia - Automatic Recognition.

Tiwari, G., Pandey, P., Kaul, R., Lee, H., Singh, R., 2021. Comparison of point and roadside transect methods to evaluate the abundance and richness of diurnal raptors in the arid region of Rajasthan. PLoS One 16, e0259805. https://doi.org/10.1371/journal.pone.0259805.

Wilson, R.R., Twedt, D.J., Elliott, A.B., 2000. Comparison of Line Transects and Point Counts for Monitoring Spring Migration in Forested Wetlands (Comparaci´on de Transectos Lineales y de Conteo de Puntos para Monitorear la Migraci´on Primaveral en Bosques Anegados). J. Field Ornithol. 71, 345–355.