The strategy implemented to monitor the model performance during training involves several steps. First, eight different machine learning algorithms were tested to generate predictive models for habitat suitability. These algorithms include Generalized Linear Model (GLM), Support Vector Machine (SVM), Multivariate Adaptive Regression Spline (MARS), Random Forest (RF), Flexible Discriminant Analysis (FDA), Classification and Regression Trees (CART), Generalized Boosting regression Model (GBM), and Maximum-Entropy learning (MAXENT).

To verify the model's validity, 30% of each taxon's data records were utilized as testing data, while the remaining 70% were used as training data. After 10 K-fold cross-validation and 10-fold bootstrapping, all models were assessed based on the mean values for Area Under the Curve AUC (Hanley and McNeil, 1982), True Skill Statistics TSS (Monserud and Leemans, 1992), Cohen's KAPPA (Allouche et al., 2006), point-biserial correlation COR (Elith et al., 2010), and Receiver Operator Characteristics ROC (Hanley and McNeil, 1982). Bootstrapping was used to provide unbiased predictive accuracy with a sufficiently low variance (Harrell et al., 2005; Lima et al., 2019).

For the model threshold, the sensitivity-specificity sum maximization technique was employed (Liu et al., 2005). This evaluation criterion ensures that species distribution can be accurately predicted (Liu et al., 2005). Additionally, the "shiny" packages in RStudio (RStudio Team, 2020) were used to extract model mean performances for AUC, ROC, TSS, KAPPA, and COR values.

Furthermore, the importance and regularized training gain for each variable were calculated. A variable with the highest regularized training gain indicates that this variable has the most useful information on its own when used in isolation. Model sensitivity and accuracy for habitat suitability were also checked with the AUC values. Graphical representation of MAXENT models was produced in QGIS Desktop v 3.24.2 (QGIS Development Team, 2022).

In summary, the strategy to monitor the model performance during training involves using multiple machine learning algorithms, cross-validation, bootstrapping, and various evaluation metrics such as AUC, TSS, KAPPA, COR, and ROC. Additionally, the importance and regularized training gain for each variable were calculated, and graphical representations were produced to visualize the model's performance.