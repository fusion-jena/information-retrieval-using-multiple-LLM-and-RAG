Based on the provided context, there is no explicit information about the specific criterion used to determine when training is complete. However, it can be inferred that the training process involves using data from 2003 to 2020 for training, with the validation data from points A, B, and C being used to assess the effectiveness of the model's structure and hyperparameters.

The table shows the RMSE (Root Mean Square Error) values for different models, solvers, and input time series lengths at points A, B, and C. It appears that the model's performance is being evaluated based on these RMSE values, with the Adam solver and a 5-day input time series length generally resulting in lower RMSE values.

However, the specific condition for stopping the training, such as a validation loss plateau or a certain number of epochs, is not mentioned in the text. Therefore, I cannot provide a definitive answer to this query without additional information.

It is also important to note that the choice of the stopping criterion can depend on various factors, including the specific problem being addressed, the complexity of the model, and the amount of available data. In this case, without more context, it is not possible to determine the exact criterion used to decide when the training should be stopped.