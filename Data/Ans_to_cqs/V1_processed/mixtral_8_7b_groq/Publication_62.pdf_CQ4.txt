Based on the information provided, there is no explicit mention of specific data augmentation techniques such as flipping, rotating, or scaling that were applied in the deep learning pipeline. The tables and text describe the architecture of the convolutional neural networks (CNNs) used in the study, but they do not include details about data augmentation.

However, it is important to note that data augmentation is a common practice in deep learning, particularly in computer vision tasks, to increase the size and variability of the training set. Some of the common data augmentation techniques include:

1. Flipping: Horizontal or vertical flipping of the images to increase the number of training samples and to help the model generalize better.
2. Rotation: Rotating the images by a certain angle to simulate different perspectives.
3. Scaling: Changing the size of the images to make the model more robust to variations in object size.
4. Translation: Shifting the images horizontally or vertically to account for variations in object position.
5. Color jittering: Changing the brightness, contrast, hue, or saturation of the images to increase the model's robustness to lighting and color variations.

Given that the study uses CNNs for image classification, it is highly likely that some form of data augmentation was applied. However, without explicit information in the provided context, it is not possible to answer this query with certainty.

 There is no explicit mention of specific data augmentation techniques such as flipping, rotating, or scaling in the provided context. However, data augmentation is a common practice in deep learning, particularly in computer vision tasks, and it is likely that some form of data augmentation was applied in this study.