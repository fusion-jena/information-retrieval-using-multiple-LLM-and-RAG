Based on the provided context, there are several measures that were taken to ensure the generalizability of the deep learning models, although the specific techniques used are not explicitly mentioned for each reference. Here are some measures that can be inferred:

1. Diverse dataset: Some studies used various types of images from different sources to train their models. For instance, Esteva et al. (2017) used a dataset of over 129,000 clinical images of skin lesions, which were collected from various sources, to train their deep neural network for skin cancer classification. Similarly, Su et al. (2018) used remote sensing images from different regions and seasons to model the habitat suitability of migratory birds.

2. Cross-validation: Cross-validation is a common technique used to assess the performance and generalizability of machine learning models. Although not explicitly mentioned, some studies might have used cross-validation to evaluate their models. For example, Kim et al. (2016) used a validation set to tune the parameters of their very deep convolutional network for image super-resolution.

3. Stratified splitting: Stratified splitting is a technique used to ensure that the training and testing sets have similar distributions of the target variable. This can help improve the generalizability of the model. In the context of remote sensing and image processing, this technique can be used to ensure that the training and testing sets have similar distributions of land cover types, atmospheric conditions, or other relevant factors. However, the provided context does not explicitly mention the use of stratified splitting.

4. Data augmentation: Data augmentation is a technique used to increase the size and diversity of the training dataset by applying various transformations to the existing images. For example, Dodge and Karam (2016) used data augmentation to investigate the effect of image quality on deep neural networks. Similarly, Basaeed et al. (2015) used multi-band fusion and boundary detection techniques to enhance the features of remotely sensed images.

5. Hierarchical training datasets: Some studies used hierarchical training datasets to improve the generalizability of their models. For instance, Yan et al. (2015) used a hierarchical deep convolutional neural network (HD-CNN) for large-scale visual recognition. The HD-CNN consisted of multiple layers of convolutional neural networks, each of which was trained on a different level of image features.

6. Use of multiple spectral bands and temporal information: Some studies used multiple spectral bands and temporal information to improve the generalizability of their models. For example, Fang et al. (2016) used subpixel rendering to increase the image resolution on portable displays. This technique can be useful for remote sensing applications where high-resolution images are required.

In summary, while the provided context does not explicitly mention the use of specific techniques such as cross-validation or stratified splitting, it does suggest that various measures were taken to ensure the generalizability of the deep learning models. These measures include using diverse datasets, data augmentation, hierarchical training datasets, and incorporating multiple spectral bands and temporal information.