The provided context discusses various applications of deep learning in analyzing sound data, such as bird songs and soundscapes, but it does not explicitly mention the optimization techniques used in the deep learning pipelines. However, it can be inferred that popular optimization techniques like Stochastic Gradient Descent (SGD) and Adam might have been used.

In the paper "A survey on deep learning: algorithms, techniques, and applications" by Pouyanfar et al., 2018, the authors provide a comprehensive overview of deep learning algorithms and techniques, including optimization methods. They mention that gradient-based optimization algorithms are commonly used in deep learning, and SGD is the most basic optimization algorithm. However, they do not specify which optimization techniques were used in the studies they reviewed.

In the context of sound data analysis, the paper "Soundscape classification with convolutional neural networks reveals temporal and geographic patterns in ecoacoustic data" by Quinn et al., 2022, mentions that tuning network hyperparameters is an essential optimization step. However, they do not specify which optimization techniques were used.

In the paper "Pre-processing spectrogram parameters improve the accuracy of bioacoustic classification using convolutional neural networks" by Knight et al., 2020, the authors discuss the importance of pre-processing spectrogram parameters to improve the accuracy of bioacoustic classification using CNNs. However, they do not mention the optimization techniques used in their deep learning pipeline.

Therefore, while it can be inferred that optimization techniques like SGD and Adam might have been used in the deep learning pipelines for sound data analysis, the provided context does not explicitly mention which optimization techniques were used.