The performance of the deep learning model is evaluated using four basic classification metrics: accuracy, precision, recall, and F1-score. Accuracy is the ratio of the correctly classified samples to the total number of samples. Precision represents the relationship between the true positive predicted values and all positive predicted values. Recall, also known as sensitivity, is the ratio of the true predictive positive values to the summation of both predicted true positive and predicted false values. F1-score is an overall accuracy measure of the developed classifier that combines the double ratio of both the precision and recall metrics. These metrics are used to quantify the performance of the developed mobile application for recognizing insect pests. A confusion matrix is generated using a cross-validation estimator, which compares the true crop pest labels of tested images and predicted classification results of the Faster R-CNN model. The confusion matrix has four expected outcomes: True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN). These outcomes are used to calculate the evaluation metrics, including accuracy, precision, recall, and F1-score.