The performance of the deep learning models in the given context is evaluated using precision, recall, and F1-score metrics. These metrics are commonly used in machine learning classification tasks, and they provide insights into the model's performance in identifying true positive, false positive, and false negative predictions.

Precision is the ratio of true positive predictions to the total predicted positives. It measures the model's ability to correctly identify positive instances. High precision indicates that the model has a low false positive rate.

Recall, also known as sensitivity, is the ratio of true positive predictions to the total actual positives. It measures the model's ability to find all positive instances. High recall indicates that the model has a low false negative rate.

F1-score is the harmonic mean of precision and recall, providing a single metric that captures both aspects of the model's performance. It ranges from 0 to 1, with higher values indicating better overall performance.

In the given context, the average precision, recall, and F1-score are reported for the ResNet50 and EfficientNetB3 models, which are modified for multitask learning (MTL) and trained with transfer learning using pre-trained weights from ImageNet. The models are trained and validated on the TLm dataset, and the performance metrics are calculated for each taxonomic level (L1, L2, and L3) for both the ResNet50MTL and EfficientNetB3MTL models.

Moreover, Table 7 provides F1-scores for each level in the hierarchy of models trained on three different datasets (GBIFm, TLm, and MIX) and validated on either the TLm or GBIFm validation dataset. This table further demonstrates the use of F1-score as a performance metric for the deep learning models.

In summary, the performance of the deep learning models in the given context is evaluated using precision, recall, and F1-score metrics, which are essential for assessing classification tasks. These metrics help to understand the model's ability to identify true positive, false positive, and false negative predictions, providing insights into the model's overall performance.