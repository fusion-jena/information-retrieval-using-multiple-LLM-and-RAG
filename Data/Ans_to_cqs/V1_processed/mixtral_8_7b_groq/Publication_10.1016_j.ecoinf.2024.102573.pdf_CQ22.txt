The performance of the deep learning models mentioned in the context is evaluated using several metrics. These metrics include accuracy, top-3 accuracy, F1-score, precision, and recall.

Accuracy is a common metric used to evaluate the performance of a model. It measures the proportion of correct predictions out of the total number of predictions made by the model.

Top-3 accuracy is a metric that measures the proportion of times the correct class appears in the top three predicted classes. This metric is useful when the exact class may not be as important as identifying one of the top classes.

The F1-score is the harmonic mean of precision and recall. Precision measures the proportion of true positive predictions out of all positive predictions made by the model. Recall, on the other hand, measures the proportion of true positive predictions out of all actual positive instances in the data. The F1-score provides a balance between precision and recall, giving equal importance to both metrics.

These metrics are used to evaluate the performance of various frontends, including Mel-log-A, Mel-log, Mel-pcen-S, Mel-log-M, and others. The frontends are trained for 100 epochs using the Adam optimizer with a cosine decay scheduler for the learning rate. The loss function used is cross-entropy for multi-class single-label classification. The macro-averaged F1-score on the validation set is used to monitor the model convergence. Macro averaging gives equal importance to all classes regardless of the number of data points in each one.

Therefore, the models are evaluated using a comprehensive set of metrics that provide a holistic view of their performance, including accuracy, top-3 accuracy, F1-score, precision, and recall.