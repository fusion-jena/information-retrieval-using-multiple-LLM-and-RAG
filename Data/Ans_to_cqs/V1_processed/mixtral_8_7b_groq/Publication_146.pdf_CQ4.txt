Based on the provided context, there is no explicit mention of the data augmentation techniques applied in the deep learning pipeline. However, there is a reference to a paper titled "The impact of multi-optimizers and data augmentation on TensorFlow convolutional neural network performance" [18]. This paper investigates the impact of data augmentation on the performance of a TensorFlow convolutional neural network, but it does not specify the exact data augmentation techniques used.

In general, data augmentation techniques commonly used in deep learning include flipping, rotating, scaling, and other transformations such as width and height shifts, shearing, and brightness changes. These techniques are used to increase the size and diversity of the training dataset, thereby improving the model's ability to generalize.

For instance, in the context of object detection in aerial images using convolutional neural networks (CNNs) [20], data augmentation techniques such as random horizontal flipping, random vertical flipping, and random cropping are commonly used. These techniques help to increase the number of training samples, improve the model's robustness to different orientations and scales, and reduce overfitting.

Therefore, while there is no specific information on the data augmentation techniques used in the provided context, it is reasonable to assume that common techniques such as flipping, rotating, and scaling were applied to augment the dataset and improve the model's performance.