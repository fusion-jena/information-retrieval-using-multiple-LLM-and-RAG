Based on the provided context, GPUs are the primary hardware resource used for training deep learning models. The text mentions that the proportion of articles using GPU computing for machine learning tasks has rapidly increased, with 97% of these articles using GPUs for training deep learning models. The most commonly used software tools for these tasks are those that provide accessible extensions to the Python programming language, such as TensorFlow, Keras, and PyTorch, which are designed to work with GPUs.

The context also explains that a GPU streaming multiprocessor (SM) is a collection of cores with fast cache memory shared between them, and a GPU's global memory is a longer block of memory that is accessible by all cores on the GPU. These hardware resources enable GPUs to perform parallel computations that are well-suited for training deep learning models.

Therefore, it can be concluded that GPUs are the primary hardware resource used for training deep learning models.