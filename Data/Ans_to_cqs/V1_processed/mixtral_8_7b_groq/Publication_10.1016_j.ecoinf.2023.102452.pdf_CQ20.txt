The provided pieces of context do not contain specific information about the hardware resources used for training the deep learning models. However, they do mention the use of various software tools and techniques for developing and implementing these models.

For instance, the Eureqa Pro software is used for GP modeling in one of the studies (Althoey et al., 2023; Hu, 2023), and the FORTRAN platform is chosen for its computational capabilities in another study (Quilty & Adamowski, 2018). Additionally, the studies discuss the use of neural networks (Turing, 1948; Dehghani et al., 2023), Gaussian regression (Uncuoglu et al., 2022), support vector machines (Uncuoglu et al., 2022), long short-term memory (Uncuoglu et al., 2022; Dehghani et al., 2023), multi-gene genetic programming (Uncuoglu et al., 2022), M5 trees (Uncuoglu et al., 2022), and wavelet network models (Wang & Ding, 2003).

However, the context does not specify whether these models were trained on CPUs, GPUs, TPUs, or other hardware resources. Therefore, it is not possible to provide a definitive answer to the query based on the given information.