The context provided does not explicitly mention the specific criteria used to determine when training is complete for the deep-learning models. However, it does mention that the number of epochs until convergence varies between models. Specifically, it notes that the EfficientNetB3 model converges at the fourth epoch.

In general, training of deep-learning models can be considered complete when the validation loss plateaus or starts to increase, or when the model begins to overfit. These are common criteria used to prevent overfitting and ensure that the model generalizes well to unseen data.

The context also mentions that the authors measure the accuracy of the deep-learning models using various metrics, including accuracy, precision, and recall. While these metrics are useful for evaluating the performance of the models, they do not directly indicate when training should be stopped.

Therefore, while the context provides some insight into the training process and the performance of the models, it does not explicitly answer the query regarding the criteria used to determine when training is complete.