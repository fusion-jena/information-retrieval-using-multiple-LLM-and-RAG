Based on the provided context, there is no explicit information given about the process followed to deploy the trained deep learning model. However, there are some implicit details that can help us infer a part of the deployment process.

Firstly, it is mentioned that the model is built using a proposed MIF block (Mixed-scale Interaction Block) which needs to be trained from scratch. This suggests that the model training and serialization process might involve saving the trained model's weights and architecture to a file, which can be later loaded for inference.

Secondly, there is a comparison of total training time, average inference time, model parameters, and FLOPs (Floating Point Operations Per Second) between TrunkNet and other 10 SOTAs (State-Of-The-Art models). This implies that the authors might have tested the model's performance on a specific platform or framework, which is capable of providing these metrics.

Therefore, we can infer that the deployment process might have involved:

1. Training the model from scratch using the proposed MIF block and saving the trained model's weights and architecture to a file (model serialization).
2. Testing the model's performance on a specific platform or framework for inference, which can provide metrics like average inference time, model parameters, and FLOPs.

However, the context does not provide information about other crucial steps in the deployment process, such as platform selection, model optimization for the target platform, and integration with other systems or services.

 The provided context does not give explicit information about the process followed to deploy the trained deep learning model. However, based on the implicit details, we can infer that the process might have involved training the model from scratch using the proposed MIF block, saving the trained model's weights and architecture, and testing the model's performance on a specific platform or framework for inference. Crucial steps like platform selection, model optimization, and integration with other systems or services are not mentioned in the context.