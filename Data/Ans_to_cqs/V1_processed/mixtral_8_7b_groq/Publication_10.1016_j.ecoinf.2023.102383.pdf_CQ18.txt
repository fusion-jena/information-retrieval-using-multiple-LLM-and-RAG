Based on the provided context, there is no explicit strategy mentioned for monitoring the model's performance during training. However, there are several strategies discussed that can be inferred as aiding in the monitoring of performance indirectly.

One such strategy is the use of hard negative mining. This technique involves focusing on challenging negative examples during the training process. By selectively mining hard negative examples, the model can learn to better distinguish between objects and background regions. This process can be seen as a way of monitoring performance, as the model's ability to handle difficult negative examples implies that it is learning effectively.

Another strategy mentioned is the trade-off between detection accuracy and performance. This is achieved by dedicating more time for training and detection, while reducing the number of parameters by selecting small feature maps. This results in faster detection speed. By adjusting these parameters, the model's performance can be monitored and optimized accordingly.

However, it is important to note that these strategies do not directly address the query of monitoring the model's performance during training. To answer this query more accurately, additional context would be required, such as the use of validation sets, early stopping, or learning rate schedules.

In conclusion, while the provided context does not explicitly mention a strategy for monitoring the model's performance during training, there are strategies discussed that can indirectly aid in this process. These include hard negative mining and adjusting the trade-off between detection accuracy and performance. However, further context would be needed to provide a more direct answer to the query.