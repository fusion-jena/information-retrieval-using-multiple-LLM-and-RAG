The performance of the deep learning model is evaluated using several metrics, including accuracy, precision, recall, and F1 score. 

Accuracy is calculated as the number of correct predictions divided by the total number of images. It provides a general understanding of how well the model is performing. However, it may not be a reliable metric when the classes are imbalanced, as it can overestimate the performance for rare classes and underestimate it for abundant classes.

Precision, also known as positive predictive value, is the ratio of true positives (correctly predicted instances of a class) to the sum of true positives and false positives (incorrectly predicted instances of a class). It measures the proportion of correct positive predictions out of all positive predictions made by the model.

Recall, also known as sensitivity, is the ratio of true positives to the sum of true positives and false negatives (instances that belong to a class but were not predicted as such). It measures the proportion of correctly predicted instances out of all instances that belong to a class.

The F1 score is the harmonic mean of precision and recall, providing a single metric that captures both. It is calculated as 2*(precision*recall) / (precision + recall).

These metrics are calculated for each class in the model, allowing for a more detailed evaluation of the model's performance. This is particularly useful in the context of the given study, where the classes are imbalanced and the model is used to identify specific animal species.