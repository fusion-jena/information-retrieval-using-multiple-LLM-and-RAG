Based on the provided context, the data annotation techniques used in the deep learning pipeline are not explicitly stated. However, we can infer that the annotation process involved identifying and marking specific fish species within images.

The criteria for annotation include annotating a fish only if there is no more than 10% of its surface covered by another object, annotating a fish only if it can be identified at the species level in the frame, annotating a fish only if its apparent size is larger than 3000 squared pixels, and annotating images from different habitats and depths to represent a broad range of light conditions and environment. These criteria suggest that the annotation process was focused on precise identification and marking of individual fish instances within the images.

Additionally, the use of a deep convolutional neural network (CNN) architecture, specifically GoogLeNet, indicates that the annotations were likely used for training the network to identify and classify fish species within images. CNNs are commonly used for object detection and image classification tasks, and they typically require annotated data for training.

However, the specific annotation technique used, such as bounding box annotation or instance segmentation, is not mentioned in the provided context. Bounding box annotation involves drawing a box around the object of interest, while instance segmentation involves precisely segmenting the object from the background and other objects in the image. Both techniques could be used for annotating fish in images, but the context does not provide enough information to determine which technique was used.

Therefore, while we can infer that some form of image annotation was used in the deep learning pipeline, the specific annotation technique is not specified in the provided context.