Based on the provided context, there is no explicit information about the process followed to deploy a trained deep learning model, such as model serialization or platform selection. However, we can infer that the researchers developed a methodology for discriminant analysis of species and sex using Fisher's linear discriminant analysis. They collected and curated data, specifically marten and fisher tracks, and divided the dataset into training, validation, and test groups. After processing the data, they conducted discriminant analysis for species and sex discrimination.

Though the text does not mention deep learning models explicitly, it is possible that they used deep learning techniques as part of their data processing or feature extraction. If they did use deep learning, they might have followed common deployment processes such as:

1. Model serialization: Once the deep learning model was trained and validated, they could have saved the model's architecture, weights, and biases to a file for later use. This allows for easier deployment and sharing of the model.
2. Platform selection: Depending on the intended application, the researchers might have chosen a specific platform or hardware for deploying the model. For instance, they could have deployed the model on a local machine for offline analysis or on a cloud platform for real-time predictions.

However, these are assumptions based on general practices in deep learning model deployment. The provided context does not contain specific details about these steps.