The text provided does not give a detailed explanation of the strategies used to handle randomness in the deep learning pipeline. However, it does mention the use of Convolutional Neural Networks (CNNs) and an ensemble approach, which can be used to manage randomness.

In deep learning, randomness can be introduced in various ways, such as the initialization of weights, the order of training samples, and the use of dropout regularization. To manage this randomness, researchers can set a random seed value to ensure reproducibility of results. However, the text does not explicitly mention the use of a random seed value.

The text does mention the use of CNNs, which are a type of deep learning model commonly used in image recognition tasks. CNNs typically consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The parameters of these layers are learned from the training data, and randomness can be introduced during the training process. To manage this randomness, techniques such as batch normalization and dropout regularization can be used.

The text also mentions the use of an ensemble approach, in which multiple models are trained and their predictions are averaged. This approach can help reduce the impact of randomness on the final predictions, as the averaging of multiple models can help smooth out the variations introduced by randomness.

In summary, while the text does not explicitly mention the use of a random seed value to manage randomness in the deep learning pipeline, it does mention the use of CNNs and an ensemble approach, which can be used to manage randomness.