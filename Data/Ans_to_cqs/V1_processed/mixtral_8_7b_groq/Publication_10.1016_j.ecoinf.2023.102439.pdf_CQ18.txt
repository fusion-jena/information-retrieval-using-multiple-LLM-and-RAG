The strategy implemented to monitor the model performance during training involves the use of several statistical metrics. These metrics include the Mean Absolute Percent Error (MAPE), Mean Square Error (MSE), Root Mean Square Error (RMSE), and correlation coefficient (R). These metrics are employed to assess the accuracy and predictive capability of the model by measuring the deviation between the predicted EVI values and the actual observed values. 

Specifically, the MSE and R values are used to evaluate the performance of the Artificial Neural Network (ANN) model during the training phase. The MSE measures the average squared difference between the predicted and actual values, while the R value, which ranges from -1 to 1, indicates the strength and direction of the linear relationship between the predicted and actual values. A higher R value indicates a stronger correlation, and thus, better model performance.

Moreover, the model's performance is also monitored by comparing the MSE and R values for different numbers of neurons in the hidden layer. This comparison helps determine the optimal configuration that yields the best results. Insufficient neurons may hinder successful learning, while excessive neurons may lead to overfitting and compromise the network's performance.

Finally, the model's performance is further evaluated using a separate dataset reserved for testing and validation purposes. This dataset, which comprises 40% of the total data, is used to assess the model's performance on unseen data and ensure that the model can generalize well to new observations. This data partitioning strategy, which results in a distribution of 60% for training and 40% for validation and testing, provides a robust method for monitoring the model's performance during training.