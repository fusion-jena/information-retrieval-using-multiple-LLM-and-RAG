The pieces of context provided do not give specific information about the criteria used to determine when training is complete in the study. However, they do mention that both training scores and validation scores were examined to diagnose signs of overfitting.

The training scores were calculated from models fit on all 7331 grid cells, and their outputs for the area shown in Fig. 1a were compared to their true labels to compute the values. The validation scores of the models were calculated through a 10-fold cross-validation (CV) using one fold pattern of spatial-CV feature selection, shown in Fig. 2. The scores are the average of the 10 validation folds.

It is common practice in machine learning to use validation loss plateau as a criterion for determining when training is complete. This means that training is stopped when the validation loss stops decreasing, even if the training loss continues to decrease. This helps to prevent overfitting, which occurs when the model performs well on the training data but poorly on new, unseen data.

However, the pieces of context provided do not mention specifically if this criterion was used in the study. Therefore, it is not possible to give a definitive answer to the query based on the provided information.