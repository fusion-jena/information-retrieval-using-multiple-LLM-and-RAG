The provided context discusses various techniques used in deep learning for training models and increasing their performance, such as data augmentation and feature engineering. However, it does not explicitly mention the techniques used to address data bias during the preprocessing of the deep learning pipeline. Therefore, I will provide a general overview of some common techniques used to address data bias:

1. Stratified sampling: Stratified sampling is a method of sampling that ensures each stratum (a subset of the population sharing similar characteristics) is proportionally represented in the sample. This technique can help ensure that the training and testing datasets have a similar distribution of classes, reducing bias.
2. Oversampling: Oversampling is a technique used to increase the number of instances from the minority class in the dataset. This can help the model learn more about the minority class, reducing bias. However, oversampling can lead to overfitting if not done carefully.
3. Undersampling: Undersampling is a technique used to decrease the number of instances from the majority class in the dataset. This can help balance the dataset and reduce bias. However, undersampling can lead to loss of information if not done carefully.
4. Diverse data collection: Collecting data from various sources and ensuring that the dataset is diverse can help reduce bias. This can include collecting data from different geographical locations, different demographic groups, and different time periods.
5. Data augmentation: Data augmentation can help increase the size and variability of the dataset, which can help reduce bias. Techniques such as random cropping, horizontal/vertical flipping, image rotation, image translation, zooming, brightness adjustment, contrast adjustment, hue and saturation adjustment, and Gaussian noise can be used to augment the dataset.

While the provided context does not explicitly mention these techniques, it does mention the use of data augmentation, which can help reduce bias by increasing the size and variability of the dataset. However, it does not mention the use of stratified sampling, oversampling, undersampling, or diverse data collection.