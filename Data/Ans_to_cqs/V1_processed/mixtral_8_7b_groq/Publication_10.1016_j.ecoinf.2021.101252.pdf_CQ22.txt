The performance of the deep learning models in the case studies is evaluated using two metrics: accuracy and area under the receiver operating characteristic curve (AUC).

Accuracy is calculated as the proportion of correctly classified cases out of the total number of cases. For example, in Case Study 1, the ResNet model has an accuracy of 0.91, which means it correctly classified 91% of the cases. This metric is used to evaluate the performance of the candidate models in each case study.

On the other hand, AUC is used to evaluate the performance of the selected model in each case study. AUC measures the model's ability to distinguish between positive and negative classes. It ranges from 0 to 1, where a value closer to 1 indicates better performance. For instance, in Case Study 1, the AUC of the selected model is 0.91, indicating that the model is excellent at distinguishing between positive and negative classes.

It is worth noting that the AUC metric is preferred over accuracy in imbalanced datasets, where one class has significantly more instances than the other. In such cases, accuracy can be misleading, as a classifier can achieve high accuracy by always predicting the majority class. Therefore, AUC is a more reliable metric for evaluating the performance of deep learning models in imbalanced datasets.

In summary, accuracy and AUC are the two metrics used to evaluate the performance of deep learning models in the case studies. Accuracy is used to evaluate the performance of the candidate models, while AUC is used to evaluate the performance of the selected model. These metrics provide insights into the models' ability to classify cases and distinguish between positive and negative classes, respectively.