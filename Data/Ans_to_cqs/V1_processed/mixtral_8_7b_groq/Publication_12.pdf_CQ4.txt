Based on the provided context, there is no explicit mention of data augmentation techniques such as flipping, rotating, or scaling in the described deep learning pipeline for Waveman. The text focuses on the modifications made to BatNet, specifically the addition of BNorm layers and shortcuts to prevent overfitting and information loss, as well as the optimization of parameter settings such as batch size.

However, there are two indirect mentions of data manipulation techniques that could be interpreted as data augmentation:

1. Resizing images: The size of the input images was reduced from 256x256 pixels to 64x64 pixels to save training time and reduce high memory graphics use. Although this is primarily done for computational efficiency, it can also be seen as a form of data augmentation since it alters the original data.
2. Exponential rescaling and window shifting for rare species: To ensure that rare species with small image numbers are not under-represented and under-classified, the authors developed a method to increase the number of images for these species. This involved rescaling signals exponentially and shifting the window slightly either side of the call to change background noise. While this is primarily done to balance the dataset, it can also be seen as a data augmentation technique.

In summary, while the text does not explicitly mention common data augmentation techniques like flipping, rotating, or scaling, it does describe two data manipulation techniques that could be interpreted as data augmentation: resizing images and applying exponential rescaling and window shifting for rare species.