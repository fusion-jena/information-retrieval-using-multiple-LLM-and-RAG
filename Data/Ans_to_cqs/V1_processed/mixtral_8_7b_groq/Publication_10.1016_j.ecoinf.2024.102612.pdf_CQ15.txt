Based on the provided context, there is no explicit mention of any optimization techniques such as Stochastic Gradient Descent (SGD), Adam, or others that are applied in the deep learning pipeline. The text focuses on the evaluation metrics used for the model, such as Mean Accuracy (MA), Intersection over Union (IoU), and their mean counterparts MIoU and MA, which are used to assess the model's performance on imbalanced data.

The training process of the SoftGroup architecture over 1000 epochs is discussed, and metrics such as MIoU or MA are computed after each epoch to analyze the training performance. However, the specific optimization techniques used during the training process are not mentioned.

The text does mention that the deep learning model uses convolutional layers and filters, and different variations of the model are trained using input point clouds with different kernel configurations. However, it does not specify if any optimization techniques are applied during the training process of these variations.

Therefore, based on the provided context, it is not possible to answer the query regarding the optimization techniques applied in the deep learning pipeline.