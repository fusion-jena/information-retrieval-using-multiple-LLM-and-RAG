Based on the provided context, there is no explicit information given about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it is mentioned that the synthetic connectivity data was generated using a Generative Adversarial Network (GAN) model. In the context of GANs, the synthetic data is typically generated by the generator component of the model, while the discriminator component is trained on both the synthetic and original data. This process continues until the discriminator can no longer distinguish between the synthetic and original data, indicating that the synthetic data successfully represents the original data.

However, in the case of the decision support tool mentioned in the context, small differences in initial coral cover, DHW data, and connectivity can have a significant impact on the ecological model's output trajectory. Therefore, it is important to evaluate the performance of the model on unseen data, which is typically done by splitting the data into training, testing, and validation sets.

In general, the data is split into three sets: training, testing, and validation. The training set is used to train the model, the testing set is used to evaluate the model's performance on unseen data, and the validation set is used to fine-tune the model's hyperparameters. The most common way to split the data is to use 60% for training, 20% for testing, and 20% for validation. However, the optimal split can depend on the size and complexity of the data.

Therefore, while the context does not provide specific information on how the data is split for the deep learning model training, it is common practice to split the data into training, testing, and validation sets in order to evaluate the model's performance on unseen data.