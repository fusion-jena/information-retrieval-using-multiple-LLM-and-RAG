The deep learning models used in the pipeline are Convolutional Neural Networks (CNNs) and Transformers. 

The CNNs used include ResNet-50 and Inception-V3. ResNet-50 is a model that uses skip connections, which made it possible to train deeper models than was previously possible. This model was chosen for comparison as it is a well-performing baseline in computer vision classification tasks. Inception-V3 is another CNN used, which has an auxiliary classifier that acts as a regularizer. This model is built on previous Inception models with the aim of making it computationally efficient.

The Transformer model used is the Vision Transformer (ViT). This model was applied successfully in few-shot learning and image classification tasks. The Transformer architecture uses an attention mechanism, allowing it to outperform state-of-the-art models in NLP tasks without using recurrence in the model architecture. Dosovitskiy et al., 2023 showed that convolutions are not necessary for state-of-the-art performance in image classification tasks, and that transformers can perform well on these tasks when applied to image patches.

In summary, the pipeline uses a combination of CNNs and Transformer models for image classification tasks.