The context provided does not give specific information about the datasets used in the deep learning pipeline. It mentions the use of custom CNN architectures and transfer learning, but it does not specify which datasets were used for training these models.

In general, when training deep learning models, researchers often use publicly available datasets such as MNIST, CIFAR, and ImageNet. These datasets are widely used and well-established in the machine learning community, and they provide a standardized way to evaluate and compare the performance of different models.

The MNIST dataset, for example, consists of 60,000 training images and 10,000 test images of handwritten digits, and it is commonly used for training image classification models. The CIFAR-10 dataset, on the other hand, consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The ImageNet dataset is a large-scale dataset of over 1 million images, with 1000 classes. It is often used for training large, complex models such as ResNet and Inception.

Without more information from the context, it is not possible to say for certain which datasets were used in this particular deep learning pipeline. However, based on the general practices in the field, it is likely that one or more of these commonly used datasets were used for training the models.