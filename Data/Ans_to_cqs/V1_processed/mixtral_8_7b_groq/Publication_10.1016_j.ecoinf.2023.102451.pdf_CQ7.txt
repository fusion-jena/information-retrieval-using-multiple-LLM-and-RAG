The context provided does not give specific details about the criteria used to split the data into training, validation, and test sets for the deep learning models. However, it is common practice in machine learning and deep learning to split the data into these three sets to evaluate the performance of the models effectively.

Typically, the data is split into three subsets: training, validation, and test. The training set is used to train the model, the validation set is used to fine-tune the model's hyperparameters and select the best model, and the test set is used to evaluate the final model's performance.

The exact proportions for splitting the data can vary depending on the size of the dataset and the specific requirements of the problem. However, a common split is to use 60-70% of the data for training, 10-15% for validation, and 15-20% for testing.

In the context provided, the performance of various deep learning models, including the proposed EMViT-Net, is evaluated on the validation and test sets of the EMDS-6 dataset. The models are trained on an unspecified training set, and their performance is compared based on their validation and test accuracy.

Therefore, while the context does not provide specific details about the criteria used to split the data, it is clear that the data is split into training, validation, and test sets, and the models' performance is evaluated on the validation and test sets.