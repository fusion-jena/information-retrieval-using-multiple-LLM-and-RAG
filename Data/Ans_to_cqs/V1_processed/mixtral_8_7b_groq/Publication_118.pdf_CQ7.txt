The provided context does not give specific details about how the data was split for training the deep learning model. However, it is common practice in machine learning to split the data into three sets: training, validation, and testing.

The training set is used to train the model, i.e., to adjust the model's parameters to minimize the error on the training data. The validation set is used during the training process to tune hyperparameters and prevent overfitting. Overfitting occurs when the model learns the training data too well, including its noise and outliers, and performs poorly on new, unseen data. The testing set is used to evaluate the final model's performance on new data.

The exact proportion of data allocated to each set depends on the size of the dataset and the specific requirements of the problem. A common split is 60-20-20, where 60% of the data is used for training, 20% for validation, and 20% for testing. However, other splits, such as 70-15-15 or 80-10-10, can also be used.

In the context provided, it can be inferred that the authors used a portion of their highly annotated dataset for training the auto-encoder and evaluating its performance. They mention that the extensive annotation of the dataset allowed for easy evaluation of the feature representation produced by the auto-encoder and training on a higher proportion of non-silent audio clips. However, the exact split of the data is not specified.

In summary, while the provided context does not give specific details about how the data was split for training the deep learning model, it is common practice to split the data into training, validation, and testing sets. The exact proportion of data allocated to each set depends on the size of the dataset and the specific requirements of the problem.