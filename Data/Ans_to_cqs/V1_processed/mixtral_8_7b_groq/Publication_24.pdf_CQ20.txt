The provided context does not explicitly mention the specific hardware resources used for training the deep learning model. However, it can be inferred that the model was likely trained using a GPU (Graphics Processing Unit) or a similar type of accelerator, due to the complexity and computational requirements of deep learning models. This is suggested by the use of Theano and Lasagne libraries for developing the machine learning pipeline, as these libraries can take advantage of GPU acceleration for computations. Additionally, the use of librosa library for audio processing indicates that the training was performed on a high-performance computing system, as audio processing can be computationally intensive. However, without explicit information, it is not possible to give a definitive answer.