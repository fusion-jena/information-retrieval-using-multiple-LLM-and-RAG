The pieces of context provided do not explicitly mention the data formats used in the deep learning pipeline. However, they do indicate that the models are used for object counting in images, specifically for satellite-synthetic large landscapes (SSLs) and elephants. Therefore, it can be inferred that the input data is in the image format.

In the paper "Training Deep Learning Models via Synthetic Data: Application in Unmanned Aerial Vehicles" (Kamilaris et al., 2019), the authors use synthetic data generated by a game engine for training deep learning models. These data are used for object detection and semantic segmentation tasks in unmanned aerial vehicle (UAV) images. The paper does not explicitly mention the format of the synthetic data, but it is likely that the data are provided as image files.

In the paper "Counting Objects by Density Estimation: A Multi-task Learning Approach" (Laradji et al., 2020), the authors use two datasets for training and testing their deep learning models. The first dataset, SSLs, consists of satellite images of size 1024 × 1024 pixels. The second dataset, elephants, consists of images of size 1280 × 1280 pixels. These image data are used for object counting tasks using density estimation techniques.

In the paper "Animal detection in huge air-view images using CNN-based sliding window" (Yoon, 2018), the author uses aerial images of size 1280 × 1280 pixels for object detection tasks using a CNN-based sliding window approach.

Therefore, it can be concluded that the deep learning pipeline in the context provided uses image data as input. However, the pieces of context do not provide information on whether other data formats, such as audio, video, or CSV, are used in the pipeline.