The data for deep learning model training is split into training and testing images with a ratio of 80 : 20. For the SSLs’ data set, the first 800 images are used for training, and the remaining 148 are used as test images to evaluate the model’s performance. For the elephants’ data set, 1649 images are used for training, while 452 images are used for testing.

The context does not mention the use of a validation set explicitly. However, it is mentioned that the early stopping technique was applied based on the model’s performance on the validation set. This implies that a validation set was created, but the specific criteria for its creation are not provided.

In general, the purpose of splitting data into training, validation, and test sets is to ensure that the model can generalize well to unseen data. The training set is used to train the model, the validation set is used to tune hyperparameters and prevent overfitting, and the test set is used to evaluate the model's performance.

Another common practice in data splitting is cross-validation, where the data is split into k folds, and the model is trained and validated k times, each time with a different fold as the validation set. This approach can provide a more reliable estimate of the model's performance and reduce the risk of overfitting.

In summary, while the specific criteria for splitting the data in this case are not provided, the general principles of data splitting for deep learning model training involve creating separate sets for training, validation, and testing to ensure that the model can generalize well to unseen data.