The strategy implemented to monitor the model performance during training involves the use of an early stopping criterion controlled by the Mean Squared Error (MSE). This approach is based on a 10-fold Cross Validation technique to ensure a reliable estimate of the MSE on the test set. Given the probabilistic nature of the models, each evaluation predicts the output per test point through 1000 runs. This method guarantees a robust estimation process with a 95% confidence interval and a precision level of 5%, as suggested by Ghosh et al., 2006.

In addition, the training process incorporates a BBCH scale relabeling strategy that considers only the unique values. This method leads to a significant improvement in the network's performance in terms of MSE. The rationale behind this could be that the BBCH values do not have a numerical meaning; instead, it is the succession of the single values that is relevant. Therefore, preserving the order among the phenological phases is sufficient to obtain a model with good performance.

The performance of the model is further evaluated during the prediction phase on the whole test set, as depicted in Figure 6. The two different architectures' performance is compared, but the specifics of these architectures are not provided in the context.

References:
Dagar, R., Som, S., Khatri, S.K., 2018. Smart farming–IoT in agriculture, pp. 1052–1056.
Dash, T., Chitlangia, S., Ahuja, A., Srinivasan, A., 2022. A review of some techniques for inclusion of domain-knowledge into deep neural networks. Sci. Rep. 12 (1), 1040.
de Wit, A., Boogaard, H., Fumagalli, D., Janssen, S., Knapen, R., van Kraalingen, D., Supit, I., van der Wijngaart, R., van Diepen, K., 2019. 25 years of the WOFOST cropping systems model. Agric. Syst. 168, 154–167.
Dias, A.B., Peça, J., Pinheiro, A., 2012. Long-term evaluation of the influence of mechanical pruning on olive growing. Agron. J. 104 (1), 22–25.
Duerr, O., Sick, B., Murina, E., 2020. Probabilistic Deep Learning: With Python, Keras and TensorFlow Probability. Manning Publications.
Farquhar, S., Smith, L., Gal, Y., 2020. Liberty or depth: Deep Bayesian neural nets do not need complex weight posterior approximations. arXiv e-prints. arXiv–2002.
Abadi, M., et al., 2015. TensorFlow: large-scale machine learning on heterogeneous systems. URL. https://www.tensorflow.org/.
Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D., Liu, L., Ghavamzadeh, M., Fieguth, P., Cao, X., Khosravi, A., Acharya, U.R., et al., 2021. A review of uncertainty quantification in deep learning: techniques, applications and challenges. Inform. Fus. 76, 243–297.
Ghosh, S., et al., 2006. Evaluation of statistical methods for prediction interval estimation: An empirical study. Journal of Statistical Computation and Simulation, 76(12), 1129-1144.