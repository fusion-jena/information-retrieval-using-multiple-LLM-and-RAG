Based on the provided context, there is no explicit information given about the specific criteria used to determine when training is complete in the DeepMeerkat project. However, it is mentioned that the model was trained on a test dataset consisting of 70 videos, and the training of new layers was completed in 27 minutes on a single CPU.

In general, when training a neural network, it is common to monitor the performance on a validation dataset that is separate from the training dataset. The training process is typically considered complete when the performance on the validation dataset stops improving or starts getting worse, even if the performance on the training dataset continues to improve. This is often referred to as early stopping.

Another common criterion for determining when training is complete is when the validation loss plateaus or converges to a minimum value. This indicates that the model has learned the underlying patterns in the data and further training is unlikely to improve the performance.

In the context of the DeepMeerkat project, it is possible that the training was determined to be complete based on one or both of these criteria. However, without more specific information, it is not possible to provide a definitive answer.

It is also worth noting that the training duration for the new layers was relatively short (27 minutes), which suggests that the model may have been trained for a fixed number of iterations or epochs rather than using a more adaptive stopping criterion.

Overall, while the specific criteria used to determine when training is complete in the DeepMeerkat project are not provided in the given context, it is common practice in neural network training to monitor the performance on a validation dataset and use early stopping or convergence of the validation loss as criteria for determining when training is complete.