Based on the provided context, it is not explicitly stated which measures were taken to ensure the generalizability of the deep learning model. However, there are some indications that suggest certain techniques may have been used.

Firstly, the training set included images of 21 different individuals, each having 4 different images. This suggests some degree of diversity in the dataset, as it includes images of different people. However, it is not clear if the images vary sufficiently in terms of other factors such as lighting, pose, and image quality.

Secondly, the test set included 99 other labeled images of the individuals that appeared in the training set. The test and training sets varied in terms of pose and other image characteristics. This suggests that some form of data splitting was used, although it is not explicitly stated whether it was cross-validation or stratified splitting.

Thirdly, the authors mention that they examined two Siamese architectures based on the work of Koch et al. (2015), which suggests that some form of model selection or validation was carried out.

Finally, the authors discuss the use of Contrastive Loss (CoL) as a loss function, which is a form of regularization that can help improve the generalizability of a model.

In summary, while the context does not provide explicit information on the measures taken to ensure the generalizability of the deep learning model, there are some indications that suggest techniques such as diverse dataset, data splitting, model selection, and regularization may have been used. However, without further information, it is not possible to give a definitive answer.