Based on the provided context, there is no explicit information about the specific postprocessing steps taken after model training. However, it does mention that they computed the top-k accuracy on a test set to assess the efficacy of the techniques, where k = 1, 5, and 10. This implies that they calculated the accuracy of the model's predictions by checking if the correct match was within the top k positions of the predicted list.

Additionally, the context mentions that they tuned the number of required epochs and inspected the model outputs and error outcomes for signs of overfitting. This suggests that they may have used techniques such as monitoring the model's performance on a validation set during training, or calculating metrics such as precision, recall, or F1 score.

However, there is no mention of other postprocessing techniques such as generating saliency maps or creating confusion matrices. Therefore, based on the provided context, it is not possible to provide a comprehensive answer to the query.