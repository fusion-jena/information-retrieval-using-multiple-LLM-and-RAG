The provided context does not give detailed information on the process followed to deploy the trained deep learning model. However, it does mention that the authors implemented a deep learning technique for fish biomass estimation.

In general, the process of deploying a trained deep learning model involves several steps. After training the model, the model is typically saved or serialized to disk so that it can be loaded and used in other applications. This is often done using model serialization libraries or frameworks provided by the deep learning library or platform used for training.

Once the model is serialized, it can be deployed on a suitable platform for serving predictions. The choice of platform depends on various factors such as the expected volume of predictions, the required latency, and the available resources. Common deployment platforms for deep learning models include cloud-based services, on-premises servers, and edge devices.

To deploy the model on a cloud-based service, the serialized model is typically uploaded to the cloud platform, and an API endpoint is created to serve predictions. The API endpoint can then be called from other applications to obtain predictions.

For on-premises servers or edge devices, the serialized model can be loaded and run on the target platform. This may involve installing the necessary dependencies and configuring the platform to serve predictions.

In the case of the fish biomass estimation model, the context does not provide enough information to determine the specific steps taken for model deployment. However, it is mentioned that the system is fully automatic, which suggests that the model is deployed on a suitable platform that can serve predictions without manual intervention.