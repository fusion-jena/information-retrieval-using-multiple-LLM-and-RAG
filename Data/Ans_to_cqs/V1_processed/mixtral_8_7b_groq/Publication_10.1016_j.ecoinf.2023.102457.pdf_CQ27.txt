The pieces of context provided do not give detailed information on the process followed to deploy the trained deep learning model. However, they do offer some insights into the pre-training and customization of the BirdNET model for the specific task of gibbon vocalization analysis.

First, the researchers used the BirdNET model, which was pre-trained on a large dataset of bird and non-bird sounds from eBird, Xeno-canto, and the Macaulay Library of Natural Sounds. BirdNET is a task-specific model based on the ResNet family of residual networks, with 157 layers and over 27 million parameters. It is capable of identifying 984 North American and European bird species by sound.

Next, the researchers customized the BirdNET model for their specific task by using a dataset of gibbon vocalizations. They took the mean and standard deviation for embeddings over the entire duration of the call, resulting in a feature vector. This customization process likely involved modifying the pre-trained model's architecture, adjusting hyperparameters, and fine-tuning the model on the gibbon vocalization dataset.

As for the deployment process, the context does not provide specific details. However, it can be inferred that the researchers used Python version 3.10 and the code from the BirdNET-Analyzer GitHub repository for their work. Model serialization, platform selection, and other deployment-related steps might have been carried out using standard deep learning libraries and tools, such as TensorFlow or PyTorch, and cloud-based platforms, such as Google Cloud or AWS.

In summary, while the provided context does not offer detailed information on the deployment process, it does indicate that the researchers used the pre-trained BirdNET model, customized it for gibbon vocalization analysis, and likely used standard deep learning libraries and tools for deployment.


The provided context does not offer detailed information on the process followed to deploy the trained deep learning model. However, it can be inferred that the researchers used the pre-trained BirdNET model, customized it for gibbon vocalization analysis, and likely used standard deep learning libraries and tools for deployment, such as TensorFlow or PyTorch, and cloud-based platforms, such as Google Cloud or AWS.