The provided context discusses the training of deep learning models for a specific application in remote sensing, but it does not explicitly mention preprocessing steps like normalization, scaling, or cleaning. However, it is common practice to perform such preprocessing on the data before training deep learning models.

In the context of this problem, the input data consists of optical images and Synthetic Aperture Radar (SAR) images, along with a Norway-wide timber volume map. Before feeding this data into the model, some preprocessing steps could have been applied, such as:

1. **Normalization**: To make sure that all features have a similar scale and range, it is common to normalize the data. This can be done by subtracting the mean and dividing by the standard deviation for each feature. In this case, this step could be applied to both the optical and SAR images, as well as the timber volume map.

2. **Scaling**: Another way to ensure that all features have a similar scale is by scaling them to a specific range, often between 0 and 1. This can be done by using the minimum and maximum values of each feature. Again, this step could be applied to all input data.

3. **Cleaning**: The context mentions that only forested areas are considered for training. Therefore, a cleaning step might involve removing non-forested areas from the input data. This could be done by applying a mask based on the timber volume map and the Dz threshold mentioned in the context.

4. **Data augmentation**: Although not explicitly mentioned as a preprocessing step, data augmentation is a common technique used during training to increase the size and variability of the training set. In this case, data augmentation could involve applying random transformations to the input data, such as rotations, translations, or flips.

While the context does not explicitly mention these preprocessing steps, it is likely that some or all of them were applied before training the models.