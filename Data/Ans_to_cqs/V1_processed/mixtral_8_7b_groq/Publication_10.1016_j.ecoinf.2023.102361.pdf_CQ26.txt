The provided context discusses several techniques used to address issues related to data and deep learning models, but it does not explicitly mention the specific techniques asked for in the query. However, it does mention some related concepts that can be used to infer potential answers.

Firstly, the context explains that the dataset was randomly divided into three parts for training, validation, and testing, but it does not mention any stratified splitting technique. Stratified splitting is a method of splitting data that ensures each subset (training, validation, or testing) maintains the same proportion of classes as the original dataset. This technique can be useful in addressing data bias when classes are imbalanced.

Secondly, the context mentions data augmentation as a technique used to increase the number of training data. Data augmentation can be used to address data bias by creating new synthetic data points from the existing data, which can help balance the classes and improve the performance of deep learning models.

Thirdly, the context discusses several image pre-processing techniques, such as resizing, removing background, image enhancement, and denoising. While these techniques are not explicitly mentioned as addressing data bias, they can help improve the quality of the data and the performance of deep learning models.

Lastly, the context does not mention oversampling or undersampling techniques explicitly. Oversampling is a technique used to increase the number of instances of the minority class, while undersampling is a technique used to decrease the number of instances of the majority class. Both techniques can be used to address data bias when classes are imbalanced.

In summary, while the provided context does not explicitly mention the techniques asked for in the query, it does mention related concepts that can be used to infer potential answers. These include stratified splitting, data augmentation, image pre-processing techniques, and oversampling/undersampling techniques.