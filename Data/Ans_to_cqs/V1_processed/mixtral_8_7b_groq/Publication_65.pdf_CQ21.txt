Based on the provided context, there is no explicit information about the specific postprocessing steps involved after the model training for the mentioned methods (FCN, U-Net, SegNet, DeepLabV3+, and DDCN). However, it is common practice in machine learning and computer vision to use certain postprocessing techniques to evaluate the performance of models and gain insights into their behavior. Some of these techniques include:

1. Saliency maps: These visualizations highlight the important regions in the input images that contribute to the model's prediction. Saliency maps can help to understand which parts of the input images the model is focusing on.

2. Metrics calculation: Various metrics, such as accuracy, precision, recall, F1-score, and Intersection over Union (IoU), are used to evaluate the performance of segmentation models. These metrics provide a quantitative assessment of the model's performance.

3. Confusion matrix: A confusion matrix is a table that summarizes the performance of a classification model by comparing the predicted labels with the ground truth labels. It shows the number of true positives, true negatives, false positives, and false negatives, which can be used to calculate various metrics.

4. Other visualizations: It is also common to visualize the feature maps learned by the model's convolutional layers to gain insights into the model's internal representations.

Given that the context discusses the visual analysis of feature maps learned by the models, it is possible that these models underwent some visual postprocessing steps. However, there is no explicit information about other postprocessing techniques.

In summary, while the provided context does not explicitly mention the postprocessing steps taken after training the models, it is common practice to use techniques such as saliency maps, metrics calculation, confusion matrix, and other visualizations for model evaluation and understanding.