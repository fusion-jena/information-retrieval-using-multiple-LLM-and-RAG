Based on the provided context, there is no explicit information about specific postprocessing steps such as Saliency maps, Metrics calculation, or Confusion matrix after the model training. However, it does mention that the model performance was evaluated by forecasting or hindcasting SOC conditions over time.

The Mean Squared Error (MSE) was used as the parameter selection method, which implies that the MSE was calculated for the model's predictions. This is a metric for regression problems, which SOC prediction is. Therefore, Metrics calculation was performed, even if it was not explicitly stated.

The model specifications, such as the number of layers, number of neurons, activation functions, dropout, optimizer, epochs, batch size, and validation split, are provided in Table 2. These specifications suggest that the model's performance was likely evaluated using k-fold cross-validation or a similar method, given the validation split parameter. However, the context does not explicitly mention any cross-validation techniques.

In summary, based on the provided context, the postprocessing steps involved after the model training include Metrics calculation (MSE) and possibly K-fold cross-validation. There is no explicit information about Saliency maps or Confusion matrix.