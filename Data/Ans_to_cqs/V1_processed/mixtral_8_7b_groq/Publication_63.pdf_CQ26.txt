The provided context does not give specific details about the techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention that a random sample of 10% of the dataset was extracted before model training and used as a "test dataset" for independent evaluation of the trained models. This suggests that some form of data splitting was employed, but it does not specify if it was stratified splitting or not.

Additionally, the context describes the use of "transfer learning" by using pre-trained layer weights from a classification task on the ImageNet dataset for all CNN models used in the study. This technique can help to mitigate data bias by leveraging a large and diverse dataset to build a knowledge base that can be applied to a new task.

The context also describes the use of an ensemble approach, where two more state-of-the-art model architectures were trained on the same configuration and their predictions were averaged. This approach can help to reduce the impact of data bias by combining the predictions of multiple models trained on the same data.

In summary, while the provided context does not give specific details about the techniques used to address data bias during preprocessing, it does suggest the use of transfer learning, ensemble approach and data splitting which can help to mitigate data bias.