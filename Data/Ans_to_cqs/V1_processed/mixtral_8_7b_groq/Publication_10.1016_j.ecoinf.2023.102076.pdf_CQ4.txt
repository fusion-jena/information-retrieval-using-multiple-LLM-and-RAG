Based on the provided context, there is no explicit mention of specific data augmentation techniques such as flipping, rotating, or scaling being applied in the deep learning pipeline. The context does mention data augmentation in general as a method to alleviate issues when the target class makes up a small proportion of the text. However, it does not specify the particular techniques used.

Data augmentation techniques like flipping, rotating, and scaling are commonly used in computer vision tasks where images are transformed in various ways to increase the size of the training dataset. These techniques are not directly applicable to text data, which is the focus of the given context.

In the context of text classification, data augmentation techniques could include methods such as:

1. Synonym replacement: Replacing words in the training data with their synonyms to increase the dataset size while preserving the original meaning.
2. Random word insertion: Adding a random word from the same context to the training data.
3. Random word deletion: Removing a random word from the training data.
4. Swap words: Swapping the position of two random words in the training data.
5. Oversampling of the minority class: Duplicating samples from the minority class to balance the dataset.

The context does mention oversampling of the minority class as a potential data augmentation technique. However, it does not explicitly state that this method was applied in the deep learning pipeline.

In summary, while the context discusses data augmentation as a method to improve text classification performance, it does not provide specific details on the data augmentation techniques used in the deep learning pipeline.