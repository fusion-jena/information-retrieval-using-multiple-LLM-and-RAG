Based on the provided context, there is no direct information about the criteria used to determine when training is complete in the mentioned studies. However, it is common practice in machine learning and statistical modeling to use certain criteria to determine when training has reached a satisfactory level of convergence or performance.

One such criterion is the validation loss plateau. In this method, the training process continues until the validation loss (or error) stops decreasing or reaches a minimum value. This indicates that the model has learned the underlying patterns in the data and further training is unlikely to improve its performance.

In the context of species distribution models (SDMs) like Maxent, Random Forests, and Boosted Regression Trees, the training process involves fitting the model to a set of presence data and evaluating its performance on a separate validation set. The validation set is used to calculate metrics such as the area under the receiver operating characteristic curve (AUC) or true skill statistic (TSS). When the validation metric stops improving or reaches a satisfactory level, the training process can be considered complete.

It is also worth noting that the studies mentioned in the context have used various evaluation metrics to assess the effectiveness of their models in correcting sampling bias. These metrics include ΔAUC, ΔD, and others. While these metrics are used for model evaluation and comparison, they are not directly related to determining when training is complete.

In summary, while the provided context does not explicitly mention the criteria used to determine when training is complete, it is common practice in machine learning and statistical modeling to use a validation loss plateau or a stable performance metric as an indicator of training convergence.