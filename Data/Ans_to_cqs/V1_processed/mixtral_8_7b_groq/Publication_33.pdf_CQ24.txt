The provided context does not directly mention strategies employed to handle randomness in the deep learning pipeline, such as the use of a random seed value. However, it does discuss a framework for reducing error rates in deep learning algorithms (DLAs) when used for species classification in ecology. This framework includes two main phases: model training and risk threshold tuning.

In the first phase, a classification model is built by training a Convolutional Neural Network (CNN) on a given database T0. The training process of neural networks, including CNNs, involves random initialization of weights and biases, which can lead to different results in each training run. A common practice to ensure reproducibility and manage randomness in deep learning is setting a fixed random seed value. Although the context does not explicitly mention this strategy, it is a standard approach in deep learning to handle randomness.

In the second phase, the framework tunes a risk threshold Ï„i specific to each class using a second and independent database T1. This phase does not seem to be directly related to handling randomness in the deep learning pipeline. Instead, it focuses on reducing classification errors by adjusting species-specific thresholds based on a separate dataset.

In summary, while the provided context does not explicitly discuss strategies for handling randomness in the deep learning pipeline, it is reasonable to assume that standard practices, such as fixing the random seed value, are being used. The main contribution of the context is a framework for reducing error rates in species classification using DLAs in ecology by tuning species-specific thresholds.