The provided context does not give specific information about the optimization techniques used in the deep learning pipeline. However, it is mentioned that the study used Deep Neural Network (DNN) models, which are a type of deep learning algorithm. These models use hierarchical data processing, where the input data in each module results in an output that is an input for the next module, connected through weights and biases whose values are learned during the training of the network.

In the context, it is mentioned that the DNN models were trained using sample sets, where 70% of the samples were used for training and 30% for testing. This process is used to estimate the ability of the DNN algorithm to map burned areas in the study area. However, it is not specified what optimization techniques were used during the training of the DNN models.

Optimization techniques are used to minimize the loss function of a deep learning model, which is a measure of how well the model's predictions match the actual data. Some common optimization techniques used in deep learning include Stochastic Gradient Descent (SGD), Adam, and RMSprop.

Therefore, based on the provided context, it is not possible to give a specific answer about the optimization techniques used in the deep learning pipeline. It is possible that the study used one or more of the common optimization techniques, but this information is not provided in the context.