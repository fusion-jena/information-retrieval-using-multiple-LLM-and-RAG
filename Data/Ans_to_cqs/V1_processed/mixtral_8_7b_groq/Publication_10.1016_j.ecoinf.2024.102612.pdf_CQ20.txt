A system equipped with four graphical processing units (GPUs) of the NVIDIA A100 model, each with 40 GB of High Bandwidth Memory 2 (HBM2), was utilized for training the deep learning model. This information is derived from the context provided in the discussion section, which mentions that a specific supercomputer node system, Finisterrae III, was used for addressing limitations during the training process. The context suggests that GPUs were employed for this task, as they are commonly used for deep learning training due to their ability to perform parallel computations efficiently. No other hardware resources, such as TPUs (Tensor Processing Units), are mentioned in the provided context.