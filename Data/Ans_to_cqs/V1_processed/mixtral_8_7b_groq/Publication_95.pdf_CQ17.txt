Based on the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are not explicitly mentioned. However, there are some data augmentation techniques and image processing methods discussed that can help reduce overfitting indirectly.

Data augmentation techniques like randomly flipping images horizontally, scaling the contrast of each image channel by a random factor, and randomly cropping the image to a square with side lengths equal to the image height are applied to the images during training. These techniques increase the diversity of the training data, which can help improve the generalization performance of the model and reduce overfitting.

Furthermore, the training set was balanced by upsampling the images from the underrepresented classes through repetition to match the number of images of the most represented class. This technique can help ensure that the model is exposed to a more diverse set of examples, reducing the risk of overfitting to the majority class.

However, the context does not mention any explicit regularization techniques such as dropout or L2 regularization. Dropout is a regularization technique that randomly sets a fraction of the output features of a layer to zero during training, preventing the network from relying too heavily on any single feature. L2 regularization, on the other hand, adds a penalty term to the loss function that is proportional to the sum of the squares of the model weights, encouraging the model to learn smaller weight values and reducing overfitting.

Therefore, while there are some data augmentation and image processing techniques used in the pipeline that can help reduce overfitting, the explicit regularization techniques such as dropout and L2 regularization are not mentioned.


Based on the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are data augmentation techniques such as randomly flipping images horizontally, scaling the contrast of each image channel by a random factor, and randomly cropping the image to a square with side lengths equal to the image height. Additionally, the training set was balanced by upsampling the images from the underrepresented classes. However, the explicit regularization techniques such as dropout and L2 regularization are not mentioned in the context.