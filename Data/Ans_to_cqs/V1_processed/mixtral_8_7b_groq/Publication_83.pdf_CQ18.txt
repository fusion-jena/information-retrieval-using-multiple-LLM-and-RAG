Based on the provided context, there is no specific information about the strategy implemented to monitor the model performance during training. The text mainly focuses on the comparison of different methods and architectures for bird species classification using sound signals, and the selection of the best model based on that comparison.

However, it is mentioned that multiple CNN-based models were trained, and the training time was a concern due to the high computational load. Therefore, it can be inferred that some form of monitoring was implemented to track the progress of the training and ensure that it was completed successfully.

In general, there are several strategies commonly used to monitor model performance during training, such as:

1. Validation loss: This involves monitoring the loss function on a validation set that is separate from the training set. If the validation loss starts to increase while the training loss continues to decrease, it may indicate overfitting, and the training process can be stopped or adjusted accordingly.
2. Early stopping: This is a specific technique that involves stopping the training process when the validation loss stops improving for a certain number of epochs. This can help prevent overfitting and reduce training time.
3. Learning rate scheduling: This involves adjusting the learning rate during training based on the performance of the model. For example, the learning rate can be reduced if the validation loss plateaus or starts to increase.
4. Model checkpoints: This involves saving the model weights periodically during training, so that the best-performing model can be selected at the end of the training process.

Without more specific information, it is difficult to determine which of these strategies (if any) were used in the bird species classification study. However, it is clear that the training process was carefully managed to ensure the best possible performance while balancing computational load and training time.