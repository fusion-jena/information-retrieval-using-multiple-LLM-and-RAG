Based on the provided context, there is no information about how the data was split specifically for a deep learning model training, such as into training, validation, and test sets. The text focuses on the evaluation of iSDM (species distribution model) models using two test datasets and a training set, but it does not mention any deep learning models or how the data was split for such models.

However, it does provide information about how the data was split for the iSDM models. The training set consisted of 75% of the presence data selected at random. Then, there were two test datasets: Test dataset #1 represented 25% of the presence data also selected at random, and Test dataset #2 represented presence data from Ireland only.

For the iSDM models, the text mentions that two different test datasets were used, and thus two different thresholds would have been generated, making each non-comparable to the other. To address this, the 10th percentile training presence was used as the threshold for model evaluation metrics, which was the same across both test datasets.

In summary, while the context does not provide information about the data splitting approach for deep learning models, it does provide information about the data splitting approach for iSDM models, which involved a training set consisting of 75% of the presence data selected at random and two test datasets, one representing 25% of the presence data selected at random and the other representing presence data from Ireland only.