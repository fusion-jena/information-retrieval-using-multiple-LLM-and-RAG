The provided context does not give specific information about the data repository of the deep learning pipeline. However, it mentions that the study uses social media data for semantic segmentation processing in PyCharm software. It is also stated that the graphics processing software is used for proofreading. However, there is no explicit information about the data repository where the dataset is stored and made available for the research. Common data repositories for such datasets include Zenodo, Figshare, Dryad, and GBIF, but without further information, it is not possible to provide a definitive answer.