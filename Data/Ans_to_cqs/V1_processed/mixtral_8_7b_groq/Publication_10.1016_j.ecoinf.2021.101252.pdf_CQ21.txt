Based on the provided context, there are several postprocessing steps that can be involved after the model training, such as validation performance examination, metrics calculation, and model performance evaluation using a final test data set. However, there is no explicit mention of techniques like saliency maps.

To identify an 'optimal' number of training epochs, the progression of validation performance (Bv) is examined. This involves monitoring the model's validation performance to determine the point at which the model provides the best validation performance. In this case, if no increase in validation performance is observed after 25 epochs, training is stopped. Once the 'optimal' number of training epochs is determined, the model's performance is evaluated using a final test data set (T), providing the best estimate of the model's predictive performance.

Metrics calculation is also an essential part of the postprocessing steps. In the given context, the accuracy of candidate models is measured using the proportion of correctly classified cases, while the accuracy of selected models is measured using the area under the receiver operating characteristic curve (AUC). The AUC of the selected model is reported in the table for each candidate model and architecture.

However, there is no explicit mention of other postprocessing techniques like confusion matrices or saliency maps. A confusion matrix is a table that is often used to describe the performance of a classification model (or "classifier") on a set of test data for which the true values are known. It allows visualization of the performance of an algorithm and can be used to determine the areas where the classifier is performing well and the areas where it is not. Saliency maps, on the other hand, are a technique used to highlight the important features in the input data that the model is using to make its predictions.

In summary, the postprocessing steps involved after the model training, as described in the provided context, include validation performance examination, 'optimal' number of training epochs determination, metrics calculation (such as AUC), and model performance evaluation using a final test data set. Other techniques like confusion matrices and saliency maps are not mentioned in the provided context.