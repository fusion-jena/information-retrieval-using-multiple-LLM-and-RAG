The criteria used to determine when training is complete for the models in the study is early stopping, which is introduced to prevent overfitting when no further improvement is observed in the validation loss. However, the specific details of how the validation loss is monitored for a plateau or other sign of convergence are not provided in the context.

The study trains the models for 50 epochs without mixing up augmentations and for 100 epochs with mixing up augmentations. The training setup includes a validation process using a 5-fold cross validation. Additionally, a data set sampler is deployed to address class imbalance by upsampling and duplicating randomly selected samples and augmenting them.

The study also mentions that the training and testing times are increased for the ViT-B/16 model, which suggests that the training process is computationally costly and time-consuming. However, the specific impact of the early stopping criteria on the training time is not provided in the context.

In summary, the study uses early stopping as the criteria to determine when training is complete, but the specific details of how the validation loss is monitored for a plateau or other sign of convergence are not provided in the context.