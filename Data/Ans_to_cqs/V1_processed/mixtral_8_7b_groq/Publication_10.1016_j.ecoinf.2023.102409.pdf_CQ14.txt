The hyperparameters of the model were optimized using iterative testing. Specifically, the initial learning rate was set to 0.01 and further refined through this process. The number of iterations was 150, with a batch size of 4, downsampling multiplier set at 8, and the SGD optimizer, ReLu activation function, and Dice loss function were utilized. However, the context does not provide information on whether other methods such as grid search or random search were also used in the optimization process.