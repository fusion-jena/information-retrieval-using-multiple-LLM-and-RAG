The criteria used to split the data for deep learning model training typically include a training set, a validation set, and a test set. However, the specific criteria used to split the data are not provided in the context.

The training set is used to train the model by adjusting the model's parameters to minimize the loss function. The validation set is used to tune the hyperparameters of the model and prevent overfitting. The test set is used to evaluate the performance of the final model.

The mini-batch size is an important parameter that affects the training of the deep learning model. A mini-batch size that is too small may not provide sufficient image data for the network to learn from some or all of the classes within each iteration. On the other hand, a mini-batch size that is too large may cause the network to overfit to the training images. The mini-batch size is limited by the amount of memory available to the GPU, the size of the images, and the number of internal parameters in the network.

During the training process, the network performs a new round of learning on a mini-batch of images, focusing relatively more on images with higher loss scores, and updates its internal parameters before proceeding to the next training iteration with a new mini-batch of images. A full cycle through the entire set of training images is referred to as an 'epoch'.

The diversity of considerations and possibilities for improvement highlights the challenge of using deep learning as a still-burgeoning technology. A sensible approach is to initially set options based on a review of published studies involving similar analysis tasks and then attempt to refine certain settings through trial and error. However, the computationally laborious process of training a CNN imposes a practical limit on the extent of trial and error that can be undertaken.

Therefore, while the context provides valuable information about the deep learning training process, it does not provide specific criteria used to split the data for deep learning model training.