The context provided does not give specific information about the hardware resources used for training the deep learning model. However, it does mention that the research involved a hyperparameter search for fully connected architectures, which suggests that significant computational power was required. Additionally, it is noted that large cross-validation (CV) experiments with deep learning-based models are often infeasible due to their high computational costs. This further implies that powerful hardware, such as GPUs or TPUs, were likely used to train the models, but the specific type of hardware is not mentioned. Therefore, while the context suggests that advanced computational resources were used, it does not provide enough information to give a definitive answer to the query.