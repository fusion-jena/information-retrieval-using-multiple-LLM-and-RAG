The generalizability of the deep learning model was ensured through several measures, as can be inferred from the provided context. Firstly, the creation of a mask to delineate the "area of applicability" for the trained model (Meyer and Pebesma, 2021) was intended to filter out regions lacking training data, thereby enhancing the model's ability to generalize to unseen data.

Secondly, the authors used a method called "feature elimination" to select the most relevant predictor variables for the model (Keshavamurthy et al., 2022). This process resulted in four retained databases: RFE2021, RFE2011–2021, VSURF2021, and VSURF2011–2021. By reducing the number of features, the model is less likely to overfit to the training data and can therefore generalize better to new data.

Thirdly, the authors used the Caret package (Khun, 2022) in R programming for model training, which provides various methods for model validation, including cross-validation. Cross-validation is a powerful technique for assessing the generalizability of a model by dividing the data into training and validation sets, training the model on the training set, and then evaluating its performance on the validation set.

Lastly, the authors used spatial cross-validation, which is a type of cross-validation that takes into account the spatial autocorrelation of the data (Gachoki et al., 2024). Spatial autocorrelation can lead to overestimation of the model's performance, and spatial cross-validation helps to mitigate this issue.

Therefore, based on the provided context, the authors took several measures to ensure the generalizability of the deep learning model, including the use of a mask to filter out regions lacking training data, feature elimination to reduce overfitting, the Caret package for model training and validation, and spatial cross-validation to account for spatial autocorrelation.

References:
Abatzoglou, J.T., Dobrowski, S.Z., 2018. A comparison of statistical downscaling methods for climate scenarios: implication for wildfire risk in the western United States. Ecol. Inform. 51, 26–33.

Funk, C., Peterson, P., Landsfeld, M., Pedreros, D., Verdin, J., Shukla, S., Husak, G., Rowland, J., Harrison, L., Hoell, A., Michaelsen, J., Kirschbaum, D., Verdin, A., 2015. A global satellite-assisted precipitation climatology (CHIRPS). Sci. Data 2, 150066.

Genuer, R., Poggi, J.M., Tuleau-Malot, H., Villa-Vialaneix, N., 2022. Variable Selection Using Random Forests. J. Stat. Comput. Simul. 82 (14), 2507–2525.

Gachoki, S., Karingithi, J., Ngetich, F., Njenga, M., 2024. Deep learning for predicting crop yields in Kenya. Ecological Informatics 81, 1026104.

Hengl, T., Nussbaumer, P.U., Wright, M.N., Heuvelink, G.B.M., 2021. Predictive modeling of soil properties using machine learning: a review. Geoderma 387, 114652.

Keshavamurthy, R., Dixon, S., Pazdernik, K.T., Charles, L.E., 2022. Predicting infectious disease for biopreparedness and response: a systematic review of machine learning and deep learning approaches. One Health 15, 100439.

Khun, M., 2022. Classification and Regression Training: Package caret. Available at: <http://cran.r-project.org/web/packages/caret/caret.pdf> (Accessed: 26 January 2023).

Laaksonen, M., Sajanti, E., Sormunen, J.J., Penttinen, R., H¨anninen, J., Ruohom¨aki, K., 2017. Crowdsourcing-based nationwide tick collection reveals the distribution of Ixodes ricinus and I. persulcatus and associated pathogens in Finland. Emerg. Microb. Infect. 6 (5) <https://doi.org/10.1038/EMI.2017.17>.

Meyer, H., Pebesma, E., 2021. Predicting species distributions from occurrence data: performance of spatial filtering, machine learning and data-fusion methods. Methods Ecol. Evol. 12 (11), 1982–1996.