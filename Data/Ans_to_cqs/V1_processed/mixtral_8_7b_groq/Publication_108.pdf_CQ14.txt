The context does not provide explicit information about how the hyperparameters of the model were optimized, such as whether a grid search, random search, or some other method was used. However, it can be inferred that some form of hyperparameter tuning was performed, as the study tested different numbers of blocks and filters, as well as different learning rates.

Hyperparameter tuning is the process of searching for the best set of hyperparameters for a model. This can be done using a variety of methods, including grid search, random search, and Bayesian optimization. Grid search involves systematically trying all possible combinations of hyperparameters within a given range. Random search, on the other hand, involves randomly selecting hyperparameters within a given range. Bayesian optimization uses a probabilistic model to make informed decisions about which hyperparameters to try next.

Without more information, it is not possible to say for certain which method was used in this study. However, it can be said that some form of hyperparameter tuning was performed, as the study tested different numbers of blocks and filters, as well as different learning rates. The study found that Scenario 5, which had 4 encoding blocks with 4 filters each and a learning rate of 0.001, had the best values for IoU and accuracy while training on fewer epochs. This architecture was selected as the optimal solution.