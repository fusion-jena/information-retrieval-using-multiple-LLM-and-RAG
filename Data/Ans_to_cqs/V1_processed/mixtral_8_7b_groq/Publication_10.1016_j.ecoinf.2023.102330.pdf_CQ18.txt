Based on the provided context, there is no specific information about the strategy implemented to monitor the model performance during training. The context includes details about various studies and models related to distance sampling, Northern Bobwhite detection, and wildlife conservation, but it does not mention any techniques for monitoring model performance during training.

In general, monitoring model performance during training is crucial to ensure that the model is learning effectively and not overfitting or underfitting the data. There are several strategies that can be used to monitor model performance during training, such as:

1. Validation curves: Plotting the model's performance on a validation set after each epoch can help identify if the model is overfitting or underfitting.
2. Early stopping: Stopping the training process when the model's performance on a validation set stops improving can prevent overfitting.
3. Learning rate schedules: Adjusting the learning rate during training can help the model converge to the optimal solution.
4. Regularization: Adding a regularization term to the loss function can prevent overfitting by penalizing complex models.
5. Cross-validation: Splitting the data into multiple folds and training the model on each fold can provide a more robust estimate of the model's performance.

Without more information about the specific model and training process, it is difficult to determine which of these strategies (if any) were used to monitor model performance during training.