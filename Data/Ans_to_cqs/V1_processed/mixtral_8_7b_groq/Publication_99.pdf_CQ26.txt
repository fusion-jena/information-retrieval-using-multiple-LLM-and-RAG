The provided context does not directly mention the techniques used for addressing data bias during preprocessing of the deep learning pipeline. However, it does mention that the input images were preprocessed by mean centering the image with ImageNet values and then rescaled between 0 and 1. This preprocessing technique is a form of data normalization, which can help to reduce data bias by ensuring that all features have similar scales and ranges.

In addition, the context mentions that the classification network was trained on a balanced dataset, which can also help to reduce data bias. When a dataset is balanced, it means that each class has an equal number of samples. This can help to prevent the model from being biased towards the majority class, which can occur when the dataset is imbalanced.

Furthermore, the context also mentions that various data augmentation techniques such as height and width shift, flipping, zooming and brightness changes were used during training of the classification network. Data augmentation can help to increase the diversity of the training data, which can also help to reduce data bias by ensuring that the model is exposed to a wider range of variations in the data.

Therefore, while the context does not explicitly mention techniques such as stratified splitting, oversampling, undersampling, or diverse data collection, it does mention several preprocessing techniques that can help to reduce data bias in the deep learning pipeline, including data normalization, training on a balanced dataset, and data augmentation.