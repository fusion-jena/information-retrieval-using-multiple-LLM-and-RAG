After the model training, there are several postprocessing steps that can be taken to further analyze and evaluate the performance of the object detection model. However, based on the provided context, the specific postprocessing steps mentioned are the calculation of metrics such as mAP50 and mAP50-95.

The mAP50 and mAP50-95 metrics are commonly used in object detection tasks to evaluate the accuracy of the model. mAP50 represents the average accuracy for all classes at an Intersection over Union (IoU) threshold of 0.5, while mAP50-95 represents the average accuracy across all classes at different IoU thresholds, spanning from 0.5 to 0.95 in increments of 0.05.

The calculation of these metrics involves the use of precision and recall values. Precision is calculated as the number of true positives (TP) divided by the sum of true positives and false positives (FP), while recall is calculated as the number of true positives divided by the sum of true positives and false negatives (FN). The mAP value is then calculated as the average of the AP values for all classes.

In addition to the calculation of metrics, the context also mentions the use of ablation experiments to evaluate the enhancements made to various components of the network architecture. These experiments involve training different network models with varying structures and comparing their performance.

However, other postprocessing steps such as the generation of saliency maps or confusion matrices are not mentioned in the provided context. Saliency maps can be used to visualize the regions of the input image that the model is focusing on, while confusion matrices can be used to evaluate the performance of the model across different classes.

Therefore, based on the provided context, the postprocessing steps involved after the model training are the calculation of mAP50 and mAP50-95 metrics, as well as the use of ablation experiments to evaluate the enhancements made to the network architecture.