Based on the information provided, there is no explicit mention of how the hyperparameters of the models were optimized, such as through methods like grid search or random search. The text focuses on comparing the performance of different models in a drone survey for Pacific oyster detection, providing metrics like F-score, precision, recall, and standard errors.

However, it can be inferred that the hyperparameters were carefully chosen and tuned to achieve the best performance for each model. This is evident from the varying performance of the models, with YOLOv5s having the highest precision score and TPH-YOLOv5, an extension of YOLOv5s, having a slightly lower precision score. This suggests that the creators of these models went through a process of optimization to find the best set of hyperparameters for the given task.

Additionally, the text highlights the success of these YOLO-based models when trained with smaller data quantities, implying that the learning rate, batch size, and other hyperparameters were adjusted to accommodate the limited data. The comparison between the models also indicates that a simpler model, like YOLOv5s, can perform better than a more complex model, such as YOLOv5m, for this specific task. This further supports the idea that the hyperparameters were carefully optimized for each model.

In summary, while the text does not explicitly mention the hyperparameter optimization methods used, it is clear that the hyperparameters were carefully tuned for each model to achieve the best performance in the drone survey for Pacific oyster detection.