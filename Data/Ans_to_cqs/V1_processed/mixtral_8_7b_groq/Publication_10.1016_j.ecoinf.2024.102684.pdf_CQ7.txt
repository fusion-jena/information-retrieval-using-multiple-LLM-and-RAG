The dataset was divided into three subsets for model evaluation and hyperparameter search: training (60%), validation (20%), and testing (20%). This partitioning approach aims to obtain an unbiased estimation of error. Data augmentation was only applied to the training data to avoid overlapping the same data in different partitions.

The training data is used to train the deep learning model by adjusting the model's parameters to minimize the error on this subset. The validation data is used to fine-tune the model's hyperparameters and prevent overfitting. The testing data is used to evaluate the model's performance on unseen data.

The coefficients of determination (R2) and the root mean squared error (RMSE) metrics were used to evaluate the models. R2 measures the percentage of variation in the response variable explained by the model, while RMSE quantifies the difference between the actual and predicted values. Lower RMSE values indicate better model predictions.

The hyperparameter search involved a small grid search over the activation function (ReLU, sigmoid, or elu), the optimizer (RMSprop or adam), and the learning rate (0.1, 0.001, 0.0001, and 0.00001). The training, validation, and testing performance were compared to avoid overfitting.

Typically, deep learning-based models employ simple data partitioning strategies, such as training, validation, and testing. This simple scheme can help add heterogeneous information to the training procedure. However, evaluations within and outside the domain of the training data can provide a deeper insight into the generalization capabilities of a model.

In summary, the criteria used to split the data for deep learning model training include a 60-20-20 partition for training, validation, and testing, respectively. The data partitioning strategy aims to obtain an unbiased estimation of error, prevent overfitting, and evaluate the model's performance on unseen data. Additionally, the coefficients of determination (R2) and the root mean squared error (RMSE) metrics were used to evaluate the models. The hyperparameter search involved a small grid search over the activation function, the optimizer, and the learning rate.