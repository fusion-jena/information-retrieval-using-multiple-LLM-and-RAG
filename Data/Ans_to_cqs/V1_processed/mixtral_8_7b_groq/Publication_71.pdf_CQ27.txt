Based on the provided context, the process followed to deploy the trained DeepLabv3+ model can be summarized as follows:

1. **Model Training:** The model training was carried out on a Windows 10 PC equipped with an RTX2070 GPU and 16GB memory. The TensorFlow framework was used for training. The DeepLabv3+ model was trained for land cover classification using the training datasets. The weights of a pre-trained model, specifically the Xception-65 backbone based model trained on the PASCAL VOC 2012 dataset, were used as the starting point. The logit weights of the pre-trained model were excluded during the training of the land cover model due to the difference in the number of land covers in the Vasiliko and Kimisala dataset and the number of classes in the PASCAL VOC-2012 dataset. The training parameters used for this process are detailed in Table 1.

2. **Model Serialization:** Although the context does not explicitly mention the serialization process, it can be inferred that the trained model was saved for later use. TensorFlow provides a way to save the entire model or just the weights. Given that the fine-tuning was done starting from the pre-trained model's weights, it is reasonable to assume that the trained model's weights were saved at the end of the training.

3. **Platform Selection:** The context does not provide specific details about the deployment platform. However, it can be assumed that the model was deployed on a platform that supports the running of TensorFlow models. This could be a local server, a cloud-based platform, or an embedded device with TensorFlow support.

Please note that this answer is based on the provided context and some assumptions had to be made due to the lack of explicit information.