The strategy implemented to monitor the model performance during training is rigorous folded cross-validation. This method involves partitioning the dataset into ten equal sections, or folds, and then training the model using nine of these folds while testing it on the remaining fold. This process is repeated for each fold, with the performance metrics of each test then being averaged to provide a comprehensive assessment of the model's performance. This approach allows for the control of external factors that could influence the results, thereby enhancing the precision and reliability of the tests. Through this strategy, the detection accuracy of the model is consistently maintained and evaluated, as demonstrated by the improved recognition accuracy and recall when compared to the benchmark model. The use of quantitative values and data visualizations further highlights the notable differences in performance between the proposed and benchmark models.