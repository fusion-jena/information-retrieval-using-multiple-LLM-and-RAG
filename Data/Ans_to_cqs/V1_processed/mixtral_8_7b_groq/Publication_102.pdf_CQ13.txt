The hyperparameters used in the deep learning models are as follows:

1. Model-1 and Model-2:
- The models were optimized using the Adam optimizer.
- The learning rate used was 0.001.

2. Model-K:
- The model was initialized with pre-trained ImageNet weights.
- It was trained using the Stochastic Gradient Descent (SGD) optimizer and an MSE loss function.

These details are provided in the context on Page 6, where it is mentioned that "All the parameters were optimized using the Adam optimizer with a learning rate of 0.001" for Model-1 and Model-2. For Model-K, it is stated that the model was initialized with pre-trained ImageNet weights and then trained using our training data set with a Stochastic Gradient Descent (SGD) optimizer and an MSE loss function.