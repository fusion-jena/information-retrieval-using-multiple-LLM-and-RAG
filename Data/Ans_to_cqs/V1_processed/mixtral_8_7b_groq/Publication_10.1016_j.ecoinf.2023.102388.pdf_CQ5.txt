The provided context does not specify any particular dataset used in the deep learning pipeline. It focuses on discussing the concepts of overfitting and no-overfitting in the context of Convolutional Neural Networks (CNNs), providing information on the optimization algorithm, learning rate, weight decay, batch size, number of training epochs, and techniques such as batch-norm, dropout, and weight decay to reduce overfitting.

However, the context does mention a few papers that might use popular datasets in their experiments. For instance, the paper "Deep residual learning for image recognition" by He et al., 2016b, does not explicitly mention the dataset used. Still, it is highly likely that they used a well-known image recognition dataset, such as CIFAR or ImageNet, given the nature of their research. Similarly, the paper "Mask r-cnn" by He et al., 2018, does not provide information on the dataset used.

In addition, the paper "Densely connected convolutional networks" by Huang et al., 2017, does not explicitly mention the dataset either. However, they do reference the "Image Recognition" paper by CoRR abs/1409.1556, which might have used a popular dataset for image recognition tasks.

The paper "Deepface: closing the gap to human-level performance in face verification" by Taigman et al., 2014, likely used a face recognition dataset, but it is not explicitly stated in the context provided.

In summary, the provided context does not offer enough information to determine the specific datasets used in the deep learning pipelines discussed. It is highly likely that popular datasets, such as MNIST, CIFAR, or ImageNet, were used in the research mentioned. However, without explicit references or additional information, it is impossible to definitively answer this question.