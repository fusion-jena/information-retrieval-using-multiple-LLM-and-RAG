The provided context does not give specific criteria used to split data for deep learning model training. However, it is a common practice in machine learning, including deep learning, to split the dataset into three subsets: training, validation, and testing.

The training set is used to train the model, i.e., to adjust the model's parameters to minimize the error on the training data. The validation set, also known as the development set, is used during the model training process to provide an unbiased evaluation of the model. It helps to tune hyperparameters and prevent overfitting. The test set, finally, is used to assess the model's performance. It is the ultimate judge of how well the model generalizes to unseen data.

The splitting criteria can vary depending on the problem and the amount of available data. A common approach is to use 60-20-20 or 70-15-15 splits for training, validation, and testing, respectively. However, for small datasets, it is recommended to use a 50-50 or even 30-70 split for training and testing, respectively, and to avoid using a validation set due to the limited data. In such cases, cross-validation techniques can be used to assess the model's performance and tune hyperparameters.

In the context of EF calculation, where a short time series is considered a small sample test object, the provided information suggests using the Gaussian kernel function for simplicity and effectiveness in addressing nonlinear relationships. However, it does not mention any specific data splitting criteria. Therefore, it is safe to assume that the general data splitting practices apply.