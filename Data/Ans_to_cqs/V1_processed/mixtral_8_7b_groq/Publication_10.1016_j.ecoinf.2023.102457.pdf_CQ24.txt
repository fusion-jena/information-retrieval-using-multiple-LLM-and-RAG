The text provided does not give specific information about strategies used to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does describe a process of cross-validation in the context of supervised classification, which can help manage variability in model performance.

In the study, the researchers used random forests, a type of supervised classifier, to distinguish between female gibbon calls. They divided their data into training and test sets using an 80/20 split, repeating this process over 20 iterations of cross-validation. This approach allowed them to assess the consistency of each feature extraction method's performance, as they report the mean and standard deviation of classification accuracy for each method.

Additionally, the study compares the performance of various feature extraction techniques, including MFCCs, BirdNET, VGGish, Wav2Vec2, and acoustic indices. By using multiple feature extraction methods and comparing their performance, the study implicitly accounts for variability that may arise from the feature extraction process itself.

While the text does not explicitly mention strategies for handling randomness in the deep learning pipeline, such as setting a random seed value, the described process of cross-validation and comparing multiple feature extraction methods can help manage variability in model performance.