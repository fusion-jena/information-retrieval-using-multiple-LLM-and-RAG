The criteria used to split the data for deep learning model training are not explicitly mentioned in the provided context. However, it is mentioned that the training on weakly labeled samples of varying lengths poses a challenge in extracting segments of audio recordings that contain the target signal. To overcome this, a simple detector based on signal strength was developed to extract segments containing vocalizations from the recordings.

The data pre-processing includes a 5x5 Conv+BN+ReLU, Ma x pooling, and Downsampling block for the input shape (1x64x384) and produces an output shape of (32x64x384). This process is repeated for four ResStacks with different input and output shapes, followed by a Classification block.

The overall process mostly follows current best practices in deep learning, as summarized in (Chollet, 2017). Therefore, it can be inferred that the data splitting criteria could be similar to those best practices, which typically involve splitting the data into training, validation, and test sets, often in an 80-10-10 or 70-15-15 ratio.

However, without explicit information on how the data was split in this specific case, it is not possible to provide a definitive answer. It is recommended to refer to the original research paper or source for more information on the data splitting criteria used in this study.