The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the model's performance was evaluated on three different datasets: training, validation, and testing. 

The training data was used to train the model, and the model achieved F1 scores above 0.991. The validation data was used to validate the model, and it achieved F1 scores of 0.934. The testing data was used to evaluate the model's ability to generalize, and it achieved F1 scores above 0.934 over time at all locations and nearly perfect scores at locations it had never seen before.

Moreover, the F1 scores, the number of actual nests, true positives, false positives, and false negatives were reported for each individual orthomosaic. This level of detail in reporting the results suggests that the model's performance was closely monitored during training, and adjustments were made accordingly.

It can also be inferred that cross-validation was used as a strategy to monitor the model's performance during training. Cross-validation is a technique used to assess how well a model will generalize to an independent dataset. It involves dividing the dataset into a training set and a validation set, training the model on the training set, and then testing the model on the validation set. This process is repeated multiple times with different subsets of the data to get a more accurate estimate of the model's performance.

In addition, the use of the F1 score as a performance metric suggests that the strategy implemented to monitor the model performance during training was focused on balancing precision and recall. The F1 score is the harmonic mean of precision and recall, and it is a better metric than accuracy when dealing with imbalanced datasets.

Overall, while the specific strategy implemented to monitor the model performance during training is not explicitly stated, it can be inferred that a combination of using different datasets, cross-validation, and the F1 score as a performance metric was used to ensure that the model was accurately trained and able to generalize well.