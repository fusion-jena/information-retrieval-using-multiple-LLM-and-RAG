The context provided does not explicitly mention the specific criterion used to determine when training is complete. However, it does mention that the convergence of P, R, and mAP50 during training and loss of cls_loss during validation are monitored in Figure 11. This suggests that the training process might be evaluated based on these metrics.

In machine learning, it is common to use a validation set to evaluate the performance of a model during training. The validation set is separate from the training set and is used to provide an unbiased evaluation of the model's performance. One common approach to determine when training is complete is to monitor the performance on the validation set and stop training when the performance plateaus or starts to degrade.

In the context of object detection, P (precision), R (recall), and mAP50 (mean average precision at IoU threshold of 0.5) are common evaluation metrics. Precision measures the proportion of true positive detections among all positive detections, while recall measures the proportion of true positive detections among all actual positives. mAP50 is the average precision across all classes at an IoU threshold of 0.5. The cls_loss is the classification loss, which measures the error between the predicted and actual class labels.

Therefore, it is possible that the training of the YOLO_MRC model is determined to be complete when the convergence of P, R, and mAP50 during training and the cls_loss during validation plateaus or starts to degrade. However, this is an inference based on the provided context, and the specific criterion used to determine when training is complete is not explicitly stated.