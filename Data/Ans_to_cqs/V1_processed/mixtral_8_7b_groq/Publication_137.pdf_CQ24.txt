Based on the provided context, there is no explicit mention of strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, the text does discuss several aspects of their training process that could be related to handling randomness.

First, they set the learning decay rate to 0.7 for the training, which allows the learning rate to gradually decays as the training progresses. This could help reduce the impact of randomness in the learning process by providing a more stable learning rate over time.

Second, they adjusted the regularization strength during their experiments and found that a regularization strength of 0.2 yielded the best results. Regularization is a technique used to prevent overfitting in deep learning models, and adjusting its strength could help manage the impact of randomness on the model's performance.

Third, they varied the batch size during their experiments and found that a batch size of 8 yielded the best results for tree species segmentation. The batch size determines how many training examples are used in each iteration of the training process, and changing it can affect the model's convergence behavior. By carefully selecting the batch size, they may have been able to manage the impact of randomness on the training process.

Lastly, they used a deep neural network to process data and adjusted the training epoch, batch size, and volume size to output a classifier for prediction. The number of training epochs and batch size can both impact the randomness of the training process, and adjusting these parameters could help manage the impact of randomness.

In summary, while the provided context does not explicitly mention strategies for handling randomness in the deep learning pipeline, it does discuss several aspects of the training process that could be related to managing randomness. These include setting a learning decay rate, adjusting regularization strength, varying the batch size, and carefully selecting the number of training epochs and batch size.