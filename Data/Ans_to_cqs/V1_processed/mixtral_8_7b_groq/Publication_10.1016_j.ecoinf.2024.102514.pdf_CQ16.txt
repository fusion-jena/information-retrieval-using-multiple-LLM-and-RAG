Based on the provided context, there is no explicit information given about the specific criteria used to determine when training is complete in this particular study. However, it is mentioned that the WQ indicator data was divided into training and testing datasets, with 80% and 20% of the data being used for training and testing, respectively.

In general, there are several common criteria used to determine when training is complete in machine learning models. One common method is to monitor the validation loss during training and stop training when the validation loss plateaus or starts to increase, indicating that the model is no longer improving its performance on new data. This is known as early stopping.

Another common method is to use a technique called learning rate scheduling, where the learning rate (the size of the steps taken during training) is gradually reduced over time. This allows the model to make smaller and smaller adjustments to its weights and biases, helping it to converge on the optimal solution.

Additionally, some models may use a technique called regularization to prevent overfitting, which can occur when a model learns the training data too well and performs poorly on new data. Regularization adds a penalty term to the loss function, which discourages the model from learning overly complex patterns in the training data.

In the context of the provided study, it is possible that one or more of these methods were used to determine when training was complete. However, without further information, it is not possible to provide a definitive answer.