The strategy implemented to monitor the model performance during training involves the use of a validation dataset, which is independent of the training and testing datasets. This validation dataset is used to provide an unbiased evaluation of the model's performance during the training process. The model's performance is monitored by calculating the accuracy and kappa statistics on the validation dataset after each epoch. The accuracy measures the proportion of correct predictions made by the model, while the kappa statistic provides a measure of the agreement between the predicted and actual class labels, taking into account the possibility of the agreement occurring by chance.

In addition to monitoring the model's performance on the validation dataset, several techniques were employed to prevent overfitting and improve the generalization of the model. These techniques include the use of dropout and batch normalization layers, which reduce overfitting by introducing randomness during training and normalizing the inputs to each layer, respectively. Furthermore, the hyperparameters of the model, including the learning rate, number of epochs, and batch size, were optimized using GridSearchCV to find the best values that result in the highest testing accuracy and kappa.

For instance, in the Deep Neural Network (DNN) model, a batch normalization layer after hidden layer 2 increased the testing accuracy of the model. These additional layers, dropout and batch normalization, reduce the overfitting of the model on the training data and increase generalization on testing data. The hyperparameters in this network, the learning rate, number of epochs, and batch size, were further tuned such that the testing accuracy and the kappa were the best among all models. The optimized hyperparameter values for learning rate and batch size were 0.007 and 48, respectively.

Similarly, for the Support Vector Machine (SVM) model, the RBF kernel requires tuning of two parameters, C and γ. The best values for C and γ were optimized using GridSearchCV and were found to be 1000 and 1, respectively.

Moreover, for the U-Net model implemented in the arcgis.learn module of the ArcGIS API for Python, hyperparameter tuning was done to select the best U-Net model. Based on hyperparameter optimization, it was found that the best model uses an input patch size of 64 × 64 pixels and a ResNet-50 backbone.

Overall, the strategy implemented to monitor the model performance during training involves the use of a validation dataset, the calculation of accuracy and kappa statistics, and the use of techniques to prevent overfitting and improve generalization. These techniques include the use of dropout and batch normalization layers, hyperparameter optimization, and the use of pre-trained models.