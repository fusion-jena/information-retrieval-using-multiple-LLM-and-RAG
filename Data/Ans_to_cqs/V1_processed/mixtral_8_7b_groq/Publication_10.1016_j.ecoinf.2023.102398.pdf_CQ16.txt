The criteria used to determine when training is complete in the provided context is the validation loss plateau. This is suggested by the mention of graded MSE convergence being adopted to fine-tune the model, which implies that the training process is halted when the validation loss reaches a plateau, indicating that the model's performance has stabilized. Additionally, the training summary tables provided for different epoch values (100, 200, and 250) suggest that the model's performance, as measured by mAP@0.5 and mAP@0.5:0.95, generally improves with an increasing number of epochs, but the rate of improvement slows down as the validation loss plateaus. Therefore, it can be inferred that the training process is designed to stop when the validation loss reaches a plateau, indicating that the model's performance has stabilized and further training is unlikely to yield significant improvements.