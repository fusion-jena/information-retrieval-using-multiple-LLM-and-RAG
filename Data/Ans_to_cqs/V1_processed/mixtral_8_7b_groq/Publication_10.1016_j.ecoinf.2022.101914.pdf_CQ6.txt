Based on the provided context, there is no explicit mention of the preprocessing steps involved before training a deep learning model such as normalization, scaling, or cleaning. However, the text does describe the data preparation process for building models using environmental covariates and presence-background data. Here's an overview of those steps:

1. Obtain presences (red circles) and generate background points (black triangles).
2. Separate data into folds for cross-validation.
3. Set aside one fold as an external evaluation dataset and keep the remaining folds as training data.
4. Perform scale optimization for environmental covariates using focal statistics and t-tests.
5. Subsample background points in the training data to create three datasets with different background-to-presence ratios: 1×, 10×, and 10K.

While these steps do not directly address normalization, scaling, or cleaning, it is important to note that such preprocessing techniques are generally recommended for many machine learning algorithms, including deep learning models. Therefore, it is plausible to assume that these steps were applied before or during the data preparation process, but they are not explicitly mentioned in the provided context.

In summary, while the provided context does not specifically mention the preprocessing steps of normalization, scaling, or cleaning for deep learning models, it is a common practice to apply these steps in machine learning pipelines.