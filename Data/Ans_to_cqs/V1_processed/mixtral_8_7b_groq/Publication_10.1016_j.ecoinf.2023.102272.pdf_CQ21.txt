Based on the provided context, there is no explicit information about specific postprocessing steps, such as saliency maps or confusion matrix calculation, being carried out after the model training. However, it does mention that the accuracy of candidate models is compared using a left-out validation data set (data partition Av) during the model selection procedure. 

The metrics used for comparison are not specified, but it can be inferred that some form of accuracy or error metric would have been used to evaluate the performance of the models. This could include metrics such as precision, recall, F1 score, or mean squared error, depending on the nature of the prediction task. 

Additionally, after the final model is selected and trained on the full training data, it is evaluated on a separate test data set (partition T) to assess its predictive performance. This evaluation could also involve the calculation of various metrics, but this is not explicitly mentioned in the context. 

Therefore, while the specific postprocessing steps are not detailed in the provided context, it is clear that some form of model evaluation and performance metrics calculation are carried out after the model training.