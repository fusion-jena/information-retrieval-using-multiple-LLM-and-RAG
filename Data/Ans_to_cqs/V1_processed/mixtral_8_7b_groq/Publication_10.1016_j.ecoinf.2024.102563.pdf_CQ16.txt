The provided context does not give specific information about the criteria used to determine when training is complete for the machine learning models mentioned. However, it is common in machine learning to use a validation set to monitor the model's performance during training. The training process is typically stopped when the model's performance on the validation set stops improving or starts to degrade, indicating that the model may be overfitting to the training data. This is often referred to as a validation loss plateau.

In the context of the table provided, it appears that the models' performance is being evaluated based on their overall accuracy and kappa index. The kappa index is a measure of the agreement between the predicted and actual classifications, taking into account the possibility of the agreement occurring by chance. It is possible that these metrics are being used to monitor the model's performance on the validation set during training, and that the training process is being stopped when a validation loss plateau is reached.

Additionally, the paper by Saboori et al. (2019) mentions using a graded proportion method of training sample selection for updating conventional soil maps, which could be used as a stopping criterion for training. This method involves selecting a proportion of samples from each class based on the class's prevalence in the data, which could help to ensure that the model is trained on a representative sample of the data.

Overall, while the provided context does not give specific information about the criteria used to determine when training is complete, it is likely that a validation set is being used to monitor the model's performance during training, and that the training process is being stopped when a validation loss plateau is reached. Additionally, other methods such as graded proportion method of training sample selection could be used as a stopping criterion for training.