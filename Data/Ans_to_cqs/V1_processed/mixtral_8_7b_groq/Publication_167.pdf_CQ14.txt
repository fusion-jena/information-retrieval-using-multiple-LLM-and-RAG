The hyperparameters of the model are optimized using the validation set in the 10-fold cross-validation method. However, the specific method of hyperparameter optimization is not mentioned in the provided context. Common methods for hyperparameter optimization include grid search and random search.

In grid search, a predefined set of hyperparameter values is specified, and the model is trained for each combination of hyperparameters in the set. The set of hyperparameters that results in the best performance on the validation set is then selected for the final model.

In random search, a random set of hyperparameter values is generated, and the model is trained for each combination of hyperparameters in the set. This method is more efficient than grid search, as it is less likely to get stuck in local optima.

It is important to note that the testing set should not be used for hyperparameter optimization, as it is reserved for evaluating the generalization ability of the final model.

In the provided context, the training set consists of a grid with neighborhood features of six years (1986, 2005, 2008, 2010, and 2013), including the LU type, soil, topography, elevation, slope, aspect, distance to settlements, distance to roads, distance to rivers in this grid unit, and the 4 neighborhood grid units. The constraint factors are the statistical data and the quantity simulated by the backtracking of the Markov model, which are combined and used to modify the numbers of different LU types in 2000. Water and settlements are constraint factors that can be determined by manual interpretation.

The validation set is a set of samples set aside separately during the model training and can be used to adjust the hyperparameters of the model and to conduct a preliminary evaluation of the modelâ€™s capabilities. The testing set is used to evaluate the generalization ability of the final model. The mean value of the ten results is used to estimate the accuracy of the algorithm.