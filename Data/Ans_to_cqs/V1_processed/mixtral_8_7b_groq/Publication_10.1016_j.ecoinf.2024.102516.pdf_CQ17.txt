The provided context does not give specific information about the regularization methods used to prevent overfitting in the deep learning pipeline. It discusses the training of a network for plant cover estimation, including the use of a mean scaled absolute error as the regression loss, a batch size of 1, an input image resolution of 5, a learning rate of 10, and horizontal flipping for data augmentation. It also mentions the use of segmentation pre-training and transfer learning. However, it does not mention any regularization techniques such as dropout or L2 regularization. Therefore, based on the provided context, it is not possible to answer this question.

It's worth noting that regularization methods like dropout, L2 regularization, data augmentation, early stopping are commonly used techniques to prevent overfitting in deep learning models. But in this case, the context does not explicitly mention any of these methods.