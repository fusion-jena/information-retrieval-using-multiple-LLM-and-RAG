The raw dataset was split into three sets for training, validating, and testing the deep learning model. The data partitioning ratio between the training, validation, and test sets was set as 8:1:1. This means that 80% of the data was used for training, 10% for validation, and the remaining 10% for testing. The random partition was repeated ten times to reduce the influence of random splitting while ensuring converged performance.

The training set was used to learn the parameters of the model during the training process. The validation set was used to evaluate the modeling and tune its hyperparameters. The performance and generalizability of the optimal model were evaluated using the test set.

The data splitting criteria used here are common in deep learning model training. The training set is used to build the model, the validation set is used to tune the model's hyperparameters and select the best model, and the test set is used to evaluate the final model's performance. This approach helps to ensure that the model can generalize well to unseen data.