The provided context does not directly mention the methods used for collecting raw data in the deep learning pipeline. However, it does give some insight into the types of data used in the model being discussed.

The model is used for predicting real-world phenomena such as wildfire spreads or pest plants propagation. This suggests that the data used in the model is likely collected from sensors or other monitoring systems that track temperature, humidity, and other environmental factors. Additionally, the model uses partitions to increase the number of cells exposed in each iteration, which implies that the data is collected at a cellular level, possibly from a grid or matrix of sensors.

The context also mentions the use of public datasets in the development of the model. Specifically, it mentions the use of machine-learning tools, which often rely on large datasets to train models. These datasets could be publicly available datasets related to environmental phenomena, such as wildfire or plant propagation data.

In summary, while the provided context does not explicitly mention the methods used for collecting raw data in the deep learning pipeline, it suggests that the data is likely collected from sensors or other monitoring systems that track environmental factors at a cellular level. Additionally, the model may use publicly available datasets to train machine-learning algorithms.