The provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it is generally common practice in deep learning to divide the dataset into three subsets: training, validation, and testing.

The training set is used to train the model, the validation set is used for tuning hyperparameters and making decisions during the model building process, and the testing set is used to evaluate the model's performance.

In the context provided, it is mentioned that various data augmentation techniques were employed to expand the training dataset, including random adjustments to image size, image flipping, cropping, and conversion. The AIP-OD model was then trained using the Adam optimizer for 150 epochs with a batch size that gradually decreased. The experiments were conducted using Tensorflow 1.14 and executed on a GTX2080Ti GPU. However, the specifics of how the data was split into training, validation, and testing sets are not provided.

Therefore, while the context does not directly answer the query, it can be inferred that the dataset was likely split into these three subsets according to common deep learning practice.