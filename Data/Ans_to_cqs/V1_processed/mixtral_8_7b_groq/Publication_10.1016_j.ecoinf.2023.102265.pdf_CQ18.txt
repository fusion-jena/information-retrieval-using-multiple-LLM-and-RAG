The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that a 5-fold cross-validation method was used while training an SVM model with the extracted background features. This method involves dividing the dataset into five subsets or "folds" and training the model on four of these folds while validating it on the remaining fold. This process is then repeated five times, each time with a different fold used for validation, and the results are averaged to provide a more robust estimate of the model's performance.

Additionally, the context mentions that the training and validation of the classifier were run on a basic laptop using its CPU. This suggests that the model's performance was monitored in real-time on a local machine, allowing for easy observation of the model's behavior during training.

It is also worth noting that the authors compared the computational expense of their proposed method with softmax and found that their method was more efficient. This comparison suggests that the authors were attentive to the model's computational performance and likely monitored it during training to ensure that it was within acceptable limits.

Overall, while the specific strategy for monitoring the model performance during training is not explicitly stated, it can be inferred that the authors used a 5-fold cross-validation method and monitored the model's computational performance in real-time on a local machine.