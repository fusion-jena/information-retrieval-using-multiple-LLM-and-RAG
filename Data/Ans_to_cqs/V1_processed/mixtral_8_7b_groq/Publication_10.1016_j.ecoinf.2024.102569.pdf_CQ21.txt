Based on the provided context, there is no explicit mention of postprocessing steps such as saliency maps, metrics calculation, or confusion matrix. The text focuses on the process of training a point process model using a log-likelihood function and selecting tuning parameters using the root trimmed mean squared prediction error (RTMSPE).

However, in a general machine learning context, postprocessing steps after model training can include:

1. **Calculating Metrics**: After training a model, it's common to calculate various metrics to evaluate its performance. These metrics can include accuracy, precision, recall, F1 score, area under the ROC curve, etc., depending on the specific task and the nature of the targets and predictions.

2. **Creating Confusion Matrices**: A confusion matrix is a table that is often used to describe the performance of a classification model. It can help visualize the number of true positives, true negatives, false positives, and false negatives, from which other metrics can be derived.

3. **Generating Saliency Maps**: Saliency maps are a way to visualize the importance of different input features for a model's prediction. They can help in interpretability and understanding which features the model is focusing on.

Given the complexity of the model described in the context (a thinned PPP model with tuning parameters and a specific log-likelihood function), it's likely that similar postprocessing steps would be involved. However, the specifics would depend on the exact nature of the predictions and the tasks at hand.