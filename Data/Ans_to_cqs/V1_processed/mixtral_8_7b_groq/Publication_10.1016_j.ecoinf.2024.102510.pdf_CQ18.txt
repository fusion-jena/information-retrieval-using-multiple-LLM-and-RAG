The strategy implemented to monitor the model performance during training involves a two-stage approach using manual search and random search techniques for hyperparameter optimization.

In the first stage, manual search is employed to explore the hyperparameter space. An empty set, Smanual, is initialized to store the hyperparameter configurations. For each hyperparameter configuration h in the set M, a model is trained with those hyperparameters on the dataset D, and its performance is evaluated on dataset D to obtain a performance metric Φ(M, D). If this configuration yields the highest performance so far, it is added to Smanual. This process continues until a satisfactory level of model performance is achieved or a predetermined number of iterations have been executed.

The second stage involves random search, which samples a random subset of hyperparameters from the configurations identified in the manual search stage. An empty set, Srandom, is initialized to store these new hyperparameter configurations. For each configuration hrandom in Smanual, a model is trained with these hyperparameters on dataset D, and its performance is evaluated on dataset D to obtain a performance metric Φ(Smanual, D). If hrandom yields the highest performance so far, it is added to Srandom. This stage allows for a more thorough exploration of the hyperparameter space, focusing on the areas that showed promise in the manual search stage.

This two-stage approach enables the monitoring of model performance during training by continuously evaluating and comparing the performance of models trained with different hyperparameter configurations. The aim is to achieve the maximum possible accuracy through multiple iterations. The results of this experimental analysis revealed that the Fine-tuned EfficientNetB0 model exhibited superior performance, achieving an accuracy of 99.12%, while other models, such as ResNet18, underperformed in comparison.