The text does not explicitly mention any regularization methods like dropout or L2 regularization used to prevent overfitting in the deep learning pipeline. However, it discusses another technique called data augmentation which is also commonly used to combat overfitting. Data augmentation involves expanding the dataset by applying various transformations to the existing data, such as flipping, translation, and shear. These transformations help maintain dataset balance, reduce overfitting, and improve the generalization of deep learning models. In this particular case, horizontal and vertical translations were performed within a range of 30 to 30 pixels, allowing random shifts. Shear distortion was applied within a range of 5 to 5, representing maximum distortion to the left and right. As a result of these augmentations, the training dataset size increased from 11,788 to 40,000 images.