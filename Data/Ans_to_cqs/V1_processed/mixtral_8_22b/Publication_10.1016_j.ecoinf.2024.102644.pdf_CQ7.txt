The provided context does not explicitly mention the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it is common practice in machine learning and deep learning to randomly divide the dataset into three subsets: training, testing, and validation. Typically, around 60-80% of the data is allocated for training, while the remaining 20-40% is divided between testing and validation. The exact ratio depends on factors like the total amount of available data and the complexity of the problem being addressed.

In some cases, stratified sampling may also be employed when splitting the data. Stratified sampling ensures that each subset maintains the same class proportions as the original dataset. This approach is particularly useful when dealing with imbalanced datasets, which contain significantly more instances from one class compared to others.

Additionally, time series data might require different strategies for splitting the data, such as using a rolling window or expanding window method, due to temporal dependencies within the data.

However, without further information regarding the specific application or dataset mentioned in the provided context, I cannot provide a definitive answer about the criteria used to split the data for this particular case.