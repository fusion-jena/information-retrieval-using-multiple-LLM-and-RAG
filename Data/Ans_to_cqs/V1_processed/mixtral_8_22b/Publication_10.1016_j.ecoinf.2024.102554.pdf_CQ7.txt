The context does not explicitly mention the specific criteria used to split the data for deep learning model training (train, test, validation). However, it can be inferred that the data was collected over different years, ranging from 2002 to 2023, with various datasets available for analysis. Additionally, there are multiple sources of data, including ESA and NASA, which provide information on vital parameters like reflectance, Aerosol Optical Thickness (Kd940), and Chl-a concentrations.

Typically, when splitting data for deep learning models, one common approach is to use a random stratified sampling method based on time periods or other relevant factors. This ensures that the distribution of classes or features remains consistent across the training, testing, and validation sets. Another popular method is cross-validation, where the dataset is divided into k subsets, and the model is trained and tested k times, each time leaving out a different subset for evaluation.

Without explicit details about the specific criteria used in this case, we cannot definitively state how the data was split for deep learning model training. Nonetheless, based on general practices, it is likely that the data was partitioned using temporal or source-based criteria to maintain consistency and ensure robust model performance.