During the training process, the authors used a cross-validation approach called fivefold cross-validation. They divided their dataset into five equal parts, using four parts for training and the remaining part for validation. This process was repeated five times, ensuring that each subset served once as the validation set. By doing so, they aimed to reduce bias and variance in the final model.

Additionally, the authors calculated both unweighted and category-weighted classification accuracies for the training dataset. These metrics helped them evaluate the overall performance of the model across different sound categories. The reported average unweighted and category-weighted training classification accuracies were 98.9% and 97.4%, respectively. However, the actual training confusion matrix was not provided due to brevity considerations.

For the test dataset, the authors also computed unweighted and weighted accuracies, achieving 94.7% and 88.8%, respectively. Furthermore, they calculated F1-scores for both the training and testing datasets, resulting in.980 and.907, respectively. Lower testing accuracy scores were observed in certain categories, such as background noise and smaller classes with fewer training examples, like the squirrel "kuk" and the white-breasted nuthatch call.