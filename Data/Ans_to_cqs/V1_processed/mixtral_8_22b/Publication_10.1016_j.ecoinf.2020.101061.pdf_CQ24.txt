To address the issue of randomness in the deep learning pipeline, such as variations due to different random seed values, the authors conducted a sensitivity study. They trained their models using different proportions of training data, specifically selecting 5%, 25%, 50%, and 75% of the total hand-annotations to compare against the full dataset for within-site results at each site. To account for the random subsampling of annotations, they repeated this experiment five times. Additionally, they evaluated the performance of the pretraining model alone (i.e., without any hand-annotated data) to determine if adding hand-annotated data improved the within-site pretraining. However, the text does not explicitly mention specific strategies to control or manage the randomness caused by factors like random seed values.