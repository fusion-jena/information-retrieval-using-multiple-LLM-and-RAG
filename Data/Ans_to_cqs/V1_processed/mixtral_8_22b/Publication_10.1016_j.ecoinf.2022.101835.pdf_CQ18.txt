The authors have employed several strategies to monitor the performance of their machine learning models during training. They utilized various libraries like Scikit-learn, TensorFlow, Keras, and LightGBM to build their Random Forest (RF), Artificial Neural Network (ANN), and LightGBM models. To determine the optimal structure and hyperparameters for these models, they used Optuna, which is an open-source hyperparameter optimization framework. This allowed them to find the most suitable configurations for their models based on predefined parameters and ranges.

For evaluating the performance of the algorithms, the authors compared the loss functions (Mean Squared Error - MSE) of the optimized models. Additionally, they also computed Mean Absolute Error (MAE) and Coefficient of Determination (R^2) as references. After this, they calculated the Root Mean Square Error (RMSE) for all observation sites to assess the overall performance of the optimized models. Furthermore, they calculated the RMSE for each observation site individually to gauge the performance of the models for each specific location.

To understand the machine learning models better, the authors used SHAP (SHapley Additive exPlanations) values. These values help explain how much each feature contributes to the prediction made by the model. By calculating the average of the absolute SHAP values for each input variable, they could identify the importance of different variables in predicting the first flowering and full blossom dates.

Overall, the authors have adopted a comprehensive approach to monitoring the performance of their machine learning models during training. They have used multiple evaluation metrics, tuned hyperparameters using Optuna, and leveraged SHAP values to gain insights into the significance of individual features in making predictions.