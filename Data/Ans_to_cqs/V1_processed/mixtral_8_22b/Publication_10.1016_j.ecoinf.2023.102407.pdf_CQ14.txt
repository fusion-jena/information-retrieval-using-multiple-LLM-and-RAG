The text does not provide explicit information about how the hyperparameters of the model were optimized. However, it mentions that the hyperparameters were set up as in Bean et al. (2012), which suggests that they might have been optimized using a method similar to what was used in that paper. Without access to the full content of Bean et al. (2012), I cannot confirm this assumption. Nevertheless, common methods for hyperparameter optimization include grid search, random search, Bayesian optimization, and gradient-based optimization. Grid search involves trying all possible combinations of hyperparameters within a predefined range, while random search randomly samples from the same space. Bayesian optimization uses a probabilistic approach to find the optimal parameters, and gradient-based optimization leverages gradients to iteratively update the hyperparameters.