Based on the given context, it does not provide explicit information about the specific preprocessing steps used before training the deep learning models. However, common practices in preparing data for deep learning include normalization, scaling, and cleaning. Normalization involves rescaling the values of features so they fall within a certain range, often between 0 and 1 or -1 and 1. This helps prevent any single feature from dominating the others due to its scale. Scaling is similar to normalization but focuses more on adjusting the range of numerical values to avoid issues caused by large differences in magnitudes. Cleaning refers to handling missing or inconsistent data points, such as removing them entirely or imputing their values based on available information. In this case, since the study uses audio signals, additional preprocessing might involve converting raw audio files into spectrograms or Mel-frequency cepstrum coefficients (MFCCs) to better represent the frequency content of the sounds.