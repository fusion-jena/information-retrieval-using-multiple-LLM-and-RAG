The given text does not provide information about the specific hardware resources used for training the deep learning model. It discusses various aspects of the model architecture, including the use of wide residual networks, ReLU activation functions, and the application of techniques like batch normalization and L1 regularization. However, it does not mention any details regarding the type or configuration of hardware resources employed during the training process. Therefore, based on the provided context, it is not possible to determine whether GPUs, TPUs, or other types of hardware were utilized for training the deep learning model.