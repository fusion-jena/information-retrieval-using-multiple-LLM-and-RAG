The provided context does not explicitly mention the specific hardware resources used for training the deep learning models. However, there are some clues about the hardware used in the overall setup. For instance, the text mentions using off-the-shelf components like Raspberry Pi, PiCamera, routers, switches, PCs, and graphics cards to build the system. Additionally, the authors state that they used open free and open source software, which often benefits from GPU acceleration for faster computation. Given these points, it is reasonable to infer that the team might have employed GPUs for training their deep learning models, considering the widespread usage of GPUs in machine learning tasks due to their parallel processing capabilities. Nevertheless, without explicit information regarding the hardware resources used specifically for training the deep learning models, it remains uncertain whether the team utilized GPUs, TPUs, or any other specialized hardware.