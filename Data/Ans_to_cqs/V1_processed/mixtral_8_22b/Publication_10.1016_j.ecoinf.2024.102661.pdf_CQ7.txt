Based on the given context, there isn't any explicit information about the criteria used to split the data for deep learning model training (e.g., train, test, validation). However, it can be assumed that common practices were followed such as splitting the data into training, testing, and validation datasets. Typically, this division is done randomly or using stratified sampling techniques to maintain class balance if dealing with classification problems. In some cases, temporal or spatial partitioning might be applied depending on the nature of the problem. For instance, when working with time series data, one could use a sliding window technique to create overlapping segments for training and testing purposes. Nevertheless, without specific details from the context, these assumptions remain speculative.