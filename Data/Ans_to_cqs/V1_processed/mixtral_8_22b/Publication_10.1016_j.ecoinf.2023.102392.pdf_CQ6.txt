Before training a deep learning model, several preprocessing steps can be applied to improve its performance. These include:

1. Data Cleaning: This involves removing any irrelevant, redundant, or incorrect information from the dataset. It also includes handling missing values if present.

2. Normalization: This process scales numeric columns to a similar range, typically between 0 and 1. It helps prevent attributes with larger ranges from dominating those with smaller ranges during the learning process.

3. Scaling: Similar to normalization, scaling transforms features so they have a standard scale. Common methods include Min-Max scaling and Standardization.

4. Feature Selection: This involves selecting a subset of relevant features for use in model construction. It reduces overfitting and improves model interpretability.

5. Encoding categorical variables: Deep learning models cannot handle non-numeric input directly. Therefore, categorical variables need to be converted into numerical form. Techniques like label encoding and one-hot encoding can be used.

However, based on the given context, it does not explicitly mention the preprocessing steps taken before training their deep learning model. But generally, these are common practices when preparing datasets for deep learning tasks.