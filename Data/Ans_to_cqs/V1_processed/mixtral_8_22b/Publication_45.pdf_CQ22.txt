The performance of the deep learning model was evaluated using several metrics due to the imbalance in the class distribution of the data. Accuracy, defined as the ratio of correct classifications to the total number of examples, was considered to have limited value as an evaluation metric because of this imbalance. Therefore, additional metrics such as precision, recall, and the F1 score were also calculated. Furthermore, Conditional Kappa and the True Skill Statistic were employed, both ranging from -1 to +1, where +1 indicates perfect agreement with test data and values greater than 0 indicate better performance than random. These metrics provide a more comprehensive understanding of the model's performance beyond simple accuracy.