Based on the provided context, there isn't any explicit mention of specific optimization techniques used in the deep learning pipeline such as Stochastic Gradient Descent (SGD), Adam, etc. However, the text mentions the use of the Apriori algorithm, which is a classic algorithm used in data mining for finding frequent item sets and association rules. It doesn't directly relate to optimization techniques used in deep learning pipelines like SGD or Adam.

Moreover, the context discusses the concept of 'pruning', which is a data compression technique used in machine learning and search algorithms to reduce the size of decision trees by removing non-critical and redundant parts of the tree. While this could be considered a form of optimization, it is not one of the commonly referred optimization techniques used in deep learning pipelines like SGD or Adam.

Therefore, based on the provided context, I cannot provide a direct answer regarding what optimization techniques are applied in the deep learning pipeline.