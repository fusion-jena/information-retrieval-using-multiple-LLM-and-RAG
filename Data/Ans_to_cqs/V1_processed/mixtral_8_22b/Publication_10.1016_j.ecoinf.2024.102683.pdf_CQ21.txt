After the model training process, there are several postprocessing steps that can be taken to evaluate and analyze the performance of the trained model. Based on the given context, it appears that the authors have conducted some of these steps.

One common postprocessing step is calculating various performance metrics, which help assess the effectiveness of the model. From the context, it is clear that the authors calculated several performance metrics, including accuracy, precision, recall, specificity, and F1-score. These metrics provide insights into how well the model performs in classifying medicinal and poisonous plants.

Additionally, the authors also seem to have created confusion matrices, although they are not explicitly mentioned. This can be inferred from their comparison of different models using various performance metrics, which typically involves creating confusion matrices to calculate those metrics.

However, there is no mention of saliency maps in the provided context. Saliency maps are visualizations that highlight important regions in input images that contribute significantly to the model's predictions. They can be useful for understanding what parts of the image the model focuses on while making its decisions. It is possible that the authors did not create saliency maps or simply did not discuss them in the given context.

In summary, based on the provided context, the postprocessing steps involved after the model training include calculating performance metrics like accuracy, precision, recall, specificity, and F1-score, and possibly creating confusion matrices. There is no explicit mention of generating saliency maps.