The provided context does not directly discuss the use of specific methods for collecting raw data in a deep learning pipeline. However, it does mention some aspects related to data collection in the context of environmental studies. In this case, the researchers conducted four field campaigns to collect water samples from different locations. They used clean polyethylene bags to gather surface water samples and transport them to the lab for further analysis. Additionally, they employed optical measurements and analysis techniques to retrieve information about total suspended matter (TSM), chlorophyll-a concentration, and other parameters. While these methods may not be directly applicable to a deep learning pipeline, they demonstrate how researchers can collect and process real-world data for analysis.

In general, when working with deep learning pipelines, common methods for collecting raw data include:

1. Sensors and IoT devices: These tools can capture real-time data from various sources such as cameras, microphones, temperature sensors, or GPS devices. For example, autonomous vehicles rely heavily on sensor data to navigate and make decisions.
2. Public datasets: Many organizations and institutions provide open access to pre-existing datasets that can be used for training and testing machine learning models. Examples include ImageNet for image classification tasks, UCI Machine Learning Repository for various types of datasets, and Google's Dataset Search tool for discovering relevant datasets.
3. Surveys and questionnaires: Collecting human input through surveys or questionnaires is another way to generate labeled data for supervised learning tasks. Platforms like Amazon Mechanical Turk allow researchers to crowdsource labeling tasks to a large pool of workers.
4. Web scraping: Extracting structured data from websites can also serve as a valuable source of information for certain applications. Tools like Beautiful Soup and Scrapy help automate the web scraping process.