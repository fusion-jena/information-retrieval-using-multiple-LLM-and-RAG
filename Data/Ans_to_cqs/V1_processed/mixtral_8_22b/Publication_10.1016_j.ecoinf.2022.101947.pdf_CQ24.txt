The context does not directly address the specific strategies used to handle randomness in the deep learning pipeline, such as managing random seed values. However, it does discuss a methodology used to manage randomness in the process of determining the optimal number of footprint trails needed for algorithm training and testing sets. This method involves using a holdback trial partitioning test on training sets for 44 captive Amur tigers, which is iterated 10 times for each combination of test/training size with randomly selected trails. This approach allows for examining how the predicted outcome compares with the known test set size, providing insights into the impact of randomness on the results. While this strategy is specific to the given context, it illustrates a broader principle applicable to handling randomness in machine learning pipelines - namely, employing repeated trials with different random seeds or sampling methods to understand the variability and robustness of the models.