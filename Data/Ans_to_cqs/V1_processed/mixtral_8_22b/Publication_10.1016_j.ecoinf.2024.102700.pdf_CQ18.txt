Based on the given information, it appears that various methods have been employed to validate and measure the performance of models. These include internal validation strategies, external validation methods, and ensemble approaches. However, there are also instances where no explicit validation method has been stated or used.

For internal validation strategies, techniques such as cross-validation or bootstrapping might be applied. External validation involves testing the model with independent data sets that weren't part of the initial training process. This can provide insights into how well the model generalizes beyond its original scope.

Ensemble approaches combine multiple models to improve overall prediction accuracy. They leverage the strengths of individual models while mitigating their weaknesses.

However, the specific strategy implemented to monitor the model performance during training isn't explicitly mentioned in the provided context. Therefore, without additional details, it's challenging to pinpoint the exact strategy used for monitoring model performance during training.