The given context does not provide explicit information about the postprocessing steps involved after the model training. However, it can be inferred from general machine learning practices that some common postprocessing steps include metrics calculation, confusion matrix generation, saliency map creation, and model optimization.

Metrics calculation involves evaluating the performance of the trained model using various measures such as accuracy, precision, recall, F1 score, ROC curve, etc. These metrics help assess how well the model has learned from the training data and its ability to predict new instances accurately.

A confusion matrix is another useful tool for understanding the performance of a classification model. It provides a summary of prediction results on a classification problem by displaying the number of true positives, false negatives, false positives, and true negatives. This visual representation helps identify any patterns or trends in misclassifications made by the model.

Saliency maps are often used with convolutional neural networks (CNNs) to highlight important features contributing to the final output. They show which parts of an input image have the most significant impact on the network's decision-making process. By analyzing these heatmaps, researchers can gain insights into what aspects of the images are essential for accurate predictions.

Model optimization techniques like hyperparameter tuning and regularization methods may also be applied during postprocessing to improve the overall performance of the trained models further. Hyperparameters refer to parameters whose values need to be determined before starting the learning process, while regularization methods aim to prevent overfitting by adding penalties to large weights in the model.

In conclusion, although the given context lacks specific details regarding postprocessing steps, typical procedures involve metric calculations, generating confusion matrices, creating saliency maps, and optimizing models through hyperparameter tuning and regularization techniques.