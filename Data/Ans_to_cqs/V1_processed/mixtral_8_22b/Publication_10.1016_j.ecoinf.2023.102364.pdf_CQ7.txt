The text does not provide explicit information about how the data was split for deep learning model training into categories such as train, test, and validation sets. However, it mentions using machine learning ensembles and provides several figures related to model diagnostics, which suggests that some form of splitting or cross-validation may have been employed during the modeling process. Common practices include randomly dividing the dataset into training, testing, and validation subsets, with typical ratios being around 70%, 15%, and 15%, respectively. Another approach could be k-fold cross-validation, where the original sample is randomly partitioned into k equal sized subsamples. Of these k subsamples, one subsample is retained as the validation data for testing the model, while the remaining kâˆ’1 subsamples are used as training data. This process is repeated k times, with each of the k subsamples used exactly once as the validation data. The results from all k trials are then averaged to produce a single estimation. Without further specifications, we cannot determine the exact methodology used for this study.