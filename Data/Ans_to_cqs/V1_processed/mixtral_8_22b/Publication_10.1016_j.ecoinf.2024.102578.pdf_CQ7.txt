Based on the given context, it does not explicitly state how the data was split for deep learning model training (i.e., into train, test, or validation sets). However, it can be inferred from common practices in machine learning that some form of splitting would have been applied. Typically, datasets are divided into three parts: training, testing, and validation sets. The training set is used to fit the model, while the testing set is used to evaluate its performance. The validation set is often used during hyperparameter tuning to prevent overfitting. In this case, the authors mention using a separate dataset for testing the model's performance (Table 5), which suggests they likely followed these standard practices. However, without explicit information about the exact methodology used for splitting the data, we cannot provide a definitive answer.