Based on the given context, the exact criteria for determining when training is complete are not explicitly stated. However, since the study uses the XGBoost model, which is a type of gradient boosting machine, it can be inferred that the training process continues until a certain number of trees or rounds are built, or until the improvement in the evaluation metric becomes negligible. This is because XGBoost models work by building new trees that predict the residuals of the preceding ones, gradually improving the overall prediction accuracy. Therefore, the training could stop when adding more trees no longer significantly improves the model's performance. Additionally, early stopping techniques might also be employed to prevent overfitting, where the training stops if the validation score doesn't improve after a set number of rounds.