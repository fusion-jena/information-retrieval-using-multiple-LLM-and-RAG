During the training process, a strategy called early stopping is employed to monitor the model performance. Early stopping is designed to prevent overfitting by halting the learning process when there is no further improvement in accuracy after a certain number of epochs. Specifically, in this case, the learning process will stop if there is no improvement in accuracy after 20 epochs out of the total 100 epochs used for training. Additionally, the cross-entropy loss function is utilized to measure the difference between the actual and predicted outputs, providing another metric to evaluate the model's performance.