From the given context, it appears that there isn't explicit mention of specific measures taken to ensure the generalizability of the deep learning model such as using diverse datasets, cross-validation, or stratified splitting. However, some aspects related to ensuring robustness can be observed.

Firstly, the study considered multiple datasets, including those containing vocalizations of Hainan gibbons, which varied in duration from 2 to 9 seconds. This suggests that the researchers aimed to include diverse data sources to improve the applicability of their findings.

Secondly, the use of pre-trained networks like ResNet50, which had been trained on large image databases like ImageNet, indicates that transfer learning was employed. Transfer learning allows leveraging knowledge gained from solving one problem to another related problem, thereby improving the performance and generalization capabilities of the new model.

Thirdly, the table comparing the average F1 scores across different network architectures and dataset configurations shows that the results were averaged across 13 unique executions. While this does not directly indicate cross-validation or stratified splitting, it implies that multiple runs were conducted to assess the consistency and reliability of the model's performance.

Lastly, the authors acknowledge the challenges associated with creating and utilizing convolutional neural networks (CNNs) for bioacoustic research questions, including finding the most optimal model through hyperparameter tuning. Although no direct evidence of cross-validation or stratified splitting is mentioned, addressing these issues contributes to building a more robust and reliable model.