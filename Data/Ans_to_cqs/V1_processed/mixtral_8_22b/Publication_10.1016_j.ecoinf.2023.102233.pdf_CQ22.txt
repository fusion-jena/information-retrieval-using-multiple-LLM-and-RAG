In the given context, it is mentioned that the CNN model performance was evaluated using macro-averaged Mean Absolute Error (MAE). This metric was used to measure the difference between the predicted values and actual values, providing insights into the overall performance of the model. However, due to the class imbalance issue in the evaluation data, a random selection approach was employed that was stratified across the model's predictions (logits). This approach helped reduce class imbalance but altered the distribution of data, making it difficult to generalize evaluation metrics to the unlabelled data. Therefore, additional research is required to investigate more appropriate evaluation methods for highly imbalanced and unlabelled test data. It should be noted that other common evaluation metrics such as accuracy, precision, recall, and F1 score were not explicitly mentioned in the provided context.