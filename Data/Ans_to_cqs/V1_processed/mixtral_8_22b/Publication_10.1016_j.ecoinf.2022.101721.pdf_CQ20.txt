The given context does not provide information about the specific hardware resources used for training the deep learning models mentioned in the text. However, it is common practice in the field of machine learning and artificial intelligence to use Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) for training deep learning models due to their ability to perform parallel computations efficiently. These specialized processors accelerate the training process by processing multiple calculations simultaneously, making them well suited for handling large datasets and complex neural networks. Therefore, while the exact hardware resources used for training the deep learning models discussed in the context are unknown, it is likely that they utilized either GPUs or TPUs.