The article does not provide specific information about the hardware resources used for training the deep learning models. It only mentions that choosing appropriate training times for different models is beneficial to save computing resources. However, it does not specify what type of computing resources were utilized during the training process. Typically, deep learning models are trained using high-performance computing devices such as Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). These specialized hardware accelerators enable faster computation and reduce training time compared to traditional Central Processing Units (CPUs). Without explicit mention in the given context, one cannot definitively state which hardware resources were used for training the deep learning models in this particular study.