Based on the given context, there isn't explicit information about the specific criteria used to determine when training is complete for the XGBoost models. However, generally speaking, common criteria used to determine when training is complete include reaching a certain number of epochs or iterations, achieving a desired level of performance on a validation set, or observing a plateau in the validation loss. In this case, since the context mentions the use of a test dataset for validation, it can be inferred that the training process might have been stopped once a satisfactory level of performance was achieved on the validation set. This could mean that the training was halted when the validation loss reached a minimum value or stopped decreasing significantly, indicating that further training would not improve the model's performance.