Unfortunately, there isn't enough information available from the given context to provide a detailed explanation about the deployment process of the trained deep learning model. However, based on common practices in machine learning projects, we can infer some possible steps that might have been taken during this phase.

After training the final CNN architecture, the next step would be to save or serialize the model so that it can be deployed for making predictions on new data. This could involve saving the model's structure, learned weights, and other relevant metadata into a file format like.h5 (HDF5) or.pkl (Pickle) if Python programming language was used.

Once the model is saved, it needs to be integrated into a suitable platform or application where it can receive inputs, perform predictions, and return outputs. Depending on the use case, this could range from integrating the model into a web application, mobile app, IoT device, or cloud service. For instance, platforms like TensorFlow Serving, AWS SageMaker, Google Cloud AI Platform, or Microsoft Azure Machine Learning Studio could be considered for deploying the model.

However, without specific details regarding the project requirements, target environment, and constraints, it is not feasible to determine the exact methodology employed for deploying the trained deep learning model.