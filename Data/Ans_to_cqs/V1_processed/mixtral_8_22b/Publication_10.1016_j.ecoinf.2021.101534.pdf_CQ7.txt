Unfortunately, based on the given information, there isn't any explicit mention of how the dataset was divided into training, testing, or validation sets for the deep learning model. However, typically, datasets are randomly partitioned into three subsets: training set, validation set, and test set. The training set is used to fit the model; the validation set is used to provide an unbiased evaluation of the model while tuning its hyperparameters; and the test set provides a final assessment of the generalization ability of the trained model. In this case, since no specific details were mentioned about these splits, one can assume that a common approach might have been followed.