The hyperparameters of the model are optimized using various approaches such as Grid Search, Random Search, Hyperband, and Bayesian Optimization. In this particular study, three popular hyperparameter optimization approaches were employed: Random Search, Hyperband, and Bayesian Optimization. Each method has its own strengths and weaknesses.

Random Search (RS) is a simple and effective optimization approach that selects and evaluates a set of hyperparameters randomly to find the set with the best accuracy. Although RS can provide the largest architecture with many hidden layers, it requires additional time to randomly identify the best hyperparameter combination.

Hyperband is another optimization method that improves classification accuracy but involves making several assumptions about resource allocation that may only hold in certain scenarios. In this study, Hyperband was found to be the most efficient method, having the lowest computation time compared to the other methods.

Bayesian Optimization provides a systematic approach towards hyperparameters tuning by modeling the relationship between hyperparameters and performance metrics. However, it can be computationally expensive and may not always converge to the global optimum.

In summary, the hyperparameters of the model are optimized using different approaches depending on the specific requirements and constraints of the application. Random Search, Hyperband, and Bayesian Optimization are all popular methods for hyperparameter optimization, each with their own advantages and disadvantages.