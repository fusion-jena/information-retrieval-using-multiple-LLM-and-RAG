To monitor the model performance during training, the authors employed various strategies. They tracked the loss value throughout the training process, observing its reduction from an initial state to around 0.54%, indicating that the model was learning effectively from the training data. Additionally, they evaluated the model's precision, recall, and mean average precision (mAP), noting improvements until approximately 1000 iterations, after which the model began to plateau. This suggests that monitoring these metrics helped determine the optimal point to stop training and prevent overfitting. Furthermore, the authors utilized a validation set to assess the model's generalization capabilities, ensuring that it did not become too specialized to the training data. Lastly, they experimented with different hyperparameter configurations, such as varying the number of epochs and learning rate, to find the best combination for maximizing model performance.