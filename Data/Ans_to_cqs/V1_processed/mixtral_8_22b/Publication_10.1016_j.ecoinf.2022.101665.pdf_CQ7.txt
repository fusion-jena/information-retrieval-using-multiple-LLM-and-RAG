In machine learning, when data is abundant, it is common practice to randomly divide the entire dataset used for modeling into three distinct sets: a training set, a validation set, and a test set. Each set serves its own unique purpose during the process of building and evaluating a predictive model.

The training set is utilized to fit the models, meaning that the algorithm learns patterns within the data based on the input features and corresponding output labels. It essentially teaches the model how to make predictions.

The validation set is employed to estimate prediction errors for model selection and hyperparameter tuning. Hyperparameters are parameters whose values are set before the commencement of the learning process. By comparing the performance of various models with different hyperparameters on the validation set, one can select the best combination of hyperparameters that results in optimal performance.

Lastly, the test set is reserved for assessing the accuracy of the final model. After selecting the most suitable model and optimizing its hyperparameters using the training and validation sets respectively, the test set provides an unbiased evaluation of the modelâ€™s ability to generalize to new, unseen data.

However, there may be instances where data availability is limited, making it challenging to allocate a separate test set. In such cases, resampling methods like k-fold cross-validation are employed. K-fold cross-validation involves splitting the full dataset into 'k' approximately equal-sized disjoint subsets or folds. The model is then trained on 'k-1' folds, while the remaining fold is used for assessing prediction accuracy. This process is repeated 'k' times, each time with a different fold serving as the test set. The overall cross-validation accuracy is estimated by aggregating the squared residuals over the 'k' folds.