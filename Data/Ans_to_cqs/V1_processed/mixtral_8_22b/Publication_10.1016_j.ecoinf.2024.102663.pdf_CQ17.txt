The text does not explicitly mention any regularization methods used to prevent overfitting in the deep learning pipeline. However, it does discuss the use of Lasso and Ridge regression models, both of which incorporate regularization terms into their loss functions to reduce overfitting. Lasso uses L1 regularization, while Ridge uses L2 regularization. These methods help to shrink the coefficients of the features, making them more generalizable and reducing the risk of overfitting. Additionally, the Random Forest Regressor mentioned in the text also helps to prevent overfitting through ensemble learning, combining multiple decision trees to create a more robust and accurate prediction model.