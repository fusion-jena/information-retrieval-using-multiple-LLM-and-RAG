The text does not explicitly mention any specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, there are some hints about how the authors might have dealt with data imbalance.

Firstly, the authors mention using larger batches, which they suggest may be more representative of the intra-class variability, allowing the network to focus on inter-class variance. This could potentially help mitigate the effects of class imbalance.

Secondly, the authors discuss using different patch sizes for their images. They found that a patch size of 224 x 224 pixels performed the best, as it included enough contextual noise to regularize overfitting and enable better generalization. This suggests that the authors may have been trying to find a balance between providing enough contextual information without overwhelming the model with unnecessary detail.

Lastly, the authors mention applying data augmentation to all patches, including random rotations, brightness scaling, and horizontal/vertical flipping. This technique can help increase the diversity of the training data and reduce overfitting, especially in cases where there is a high class imbalance.

Overall, while the authors do not explicitly state that they used techniques like stratified splitting, oversampling, undersampling, or diverse data collection, they do describe several strategies that could potentially help address data bias and imbalance in their deep learning pipeline.