The authors took several measures to ensure the generalizability of their deep learning model. They used a diverse dataset consisting of images captured under various conditions and scenarios. This helped to prevent overfitting and improve the robustness of the model. Additionally, they employed cross-validation techniques during training to further reduce the risk of overfitting and enhance the model's ability to perform well on unseen data. Furthermore, stratified splitting was utilized when dividing the dataset into training, validation, and testing sets. This ensured that each set contained a representative distribution of classes, which is crucial for maintaining the balance between different categories and preventing any class imbalance issues. Overall, these strategies contributed to creating a more reliable and accurate deep learning model capable of handling real-world applications with greater confidence.