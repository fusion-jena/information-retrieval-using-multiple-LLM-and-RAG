Based on the given context, there isn't any direct mention or discussion about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, some common techniques used to handle data bias include stratified sampling, oversampling, undersampling, and diverse data collection.

Stratified sampling involves dividing the dataset into different subsets based on certain criteria, like classes or labels, before splitting them into training and testing sets. This ensures that each subset has equal representation in both sets, reducing potential biases caused by imbalanced classes.

Oversampling and undersampling are methods used to balance datasets containing unequal distributions of classes. Oversampling increases the minority class samples by duplicating existing instances or creating synthetic ones, while undersampling reduces majority class samples by randomly removing instances. Both techniques aim to achieve balanced datasets, improving model performance and generalizability.

Diverse data collection focuses on gathering various types of data from multiple sources to ensure broad coverage of possible scenarios and reduce biases introduced by limited perspectives. By incorporating diverse data, models can better capture underlying patterns and trends, leading to improved accuracy and reliability.

In summary, although not directly mentioned in the provided context, commonly employed techniques to tackle data bias during preprocessing of deep learning pipelines include stratified sampling, oversampling, undersampling, and diverse data collection. Each technique addresses specific aspects of data imbalance and diversity, contributing to enhanced model performance and robustness.