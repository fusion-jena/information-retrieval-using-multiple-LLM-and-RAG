To deploy the trained deep learning model, the following process was followed:

Firstly, the trained models were converted into the TensorFlow Lite version using the TensorFlow Lite converter. This step was necessary because TensorFlow Lite is a set of tools designed to perform deep learning on smartphones and Internet of Things (IoT) devices.

After conversion, the models were integrated into a mobile application developed using Android Studio. The architecture of the mobile app is depicted in Figure 4. The app includes a TensorFlow Lite interpreter for the TensorFlow Lite model, which enables the app to utilize the trained model for making predictions.

For testing the application, two options were available. One option was to use the built-in phone emulators provided by Android Studio. Alternatively, the app could be deployed to an actual device. In either case, the goal was to ensure that the app functioned correctly and provided accurate predictions when presented with real-world data.

In summary, the process involved converting the trained models to TensorFlow Lite format, integrating them into a mobile application, and then testing the application using either built-in phone emulators or an actual device.