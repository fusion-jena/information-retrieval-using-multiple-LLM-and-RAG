Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does state that the training set must be normalized and standardized before fitting into the network. Normalization and standardization are common techniques used in preprocessing to ensure that all features contribute equally to the model and prevent biases due to different scales or ranges of values. These methods do not directly address class imbalance but help in scaling the input features to improve the performance of the model. Therefore, while the text does not provide information about addressing data bias through techniques like stratified splitting, oversampling, undersampling, or diverse data collection, it does indicate the use of normalization and standardization for preprocessing the dataset.