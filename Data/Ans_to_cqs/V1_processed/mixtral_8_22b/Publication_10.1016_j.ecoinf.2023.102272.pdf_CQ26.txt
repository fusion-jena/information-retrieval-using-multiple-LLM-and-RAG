In the given context, there is no explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, some general practices can be inferred from the information provided.

Firstly, it appears that the authors have employed stratified sampling when dividing their data into different partitions (At, Av, Bt, and Bv). This technique ensures that each partition maintains the same proportion of classes as the original dataset, which helps prevent class imbalance issues.

Secondly, although not explicitly stated, the use of diverse data collection could potentially contribute to addressing data bias. By collecting data from various sources, the risk of overfitting to a particular type of data or source is reduced, leading to more robust and unbiased models.

Lastly, while not mentioned in this context, other common techniques to handle data bias include oversampling and undersampling methods. Oversampling involves duplicating examples from the minority class, whereas undersampling removes instances from the majority class. These techniques help balance datasets with significant class imbalances, reducing potential biases towards the dominant class.

However, without further details regarding the nature of the data and any potential biases present, it is difficult to provide a definitive list of techniques used to address data bias in this study.