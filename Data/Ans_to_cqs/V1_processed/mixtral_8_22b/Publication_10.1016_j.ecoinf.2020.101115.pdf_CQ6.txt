The sources provided do not directly address the specific preprocessing steps involved before training a deep learning model such as normalization, scaling, or cleaning. However, they discuss various aspects related to data handling and processing in marine science and fisheries research.

In general, preprocessing steps depend on the nature of the data and the requirements of the machine learning algorithm used. Common preprocessing techniques include data cleaning (removing missing values, outliers, or irrelevant information), normalization (scaling numerical input features to a standard range), and encoding categorical variables into numerical form. These steps help improve the performance and efficiency of the deep learning models by reducing noise, improving convergence speed, and preventing overfitting.

While these sources do not explicitly mention preprocessing steps for deep learning models, they emphasize the need for adherence to FAIR (Findable, Accessible, Interoperable, and Reusable) data principles in managing and sharing scientific datasets. They also highlight the development of systems and workflows for integrating different types of data, including those obtained from routine sampling and research activities. Therefore, it can be inferred that proper data preprocessing would play a crucial role in ensuring the quality and usability of datasets in marine science and fisheries research.