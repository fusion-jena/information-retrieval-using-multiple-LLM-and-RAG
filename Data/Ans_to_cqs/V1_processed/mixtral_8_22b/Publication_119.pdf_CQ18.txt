Based on the given context, there are several strategies implemented to monitor the model performance during training. For the Deep Neural Network (DNN) model, dropout and batch normalization layers were added to reduce overfitting and increase generalization on testing data. Furthermore, hyperparameters like learning rate, number of epochs, and batch size were tuned to achieve the best testing accuracy and kappa score. Specifically, the optimized hyperparameter values for learning rate and batch size were 0.007 and 48, respectively.

For the Support Vector Machine (SVM) model, the RBF kernel was used, requiring tuning of two parameters - C and γ. A smaller C value would result in a wider margin but lower accuracy, while a larger γ value would lead to overfitting on the training data and poor generalization on the testing data. The best values for C and γ were optimized using GridSearchCV and found to be 1000 and 1, respectively.

In the case of the Random Forest (RF) algorithm, multiple decision trees were constructed, each predicting a class using different training data subsets selected through repetition and replacement of the original training dataset. This process creates a 'bagged' dataset for each decision tree within the random forest.

Lastly, for the U-Net model, hyperparameter tuning was performed to select the best model. It was found that the best model uses an input patch size of 64 x 64 pixels and a ResNet-50 backbone.