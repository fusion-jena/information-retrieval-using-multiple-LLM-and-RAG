In the provided context, there isn't explicit information about the specific criteria used to determine when training is complete. However, it does mention the importance of model validation and performance evaluation in modeling tasks.

Model validation typically involves setting aside a portion of the available data (usually around 30%) to evaluate the trained model's performance. This process can provide insights into whether the model has been adequately trained or if further adjustments are needed.

One common criterion used to assess the completion of training is the observation of a validation loss plateau. When the validation loss stops improving significantly after several epochs, this may indicate that the model has learned all it can from the training data and no longer benefits from additional training. At this point, the training could be considered complete.

Additionally, the context mentions the use of Area Under Receiver Operating Characteristic Curve (AUC), True Skill Statistic (TSS), and Kappa coefficient as performance evaluation metrics for comparing the accuracy or performance of different models. These metrics can also serve as indicators of how well the model has been trained and whether further training is necessary.

However, without more specific details regarding the training process mentioned in the context, it is not possible to definitively state what criteria are being used to determine when training is complete.