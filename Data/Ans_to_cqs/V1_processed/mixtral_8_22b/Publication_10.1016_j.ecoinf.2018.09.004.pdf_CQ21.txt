After the model training process, several postprocessing steps can be performed depending on the specific requirements of the task or project. Some common postprocessing steps include:

1. Model Evaluation: The trained models need to be evaluated using appropriate metrics such as accuracy, precision, recall, F-score, etc. These metrics help assess the performance of the models and compare them against other models or baselines. For example, in this case, the authors evaluate their models using stratified cross-validation and report the results in terms of precision, recall, and F-measure. They also explain why accuracy might not be a suitable metric due to the imbalanced nature of the dataset.

2. Visualizing Results: Another important aspect of postprocessing involves visualizing the results obtained from the models. This could involve generating saliency maps, confusion matrices, ROC curves, etc. These visualizations provide insights into the strengths and weaknesses of the models and help identify areas where improvements can be made. However, there is no mention of these types of visualizations being generated in this particular study.

3. Parameter Tuning: Postprocessing often includes fine-tuning the parameters of the models to improve their performance further. This could involve adjusting hyperparameters like learning rate, regularization strength, batch size, etc. Again, there is no explicit mention of parameter tuning being carried out in this study.

In summary, some possible postprocessing steps after model training include evaluating the models using appropriate metrics, visualizing the results, and fine-tuning the parameters. However, the exact set of postprocessing steps will depend on the specific needs and goals of the project.