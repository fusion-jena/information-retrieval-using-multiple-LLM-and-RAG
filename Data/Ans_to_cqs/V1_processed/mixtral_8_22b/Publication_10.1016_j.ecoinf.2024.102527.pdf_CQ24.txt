Based on the given context, there is no explicit mention of any specific strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, it does provide information about the overall methodology used for training and testing the deep learning models.

The authors use Stochastic Gradient Descent (SGD) as their optimizer with a momentum value of Î¼ = 0.9. This implies that they might be utilizing some form of randomness during the training process. Additionally, they divide their datasets into training, validation, and test sets, which could also introduce some level of randomness due to the selection process.

However, without further context or additional information regarding the implementation details, it is not possible to definitively state what strategies, if any, have been employed to manage randomness in the deep learning pipeline.