The strategy implemented to monitor the model performance during training involved performing data validation on the captive Amur tiger dataset. This was done to determine the optimal number of footprint trails required for the algorithm training set and test sets that could provide an accurate population estimate. A holdback trial partitioning test was conducted on training sets for 44 captive Amur tigers. The analysis was iterated 10 times for each combination of test/training size, with randomly selected trails, to examine how the predicted outcome compared with the known test set size. The results showed that the mean of the predicted test set size diverged from the actual test set size. Optimal classification accuracy was obtained when the test set size was smallest relative to the training set. Even when the test to training set ratio was 32:12, the predicted value was close to the expected value, demonstrating the robustness of the model.