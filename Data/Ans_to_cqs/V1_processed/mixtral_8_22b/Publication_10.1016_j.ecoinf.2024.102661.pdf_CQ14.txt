The hyperparameters of the model are optimized using the Tree Parzen Estimator Bayesian Optimization (TPEBO) algorithm. This algorithm begins with an exploratory phase of random searches for feasible hyperparameter configurations. It then progressively narrows down its focus to zones within the search space where a local optimum is identified, thereby approximating the global optimum with increasing precision. This methodological approach is particularly beneficial for fine-tuning Long Short-Term Memory (LSTM) models, known for their intricate structures. By automating the hyperparameter adjustment process, TPEBO not only enhances the model's efficiency but also significantly curtails the time traditionally spent on manual tuning, making the modeling workflow more efficient.

The TPEBO method utilizes a probabilistic model based on a formal representation given by Eq. (3), which guides the identification and selection of optimal hyperparameter combinations. This model incorporates a probabilistic approach to continuously refine the optimization based on objective function assessments, thereby facilitating an effective search for hyperparameter sets that minimize the objective function most effectively. The algorithm is further designed to mitigate the risks of local optima and to explore new potential minimization areas through the Expected Improvement (EI) function, promoting a balance between exploration and exploitation in the optimization journey.

Therefore, unlike traditional methods such as grid search or random search, TPEBO employs a more sophisticated approach to hyperparameter optimization, leveraging both exploration and exploitation strategies to efficiently find the optimal set of hyperparameters for the model.