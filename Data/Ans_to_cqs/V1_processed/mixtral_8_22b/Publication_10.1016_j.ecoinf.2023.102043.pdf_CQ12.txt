The pipeline uses a deep learning model called YAMNet, which is based on the MobileV1 convolution architecture. This model is pre-trained on data coming from 521 classes and is trained on the AudioSet-YouTube corpus. Therefore, it can be classified as a Convolutional Neural Network (CNN), specifically designed for audio processing tasks such as sound event recognition or keyword spotting.