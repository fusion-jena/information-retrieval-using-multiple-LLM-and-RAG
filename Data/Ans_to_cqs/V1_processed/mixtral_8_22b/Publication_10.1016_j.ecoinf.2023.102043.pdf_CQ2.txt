In the given context, the deep learning pipeline uses audio data. Specifically, the audio data is first converted to a monophonic channel and resampled at 16 kHz. Then, the spectrogram is extracted and created using Short Time Fourier Transform (STFT) magnitudes of 25 ms overlapped by 15 ms. Afterward, the Mel spectrogram is calculated by mapping to 64 bins of the Mel scale within the range of 125â€“7500 Hz. Finally, the resulting audio data is fed as input to a sequential and a reduce mean layer mapping to the classes mentioned above. Therefore, the data format used in this deep learning pipeline is audio data.