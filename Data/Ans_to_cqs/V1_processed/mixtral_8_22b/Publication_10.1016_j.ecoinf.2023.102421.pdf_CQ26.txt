In this given context, the authors use 10-fold cross-validation during the training process to eliminate data bias. Cross-validation is a technique used to assess the predictive performance of a statistical model. In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, one subsample is retained as the validation data for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The k results can then be averaged to produce a single estimation.

However, the context does not explicitly mention other common techniques like stratified splitting, oversampling, undersampling, or diverse data collection. These techniques are often employed to mitigate class imbalance issues or to increase diversity in the dataset. Stratified splitting ensures that each fold has approximately the same percentage of samples of each target class as the complete set. Oversampling increases the number of instances in the minority class by replicating them, while undersampling reduces the number of examples in the majority class by removing some instances. Lastly, diverse data collection involves gathering data from various sources to capture a wide range of scenarios and avoid overfitting to a particular type of data.