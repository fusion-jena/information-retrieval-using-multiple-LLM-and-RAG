The text does not provide explicit information about how the hyperparameters of the model are optimized. However, common methods for hyperparameter optimization include grid search, random search, Bayesian optimization, and gradient-based optimization. Grid search involves trying all combinations of hyperparameters within a manually specified range, while random search selects random combinations within the same range. Bayesian optimization uses a surrogate model to approximate the objective function and guide the search process, and gradient-based optimization uses gradients to update hyperparameters iteratively. Without specific details, we cannot determine which method was used for this model.