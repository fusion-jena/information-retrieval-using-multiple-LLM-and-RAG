Based on the given context, there isn't any explicit information about how the data was split for deep learning model training (train, test, or validation sets). However, we can infer from the text that some form of splitting was done since the authors mention both training and validation F1-scores. Typically, datasets are divided into three parts: training set, validation set, and testing set. The training set is used to fit the model, while the validation set helps tune hyperparameters and prevent overfitting. Finally, the testing set evaluates the final performance of the model. It appears that the authors have followed this standard practice, although they do not explicitly discuss their methodology for splitting the data.