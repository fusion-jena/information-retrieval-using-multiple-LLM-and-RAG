To monitor the model performance during training, a strategy involving line graphs representing accuracy and loss over epochs is employed. These graphs display the mathematical calculations performed by the proposed model on the data, with each point connected by lines to illustrate trends and patterns in the model's performance. Data points and lines are color-coded to differentiate between training and validation results; blue indicates training results, while orange signifies validation results.

Two separate graphs are utilized for this purpose. The first graph, labeled "Accuracy," measures the percentage of accurate predictions made by the model. This graph helps track improvements in classification performance as the number of epochs increases. The second graph, titled "Loss," provides insights into the degree of error produced by the model. By observing these graphs, it becomes possible to identify any discrepancies between the training and validation results, such as when the model excessively memorizes the training data without effectively adapting to new information. In such cases, dropout techniques can be applied to minimize the disparity between training and validation outcomes, thereby enhancing the model's overall generalizability.