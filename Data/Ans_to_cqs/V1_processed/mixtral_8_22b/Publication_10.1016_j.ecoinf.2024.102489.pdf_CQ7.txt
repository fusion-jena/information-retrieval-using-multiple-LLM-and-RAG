In the given context, it is mentioned that while building the RF model, the training samples were divided into two parts with proportions of 80% and 20%, which were then used for the training and test datasets, respectively. It means that the dataset was split into 80% for training the model and 20% for testing its performance. However, there is no mention of any specific criterion used to divide the data or any information about using a separate validation set. In general, when splitting the data for deep learning model training, one common approach is to use a stratified sampling technique to maintain the same distribution of classes in each subset. Another popular approach is to use a holdout method, where the data is randomly split into three subsets: training, validation, and testing sets. The training set is used to fit the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to evaluate the final model's performance.