The text does not provide explicit information about the hyperparameters used in the deep learning models. However, it mentions using pre-trained models like AlexNet, VGG-19, ResNet-101, and DenseNet-201, which were originally trained on the ImageNet dataset. It also states that these models are fine-tuned for the specific task, but there is no mention of the exact hyperparameters used during training or fine-tuning. Additionally, the reference list includes a citation to Kingma and Ba (2014)'s work on Adam optimization, suggesting that the Adam optimizer might have been used in the study. But without more specific details, it cannot be confirmed.