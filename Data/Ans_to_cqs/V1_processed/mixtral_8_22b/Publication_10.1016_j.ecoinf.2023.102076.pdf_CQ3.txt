The given context does not provide specific details about the data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, it does mention that researchers can annotate a randomly selected sample of collected data according to their own relevancy criteria. This suggests that the authors might have used a form of semantic annotation, where they labeled parts of the text based on its relevance to the topic of interest. Additionally, the context mentions that documents were split into chunks of 300 tokens using the NLTK word-tokenizer, and chunks containing certain keywords were retained. This could indicate a type of keyword-based annotation technique. Nevertheless, without explicit information about the use of bounding box annotation, instance segmentation, or other similar techniques, it cannot be confirmed if these methods were employed in the described deep learning pipeline.