Based on the given information, there isn't any explicit mention of specific postprocessing steps taken after the model training. However, we do see some indicators of certain processes such as validation performance evaluation and testing accuracy calculations.

In Table 2, it is shown that the original image model and background-removed model had almost the same validation performance, reaching 98% accuracy. This suggests that some form of metrics calculation was done during or after the training process to evaluate the model's performance.

Furthermore, in section 3.2, it mentions that the MG dataset led to better ability to generalize to the test sets. This implies that testing accuracy was calculated using different test sets to assess how well the trained models could predict unseen data.

However, there is no direct reference to other common postprocessing techniques like saliency maps or confusion matrices. Therefore, based solely on the provided context, it cannot be determined if these methods were employed.