After the model training process, there are several postprocessing steps that can be taken to evaluate the performance of machine learning models (MLMs). According to the given context, the performance of each MLM was assessed using several metrics such as AUC, TSS, Kappa, and phi. These evaluations were presented in Table 3 and visualised in Figure 4. Additionally, the model complexity was evaluated by computing the difference between the AUC (train) and AUC (CV), represented as Î” AUC. This score provides insight into the sensitivity of the models to the training data. Furthermore, the Kruskal-Wallis test was conducted to determine if there was a significant difference in prediction accuracy among the classifiers.

In addition to these statistical measures, other common postprocessing techniques include creating saliency maps, calculating confusion matrices, and generating ROC curves. Saliency maps highlight the areas of input images that contribute most significantly to the output predictions made by the model. Calculating confusion matrices allows researchers to understand how well the model performs on different classes of data. Generating ROC curves enables researchers to compare the performance of multiple models across various thresholds.

Overall, postprocessing steps play a crucial role in validating the predictive capabilities of MLMs. By employing robust statistical measures and visualisation tools, researchers can gain valuable insights into the strengths and weaknesses of their models.