Based on the given information, there isn't any explicit mention of the specific process used to deploy the trained deep learning model. However, common practices for deploying such models often involve model serialization and platform selection.

Model serialization refers to converting the trained model into a format that can be stored or transferred easily. This could be done using various libraries like Pickle in Python or ONNX (Open Neural Network Exchange). Once serialized, the model can then be loaded onto different platforms for deployment.

Platform selection depends on several factors including the nature of the application, scalability requirements, and available resources. Some popular choices for deploying deep learning models include cloud services like AWS, Google Cloud, and Azure; edge devices; or even custom servers depending on the use case.

However, without further details about the specific implementation, it's impossible to provide a definitive answer regarding the exact process followed to deploy this particular model.