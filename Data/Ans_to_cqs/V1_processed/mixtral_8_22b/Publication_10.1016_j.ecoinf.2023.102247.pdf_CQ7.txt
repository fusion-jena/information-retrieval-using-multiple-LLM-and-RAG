The authors used a cross-validation technique to evaluate their ensemble modeling approach. They divided their dataset into two parts: 70% was used as training data to build the models, while the remaining 30% served as testing data to assess the models' accuracy. This division allowed them to measure how well the models could generalize to unseen data, which is crucial for evaluating the robustness and reliability of machine learning models.

The Area Under the Receiving Operator Characteristics Curve (AUC) was chosen as the metric to quantify the models' accuracy. AUC values range between 0.5 and 1.0, where a higher score indicates better model performance. By employing this criterion, the researchers aimed to ensure that their models were not only accurate but also capable of distinguishing between suitable and non-suitable habitats for the study species.