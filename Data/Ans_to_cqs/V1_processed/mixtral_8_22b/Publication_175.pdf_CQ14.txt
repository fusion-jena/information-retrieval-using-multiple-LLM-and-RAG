The text does not provide explicit information about how the hyperparameters were optimized. However, it mentions that the same hyperparameters were used across different models and datasets, suggesting that they might have been determined beforehand rather than being optimized separately for each case. Common methods for hyperparameter optimization include grid search, which systematically explores all possible combinations within a predefined range, and random search, which samples random values from specified ranges. Other techniques like Bayesian Optimization or Gradient-based Optimization can also be employed. Without further details, it is impossible to determine the exact method used for hyperparameter optimization in this study.