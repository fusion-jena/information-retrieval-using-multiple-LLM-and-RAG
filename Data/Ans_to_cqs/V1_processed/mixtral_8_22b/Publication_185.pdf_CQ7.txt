Based on the given context, there isn't explicit information about how the data was split into training, testing, and validation sets. However, we do see that the experiments were conducted using a small dataset without data augmentation. The MG and MO models were trained and validated on their respective datasets, demonstrating good performance in their validation sets. This suggests that the dataset might have been divided into separate subsets for training and validation purposes. Typically, in machine learning and deep learning projects, the dataset is often split into three parts: training, validation, and testing. The training set is used to fit the model, while the validation set is used to tune hyperparameters and prevent overfitting. Lastly, the testing set is used to evaluate the final model's performance. Although the specific criteria for splitting the data aren't mentioned here, common practices include random sampling or stratified sampling based on class distribution.