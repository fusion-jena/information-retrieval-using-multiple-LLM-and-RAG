To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the model was trained using epochs and batch sizes of 10 and 32, respectively. Secondly, the model was compiled using a categorical cross-entropy loss function, and the hyperparameters were tuned using a root mean square propagation (RMSProp) optimizer. Thirdly, the model was evaluated using stratified 10-fold cross-validation with calculated values of accuracy, precision, recall, F1-Score, area under the curve (AUC) score, confusion matrix, and model training time for binary and multiclass classifications. Lastly, the standard deviation values for each performance indicator were compared to determine the optimal configuration. Configuration 8 was determined as the ideal parameter due to its reduced standard deviation value. These measures ensured that the deep learning model had a high level of generalizability.