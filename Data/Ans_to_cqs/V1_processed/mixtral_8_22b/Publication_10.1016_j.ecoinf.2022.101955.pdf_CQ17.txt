The text does not provide specific information about the regularization methods used to prevent overfitting in the deep learning pipeline. However, it mentions that the authors used the package "nnet" in R, which allows for adjusting weighted decay and size to counteract the effects of model overfitting. Weighted decay is a form of L2 regularization, also known as Ridge Regression, where a penalty term is added to the loss function to shrink the weights towards zero. This helps to reduce overfitting by preventing the model from becoming too complex. Additionally, the authors mention using a backpropagation learning algorithm during the training phase of the model, but they do not specify whether any other regularization techniques, such as dropout, were employed.