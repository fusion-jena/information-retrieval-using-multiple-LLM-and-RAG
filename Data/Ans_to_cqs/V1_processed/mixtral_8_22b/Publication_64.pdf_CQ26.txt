Based on the given context, there isn't explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, the text does mention that they selected the most popular labels and retrieved the top results from Google Image Search to minimize the presence of mislabeled images. This could be considered a form of addressing potential biases in the data. Additionally, the authors applied standard data augmentation techniques like sheering, translating, and mirroring to ensure that the network never saw the same image twice. They also avoided rotating or flipping 'habit' images, which may introduce unwanted artifacts or distortions. These practices can help reduce overfitting and improve generalizability, but they do not directly address issues related to imbalanced classes or representation bias.