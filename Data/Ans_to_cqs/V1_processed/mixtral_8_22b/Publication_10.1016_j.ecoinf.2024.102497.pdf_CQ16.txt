The text does not provide explicit information on the criteria used to determine when training is complete for either the Classification and Regression Tree (CART) or Random Forest Regression (RFR) methods. However, it can be inferred that the authors optimized their models by fine-tuning specific parameters to prevent overfitting and minimize cross-validation errors.

For the CART method, they adjusted'max_depth','min_samples_leaf', and'max_leaf_nodes'. Similarly, for the RFR method, they experimented with'max_depth','min_samples_split','min_samples_leaf', and'max_features'. Although the exact criteria for determining when training is complete are not mentioned, it is common practice in machine learning to use metrics like validation loss plateaus, early stopping, or reaching a predefined number of epochs/iterations to decide when to stop training.

In conclusion, while the text does not explicitly state the criteria used to determine when training is complete, it is reasonable to assume that the authors employed standard practices in machine learning, such as monitoring validation loss or other performance metrics during training to ensure optimal model performance and avoid overfitting.