Based on the given context, there is no information about the specific optimization techniques applied in the deep learning pipeline such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). However, it does mention the use of various modeling methods like Random Forest (RF), Support Vector Machine (SVM), Multi-Layer Perceptron (MLP), Extreme Gradient Boosting (XGBoost), and Multiple Linear Regression (MLR). These methods can be optimized using different techniques depending on their implementation. For instance, neural networks like MLP can be trained using backpropagation and optimizers like SGD or Adam. But without further details, I cannot provide a definitive answer regarding which optimization techniques are used in this particular case.