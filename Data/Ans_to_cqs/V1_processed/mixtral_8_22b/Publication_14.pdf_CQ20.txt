Based on the given information, it appears that the deep learning model was trained using multiple CPUs. Specifically, feature extraction of the fixed inception layers was completed in 1 hour and 26 minutes on 15 CPUs, while training of the new layers took 27 minutes on a single CPU. Additionally, model evaluation on the 70 test videos was done on 30 CPUs with an average frame rate of 17 frames per second. However, there is no explicit mention of any specific hardware resources such as GPUs or TPUs being used for training the deep learning model. Therefore, based solely on the provided context, we cannot definitively state which hardware resources were used for training the deep learning model beyond the use of CPUs.