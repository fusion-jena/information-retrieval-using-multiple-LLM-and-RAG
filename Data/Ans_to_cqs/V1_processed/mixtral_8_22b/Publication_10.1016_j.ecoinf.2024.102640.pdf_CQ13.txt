The deep learning model used in this case is SegFormer, which uses the AdamW optimizer with the momentum parameter (β1) set to 0.9 and (β2) set to 0.999. The epsilon value (ε) is set to 10^-8. A cosine annealing schedule is employed, and the initial learning rate is set to 0.0001. The model is trained on the UGE-D dataset for 100 epochs with a batch size of eight. The Cross-Entropy loss function is used to supervise SegFormer's training.