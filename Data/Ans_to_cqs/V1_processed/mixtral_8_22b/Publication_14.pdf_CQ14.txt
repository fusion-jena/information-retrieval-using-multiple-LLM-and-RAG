Based on the given information, there isn't any explicit mention of how the hyperparameters of the model were optimized, such as through methods like grid search or random search. However, it does state that the model was trained with a batch size of 100 for 20,000 steps. This suggests that some form of optimization may have taken place, but without further details, we cannot definitively determine which method was used. Therefore, based on the available information, it appears that the specific method used to optimize the hyperparameters of the model remains unknown.