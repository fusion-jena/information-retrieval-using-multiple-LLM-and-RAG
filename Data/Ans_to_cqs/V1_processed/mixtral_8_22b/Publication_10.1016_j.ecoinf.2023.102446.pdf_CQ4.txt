Unfortunately, there isn't enough information in the given context to determine what specific data augmentation techniques were used in their deep learning pipeline. However, common data augmentation techniques include flipping, rotating, scaling, cropping, zooming, and adding noise or filters to images. These methods help increase the size of the dataset and improve model performance by introducing more variability into the training set.

Based on the context provided, it appears that the researchers collected data using a flux tower over a two-year period, measuring various environmental factors such as respiration, net solar radiation, air temperature, wind speed, relative humidity, and precipitation. They then analyzed this data using a method called Temporal Information Partitioning Network (TIPNet). While they mention using lagged information in their computation, no explicit reference is made to any data augmentation techniques being employed within their deep learning pipeline. Therefore, I cannot provide a definitive list of data augmentation techniques used in their research based solely on the given context.