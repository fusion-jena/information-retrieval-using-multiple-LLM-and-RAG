Based on the given information, it appears that the optimization method used for the models is Stochastic Gradient Descent (SGD) with a learning rate of 0.5 and momentum of 0.9. However, there is no explicit mention of how the hyperparameters were chosen or if any specific methods like grid search or random search were employed. It can only be inferred that the mentioned values were manually chosen based on experience or some form of trial and error.