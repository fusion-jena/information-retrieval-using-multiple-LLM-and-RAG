Deep learning models typically demand more resources for training compared to computationally efficient algorithms like XGBoost. These resources include Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). Therefore, the hardware resources used for training the deep learning model are GPUs and TPUs.