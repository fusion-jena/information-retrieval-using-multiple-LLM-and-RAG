The performance of the deep learning model is evaluated using Mean Absolute Error (MAE), which measures the average magnitude of errors between predicted and actual values without considering their direction. It is calculated by taking the absolute difference between the predicted and actual values, summing those differences, and dividing by the total number of observations. A lower MAE indicates better model performance. Additionally, the validation dataset's MAE is computed after each epoch during the training process to monitor overfitting. Overfitting occurs when the validation MAE does not further improve compared to previous epochs and diverges from the training MAE.