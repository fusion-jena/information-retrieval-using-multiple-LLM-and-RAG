Before training a deep learning model, several preprocessing steps may be involved depending on the nature of the input data. These steps help improve the performance and efficiency of the model by preparing the data in a suitable format. Some common preprocessing techniques include:

1. Normalization or standardization: This involves rescaling the input features so they have zero mean and unit variance. This is often done when different features have varying scales, which could affect the convergence rate during optimization. For example, image pixel values might range between 0 and 255, while other features might lie within a smaller range. In such cases, normalizing the inputs ensures all features contribute equally to the loss function.

2. Scaling: Similar to normalization, scaling involves transforming the feature values to a specific range, typically [0, 1] or [-1, 1]. This helps prevent any single feature from dominating the others due to its scale.

3. Cleaning: This step involves handling missing or corrupted data points in the input dataset. Common strategies include removing these instances, imputing them with statistical measures like mean or median, or employing more sophisticated methods like regression or machine learning algorithms.

4. Encoding categorical variables: Deep learning models require numerical input, so categorical variables need to be converted into numeric form. One popular method is one-hot encoding, where each category is represented as a binary vector with a single '1'. Another approach is label encoding, which assigns unique integers to each category.

5. Feature extraction or selection: Depending on the complexity of the problem, it might be beneficial to extract relevant features from raw data or select only those features that significantly impact the target variable. Techniques like Principal Component Analysis (PCA) or Recursive Feature Elimination (RFE) can be employed for this purpose.

However, based on the given context, there isn't explicit mention of the preprocessing steps taken before training a deep learning model. Therefore, I cannot provide a definitive list of preprocessing steps applied in this particular case.