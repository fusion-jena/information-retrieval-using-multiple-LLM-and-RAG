The text does not explicitly mention any specific preprocessing steps taken before training the deep learning models. However, common practices in preparing data for deep learning include normalization or standardization, handling missing values, encoding categorical variables, and splitting the dataset into training and testing sets. Normalization scales numerical input features to a range between 0 and 1, while standardization transforms them to have a mean of 0 and a standard deviation of 1. Handling missing values can be done by either removing those instances or imputing them based on other available information. Encoding categorical variables involves converting them into numerical representations that can be processed by the model. Lastly, splitting the dataset allows for evaluating the model's performance on unseen data during training.