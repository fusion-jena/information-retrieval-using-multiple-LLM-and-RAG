Based on the given context, there is no explicit mention of any specific regularization methods used to prevent overfitting in the deep learning pipeline. Regularization methods such as dropout or L2 regularization can be employed to avoid overfitting during model training. However, without further information about the implementation details of the deep learning pipeline, it cannot be confirmed whether these techniques were utilized.

Unhelpful 
The article uses a batch size of 32 and employs the Adam optimization algorithm with a varying learning rate based on the cosine function's law. Additionally, the authors utilize the cross-entropy loss function for their model. While these aspects contribute to the overall performance of the deep learning pipeline, they do not directly address the prevention of overfitting through regularization methods like dropout or L2 regularization.