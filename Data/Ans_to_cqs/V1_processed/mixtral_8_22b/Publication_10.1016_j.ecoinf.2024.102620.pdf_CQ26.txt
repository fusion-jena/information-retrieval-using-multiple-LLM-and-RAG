The paper does not provide information on specific techniques used to address data bias during preprocessing of a deep learning pipeline. However, some common techniques for addressing data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes or labels in both sets. This helps ensure that the model is trained and tested on representative samples from each class.

Oversampling and undersampling involve adjusting the number of instances in each class to balance the dataset. Oversampling increases the number of instances in minority classes, while undersampling reduces the number of instances in majority classes. These techniques can help prevent the model from being biased towards the majority class.

Diverse data collection involves collecting data from various sources and demographics to increase the diversity of the dataset. This can help reduce bias caused by overrepresentation of certain groups or underrepresentation of others.

Without more information about the specific deep learning pipeline used in the paper, it is difficult to determine which technique would be most appropriate for addressing data bias. However, these techniques are commonly used in machine learning and deep learning applications to improve model performance and reduce bias.