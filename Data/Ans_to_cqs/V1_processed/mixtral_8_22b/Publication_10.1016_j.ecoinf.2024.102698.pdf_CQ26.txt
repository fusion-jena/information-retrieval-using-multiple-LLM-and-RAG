The query asks about techniques used to address data bias during preprocessing of the deep learning pipeline. Some common techniques used to mitigate data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets such that each subset has approximately the same proportion of classes as the overall dataset. This ensures that the training and validation sets maintain the class distribution of the original dataset.

Oversampling is a technique where samples from the minority class are duplicated to balance the class distribution. This helps prevent the model from becoming biased towards the majority class. Undersampling, on the other hand, involves removing samples from the majority class to achieve a balanced class distribution. However, undersampling can result in loss of valuable information.

Diverse data collection involves collecting data from various sources to ensure that the dataset represents different populations and scenarios. This helps reduce bias by ensuring that the model generalizes well across different groups.

Other techniques used to address data bias include transfer learning, where a pre-trained model is fine-tuned on a smaller dataset, and ensemble learning, where multiple models are combined to improve performance. Additionally, data augmentation techniques such as rotation, scaling, and flipping can also help increase the diversity of the dataset and reduce overfitting.