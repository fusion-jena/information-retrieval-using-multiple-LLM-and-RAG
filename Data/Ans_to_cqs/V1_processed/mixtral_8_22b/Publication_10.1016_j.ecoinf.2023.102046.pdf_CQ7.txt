Based on the given context, there isn't any explicit mention of how the data was split into training, testing, and validation sets. However, some common practices in machine learning include splitting the data randomly or stratified based on the target variable. Typically, the data is divided into three parts: training, validation, and testing datasets. The training dataset is used to fit the model, while the validation dataset helps tune hyperparameters and prevent overfitting. Lastly, the testing dataset evaluates the final model's performance.

Regarding the specific percentages for each set, they may vary depending on the total amount of data available. Common splits include 80/20, where 80% of the data goes towards training and 20% towards testing; 70/15/15, where 70% is allocated for training, 15% for validation, and another 15% for testing; or even 60/20/20. These ratios depend on factors such as the complexity of the task, the number of classes, and the overall size of the dataset.