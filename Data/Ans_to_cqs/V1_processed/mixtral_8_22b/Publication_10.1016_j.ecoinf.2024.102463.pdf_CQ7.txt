Based on the given context, the criteria used to split the data for deep learning model training are not explicitly mentioned. However, it can be inferred from the text that the data is divided into a training base and a test base. One dataset out of the three available datasets is chosen as the training base, and the standardization parameters are calculated based on this dataset. These parameters are then applied to the remaining two datasets, which serve as the test bases.

Additionally, the context mentions using the HyperBand algorithm for optimization, where the role of the training base and test base of each system is swapped. This suggests that the data might also be split into multiple sets for cross-validation purposes. Cross-validation is a technique used to assess how well a statistical model will generalize to an independent dataset. By splitting the data into multiple subsets, the model can be trained and evaluated several times, with each subset serving as both the training and testing data.

In summary, although the exact criteria used to split the data are not specified in the provided context, it can be deduced that the data is divided into a training base and a test base, possibly with additional splits for cross-validation purposes.