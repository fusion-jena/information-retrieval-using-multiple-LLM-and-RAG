Based on the given information, it appears that the researchers monitored the model performance during training by examining the relationship between the number of texts in the training data and the median F1 score achieved by the classifiers over five runs. They increased the size of the training data incrementally by 50 texts and observed the impact on the model performance. Additionally, they experimented with different methods of selecting training data, including random sampling and active learning techniques like Bert K-means and Least Confidence. These strategies allowed them to evaluate the effectiveness of various approaches in improving the model performance while minimizing the amount of training data needed.