After training the BirdNET model, several postprocessing steps were taken to analyze its performance and extract meaningful features. These include creating a mel-scale spectrogram between 150 Hz and 15 kHz, returning 1024 embeddings per 3-second audio sample, calculating the mean and standard deviation for embeddings over the entire duration of the call, and generating a feature vector.

To evaluate the model's performance, various metrics were calculated, such as classification accuracy and normalized mutual information (NMI). Classification accuracy was measured by comparing predicted labels to actual labels, while NMI assessed the quality of clustering results. Both metrics were computed over multiple random iterations and visualized with their respective confidence intervals.

Additionally, successful clustering was achieved using Mel Frequency Cepstral Coefficients (MFCCs) as a feature extraction technique and Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) for unsupervised classification. This combination proved effective for classifying bird sounds within a certain distance range.

In summary, the postprocessing steps involved after training the BirdNET model included creating a mel-scale spectrogram, computing embeddings, calculating mean and standard deviation for feature vectors, evaluating performance using metrics like classification accuracy and NMI, and applying techniques like MFCCs and HDBSCAN for clustering and classification tasks.