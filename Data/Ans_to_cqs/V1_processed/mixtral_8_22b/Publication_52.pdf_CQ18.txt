Based on the given context, there isn't enough information to provide a specific strategy for monitoring the model performance during training. However, generally speaking, strategies for monitoring model performance during training include tracking metrics like accuracy, precision, recall, F1 score, ROC curves, etc. Additionally, cross-validation techniques can also be used to evaluate the model's performance on unseen data. In the case of Extreme Learning Machines (ELMs), since they do not require fine manipulation of operating parameters and can determine the appropriate output weights towards effective problem resolution, monitoring could involve checking if the output weights converge to optimal values within a reasonable amount of iterations. Furthermore, since ELMs have the potential to generalize based solely on their training dataset, evaluating the model's ability to perform well on unseen data would also be crucial.