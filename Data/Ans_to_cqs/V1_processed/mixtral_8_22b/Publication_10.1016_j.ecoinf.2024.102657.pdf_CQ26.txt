The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions a few aspects related to handling the dataset. For instance, the dataset is divided into training and testing sets using an 80/20 split ratio. This approach ensures that both sets contain representative samples from all dialect classes, which can help mitigate potential biases due to uneven distribution of classes. Additionally, the use of identical structures for metadata files suggests consistency in data organization across different subsets, further reducing the risk of introducing any systematic biases. While these practices contribute to maintaining balance within the dataset, they do not directly correspond to common techniques like stratified splitting, oversampling, undersampling, or diverse data collection mentioned in the query. Therefore, based solely on the given context, we cannot definitively state which specific technique(s) are employed to tackle data bias during preprocessing.