The given context does not provide explicit information about the specific hardware resources used for training the deep learning models mentioned. However, it does mention that long audio files are divided into shorter chunks so that a whole batch can fit inside the limited memory of GPUs. This suggests that GPU resources were likely utilized during the training process due to their ability to handle parallel computations efficiently. Nevertheless, the exact type or number of GPUs used remains unknown based on the provided context.