The text does not provide explicit information on the specific strategy used to monitor the model performance during training. However, it mentions several aspects related to model evaluation and validation. It suggests that the standard practice of withholding parts of the training data for validating a model might lead to both training and testing data suffering from the same spatial and environmental biases. Additionally, it discusses the use of appropriate validation metrics, which may be less straightforward for integrated models due to differences in biases and sampling methods. Furthermore, it highlights the importance of considering all available data and integrating prior knowledge of the species biology into the model. Lastly, it mentions the possibility of raising warnings and highlighted messages if the provided information is insufficient for inferring a species distribution. Based on this context, we can infer that monitoring the model performance during training involves careful consideration of validation strategies, selection of suitable metrics, and potential inclusion of domain knowledge to improve model outcomes. However, without further details, it is impossible to specify the exact strategy employed for monitoring the model performance during training.