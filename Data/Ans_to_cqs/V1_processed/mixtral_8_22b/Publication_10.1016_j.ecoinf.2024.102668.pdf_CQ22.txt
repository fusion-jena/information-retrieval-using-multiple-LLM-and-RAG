The given context does not provide information on the specific metrics used to evaluate the performance of a deep learning model. However, common metrics used to evaluate deep learning models include accuracy, precision, recall, F1 score, ROC AUC, and confusion matrix. Accuracy measures the proportion of correct predictions out of total predictions made. Precision measures the proportion of true positive predictions out of all positive predictions made. Recall measures the proportion of true positive predictions out of actual positives. The F1 score is the harmonic mean of precision and recall. ROC AUC stands for Receiver Operating Characteristic Area Under Curve, which measures the area under the curve plotted based on True Positive Rate vs False Positive Rate. Confusion Matrix provides a summary of prediction results on a classification problem. It shows the number of correctly classified instances, misclassified instances, false negatives, and false positives.