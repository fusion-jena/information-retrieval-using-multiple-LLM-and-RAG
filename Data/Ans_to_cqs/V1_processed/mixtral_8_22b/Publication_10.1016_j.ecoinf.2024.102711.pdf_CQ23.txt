To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the development dataset was divided into two categories: the training dataset and the tuning dataset. This division aimed to use all available data records for training, thereby enhancing the model's generalization ability. Secondly, due to the constraints of the dataset size, k-fold cross-validation was chosen as the preferred approach for hyperparameter tuning. This technique involves evenly dividing the development dataset into 'k' groups. Each group is then used once as the validation set while the other 'k-1' groups serve as the training set. This process is repeated 'k' times, ensuring that every data point gets to be in the validation set exactly once. For this study, a value of 5 was assumed for 'k'. Lastly, grid search was employed to evaluate the data-driven model's performance using each combination of predefined hyperparameters and identify the best hyperparameters. The maximum depth of the tree, the number of trees in the ensemble model, and the learning rate were tuned in this study as the influential hyperparameters. These measures collectively helped improve the model's accuracy and prediction performance, thus ensuring its generalizability.