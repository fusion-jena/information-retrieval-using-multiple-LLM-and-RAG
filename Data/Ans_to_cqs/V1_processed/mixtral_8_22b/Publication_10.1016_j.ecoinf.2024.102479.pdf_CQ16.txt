The text does not explicitly mention the specific criteria used to determine when training is complete. However, it can be inferred from the context that Grid Search Cross Validation (GSCV) is used during the training phase to identify the most effective set of hyperparameters that enhance the model's performance. This technique involves generating a series of models, each characterized by a different set of hyperparameters, and systematically training and assessing their performance through cross-validation. The process concludes with the selection of the model that demonstrates the most superior performance, determined by its optimal hyperparameter combination. Therefore, one could infer that the completion of training might occur once the best performing model with the optimal hyperparameter combination is identified using GSCV. Additionally, the use of k-fold cross-validation, specifically a 10-fold cross-validation design, further supports the idea that the training process may continue until the best performing model is selected based on its performance across multiple folds or iterations.