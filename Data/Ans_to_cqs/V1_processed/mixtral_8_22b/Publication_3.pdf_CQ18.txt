To monitor the model performance during training, the authors employed a strategy involving several components. Firstly, they utilized a leave-one-out cross validation technique, particularly for Challenges 1, 3, and 4. This method involves setting aside one observation from the dataset and then fitting the model to the remaining observations. Afterward, the fitted model is used to predict the response for the left out observation. This process is repeated until every observation has been left out once. Secondly, considering their limited number of images per species (n=20), they increased the validation parameter to 20%. Validation data is used to provide an unbiased evaluation of the model fit while tuning its parameters. Lastly, they also adjusted the number of training steps and compared results to strike an optimal balance between computing time and classification efficiency.