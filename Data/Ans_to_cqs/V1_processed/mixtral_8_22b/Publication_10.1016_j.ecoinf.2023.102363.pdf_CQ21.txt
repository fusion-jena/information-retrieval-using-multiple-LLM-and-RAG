The provided context does not explicitly mention any specific postprocessing steps taken after the model training. However, it can be inferred that some form of visualization or analysis was performed based on Figure 7, which shows exemplar model classifications using GradCAM. This suggests that saliency maps were generated to understand the regions of importance within the spectrogram for the model's classification predictions. Additionally, since the models are evaluated during training and validation, it can also be assumed that metrics such as accuracy, precision, recall, F1-score, etc., would have been calculated to measure the performance of the models. Furthermore, considering the classes are imbalanced, it might be possible that a confusion matrix was created to better understand the misclassification errors between different classes.