The experiments for training the deep learning model were performed using GPU acceleration to expedite computations. Specifically, the text mentions the use of NVIDIA Tesla K40c GPU for radiation therapy and Nvidia GPU with four CUDA kernels for video compression. These examples suggest that the hardware resources used for training the deep learning model include GPUs. Additionally, the mention of Compute Unified Device Architecture (CUDA) further supports the use of GPUs, as CUDA is a parallel computing platform and application programming interface (API) model created by Nvidia. However, there is no explicit mention of TPUs or any other specific hardware resources being used for training the deep learning model.