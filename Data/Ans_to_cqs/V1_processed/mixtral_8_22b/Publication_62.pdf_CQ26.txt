The supplementary materials do not explicitly mention any specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on common practices in deep learning, some possible techniques include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining a similar distribution of classes or labels in both sets. This helps prevent overfitting and ensures that the model generalizes well to new data.

Oversampling is a technique where samples from the minority class are duplicated to balance the dataset. Undersampling, on the other hand, involves removing samples from the majority class to achieve a more balanced dataset. Both methods aim to mitigate the effects of imbalanced datasets on model performance.

Diverse data collection refers to collecting a wide range of examples representing different variations within each class. This helps improve the robustness and accuracy of the model when dealing with real-world data.

While these techniques are commonly employed to address data bias, it is essential to note that the choice of method depends on the nature and characteristics of the dataset being used. Without further information about the specific dataset used in this study, we cannot definitively state which techniques were applied.