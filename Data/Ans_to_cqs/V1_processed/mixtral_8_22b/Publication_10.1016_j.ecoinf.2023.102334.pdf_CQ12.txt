The pipeline uses a hybrid deep learning model that combines both Convolutional Neural Network (CNN) and Transformer architectures. This hybrid design leverages the strengths of both types of networks. Specifically, the CNN component serves as a backbone for extracting features from input images, while the Transformer component focuses on modeling global attention using these extracted features. This combination allows for better performance with relatively less computational workload compared to using a vanilla Vision Transformer (ViT) model alone. The use of a hybrid model aligns with recent trends in computer vision research, where Transformers have been adapted from their original application in Natural Language Processing (NLP) to handle tasks involving long-range dependencies between pixels in images.