From the given context, it appears that several measures have been taken to ensure the generalizability of the deep learning models. These include:

1. Data Augmentation: As mentioned in Figure 3, half of the models (24 out of 48) used data augmentation techniques. This helps improve the model's ability to generalize by providing more varied examples during training.

2. Normalization Schemes: Two different normalization schemes - Standardization and Min-Max Normalization - were applied to the models. Each scheme was used for 16 models, ensuring diversity in preprocessing methods.

3. Different Compression Techniques: Half of the models used Per-Channel Energy Normalization (PCEN) while the other half used Log compression. This variety allows the evaluation of the model's performance under different feature extraction conditions.

4. Multiple Frontends: Four types of frontends - Mel, STFT, Sinc, and Leaf - were employed in the experiments. Using multiple frontends can help assess the robustness and adaptability of the models across various input representations.

However, there is no explicit mention of cross-validation or stratified splitting in the provided context. Cross-validation is a technique used to evaluate machine learning models on limited data samples, while stratified sampling ensures that the distribution of classes remains consistent among folds. Although these techniques might have been implemented but not explicitly stated, based solely on the given information, we cannot confirm if they were part of the methodology.