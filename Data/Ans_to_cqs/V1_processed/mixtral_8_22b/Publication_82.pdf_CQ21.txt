The authors do not explicitly mention any specific postprocessing steps after the model training in their study. However, they discuss various aspects related to performance measurement and evaluation. They measure the performance of their models using different train-test split ratios ranging from 80-20 to 20-80. Each experiment runs for a total of 30 epochs, with stochastic gradient descent as the solver type and a base learning rate of 0.005. To ensure a fair comparison among the experimental configurations, they standardized the hyperparameters across all experiments. Although not mentioned directly, it can be assumed that common practices like calculating metrics (accuracy, precision, recall, F1 score) and generating confusion matrices were employed to evaluate the models' performance. Additionally, the authors acknowledge the limitation of reduced accuracy when applying the trained model to images captured under different conditions than those used for training. This suggests that further analysis or visualization techniques, such as saliency maps, might be beneficial to understand the model's behavior better.