The paper "Identifying wildlife observations on Twitter" does not explicitly mention the use of any specific deep learning model such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), or Transformers in their methodology. However, they do reference the use of BERT (Bidirectional Encoder Representations from Transformers) in the cited work "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding". Therefore, it can be inferred that the authors might have employed some form of transformer-based architecture in their pipeline, but this cannot be confirmed without further information.