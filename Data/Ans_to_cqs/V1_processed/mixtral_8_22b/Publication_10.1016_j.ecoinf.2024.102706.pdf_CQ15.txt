The given context does not provide specific details about optimization techniques applied in the deep learning pipeline, such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). Instead, it focuses on various machine learning models like Linear Regression, Elastic Net, Support Vector Machine, Random Forest, Extreme Gradient Boosting, and Light Gradient Boosting Machine. It also discusses their performance metrics, including R2, Root Mean Square Error (RMSE), Relative Root Mean Square Error (rRMSE), and Mean Absolute Error (MAE). Additionally, the text mentions hyperparameters for each model but does not explicitly state any optimization technique used during the training process. Therefore, based on the provided context, I cannot determine what optimization techniques are applied in the deep learning pipeline.