The study uses Bayesian Optimization for automated hyperparameter tuning of the model. This method is more efficient compared to traditional methods like Grid Search or Random Search because it uses previous evaluation results to inform the next set of parameters to evaluate. It does this by constructing a posterior distribution of functions (Gaussian Processes), which is then used to select the most promising set of hyperparameters to evaluate next. This iterative process continues until the best combination of hyperparameters is found. In this way, Bayesian Optimization can find better solutions faster and with fewer evaluations than other methods.