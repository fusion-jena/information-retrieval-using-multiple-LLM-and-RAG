Based on the given context, there isn't explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some practices can still be inferred.

In the study, it appears that they use a pre-trained model and then perform fine-tuning for four iterations using the entire Southwest (SW) stratum employing the Selective Annotation Loop (SAL). This iterative process serves to enhance the model's performance and gather samples pertaining to each key species present in the region.

For the first two fine-tuning iterations, the training procedure consists of two main steps: 1) training the architecture using positive patches for 200 epochs, and 2) collecting and including hard negative patches, which are patches containing false positives, to further train the model for 50 epochs in order to reduce the number of false positives. During the last two fine-tuning iterations, only the second step of the training procedure is used.

While this doesn't directly address data bias, it does suggest that the researchers are aware of potential issues related to class imbalance and false positives, and are actively working to mitigate these problems. By incorporating hard negative patches into their training process, they aim to improve the model's ability to distinguish between true and false detections, thereby reducing the impact of data bias.