Unfortunately, the given context does not explicitly mention how the hyperparameters of the Genetic Programming (GP) model are optimized. Therefore, I cannot provide specific information about whether grid search, random search, or any other optimization method is used for tuning the hyperparameters of the GP model. However, generally speaking, hyperparameter optimization is a critical step in building machine learning models like GP. Common methods for hyperparameter optimization include Grid Search, Random Search, Bayesian Optimization, and Gradient-based Optimization. Each method has its strengths and weaknesses, and the choice depends on factors such as computational resources, time constraints, and the complexity of the problem. In practice, researchers and practitioners often use a combination of these methods or even develop custom optimization strategies tailored to their specific needs.