The authors acknowledged the importance of considering the limitations and potential biases of the training dataset when interpreting the results and making inferences about real-world bird species recognition. They recognized that the dataset used might not fully capture the diverse range of bird populations present in the wild, which could lead to a biased representation and impact the accuracy and generalization ability of the model. To address these concerns, they employed several strategies to improve the generalizability of their deep learning model. Firstly, they utilized a 60:40 split of training and testing data, ensuring that the model had sufficient exposure to both seen and unseen data during its development. Secondly, they compared the performance of eight different pre-trained models, including MobileNetV2, EfficientNetB0, GoogleNet, DenseNet201, InceptionV3, ResNet18, InceptionResNetV2, and NASNetMobile, each with varying architectures and feature extraction capabilities. By selecting the best performing model based on validation accuracy, precision, recall, and F1-score, they aimed to minimize overfitting and enhance the robustness of their final solution. Lastly, they conducted a comprehensive hyperparameter optimization process, involving both manual and automated searches, to fine-tune the chosen model further. Through these combined efforts, the authors sought to create a deep learning model capable of accurately recognizing bird species across diverse environments and conditions.