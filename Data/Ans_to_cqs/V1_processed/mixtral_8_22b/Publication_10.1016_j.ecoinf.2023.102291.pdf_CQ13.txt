The deep learning model used in this study employed a customized CNN architecture and a pre-trained ResNet152V2 architecture. For the customized architecture, the model consisted of three convolutional layers with 32 filters each, a kernel size of 4x4, and ReLU activation. Each convolutional layer was followed by dropout with a rate of 0.4 and a max pooling layer with a kernel size of 4x4. After these layers, there was a fully connected layer with 64 ReLU units, another dropout layer with a rate of 0.4, and finally a softmax function. The number of units in the softmax function varied between two, three, or four depending on the number of species being classified.

The models were trained for 50 epochs using the Adam optimizer with a learning rate of 0.001 and a batch size not explicitly mentioned in the given information. The implementation was done using TensorFlow and Python 3 on the Ubuntu 20.04 operating system running on Microsoft Azure instances with 12 vCPUs and 112GB RAM.