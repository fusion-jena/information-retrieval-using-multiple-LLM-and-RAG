The article does not provide information on the specific regularization methods used to prevent overfitting in the deep learning pipeline for cloud detection with machine learning. However, some common regularization techniques used in deep learning include dropout, L1 regularization, and L2 regularization. Dropout involves randomly dropping out nodes during training to reduce co-dependencies between layers, while L1 and L2 regularizations add a penalty term to the loss function to discourage large weights and encourage simpler models. These techniques can help prevent overfitting by reducing model complexity and improving generalization performance.