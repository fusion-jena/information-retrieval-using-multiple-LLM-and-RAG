Based on the given context, there isn't any explicit information about the strategy implemented to monitor the model performance during training. However, we do have some insights into how different methods were evaluated based on their performance indices.

In the study, various methods were compared to correct sampling bias effects in species distribution modeling. These methods included BGenv, BGgeo, Fenv, and Fgeo. Their performances were assessed using three evaluation indices: ΔAUC, ΔDenv, and ΔDgeo. The mean relative ranks of these methods were presented in Figure 6, showing variations depending on the correction type and the number of presence sites.

For instance, when considering ΔDenv, Fenv was found to be the best method followed by BGenv when the number of presence sites was 20. As the number of presence sites increased, BGgeo was ranked the best in terms of ΔAUC, while BGgeo and Fenv performed well in terms of ΔDenv, and Fgeo excelled in terms of ΔDgeo.

However, none of the correction methods consistently outperformed others across all evaluation indices and numbers of presence sites. It was noted that BGenv often achieved first or second rank when focusing on a smaller number of presence sites, irrespective of the evaluation index used.

Overall, the discussion section suggests that the study primarily focused on comparing and evaluating the performance of different methods rather than monitoring the model performance during training. Therefore, without further context, it cannot be determined what specific strategies were employed to monitor the model performance during training.