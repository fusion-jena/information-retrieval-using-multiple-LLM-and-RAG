To monitor the model performance during training, several strategies have been employed. Firstly, various callbacks such as ReduceLROnPlateau, ModelCheckpoint, and EarlyStopping were used. These callbacks help in dynamically modifying the learning rate based on the validation accuracy and saving the best performing model throughout the training phase. Secondly, the training phase was conducted over 35 epochs with a batch size of 16, and the progress was carefully tracked using metrics such as accuracy, precision, recall, F1-score, AUC, model size, and analysis time. This comprehensive approach ensures that the model's performance can be thoroughly evaluated and fine-tuned during the training process.