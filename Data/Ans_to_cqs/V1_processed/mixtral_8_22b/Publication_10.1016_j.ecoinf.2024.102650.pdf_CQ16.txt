The given context does not provide information about the criteria used to determine when training is completed. However, generally speaking, some common criteria used to determine when training is complete include reaching a certain number of epochs or iterations, achieving a desired level of accuracy or performance on a validation dataset, observing a plateau or decrease in the validation loss over time, or meeting other predefined stopping conditions. These criteria may vary depending on the specific machine learning model, task, and dataset being used.

Based on the given context, it appears that the authors used Latent Dirichlet Allocation (LDA) to extract topics from Twitter data related to contaminated sites. They calculated perplexity using equation (1), which measures how well the LDA model fits the data. However, there is no mention of any specific criteria used to determine when training should stop. Therefore, we cannot definitively answer the query based solely on the provided context.