The sources of raw data used in the deep learning pipeline can vary depending on the specific application. For instance, in the field of marine ecology, imaging sonars have been employed to collect data on the abundance, species richness, and size of reef fish assemblages (Mar. Ecol. Prog. Ser. 717, 157–179). Additionally, video footage has also been used to detect, track, and count fish in unconstrained underwater environments (In: International Conference on Computer Vision Theory and Applications(VISAPP)).

For machine translation tasks, text corpora serve as the primary source of raw data. These datasets may be publicly available, like the LFW face database (Huang et al., 2008) and the CelebA dataset (Liu et al., 2015), which provide abundant, clear, high-quality examples for facial recognition tasks. However, there are often scarce datasets available for more specialized applications, such as underwater fish identification (Fig. 1. Images of some individual underwater fishes).

Deep learning models for speech recognition rely on audio recordings as their input data. For example, Song (2020) developed an English speech recognition model utilizing multiple features extracted from audio signals. Similarly, other studies have focused on recognizing human actions from video sequences captured by surveillance cameras (Uçar et al., 2017).

In summary, various methods are employed to gather raw data for use in deep learning pipelines. These include imaging sonars, video footage, text corpora, audio recordings, and sensor data. Depending on the specific application, researchers may utilize publicly available datasets or collect custom data tailored to their needs.