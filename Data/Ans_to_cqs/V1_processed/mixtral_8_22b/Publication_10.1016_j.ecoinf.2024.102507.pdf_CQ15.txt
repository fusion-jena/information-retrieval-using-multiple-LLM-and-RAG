Based on the given information, the exact optimization technique used in the deep learning pipeline is not explicitly mentioned. However, it is common practice in deep learning to use optimization algorithms like Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) during the training phase. These methods help minimize the loss function by adjusting the weights and biases of the model. Since the text mentions the use of TensorFlow and Keras, both of which support various optimization techniques including SGD and Adam, it can be assumed that one of these popular optimization techniques might have been employed in this case. Nevertheless, without explicit mention, it cannot be confirmed which specific optimization algorithm was utilized in this particular deep learning pipeline.