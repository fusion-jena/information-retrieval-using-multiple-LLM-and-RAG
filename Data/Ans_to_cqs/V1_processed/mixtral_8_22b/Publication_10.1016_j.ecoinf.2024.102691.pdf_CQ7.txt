Based on the given context, it does not explicitly mention how the data was split for deep learning model training. However, typically, datasets are divided into three subsets: training, validation, and testing sets. This division allows us to assess the model's ability to generalize its predictions to unseen data accurately.

The training set is used to fit the parameters of the model, while the validation set helps tune the model's hyperparameters and prevents overfitting by providing feedback during the training process. Lastly, the testing set evaluates the final model's performance on completely new data.

Although the exact splitting ratios can vary depending on the dataset size and specific requirements, common practices include dividing the data into 60-80% for training, 10-20% for validation, and 10-20% for testing.

In this case, since the context mentions that the evaluation metrics for each model were calculated after 300 epochs on the validation set, we can infer that there must have been a separate validation set used for tuning the model during training.