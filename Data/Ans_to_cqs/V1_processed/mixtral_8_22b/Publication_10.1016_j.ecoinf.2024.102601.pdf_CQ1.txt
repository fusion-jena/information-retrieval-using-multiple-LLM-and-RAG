The given context does not provide information about the specific methods used for collecting raw data in the deep learning pipeline. However, generally speaking, various methods can be employed depending on the nature of the problem being addressed. These may include surveys or questionnaires for gathering human input, sensors for capturing real-time environmental data, or publicly available datasets such as those found in open repositories like UCI Machine Learning Repository or Kaggle. Each method has its own advantages and limitations, and the choice depends on factors such as cost, time constraints, availability of resources, and the desired level of accuracy and reliability.

This study utilizes machine learning for multi-layered classification to precisely identify areas impacted by wildfires. To ensure precision in wildfire mapping, the model's performance was assessed using two main evaluation metrics: overall accuracy (OA) and Cohen's Kappa statistic. OA measures the ratio of correctly classified instances (both wildfire-affected and unaffected areas) to the total number of instances evaluated.

To optimize the data structure for machine learning classification, the researchers selected the 12 most relevant predictors from Sentinel-2 (S2) imagery. They also integrated explainable AI (XAI) techniques into their approach. For hyperparameter optimization, they employed both RandomizedSearchCV and GridSearchCV from the scikit-learn library to improve the performance of the Random Forest (RF) algorithm. Initially, RandomizedSearchCV was used to explore the hyperparameter space broadly, followed by a more targeted and comprehensive search using GridSearchCV to fine-tune the model.