Based on the given context, there is no explicit mention of any specific postprocessing steps involved after the model training. However, we do have some clues about potential postprocessing steps based on the information available.

Firstly, the text mentions using a minimum detection confidence score of 0.7 for benchmarking their best model. This suggests that they might have employed a form of thresholding or filtering as part of their postprocessing pipeline to eliminate low-confidence predictions.

Secondly, the table presented in the context provides average precision and recall values for different datasets. These metrics are typically calculated during the evaluation phase, which could indicate that these calculations were performed as part of the postprocessing step.

Lastly, the context also discusses using various image augmentation techniques such as flips, rotations, and affine transformations during the training process. While not explicitly mentioned, it is possible that similar transformations may have been applied during postprocessing to enhance the robustness of the model's predictions.

In conclusion, while the exact postprocessing steps are not specified in the given context, we can infer that thresholding, metric calculation, and potentially additional image transformations may have been involved in the postprocessing pipeline.