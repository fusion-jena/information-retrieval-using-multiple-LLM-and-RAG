The text mentions that the dataset was divided into three parts: 80% for training ensemble models, and the remaining 20% for validating each model to obtain individual optimized model hyperparameters. However, it does not explicitly mention any specific criteria used to split the data for deep learning model training, such as train, test, or validation sets. It only states that the optimization algorithm used was Optuna, which employs complex optimization algorithms to automatically search the hyperparameter space for the best combination of hyperparameters that minimizes the mean squared error. Additionally, the text discusses two important hyperparameters for Random Forest models: max_features and min_samples_leaf, but these do not directly relate to splitting the data for deep learning model training. Therefore, based on the given information, there is no clear criterion mentioned for splitting the data for deep learning model training.