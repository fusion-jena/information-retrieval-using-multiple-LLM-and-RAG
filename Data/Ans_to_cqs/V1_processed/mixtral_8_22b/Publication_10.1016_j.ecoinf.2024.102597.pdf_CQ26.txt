The given context does not provide information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, some commonly used techniques to address data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets or strata based on certain criteria, ensuring each subset has roughly the same distribution of classes or labels. This technique helps maintain class balance across different stages of the machine learning process.

Oversampling is a method where synthetic examples from the minority class are created to achieve balanced datasets. Techniques like SMOTE (Synthetic Minority Over-sampling Technique) generate artificial instances between existing minority class instances.

Undersampling reduces the size of the majority class by randomly removing instances until the desired ratio with the minority class is achieved. It should be noted that undersampling might lead to losing valuable information.

Diverse data collection aims to gather data from various sources and demographics to ensure fair representation and reduce biases. This approach can help improve the overall performance and reliability of the deep learning models.