From the provided context, it appears that the authors used several strategies to ensure the generalizability of their deep learning model. Firstly, they employed Convolutional Neural Networks (CNNs), a subset of Deep Neural Networks (DNNs), known for their ability to perform automated feature extraction, eliminating the need for hand-crafted feature extraction. This allows the model to learn relevant features directly from the data, improving its adaptability to diverse datasets.

Secondly, the authors mentioned using the Transfer Learning technique, a method where a pre-trained model is fine-tuned using a smaller dataset. This approach not only improves identification rates but also reduces computational costs. By leveraging this technique, the authors could potentially enhance the model's performance across a wide range of species, even when dealing with limited data for certain species.

Lastly, while the context does not explicitly mention cross-validation or stratified splitting techniques, the authors did consider two factors to determine the optimal number of training steps: correct identification rate and processing time. They tested different numbers of training steps and found that 4000 training steps worked best for most challenges, while 8000 training steps were needed for one specific challenge involving 41 species. This suggests that the authors might have used some form of validation process to evaluate the model's performance during training, although more specific details about the validation strategy are not provided in the available context.