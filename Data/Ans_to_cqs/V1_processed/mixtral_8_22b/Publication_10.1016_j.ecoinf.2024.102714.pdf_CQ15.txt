The text does not provide information about specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) being used in the deep learning pipeline. However, it mentions the use of an optimized random trees approach where each new tree learns from the errors of those previous. This suggests that some form of optimization is indeed employed, but the exact technique remains unspecified within the provided context.