The text does not explicitly state the strategy used to monitor the model performance during training. However, it mentions several methods used to evaluate the performance and effectiveness of the model after its development. These include accuracy, F1-score, confusion matrices, false positive and false negative percentages, balanced accuracy, F-measure, Cohen’s kappa coefficient, and Matthew’s correlation coefficient. These metrics are used to provide detailed information about the model's correct and incorrect classifications, enabling potential deficiencies in classifying specific classes or categories to be identified. Therefore, while the monitoring strategy during training isn't specified, it can be inferred that these same metrics may have been employed to track progress and adjust the model accordingly.