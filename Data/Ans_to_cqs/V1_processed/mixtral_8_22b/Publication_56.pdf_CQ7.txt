The text mentions that the data was split into two parts, with 70% being used for training the algorithms and the remaining 30% being used only for validation. This means that no separate testing set was created in this case. Instead, the validation set is likely used both to tune hyperparameters during training and to estimate the final performance of the trained models. It should be noted that this approach may lead to overly optimistic estimates of the model's generalization error if the same data is used for both tuning and evaluation. Ideally, a separate holdout dataset should be reserved exclusively for evaluating the final model's performance. However, in practice, it is common to see datasets divided into training, validation, and testing sets, often with ratios such as 60%, 20%, and 20%, respectively.