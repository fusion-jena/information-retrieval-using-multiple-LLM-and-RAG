To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the data was balanced by randomly duplicating presence records and deleting absence records until a balance of approximately 50:50 was achieved. This was executed using the ROSE package for R. Secondly, the data was split into three partitions - At, Av, and Bt - for internal assessment of accuracy. Thirdly, the AutoML procedure was employed, which generates a set of candidate models with architectures and hyperparameters selected at random from a predefined range of values. After training, the performance of these candidate models was evaluated using a left-out validation data set (Av). Lastly, the selected candidate model (typically the best performer among candidates) was further trained on the complete training data (Bt). These steps help prevent overfitting and improve the robustness and applicability of the model across different datasets.