After the model training process, several postprocessing steps can be taken to evaluate and interpret the results. Some common methods include:

1. Saliency Maps: These visualize which parts of the input data had the most significant impact on the model's predictions. They help identify important features or areas within the dataset.

2. Metrics Calculation: Various performance metrics such as accuracy, precision, recall, F1 score, ROC curves, and AUC scores can be calculated to assess the model's effectiveness. In this case, the authors used the Continuous Boyce Index (CBI) along with the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) due to challenges in obtaining true absences.

3. Confusion Matrix: This table summarizes the number of correct and incorrect predictions made by the model. It helps understand the types of errors the model makes and provides insights into its strengths and weaknesses.

In this specific example, the authors also determined the optimal model based on the minimum delta.AICc value and selected the final optimal parameters using the feature class 'LQP' and a regularization multiplier of 3.5. The mean AUC-ROC stood at 95.5%, while the average CBI index for the validation dataset was 82.6%.