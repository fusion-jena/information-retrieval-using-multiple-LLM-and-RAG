Unfortunately, the given context does not provide information about any specific preprocessing steps involved before training the deep learning models. However, it is common practice in machine learning and deep learning to perform various preprocessing techniques such as normalization, scaling, cleaning, augmentation, etc., depending on the type of data being used. Normalization typically involves rescaling the input features so they fall within a certain range, often between 0 and 1 or -1 and 1. Scaling can also help ensure that all features have similar magnitudes, preventing those with larger scales from dominating the learning process. Cleaning refers to handling missing or corrupted data points, either by removing them entirely or imputing appropriate values. Data augmentation is a strategy commonly applied when working with image data, where existing images are modified through operations like rotation, flipping, zooming, cropping, etc., to artificially increase the amount of available training data.