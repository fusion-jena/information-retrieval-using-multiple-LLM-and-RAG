To address data bias during preprocessing of the deep learning pipeline, several techniques are commonly used. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same proportion of classes in each set. This ensures that the model learns from a representative sample of all classes, reducing any potential bias towards one class over another.

Oversampling is a technique used when dealing with imbalanced datasets where one class has significantly fewer samples than others. It involves duplicating examples from the minority class until both classes have roughly equal representation. This helps prevent the model from being biased towards the majority class.

Undersampling, conversely, reduces the number of examples in the majority class so that both classes have approximately equal representation. While this may result in losing valuable information, it can help reduce bias towards the majority class.

Diverse data collection aims to gather data from various sources and environments to ensure that the model generalizes well across different conditions. By collecting diverse data, we can minimize any potential bias caused by using only specific types of data.

In addition to these techniques, the given context mentions methods for mitigating sampling bias through dataset filtering, such as the target-group background method (Phillips et al., 2009) and spatial thinning (Veloz, 2009). These methods can be applied simultaneously to further improve the quality of the dataset. Furthermore, the proposed method in the context can be combined with other useful statistical methods to handle spatial dependence or autocorrelation in species distribution.