In the given context, the authors have utilized Bayesian Optimization to find the optimal values for hyperparameters of their deep learning models. This technique uses a Gaussian process model of the objective function. The specific hyperparameters optimized in this case were batch size and initial learning rate. The optimization was carried out by minimizing the loss on the validation dataset. Additionally, the Stochastic Gradient Descent with Momentum ('sgdm') optimizer was used during training for a maximum of 10 epochs. Therefore, the optimization techniques applied in this deep learning pipeline include Bayesian Optimization and Stochastic Gradient Descent with Momentum.