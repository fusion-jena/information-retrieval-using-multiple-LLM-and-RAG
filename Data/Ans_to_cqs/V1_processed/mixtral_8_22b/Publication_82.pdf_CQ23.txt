The authors took several measures to ensure the generalizability of their deep learning models. They ran each of their 60 experiments for a total of 30 epochs, where one epoch is defined as the number of training iterations in which the particular neural network has completed a full pass of the whole training set. This ensured that the learning always converged well within 30 epochs. To enable a fair comparison between the results of all the experimental configurations, they also tried to standardize the hyper-parameters across all the experiments.

Additionally, to get a sense of how their approaches would perform on new unseen data and to keep track of whether any of their approaches were overfitting, they ran all their experiments across a whole range of train-test set splits. These included 80-20, 60-40, 50-50, 40-60, and finally 20-80 split ratios. This allowed them to test the performance of their models on different proportions of training and testing data. Furthermore, they had the mappings of multiple images of the same leaf taken from different orientations for 41,112 images out of the 54,306 images. However, it should be noted that when tested on a set of images taken under conditions different from the images used for training, the model's accuracy was reduced substantially, to just above 31%. Therefore, a more diverse set of training data is needed to improve the accuracy.