In the given context, there isn't explicit mention of specific data annotation techniques used in their deep learning pipeline. However, we can infer some possible methods based on the information provided.

Firstly, the term 'bounding box estimation' suggests that one of the techniques used could be bounding box annotation. Bounding box annotation involves drawing rectangles or squares around objects within an image to identify them. In this case, it seems like bounding box annotation might have been used to help the network learn the probabilities of the values around the continuous locations of the target bounding boxes.

Secondly, the use of 'ground truth' implies that they had some form of manually annotated data to compare their predictions against. Ground truth refers to the actual, known labels or categories assigned to data points, often done through manual annotation.

Lastly, while not directly mentioned, the process of extracting clusters of numbers and producing images from these clusters could suggest a form of semantic segmentation. Semantic segmentation involves assigning every pixel in an image to a certain class or category, essentially creating a richer understanding of the image content.

However, without further details about how exactly the data was processed and annotated, these remain speculations. The text does not provide concrete evidence of the use of instance segmentation, polygon annotation, key-point annotation, or any other specific data annotation technique.