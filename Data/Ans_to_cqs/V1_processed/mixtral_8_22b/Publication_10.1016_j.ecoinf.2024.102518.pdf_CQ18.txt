The authors used cross-validation to monitor the model performance during training. They created five subsets of data, each containing both presence and absence records. Four subsets were used for training, and the remaining subset was used for testing. This process was repeated five times until all subsets had been used once for testing. The threshold was then derived from the average output of these five models. Additionally, they evaluated nine different algorithms using AUC-ROC and Cohen's Kappa metrics to select the most suitable model. Ultimately, MaxEnt was chosen due to its balance between accuracy and robustness.