The given context does not provide information about the specific strategy used to monitor the model performance during training. However, it can be assumed that common strategies such as using validation datasets or cross-validation techniques could have been employed for this purpose. These methods involve setting aside a portion of the dataset for testing the model's accuracy and generalization capabilities while adjusting hyperparameters and optimizing the model architecture. Additionally, monitoring metrics like loss function values, accuracy, precision, recall, and F1 score are often used to evaluate the model's performance during training.