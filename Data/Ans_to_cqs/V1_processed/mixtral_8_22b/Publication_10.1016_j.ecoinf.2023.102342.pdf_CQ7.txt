Based on the provided context, there isn't explicit mention of the criteria used to split the data for deep learning model training such as train, test, and validation sets. However, I can provide general guidelines on how this splitting is typically done.

Data splitting is crucial in building robust and reliable models. Typically, the entire dataset is divided into three subsets: training, testing, and validation datasets.

1. Training Set: This subset is used to train the model, i.e., to fit the parameters of the model. It is usually the largest portion of the dataset.

2. Testing Set: After the model has been trained, it needs to be tested to see how well it performs on unseen data. This is where the testing set comes in. It helps evaluate the performance of the model and estimate its generalization error.

3. Validation Set: Also known as the development or dev set, this subset is used during the model development phase to fine-tune the model's hyperparameters. It provides feedback on the model's performance while tuning the parameters.

The common practice is to use 60-80% of the data for training, 10-20% for testing, and another 10-20% for validation. However, these percentages may vary depending on the size of the dataset and the problem at hand. For instance, when dealing with small datasets, one might opt for cross-validation instead of maintaining separate validation sets.