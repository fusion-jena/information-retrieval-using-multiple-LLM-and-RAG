Unfortunately, there isn't enough information in the given context to determine the specific strategy used to monitor the model performance during training. However, it does mention that after training all nine models for each stage, they formed an ensemble of the trained models by averaging their predictions. This implies that some form of evaluation was conducted post-training to assess the performance of these models. Additionally, it states that all architectures achieved a classification accuracy of over 95.8%, with the VGG model achieving the highest accuracy of 96.8%. These results suggest that the performance of the models was monitored throughout the training process, but the exact methods used aren't explicitly mentioned.