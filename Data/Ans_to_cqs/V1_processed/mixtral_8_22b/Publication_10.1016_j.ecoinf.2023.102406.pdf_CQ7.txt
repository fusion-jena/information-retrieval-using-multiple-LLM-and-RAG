The text does not provide explicit information about the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it mentions that the testing data was 25% of the samples for this modeling, which suggests that the remaining 75% of the data could have been used for training purposes. It also states that the testing data was randomly sampled, indicating that a random sampling approach might have been employed to divide the dataset. Furthermore, the use of the 'createDataPartition' function from the 'caret' package implies that the splitting process followed good practices such as stratified sampling to ensure balanced representation across classes in both the training and testing datasets. Nevertheless, without more detailed information, we cannot definitively state the exact criteria used for splitting the data.