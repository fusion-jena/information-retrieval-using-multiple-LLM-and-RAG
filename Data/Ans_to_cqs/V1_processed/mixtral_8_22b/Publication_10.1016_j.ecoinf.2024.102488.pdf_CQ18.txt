The strategy implemented to monitor the model performance during training involves using Recursive Feature Elimination and Cross-Validation (RFECV) for feature selection. This method helps reduce redundancy caused by multi-source feature datasets and improves model performance. RFECV is a wrapper approach to feature selection that works by recursively pruning away the least important features. In this case, a five-fold cross-validation was employed to determine the optimal number and combination of features. By monitoring the cross-validation accuracy, the researchers aimed to achieve the highest possible accuracy level during the training phase.