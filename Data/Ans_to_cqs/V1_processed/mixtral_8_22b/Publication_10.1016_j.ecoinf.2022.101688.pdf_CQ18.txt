Based on the given information, there isn't any explicit mention of a specific strategy implemented to monitor the model performance during training. However, one can infer from the text that the performance of the network was computed on each testing file and reported on the F1-score, which is commonly used in literature. This suggests that the F1-score might have been used as a metric to evaluate the model's performance during training. Additionally, the use of Microsoft Azure with the Data Science Virtual Machine and a NCv2-series virtual machine (NVIDIA Tesla P100 GPU) implies that these tools were utilized for both training and testing the models. It's also mentioned that the results are averaged across 13 unique executions, indicating that multiple runs were conducted to ensure consistency and reliability in the evaluation process. Therefore, while not explicitly stated, it can be assumed that monitoring the model performance during training involved tracking metrics such as the F1-score and conducting multiple runs to validate the results.