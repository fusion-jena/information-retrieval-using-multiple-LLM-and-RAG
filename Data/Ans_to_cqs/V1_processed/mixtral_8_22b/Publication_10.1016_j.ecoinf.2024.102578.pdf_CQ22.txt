Three main metrics are used to evaluate the performance of the deep learning model: Accuracy, Precision, and Recall. These metrics are defined based on True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).

Accuracy measures the proportion of correct predictions in the whole dataset. It is calculated as (TP + TN)/(TP + FP + TN + FN).

Precision, also known as positive predictive value, measures the proportion of images that a model classified as a specific category C that are actually category C. It is calculated as TP/(TP + FP).

Recall, also known as sensitivity or true positive rate, measures the proportion of images that are actually a specific category C that the model classified as C. It is calculated as TP/(TP + FN).

Additionally, the F1 score is used, which is the weighted average of precision and recall. It is calculated as 2*(precision * recall)/(precision + recall).

In Table 5, these metrics are applied to evaluate the performance of the image quality model on the test data for both Finnmark and Yamal locations. For example, for Finnmark location, the precision for 'bad' images is 0.920, the recall is 0.910, and the F1 score is 0.915. Similarly, for 'good' images, the precision is 0.986, the recall is 0.988, and the F1 score is 0.987.