Based on the given context, there isn't specific information about the techniques used to address data bias during preprocessing of the deep learning pipeline. However, some common techniques used to address data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes in both sets. This ensures that the model is trained and tested on representative samples from each class.

Oversampling involves increasing the number of instances in the minority class by duplicating existing instances or creating synthetic ones. Undersampling, on the other hand, involves reducing the number of instances in the majority class by randomly removing them or selecting only those that are most informative. Both methods aim to balance the class distribution in the dataset.

Diverse data collection involves collecting data from various sources and ensuring that it represents all possible scenarios. This helps prevent biases caused by limited or unrepresentative datasets.

Without more specific information regarding the context, it cannot be determined which technique was used in this case.