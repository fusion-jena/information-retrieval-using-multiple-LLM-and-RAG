The Random Forest algorithm used in this study does not have a specific criterion to determine when training is complete like some other machine learning algorithms such as neural networks where validation loss plateau might be used. Instead, the performance of the model is evaluated using out-of-bag (OOB) samples, which are those not included in the training subset. In this case, the total number of samples used for validation is 8. Additionally, hyperparameter tuning is performed to find the optimal parameters for the model. In this study, the maximum shaft number value was tested from 1 to 100 and the minimum sample number from 1 to 50. Finally, the most accurate results for RF were obtained when the maximum tree depth was set to 10 and the minimum number of samples was set to 2. This indicates that the training process is considered complete once the optimal hyperparameters have been found through testing different combinations.