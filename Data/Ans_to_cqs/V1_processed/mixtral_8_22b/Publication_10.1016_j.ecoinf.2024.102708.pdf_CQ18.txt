Based on the given information, there isn't any explicit mention of a strategy used to monitor the model performance during training. However, some insights about the model performance can still be derived from the available data.

From the table, we see that the metrics such as precision, recall, and F-score have been computed for various models like FRCNN, TPH-YOLOv5, YOLOv5s, and YOLOv5m. These metrics help evaluate the effectiveness of these models in identifying objects accurately. Additionally, the standard errors and confidence intervals for precision and recall provide insight into the variability and reliability of the model predictions.

Moreover, the text mentions that the results indicate that YOLOv5s, being the smallest model, performs best in terms of precision. This suggests that monitoring the performance of the models during training might involve comparing their precision values and selecting the one with the highest value.

However, without direct evidence or explanation regarding the strategy employed to monitor the model performance during training, it cannot be definitively stated what approach was taken.