Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does discuss some aspects related to data augmentation and model training.

For instance, the authors use the Keras image\_data\_generator function for image augmentation, which includes random assignments like rotation, width and height shifts, shearing, zooming, flipping, and filling modes. This technique can help improve the diversity of the dataset and potentially mitigate biases caused by limited data variability.

Additionally, the paper mentions building upon previous works that combine MegaDetector with manual classification and custom-trained models. While this doesn't directly relate to addressing data bias, it suggests that multiple approaches might be integrated into their methodology to enhance overall performance.

However, without further information regarding the dataset characteristics, potential imbalances, or other sources of bias, it remains unclear whether these methods specifically target data bias reduction. Therefore, based solely on the provided context, I cannot definitively state what techniques are employed to address data bias during preprocessing of the deep learning pipeline.