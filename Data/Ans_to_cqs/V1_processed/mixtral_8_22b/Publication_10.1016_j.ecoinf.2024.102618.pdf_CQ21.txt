After the model training process, several postprocessing steps can be performed depending on the specific requirements of the project or task. Some common postprocessing steps include:

1. Model Evaluation: After training, the performance of the model needs to be evaluated using various evaluation metrics like accuracy, precision, recall, F1 score, etc. These metrics help us understand how well our model has learned to predict the target variable.

2. Confusion Matrix: A confusion matrix is a table used to evaluate the performance of a machine learning algorithm. It provides information about actual and predicted values generated by a classification model. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class.

3. Saliency Maps: Saliency maps are visualizations that highlight the pixels in an input image that contribute most strongly to the output of a convolutional neural network (CNN). They provide insights into what parts of the input data are important for making accurate predictions.

4. Hyperparameter Tuning: Postprocessing may also involve tuning hyperparameters to improve the performance of the model further. This could include adjusting the learning rate, batch size, regularization parameter, etc.

5. Ensemble Models: Another postprocessing technique is creating ensembles of multiple models to improve prediction accuracy. This involves combining the outputs of individual models to produce a final prediction.

Based on the provided context, it appears that the authors have employed some of these postprocessing techniques. For instance, they have computed the accuracy, precision, recall, and F1 scores of their deep learning models. Additionally, they have created confusion matrices to analyze the performance of their models. Furthermore, they have experimented with ensemble modeling to enhance the accuracy of their predictions.