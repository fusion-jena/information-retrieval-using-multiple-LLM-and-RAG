Based on the given information, it appears that the optimization of the Random Forest Regression (RFR) model's hyperparameters involved conducting multiple experiments and comparisons. This process is often referred to as hyperparameter tuning. While the specific method used for this task isn't explicitly mentioned, common approaches include Grid Search, Random Search, Bayesian Optimization, and Gradient-based optimization. Given the nature of the problem and the fact that multiple experiments were conducted, it can be inferred that either Grid Search or Random Search might have been used. These methods involve defining a range of values for each hyperparameter and then training the model with different combinations of these values. The combination that yields the best performance is chosen as the optimal set of hyperparameters. It should be noted that without explicit mention of the method used, this remains an educated guess.