After the model training, several postprocessing steps were taken to evaluate the model's performance. Firstly, the model was tested using a separate test subset consisting of spectrograms of two-second duration, which were not included during the training phase. The multi-class predictions made by the model were evaluated using standard metrics such as True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN). These metrics helped determine the accuracy of the model's predictions.

Furthermore, since the model produced output probabilities between 0 and 1, a decision threshold 'θ' was established to classify each prediction as either positive (presence) or negative (absence). Using these θ-dependent elemental indicators, two important measures were derived - Precision (P) and Recall (R). Precision represented the ratio of correctly predicted presences out of all predicted presences, while Recall indicated the fraction of accurately detected presences among all actual presences.

Additionally, the evaluation also considered the processing time required for extracting features using Short Time Fourier Transform (STFT) and Fast Cosine Transform (FCT). Despite the higher dimensionality of vectors generated through FCT compared to STFT, the latter was preferred due to its significantly shorter processing time.

Finally, the Uniform Manifold Approximation and Projection (UMAP) technique was employed to visualize the variety and clustering of representative samples in both feature spaces (STFT and FCT). This facilitated the prediction of encouraging separability in the supervised learning process.