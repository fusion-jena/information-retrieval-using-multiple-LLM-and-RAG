Based on the provided context, there isn't explicit information about how the authors split their dataset into training, testing, or validation sets for their deep learning models. However, typically, datasets are divided into these subsets using various strategies such as random sampling, stratified sampling, or time-series based splitting depending on the nature of the problem and the available data. The common practice is to use approximately 70-80% of the data for training, 10-15% for validation, and 10-15% for testing. It would be reasonable to assume that the authors followed similar practices when preparing their dataset for deep learning model training.