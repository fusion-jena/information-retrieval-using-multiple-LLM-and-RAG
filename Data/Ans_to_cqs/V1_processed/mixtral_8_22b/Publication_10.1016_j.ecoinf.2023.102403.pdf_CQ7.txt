Based on the given context, there is no explicit mention of the specific criteria used to split the data for deep learning model training (i.e., train, test, validation sets). However, it can be inferred that the authors followed standard practices for splitting their cleaned and filtered dataset into different subsets for training, testing, and validating their models. Typically, this involves randomly dividing the dataset into three parts: training set (used to fit the model), validation set (used to tune hyperparameters during model development), and test set (used to evaluate the final performance of the trained model). Without additional context or access to the full paper, it is not possible to provide more detailed information about the exact proportions or methods used for splitting the data.