The given context does not provide explicit details regarding the specific criteria used to split the dataset into training, testing, and validation sets for the deep learning models. However, based on common practices in machine learning and deep learning, some possible criteria include:

1. Random splitting: This involves randomly dividing the entire dataset into three subsets - training, testing, and validation. A typical ratio might be 70% for training, 15% for validation, and 15% for testing.

2. Stratified sampling: In this method, the dataset is divided such that the distribution of classes remains consistent across all subsets. This ensures that the model gets exposed to a representative sample of each class during both training and evaluation phases.

3. Time-series splitting: When dealing with temporal datasets, it is essential to maintain the chronological order while creating splits. Typically, earlier data points are allocated for training, followed by validation and then testing.

4. Cross-validation: This technique involves partitioning the original dataset into 'k' equal-sized subsamples or folds. Each fold serves as the validation set once, while the remaining k-1 folds form the training set. This process is repeated 'k' times, ensuring every observation has been part of the validation set exactly once.

Without additional context, it cannot be determined which of these methods, if any, were employed for splitting the dataset in this particular case.