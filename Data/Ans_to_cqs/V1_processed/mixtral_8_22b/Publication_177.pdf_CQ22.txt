The performance of the deep learning models in this study was evaluated using several metrics due to the presence of an imbalanced dataset. Accuracy alone would not have been a sufficient metric for evaluating the performance of the proposed method. Therefore, additional metrics such as recall, precision, specificity, and F1-score were also utilized. These metrics are based on the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). True positives refer to cases where the predicted species match the ground truth class, while false positives occur when the predicted species do not match the ground truth class. Similarly, true negatives represent cases where the absence of a particular species is accurately identified, whereas false negatives occur when the absence of a species is incorrectly classified as its presence. The equations representing these evaluation metrics are presented in the paper.