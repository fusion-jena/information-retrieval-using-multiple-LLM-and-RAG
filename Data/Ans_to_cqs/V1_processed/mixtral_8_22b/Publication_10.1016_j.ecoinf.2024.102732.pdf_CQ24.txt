The provided context does not directly address the specific strategies used to handle randomness in the deep learning pipeline, such as managing random seed values. However, it does mention the use of machine learning algorithms like Random Forest Regression Algorithm in estimating forest aboveground biomass using combinations of Landsat 8 and Sentinel-1A data (Purohit et al., 2021a; Purohit et al., 2021b). The paper also cites Probst et al.'s work (2019), which discusses hyperparameters and tuning strategies for Random Forest models.

While these sources do not explicitly provide information about handling randomness in deep learning pipelines, they suggest some general strategies applicable to machine learning models. These include setting fixed seeds for reproducibility, cross-validation techniques, and parameter tuning methods like grid search or randomized search.

To specifically manage randomness in deep learning pipelines, common practices involve fixing the random seed value before training the model, ensuring consistent results across different runs. Additionally, employing techniques like k-fold cross-validation helps mitigate the impact of random initialization on model performance. Lastly, utilizing ensemble methods, such as bagging or boosting, can further reduce variance caused by randomness in individual models.