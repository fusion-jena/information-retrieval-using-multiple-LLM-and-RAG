The given context does not provide explicit details about the specific preprocessing steps used before training the deep learning models (SAE and SVM). However, generally speaking, common preprocessing techniques applied before training deep learning models include normalization, scaling, cleaning, and augmentation. Normalization involves rescaling the input features so they fall within a certain range, often between 0 and 1 or -1 and 1. Scaling adjusts the scale of independent variables to bring all variables to an approximate magnitude, which helps prevent any single variable from dominating the outcome. Cleaning refers to handling missing values, outliers, and noisy data. Data augmentation generates additional training samples by applying transformations such as rotation, flipping, zooming, etc., to increase the size of the dataset and reduce overfitting.