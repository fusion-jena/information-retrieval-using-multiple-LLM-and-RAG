The authors performed a 5-fold cross-validation to assess the robustness of their method. For each fold, they randomly selected 80% of their dataset Videoclips to train their model and 20% to test it. They couldn't directly split images from the frame dataset because images from the same videos were too similar, leading to a model with low generalization capacity. Instead, they used an 80% training/20% testing random split on videos rather than images to ensure full independence between images of the training set and testing set. No mention is made of a separate validation set or any specific criteria used to select the folds.