In the given context, there is no explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on general practices in machine learning and deep learning, some common techniques can be mentioned.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes in each subset. This helps prevent any imbalance in the target variable from affecting the performance of the model.

Oversampling and undersampling involve adjusting the number of samples in the minority and majority classes, respectively. Oversampling increases the number of instances in the minority class, while undersampling reduces the number of instances in the majority class. Both techniques aim to balance the dataset and reduce bias towards the majority class.

Diverse data collection refers to collecting a wide range of data samples representing different scenarios, environments, and conditions. This ensures that the model learns from diverse data points and becomes more robust and accurate.

While these techniques are not explicitly discussed in the given context, they are commonly employed in addressing data bias during preprocessing of deep learning pipelines.