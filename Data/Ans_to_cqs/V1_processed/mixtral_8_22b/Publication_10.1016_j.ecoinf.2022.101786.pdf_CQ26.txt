Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does discuss some aspects related to managing data for training, validating, and testing their Convolutional Neural Network (CNN).

They mentioned using manually annotated images to create separate datasets for training, validation, and testing purposes. This approach can help ensure that the network learns from a diverse range of examples and reduces potential biases caused by imbalanced classes or non-representative samples.

Additionally, they discussed the challenge of collecting representative datasets in the deep sea, which could imply that efforts have been made to gather diverse data to minimize biases. They also adjusted certain model parameters like resolution, batch size, and subdivisions to optimize resource usage and training speed.

However, without further information about how these datasets were created and whether any specific techniques were employed to handle class imbalance or other forms of data bias, we cannot definitively state what methods were used to address data bias during preprocessing.