Based on the given context, there isn't explicit information about the methods used for collecting raw data in the deep learning pipeline. However, we can infer some possible methods from the context.

In the context of ESS-DIVE, which enables advanced search of data across its data packages, it's mentioned that projects like AmeriFlux are required to submit their data for long-term stewardship. This suggests that one method of data collection could be direct submission by researchers or organizations.

Furthermore, the mention of AmeriFlux sites implies that sensor data might be collected. Sensors are commonly used in various fields to collect real-time data, and AmeriFlux, being a network of PI-managed sites measuring ecosystem CO2, water, and energy fluxes using micrometeorological methods, likely uses such sensors.

However, it's important to note that these are assumptions based on the given context. The actual methods used for collecting raw data in the deep learning pipeline could vary widely depending on the specific application and field. These methods could range from manual data entry, use of IoT devices, web scraping, APIs, surveys, experiments, simulations, etc.

Therefore, while we can speculate that direct submissions and sensor data might be part of the data collection process in the context of ESS-DIVE, a definitive answer regarding the methods used for collecting raw data in the deep learning pipeline cannot be provided based solely on the given context.