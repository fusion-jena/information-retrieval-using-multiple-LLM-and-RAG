After the model training, several postprocessing steps can be taken to evaluate the performance of the deep learning (DL) network. These include generating saliency maps, calculating metrics, and creating confusion matrices.

Saliency maps help visualize which areas of the image contribute most significantly to the final prediction made by the model. They provide insights into how the model interprets different features within the images.

Calculating various metrics such as accuracy, precision, recall, F1 score, etc., helps quantitatively assess the performance of the model. These metrics offer valuable information about the strengths and weaknesses of the model when dealing with specific classes or types of inputs.

Confusion matrices are another useful tool for evaluating the performance of the trained model. A confusion matrix provides a summary of prediction results on a classification task. It displays the count of true positives, false negatives, false positives, and true negatives for each class. By analyzing the confusion matrix, researchers can identify patterns of misclassification and understand where the model struggles.

In the given context, confusion matrices are mentioned as part of the postprocessing steps after model training. Furthermore, the text discusses the use of annotated data during the supervised training process and the subsequent evaluation of the network on an independent dataset (testing data set). However, the exact postprocessing steps involving saliency maps and metric calculations are not explicitly stated but are common practices in evaluating deep learning models.