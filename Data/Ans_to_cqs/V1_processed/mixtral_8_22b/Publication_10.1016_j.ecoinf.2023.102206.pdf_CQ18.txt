Based on the given context, there isn't any explicit mention of a specific strategy used to monitor the model performance during training. However, we can infer that the authors might have monitored the performance of models like Extreme Learning Machine (ELM), General Regression Neural Network (GRNN), and Support Vector Regression (SVR) through various evaluation metrics such as accuracy, precision, recall, or mean squared error. These metrics help assess how well the models perform during both training and testing phases. Additionally, the authors discuss the issue of overconfidence in these models when dealing with datasets having large data distribution differences between the source and target domains. To address this problem, they propose Intuitionistic Fuzzy Transfer Learning (IFTL). By implementing IFTL, the authors aim to capture uncertainty resulting from extreme variations in data distribution or predictive tasks across different datasets. Furthermore, IFTL helps restrict overconfidence for improved learning while transferring learned knowledge. Although not directly mentioned, monitoring the performance of IFTL would likely involve evaluating its ability to reduce overconfidence and enhance learning compared to traditional methods like Fuzzy Transfer Learning (FTL).