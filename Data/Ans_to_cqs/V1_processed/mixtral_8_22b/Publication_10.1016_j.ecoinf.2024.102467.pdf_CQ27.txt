Based on the given context, there is no information about the specific process followed to deploy the trained deep learning model. However, typically after training a deep learning model, it needs to be serialized into a format that can be used for prediction or inference. This usually involves saving the weights and architecture of the model into a file using a standard format such as HDF5 or ONNX. Once the model has been serialized, it can then be deployed onto a platform suitable for its use case. For example, if the model is being used for real-time object detection, it may need to be deployed onto a GPU-enabled device capable of handling high throughput video streams. Alternatively, if the model is being used for batch processing tasks, it could be deployed onto a cloud-based platform such as AWS SageMaker or Azure Machine Learning Studio. Ultimately, the choice of deployment platform will depend on factors such as cost, scalability, latency, and security requirements.