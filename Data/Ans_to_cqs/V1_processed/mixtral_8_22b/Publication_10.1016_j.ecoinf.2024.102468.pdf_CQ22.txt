The performance of the proposed WT-HMM is evaluated using two main metrics: accuracy and F1-score. Accuracy measures the overall correctness of the model's detection and classification by calculating the ratio of correctly classified instances to the total number of instances. It is calculated using Equation (11), which divides the sum of True Positives (TP) and True Negatives (TN) by the total number of classifications.

Precision, also known as Positive Predictive Value, is another metric used to assess the performance of the model. It focuses on the correctness of positive detections and classifications and helps evaluate the model's ability to avoid false positives. Precision is calculated using Equation (12), which divides the number of True Positives by the sum of True Positives and False Positives (FP).

Recall, also known as Sensitivity or True Positive Rate, is yet another metric used to evaluate the performance of the model. It measures the proportion of true positive detections and classifications among the actual positive instances in the dataset. Recall is calculated using Equation (13), which divides the number of True Positives by the sum of True Positives and False Negatives (FN).

Finally, the F1-score provides a balanced measure of the model's performance, considering both precision and recall. It is calculated using Equation (14), which multiplies twice the product of precision and recall divided by their sum. Typically, a higher F1-score (close to 1) indicates a better model performance, while a lower F1-score (close to 0) suggests that the model may struggle to accurately classify positive instances and/or miss a significant number of them.