The text does not provide explicit information about how the data is split for deep learning model training. However, it can be inferred that the authors use a validation set to evaluate their models during training, as they mention choosing the most suitable architecture based on the best validation accuracy and precision obtained during training. This suggests that they likely follow common practices in machine learning where the dataset is typically split into three parts: training, validation, and testing sets. The training set is used to fit the model, the validation set is used to tune hyperparameters and select the best model, and the testing set is used to evaluate the final performance of the selected model. It is also mentioned that the models are tested on a separate testing file, suggesting that there might be a distinct testing set apart from the training and validation sets.