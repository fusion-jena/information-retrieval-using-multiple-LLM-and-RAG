Based on the provided context, there does not seem to be any direct information regarding strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, it is common practice in machine learning and deep learning to use fixed random seeds or deterministic algorithms to ensure reproducibility and consistency across experiments. This allows researchers to compare different methods and architectures more accurately. Additionally, techniques like cross-validation and ensemble methods can help mitigate the effects of randomness in training datasets and improve overall performance.