Based on the given context, it is not explicitly stated how the data was split for deep learning model training. However, it can be inferred that some form of splitting was done due to mentions of cross-validation and grid search techniques. Cross-validation is often used to evaluate the performance of a model by dividing the data into k subsets or folds, where each fold serves as the testing set once while the remaining folds serve as the training set. Grid search is a technique used to find the optimal combination of hyperparameters for a model by trying out different combinations and evaluating their performance using cross-validation. Therefore, it can be assumed that the data was divided into multiple sets for training, testing, and validation purposes. However, without explicit information about the exact proportions or methods used for splitting the data, it cannot be definitively answered what criteria were used to split the data for deep learning model training.