To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the training samples were divided into two parts using a proportion of 80% for the training dataset and 20% for the test dataset. This division was done randomly to prevent any bias towards specific data points. Secondly, the study utilized a grid search method (GridSearchCV) based on the out-of-bag (OOB) error and five-fold cross-validation to find the optimal parameters of the model. Cross-validation is a powerful preventive measure against overfitting, ensuring that the model can perform well with unseen data. Lastly, the n_estimators, minleaf, and max_features parameters were varied systematically within specified ranges to identify the best combination that would yield high accuracy without increasing the complexity of the model. These steps ensured that the final model was robust and capable of handling diverse datasets.