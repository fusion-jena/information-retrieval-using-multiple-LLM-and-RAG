During the training process, the models are validated using a combination of the original base model validation set and 100 frames per class from the labeled December 3rd, 2019 training set. These frames are randomly pooled per experiment. This approach allows for simultaneous assessment of the model's performance across both environments. Additionally, early stopping is deployed if the validation loss does not improve within 10 epochs.