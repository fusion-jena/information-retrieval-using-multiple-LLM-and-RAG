Based on the given context, no explicit mention of regularization methods like dropout or L2 regularization has been made. However, the issue of overfitting was encountered when the model was trained on both MNIST and custom datasets due to the large number of training examples in MNIST compared to the small test set. To address this, Model 4 was trained only on the custom dataset, resulting in better performance. Additionally, k-fold cross-validation was used to find the optimal train-test split for the model. While these strategies help mitigate overfitting, they do not directly correspond to traditional regularization methods like dropout or L2 regularization.