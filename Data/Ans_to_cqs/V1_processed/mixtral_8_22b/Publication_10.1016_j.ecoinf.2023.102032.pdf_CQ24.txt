The article does not provide information on handling randomness in the deep learning pipeline or using random seed values. Therefore, it is not possible to provide an accurate response based solely on this source.

However, some common strategies used to manage randomness in deep learning pipelines include setting fixed seeds for reproducibility, using techniques such as cross-validation and bootstrapping to reduce variability, and employing ensemble methods to combine multiple models trained with different initializations. Additionally, researchers may choose to report results across multiple runs with different random seeds to demonstrate the robustness of their findings.