After the model training process, several postprocessing steps can be taken to evaluate the performance of the trained model. These include metrics calculation, confusion matrices, and saliency maps.

Metrics calculation involves computing various evaluation metrics such as Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and coefficient of determination (R^2). These metrics help assess the quality of predictions made by the model. For instance, the 'yardstick' package for R provides functions like'metrics' to calculate these values.

A confusion matrix is another useful tool for understanding the performance of classification models. It summarizes the number of correct and incorrect predictions made by the classifier, broken down into true positives, false negatives, true negatives, and false positives. This information helps compute additional metrics like precision, recall, and F1 score.

Lastly, saliency maps are visualizations that highlight which parts of input data contribute most significantly to the output of a machine learning model. They provide insights into how the model makes its decisions and can aid in interpreting complex models.

These postprocessing techniques offer valuable insights into the strengths and weaknesses of a trained model, enabling researchers to fine-tune their approach or select appropriate models based on their requirements.