The text does not provide specific details about the regularization methods used in the deep learning pipeline to prevent overfitting. However, it mentions that ensemble modeling is used to enhance predictive accuracy, increase stability, improve generalization, provide robustness against overfitting, and increase model interpretability. Ensemble modeling combines the predictions of diverse models to achieve more accurate and reliable results by mitigating the risks of errors and biases, resulting in stable predictions that generalize well to unseen data. In this case, the authors used the AUC-weighted ensemble method to build the final ensemble model, which utilizes performance metrics to effectively combine the predictions from all models. Additionally, the authors mention that they used a 10-fold cross-validation design to validate each model after fitting each MLM with optimized parameters. Cross-validation is a common technique used to evaluate the performance of machine learning models and prevent overfitting. While the text does not explicitly state the use of regularization methods such as dropout or L2 regularization, these techniques could also be applied within the individual models used in the ensemble to further reduce overfitting.