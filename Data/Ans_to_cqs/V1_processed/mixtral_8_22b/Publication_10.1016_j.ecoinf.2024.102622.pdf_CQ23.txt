To ensure the generalizability of their deep learning model, several measures were implemented by L. Liu et al. These include using diverse datasets, employing cross-validation techniques, and stratified splitting. Specifically, they collected data from different regions and years, including low-, medium-, and high-coverage levels, to create a diverse dataset. They also utilized five modeling methods - Random Forest (RF), Support Vector Machine (SVM), Multi-Layer Perceptron (MLP), Extreme Gradient Boosting (XGBoost), and Multiple Linear Regression (MLR) - to improve the model's performance and robustness. Furthermore, they divided the dataset into training and verification sets in a 3:1 ratio, ensuring that the model could be tested against unseen data. Lastly, they extended the model to Northeast China in 2023, demonstrating its strong generalization ability and robustness.