The study uses a Multilayer Perceptron (MLP) model for its deep learning approach. The hyperparameters used in the model include the number of neurons in the first and second layers, the strength of the L2 regularization term, the solver for weight optimization, initial learning rate, learning rate schedule for weight updates, maximum number of iterations, and maximum number of iterations with no improvement. The specific range of these hyperparameters can be found in Table 2 of the given context. The optimal values for each parameter were determined through a grid search process, focusing on minimizing the Mean Squared Error (MSE) metric.