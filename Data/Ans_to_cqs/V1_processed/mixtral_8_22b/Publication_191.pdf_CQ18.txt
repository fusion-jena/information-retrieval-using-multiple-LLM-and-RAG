The strategy implemented to monitor the model performance during training varies depending on the specific model used. For instance, in the case of the deconvolutional network, a fixed learning policy is employed. The learning rate is initially set to 10^-3 and then decreased by a factor of 10 when the validation set accuracy stops improving. This indicates that the model performance is monitored based on the validation set accuracy. On the other hand, for the model trained using the Caffe framework, a step learning policy is utilized. The learning rate is initially set to 10^-3 for all layers but is higher for the newly defined last fully connected layer. The learning rate is then decreased by a factor of 10 every 20K iterations and stopped after 100K iterations. Here, the model performance seems to be monitored based on the number of iterations and the learning rate adjustments. However, without explicit mention of validation set accuracy monitoring in this context, it cannot be confirmed if this strategy is also used here.