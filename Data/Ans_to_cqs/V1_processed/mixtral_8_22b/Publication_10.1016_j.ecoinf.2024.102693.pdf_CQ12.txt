The pipeline uses a combination of Convolutional Neural Networks (CNNs) and Transformer-based models. Specifically, it employs ResNet-50, a popular CNN architecture known for its robustness and effectiveness in image classification tasks. Additionally, the pipeline utilizes Vision Transformers (ViTs), which are based on the original Transformer architecture but adapted for computer vision tasks. These models have shown exceptional performance in various natural language processing tasks and have been successfully applied to computer vision problems. However, one limitation of ViTs is their reliance on large amounts of pre-training data. To overcome this, the authors propose Volo, a variant of ViT with a novel Outlook Attention mechanism designed to improve fine-grained token representations and aggregate global information.

Reference(s):
[1] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, ≈Å., & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.
[2] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.
[3] Yuan, F., Li, W., Wang, C., Wu, Q., & Huang, J. (2022). Volonet: Fine-grained token representation for vision transformers. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10977-10986.
[4] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778.