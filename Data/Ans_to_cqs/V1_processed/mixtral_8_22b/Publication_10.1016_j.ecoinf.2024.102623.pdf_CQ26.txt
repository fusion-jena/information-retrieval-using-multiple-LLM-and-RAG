The text mentions several techniques used to address data bias during preprocessing of the deep learning pipeline. These include addressing issues such as class imbalance and sampling bias. To tackle class imbalance, two key aspects need to be addressed: ecological fallacy and Simpson's paradox. However, the text does not provide explicit details on how these issues are specifically addressed. Nevertheless, common methods to handle class imbalance include stratified splitting, oversampling, undersampling, and diverse data collection. Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes in both sets. Oversampling increases the number of instances from minority classes by duplicating existing samples or generating synthetic ones. Undersampling reduces the number of instances from majority classes by randomly removing some samples. Lastly, diverse data collection aims to gather more representative data from underrepresented classes. In addition to these techniques, the text also mentions the use of advanced deep learning architectures like MLP with residual connections, batch normalization, ReLU activation functions, and sigmoid functions for multi-label classification. Furthermore, it discusses the use of AdamW optimizers, setting appropriate weight decays, learning rates, and introducing dropouts to improve model performance.