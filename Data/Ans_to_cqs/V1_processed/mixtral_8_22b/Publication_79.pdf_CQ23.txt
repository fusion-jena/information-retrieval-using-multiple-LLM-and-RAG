To ensure the generalizability of the deep learning model, several measures were taken. Firstly, a diverse dataset was used for training and validation purposes. The dataset included samples generated through data augmentation procedures, which helped increase its diversity. Secondly, cross-validation was employed to evaluate the performance of the model. Specifically, three experiments were conducted using different regions for training, validation, and testing. Each experiment repeated the process until all three regions had semantic segmentation resulting from the cross-validation approach. Lastly, stratified splitting was also applied during the training phase. During this stage, early stopping criteria were set to halt the training process if the validation accuracy did not improve after 50 epochs. This measure ensured that the model would not overfit on the training data, thereby improving its ability to generalize to new data. Overall, these measures aimed to enhance the robustness and reliability of the deep learning model by ensuring it could perform well on unseen data.