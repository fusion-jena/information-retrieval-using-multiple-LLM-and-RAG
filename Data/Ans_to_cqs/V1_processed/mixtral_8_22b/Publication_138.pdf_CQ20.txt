Based on the given context, there is no information about the specific hardware resources used for training the deep learning models mentioned such as LeNet, AlexNet, GoogLeNet, or ICSNet. However, generally speaking, deep learning models often require substantial computational power and memory capacity. Therefore, they are typically trained using specialized hardware like Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs). These hardware resources provide the necessary parallel processing capabilities required for efficiently handling the complex mathematical operations involved in training deep neural networks.