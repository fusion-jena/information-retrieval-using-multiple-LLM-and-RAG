The text does not provide explicit information about the specific strategy implemented to monitor the model performance during training. However, we can infer from the given data that the authors might have used some form of validation process, such as k-fold cross-validation or holdout method, to evaluate their models. This assumption is based on the presence of accuracy, precision, recall, sensitivity, and F1 score metrics for each model, which are commonly used to assess the performance of machine learning algorithms during the training phase. Additionally, there is a mention of confusion matrices generated during the cross-validation phase, further supporting this hypothesis. Nevertheless, without more detailed information regarding the exact methods employed by the authors, it is impossible to definitively state what strategy they implemented to monitor the model performance during training.