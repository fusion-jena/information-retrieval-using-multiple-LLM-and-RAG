The strategy implemented to monitor the model performance during training involves setting the hyperparameters of the ensemble models to those optimized by the Tree-Structured Parzen Estimator (TPE) algorithms. Each Machine Learning (ML) model is trained on 100 different subsets generated from the original training sets using the bootstrap method (sampling with replacement). The number of samples in each subset equals the number of samples in the original training data. The predictions of the trained models on the testing dataset are averaged to obtain the main prediction. The average loss, average bias, and average variance are then derived for each model. This approach helps to ensure the stability and generalizability of the ML models, reducing the risk of overfitting or underfitting.