The deep learning model used in this study employed an ADAM optimizer with a learning rate of 10. The model was trained for approximately 4 days, passing over the entire training set multiple times (not explicitly stated but implied by the mention of epoch 448). The batch size used during training was 64. Additionally, image augmentation techniques such as horizontal flipping, counterclockwise shearing, and random zooming were applied to enhance the input tensors, resulting in 224 x 244 pixel RGB input tensors. The data was normalized to ImageNet mean values, and the pixel values were rescaled within the range of [0, 1].