Based on the given information, there isn't any explicit mention of the specific strategy employed to monitor the model performance during training. However, we can infer some aspects related to the evaluation process.

Firstly, the final model selection was made based on the F1-score, which indicates the balance between precision and recall. The chosen model had an F1-score of 92.75%. Additionally, the table showing the ranking of CNN architectures suggests that various hyperparameter combinations were explored to find the best performing models.

Secondly, the use of different optimization algorithms like Adam and SGD implies that these methods might have been utilized to improve the model's performance during training. Optimizers help minimize the loss function by adjusting the weights and biases of the neural network.

Lastly, the summary statistics section mentions that fewer than 1% of the images from the survey period were used to train the CNN model. This approach allows testing the algorithm on mostly unknown data material, providing insights into how well the model generalizes to unseen data.

In conclusion, while the exact strategy to monitor the model performance during training remains undisclosed, the available information points towards evaluating the model using metrics such as F1-scores, exploring different hyperparameters, employing optimization techniques, and assessing the model's ability to generalize to new data.