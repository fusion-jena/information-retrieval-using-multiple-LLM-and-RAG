The text does not provide information about specific datasets used in a deep learning pipeline such as MNIST, CIFAR, or ImageNet. Instead, it discusses the process of separating data into training and testing datasets using a spatial blocking technique for a study area. The data was divided into 25 equally sized blocks, each approximately 41 km x 41 km in size, using the blockCV package in the R programming language. The goal was to ensure that data within a block was relatively independent of data outside of that block. Six modeling approaches were used to build component models for ensemble models, including regression-based models (Generalized Linear Models, Generalized Additive Models, Multivariate Adaptive Regression Splines) and machine learning models (Random Forest, Artificial Neural Networks, Maximum Entropy software). The biomod2 package in R was used to build all models. The results showed that an ensemble of models, each trained with an optimal number of background points, outperformed ensembles of models trained with the same number of background points. Additionally, Random Forest with equal numbers of presences and background points could perform better than an ensemble model when using a single modeling method.