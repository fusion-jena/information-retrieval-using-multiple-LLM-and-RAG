The hyperparameters of the model, specifically the Artificial Neural Network (ANN), were optimized using a trial-and-error method. This method involved varying the number of nodes in the hidden layer between 5 and 23, and the learning rate from 0.01 to 1.0 in increments of 0.05. For each configuration, the Mean Square Error (MSE) between the model output and the measured data was calculated. The optimal number of neurons in the hidden layer and the optimal learning rate were determined based on the configuration that resulted in the maximum model performance as indicated by the lowest MSE. Therefore, the final ANN structure included five input variables with one node accounting for bias, 19 hidden neurons with one node accounting for bias, a 0.7 learning rate, and one output variable of the output layer.