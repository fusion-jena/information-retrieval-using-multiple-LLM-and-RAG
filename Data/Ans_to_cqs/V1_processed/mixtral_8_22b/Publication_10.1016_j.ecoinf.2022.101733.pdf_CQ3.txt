The given context does not provide explicit information about specific data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, based on the available information, it can be inferred that the researcher employed a form of image interpretation for obtaining training and validation sample points. This technique involves analyzing and interpreting satellite imagery to identify and label various classes or categories present within the images. While this approach might not directly correspond to traditional data annotation techniques like bounding boxes or instance segmentation, it still serves as a means of generating labeled datasets required for training deep learning models. The mentioned McNemar's test analysis suggests that multiple feature sets were utilized during the model development process, including visible bands, multispectral bands, spectral indices, and textural features derived from Sentinel-1 and Sentinel-2 data. These diverse feature sets likely contributed to improved performance across various classes, such as water-covered surfaces, urban areas, and vegetated landscapes.