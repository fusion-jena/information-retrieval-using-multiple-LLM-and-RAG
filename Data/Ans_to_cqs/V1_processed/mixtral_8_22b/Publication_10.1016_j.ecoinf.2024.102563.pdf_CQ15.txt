The given context does not provide information on specific optimization techniques used in the deep learning pipeline such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). However, it mentions several machine learning models like Multilayer Perceptron (MLP), Support Vector Machine (SVM), Artificial Neural Network (ANN), and Random Forest (RF) which can be trained using these optimization techniques. For instance, backpropagation algorithm is commonly used for training MLP and ANN models, while SVM employs quadratic programming for optimization. The choice of optimization technique depends on factors like model complexity, convergence speed, and generalization performance.

Unhelpful 
I am sorry, but I cannot find any information regarding optimization techniques applied in the deep learning pipeline within the provided context.