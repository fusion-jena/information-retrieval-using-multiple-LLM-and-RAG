To ensure the generalizability of the deep learning model, several measures were implemented. Firstly, the models were trained with consistent parameters across all experiments, including 500 epochs, an initial learning rate of 0.01 with a weight decay of 0.005, and the optimizer Adam with a beta1 of 0.937. These uniform settings helped maintain consistency and reduce potential biases introduced by varying configurations.

Secondly, data augmentation techniques were employed during training to artificially expand the dataset. By generating new samples from existing ones, the model could learn from a broader range of variations, thereby improving its capacity to generalize and reducing the risk of overfitting. This approach is particularly beneficial when working with limited datasets, which is often the case in deep learning applications.

Thirdly, cross-validation was utilized to assess the performance of the models. Specifically, a five-fold cross-validation was performed, where the original sample was randomly partitioned into five equal subsets. Four of these subsets were used for training, while the remaining subset served as the validation set. This process was repeated five times, ensuring that each unique group functioned as the validation set once. Cross-validation helps prevent overfitting and provides a robust estimate of the model's performance on unseen data.

Lastly, the Mean Average Precision (mAP) metric was adopted to evaluate the overall performance of the model across multiple species. Unlike the Average Precision (AP), which only considers individual species, the mAP offers a comprehensive assessment of the model's reliability. This holistic perspective enables researchers to gauge the model's effectiveness in handling diverse scenarios, further enhancing its applicability in real-world situations.