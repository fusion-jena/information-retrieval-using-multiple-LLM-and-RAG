In this study, the researchers utilized a Convolutional Neural Network (CNN) called BirdNET for extracting embeddings. They compared its performance against other pre-trained models like VGGish and Wav2Vec 2.0. While they observed higher classification accuracy with BirdNET, which was specifically trained on audio data of bird vocalizations, they acknowledged that their methodology had limitations due to the use of pre-trained CNNs. Despite these constraints, they expressed optimism that further advancements in AI and deep learning techniques would lead to significant improvements in feature extraction and classification, ultimately enabling more effective use of Passive Acoustic Monitoring (PAM) for individual acoustic discrimination and long-term, non-invasive monitoring of animal populations.