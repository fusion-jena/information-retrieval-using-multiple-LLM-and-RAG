The text does not provide explicit information about which hardware resources were used for training the deep learning model. However, it mentions that one of the major enablers for the success of Deep Learning (DL) has been the corresponding computational infrastructure required by the learning algorithms. This suggests that powerful computing resources like Graphical Processing Units (GPUs) or Tensor Processing Units (TPUs) might have been employed for training the models. These types of hardware resources are commonly used for accelerating complex computations involved in deep learning tasks.