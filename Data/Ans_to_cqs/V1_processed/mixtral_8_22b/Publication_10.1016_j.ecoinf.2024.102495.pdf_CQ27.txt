Based on the given information, there isn't any specific detail about the deployment process of the trained deep learning model. However, it can be assumed that after training the model, the authors might have serialized the model using popular libraries like TensorFlow or PyTorch. This would allow them to save the model architecture and weights into a file which could then be loaded later for prediction purposes. As for platform selection, depending upon their use case, they may choose cloud platforms such as AWS, Google Cloud, Azure etc. or edge devices based on hardware constraints. But without explicit details, this remains speculative.