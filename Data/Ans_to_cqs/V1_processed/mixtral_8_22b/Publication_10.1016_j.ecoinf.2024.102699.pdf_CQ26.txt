Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some relevant points regarding data augmentation strategies have been discussed.

The authors employed various data augmentation techniques in both the time domain and frequency domain, including Gaussian noise, pink noise, primary and secondary background noise soundscapes, mixed-up random bird species, horizontal and vertical rolls, pitch shifts, time masks, frequency masks, gain, loudness normalization, horizontal and vertical flips, time stretches, tanh-based distortions, and others. These augmentation sets were tested across multiple deep learning models like DenseNet-161, ResNet-50, and ViT-B/16.

Moreover, the study mentions adding noise from the Bird Audio Detection dataset (BAD) from the DCASE challenge for IDs 5 and 6. This could potentially help reduce data bias by introducing additional variability into the dataset.

While these details provide insights into the data augmentation strategies used, they do not directly discuss techniques specifically aimed at addressing data bias during preprocessing. Therefore, based solely on the provided context, it cannot be determined what techniques are used to address data bias during preprocessing of the deep learning pipeline.