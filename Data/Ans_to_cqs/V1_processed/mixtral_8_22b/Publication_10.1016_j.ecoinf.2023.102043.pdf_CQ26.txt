Based on the given context, there isn't any explicit mention of techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some aspects of the process could be interpreted as addressing potential biases. For instance, the use of a sliding window with an overlap of 50% ensures that important information is not lost due to edge effects, which might otherwise introduce a bias towards certain features. Additionally, the fact that the dataset is divided into 70% for training, 10% for validation, and 20% for testing purposes suggests a balanced approach to ensure the model generalizes well to unseen data. Nevertheless, without further details about the distribution of classes in the dataset or specific measures taken to handle class imbalance, it cannot be definitively stated what techniques were used to address data bias.