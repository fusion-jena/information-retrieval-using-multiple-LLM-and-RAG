Based on the given context, there isn't any explicit information about specific post-processing steps such as saliency maps, metrics calculations, or confusion matrices. However, we can infer some possible post-processing steps based on the described methods for optimizing and evaluating the MLP model.

After training the MLP model, it appears that the authors use the validation set to perform hyperparameter tuning via grid search. This step aims to maximize the R value, which serves as the performance indicator. They consider various combinations of neural network structures, numbers of neurons in hidden layers, percentages of dropout layers, learning rates, and batch sizes.

Once they obtain the optimal model, the authors then proceed to evaluate its performance and generalizability using the test set. Although not explicitly mentioned, this evaluation likely includes calculating relevant metrics like accuracy, precision, recall, F1 score, etc., depending on the problem domain.

Additionally, since the authors mention repeating the random partition of datasets ten times to ensure converged performance, it suggests that they might also be performing cross-validation techniques to further validate their results.

However, without more detailed information regarding the specific task or problem domain, it is challenging to provide a definitive list of post-processing steps. Therefore, I recommend referring to best practices within the respective field when implementing these steps.