To monitor the model performance during training, a 10-fold cross-validation (CV) design was implemented. In each run of the cross-validation procedure, 30% of the forest fire occurrence data was reserved as a validation set, while the remaining 70% of the data was used to train the model. This process resulted in 50 models, comprising 10 models for each machine learning algorithm. The performance of each model was then assessed using various metrics such as AUC, TSS, Kappa, and phi. The outcomes of these evaluations were presented in Table 3 and visualised in Figure 4. The performance of the models was found to be consistent, except for the CART model which showed lower performance compared to others. No significant differences in prediction accuracy were found among the classifiers according to the Kruskal-Wallis statistic.