Based on the given information, it appears that the specific criteria used to determine when training is complete are not explicitly mentioned. However, we can infer from common machine learning practices that there could be several possible criteria used to decide when to stop training. Some examples include reaching a predefined number of epochs, observing a plateau in the validation loss, or achieving a desired level of performance on the validation set.

From the table provided (Table II), we see that different hyperparameters have been determined using grid search for various models such as Inception-V3, MobileNet-V2, ResNet-18, and DenseNet-121. Among these parameters, one important factor is the number of epochs, which indicates how many times the entire dataset is passed through the neural network during training. For instance, Inception-V3 has been trained for 75 epochs, while ResNet-18 has been trained for 150 epochs. This suggests that the authors might have chosen to stop training based on reaching a certain number of epochs.

Additionally, the paper mentions that a 60-20-20 train/validate/test regime was employed to split the data into training, validation, and testing sets. Monitoring the performance metrics on the validation set, such as validation loss or accuracy, can also help determine when to stop training. Although the exact stopping criterion is not specified, it is reasonable to assume that the authors may have considered factors like validation loss plateau or achieving a satisfactory level of performance on the validation set before deciding to halt the training process.