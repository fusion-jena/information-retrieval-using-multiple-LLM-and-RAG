After the model training, several postprocessing steps can be performed depending on the specific requirements of the task or application. Some common postprocessing steps include metrics calculation, confusion matrices, saliency maps, and visualizations.

In this case, the authors used the coefficients of determination (R^2) and the root mean squared error (RMSE) as their primary metrics for evaluating the performance of their models. These metrics were calculated based on the actual and predicted values of the target variable, where R^2 measures the proportion of variance in the dependent variable that can be predicted from the independent variables, and RMSE quantifies the difference between the predicted and actual values.

To avoid bias in estimating the error, the dataset was split into three subsets: training (60%), validation (20%), and testing (20%). Data augmentation was applied only to the training data to prevent overlap between different subsets. Overfitting was also considered during the evaluation phase, and the authors compared the performance of the models on both the training and testing sets.

Furthermore, spatial analysis was conducted to evaluate the performance of the models across different geographical locations. Table 2 presents the results of the model's performance on test data and transfer learning data for five sites, measured in terms of R^2. Mono-site models were trained separately for each location, while multi-site models combined data from multiple locations. The results showed that while the mono-site models had high performance on the test data, their transfer performance varied significantly across different locations.

Overall, the postprocessing steps involved in this study included calculating metrics such as R^2 and RMSE, conducting spatial analysis, and considering factors such as overfitting and transfer performance. However, other postprocessing techniques such as saliency maps or confusion matrices could also be employed depending on the specific needs of the project.