The authors do not explicitly mention how they split the data for deep learning model training into train, test, or validation sets. However, they discuss fitting Random Forests (RFs) and Gradient Boosting Machines (GBMs) using specific packages and parameters. They also mention evaluating variable importance in Artificial Neural Networks (ANNs) using the Olden method. The study focuses on interpolating weather station data and downscaling WorldClim and CHELSA datasets. To evaluate model performance, they use metrics such as KGE scores, pbias, MAE, and RMSE. Based on this information, it can be assumed that the authors followed standard practices for splitting the data into training and testing sets, but the exact details are not mentioned in the given context.