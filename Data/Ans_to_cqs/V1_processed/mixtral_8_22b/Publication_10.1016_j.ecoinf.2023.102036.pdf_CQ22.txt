The given context does not provide explicit information about the specific evaluation metrics used to assess the performance of the deep learning model. However, it mentions using TensorBoard, a tool from the TensorFlow library, to monitor the performance of the runs during training. Typically, when working with deep learning models, common evaluation metrics include accuracy, precision, recall, F1-score, ROC AUC, etc. These metrics help measure how well the model performs in predicting the correct labels for the data. Since the context does not specify any particular metric, it would be best to assume that standard evaluation metrics like accuracy, precision, recall, or others relevant to the problem domain might have been employed.