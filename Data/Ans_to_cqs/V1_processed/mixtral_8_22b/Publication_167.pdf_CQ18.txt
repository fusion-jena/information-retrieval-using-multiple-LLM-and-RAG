To monitor the model performance during training, the authors use a 10-fold cross-validation method. This involves dividing the training and validation set into ten equal parts or folds. Nine of these folds are used for training the model, while the remaining fold serves as the validation set. This process is repeated ten times, ensuring that each fold gets a chance to act as the validation set once. The mean value of the ten results is then used to estimate the accuracy of the model. Additionally, the authors perform batch normalization on the input data due to the large differences in the distribution between different batches of training data and between the training set and the test set. This helps improve the stability and speed of the learning process.