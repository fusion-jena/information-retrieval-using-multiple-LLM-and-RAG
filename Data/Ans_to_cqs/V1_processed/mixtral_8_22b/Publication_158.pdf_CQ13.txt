The text provides information about the use of a Convolutional Neural Network (CNN) in the study. However, it does not explicitly mention all the hyperparameters used in the deep learning model. From the given context, we can infer that the Adam optimizer was used with 500 epochs and categorical-cross entropy loss function. The batch size was set to 64. Additionally, data augmentation techniques such as rotation, reflectance bias of ±10%, and random noise of ±10% reflectance for 15% of the input image were applied. It is mentioned that early stopping criteria was applied if no improvement was found in 50 epochs. Furthermore, an ensemble of three models was generated, and the average of the final output layer was taken. Two models in the ensemble used max pooling, while one used average pooling.