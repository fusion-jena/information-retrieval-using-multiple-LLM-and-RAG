The given context does not provide specific information about the techniques used to address data bias during preprocessing of the deep learning pipeline. However, some common techniques used for addressing data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes in both sets. This helps prevent any imbalance between the classes in the training set from affecting the model's performance.

Oversampling and undersampling involve adjusting the number of instances in each class to balance the dataset. Oversampling increases the number of instances in the minority class, while undersampling reduces the number of instances in the majority class. These techniques can help improve the model's ability to learn patterns in the minority class.

Diverse data collection involves collecting data from various sources to ensure that the dataset represents different populations and scenarios. This technique can help reduce bias caused by overrepresentation of certain groups or situations in the dataset.

Without further context, it cannot be determined which of these techniques were used in this particular study.