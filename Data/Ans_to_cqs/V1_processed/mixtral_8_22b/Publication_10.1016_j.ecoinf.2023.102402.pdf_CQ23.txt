Based on the given information, there is no explicit mention of specific measures taken to ensure the generalizability of a deep learning model, such as using a diverse dataset, cross-validation, or stratified splitting. However, it can be inferred that the authors have employed certain techniques to validate their Species Distribution Models (SDMs) and evaluate their performance.

To measure the SDMs' performance, they utilized two metrics: Area Under the receiver-operator Curve (AUC) and True Skill Statistics (TSS). These methods are commonly used to assess the model performance in species distribution model studies. High AUC and TSS values close to 1 indicate a more accurate model prediction. The reported AUC and TSS values for both Hippocampus guttulatus and Hippocampus hippocampus suggest an excellent level of predictive performance.

Additionally, the authors validated their models using multiple databases, which could contribute to enhancing the robustness and generalizability of the results. This approach might help capture various aspects of the underlying data distributions and reduce potential biases associated with relying solely on one source.

In summary, while the text does not explicitly discuss specific techniques like cross-validation or stratified splitting, it suggests that the authors took some measures to ensure the reliability and applicability of their SDMs. They achieved this through employing widely accepted performance metrics and utilizing multiple databases for model validation.