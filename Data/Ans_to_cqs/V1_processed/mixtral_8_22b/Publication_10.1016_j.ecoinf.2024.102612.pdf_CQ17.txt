The given context does not provide information about the specific regularization methods used to prevent overfitting in the deep learning pipeline. Regularization methods like dropout and L2 regularization are commonly used techniques to avoid overfitting in deep learning models. Dropout randomly drops out neurons during training, while L2 regularization adds a penalty term to the loss function to discourage large weights. However, without explicit mention in the provided text, we cannot confirm if these methods were utilized in this particular study.