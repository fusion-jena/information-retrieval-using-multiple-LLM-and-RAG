Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, the text mentions the use of data augmentation techniques like rotation, noise, and flip to increase the size of the dataset by six times. Data augmentation helps improve the robustness and generalization of the CNN classification model. It should also be noted that the learning rate was adjusted using an exponential decay parameter of 0.5 by an SGD scheduler after 50,000 iterations to prevent overfitting and ensure better generalization to unseen datasets.