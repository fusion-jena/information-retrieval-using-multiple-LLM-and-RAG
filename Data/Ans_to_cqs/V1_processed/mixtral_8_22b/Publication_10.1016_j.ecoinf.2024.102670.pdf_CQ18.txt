The paper does not provide explicit information about a specific strategy used to monitor the model performance during training. However, considering the general practices in machine learning and deep learning, one common approach to monitoring model performance during training is through validation techniques such as cross-validation or using separate validation sets. These strategies help evaluate how well the model is performing and whether it is overfitting or underfitting the training data. In addition, tracking metrics like accuracy, precision, recall, or loss functions are also commonly employed to assess the model's progress throughout the training process.