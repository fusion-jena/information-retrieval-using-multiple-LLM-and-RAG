Based on the provided context, there isn't any direct mention of the criteria used to determine when training is complete, such as a validation loss plateau. However, the text discusses the concept of data mining and its application in the form of the Apriori algorithm.

Data mining involves extracting valuable insights from large datasets, which often includes machine learning models. When training these models, one common criterion to determine when training should stop is indeed the validation loss plateau. A validation loss plateau occurs when the model's performance on the validation dataset stops improving significantly over several epochs. At this point, further training might lead to overfitting, causing the model to perform poorly on unseen data.

However, since the context doesn't explicitly state the use of machine learning models or provide details about their training, I cannot definitively confirm that a validation loss plateau is used as a stopping criterion in this particular scenario.