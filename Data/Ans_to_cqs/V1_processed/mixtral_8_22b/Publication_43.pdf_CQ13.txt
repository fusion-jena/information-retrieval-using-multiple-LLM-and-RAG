The deep learning models used in this study are Deep Convolutional Neural Networks (CNNs) such as ResNet and GoogLeNet. These networks were trained using stochastic gradient descent (SGD) optimization algorithm. The hyperparameters used in the SGD include the learning rate (α) and the momentum weight (µ). However, the specific values of these hyperparameters are not mentioned in the given context. Additionally, the loss function used for training includes the weight decay term (R) with its Lagrange multiplier (λ). Again, the exact value of λ is not specified in the given context. Furthermore, it is also mentioned that the losses of two auxiliary classifiers in GoogLeNet are weighted by 0.3 and added to the total loss during each training iteration. Lastly, the concept of fine-tuning is discussed where the entire network is updated or only certain parts of the network are updated based on the size of the new dataset. This process helps prevent overfitting, especially in the first layers of the network.