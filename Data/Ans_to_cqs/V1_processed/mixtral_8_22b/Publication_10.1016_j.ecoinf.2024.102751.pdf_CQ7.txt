Unfortunately, there isn't enough context provided to determine the specific criteria used to split the data for deep learning model training (e.g., train, test, validation) in this case. However, common practices for splitting datasets in machine learning applications often involve using a random stratified sampling method to maintain class balance between different subsets. Typically, the dataset is divided into three parts: training set (used to fit the model), validation set (used to tune hyperparameters during model selection), and testing set (used to evaluate the final performance of the selected model). Common ratios for these splits can vary but are often around 60%, 20%, and 20%, respectively.