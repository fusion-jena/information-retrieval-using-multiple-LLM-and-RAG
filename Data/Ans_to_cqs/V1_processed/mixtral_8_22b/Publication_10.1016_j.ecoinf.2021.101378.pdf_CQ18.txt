Based on the given context, there isn't any specific information about the strategy used to monitor the model performance during training. However, it can be assumed that common strategies such as cross-validation or holdout validation might have been employed. These techniques involve splitting the dataset into training and testing sets, where the former is used to train the model while the latter is utilized to evaluate its performance. Additionally, metrics like accuracy, precision, recall, or area under the curve (AUC) could have been used to measure the model's effectiveness. Nevertheless, without explicit details regarding the methodologies applied in this study, these assumptions remain speculative.