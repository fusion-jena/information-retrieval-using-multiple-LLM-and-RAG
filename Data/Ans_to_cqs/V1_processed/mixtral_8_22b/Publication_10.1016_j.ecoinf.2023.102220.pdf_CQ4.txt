The given context does not mention any specific data augmentation techniques applied in the deep learning pipeline. Data augmentation techniques like flipping, rotation, scaling, etc., are often used to increase the amount of training data available by applying random (but realistic) transformations such as shifting or rotating an image. This helps prevent overfitting and improves model generalization. However, since these details aren't mentioned in the provided context, I cannot specify what data augmentation techniques were applied in their deep learning pipeline.