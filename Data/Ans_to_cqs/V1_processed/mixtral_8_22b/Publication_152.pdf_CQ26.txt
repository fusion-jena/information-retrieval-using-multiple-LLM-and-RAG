Based on the given context, it is not explicitly mentioned which specific techniques were used to address data bias during preprocessing of the deep learning pipeline. However, some common techniques for addressing data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes or labels in both sets. This ensures that the model is trained and tested on a representative sample of the entire dataset.

Oversampling and undersampling involve adjusting the number of samples in each class to balance the dataset. Oversampling increases the number of minority class samples by duplicating them, while undersampling reduces the number of majority class samples by randomly removing some of them. These techniques can help prevent the model from being biased towards the majority class.

Diverse data collection involves collecting data from different sources, environments, and conditions to ensure that the model generalizes well to new data. In this case, images were collected using UAV flights at constant height above ground, but small changes in brightness and zoom proved effective in improving results. Medium or large changes in zoom range caused degradation of results, indicating that careful consideration should be taken when selecting the appropriate data augmentation techniques.

Overall, it is important to carefully consider the potential sources of bias in the dataset and use appropriate techniques to mitigate their impact on the model's performance.