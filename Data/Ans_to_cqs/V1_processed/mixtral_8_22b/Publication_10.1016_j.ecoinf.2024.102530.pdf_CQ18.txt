Unfortunately, there isn't enough information available to provide a detailed response regarding the specific strategy implemented to monitor the model performance during training. However, generally speaking, strategies to monitor model performance during training often involve techniques such as using validation datasets, tracking metrics like accuracy, precision, recall, or loss function values, visualizing learning curves, or employing methods like cross-validation. In this case, since the text mentions a validation process and compares the model's outcomes with field estimations, it suggests that a form of validation dataset might have been employed to assess the model's performance during training.