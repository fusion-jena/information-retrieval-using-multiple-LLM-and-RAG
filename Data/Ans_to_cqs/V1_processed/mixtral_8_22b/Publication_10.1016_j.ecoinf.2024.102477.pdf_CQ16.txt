The completion of training in machine learning models like SVR (Support Vector Regression) depends on various factors such as the convergence of the algorithm, the performance on validation sets, and the desired level of accuracy. However, there isn't a specific criterion mentioned in the given context regarding when training should be considered complete.

In general, some common criteria used to determine when training is complete include:

1. Validation Loss Plateau: When the validation loss stops decreasing significantly and remains relatively constant, it may indicate that further training will not improve the model's performance. At this point, training could be stopped to avoid overfitting.

2. Maximum Number of Iterations/Epochs: Training can be stopped after reaching a predefined number of iterations or epochs. This approach assumes that the model has learned enough patterns within the specified limit.

3. Early Stopping: Based on monitoring the validation loss, if the loss does not decrease for a certain number of consecutive iterations, training can be halted. This helps prevent overfitting and saves computational resources.

4. Desired Level of Accuracy: Training can be stopped once the model achieves a satisfactory level of accuracy on the validation dataset. This requires setting a target accuracy beforehand.

However, these criteria might vary depending on the specific problem, available resources, and the chosen machine learning technique. For instance, in the case of SVR, the regularization parameter 'C' plays a crucial role in controlling the trade-off between minimizing errors and maximizing margins. Therefore, tuning this parameter appropriately would impact the decision about when to stop training.