The sources of raw data collection for deep learning pipelines can vary depending on the specific application or use case. Some common methods include:

1. Surveys: These can be used to collect large amounts of labeled data from human participants. For example, image classification tasks often rely on crowdsourced labels obtained through online surveys.

2. Sensors: Various types of sensors can be used to collect real-time data streams. This is particularly useful for time series forecasting and anomaly detection tasks. Examples include temperature sensors, accelerometers, gyroscopes, and GPS devices.

3. Public Datasets: There are many publicly available datasets that can be used for training deep learning models. These datasets cover a wide range of domains such as computer vision, natural language processing, speech recognition, and more. Some popular examples include ImageNet, COCO, and MNIST.

4. Web Scraping: This involves extracting structured data from websites using automated scripts or tools. It can be used to gather large volumes of textual data for natural language processing tasks.

5. APIs: Application Programming Interfaces allow developers to access data from third-party services. For instance, social media platforms provide APIs that enable researchers to collect user-generated content for sentiment analysis and other text mining tasks.

6. IoT Devices: Internet of Things devices generate vast quantities of sensor data that can be leveraged for various deep learning applications. Examples include smart home appliances, wearables, industrial machinery, and autonomous vehicles.