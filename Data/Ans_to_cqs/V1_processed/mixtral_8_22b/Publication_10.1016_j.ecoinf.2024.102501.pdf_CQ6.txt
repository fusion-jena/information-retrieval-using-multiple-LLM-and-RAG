Before training a deep learning model, several preprocessing steps are typically involved to ensure the data is suitable for use with the chosen algorithm. These steps may include normalization, scaling, cleaning, and transformation. Normalization involves adjusting the range of features so they have similar scales, often between 0 and 1 or -1 and 1. This helps prevent any single feature from dominating the others due to its scale. Scaling refers to rescaling numerical attributes to a standard range, usually between 0 and 1. Cleaning involves removing noise, outliers, and missing values from the dataset. Transformation includes converting categorical data into numerical form, encoding labels, and applying dimensionality reduction techniques like Principal Component Analysis (PCA). In this case, the given text mentions that the data was normalized using the formula presented in Eq. (1) to reduce the impact of large differences among various parameters.