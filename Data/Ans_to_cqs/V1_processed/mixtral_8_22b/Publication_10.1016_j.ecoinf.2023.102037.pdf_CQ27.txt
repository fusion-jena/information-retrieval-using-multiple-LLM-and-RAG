Unfortunately, there is no explicit information given about the specific process followed to deploy the trained deep learning model. However, we do have some clues from the context.

Firstly, it is mentioned that the training procedure of the detection model ran for 150 epochs using stochastic gradient descent (SGD) as the model’s optimizer with a momentum of 0.9. This suggests that the model was likely saved after this training period, possibly through model serialization or checkpointing.

Secondly, the hardware used for training is specified as having an NVIDIA® Quadro RTX 5000 GPU. This implies that the deployment platform may also be GPU-based, although this is not explicitly stated.

Lastly, the mention of maintaining multiple models at each branch could suggest that the deployed model might involve ensemble methods or multi-branch architectures. However, without more specific details, this remains speculative.

Therefore, while we cannot provide a definitive answer to the query, we can infer that the process likely involved saving the model after training, potentially using GPU resources for deployment, and possibly incorporating ensemble or multi-branch strategies.