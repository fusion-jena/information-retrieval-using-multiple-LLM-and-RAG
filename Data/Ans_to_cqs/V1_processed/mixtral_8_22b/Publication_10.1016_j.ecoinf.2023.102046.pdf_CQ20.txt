Unfortunately, there is no information provided about the specific hardware resources used for training the deep learning models mentioned in the given context. Therefore, it is not possible to provide an accurate answer based solely on this information. However, typically, deep learning models like ResNet-50, Inception-V3, and ViT require significant computational resources such as GPUs or TPUs to train efficiently due to their large number of parameters and complex architectures.

Reference(s):
[1] He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. CoRR abs/1512.03385 (2015)
[2] Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception architecture for computer vision. CoRR abs/1512.00567 (2015)
[3] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Houlsby, N., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Vaswani, A.: An image is worth 16x16 words: Transformers for image recognition at scale. CoRR abs/2010.11929 (2020)