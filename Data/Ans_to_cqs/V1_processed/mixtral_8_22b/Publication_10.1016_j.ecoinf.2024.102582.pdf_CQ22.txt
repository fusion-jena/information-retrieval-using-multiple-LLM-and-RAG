The text does not provide explicit information about the specific metrics used to evaluate the performance of a deep learning model. However, based on the given table, it can be inferred that the metrics used include user's accuracy (%), total accuracy (%), and Kappa coefficient. User's accuracy is also known as precision or positive predictive value, which measures the proportion of true positives among all predicted positives. Total accuracy represents the overall correctness of the classifier, while the Kappa coefficient is a statistical measure of agreement between two raters who each classify items into mutually exclusive categories. It takes into account the possibility of the agreement occurring by chance.

The table shows these metrics for different years, indicating that they might have been used to assess the performance of a deep learning model over time. However, without more specific details, it cannot be confirmed if these are the only metrics used or if other common metrics like recall (also known as sensitivity or true positive rate) or F1 score (a harmonic mean of precision and recall) were also considered.