In the context of the given information, there isn't any explicit mention of specific strategies employed to handle randomness in the deep learning pipeline, particularly regarding random seed values. However, we can infer some possible approaches based on the described methodology.

Firstly, the use of the Hybrid Hyperparameter Optimization Scheme (HHOS) suggests that the authors have taken steps to mitigate the effects of randomness. By combining manual and random search methods, they aim to strike a balance between exploring the hyperparameter space effectively while also reducing the risk of missing optimal configurations due to subjectivity or randomness.

Secondly, the process of manually searching for frequently used hyperparameter configurations implies that the researchers have attempted to limit the scope of their investigation to those parameters that have shown promise in previous studies. This could help minimize the influence of random factors since these selected configurations would likely have been tested under different conditions and still yielded positive results.

Lastly, although not explicitly stated, one common strategy to address randomness in deep learning pipelines is fixing the random seed value. Fixing the random seed ensures reproducibility by generating consistent results across experiments. While this technique is not mentioned in the provided context, it remains a viable option for handling randomness in similar scenarios.