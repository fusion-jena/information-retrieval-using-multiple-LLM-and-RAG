The pipeline utilizes three types of deep learning models: Convolutional Neural Networks (CNNs), specifically ResNet-50 and Inception-V3, and a Transformer model called Vision Transformer (ViT).

ResNet-50 is a variant of the Residual Network (ResNet) family of architectures, which introduces skip connections or shortcut paths to enable better gradient flow during backpropagation. This makes it easier to train deeper networks, improving their performance. ResNet-50 consists of 50 layers and is widely used for computer vision tasks like image recognition and object detection.

Inception-V3 is another CNN architecture designed for image analysis tasks. It incorporates an auxiliary classifier that serves as a regularizer, helping prevent overfitting. Inception-V3 builds upon earlier Inception models, focusing on computational efficiency while maintaining high accuracy.

Lastly, the pipeline employs a Transformer model known as Vision Transformer (ViT). Unlike traditional CNNs, ViT applies self-attention mechanisms directly to image patches, allowing the model to weigh different parts of the input differently. This approach enables ViT to achieve competitive results in various image classification tasks without relying on convolution operations.