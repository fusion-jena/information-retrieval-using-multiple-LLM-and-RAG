To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the labeled dataset was split into 70/30 training and testing datasets. This approach allows the model to learn from a larger portion of the data while still having a separate set of data to evaluate its performance. Secondly, 50% of the training data were held out for validation. This process helps prevent overfitting, where the model becomes too specialized to the training data and performs poorly on new, unseen data. Lastly, a 10-fold cross-validation was employed to define the score-to-posterior-probability transformation function. Cross-validation is a technique used to assess how well a statistical model will generalize to an independent dataset. In this case, it provides a way to estimate the model's ability to predict new observations accurately. These steps collectively contribute to enhancing the robustness and reliability of the deep learning model.