The text describes the use of a K-fold cross-validation technique during the validation phase of machine learning algorithms, specifically setting K to four. In this case, the feature set was randomly divided into four mutually exclusive folds through stratified sampling. Each fold served as the validation set, while the remaining three folds constituted the training set for model training. To address imbalances, random under sampling (RUS) was applied to the training set, while the validation set remained unchanged.

In summary, the criteria used to split the data for deep learning model training were:

1. Stratified Sampling: This method ensures that each fold contains approximately the same proportion of samples from each class as the original dataset. It helps maintain the balance between classes when splitting the data.

2. Four Mutually Exclusive Folds: The feature set was divided into four non-overlapping subsets, ensuring no overlap between the training and validation sets. This approach allows for more efficient use of available data and reduces overfitting by exposing the model to diverse subsets of the data.

3. Random Under Sampling (RUS): Applied to the training set to handle class imbalance issues. By reducing the majority class instances, RUS aims to create a more balanced distribution of classes within the training set.

These techniques help ensure that the model generalizes well to new, unseen data and provides accurate predictions across various scenarios.