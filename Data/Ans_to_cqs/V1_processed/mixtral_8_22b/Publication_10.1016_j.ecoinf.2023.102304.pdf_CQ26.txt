The context does not directly discuss techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does mention optimization of parameters which could be related to addressing data bias. In general, these techniques are commonly used to handle class imbalance or uneven distribution of samples across different classes in a dataset.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same proportion of samples from each class in both sets. This ensures that the model is trained and tested on a representative sample of the entire dataset.

Oversampling involves duplicating examples from the minority class to balance the dataset. Undersampling, on the other hand, involves removing examples from the majority class to achieve the same goal. Both methods have their advantages and disadvantages, and the choice between them depends on the nature of the problem and the available resources.

Diverse data collection involves collecting data from various sources to ensure that the dataset is representative of the population being studied. This technique helps reduce bias introduced by using a single source of data.

In summary, the context does not explicitly discuss techniques used to address data bias during preprocessing of the deep learning pipeline. However, common techniques include stratified splitting, oversampling, undersampling, and diverse data collection. These techniques help handle class imbalance or uneven distribution of samples across different classes in a dataset.