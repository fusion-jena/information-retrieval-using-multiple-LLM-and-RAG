The text does not provide explicit information about the specific postprocessing steps involved after the model training. However, it does mention some relevant details. After training the algorithms with the available data, excluding the testing set, the performance metrics were computed in the test set. This suggests that one of the postprocessing steps might involve calculating performance metrics such as accuracy, precision, recall, or F1 score. Additionally, the text mentions that a min-max scaler was used during training and then reverted at the end, which could indicate normalization or scaling of the input features before computing these metrics. Furthermore, since the study compares DMF with other methods like MF, MICE, and imputation by EM algorithm, it can be inferred that another postprocessing step might involve comparing the results obtained from different models through techniques such as confusion matrices or statistical tests. Lastly, although not explicitly stated, visualizing the results using tools like saliency maps or heatmaps could also be considered as potential postprocessing steps to better understand the model's behavior and interpretability.