The given context does not provide information about the specific data augmentation techniques used in the deep learning pipeline. However, common data augmentation techniques for image datasets include flipping, rotation, scaling, cropping, translation, and color space transformations. These techniques help increase the size of the dataset and improve model robustness by introducing variations into the training set. Please note that this is a general explanation, and the actual techniques used may vary depending on the specific application or research.

Based on the given context, it appears that the study utilizes eleven different machine learning models, including Multilayer Perceptron (MLP), Logistic Regression (LR), Naive Bayes (NB), CatBoost (CAT), Random Forest (RF), XGBoost (XGB), LightGBM (LGB), Weighted Soft Voting (WSOFT), Weighted Hard Voting (WHARD), Blending, and Stacking. The Hyperparameter tuning was performed using Grid Search, Randomized Search, Tree Parzen Estimator (TPE), and Bayesian Optimization algorithms. The packages used for these implementations are mentioned in the context.

However, there is no mention of any data augmentation techniques being applied in the deep learning pipeline. Therefore, I cannot provide a helpful answer regarding the specific data augmentation techniques used in this case.