After the model training, several postprocessing steps can be performed depending on the specific requirements of the task. Based on the given context, it appears that the authors have conducted various evaluations and analyses to understand the performance of different frontends and configurations. Here are some of the postprocessing steps mentioned or implied in the context:

1. Performance Summary: The authors created a performance summary for the 48 models to understand the importance of each component (Fig. 3). This step involves aggregating and visualizing the performance metrics obtained from all the trained models.

2. Confusion Matrices: To further analyze the performance of the base and best configurations for each frontend, the authors generated confusion matrices (Fig. 4). These matrices help identify which classes are being confused by the models and provide insights into potential areas for improvement.

3. Evaluation Strategy: For a fair evaluation, the authors used the entire recording but had to split them into smaller segments due to memory limitations. They also monitored the models during training using the first five seconds of the validation recordings to reduce computational time.

4. Normalization Techniques: The authors experimented with different normalization techniques such as standardization and min-max normalization. These techniques are applied to the input features before feeding them into the models.

In conclusion, based on the given context, the postprocessing steps involved after the model training include creating performance summaries, generating confusion matrices, implementing an appropriate evaluation strategy, and applying normalization techniques. However, there might be other postprocessing steps not explicitly mentioned here, such as calculating additional performance metrics or generating saliency maps, depending on the specific needs of the project.