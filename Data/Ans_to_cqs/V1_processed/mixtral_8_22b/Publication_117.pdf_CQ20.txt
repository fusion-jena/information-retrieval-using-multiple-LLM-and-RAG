The text does not explicitly mention the specific hardware resources used for training the deep learning models. However, given the context, it can be inferred that Graphical Processing Units (GPUs) might have been utilized due to their parallel computing power, which is beneficial for deep learning applications. Additionally, libraries like TensorFlow, mentioned in the text, support GPU acceleration for faster computations. Therefore, while not directly stated, it is likely that GPUs were used for training the deep learning models.