The text does not provide explicit information about how the hyperparameters of the model were optimized. However, based on common practices in machine learning, possible methods include grid search or random search. Grid search involves testing all combinations of predefined values for each hyperparameter, while random search randomly samples points within the defined range of hyperparameters. Another method mentioned in the text is stochastic gradient descent, but this refers to the optimization of weights during training rather than hyperparameters. Therefore, without additional information, we cannot definitively state how the hyperparameters were optimized.