In the provided context, there isn't explicit information about the specific criteria used to determine when training is complete. However, it does mention the use of a validation process involving a comparison between the Apis-FIS model predictions and field estimations. This suggests that the performance of the model during validation could be used as a criterion to decide if training is complete.

Typically, in machine learning models like Fuzzy Inference Systems (FIS), common criteria to determine when training is complete include observing a plateau in the validation loss, achieving a predefined accuracy threshold, or reaching a maximum number of iterations/epochs. These criteria help ensure that the model has learned sufficiently from the training data without overfitting.

Since the context doesn't provide details regarding the exact stopping criteria used for the Apis-FIS model, I cannot give a definitive answer. Nonetheless, based on general practices in machine learning, potential criteria might involve monitoring the validation error or ensuring that the model performs well against ground truth data collected through field estimations.