Based on the given context, there isn't explicit mention of specific techniques such as stratified splitting, oversampling, undersampling, or diverse data collection being employed to address data bias during preprocessing of the deep learning pipeline. However, some relevant techniques are mentioned.

To prevent overfitting, which could lead to biased models, the authors use data augmentation techniques like left-right mirroring. Data augmentation helps increase the diversity of the dataset without actually collecting new data, thereby potentially addressing any inherent biases present in the original dataset.

Additionally, the authors discuss the importance of having large amounts of data for deep learning tasks. They note that their contribution includes the largest fully labeled snow leopard dataset for deep learning research. This suggests that the authors believe that having a larger and more comprehensive dataset can help mitigate issues related to data bias.

However, it should be noted that while these strategies might indirectly help reduce data bias, they do not directly tackle the problem of data bias. Techniques such as stratified sampling, oversampling, undersampling, or ensuring diverse data collection would need to be explicitly implemented to specifically target and address data bias.