Based on the given context, there is no explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, it is common practice in machine learning and deep learning research to manage randomness through techniques like setting fixed seeds, which ensures reproducibility across different runs. This allows researchers to compare their results accurately and maintain consistency when evaluating various algorithms or hyperparameters. In this study, although not explicitly mentioned, it is likely that similar practices were followed to ensure reliable and consistent outcomes during experimentation.