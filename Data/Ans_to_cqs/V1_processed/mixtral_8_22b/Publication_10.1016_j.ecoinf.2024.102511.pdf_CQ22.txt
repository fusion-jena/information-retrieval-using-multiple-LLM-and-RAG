The sources provided do not explicitly mention specific metrics used to evaluate the performance of deep learning models. However, based on common practices in machine learning and deep learning, some commonly used evaluation metrics include accuracy, precision, recall, F1 score, area under the receiver operating characteristic curve (AUROC), and confusion matrix. Accuracy is the ratio of correctly predicted observations to the total observations. Precision measures the proportion of true positive predictions out of all positive predictions made by the classifier. Recall calculates the proportion of actual positives that were identified correctly. The F1 score combines both precision and recall into one metric. AUROC provides an aggregate measure of performance across all possible classification thresholds. Lastly, a confusion matrix summarizes the prediction results of a classification problem. It shows the number of correct and incorrect predictions broken down by each class.