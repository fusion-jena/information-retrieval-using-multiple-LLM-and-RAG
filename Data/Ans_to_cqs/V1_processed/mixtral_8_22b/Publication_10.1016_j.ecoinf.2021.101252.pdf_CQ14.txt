The optimization of the hyperparameters of the model is done through an automated process called AutoML. This process begins by generating a set of candidate models with architectures and hyperparameters chosen randomly within a predefined range of values. These candidate models are then trained using a small portion of the available data for a limited number of epochs. After training, the performance of these candidate models is evaluated using a separate validation dataset. The top-performing candidate model is subsequently trained on the entire training dataset. During this stage, it is crucial to determine an optimal number of training epochs to prevent both underfitting and overfitting. It should also be noted that different hardware configurations may yield varying modeling results due to differences in how TensorFlow generates random hyperparameters when running on CPUs versus GPUs.