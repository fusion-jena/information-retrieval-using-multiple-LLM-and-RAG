When splitting data for deep learning model training, there are several common approaches. One popular approach is to divide the data into three subsets: training, testing, and validation sets.

1. Training Set: This subset is used to train the model, i.e., adjust the weights and biases of the neural network based on the input features and corresponding target labels. Typically, around 60-80% of the total available data is allocated to the training set.

2. Testing Set: After training the model, it needs to be evaluated on unseen data to assess its performance and generalization capabilities. The testing set serves this purpose. Usually, about 20-30% of the total data is reserved for the testing set.

3. Validation Set: During the training process, a validation set can help tune hyperparameters and prevent overfitting. The validation set is typically created from the training set itself, often through techniques like k-fold cross-validation. However, some practitioners prefer setting aside a separate portion of the data exclusively for validation purposes.

The specific proportions of these subsets depend on factors such as the size of the overall dataset, class imbalance, and the complexity of the problem. Cross-validation methods, such as k-fold cross-validation or leave-one-out cross-validation, can also be employed to improve the robustness and reliability of the evaluation results.