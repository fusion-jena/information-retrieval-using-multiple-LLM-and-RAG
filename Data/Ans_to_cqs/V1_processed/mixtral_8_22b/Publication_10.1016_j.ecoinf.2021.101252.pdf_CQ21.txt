After the model training process, several postprocessing steps can be performed depending on the specific requirements of the task or project. Some common postprocessing steps include:

1. Model evaluation metrics: Calculating various evaluation metrics such as accuracy, precision, recall, F1 score, ROC curves, etc., to assess the performance of the model. In this case, the authors use the Area Under Curve (AUC) metric to evaluate their models.

2. Hyperparameter tuning: Adjusting hyperparameters like learning rate, batch size, regularization parameters, etc., based on the results obtained during the initial training phase.

3. Early stopping: Monitoring the validation loss or other metrics during training and halting the training process when there is no further improvement in these metrics. For example, the authors stop training if no increase in validation performance is observed after 25 epochs.

4. Ensemble methods: Combining multiple models to improve overall performance by averaging predictions or using more complex ensemble techniques like stacking or boosting.

5. Visualizing results: Creating visualizations like confusion matrices, ROC curves, saliency maps, etc., to better understand the strengths and weaknesses of the model. However, it seems that the authors did not explicitly mention any visualization techniques in the given context.

6. Deployment: Once satisfied with the model's performance, deploying it into production environments where it can be integrated with existing applications or services.