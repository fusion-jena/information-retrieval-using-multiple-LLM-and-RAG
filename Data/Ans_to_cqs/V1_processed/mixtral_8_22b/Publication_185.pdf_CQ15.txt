In the given context, the paper discusses the application of deep learning in image recognition, specifically using the CNN architecture known as AlexNet. The authors mention that the model was trained using stochastic gradient descent (SGD) and the backpropagation algorithm included in Caffe (Jia et al., 2014). The learning rate policy was set to "step", and the initial learning rate was set to 10^-2 for all layers. This indicates that SGD was used as the optimization technique in this particular deep learning pipeline. However, other optimization techniques such as Adam or RMSProp could also be used depending on the specific requirements and constraints of the problem being solved.