The optimization technique applied in the deep learning pipeline is the Adam optimizer. This information can be found in the last paragraph of the given text, where it states, "We used the cross-entropy loss as the objective function for training our network, and the Adam (Kingma and Ba, 2014) optimizer for updating the trainable parameters."