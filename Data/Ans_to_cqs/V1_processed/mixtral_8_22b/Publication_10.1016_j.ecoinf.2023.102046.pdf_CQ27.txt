Unfortunately, there isn't enough information provided about the deployment process of the trained deep learning models mentioned in the given text. Therefore, I cannot provide specific details regarding the process followed to deploy these models, such as model serialization or platform selection. However, typically, once a deep learning model is trained, it needs to be saved or serialized into a format that can be loaded later for prediction tasks. This could involve using libraries like TensorFlow's SavedModel or PyTorch's torch.save() functions. After saving the model, it would then need to be deployed onto a suitable platform, depending on its intended application. This might include cloud platforms like AWS, Google Cloud, or Azure, or edge devices for real-time predictions. Again, without more specific information, this general explanation is the best I can offer.