The text does not provide explicit information about the specific criteria used to determine when training is completed. However, it mentions that the performance of the algorithms was evaluated by comparing the loss function (mean squared error (MSE)) of the optimized models. This suggests that one possible criterion could be monitoring the validation loss during training and stopping when it reaches a plateau or starts increasing again. Additionally, the use of Optuna for hyperparameter optimization implies that cross-validation may have been employed, which would also involve tracking metrics like validation loss to decide when to stop training. Nevertheless, these details are not explicitly stated in the provided context.