To ensure the generalizability of their deep learning model, the authors took several measures while working with both the ImageNet and camera trap image datasets (SS and LSM).

For the ImageNet dataset, they used a pre-trained model on ImageNet-1k as the source model, which inherently provides diverse data due to its large scale. This approach helps improve the model's ability to generalize well across various tasks.

When dealing with the SS and LSM datasets, which consist of camera trap images, the authors maintained the integrity of events during data splitting. They ensured that all images belonging to the same event were placed in the same dataset (training, validation, or test). By doing so, they prevented any potential issues related to overfitting or poor generalization caused by having highly similar images in both the training and test sets.

Additionally, the authors conducted transfer learning experiments using different transfer strategies and evaluated them based on their performance on the test set. They also performed a binomial test to determine if there were significant differences among these strategies. These steps further contribute to ensuring the robustness and generalizability of the developed deep learning model.