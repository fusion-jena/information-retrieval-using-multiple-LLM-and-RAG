Based on the given information, it appears that the authors employed an adaptive incremental training method to improve the generalizability of their deep convolutional neural network (DCNN) model. This approach involved carrying out the training process in stages, starting with a smaller training set and gradually expanding it by incorporating more data. By doing so, they aimed to minimize the computational demands associated with model training while still ensuring its robustness and applicability across various scenarios.

However, there is no explicit mention of specific techniques such as diverse datasets, cross-validation, or stratified splitting being utilized to enhance the model's generalizability. Nevertheless, the fact that the authors evaluated the performance of their model using different training phases suggests that some form of validation may have been implemented during the development process. Additionally, the inclusion of multiple metrics like overall error, commission error, and omission error further indicates a comprehensive assessment strategy designed to gauge the model's accuracy and reliability under varying conditions.