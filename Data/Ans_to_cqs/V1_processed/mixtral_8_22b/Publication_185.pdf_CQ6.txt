Based on the given context, there isn't any explicit mention of specific preprocessing steps such as normalization, scaling, or cleaning. However, some aspects related to preprocessing can be inferred. For instance, the text mentions that the experiments were conducted on a small-sized dataset without data augmentation. This implies that the raw data might not have been expanded artificially to increase its size, but no information about other preprocessing techniques is available. Furthermore, the context discusses setting certain parameters like batch size, momentum, and penalty multipliers for L2 weight decay, along with applying dropout regularization. These are more related to the configuration of the deep learning model rather than preprocessing per se. Therefore, based solely on this context, I cannot provide a comprehensive list of preprocessing steps typically involved before training a deep learning model.