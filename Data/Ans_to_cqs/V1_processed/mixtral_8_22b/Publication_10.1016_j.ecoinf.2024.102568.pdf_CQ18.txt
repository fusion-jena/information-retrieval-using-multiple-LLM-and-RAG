To monitor the model performance during training, several strategies were employed. Firstly, the loss function used for training the Long Short-Term Memory (LSTM) model was Mean Squared Error (MSE). By tracking the changes in MSE during training, it was possible to assess how well the model was learning to predict the target variable. Secondly, to prevent overfitting, a dropout layer was incorporated into the model architecture. Dropout is a regularization technique that randomly excludes certain inputs from activation and weight updates during training. This helps ensure that the model does not become too specialized to the training data and maintains its ability to generalize to new data. Lastly, the input features were transformed using a MinMaxScaler, which scales each feature to a range between 0 and 1. This standardizes the input data and makes it easier for the model to learn patterns within the data. Overall, these strategies helped maintain the balance between model complexity and performance, ensuring that the final model could accurately predict air quality measurements without being excessively complex or prone to overfitting.