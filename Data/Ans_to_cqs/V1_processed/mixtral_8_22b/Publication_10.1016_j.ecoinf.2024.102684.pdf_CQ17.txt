The provided context does not explicitly mention any specific regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does discuss some strategies employed to address overfitting and improve the model's ability to generalize. These include conducting cross-validation experiments, adding heterogeneous information to the training procedure, and performing hyperparameter searches. While these strategies do not directly correspond to well-known regularization methods like dropout or L2 regularization, they still contribute to mitigating overfitting and enhancing the model's performance.