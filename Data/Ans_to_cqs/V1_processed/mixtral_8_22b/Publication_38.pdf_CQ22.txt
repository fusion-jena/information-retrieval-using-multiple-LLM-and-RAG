The performance of the deep learning models is evaluated using several metrics such as precision, recall, and precision-recall curves. Precision refers to the proportion of true positive predictions made by the model out of all the positive predictions. Recall, on the other hand, measures the proportion of actual positives that were correctly identified by the model. In this case, the authors use precision greater than 0.95 at any recall level as one of their evaluation metrics. They also report recall at 0.95 precision, which measures the fraction of calls that were detected while accepting a false positive rate of 5%. Additionally, they represent the results as a single point on the precision-recall curves.