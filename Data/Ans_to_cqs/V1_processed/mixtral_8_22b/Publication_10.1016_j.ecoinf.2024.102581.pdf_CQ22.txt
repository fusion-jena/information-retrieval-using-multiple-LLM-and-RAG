To evaluate the performance of a deep learning model, several metrics can be used. In this case, we have information about two tables (Tables 5 and 7) which provide details regarding the evaluation of the HPB3C-3PGA-based CNN approach on both the Mendeley and CVIP100 datasets. From these tables, it appears that the authors use four main metrics to assess their model's performance: accuracy, precision, recall, and F1-score.

Accuracy measures how often the classifier makes correct predictions. It is calculated as the ratio between the correctly predicted instances and the total number of instances. Precision, also known as positive predictive value, calculates the proportion of true positives among all the instances classified as positive. Recall, or sensitivity, computes the fraction of relevant instances that were retrieved. Lastly, the F1-score is the harmonic mean of precision and recall, providing a single metric that balances both factors.

Based on Tables 5 and 7, we see that the authors report the best accuracies obtained across different generations of their HPB3C-3PGA-based CNN approach. For example, Table 5 shows that the highest accuracy achieved on the Mendeley dataset was 98.96%, while Table 6 indicates that the top accuracy reached on the CVIP100 dataset was 98.97%. Additionally, Tables 5 and 7 present the corresponding values for precision, recall, and F1-scores, allowing us to understand the model's performance more comprehensively.