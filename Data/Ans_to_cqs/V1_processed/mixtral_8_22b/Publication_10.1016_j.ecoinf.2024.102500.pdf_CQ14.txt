The text mentions that the hyperparameters of the machine learning models are optimized using grid search with fivefold cross-validation. Grid search is a method used to find the optimal combination of hyperparameters for a given model. In this case, it involves specifying a set of hyperparameters and their corresponding values, then fitting the model on the training data for each combination of these hyperparameters. The resulting models are evaluated based on their performance metrics, such as coefficient of determination (R^2) or root mean squared error (RMSE), averaged across five iterations with five folds.

To select the hyperparameters, the Python library's `randint` command is used to pick integer values within a specified range for hyperparameters like `n_estimators` and `max_depth`. Additionally, the `uniform` command is employed for selecting discrete or continuous values within a range for hyperparameters like `min_samples_split`. By examining multiple hyperparameter value ranges, the optimal combination can be determined for each model.

In summary, the hyperparameters of the models are optimized through grid search with fivefold cross-validation, where various combinations of hyperparameters are tested, and the best performing ones are chosen based on average performance metrics across multiple iterations.