The given context does not provide any specific details about the hardware resources used for training the deep neural network mentioned in the paper by Zhang et al. (2024). However, generally speaking, deep learning models often require significant computational power due to their complexity. Therefore, it is common to use specialized hardware such as Graphics Processing Units (GPUs), Tensor Processing Units (TPUs), or Field Programmable Gate Arrays (FPGAs) for training these models. These hardware resources offer parallel processing capabilities, enabling faster computation and efficient handling of large datasets. Nonetheless, without explicit mention in the provided context, we cannot definitively state which hardware resources were utilized for training the deep learning model discussed in the referenced study.