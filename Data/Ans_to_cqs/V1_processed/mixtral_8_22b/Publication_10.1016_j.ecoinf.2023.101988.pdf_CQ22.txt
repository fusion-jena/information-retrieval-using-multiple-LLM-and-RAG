The papers cited in this context do not provide specific information about the evaluation metrics used for their respective deep learning models. However, common metrics used to evaluate the performance of deep learning models include accuracy, precision, recall, and F1 score. Accuracy measures the proportion of correct predictions out of all predictions made. Precision is the ratio of true positive predictions to the sum of true positives and false positives. Recall, also known as sensitivity or true positive rate, is the ratio of true positive predictions to the sum of true positives and false negatives. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both factors. Other possible metrics include area under the receiver operating characteristic curve (AUROC), Cohen's kappa coefficient, and Matthews correlation coefficient (MCC). Without further details from the authors regarding their chosen evaluation metrics, it cannot be determined which ones were specifically employed in these studies.