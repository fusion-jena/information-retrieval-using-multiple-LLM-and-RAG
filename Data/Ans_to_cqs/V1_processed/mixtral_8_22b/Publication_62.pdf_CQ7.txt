The authors do not explicitly state the criteria used to split their dataset into training, testing, and validation sets. However, they mention using a dropout layer with a probability of 0.5 during training, which is a common technique used to prevent overfitting by randomly dropping out neurons from the network during each iteration. This suggests that they likely used some form of cross-validation or held-out validation set to evaluate the performance of their models. Additionally, they provide supplementary materials containing Mathematica notebooks used to define and train their CNNs, which may contain further details on how they split their datasets.