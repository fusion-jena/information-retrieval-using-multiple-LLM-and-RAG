Unfortunately, the provided context does not directly address the specific strategies employed to handle randomness in the deep learning pipeline, including the management of random seed values. However, it can still provide insights into how deep learning techniques have been applied in various fields, particularly in soil carbon mapping and ecological information.

In general, handling randomness in the deep learning pipeline involves several strategies. One common approach is setting a fixed random seed value before training the model. This ensures reproducibility of results across different runs or experiments. Another strategy is employing cross-validation techniques, which involve splitting data into multiple subsets and iteratively training and testing the model on these subsets. This helps reduce overfitting and provides a more accurate estimation of the model's performance. Additionally, using dropout layers within neural networks can help introduce randomness during training, preventing overfitting and improving overall model performance. Lastly, ensembling multiple models trained with different initializations or architectures can further mitigate the impact of randomness and potentially lead to better predictions.