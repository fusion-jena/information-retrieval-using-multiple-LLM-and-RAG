The authors used repeated random sub-sampling to create five different datasets from the 12,000 frames extracted from the training and testing dataset. Each set was then divided into a training/testing split of 80/20, containing 9600 frames for training and 2400 for testing. This means that they randomly selected 80% of the frames for training and the remaining 20% for testing. They did not mention any specific criteria for splitting the data other than this ratio. However, it can be assumed that the selection was done randomly without considering any particular characteristics or features of the frames.

Regarding the validation set, the authors do not explicitly state how they created it. However, based on the information given, we can infer that they might have used a portion of the training set as the validation set during the training process. This is a common practice in machine learning where a part of the training set is held back and used to validate the model's performance after each epoch. In this case, since the authors mentioned that all models were trained over 100 epochs, it is likely that they used a similar approach. Nevertheless, without explicit confirmation from the authors, this remains speculation.