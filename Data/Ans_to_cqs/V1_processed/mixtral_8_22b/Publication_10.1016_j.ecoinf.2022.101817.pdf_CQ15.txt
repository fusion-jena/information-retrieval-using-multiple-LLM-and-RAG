The given context does not provide explicit information about the specific optimization techniques applied in the deep learning pipeline for this particular study. However, common optimization techniques used in training deep learning models include Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), Root Mean Square Propagation (RMSprop), and others. These methods help minimize the loss function during the training process. Without further details or references to the original research paper, we cannot determine which optimization technique was employed in this case.