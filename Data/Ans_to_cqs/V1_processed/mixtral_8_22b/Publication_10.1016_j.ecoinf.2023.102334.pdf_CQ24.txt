The text does not provide explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, some strategies can be inferred based on common practices in machine learning and deep learning. One approach is setting a specific random seed value before running any code involving random processes, ensuring consistency across different runs or sessions. Another strategy involves using techniques like cross-validation, where the dataset is divided into several subsets, with one subset serving as the testing set while others act as training sets. This helps mitigate the impact of randomness on performance evaluation. Additionally, employing ensemble methods, combining predictions from various models trained with different initializations or hyperparameters, can further reduce the effects of randomness.