The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it mentions some strategies employed to improve the model's performance and generalization.

To create a more robust and better-generalizing classifier, the authors applied image augmentations such as flipping horizontally and vertically, adjusting brightness, saturation, contrast, and hue. These techniques help increase the diversity of the training dataset and reduce overfitting.

Additionally, the dataset was divided into three subsets for training, validation, and testing in the proportion of 80:10:10. Although this is not explicitly stated as stratified sampling, maintaining the same distribution of classes across all subsets can help prevent biases caused by imbalanced datasets.

Furthermore, the authors mention that they had a large number of images compared to other studies, which could contribute to reducing potential biases due to limited data availability. They also suggest that having a minimum of 200 images per species might be necessary for accurate identification but found that even with fewer than 200 pollen grains, five out of six species achieved high classification accuracy.

In conclusion, based on the given context, the authors addressed data bias through various methods like image augmentation, dividing the dataset into different subsets, using a larger dataset, and suggesting a minimum number of images per species. However, there is no direct mention of techniques such as stratified splitting, oversampling, undersampling, or diverse data collection.