The given context does not provide specific information about the hyperparameters used in the deep learning models mentioned. However, common hyperparameters used in deep learning include learning rate, optimizer type (such as Adam, Stochastic Gradient Descent, etc.), batch size, number of epochs, weight decay, momentum, and others depending on the specific model architecture and problem domain. For example, Salman et al., (2016) mention achieving high classification rates using a CNN but do not specify the exact hyperparameters used. Similarly, Siddiqui et al., (2017) report a high classification accuracy using a very deep CNN with a cross-layer pooling approach without providing details on the hyperparameters employed. Therefore, further research would be required to determine the specific hyperparameters used in these studies.