After fitting the parameters of the different deep learning architectures and XGBoost on the training set, several postprocessing steps are performed. These include running the trained models on the test set to obtain a complete mapping of land cover (LC) and land use (LU). From these results, confusion matrices are extracted, which provide insights into the performance of the models.

To evaluate the performance of the models, four quality metrics are used: overall accuracy (OA), producer accuracy (PA), user accuracy (UA), and the F1-score. The OA measures the proportion of correctly classified pixels out of the total number of pixels. The PA measures the proportion of correctly classified pixels within each class, while the UA measures the proportion of true positives out of the total predicted positives for each class. The F1-score provides a single measure of accuracy that balances both precision and recall.

In addition to these metrics, saliency maps can also be generated to visualize the regions of the input images that contribute most significantly to the classification decision. This can help identify any biases or errors in the model predictions.

Overall, the postprocessing steps involve evaluating the performance of the trained models using various metrics and visualizations, such as confusion matrices and saliency maps, to gain insights into their strengths and weaknesses.