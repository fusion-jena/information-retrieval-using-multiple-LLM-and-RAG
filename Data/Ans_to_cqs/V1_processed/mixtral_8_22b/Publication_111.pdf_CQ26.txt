The given context does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it mentions two methods used to tackle overfitting concerns in the proposed deep learning model: early stopping strategy and dropout approach. The early stopping strategy involves separating the training data into training and validation groups to monitor the generalization performance. On the other hand, the dropout approach is a regularization technique that trains neural networks with alternate topologies in parallel by randomly dropping out a certain proportion of layer neurons. These methods help improve the model's ability to generalize better and avoid overfitting but do not directly address data bias issues.