To split the data for deep learning model training, the authors employed k-fold cross-validation. This method involves dividing the training set into 'k' fractions, where each fraction serves as a validation set iteratively, while the remaining 'k-1' fractions form the training set. Consequently, the validation process occurs 'k' times, using a distinct validation set each time. For all models, the first four years (2018-2021) were utilized as the training set, whereas the final year (2022) functioned as the test set. This resulted in an approximate proportion of 80-20%, a typical ratio in machine learning applications. Considering the data structure, choosing a value of 'k' equal to 4 was deemed appropriate, ensuring that each validation fraction corresponded roughly to one year.