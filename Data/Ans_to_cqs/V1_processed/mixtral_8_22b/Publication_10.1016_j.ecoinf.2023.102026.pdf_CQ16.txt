The text does not provide explicit information about the criteria used to determine when training is completed for either the Generalized Linear Model (GLM) or Random Forest (RF) models. However, it mentions that the performance of the non-bootstrapped GLM was evaluated using metrics like Area Under the ROC Curve (AUC), Percent Correctly Classified (PCC), sensitivity, specificity, and True Skill Statistic (TSS) using 20% of the camera trap data retained from the training dataset. For the bootstrapped GLM, these same metrics were calculated for each of the 100 iterations using the data retained from the model training, composed of 80% of the presence and absence locations. The final metrics were then obtained by averaging the results of 100 validation iterations. This suggests that the completion of training might have been determined based on achieving stable or satisfactory values for these evaluation metrics. Similarly, while the text does not explicitly mention any stopping criterion for the RF model, it discusses the use of bootstrapping (random subsampling with replacement) to improve models' precision and reduce stochastic errors in estimation. This implies that the training process might continue until a certain level of precision or stability is achieved. However, without more specific details, it is difficult to definitively state what exact criteria were used to determine when training was complete for both models.