In this study, the dataset was randomly divided into two subsets - a training dataset and a validation dataset. The training dataset comprised 75% of the total data and was used to train the model and determine the optimal model structure. On the other hand, the remaining 25% of the data served as the validation dataset to evaluate the model's performance. To ensure the robustness of the Random Forest (RF) algorithm, which is known to perform well even when trained on randomly sampled subsets of data, random sampling was employed instead of clustering. However, it was crucial to preserve the covariance structure among the predictor variables relatively intact between the training and testing datasets. This approach allowed for monitoring the model performance during training without compromising the integrity of the data or introducing bias.