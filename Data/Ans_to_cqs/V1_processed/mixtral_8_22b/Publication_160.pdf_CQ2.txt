The context does not provide explicit information about the specific data formats used in the deep learning pipeline. However, it mentions that deep Convolutional Neural Networks (CNNs) have been widely used for image classification tasks since the mid-2000s. It also discusses the use of CNNs for identifying coral reef species from underwater videos. Therefore, we can infer that images and possibly video data were used in these deep learning pipelines. Additionally, the context refers to patch-based classification, where bounding boxes are placed around annotated pixels, further supporting the idea that image data was utilized. Unfortunately, without additional context, I cannot confirm if other data formats like audio, text, or CSV files were employed in the deep learning pipelines discussed here.