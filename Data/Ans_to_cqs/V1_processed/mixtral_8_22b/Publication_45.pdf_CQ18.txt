During the training phase of the Deep Neural Network (DNN), the strategy implemented to monitor its performance involved splitting the available data into a training data set and a test data set. This approach allowed for gauging the accuracy of predictions for new input data that wasn't utilized during the training phase.

Moreover, the training of individual candidate networks was halted once the accuracy of the network on the test dataset ceased to improve further. This method ensured that the network didn't continue training beyond its optimal point, preventing potential overfitting or underperformance due to unnecessary computational cycles.

Additionally, various hyper-parameters were evaluated iteratively throughout this process. These included network capacity (defined by the number of layers and neurons per layer), applied regularization techniques, the chosen loss function, and the optimizer. By adjusting these elements, researchers could fine-tune the model's performance and ensure it remained accurate and efficient.

All experiments and predictions were carried out utilizing the TensorFlow framework, running on a desktop computer equipped with an Intel QuadCore CPU (Intel i5-6600) and an NVidia GTX 1070 GPU.