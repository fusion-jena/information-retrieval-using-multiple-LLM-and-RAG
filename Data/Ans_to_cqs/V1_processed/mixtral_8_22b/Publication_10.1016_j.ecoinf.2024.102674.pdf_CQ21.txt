After the model training process, several postprocessing steps can be performed depending on the specific requirements of the project or research. Some common postprocessing steps include:

1. Model evaluation: This involves assessing the performance of the trained model using various metrics such as accuracy, precision, recall, F1 score, ROC AUC, etc. These metrics help determine how well the model has learned from the training data and its ability to generalize to unseen data.

2. Confusion matrix: A confusion matrix is a table used to evaluate the performance of a classification model. It provides insights into the types of errors made by the model during prediction. The matrix consists of four components: True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).

3. Saliency maps: Saliency maps are visualization techniques used to highlight the most important features contributing to the output of a deep learning model. They provide insights into which parts of the input data have the greatest impact on the final predictions.

4. Uncertainty quantification: In some applications, it may be necessary to estimate the uncertainty associated with the model's predictions. Techniques such as bootstrapping, Bayesian methods, or Monte Carlo simulations can be employed to quantify this uncertainty.

5. Extrapolation assessment: When applying models to new environments or scenarios, it is essential to assess whether they are being applied outside their domain of applicability. One approach to evaluating this is through the use of extrapolation metrics such as the Shape metric described in Velazco et al. (2023).

Based on the given context, we see that the authors calculate Shape values to measure the degree of extrapolation when applying downscaling models to new areas. They do this by considering the Mahalanobis distance between the training and projection data using the FLEXSDM R package (Velazco et al., 2022). Additionally, they obtain 12 surfaces of the Shape extrapolation metric for both WorldClim and CHELSA datasets, one for each month. However, the context does not explicitly mention other postprocessing steps like saliency maps, confusion matrices, or uncertainty quantification.