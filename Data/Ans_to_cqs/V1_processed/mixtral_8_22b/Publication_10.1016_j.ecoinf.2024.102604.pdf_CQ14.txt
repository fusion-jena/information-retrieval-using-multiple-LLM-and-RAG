The provided context does not explicitly mention how the hyperparameters of the model were optimized. However, common methods used for hyperparameter optimization include grid search, random search, Bayesian optimization, and gradient-based optimization. Grid search involves defining a set of possible values for each parameter and then evaluating all combinations of these parameters. Random search randomly samples points within the defined ranges for each parameter. Bayesian optimization uses a probabilistic approach to find the optimal combination of parameters based on previous results. Gradient-based optimization techniques use gradients or derivatives to iteratively update the parameters towards their optimal values. Without further information, it cannot be determined which specific method was used for hyperparameter optimization in this case.