The text does not provide explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, it mentions some strategies used to improve the model's performance and prevent overfitting. For instance, the authors modified BatNet and optimized parameter settings like batch size. They also added new kinds of BNorm layers behind the 22 convolutional layers to help the model learn to generalize trends instead of maximizing performance on known datasets. Additionally, they set a large batch size equal to 128, meaning training with 128 images for each iteration. These techniques may indirectly address randomness in the deep learning pipeline, but specific strategies for managing random seeds are not discussed in the given context.