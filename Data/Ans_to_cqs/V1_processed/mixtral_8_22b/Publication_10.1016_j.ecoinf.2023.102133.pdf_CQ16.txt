Based on the given information, there isn't a direct mention of specific criteria used to determine when training is complete. However, some indications suggest that cross-validation was used to assess model reliability and avoid overfitting. This implies that the training process might have been monitored using metrics such as validation loss or accuracy, which could indicate when the model has reached its optimal state. Additionally, the text mentions that the best models were selected based on their performance, suggesting that some form of evaluation was conducted during the training process. Therefore, while the exact criteria aren't explicitly stated, it can be inferred that they likely involve monitoring validation metrics and evaluating model performance throughout the training process.