The paper uses several metrics to evaluate the performance of the deep learning models. These include Average Precision (AP), Mean Average Precision (mAP), Intersection over Union (IoU), Average Recall (AR), and Action Recognition Accuracy.

Average Precision (AP) measures the area under the precision-recall curve and is commonly used in object detection tasks. It is calculated using Equations (4) and (5) in the paper. The paper considers AP for various IoU thresholds ranging from 0.50 to 0.95, including AP0.50 and AP0.75, which are specific cases of the general formula.

Mean Average Precision (mAP) is another common metric used in object detection tasks. It is simply the average of the AP values across multiple classes. The paper calculates mAP using Equation (5).

Intersection over Union (IoU) is a measure of overlap between two bounding boxes or segmentation masks. It is defined in Equation (2) and is used to determine whether a detected object matches a ground truth object.

Average Recall (AR) is a measure of the ability of the model to detect objects of interest. It is calculated using Equations (7) and (8) in the paper. The paper considers two versions of AR: ARmax=1 and ARmax=10.

Action Recognition Accuracy is used to evaluate the performance of the action recognition task. The paper trains three ResNet variants for 40 epochs using Stochastic Gradient Descent (SGD) with a momentum of 0.9 and a learning rate schedule. The final accuracy is reported after training.