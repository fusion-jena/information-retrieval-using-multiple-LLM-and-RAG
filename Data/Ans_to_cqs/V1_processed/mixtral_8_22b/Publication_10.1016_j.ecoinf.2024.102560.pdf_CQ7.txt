The criteria used to split the data for deep learning model training typically include the following:

* Train set: This dataset is used to train the model. It consists of input features and their corresponding labels or outputs. The size of the train set should be large enough to capture all possible variations in the data.
* Test set: This dataset is used to evaluate the performance of the trained model. It contains unseen examples that were not included in the train set. The test set helps to measure the generalization ability of the model.
* Validation set: This dataset is used during the training process to tune hyperparameters and prevent overfitting. It provides feedback on how well the model is performing while adjusting its parameters. The validation set is usually created from a portion of the train set.

These splits are often done randomly but can also be stratified based on class distributions or other factors. The proportion of each split depends on the specific problem and available resources. Common ratios include 80/20, 70/30, or 60/20/20 for train/test/validation sets respectively. However, these values are not fixed and can vary depending on the application.