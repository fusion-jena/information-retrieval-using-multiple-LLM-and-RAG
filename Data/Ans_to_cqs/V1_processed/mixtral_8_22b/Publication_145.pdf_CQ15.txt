In this study, the authors use the RMSprop optimizer, which is an unpublished, adaptive learning rate method proposed by Geoff Hinton. This optimizer is not commonly known like Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam), but it has been shown to be effective in certain applications. The initial learning rate used was 0.0001, and the network was trained for 300 epochs with 24 images per batch. The implementation was done in the programming language R with RStudio interface to Keras and TensorFlow backend. Training took between 2-20 hours using a GPU from an Nvidia RTX2080 graphics card with 8GB of dedicated memory.