The given context does not provide specific details about the optimization techniques used in the deep learning pipeline. However, it mentions that during each training stage, the model was selected based on the epoch that gave the best performance on the validation set. This suggests that some form of early stopping or validation-based model selection was implemented. Additionally, the use of deep learning implies that gradient descent-based optimization methods were likely used, such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). These methods are commonly used in deep learning pipelines for optimizing network parameters. Without further context, it cannot be definitively stated which specific optimization technique was utilized.