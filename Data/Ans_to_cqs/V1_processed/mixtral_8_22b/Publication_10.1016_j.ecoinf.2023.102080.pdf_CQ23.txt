The authors did not explicitly mention any specific measures taken to ensure the generalizability of the deep learning model, such as using diverse datasets, cross-validation, or stratified splitting. However, they did evaluate the performance of various models, including GLM, GAM, and Random Forests, by calculating metrics like Area Under the Curve (AUC), maxTSS, CBI, and Score values using a split-sample strategy repeated 100 times with 30% of the data kept aside for validation. This approach can help assess the robustness and generalization capabilities of these models. Additionally, the analyses were conducted using a 10-core central processing unit strategy with AMDÂ® EPYC 7402 on the University of Lausanne HPC cluster, which may contribute to computational efficiency and reproducibility.