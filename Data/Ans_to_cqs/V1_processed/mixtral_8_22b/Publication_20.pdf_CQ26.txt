Based on the provided context, it appears that the authors have employed several strategies to mitigate potential data bias during the preprocessing stage of their deep learning pipeline. However, they do not explicitly mention specific techniques such as stratified splitting, oversampling, undersampling, or diverse data collection. Nevertheless, we can infer some methods based on the information available.

Firstly, the authors ensured that they had a sufficient number of thumbnail samples for each fish species class, with at least 2200 thumbnails per class. This approach could be considered a form of oversampling, as it ensures that even underrepresented classes have enough examples to train the model effectively.

Secondly, the authors applied two decision rules during post-processing to handle cases where the environment or parts of fish species were present in the input data. Rule r1 addresses situations where the environment is the most likely class, ensuring that the focus remains on identifying fish species rather than background elements. Meanwhile, rule r2 treats "part of species X" as equivalent to "species X," allowing the model to recognize partial representations of fish species accurately. These decision rules help maintain consistency and accuracy when dealing with potentially ambiguous inputs.

Lastly, the authors created different datasets (T3 and T4) to manage variations in the input data. Dataset T3 included a single global class called "part of fish," while dataset T4 contained multiple "part of species" classes corresponding to individual fish species. By creating these distinct datasets, the authors aimed to improve the model's ability to distinguish between various fish species and reduce any potential bias caused by inconsistent labeling or classification schemes.

In conclusion, although the authors did not directly discuss traditional techniques like stratified splitting, oversampling, undersampling, or diverse data collection, they implemented several strategies to minimize data bias during preprocessing. These include employing adequate sample sizes, applying decision rules to handle ambiguous inputs, and managing input variations through separate datasets.