The performance of the deep learning model is evaluated using several metrics, including True Positives (TP), False Positives (FP), False Negatives (FN), Precision, Recall, and F1-Measure. TP represents the correctly identified positive cases, while FP and FN represent incorrectly identified negative and positive cases, respectively. Precision is calculated as TP/(TP+FP), which indicates the proportion of correct positive identifications among all positive predictions. Recall is calculated as TP/(TP+FN), representing the proportion of correct positive identifications among all actual positive cases. F1-Measure combines both Precision and Recall into a single metric, providing a more balanced evaluation of the model's performance. Additionally, the table presented in the context shows the results of CNN-detection in Test-zone-1 at different sliding window sizes, displaying the values of TP, FP, FN, Precision, Recall, F1-Measure, and Execution Time for each window size.