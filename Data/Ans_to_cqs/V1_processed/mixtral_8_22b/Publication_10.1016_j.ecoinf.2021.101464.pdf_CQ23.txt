To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the study utilized diverse datasets, including various spatial and temporal scales, to capture the variability in the predictor variables. This diversity in the dataset helped improve the model's performance across different climate regions. Secondly, the study employed a 10-fold cross-validation technique during the training phase of the Random Forest (RF) model. Cross-validation is a powerful preventive measure against overfitting, where the model learns the noise in the training data instead of the intended underlying pattern. By using this method, the researchers aimed to achieve a balance between bias and variance, ensuring that the model performs well not only on the training set but also on new, unseen data. Lastly, the use of independent test data in the RF model for 10-fold cross-validation further verified the model's stability. These measures collectively contributed to enhancing the robustness and reliability of the deep learning model, making it applicable to a broader range of scenarios and improving its overall prediction ability.