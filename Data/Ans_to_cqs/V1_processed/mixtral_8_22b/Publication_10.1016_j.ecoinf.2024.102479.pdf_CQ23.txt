To ensure the generalizability of the deep learning model, several measures were taken. Firstly, a diverse dataset was used, which included 138 ground-based AGB estimates after eliminating outliers. Secondly, k-fold cross-validation was employed as an evaluation method. This technique helps prevent overfitting by dividing the dataset into k subsets. Some of these subsets are used for training the model, while the others are utilized to evaluate its performance. In this study, a 10-fold cross-validation design was employed. Lastly, the dataset was split into two distinct sets: 70% of the dataset was designated for model training while the remaining 30% was used as a testing dataset. This approach ensures that the model is trained on a sufficient amount of data while also providing an independent dataset for testing. These measures help ensure that the deep learning model can perform well not only on the training data but also on unseen data, thereby improving its generalizability.