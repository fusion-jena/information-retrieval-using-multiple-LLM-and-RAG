In the given context, there isn't any explicit mention of regularization methods like dropout or L2 regularization being used to prevent overfitting in the deep learning pipeline. However, some techniques employed can be considered as implicit ways to mitigate overfitting.

One technique mentioned is the use of various callbacks during the training process, specifically ReduceLROnPlateau, ModelCheckpoint, and EarlyStopping. ReduceLROnPlateau reduces the learning rate when a metric has stopped improving, which helps avoid getting stuck in local minima and improves generalization. ModelCheckpoint saves the best performing model based on a specified metric, ensuring that the final model chosen is not overfit to the training data. Lastly, EarlyStopping stops the training process if a monitored metric fails to improve after a certain number of epochs, preventing unnecessary iterations that could potentially cause overfitting.

Additionally, the ablation studies conducted for the BEiT model evaluate its performance without added noise, suggesting that the model might have been trained with some form of input augmentation or perturbation to enhance robustness and reduce overfitting.

While these techniques contribute to reducing overfitting, they do not directly correspond to traditional regularization methods like dropout or L2 regularization. Therefore, it cannot be definitively stated what regularization methods were explicitly used to prevent overfitting in this deep learning pipeline.