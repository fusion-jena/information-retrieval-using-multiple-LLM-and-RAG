Based on the provided context, there isn't explicit information about the specific criteria used to determine when training is complete. However, common practices in machine learning include monitoring the validation loss during training and stopping the process once the validation loss reaches a plateau or starts increasing. This indicates that the model has learned all it can from the training data and further training may lead to overfitting. In some cases, early stopping is also implemented, where training stops if the validation loss does not improve after a certain number of epochs. These methods help prevent overfitting and ensure optimal generalization performance on unseen data.