Unfortunately, none of the provided sources explicitly mention which specific hardware resources were used for training their respective deep learning models. However, it is common practice in the field of deep learning to use Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) due to their superior performance in handling parallel computations required during the training process. Therefore, while we cannot provide a definitive answer, it is highly likely that either GPUs or TPUs were utilized for training these deep learning models.