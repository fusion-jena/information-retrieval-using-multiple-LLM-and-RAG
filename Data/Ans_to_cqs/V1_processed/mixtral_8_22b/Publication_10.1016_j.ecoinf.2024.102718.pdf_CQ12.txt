The proposed BEiT model leverages transformer capabilities along with existing models such as Xception. This combination ensures effective and complementary strengths for their purpose. The use of transformer architecture in vision tasks suggests that the BEiT model incorporates elements of transformer networks, while Xception employs depthwise separable convolutions to enhance model performance and efficiency. Therefore, it can be inferred that the BEiT model uses a hybrid approach combining aspects of transformer networks and convolutional neural networks (CNNs).