Based on the given context, there isn't explicit information about the specific data annotation techniques used in the deep learning pipeline. However, we can infer some aspects based on the mentioned processes.

Firstly, the text mentions that each orthophoto was divided into smaller tiles of 256 x 256 pixels. This implies that the labeling was likely done at the tile level, meaning that each tile had its own set of labels.

Secondly, the mention of 'labels' suggests that semantic segmentation could have been used as a data annotation technique. Semantic segmentation involves assigning a class label to every pixel in an image, thus providing detailed information about the objects present in the scene.

Lastly, the use of a Convolutional Neural Network (CNN) for processing the tiles indicates that the input data was likely in the form of multi-dimensional arrays, such as those produced by semantic segmentation.

However, without explicit information about the type of labels used (e.g., whether they indicate object boundaries, object classes, etc.), it's impossible to definitively state what kind of data annotation techniques were used. Therefore, based on the provided context, we can only suggest that semantic segmentation may have been used, but further confirmation would be needed to confirm this.