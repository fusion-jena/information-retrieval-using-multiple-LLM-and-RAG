Based on the given context, it appears that the authors have not explicitly mentioned the specific criteria used to split their dataset for deep learning model training (train, test, validation). However, they do mention that they use a Convolutional Neural Network (CNN) for training and provide details about its architecture and parameters. They also discuss the incorporation of a dropout function to improve model reliability.

Typically, when working with machine learning models like CNNs, datasets are often divided into three subsets: training set, validation set, and testing set. This division helps prevent overfitting and allows for better evaluation of the model's performance. Common methods for splitting the data include random sampling, stratified sampling, or time series based splits depending on the nature of the problem and available resources.

Without explicit information from the authors regarding the criteria used to split their data, we can only speculate that they might have followed standard practices such as randomly dividing the dataset into training, validation, and testing sets. It would be best to refer directly to the paper or contact the authors for more precise information if needed.