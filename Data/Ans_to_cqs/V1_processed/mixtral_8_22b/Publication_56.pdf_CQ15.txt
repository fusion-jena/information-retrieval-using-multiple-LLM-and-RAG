Unfortunately, the given context does not provide information about specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) that are commonly applied in the deep learning pipeline. These optimization techniques are crucial for training deep learning models effectively and efficiently. They adjust the parameters of the model during training to minimize the loss function and improve the accuracy of the model. However, without explicit mention in the provided context, it is not possible to determine which optimization techniques are being utilized.