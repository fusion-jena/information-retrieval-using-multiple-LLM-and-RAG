After the model training, several postprocessing steps can be performed depending on the specific requirements of the project or task. Some common postprocessing steps include:

1. Model evaluation: This involves calculating various metrics like accuracy, precision, recall, F1 score, etc., to assess the performance of the model. These metrics help determine how well the model has learned to predict the target variable.

2. Confusion matrix: A confusion matrix is a table that summarizes the predictions made by the model compared to the actual values. It helps visualize the performance of the model and identify any patterns or biases in its predictions.

3. Saliency maps: Saliency maps highlight the regions of input data that contribute most significantly to the output prediction. They provide insights into which features of the input data are important for making accurate predictions.

4. Feature importance: Similar to saliency maps, feature importance analysis identifies the most relevant features contributing to the model's predictions. This information can be useful for understanding the underlying relationships between variables and improving the interpretability of the model.

5. Hyperparameter tuning: After evaluating the initial model, hyperparameters may need to be adjusted to improve performance further. Techniques such as grid search, random search, or Bayesian optimization can be employed to optimize these parameters.

6. Ensemble modeling: Combining multiple models through techniques like bagging, boosting, or stacking can often lead to improved overall performance. Postprocessing steps might involve creating ensembles of individual models and comparing their results.

7. Visualizing embeddings: Tools like t-SNE or UMAP can be used to visualize high-dimensional embeddings generated by deep learning models. This allows researchers to understand better how the model represents complex data structures and identify potential issues or areas for improvement.

Based on the given context, it appears that the authors have evaluated their models using various metrics and visualized the embeddings using tools like UMAP. However, they do not explicitly mention other postprocessing steps like generating saliency maps or performing hyperparameter tuning.