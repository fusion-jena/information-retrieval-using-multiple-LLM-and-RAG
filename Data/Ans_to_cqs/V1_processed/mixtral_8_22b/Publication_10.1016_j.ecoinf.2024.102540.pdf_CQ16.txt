Based on the given context, there isn't explicit information about the specific criteria used to determine when training is complete. However, one can infer from the mention of epoch numbers that they play a role in determining the completion of training. Epoch refers to one forward and one backward pass of all the training examples. In other words, an epoch is one iteration over the entire dataset. The number of epochs used in training determines how many times the detection model processes the dataset dedicated to training the model. Therefore, it could be assumed that the training is considered complete once the specified number of epochs has been reached. In this case, the optimal hyperparameters for their training were found to be 400 epochs. Additionally, while not explicitly mentioned, validation loss plateaus or early stopping methods might also have been employed to prevent overfitting during the training process. These methods involve monitoring the performance of the model on a separate validation dataset after each epoch and halting the training if the validation loss stops improving significantly.