Techniques such as stratified splitting, oversampling, undersampling, and diverse data collection are often employed to mitigate data bias during the preprocessing stage of the deep learning pipeline.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the original class distribution. This ensures that both subsets reflect the overall diversity of the entire dataset, thereby preventing any skewed representation of classes.

Oversampling is another technique used to balance datasets where one or more classes are underrepresented. It works by duplicating examples from minority classes until their frequency matches that of majority classes. Alternatively, synthetic samples can be created using methods like SMOTE (Synthetic Minority Over-sampling Technique), which generates new instances based on interpolation between existing ones.

Undersampling, conversely, reduces the size of overrepresented classes by randomly removing instances. While effective in achieving balanced distributions, undersampling risks discarding valuable information contained within removed examples. To avoid this issue, informed undersampling strategies like NearMiss and Tomek Links selectively eliminate instances based on specific criteria related to class boundaries and outliers.

Lastly, collecting diverse data helps capture various aspects of real-world scenarios, thus improving model generalization capabilities. Efforts should focus on acquiring representative samples across all relevant domains, including edge cases and rare events. Moreover, augmentation techniques can artificially expand datasets by applying transformations such as rotations, translations, scaling, flipping, cropping, and color space manipulations. These modifications increase variability without altering underlying semantics, ultimately enhancing robustness against biases induced by limited sample sizes.