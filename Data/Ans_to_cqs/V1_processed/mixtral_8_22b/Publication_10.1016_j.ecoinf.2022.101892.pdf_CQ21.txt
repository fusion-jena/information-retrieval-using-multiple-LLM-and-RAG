After the model training process, several postprocessing steps can be performed depending on the specific requirements of the task. Some common postprocessing steps include:

1. Model Evaluation: This involves evaluating the performance of the trained model using various metrics such as accuracy, precision, recall, F1 score, etc. These metrics provide insights into how well the model performs on unseen data.
2. Confusion Matrix: A confusion matrix is a table that summarizes the performance of a classification algorithm. It shows the number of correct and incorrect predictions made by the model for each class.
3. Saliency Maps: Saliency maps highlight the regions of an input image that contribute significantly to the final prediction made by the model. They can be useful for understanding what parts of the image the model focuses on when making its decision.
4. Visualizing Weights: Visualizing the weights of the trained model can provide insights into how the model learned to recognize patterns in the input data.
5. Hyperparameter Tuning: After training the model, hyperparameters such as learning rate, regularization strength, etc., can be fine-tuned to improve the model's performance further.

In the given context, the authors mention that they calculated Mean Absolute Error (MAE) values and compared the inference time to determine the most computationally efficient model. They also expanded their dataset by a factor of five and recorded the inference time of batches of 100 to quantify Queries Per Second (QPS). However, there is no explicit mention of any other postprocessing steps such as saliency maps or confusion matrices. Therefore, it cannot be determined if these methods were employed in this particular study.