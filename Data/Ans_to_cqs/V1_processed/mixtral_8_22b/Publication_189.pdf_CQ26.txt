Data bias can significantly impact the performance of deep learning models. Several techniques are employed to mitigate this issue during the preprocessing stage of the deep learning pipeline. Here are some commonly used methods:

1. Stratified Splitting: This technique involves dividing the dataset into training and testing sets while maintaining the same class distribution in both sets. It ensures that the model learns from a representative sample of all classes, reducing the risk of overfitting or underfitting due to imbalanced data.

2. Oversampling: When dealing with imbalanced datasets, oversampling can help balance the classes. This method involves duplicating samples from the minority class until it reaches the size of the majority class. Alternatively, synthetic examples can be generated using techniques such as SMOTE (Synthetic Minority Overfitting TEchnique).

3. Undersampling: Another approach to handling imbalanced datasets is undersampling. This method reduces the number of samples in the majority class to match the size of the minority class. However, care must be taken not to lose valuable information when removing samples.

4. Diverse Data Collection: Collecting diverse data is crucial to ensure that the trained model generalizes well across various scenarios. This includes gathering data from multiple sources, capturing variations in lighting conditions, angles, backgrounds, and subjects, among others.

In the given context, there is no explicit mention of specific techniques used to address data bias during preprocessing. However, based on the information available, we can infer that the authors have collected their own dataset using a fixed camera and stored the images in a database. While this does not directly address data bias, having control over the data collection process allows them to gather diverse data, potentially minimizing biases introduced by external factors.