The given context does not provide any direct information about the strategy implemented to monitor the model performance during training. However, it can be inferred that the researchers might have used techniques such as cross-validation, early stopping, learning curves, or confusion matrices to evaluate their models. These methods are commonly employed to assess the performance of machine learning algorithms during training. Cross-validation involves splitting the dataset into multiple subsets and using them to validate the model's accuracy. Early stopping helps prevent overfitting by halting the training process when the validation error starts increasing. Learning curves display the relationship between the size of the training set and the model's performance, while confusion matrices summarize the predictions made by the classifier. Nevertheless, without explicit details regarding the specific methodology utilized in this research, these assumptions remain speculative.