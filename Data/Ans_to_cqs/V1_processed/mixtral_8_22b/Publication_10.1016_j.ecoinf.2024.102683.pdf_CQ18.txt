The authors monitored the performance of their models by evaluating them using various performance metrics such as accuracy, precision, recall, specificity, and F1-score. They also tracked the performance of the models over different epochs and varying amounts of training data. This allowed them to observe how the models improved with additional training and larger datasets. Furthermore, they employed a data splitting technique where 50% of the dataset was used for training and the remaining 20% was utilized for testing purposes. This approach helped enhance the generalization performance of the models.