Based on the given context, there isn't explicit information regarding the specific strategy used to monitor the model performance during training. However, some clues can be derived from the text. For instance, the authors mention using the focal loss function to address class imbalance issues during training. This suggests that they might have been monitoring the model's performance through metrics such as precision, recall, or F1 score, which are commonly used to evaluate classifiers dealing with imbalanced datasets. Additionally, the authors discuss evaluating and comparing different augmentation methods, implying that they monitored the model's performance based on these variations. Lastly, the authors state that they used ImageNet-based weights for pretraining their ViT models, indicating that transfer learning was employed, and its effect on model performance would likely have been tracked throughout training.