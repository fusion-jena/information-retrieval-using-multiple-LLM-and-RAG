Training of the individual candidate networks was stopped when the accuracy of the network on the test dataset did not increase further. This suggests that the criterion used to determine when training is complete is based on the performance of the model on the test dataset. Specifically, if the model's accuracy on the test dataset does not improve after a certain point, then it can be assumed that the model has learned all it can from the training data and further training would not yield any additional benefits. This approach is known as early stopping, which is a form of regularization used to prevent overfitting. It involves monitoring the performance of the model on a separate validation dataset during training and stopping the training process once the performance starts to degrade or stops improving. In this case, the test dataset appears to have been used both for evaluating the final performance of the model and for determining when to stop training. However, it is generally recommended to use a separate validation dataset for early stopping to avoid biasing the estimates of generalization performance.