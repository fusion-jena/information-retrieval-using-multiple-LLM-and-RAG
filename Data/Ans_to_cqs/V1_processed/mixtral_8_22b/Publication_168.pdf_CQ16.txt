Based on the given context, there isn't any explicit information about the specific criteria used to determine when training is complete. However, considering common practices in machine learning, one possible criterion could be monitoring the validation loss during training. When the validation loss reaches a plateau or starts increasing while the training loss continues decreasing, it might indicate overfitting, suggesting that the training should stop. Another commonly used criterion is setting a fixed number of epochs for training, which can also help prevent overfitting. Additionally, early stopping based on the validation loss can be employed to halt training if no improvement is observed after several consecutive epochs. Nevertheless, without more specific details from the context, these suggestions remain speculative.