Based on the given context, the criteria used to split the data for deep learning model training into train, test, and validation sets are not explicitly mentioned. However, common practices in machine learning suggest that the dataset is typically divided into three subsets: training set, validation set, and testing set.

The training set is used to fit the model, i.e., adjust the weights and biases of the neurons in the network based on the input features and target labels. This process helps the model learn patterns and relationships within the data.

The validation set is employed to fine-tune hyperparameters and prevent overfitting. During the training process, the model's performance is evaluated on the validation set after each epoch or a certain number of iterations. Based on these evaluations, decisions are made regarding whether to continue training, stop early, or modify hyperparameters like learning rate, regularization parameters, etc.

Finally, the testing set serves as an independent evaluation of the trained model's performance. It provides insights into how well the model generalizes to unseen data. Typically, the testing set remains untouched until the very end of the modeling process to ensure its independence.

While the exact proportions may vary depending on the problem and available data, a commonly used ratio is 80/10/10 or 70/15/15 for splitting the data into training, validation, and testing sets, respectively.