The text does not explicitly mention the criteria used to determine when training is complete. However, based on common practices in machine learning, one possible criterion could be monitoring the validation loss during training. When the validation loss reaches a plateau or starts increasing, it may indicate that the model is starting to overfit the training data, and further training would not improve the model's performance on unseen data. In this study, the authors used a validation set (10% of the preprocessed data) to evaluate the model's performance during training, so they likely monitored the validation loss to decide when to stop training. Another potential criterion could be setting a maximum number of epochs or iterations for training, after which the training process stops regardless of the model's performance.