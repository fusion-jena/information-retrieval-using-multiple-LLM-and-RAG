In this study, passive acoustic monitoring (PAM) is used for collecting raw data in the deep learning pipeline. PAM involves using recording devices such as microphones or hydrophones to capture sounds produced by animals or their environment. This method is advantageous compared to other survey methods due to its non-invasiveness and ability to collect data over extended periods. However, one challenge associated with PAM is the need for extensive manual labor to extract species information from large numbers of recordings. To address this issue, the authors propose using a convolutional neural network (CNN) to automate sound source identification. Despite the CNN's high performance and effectiveness, it requires a significant amount of training data. Therefore, the researchers employ a technique called data augmentation, which generates new training examples by applying various transformations to existing ones. In particular, they create mixed audio clips containing multiple target species calls and background noise, which are then converted into spectrograms for model training. These spectrograms serve as input images for the CNN, enabling it to learn features relevant to distinguishing between different sound sources. Overall, this research demonstrates how combining PAM with advanced machine learning techniques can improve our understanding of wildlife populations and ecosystem dynamics.