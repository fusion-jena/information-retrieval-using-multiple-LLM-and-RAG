The authors took several measures to ensure the generalizability of their deep learning model. They conducted experiments using different combinations of hand-annotations and pretraining data. These experiments included 'within-site', where they used pretraining and hand-annotated data to predict evaluation data from the same site; 'cross-site', where they used pretraining data and hand-annotations from one site to predict evaluation data from another site; and 'transfer-learning', where they tested a model trained using pretraining data from all other sites, but hand annotations from the same site as the evaluation data.

They found that the models had a high accuracy rate of around 80%, even when applied across different sites. This was significant given that the sites were chosen to be as diverse as possible, representing a wide range of tree canopy conditions. This underscored the flexibility of convolutional neural networks in learning deep features.

Furthermore, the authors suggested that as more sites are included, the universal model would continue to improve. They proposed combining pretraining from as many sites as possible, which could potentially lead to continent-scale pretraining. Since NEON sites are designed to represent all major biogeographic regions in the US, such broad-scale pretraining could reduce the need for new local training data by enabling the model to learn the general suite of features characterizing trees within the country.