To ensure the generalizability of their deep learning models, the authors employed various techniques such as stratified cross-validation and using diverse datasets. Specifically, they utilized stratiÔ¨Åed cross-validation with K = 10 folds, ensuring that every instance was used both for training and testing. Additionally, they performed experiments using subsets of best features from top-50% down to top-5% with a step of 5%, ultimately finding that the effectiveness maximized when using top-10% of features. They also mentioned that the dataset was not balanced, indicating that they likely took steps to address potential issues related to imbalance during model development. Overall, these methods helped improve the robustness and applicability of their models across different scenarios.