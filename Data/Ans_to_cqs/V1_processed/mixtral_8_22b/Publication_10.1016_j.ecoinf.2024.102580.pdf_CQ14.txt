The text does not provide explicit information about how the hyperparameters of the model were optimized. However, there is some indication that a form of manual tuning or trial-and-error approach may have been employed. For instance, the learning rate for the model backbone was set to 10, and the model underwent 300 training cycles with a batch size of two. Additionally, the DETR modelâ€™s object queries parameter was set to 100. These specific choices suggest that the authors might have experimented with different configurations before settling on these particular settings. Nevertheless, without further details, we cannot definitively state whether they used methods such as grid search or random search for hyperparameter optimization.