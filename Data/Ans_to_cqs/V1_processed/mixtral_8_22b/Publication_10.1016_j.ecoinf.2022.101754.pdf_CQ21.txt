After the model training process, several postprocessing steps can be performed depending on the specific requirements of the analysis. Some common postprocessing steps include:

1. Model Evaluation: The performance of the trained model needs to be evaluated using appropriate metrics such as accuracy, precision, recall, F1-score, ROC curve, etc. These metrics help assess how well the model has learned from the training data and its ability to generalize to unseen data. In the given context, the authors use various evaluation metrics like RMSE, R2, Diff\_R2, CV\_R2, ACT1, and ACT2 to evaluate their models.

2. Cross-Validation: To ensure that the model performs well on new, unseen data, it is essential to perform cross-validation. Cross-validation involves splitting the dataset into multiple folds or subsets and then training and testing the model on these subsets iteratively. This helps prevent overfitting and provides a more robust estimate of the model's performance. In the given context, the authors mention performing 100 different splits to the training-and-test sets, which suggests they might have employed some form of cross-validation.

3. Hyperparameter Tuning: After evaluating the initial model, one may need to fine-tune the hyperparameters to improve the model's performance further. Hyperparameters are parameters whose values are set before the training process begins. Common examples include learning rate, number of layers in a neural network, batch size, etc. In the given context, the authors mention tuning the hyperparameters on the training set for each split, indicating that they optimized the hyperparameters for better model performance.

4. Visualization Techniques: Postprocessing also includes visualizing the results obtained from the model. This could involve creating saliency maps, confusion matrices, or other types of plots to understand the model's behavior better. However, there is no explicit mention of any visualization techniques being applied in the given context.