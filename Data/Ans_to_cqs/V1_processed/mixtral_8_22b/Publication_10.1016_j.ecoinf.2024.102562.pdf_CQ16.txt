Based on the given information, there isn't any explicit mention of specific criteria used to determine when training is complete. However, we can infer some possible methods based on common practices in machine learning.

One common method is monitoring the validation loss during training. When the validation loss stops decreasing significantly or starts increasing, it might indicate overfitting, suggesting that the training should stop. This is often referred to as a 'validation loss plateau'.

Another approach could involve setting a fixed number of training iterations or epochs. Once the model has been trained for the specified number of iterations, the training would be considered complete.

Additionally, early stopping is another technique where training is halted if the validation error fails to decrease for a certain number of epochs. This helps prevent overfitting and saves computational resources.

In the case of this study, since no specific criteria are mentioned, it's likely that they used a combination of these techniques, such as training for a set number of epochs while also monitoring the validation loss to ensure it doesn't start increasing.