The literature does not provide explicit information regarding the optimization of hyperparameters for the models used in the mentioned studies. However, it can be inferred that various techniques such as Grid Search, Random Search, or Bayesian Optimization could have been employed for tuning the hyperparameters. These techniques involve defining a range of values for each hyperparameter and then searching through these combinations to find the best set of hyperparameters that minimize the error function. For instance, in the study by Gola et al. (2019), Support Vector Machines (SVMs) were utilized for objective microstructure classification. Although the paper does not explicitly mention the use of any specific technique for hyperparameter optimization, it is likely that one of the abovementioned methods was applied to tune the SVM parameters. Similarly, in other studies like those conducted by Albayrak et al. (2021) and Ayadi et al. (2022), where Decision Tree and Random Forest algorithms were used, hyperparameter optimization might have played a crucial role in achieving accurate results. Nevertheless, without further information, it cannot be confirmed which exact method was implemented for hyperparameter optimization in these studies.