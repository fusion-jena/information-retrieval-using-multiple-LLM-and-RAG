The dataset was divided into three parts for deep learning model training: training (60%), validation (20%), and testing (20%). This division was done in a stratified manner to maintain class proportions across all parts. The training set consisted of 2880 images, the validation set had 961 images, and the testing set contained 958 images. The models were trained on an NVIDIA 3090 GPU with a 256 x 256 image input size. The parameters such as learning rate, batch size, and number of epochs were set to 0.0001, 8, and 30, respectively after parameter tuning.

The criteria used to split the data were not explicitly mentioned but can be inferred from the given information. The dataset was divided into three parts - training, validation, and testing - which is a common practice in machine learning and deep learning projects. The purpose of splitting the data is to evaluate how well the model generalizes to new, unseen data. The training set is used to fit the model, the validation set is used to tune hyperparameters and prevent overfitting, and the testing set is used to provide an unbiased evaluation of the final model. In this case, the data was divided in a stratified manner, meaning that each subset maintained the same proportion of classes as the original dataset. This ensures that the model sees enough examples of each class during training and prevents any class imbalance issues.