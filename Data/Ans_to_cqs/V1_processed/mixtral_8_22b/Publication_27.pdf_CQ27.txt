The text does not provide explicit information about the process followed to deploy the trained deep learning model. However, based on common practices in machine learning and AI, we can infer some possible steps.

Model Serialization: After training a deep learning model, it is typically saved or serialized for later use. This involves converting the model into a format that can be stored and loaded efficiently. Common formats include.h5 for Keras models,.pth for PyTorch models, and.pb for TensorFlow models.

Platform Selection: Once the model is serialized, it needs to be deployed onto a platform where it can receive input data and generate predictions. The choice of platform depends on various factors such as the nature of the application, scalability requirements, latency constraints, etc. Some popular platforms for deploying deep learning models include cloud services like AWS Sagemaker, Google Cloud ML Engine, Azure Machine Learning Studio, and edge devices like NVIDIA Jetson boards.

However, without specific details from the given context, these are only educated guesses about what processes might have been followed to deploy the trained deep learning model.