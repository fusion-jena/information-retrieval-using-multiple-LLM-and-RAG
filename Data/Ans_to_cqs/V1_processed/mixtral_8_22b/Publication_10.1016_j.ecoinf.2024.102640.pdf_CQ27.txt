The text does not provide explicit information about the specific process followed to deploy the trained deep learning model. However, it mentions that the choice of using MiT-B1 as the encoder of GVI learning was made to facilitate model deployment on resource-constrained mobile devices. This suggests that the authors considered the constraints of their target platform during the development phase. Additionally, they mention training the model on a server with an NVIDIA GeForce GTX 3090 GPU, but there is no further detail regarding the actual deployment process or any specific platforms selected for this purpose. Therefore, while some aspects related to deployment considerations can be inferred from the given context, the exact steps taken to deploy the trained deep learning model remain unknown.