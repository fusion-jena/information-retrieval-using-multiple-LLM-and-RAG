The text does not provide explicit details about specific data annotation techniques such as bounding box annotation or instance segmentation. However, it mentions that manual annotations were performed on bioacoustic datasets, specifically focusing on animal vocalizations. In this case, the annotations contained a start and end time (denoted in seconds) for each vocalization. To generate fixed inputs for Convolutional Neural Networks (CNNs), a sliding window approach was employed. This involved placing a window at the start time of an annotation and extracting a segment of audio containing the amplitude values between the start time and start time plus a certain duration. Then, the window was moved by one second in time, and another segment was extracted. This process was repeated multiple times until the end of the sliding window exceeded the end time for that particular annotation. By repeating this procedure for each annotation, a dataset was created containing various audio segments for both the presence and absence classes.