The given text does not explicitly mention the criteria used to split the data for deep learning model training into train, test, and validation sets. However, it can be inferred that the data was divided based on a common practice in machine learning called stratified sampling. In this approach, the data is split such that each set maintains the same proportions of class labels or target variables as present in the original dataset.

From the given text, we learn that the dataset consisted of 300 data-filled rows collected from five different locations in Portugal. These rows contained composite numerical data related to bivalves. To create the training and testing datasets, stratified sampling was employed. Specifically, 80% of the data (240 data rows) was allocated for training the model, while the remaining 20% (60 data rows) was reserved for testing purposes.

Although the text does not provide explicit details about the validation set, typically, a portion of the training data is further separated into a validation set. This validation set helps tune hyperparameters and prevent overfitting during the training process. It should also be noted that the optimal ratio for splitting the data into training, validation, and testing sets may vary depending on factors like the size of the dataset, its complexity, and the nature of the problem being addressed.