Based on the given context, it appears that data pre-processing for the study was performed using software such as ViewSpecPro and The Unscrambler. However, the specific pre-processing steps involved before training a deep learning model, such as normalization, scaling, or cleaning, are not explicitly mentioned in the provided text.

In general, pre-processing steps can vary depending on the nature of the dataset and the requirements of the machine learning algorithm being used. Common pre-processing techniques include:

1. Normalization: This involves rescaling the features so they fall within a specific range, often between 0 and 1. This helps prevent features with larger scales from dominating the learning process.

2. Scaling: Similar to normalization, scaling involves adjusting the scale of features to ensure they have similar magnitudes. Techniques like Min-Max scaling and Standardization (Z-score normalization) are commonly used.

3. Cleaning: This step involves handling missing values, outliers, and errors in the dataset. Strategies may include removing or imputing missing values, capping or removing outliers, and correcting any inconsistencies in the data.

4. Feature Selection/Extraction: This step aims to reduce dimensionality by selecting relevant features or creating new ones through transformations. Methods like Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and others can be employed.