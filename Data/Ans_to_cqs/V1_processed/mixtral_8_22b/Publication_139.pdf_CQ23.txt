To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the model was validated using a diverse dataset consisting of six different days from various seasons throughout the year. Secondly, the authors employed k-fold cross-validation, specifically five-fold cross-validation, which involves dividing the dataset into k subsets and iteratively training the model on kâˆ’1 subsets while evaluating its performance on the remaining subset. This process helps reduce bias and variance in the model. Lastly, stratified sampling was applied when creating the training and validation datasets. Stratified sampling ensures that the distribution of labels remains consistent across the splits, preventing any class imbalance issues that could negatively impact the model's performance. These techniques collectively contribute to enhancing the model's ability to perform well on new, unseen data.