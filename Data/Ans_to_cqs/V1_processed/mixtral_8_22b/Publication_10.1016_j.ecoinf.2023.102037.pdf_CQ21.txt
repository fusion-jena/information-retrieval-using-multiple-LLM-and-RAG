The paper does not explicitly mention the specific postprocessing steps taken after model training. However, based on common practices in machine learning projects, some possible postprocessing steps could include:

1. Evaluation metrics: The authors discuss model performance in section 3.2, indicating they likely calculated evaluation metrics such as precision, recall, accuracy, and F1 score. These metrics help assess how well the model performs on unseen data.

2. Confusion matrix: Although not mentioned directly, confusion matrices can provide valuable insights into the types of errors made by the model. They show true positives, false positives, true negatives, and false negatives, allowing researchers to understand where the model struggles most.

3. Visualizations: To better understand the model's predictions, visualizing results is essential. For example, saliency maps highlight important features contributing to the model's decision-making process. While this technique isn't discussed in the paper, it may have been employed to gain further insight into the model's behavior.

4. Threshold tuning: Since the authors use a custom threshold for detecting objects, adjusting this value might improve overall performance. By analyzing the tradeoff between false positives and false negatives, one can find an optimal threshold that balances both aspects.

5. Ensemble methods: Combining multiple models can often lead to improved performance. Though not mentioned in the paper, ensembling techniques like bagging or boosting could potentially enhance the final prediction outcomes.