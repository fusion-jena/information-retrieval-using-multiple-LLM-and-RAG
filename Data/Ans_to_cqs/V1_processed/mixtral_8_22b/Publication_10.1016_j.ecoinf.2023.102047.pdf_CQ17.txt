In the given context, there is no explicit mention of regularization methods like dropout or L2 regularization being used to prevent overfitting in the deep learning pipeline. However, it does discuss another commonly used method to avoid overfitting and improve the model's generalization â€“ data augmentation. Data augmentation techniques such as random cropping, horizontal/vertical flipping, image rotation, image translation, zooming, brightness adjustment, contrast adjustment, hue and saturation adjustment, gaussian noise, and random erasing were applied during the training process. These techniques help increase the size and variability of the dataset, making the model more robust and less prone to overfitting. While not explicitly mentioned, other popular regularization methods like dropout and L2 regularization may also have been employed but are not discussed in this particular context.