The sources of raw data used in a deep learning pipeline can vary depending on the specific application or problem being addressed. Some common methods for collecting raw data include:

1. Surveys: Data collected through surveys can be used to train models for various applications such as sentiment analysis, customer segmentation, and recommendation systems.

2. Sensors: Sensor data can be used to monitor physical phenomena such as temperature, humidity, pressure, and motion. This type of data is often used in applications like predictive maintenance, anomaly detection, and object recognition.

3. Public Datasets: There are many publicly available datasets that can be used for training deep learning models. These datasets cover a wide range of topics including images, text, audio, and video. Examples of popular public datasets include ImageNet, MNIST, CIFAR-10, and the Stanford Question Answering Dataset (SQuAD).

4. Web Scraping: Web scraping involves extracting data from websites using automated tools. This method can be used to collect large amounts of data quickly and efficiently. However, it is important to ensure that web scraping activities comply with the terms of service of the target website.

5. APIs: Application programming interfaces (APIs) allow developers to access data from third-party services. For example, social media platforms like Twitter and Facebook provide APIs that enable developers to access user data such as tweets and posts.

6. IoT Devices: Internet of Things (IoT) devices generate vast amounts of data that can be used for training deep learning models. Examples of IoT devices include smart home appliances, wearable devices, and industrial equipment.

Overall, the choice of data collection method depends on the specific requirements of the deep learning project. It is essential to consider factors such as data quality, availability, cost, and privacy when selecting a suitable data source.