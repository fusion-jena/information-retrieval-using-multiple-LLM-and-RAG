The text does not provide information about the specific process used to deploy the trained deep learning model after its final training phase. However, common practices include model serialization, which involves saving the model parameters into a file format that can be loaded later for prediction tasks. Another practice is platform selection, where the chosen deployment environment could be cloud services like AWS, Azure, or Google Cloud, or local servers depending on the use case requirements. Without further details, we cannot determine the exact method used in this scenario.