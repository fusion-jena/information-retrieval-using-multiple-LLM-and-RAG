The strategy implemented to monitor the model performance during training involves several steps. Initially, 20 candidate models were created, each belonging to one of the four available deep-ANN architectures. These models were trained with a small subset of the training data (At) for four epochs. The accuracy of these candidate models was evaluated using a separate validation dataset (Av). The model with the highest performance was chosen for further training on the complete training dataset (Bt = At + Av) for up to 30 epochs. After full training, the optimal number of training epochs was determined based on the best performance achieved. This final model demonstrated excellent overall predictive performance, with a mean area under the curve (AUC) of 0.92 ± 0.05 standard deviation. However, there were some exceptions where the performance dropped slightly, such as for the 'increase >50%' class in 2013 and 2016, and the 'increase 25–50%' class in 2017. Additionally, variable importance analysis revealed that the 'number of eggs' predictor had the most significant impact on model performance, while slight decreases in performance were observed when temperature variables were randomized.