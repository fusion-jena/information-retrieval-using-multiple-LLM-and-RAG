Based on the provided information, there is no explicit mention of how the hyperparameters of the Random Forest (RF) model used in this study were optimized. However, common practices for optimizing hyperparameters include Grid Search, Random Search, Bayesian Optimization, or even manual tuning. Since the authors did not specify which optimization technique they employed, it would be best to assume that they followed standard practices for optimizing hyperparameters in machine learning models like the RF model.

It should also be noted that the RF model itself does not require extensive hyperparameter tuning compared to some other machine learning algorithms due to its robustness and ability to handle complex interactions among features. Nevertheless, some key parameters such as the number of trees (ntree), the number of variables randomly sampled as candidates at each split (mtry), and the minimum size of terminal nodes (nodesize) can still impact the performance of the RF model. Therefore, it is reasonable to infer that the authors might have adjusted these parameters during the modeling process to achieve optimal results.