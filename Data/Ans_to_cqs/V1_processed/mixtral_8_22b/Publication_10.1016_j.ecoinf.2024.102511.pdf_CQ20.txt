The provided context does not explicitly mention which specific hardware resources were used for training the deep learning models. However, it can be inferred from the general knowledge about deep learning that GPU (Graphics Processing Units) or TPU (Tensor Processing Units) are commonly used for training such models due to their ability to perform parallel computations efficiently. Therefore, without further information, one could assume that either GPUs or TPUs might have been utilized for training these deep learning models.