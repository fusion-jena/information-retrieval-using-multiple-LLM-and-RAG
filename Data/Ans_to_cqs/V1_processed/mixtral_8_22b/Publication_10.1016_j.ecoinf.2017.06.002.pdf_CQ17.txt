The given context does not provide information on the regularization methods used to prevent overfitting in the deep learning pipeline. Therefore, I cannot provide an accurate response based solely on the provided text. However, some commonly used regularization techniques include dropout, L1 regularization, and L2 regularization. Dropout randomly sets a fraction rate of input units to 0 during training time, helping reduce overfitting. L1 regularization adds an absolute value of the magnitude of coefficients as penalty term to the loss function, while L2 regularization adds the squared magnitude of coefficient as penalty term to the loss function. Both L1 and L2 regularizations help prevent overfitting by adding constraints to the optimization problem.