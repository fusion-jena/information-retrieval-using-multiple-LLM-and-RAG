To evaluate the performance of the deep learning models, several metrics are used. These include Overall Accuracy (OA), Kappa Coefficient, User's Accuracy (UA), Producer's Accuracy (PA), and F1-score. The OA is calculated as the percentage of correctly classified pixels out of all test pixels. The Kappa Coefficient measures the agreement between predicted and actual classes, taking into account chance agreements. UA is the proportion of correct predictions among all positive predictions made by the model, while PA is the proportion of correct predictions among all actual positives. The F1-score combines Precision (which is equivalent to UA) and Recall (equivalent to PA) into a single metric, providing a more balanced evaluation of the model's performance. In Table 2, the performance of the three deep learning algorithms (VGG16, ResNet50, and AlexNet) is evaluated based on these metrics. For instance, VGG16 has an OA of 73.25% and a Kappa coefficient of 69.76%, indicating good performance.