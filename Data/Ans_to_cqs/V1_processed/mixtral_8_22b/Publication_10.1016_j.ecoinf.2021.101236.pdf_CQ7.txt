The text does not provide explicit details about how the data was split into training, testing, and validation sets for the deep learning model. However, it can be inferred that the data was likely divided based on common practices in machine learning and deep learning. This usually involves splitting the dataset into three parts: training set, validation set, and test set. The training set is used to fit the model, the validation set is used to tune hyperparameters and prevent overfitting, and the test set is used to evaluate the final performance of the model. The specific proportions used for each set may vary depending on the size of the dataset and other factors, but a common practice is to use around 70% of the data for training, 20% for validation, and 10% for testing.