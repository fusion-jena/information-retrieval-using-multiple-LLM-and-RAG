Based on the given context, there isn't specific information about the exact preprocessing steps taken before training the deep learning model. However, some general preprocessing steps often applied when working with audio data include:

1. Converting raw audio files into a suitable format such as WAV or MP3.
2. Normalizing the audio signals to ensure consistent volume levels across all samples.
3. Scaling the amplitude of the audio signal to fit within a certain range, typically between -1 and 1.
4. Cleaning the audio data by removing any unwanted noise or artifacts.
5. Extracting relevant features from the audio data, such as Mel Frequency Cepstral Coefficients (MFCC), spectral features, or chroma features.

In this case, the authors mention constraining the size of their audio spectrograms to 128 x 128 pixel RGB images with repeated values in each color channel to create a grayscale image. This could indicate that they have performed some form of feature extraction and rescaling prior to feeding the data into the deep learning model. However, without further details, it is difficult to provide a more precise answer regarding the specific preprocessing steps involved.