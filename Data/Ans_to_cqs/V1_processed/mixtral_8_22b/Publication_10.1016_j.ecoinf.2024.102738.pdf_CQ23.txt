To ensure the generalizability of their deep learning model, several measures were implemented during the development process. Firstly, a diverse dataset was used, consisting of various combinations of spectral bands, vegetation indices, soil indices, water indices, and clusters. These datasets ranged from Dataset 1 to Dataset 31, covering different input combinations such as B + VI, B + SI, B + WI, B + C, VI + SI, VI + WI, VI + C, SI + WI, SI + C, WI + C, and B + VI + SI + WI + C.

Secondly, the authors followed recommendations by Chuvieco (2020) regarding sample sizes for categorical variables. They aimed for at least 196 test points and explored alternative sampling strategies using Google Earth Engine (GEE). To further enhance the diversity of the data, they included pure training areas containing at least 50 pixels per thematic class, which prominently represented the class of interest. This approach allowed capturing more variability within each class and improving overall performance.

Lastly, although not explicitly mentioned in the given context, it is common practice in machine learning to use techniques like cross-validation and stratified splitting to evaluate models and prevent overfitting. Cross-validation involves dividing the dataset into multiple subsets, where one subset serves as the testing set while the remaining ones are used for training. The process is repeated until all subsets have been tested once. On the other hand, stratified splitting ensures that the proportion of observations belonging to each class remains consistent across both the training and testing sets. Given these standard practices, it is likely that similar methods were employed to validate the deep learning model in this study. However, without explicit confirmation in the provided context, this assumption cannot be definitively confirmed.