The text does not provide explicit information about the specific optimization techniques applied in the deep learning pipeline. However, it mentions that backpropagation is used to update the model parameters in the generator component of the Generative Adversarial Network (GAN) model. This implies that some form of gradient descent optimization technique might have been employed during training. Commonly used optimization techniques in deep learning pipelines include Stochastic Gradient Descent (SGD), Momentum, Root Mean Square Propagation (RMSProp), and Adaptive Moment Estimation (Adam). These techniques help minimize the loss function by adjusting the weights and biases of the network iteratively. Without further details, we cannot confirm which specific optimization technique was utilized in this case.