Data augmentation techniques are used in deep learning pipelines to increase the amount of training data by applying random transformations to existing data. These techniques help prevent overfitting and improve the model's performance. Some commonly used data augmentation techniques in deep learning include:

1. Flipping: Images can be flipped horizontally or vertically to create new variations. This technique is often used when the orientation of objects in the image doesn't affect their meaning.

2. Rotation: Images can be rotated by a certain degree to generate new samples. This technique is useful when dealing with objects that may appear in different orientations.

3. Scaling: Images can be scaled up or down to simulate zooming in or out. This technique helps the model learn to recognize objects at different scales.

4. Translation: Images can be shifted along the horizontal or vertical axis to mimic movement. This technique helps the model understand object displacement.

5. Shearing: Images can be distorted by shearing, creating new perspectives. This technique is helpful when dealing with objects that might appear skewed due to camera angles.

6. Noise injection: Random noise can be added to images to make the model more robust against noisy inputs.

7. Color space transformation: Images can be transformed into different color spaces like grayscale, sepia, etc., to help the model focus on other aspects besides colors.

These data augmentation techniques can be combined and applied randomly during training to create diverse and varied datasets. However, it's important to note that some transformations might not always be suitable depending on the specific task and dataset.