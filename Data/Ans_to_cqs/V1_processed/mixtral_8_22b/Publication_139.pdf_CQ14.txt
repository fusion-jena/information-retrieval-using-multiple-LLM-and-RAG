The text does not provide explicit information about how the hyperparameters of the model were optimized. However, it mentions that the optimizer Adam was selected with an initial learning rate of (cid:0) 7. This suggests that some form of optimization process was employed, but the specific method (grid search, random search, etc.) is not mentioned. Additionally, early stopping was used to prevent overfitting, indicating that the performance of the model on a validation set was monitored during training.