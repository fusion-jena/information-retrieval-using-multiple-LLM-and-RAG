To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. One common technique is stratified splitting, which involves dividing the dataset into training and testing sets while maintaining the same proportion of each class or category within both sets. This ensures that the model is trained and tested on representative samples of all categories, preventing any one category from being overrepresented or underrepresented. Another technique is oversampling, where examples from minority classes are duplicated to balance out the dataset. Conversely, undersampling involves removing examples from majority classes to achieve a more balanced dataset. Additionally, diverse data collection methods can help mitigate data bias by ensuring that the dataset includes a wide range of examples representing different demographics, geographic locations, and other relevant factors. In this case study, stratified random sampling points were generated using QGISâ€™ ACatama plugin, and the number of points per class was increased by five-fold to account for bias associated with restricted inclusion probabilities that resulted from the pre-defined distribution of GMEP squares.