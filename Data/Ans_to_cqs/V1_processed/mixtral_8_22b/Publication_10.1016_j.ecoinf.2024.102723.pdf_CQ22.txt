The paper discusses several metrics used to evaluate the performance of the deep learning models. These include Mean Absolute Error (MAE), Symmetric Mean Absolute Percentage Error (SMAPE), and Normalized Mean Prediction Interval Width (NMPIW). MAE measures the average magnitude of errors in a set of predictions, without considering their direction. SMAPE provides a measure of the quality of prediction intervals in relation to the variability of the observed data. It is expressed as a percentage and lower values indicate more accurate and balanced predictions. NMPIW is another metric used to assess the quality of prediction intervals. Lower values of NMPIW reflect narrower prediction intervals relative to the observed data range. Additionally, the authors mention that the analysis made for Mean Squared Error (MSE) is still considered valid. However, traditional metrics like accuracy, precision, and recall are not explicitly mentioned in the given context.