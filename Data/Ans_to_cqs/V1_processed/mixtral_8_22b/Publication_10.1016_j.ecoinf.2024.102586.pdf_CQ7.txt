To split the data for deep learning model training, several criteria can be employed. Typically, the dataset is divided into three subsets: training set, validation set, and testing set.

1. Training Set: This subset is used to fit the model initially. It trains the model on what it should expect during the actual prediction process. Usually, around 70-80% of the total data is allocated for this purpose.

2. Validation Set: Also known as the development or holdout set, this subset is used to fine-tune the parameters of the model. During the training phase, the performance of the model is evaluated on this set after each epoch or iteration. This helps prevent overfitting and ensures that the model generalizes well to unseen data. Around 10-15% of the total data is typically reserved for this purpose.

3. Testing Set: After the model has been trained and validated, its final evaluation is performed on this subset. This provides an unbiased estimate of how well the model will perform when deployed in real-world scenarios. Approximately 10-20% of the total data is usually kept aside for this purpose.

These percentages may vary depending on the size of the dataset and specific requirements of the problem being addressed. Additionally, techniques like cross-validation can also be employed to further improve the robustness and reliability of the model.