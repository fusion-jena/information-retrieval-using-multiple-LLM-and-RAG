The given context does not provide explicit information on the specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on general practices in machine learning and deep learning pipelines, some common techniques for addressing data bias include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting is a technique where the dataset is divided into training and testing sets while maintaining the same distribution of classes or labels in both sets. This helps prevent any class imbalance from affecting the model's performance.

Oversampling involves duplicating examples from the underrepresented class or generating synthetic samples using methods like SMOTE (Synthetic Minority Over-sampling Technique). Undersampling, on the other hand, involves removing examples from the overrepresented class to balance the dataset. Both these techniques can help mitigate class imbalances in datasets.

Diverse data collection refers to collecting data from various sources, demographics, or environments to ensure that the dataset represents different scenarios and reduces potential biases introduced due to limited data diversity.

In summary, although the given context does not explicitly mention which techniques are used to address data bias during preprocessing of the deep learning pipeline, commonly employed techniques include stratified splitting, oversampling, undersampling, and diverse data collection.