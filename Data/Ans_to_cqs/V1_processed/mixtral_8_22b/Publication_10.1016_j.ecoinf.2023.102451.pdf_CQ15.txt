The optimization technique applied in the deep learning pipeline for the proposed model EMViT-Net is AdamW. This optimizer is used along with a learning rate of 0.002. Additionally, the batch size is set to 32, and the model is trained for 100 epochs. The activation function used in this pipeline is GELU, which is known for its effectiveness with the proposed model and the considered dataset. Lastly, the default loss function used to calculate the loss of the proposed network is cross-entropy.