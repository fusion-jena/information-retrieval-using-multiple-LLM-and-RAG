The context does not provide explicit information about the specific criteria used to split the data for deep learning model training into train, test, and validation sets. However, based on typical practices in machine learning, the data could have been randomly divided into three parts: training, testing, and validation datasets. Typically, around 60-80% of the total data is allocated for training, while the remaining data is equally distributed between testing and validation. The training dataset is used to fit the parameters of the model, the validation dataset helps tune hyperparameters and prevent overfitting, and the testing dataset evaluates the final model's performance.

In the given context, there are mentions of held-out test sets and retained test sets, suggesting that some form of splitting was performed. Additionally, the authors mention using a separate set of images obtained from internet search engines to augment their training dataset. They also discuss using a feedback mechanism involving human annotation to improve the classifier iteratively, indicating that they might have used a dynamic approach to updating their training and testing datasets.