The authors utilized transfer learning by initializing an ImageNet pre-trained ResNet34 model. They employed data augmentation techniques such as vertical flipping of images, limiting overexposure, and disabling zooming augmentation. These techniques helped improve the diversity of the dataset and prevent overfitting. Additionally, they used an 80-20% split for training and validation datasets, respectively, which can be considered a form of stratified splitting. This approach ensures that both the training and validation sets contain representative samples from the entire dataset, further enhancing the model's ability to generalize well to new, unseen data.