Based on the given context, the study primarily focuses on model training and development on a high-end computer and its subsequent deployment to an edge device. However, the text does not explicitly mention any specific techniques used to address data bias during preprocessing of the deep learning pipeline.

That being said, common techniques used to mitigate data bias include stratified splitting, which ensures that each subset of the data maintains the same proportions of target classes as the original dataset; oversampling, where samples from underrepresented classes are duplicated to balance the dataset; undersampling, where samples from overrepresented classes are removed to balance the dataset; and diverse data collection, which involves gathering more varied data to reduce bias.

In the context provided, the authors discuss pre-processing steps like denoising, contrast enhancement, and image resizing, but they ultimately chose to only perform image resizing to suit their chosen models' input requirements. They do not elaborate on how they handled potential biases within their dataset.

Therefore, based solely on the information presented, I cannot provide a definitive answer regarding what techniques were employed to address data bias during preprocessing in this particular study.