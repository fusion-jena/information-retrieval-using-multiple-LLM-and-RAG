Based on the given information, there are no explicit details about specific measures taken to ensure the generalizability of the deep learning models used in this study. However, it can be inferred that the researchers employed various techniques to improve the robustness and applicability of their models.

Firstly, they utilized multiple pre-trained models like BirdNET, VGGish, and Wav2Vec2. These models have been previously trained on diverse datasets, including YouTube audio data and human speech audio data. By employing these pre-trained models, the researchers could leverage the knowledge gained from extensive training on varied datasets, which contributes to the generalizability of the results.

Secondly, the researchers tested different feature extraction techniques, such as Mel Frequency Cepstral Coefficients (MFCCs), BirdNET embeddings, and others. Using various feature extraction methods allowed them to explore how well each method performs under different conditions, thereby enhancing the overall reliability and validity of their findings.

Lastly, the researchers conducted experiments across varying distances (up to 150 meters) between the recording device and the source of the sound. They also evaluated the performance of their models by calculating mean and 95% confidence intervals of classification accuracy and normalized mutual information (NMI) for each feature type. Performing analyses at different distances and assessing the statistical significance of their results helped establish the generalizability of their models.

In conclusion, while the text does not explicitly mention specific techniques like cross-validation or stratified splitting, the researchers did take several steps to ensure the generalizability of their deep learning models. These include utilizing pre-trained models, testing various feature extraction techniques, and conducting experiments across different distances.