Unfortunately, the provided context does not explicitly mention the specific hardware resources used for training the deep learning model. However, it does indicate that the growth of deep learning is due to the recent availability of powerful hardware. In general, deep learning models often require significant computational resources, and GPU or TPU accelerators are commonly used for training these models due to their ability to perform parallel operations efficiently. Therefore, while I cannot provide a definitive answer based solely on the given context, it is reasonable to infer that the deep learning model mentioned might have been trained using either GPUs or TPUs.