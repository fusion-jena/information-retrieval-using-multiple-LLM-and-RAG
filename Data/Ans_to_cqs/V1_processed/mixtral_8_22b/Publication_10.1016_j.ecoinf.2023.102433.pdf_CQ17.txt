Based on the provided context, it does not seem like there is any information regarding the specific regularization methods used to prevent overfitting in the deep learning pipeline. Regularization methods such as dropout or L2 regularization are techniques used during training to reduce overfitting by adding a penalty term to the loss function or randomly dropping out neurons from the network. However, without more specific details about the deep learning model being used, it is impossible to determine what regularization methods might be employed.