The deep learning pipeline employs the Adam variant of Stochastic Gradient Descent (SGD) as its optimization technique. This particular version of SGD, developed by Kingma and Ba in 2015, accelerates convergence by adaptively scaling the magnitude of parameter updates based on past update statistics. During the training process, the model's prediction error is frequently assessed using a separate validation dataset. The configuration yielding the least error is then selected as the final model.

In terms of implementation specifics, the models were built utilizing PyTorch. Five models were trained with a batch size of 64 and a base learning rate of 10^-4. The learning rate is programmed to decrease by a factor of 0.1 whenever there is no improvement in the validation loss over 15 successive epochs. Weight decay is used to manage the Gaussian prior's intensity, with a value of 10^-3 that is inversely related to the hyperparameter lambda from Equation (1). Hyperparameters for the Adam optimizer include beta1=0.9, beta2=0.999, and epsilon=10^-8. Training took place on a single Nvidia RTX2080Ti GPU for approximately 14 days per neural network.