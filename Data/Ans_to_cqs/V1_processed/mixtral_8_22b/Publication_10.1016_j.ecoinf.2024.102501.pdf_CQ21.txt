After the model training process, several postprocessing steps may be involved depending on the specific application and requirements. Some common postprocessing steps include:

1. Model Evaluation: This involves calculating various metrics like accuracy, precision, recall, F1 score, ROC AUC, etc., to evaluate the performance of the trained model. These metrics help in understanding how well the model has learned from the given dataset and its ability to generalize to unseen data.

2. Confusion Matrix: It is a table layout that allows visualizing the performance of an algorithm. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class. It provides detailed information about true positive, false positive, true negative, and false negative predictions made by the model.

3. Saliency Maps: They are visualizations of the parts of an image that are most responsible for the output of a convolutional neural network. They highlight the pixels or regions of interest in the input image that contributed significantly towards the final decision made by the model.

4. Hyperparameter Tuning: After evaluating the initial model, hyperparameters might need adjustment to improve the model's performance further. Techniques like Grid Search, Random Search, Bayesian Optimization, etc., can be employed for tuning hyperparameters.

5. Model Interpretability: Postprocessing steps might involve explaining the decisions made by the model using techniques like LIME, SHAP, etc. These methods provide insights into which features had the most impact on the model's predictions.

However, based on the provided context, there isn't any explicit mention of the postprocessing steps followed after the model training. Therefore, one cannot definitively state what postprocessing steps were taken in this particular case.