The criteria used to split the data for deep learning model training typically include the following:

* Train set: This dataset is used to train the model, allowing it to learn from the input data and adjust its internal parameters accordingly. It usually consists of around 60-80% of the total available data.

* Validation set: Also known as the development or holdout set, this subset of data is used during the training process to provide an unbiased evaluation of the model while tuning hyperparameters. It helps prevent overfitting and ensures that the model can generalize well to new, unseen data. The validation set often comprises about 10-20% of the total data.

* Test set: After the model has been trained and optimized, the test set is used to evaluate its performance on completely unseen data. This allows researchers to estimate how well their model will perform in real-world scenarios. Typically, the test set makes up approximately 10-20% of the total data.

These percentages may vary depending on the specific requirements and constraints of the problem being addressed. Additionally, other factors such as class imbalance, data quality, and computational resources might influence the choice of splitting criteria.