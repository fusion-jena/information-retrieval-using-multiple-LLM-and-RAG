Based on the given context, I am unable to provide a direct answer regarding the optimization techniques applied in the deep learning pipeline such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam). However, I can discuss the methods used in the context of analyzing tweets related to biodiversity observations.

In this study, the researchers utilized the 'Full-archive search endpoint' to access the entire dataset published on Twitter since its inception in 2006-2007 until the end of 2022. They employed the twarc2 library to manage the returned data in JSON format, which simplified handling the quota limits imposed by the Twitter API and the resulting pagination from a single query.

To extract relevant tweets, the researchers searched for specific keywords, hashtags, or combinations of both within the text of tweets. They identified three common ways users expressed finding something interesting: (i) asking who knows or if anyone knows about their findings, (ii) directly asking what they found, and (iii) stating that they found something. Different verb tenses and first-person singular or plural were also considered.

After acquiring the original tweets, a series of filters were applied to eliminate irrelevant content. First, tweets containing images in GIF format, often corresponding to memes, were removed. Next, tweets without geolocation metadata were discarded, as location information is crucial for understanding biodiversity observations. Lastly, tweets with URLs pointing to external websites were filtered out, as these links could potentially introduce noise into the analysis.

While the context does not explicitly mention optimization techniques used in deep learning pipelines, it provides valuable insights into the methods employed for analyzing tweets related to biodiversity observations.