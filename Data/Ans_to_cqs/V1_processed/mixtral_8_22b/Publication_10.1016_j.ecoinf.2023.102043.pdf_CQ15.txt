Based on the given context, no explicit mention of any optimization technique such as Stochastic Gradient Descent (SGD), Adam, or others is made in relation to the deep learning pipeline. However, it does state that the number of trees in Random Forest (RF) was optimized through a grid search within a specified set. This indicates that some form of hyperparameter tuning was performed, but it doesn't provide details about the optimization techniques used specifically for the deep learning model. Therefore, without additional context, I cannot definitively determine what optimization techniques were applied in the deep learning pipeline.