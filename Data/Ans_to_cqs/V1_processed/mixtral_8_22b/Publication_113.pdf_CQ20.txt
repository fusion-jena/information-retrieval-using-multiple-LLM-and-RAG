The given context does not provide specific details about the hardware resources used for training the deep learning model. However, based on common practices in deep learning, it is highly probable that either Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) were utilized due to their superior performance in handling large-scale computations required for training deep learning models. These specialized processors accelerate matrix operations, which form the backbone of deep learning algorithms, enabling faster training times and improved efficiency. Nonetheless, without explicit mention in the provided context, it cannot be definitively stated whether GPUs, TPUs, or other hardware resources were employed for training the deep learning model.