The provided context does not explicitly mention any criteria for determining when training is complete. However, it can be inferred that the model uses resampling techniques such as cross-validation to tune its parameters automatically. This suggests that the model might monitor performance metrics like validation loss during training and stop training when these metrics plateau or meet certain thresholds. Additionally, the text mentions the use of standard practices like splitting the dataset into training and testing sets (with 25% of samples being used for testing), which could imply that the model evaluates its performance on the test set after each epoch or iteration to decide whether to continue training.