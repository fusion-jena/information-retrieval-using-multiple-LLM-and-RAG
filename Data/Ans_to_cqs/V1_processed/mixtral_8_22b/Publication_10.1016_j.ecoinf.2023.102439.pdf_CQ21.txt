After the model training process, there are several postprocessing steps that can be taken to further analyze and understand the performance of the model. Some common postprocessing techniques include calculating evaluation metrics, creating saliency maps, and generating confusion matrices.

In the given context, it is mentioned that several statistical metrics such as Mean Absolute Percent Error (MAPE), Mean Square Error (MSE), Root Mean Square Error (RMSE), and correlation coefficient (R) were employed to evaluate the performance of the model. These metrics help in understanding how well the model has learned from the training data and its ability to generalize on new data.

Additionally, the context also mentions that the model was tested and validated using data from 2016 to 2018. It would be reasonable to assume that during this phase, similar evaluation metrics would have been calculated to assess the model's performance on unseen data.

However, the context does not explicitly mention any other postprocessing techniques such as saliency maps or confusion matrices. Saliency maps are often used to visualize which parts of the input data had the most significant impact on the model's prediction. On the other hand, confusion matrices are useful for evaluating classification problems where they show the relationship between true labels and predicted labels. Since the context only discusses regression tasks, it might not be relevant to use these techniques here.

Therefore, based on the information available in the context, we can conclude that the primary postprocessing step involved after the model training was the calculation of evaluation metrics to measure the model's performance.