The papers mentioned do not provide specific details about the deployment process of their trained deep learning models. Therefore, it is not possible to determine the exact method used for each paper. However, common methods for deploying trained deep learning models include model serialization, platform selection, and containerization. Model serialization involves saving the trained model parameters into a file or database, which can then be loaded and used for predictions. Platform selection refers to choosing a suitable environment for running the deployed model, such as a server, cloud service, or edge device. Containerization involves packaging the entire application, including its dependencies and runtime environment, into a single executable unit called a container. This allows the application to run consistently across different platforms and environments. Without more information from the authors, it is impossible to determine which of these methods were used for deploying their trained deep learning models.