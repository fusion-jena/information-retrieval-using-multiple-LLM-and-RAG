The provided context does not directly address the query about handling randomness in the deep learning pipeline. However, based on general knowledge, some common strategies used to manage randomness in deep learning include setting fixed seeds for reproducibility, using techniques like cross-validation or bootstrapping to reduce variability, and employing ensemble methods to combine multiple models trained with different initializations. These strategies help mitigate the impact of random factors, such as the choice of initial weights or the order of training examples, on model performance and results interpretation.

Based on the given context, it can be inferred that the authors have utilized deep learning techniques in their studies related to ecosystem services, land degradation, deforestation, and soil degradation. However, there is no explicit mention of how they handled randomness within their deep learning pipelines. Therefore, I cannot provide specific details regarding this topic based solely on the provided information.