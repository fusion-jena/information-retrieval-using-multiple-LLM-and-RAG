The paper does not provide information about handling randomness in the deep learning pipeline, such as managing random seed values. However, it discusses a two-step "embedded" covariate selection procedure aimed at improving predictive abilities and parsimony of species distribution models. This process involves combining a collinearity-filtering algorithm (Step A) with three model-specific embedded regularization techniques (Step B): generalized linear model with elastic net regularization, generalized additive model with null-space penalization, and guided regularized random forest. These methods help manage high-dimensional candidate covariate spaces and improve model performance.

Regarding randomness management in deep learning pipelines, common practices include setting fixed random seeds for reproducibility, employing cross-validation techniques, and utilizing ensemble methods like bagging and boosting to reduce variance and improve prediction accuracy. However, these strategies are not explicitly mentioned in the provided context.