The given context does not provide explicit information about the specific criteria used to determine when training is complete. However, it mentions that the value of lambda (λ), which is a hyperparameter used to adjust the balance relationship between the nonlinear factors of the activation function and the identity mapping of A'(x), depends on the current number of rounds of training (e) and the total number of rounds of model training (E). As the training progresses, e approaches E, causing λ to approach 1, and A'(x) to approach x. This suggests that the completion of training might be determined by reaching a certain number of training rounds or epochs. Additionally, the context discusses the use of dropout technology to prevent overfitting and improve the generalization ability of the model, indicating that monitoring the model's performance during training could also play a role in determining when training should be stopped. Nevertheless, without further details, we cannot definitively state what specific criteria are used to determine when training is complete.