The learning process was stopped after 90 epochs, where the learning curve converged and loss values no longer decreased. This indicates that the model had learned enough about the patterns in the data and any additional training would likely result in overfitting or diminishing returns. The figure illustrating the improvement in loss and accuracy during the training process shows that the validation accuracy exceeds training accuracy due to the application of dropout and data augmentation on the training data only. This means that the training set contained more difficult tiles than the validation set, but it also suggests that the model was able to generalize well to new data. The best model was selected based on the two parameters accuracy and loss, with loss serving as a measure of how far model predictions differ from the actual class. The final model achieved a maximum accuracy of 96.4% on the validation set and 96.7% on a separate test dataset containing individual tiles not used during the model selection process. These high accuracies suggest that the model was effective at predicting the correct classes for new data.