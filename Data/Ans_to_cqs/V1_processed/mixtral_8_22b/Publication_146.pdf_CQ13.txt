The deep learning model used in this study employed the Adam learning rate optimizer due to its effectiveness on smaller datasets. The specific hyperparameters used were a learning rate of 0.001, a momentum of 0.9, and a weight decay of 0.0005. These values were kept consistent with the default parameters of the YOLOv3 model. The model was trained for a total of 350 epochs, with a batch size of 4.