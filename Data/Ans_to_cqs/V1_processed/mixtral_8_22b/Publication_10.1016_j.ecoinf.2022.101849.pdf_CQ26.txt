The text does not provide information on specific techniques used to address data bias during preprocessing of the deep learning pipeline, such as stratified splitting, oversampling, undersampling, or diverse data collection. Instead, it discusses three methods for creating artificial incompleteness in datasets: random reduction, random reduction with some targets reduced to zero, and non-random (biased) reduction. These methods are used to simulate various forms of label scarcity and noise found in real-world predictive tasks. After applying these methods, the authors evaluate the performance of their partial imputation algorithm using Mean Absolute Error (MAE) compared to baseline approaches.

However, based on general knowledge about addressing data bias, one could mention that stratified splitting involves dividing the dataset into subsets while maintaining the original class proportions. Oversampling increases the number of instances in minority classes, while undersampling reduces the number of instances in majority classes. Diverse data collection aims to gather data from multiple sources to ensure representation across all relevant categories.