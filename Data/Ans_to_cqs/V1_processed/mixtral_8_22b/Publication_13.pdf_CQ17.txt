The text does not provide explicit information about the use of specific regularization methods such as dropout or L2 regularization. However, it mentions that the number of units in the fully connected (FC) layers and the dropout rate were determined by five-fold cross-validation. This suggests that some form of regularization was applied to prevent overfitting, but the exact method is not specified. Additionally, the use of a fixed learning rate could also be considered a form of regularization, as it helps to stabilize the optimization process and prevent overfitting.