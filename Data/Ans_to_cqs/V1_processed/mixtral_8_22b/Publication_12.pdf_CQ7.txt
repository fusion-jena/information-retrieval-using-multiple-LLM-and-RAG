In this study, the authors used a total of 130,858 images for their deep learning model training. They divided this dataset into two parts: a training dataset containing 85% of the images (111,244 images) and a validation dataset containing 15% of the images (19,614 images). This division was done using a Python script named Making\_dataset.py within their software Waveman.

To maintain a balanced representation of all species in the dataset, the authors imposed an upper limit on the number of images per species if it had too many images. Additionally, they developed a method to augment the number of images for rare species by rescaling signals exponentially and shifting the window around the calls to alter the background noise. These steps ensured that rare species would not be underrepresented compared to more common ones.

The learning rate for most networks was set to 1e-3, except for one network (ResNet\_v2) where it was set to 1e-5. Each model was trained using the training dataset for 50-60 iterations on a GPU (Nvidia 1080ti) for approximately 2 hours and 10 minutes. After training, the resulting models contained refined parameters and graphs, which were then saved for subsequent analyses.

For testing purposes, the authors used the validation dataset, which consisted of 19,614 images. They employed this dataset to evaluate various models and assess potential taxonomic biases. Furthermore, they gathered additional audio files featuring 15 species from a corridor to investigate ways to minimize misidentifications and false positives. Lastly, they optimized the BatNet and tested its generalizability by collecting audio recordings of the same species under diverse environmental conditions.