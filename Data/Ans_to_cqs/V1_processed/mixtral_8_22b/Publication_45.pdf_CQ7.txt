The data is typically split into three parts for deep learning model training: training data, test data, and sometimes validation data. The training data is used to fit the model, while the test data is used to evaluate its performance. Validation data can be used during the training process to fine-tune hyperparameters or prevent overfitting.

The criteria used to split the data depend on various factors, including the total amount of data available, class distribution, and the complexity of the task. A common approach is to use a random stratified split, where the proportions of each class are preserved across all subsets. This ensures that the model sees a representative sample of the entire dataset during both training and testing.

For example, if there are two classes in the dataset, one might choose to allocate 80% of the data for training, 10% for validation, and 10% for testing. However, these percentages may vary depending on the specific requirements and constraints of the project. In some cases, it may be necessary to adjust the splits based on the results obtained from initial experiments.