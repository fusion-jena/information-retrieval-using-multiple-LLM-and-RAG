The text does not provide explicit information about handling randomness in the deep learning pipeline, such as managing random seed values. However, there is a mention of a strategy that could potentially address some aspects of randomness. In section 2.1, it discusses combining predictions from an ensemble of architecturally similar or identical Convolutional Neural Networks (CNNs). By using the same training data but altering the training process slightly—for example, by shuffling the sequence of data or using different batch sizes—this method aims to improve the reliability of predictions. Although this technique doesn't directly manage random seeds, it introduces controlled variability into the model training process, which might help mitigate the impact of randomness inherent in deep learning pipelines.