Based on the given context, there isn't explicit information about how the data was split into training, testing, and validation sets for the deep learning models. However, it can be inferred from common practices in machine learning that the authors likely followed similar procedures. Typically, the data is randomly divided into three subsets: training set, validation set, and test set. The training set is used to fit the model, while the validation set is employed to tune hyperparameters and prevent overfitting. Lastly, the test set is utilized to evaluate the final performance of the trained model.

In the case of the Google Search Image dataset, the authors selected 3680 labels with more than 12 images in their training dataset. They then automatically retrieved the first 10 images returned by the Google Image Search engine for each label. This suggests that they may have used a stratified sampling approach based on labels to ensure a balanced representation of classes in the training set. However, without further details, it cannot be confirmed if this was indeed the case or if any specific splitting ratios were applied.

For the Portuguese Flora dataset, the authors chose 15K images belonging to one of the 1300 species also present in their training dataset. Again, no explicit mention of the splitting strategy is made, but it can be assumed that the remaining images were used for validation and testing purposes.

Overall, while the exact criteria used to split the data for deep learning model training are not explicitly stated in the provided context, it can be reasonably inferred that the authors followed commonly accepted practices in machine learning, such as random division or stratified sampling based on labels.