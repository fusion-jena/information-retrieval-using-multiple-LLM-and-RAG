The deep learning model utilized a small grid search to select specific hyperparameters and their corresponding values. These included:

1. Hidden Activation Function: Three options were considered - ReLU, sigmoid, and elu.
2. Optimizer: Two choices were available - RMSprop and Adam.
3. Learning Rate: Four possible values were tested - 0.1, 0.001, 0.0001, and 0.00001.

After evaluating the models, the following hyperparameters were selected: Rectified Linear Unit (ReLU) activation function, RMSprop optimizer, and a learning rate of 0.001.