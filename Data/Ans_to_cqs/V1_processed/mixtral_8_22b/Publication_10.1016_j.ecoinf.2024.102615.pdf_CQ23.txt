To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the raw dataset was randomly shuffled before being divided into training, validation, and test sets. This step helps prevent any potential bias or pattern in the original order of the data that could affect the model's ability to generalize well on unseen data. Secondly, the data partitioning ratio between the training, validation, and test sets was set as 8:1:1. This distribution allows for a larger portion of the data to be used for training the model, while still reserving enough data for validation and testing purposes. Thirdly, the random partition was repeated ten times to reduce the influence of random splitting while ensuring converged performance. This repetition ensures that the results are not due to chance but rather represent the true performance of the model. Lastly, the grid search method was used to optimize five of the MLP modelâ€™s hyperparameters. By systematically searching through a defined set of possible parameter values, the grid search method can help find the best combination of hyperparameters that result in the highest accuracy and generalizability of the model. These measures collectively contribute to improving the robustness and reliability of the deep learning model.