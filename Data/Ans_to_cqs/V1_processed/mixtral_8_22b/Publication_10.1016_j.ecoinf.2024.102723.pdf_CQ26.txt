In the given context, there is no direct mention of techniques used to address data bias during preprocessing of the deep learning pipeline. However, some commonly used techniques include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into subsets based on certain characteristics, ensuring that each subset has roughly the same proportion of classes as the original dataset. This helps maintain the balance between classes when creating training and testing datasets.

Oversampling and undersampling are techniques used to handle imbalanced datasets. Oversampling increases the number of instances in the minority class, while undersampling reduces the number of instances in the majority class. These methods help achieve better class representation and improve the performance of machine learning models.

Diverse data collection focuses on gathering data from various sources and environments to ensure that the dataset represents real-world scenarios accurately. This technique aims to reduce biases introduced due to limited data sources or homogeneous data.

While these techniques are not explicitly mentioned in the given context, they are widely used in addressing data bias during preprocessing of the deep learning pipeline.