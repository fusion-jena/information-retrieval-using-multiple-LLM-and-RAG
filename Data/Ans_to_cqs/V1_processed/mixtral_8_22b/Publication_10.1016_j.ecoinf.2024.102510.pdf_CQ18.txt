The strategy implemented to monitor the model performance during training involves initializing an empty set called Smanual to store hyperparameter configurations. Then, for each hyperparameter configuration in M, a model is trained with those hyperparameters on dataset D. The model's performance is then evaluated on dataset D to obtain a performance metric. If this configuration yields the highest performance so far, it is added to Smanual. Next, another empty set called Srandom is initialized to store hyperparameter configurations. Each hyperparameter configuration in Smanual is used to sample a random subset of hyperparameters and create a new configuration called hrandom. A model is then trained with these new hyperparameters on dataset D, and its performance is evaluated again. If hrandom yields the highest performance so far, it is added to Srandom. Finally, Sbest is initialized as the best hyperparameter configuration from Srandom based on search tests that vary combinations of the hyperparameters identified in manual search and train the selected models to maximize accuracy through multiple iterations.