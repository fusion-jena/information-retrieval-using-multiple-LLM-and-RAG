The text does not provide explicit information about the criteria used to determine when training is complete. However, based on common practices in machine learning, some possible criteria include reaching a predefined number of epochs or iterations, achieving a desired level of performance on the validation set (such as a minimum accuracy or maximum validation loss), or observing no significant improvement in validation metrics after several consecutive epochs (also known as early stopping). In this case, since the authors mention using ADAM optimizer with a learning rate of 1e-3 and feeding the model with 16 elements per mini-batch, they might have chosen one of these criteria to decide when to stop training their models.