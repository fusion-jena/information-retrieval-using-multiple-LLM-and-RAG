The text does not provide information about the specific type of hardware resources used for training a deep learning model. However, it mentions that all calculations were carried out using the DAFNE HPC scientific computing center of the Universit√† degli Studi della Tuscia. The system provides for two Hewlett Packard Enterprise (HPE) ProLiant DL560 Gen10 nodes, each one equipped with four processors Intel Xeon Gold 5118 2.30GHz, 12 cores, 24 threads, and 512 GB of RAM. These nodes worked in a parallel configuration managed by the Python 3.6.8 package Ray, version 1.9.2. Therefore, it can be inferred that the computations were performed using CPUs rather than GPUs or TPUs.