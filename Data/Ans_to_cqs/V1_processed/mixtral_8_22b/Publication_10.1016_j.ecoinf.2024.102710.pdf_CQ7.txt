Based on the given context, it appears that the authors have used various approaches to split the data for deep learning model training. However, specific details regarding the exact criteria used to split the data into train, test, and validation sets are not explicitly mentioned. Nevertheless, some general practices commonly employed in machine learning and deep learning applications include splitting the dataset into three parts: training, testing, and validation sets. Typically, the training set is used to fit the model parameters, while the validation set helps tune hyperparameters and prevent overfitting during the training phase. Lastly, the test set evaluates the final model's performance after completing the training and tuning processes.

Regarding the percentage distribution of these splits, it varies depending on factors like the total amount of data available, its quality, and the complexity of the problem being addressed. A common practice is to allocate around 60-80% of the data for training, 10-20% for validation, and the remaining 10-20% for testing. However, without explicit information about the specific criteria used in this case, it is difficult to provide a precise answer.