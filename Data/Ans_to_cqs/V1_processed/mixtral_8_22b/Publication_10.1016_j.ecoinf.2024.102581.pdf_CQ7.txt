The criteria used to split the data for deep learning model training typically include a training set, a validation set, and a testing set. The training set is used to fit the model, while the validation set is used to tune the parameters of the model. The testing set is then used to evaluate the performance of the final model. In this case, the authors use a combination of cross-validation and holdout methods to split their data into these sets. Cross-validation involves splitting the data into k subsets or folds, where one fold is held out as the validation set and the remaining folds are used as the training set. This process is repeated k times, such that each fold serves as the validation set once. Holdout method, on the other hand, involves randomly selecting a portion of the data as the training set and another portion as the validation set. The remaining data is then used as the testing set. The choice of which method to use depends on various factors such as the amount of available data, computational resources, and the specific requirements of the problem being solved.