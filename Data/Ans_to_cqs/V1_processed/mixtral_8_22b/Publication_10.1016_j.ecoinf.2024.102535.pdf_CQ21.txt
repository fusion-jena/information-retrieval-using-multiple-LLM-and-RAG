Based on the given information, it is not explicitly stated what postprocessing steps were taken after the model training. However, there are some clues that can help infer possible postprocessing steps.

Firstly, the performance metrics section suggests that the authors calculated various metrics to evaluate their models. These metrics could include accuracy, precision, recall, F1 score, or any other relevant metric depending on the problem domain. Therefore, one postprocessing step would be calculating these performance metrics using the test datasets.

Secondly, the table containing the results shows average scores from three executions of each network. This implies that the authors ran multiple trials of each model and then took the average of the results. This process could involve creating confusion matrices for each trial and then aggregating them to calculate overall performance metrics.

Lastly, while not directly related to postprocessing, the mention of saliency maps in the paper's title suggests that they may have been used to visualize the features learned by the models. Saliency maps highlight the regions of input images that contribute most significantly to the final prediction made by the model. They can provide insights into how well the model has learned to focus on important features and can also aid in debugging if the model is making incorrect predictions.

In summary, although the exact postprocessing steps are not specified, it can be inferred that the authors likely calculated performance metrics, created confusion matrices, and possibly generated saliency maps to evaluate and interpret their models.