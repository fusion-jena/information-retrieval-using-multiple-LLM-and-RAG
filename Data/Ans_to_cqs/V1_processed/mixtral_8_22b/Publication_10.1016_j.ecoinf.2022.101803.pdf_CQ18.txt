The strategy implemented to monitor the model performance during training involves using k-fold cross-validation. Specifically, the dataset is divided into k subsets or 'folds'. Then, for each iteration of the optimization algorithm, one fold is held back as a validation set while the remaining k-1 folds are used as the training set. The model is trained using the training set and its performance is evaluated using the validation set. This process is repeated for each fold, resulting in k-1 out-of-sample R^2 values for each number of iterations. The median of these values is calculated to pick the best number of iterations. This process is outlined in Algorithm 1 and described in detail in the text.