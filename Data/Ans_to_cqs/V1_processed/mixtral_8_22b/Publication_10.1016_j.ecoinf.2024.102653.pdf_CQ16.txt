Based on the given information, it appears that the authors have not explicitly mentioned the specific criteria they use to determine when training is complete. However, we can infer from their description of the model validation process that they might have used certain common practices to decide when to stop training.

One possible criterion could be monitoring the validation loss during training. When the validation loss stops decreasing or starts increasing, it may suggest that the model is overfitting the training data and further training would not improve its generalization ability. In other words, reaching a validation loss plateau could signal that training should be stopped.

Additionally, the authors mention that they train their recurrent neural network model for a fixed number of epochs (i.e., full passes through the entire training set), which is another commonly used stopping criterion. They specify that they train their model for 100 epochs, but do not provide any details about how they arrived at this particular value. It is likely that they chose this number based on empirical observations or prior knowledge about similar problems.

Finally, the authors also report using early stopping, which involves halting the training process if the model's performance on the validation set does not improve after a certain number of consecutive epochs. Although they do not explicitly state whether they employ early stopping, it is a widely adopted technique in machine learning and could potentially explain why they choose to limit their training to 100 epochs.

To summarize, while the authors do not directly address the query regarding the criteria used to determine when training is complete, we can surmise that they might rely on observing the validation loss plateau, setting a predetermined number of epochs, and possibly implementing early stopping to make this decision.