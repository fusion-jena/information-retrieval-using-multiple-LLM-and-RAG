The hyperparameters of the model are optimized using the grid search method. This method involves specifying a set of possible values for each hyperparameter and then testing every combination of these values to find the best set of function parameters. For example, in this study, the Random Forest algorithm uses'mtry' as its main hyperparameter, which controls the number of input variables for decision trees. The Support Vector Machine algorithm uses 'gamma' and 'C', where 'gamma' determines how much influence the training data has, and 'C' balances the tradeoff between minimizing misclassification and maximizing margin width. Lastly, the Multivariate Adaptive Regression Splines algorithm uses 'degree' and 'nprune'. The 'degree' parameter defines the maximum degree of interaction between input variables, and 'nprune' controls the complexity of the final model.