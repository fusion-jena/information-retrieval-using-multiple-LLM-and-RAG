The performance of the deep learning model is evaluated using several metrics. These include the average unweighted and category-weighted training classification accuracies, which were found to be 98.9% and 97.4%, respectively. For the test data, the average unweighted and weighted accuracies are 94.7% and 88.8%. The F1-scores for the training and testing datasets are.980 and.907, respectively. Lower testing accuracy scores are observed in certain categories due to factors such as faint sounds occurring in other categories or class ambiguities. Smaller classes with fewer training examples may also have lower scores.

Additionally, the area under the curve, calculated using a Riemann sum, is employed for training purposes. After each epoch, the training and validation loss/accuracy are compared using 10% of the data from each fold. Another 10% of the data is reserved for performance testing once training has concluded. All reported results are averages obtained through five-fold cross-validation.

For validating the model, the network performance is assessed based on its ability to correctly predict multiple labeled classes. The average classification accuracy across all six validation days is 84.9%, with the lowest and highest reported accuracies being 81.7% and 88.6%, respectively. Recall scores are also considered when evaluating the model's performance.