The given context does not provide any specific details about the hardware resources used for training the deep learning models mentioned in the text. Therefore, it cannot be definitively stated which hardware resources were used for training the deep learning models. However, typically, deep learning models require significant computational power and memory, making them well suited for parallel processing architectures such as Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs). These specialized hardware accelerators can significantly reduce the time required for training large-scale deep learning models compared to traditional Central Processing Units (CPUs).