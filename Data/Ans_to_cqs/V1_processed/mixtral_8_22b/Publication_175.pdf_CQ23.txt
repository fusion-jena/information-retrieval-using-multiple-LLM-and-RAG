To ensure the generalizability of their deep learning model, several measures were taken by the authors. Firstly, they used diverse datasets for training and testing purposes. They utilized two main datasets, namely AT0 and AT1, where AT0 was significantly larger than AT1. This allowed them to evaluate the performance of the model under different data availability scenarios. Additionally, they created smaller subsets from the original dataset by randomly selecting 250 or 500 images per class, further demonstrating the robustness of the model across various dataset sizes.

Moreover, the authors employed stratified sampling techniques while creating these subsets. Stratified sampling ensures that each subset maintains the same distribution of classes as the original dataset, which is crucial for maintaining the representativeness of the sample population. By using stratified sampling, the authors ensured that the model would be exposed to a balanced representation of all classes during training, thus improving its ability to generalize well to unseen data.

Furthermore, the authors conducted multiple experiments using different architectures and hyperparameters. In one such experiment, they trained a classic deep learning algorithm architecture with the largest dataset, AT0, serving as a baseline for evaluating the accuracy of the deep learning models. Subsequently, they maintained the same architecture and hyperparameters but trained it on a much more limited dataset, AT1. This approach helped assess how well the model could adapt to varying amounts of available data without compromising its overall performance.

Lastly, the authors evaluated the performance of their deep learning model using a separate test dataset, T2. This step is essential for validating the model's ability to generalize to previously unseen data accurately. Overall, these measures collectively contributed towards ensuring the generalizability of the deep learning model developed by the authors.