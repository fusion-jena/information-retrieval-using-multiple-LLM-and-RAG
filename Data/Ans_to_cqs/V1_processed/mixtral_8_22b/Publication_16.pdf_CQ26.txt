Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it does discuss some aspects of data preprocessing and the overall methodology employed in the study.

The context mentions that the acquired audio files are segmented into 15-second windows, which could be considered a form of data partitioning but not directly related to addressing data bias. Each of these sample windows is then passed to a feature extraction function where Mel Frequency Cepstral Coefficients (MFCC) are used to extract features for the classifier. While this process doesn't explicitly tackle data bias, it contributes to preparing the data for further processing.

Moreover, the context outlines the configuration of the Multilayer Perceptron (MLP), including the use of backpropagation as the learning algorithm and Adam as the optimizer. It also mentions employing a dropout value of 50% in the first three layers to enhance generalization and mitigate overfitting. Although this technique helps prevent overfitting, it doesn't specifically target data bias.

Lastly, the context explains how the performance of the trained model is evaluated using sensitivity, specificity, precision, and accuracy. These metrics provide insights into the model's ability to accurately predict bird species based on the input audio data. Nonetheless, they do not indicate any direct measures taken to counteract potential biases within the dataset.

Therefore, based on the provided context, I cannot definitively state what techniques were used to address data bias during preprocessing of the deep learning pipeline.