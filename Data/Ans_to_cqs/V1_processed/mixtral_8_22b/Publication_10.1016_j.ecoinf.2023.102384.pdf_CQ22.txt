The evaluation of the deep learning model is performed using counting metrics. Specifically, the mean absolute error (MAE), mean squared error (MSE), and mean absolute relative error (MARE) are utilized as standard counting benchmarks. MAE measures the average magnitude of errors without considering their direction, MSE quantifies the average squared differences between predicted and actual observations, and MARE calculates the average of the absolute difference between predicted and actual values divided by the actual value. These metrics are applied to a non-publicly available dataset to assess the counting performance of the proposed approaches.