Based on the given context, the data was split into two subsets for training and testing purposes. For the first round of training, a subset of 498 images was used for training the model on a single GPU for 9000 iterations. Afterward, the performance of the model was evaluated using a separate test subset containing 155 images, also performed on a single GPU. In the second round of training, all 653 annotated images were utilized to train the model on three GPUs for 18000 iterations. However, the specific criteria used to divide the data into these subsets are not explicitly mentioned in the provided context. Typically, when splitting data for deep learning models, one might consider factors like ensuring a balanced distribution of classes across both sets, maintaining a certain ratio between the sizes of the training and test sets, and avoiding any overlap between the samples used for training and testing.