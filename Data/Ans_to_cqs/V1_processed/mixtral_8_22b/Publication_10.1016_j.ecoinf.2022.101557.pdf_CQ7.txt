The data is first split up into several larger blocks based on their coordinates to enable cross-validation of the model. These blocks are then divided into smaller areas of 80 x 80 pixels due to limitations in computational resources. For the 10-fold cross-validation, a 3x3 grid is placed over the map, resulting in ten sets. Nine of these sets are used for training, while the tenth set is used for evaluation. To ensure the model does not overfit, 20% of the training samples are reserved as a validation set. Additionally, dropout regularization is employed during training to improve stability. The model is trained for 150 epochs with a batch size of 128, and the ADAM optimization algorithm is utilized with a learning rate of 0.0001 to minimize the cross-entropy loss between the network's predictions and the labeled data.