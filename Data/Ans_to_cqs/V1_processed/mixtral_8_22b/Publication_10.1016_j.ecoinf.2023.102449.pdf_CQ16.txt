Based on the given context, it appears that the Variational Autoencoder (VAE) was trained under variational inference to reconstruct mini-batches of 6 spectrograms over a maximum of 100,000 batches. However, there is no explicit mention of specific criteria used to determine when training is complete, such as reaching a validation loss plateau or achieving a certain accuracy threshold. Instead, the focus seems to be on maximizing reconstruction quality without overfitting, which was achieved by tweaking the learning rate to an optimal configuration and employing stochastic gradient descent with the Adam optimizer. Additionally, weight decay was utilized, and the learning rate underwent annealing by a factor of 100 using a cosine function over the duration of the training. Therefore, based solely on the provided information, it cannot be definitively stated what criteria are used to determine when training is complete.