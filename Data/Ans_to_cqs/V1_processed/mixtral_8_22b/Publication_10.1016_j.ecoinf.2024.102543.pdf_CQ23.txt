To ensure the generalizability of the deep learning model, several measures were implemented during the development process. Firstly, a diverse dataset was curated, containing 4000 images in the training set, which allowed the model to learn from various examples and patterns. Secondly, stratified splitting was employed to divide the dataset into three distinct sets: training, validation, and testing. The training set constituted the majority of the data (82%) and was used to train the model and adjust its parameters. The validation set (13%) was utilized during training to fine-tune hyperparameters and assess the model's performance on unseen data, preventing overfitting and promoting generalization. Finally, the testing set (5%) served as an independent evaluation of the model's performance on completely unseen data, offering a reliable measure of its real-world effectiveness and ability to generalize. Additionally, during the preprocessing phase, techniques such as auto-orientation, resizing, tiling, and filtering were applied to standardize and enrich the dataset. Images were consistently oriented, had a uniform size of 640 x 640 pixels, and met the 90% annotation threshold. Furthermore, augmentation strategies, including random saturation adjustments, contributed to a more comprehensive and robust training dataset by introducing variations in color intensity and increasing the number of outputs per example to two.