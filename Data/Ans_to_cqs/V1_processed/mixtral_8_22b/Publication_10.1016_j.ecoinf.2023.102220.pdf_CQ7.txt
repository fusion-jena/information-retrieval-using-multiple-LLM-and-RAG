The authors have used various percentages of the initial observations from the time series for training their deep learning models. Specifically, they have chosen 40%, 50%, 60%, and 70% of the initial observations for training purposes. The remaining portion of the dataset, which is the complement of the training set, has been utilized as the test set. This way, they aimed to evaluate the performance of their proposed Predictive Bayesian Pareto (PBP) method against other popular machine learning techniques like Random Forests (RF), Support Vector Machines (SVM), Deep Neural Networks (DNNs), and Long Short Term Memory (LSTM) algorithms. By comparing the results across different proportions of training and testing datasets, the researchers were able to assess the robustness and generalizability of their proposed PBP method.