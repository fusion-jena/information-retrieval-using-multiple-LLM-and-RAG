Before training a deep learning model, several preprocessing steps can be taken to improve its performance. These may include:

1. Data Cleaning: This involves removing or correcting any errors, inconsistencies, or missing values in the dataset. It also includes handling outliers which might affect the model's accuracy.

2. Normalization or Standardization: This is done to rescale the features so they have zero mean and unit variance. This is important because many machine learning algorithms perform better when numerical input variables are scaled to a standard range.

3. Feature Scaling: In this step, all features are brought to the same scale. This is necessary because most machine learning algorithms expect input data to be numeric and often in the range between 0 and 1.

4. Encoding Categorical Variables: Deep learning models cannot handle categorical data directly. Therefore, it needs to be converted into numerical form using techniques like label encoding or one-hot encoding.

5. Splitting Dataset: The dataset is usually split into three parts - training set, validation set, and test set. The training set is used to train the model, the validation set is used to tune hyperparameters, and the test set is used to evaluate the final model.