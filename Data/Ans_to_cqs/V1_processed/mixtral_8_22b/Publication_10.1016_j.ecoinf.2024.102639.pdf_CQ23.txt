To ensure the generalizability of the deep learning model, several measures were implemented. Firstly, the selection of the distance metric, typically Euclidean, was predicated on the data's characteristics and the specific analytical prerequisites. This ensured that the chosen metric accurately represented the relationships within the data. Secondly, dimensionality reduction techniques were employed to reduce the number of input variables while retaining most of the original data's variance. This step aimed to prevent overfitting and improve the model's performance on unseen data. Thirdly, the regularization parameter ('C') and the kernel type (linear) were calibrated using a combination of grid search and cross-validation. Cross-validation involves dividing the dataset into training and validation sets, where the model is trained on the former and evaluated on the latter. This process helps identify the optimal hyperparameters that strike a balance between model complexity and its generalization prowess. Lastly, the Support Vector Machine (SVM) model was then trained on this dimensionally reduced dataset, further improving its capacity to generalize well to new data. These steps collectively contributed to enhancing the model's robustness and applicability across diverse datasets.