The text does not provide information about regularization methods used specifically in deep learning pipelines like dropout or L2 regularization. However, it mentions three regularization techniques used within the context of species distribution modeling:

1. Generalized Linear Model with Elastic Net Regularization (GLM-EN): This method uses a combination of L1 and L2 penalties during optimization, encouraging sparse solutions while maintaining stability. It helps avoid overfitting by reducing the complexity of the learned model.

2. Generalized Additive Model with Null-Space Penalization (GAM-NP): This technique involves applying a penalty to the null space of the model matrix, effectively shrinking coefficients towards zero without completely eliminating them. This approach allows for better control over the tradeoff between bias and variance, helping prevent overfitting.

3. Guided Regularized Random Forest (RF-GR): In this method, regularization is applied through guided feature selection and pruning of decision trees within the random forest ensemble. By controlling the growth and structure of individual trees, RF-GR aims to reduce overfitting and improve overall model performance.