The text does not provide specific information about techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it mentions some strategies to improve the quality and reliability of annotation sets used for training deep learning models. These include increasing the number of annotators per sample when there is high variability, using grouping methods like majority voting and soft labeling, ensuring representative initial training of annotators, and considering adopting a conservative approach for annotators to minimize false positives.