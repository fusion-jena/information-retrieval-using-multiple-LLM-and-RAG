To ensure the generalizability of the deep learning model, several measures were taken. Firstly, data augmentation techniques such as rotation, noise, and flip were employed to increase the size of the dataset by six times. This helped in making the CNN classification more robust and improved its ability to generalize better. Secondly, the learning rate was adjusted using an exponential decay parameter of 0.5 by an SGD scheduler after 50,000 iterations. This prevented overfitting and ensured that the model did not become too specialized to the training data. Lastly, all experiments were conducted on a diverse hardware setup consisting of a 64-bit Intel i7-8700K@3.70GHz CPU workstation, 64 GB memory, and NVIDIAÂ® GTX 1080 GPU with 12Gb of memory, under a 10.0 CUDA version. This allowed for efficient implementation and analysis of deep learning algorithms with GPUs. However, there is no explicit mention of cross-validation or stratified splitting in the given context.