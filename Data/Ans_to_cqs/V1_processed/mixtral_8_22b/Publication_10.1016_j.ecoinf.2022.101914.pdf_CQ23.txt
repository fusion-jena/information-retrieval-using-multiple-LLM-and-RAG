To ensure the generalizability of the deep learning model, several measures were taken. Firstly, a diverse dataset was utilized by setting aside one fold for obtaining presences and background points to be used during external evaluation. The remaining four folds were employed for internal cross-validation during model training. This strategy allowed the model to learn from various subsets of the data, reducing overfitting and improving its ability to perform well on unseen data. Secondly, stratified splitting was applied when dividing the data into evaluation and training datasets before training the models. This technique ensured that both datasets contained a representative distribution of classes, preventing any class imbalance issues that could negatively impact the model's performance. Lastly, the optimal number of background points for each individual modeling approach was determined by calculating the True Skill Statistic (TSS) and the Area Under the Receiver Operating Curve (AUC-ROC) using the external evaluation datasets set aside prior to training models. These metrics helped quantify the model's predictive power and robustness, ensuring that only the most effective configurations were selected for the final ensemble models.