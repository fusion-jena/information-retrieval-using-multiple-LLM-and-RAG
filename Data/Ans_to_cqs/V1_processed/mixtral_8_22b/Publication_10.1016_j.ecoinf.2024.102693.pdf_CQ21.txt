Based on the given context, there isn't any explicit mention of specific postprocessing steps involved after the model training such as saliency maps, metrics calculation, or confusion matrices. However, it does provide some insights into the evaluation process used for comparing the performance of various models. The table titled 'Classification Performance (%) of Basic Models and Proposed Methods on the IP102 Dataset' suggests that accuracy, precision, recall, and F1-score were calculated to evaluate the performance of the models. These metrics are commonly used in machine learning classification problems to assess the quality of predictions made by the models. Therefore, one could infer that these metrics might be part of the postprocessing steps performed after the model training phase. Nonetheless, without further context, it cannot be confirmed if other postprocessing techniques like saliency maps or confusion matrices were also employed.