The text does not explicitly mention which specific metrics are used to evaluate the performance of the deep learning model. However, it mentions that appropriate validation metrics are important but less straightforward than for single datasets due to potential differences in biases and sampling methods. It also suggests that the standard practice of withholding parts of the training data for validation might lead to both training and testing data suffering from the same spatial and environmental biases. Furthermore, it discusses the use of thresholding techniques like TSS (True Skill Statistic) using the "modEvA" R-package, and creating binary, categorical percentile, and normalized outputs. Therefore, based on this information, we can assume that various metrics could potentially be used to evaluate the performance of the deep learning model, including TSS, binary outputs, categorical percentiles, and normalized outputs. However, without explicit confirmation, we cannot definitively state which specific metrics are used.