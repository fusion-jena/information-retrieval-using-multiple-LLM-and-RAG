The deep learning pipeline primarily utilizes two types of data formats - audio spectrograms and raw waveform data. In the case of natural language processing tasks like human speech enhancement, deep learning-based denoising methods typically operate on audio spectrograms. However, recent advancements have shown successful implementation of state-of-the-art deep learning methods using raw waveform data for broader applications such as source separation and classification. Using raw waveform data eliminates errors introduced by applying a Fast Fourier Transform (FFT) to create a time-frequency representation and reduces reconstruction errors caused by the loss of phase information. It should be noted that these networks usually demand more data for training since the latent space needs to be established comprehensively.