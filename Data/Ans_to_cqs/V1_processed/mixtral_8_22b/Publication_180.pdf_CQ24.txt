The provided context does not explicitly mention any specific strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, it can be inferred that the authors adjusted certain parameters within TensorFlow, an open-source software platform used for deep learning research and applications, to optimize their model performance. These adjustments include increasing the validation percentage from its default value of 10% to 16% due to limited image availability for some species, and exploring various numbers of training steps instead of using the default value of 4000 steps. By comparing these results, they aimed to find the optimal balance between computational time and classification efficiency. While these actions do not directly address handling randomness in the deep learning pipeline, they demonstrate efforts to fine-tune the model for improved accuracy and efficiency.