Based on the given context, it does not explicitly mention what specific optimization techniques were applied in the deep learning pipeline. However, common optimization techniques used in deep learning include Stochastic Gradient Descent (SGD) and Adaptive Moment Estimation (Adam). These techniques are often employed to minimize the loss function during the training phase of deep learning models. Without further information, I can only speculate that similar optimization techniques could have been utilized in this case.