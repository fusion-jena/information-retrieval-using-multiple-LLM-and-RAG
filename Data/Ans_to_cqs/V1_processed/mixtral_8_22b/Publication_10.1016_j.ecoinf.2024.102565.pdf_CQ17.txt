The text does not provide explicit information about the regularization methods used to prevent overfitting in the deep learning pipeline. However, it mentions that random under-sampling (RUS) was applied to the training set to address imbalances. While RUS is primarily used to handle class imbalance issues rather than preventing overfitting, other common regularization techniques include dropout and L2 regularization. Dropout involves temporarily removing some neurons during training to reduce co-dependencies between neurons, while L2 regularization adds a penalty term to the loss function to discourage large weights. These methods were not explicitly mentioned in the given context but could be potential solutions to prevent overfitting in the deep learning pipeline.