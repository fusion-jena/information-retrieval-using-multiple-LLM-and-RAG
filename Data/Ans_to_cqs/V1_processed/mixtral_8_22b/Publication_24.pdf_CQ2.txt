The deep learning pipeline primarily uses two types of data formats: images and audio. The use of images is evident in the application of Convolutional Neural Networks (CNN), which can process multi-channel inputs such as color images (red, green, and blue channels). In this case, the CNN was employed to analyze four spectrograms, each processed differently through various normalization strategies. Spectrograms are visual representations of the spectrum of frequencies of a signal as it varies with time, essentially making them images derived from audio signals.

Audio data is also directly utilized in the deep learning pipeline. The study mentions the use of passive acoustic recording equipment to collect audio data over extended periods and vast areas. Furthermore, the paper references several works related to audio processing and analysis, including Stowell and Plumbley's research on automatic large-scale classification of bird sounds and Salamon et al.'s work on a dataset and taxonomy for urban sound research. These studies suggest that audio files serve as primary sources of information in the deep learning pipeline.

In summary, both image and audio data formats play significant roles in the deep learning pipeline. While images are generated from audio signals in the form of spectrograms, raw audio files are also analyzed directly.