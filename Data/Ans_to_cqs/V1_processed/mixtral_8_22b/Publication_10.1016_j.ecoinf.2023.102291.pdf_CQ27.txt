The text does not provide explicit information about the deployment process of the trained deep learning model. However, it mentions that the model training and prediction procedures were executed on Microsoft Azure using instance NV12s v3 with 12 vCPUs and 112 GB RAM. This suggests that the trained model might have been deployed on the same platform or a similar cloud environment. Additionally, the use of TensorFlow, a popular open-source library for machine learning, implies that the model could have been serialized using standard methods such as saving the model weights or exporting the entire model graph. Nevertheless, without more specific details, it is impossible to determine the exact process followed to deploy the trained deep learning model.