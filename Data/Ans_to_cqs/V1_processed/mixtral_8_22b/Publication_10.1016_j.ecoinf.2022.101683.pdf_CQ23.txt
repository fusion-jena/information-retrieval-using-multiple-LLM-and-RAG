To ensure the generalizability of their deep learning models, the authors employed several strategies. Firstly, they utilized a diverse dataset consisting of various types of input data such as climate, land cover, topography, and human influence variables. This diversity helped prevent overfitting and improved the model's ability to perform well with new, unseen data. Secondly, the authors performed cross-validation by dividing their dataset into multiple subsets or folds. Each fold served as a validation set while the remaining folds acted as the training set. By rotating through all possible combinations of training and validation sets, the authors could assess how well their model generalized to new data. Lastly, stratified sampling was applied during the process of splitting the dataset into training and testing sets. This ensured that the distribution of classes within the training and testing sets remained consistent, preventing any class imbalance from affecting the performance of the model. Overall, these methods contributed to enhancing the robustness and reliability of the deep learning models presented in the study.