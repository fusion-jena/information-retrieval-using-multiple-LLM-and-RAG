Based on the provided context, there isn't explicit mention of any specific techniques used to ensure the generalizability of the deep learning model, such as diverse datasets, cross-validation, or stratified splitting. However, we can infer that the researchers took certain steps towards achieving this goal.

Firstly, the use of a large number of images in the dataset for each task suggests that the researchers aimed to create a diverse dataset. For example, the set sizes for predicting River Age, Sea Age, and Spawning were 6238, 8286, and 9056 respectively. A larger dataset often leads to better generalization since it provides more examples for the model to learn from.

Secondly, while not explicitly mentioned, the table presenting the CNN performance metrics seems to indicate that the researchers may have employed some form of validation technique. The presence of test loss values implies that the models were evaluated on unseen data, which is a common practice when validating machine learning models.

Lastly, although not directly related to ensuring generalizability, the acknowledgement section mentions receiving valuable advice on the CNN architecture from Hyeongji Kim. This collaboration with experts in the field likely contributed to improving the overall quality and robustness of the deep learning model.

However, without further details about the exact methods used for creating the dataset, training the model, and evaluating its performance, it is difficult to provide a definitive answer regarding the specific measures taken to ensure the generalizability of the deep learning model.