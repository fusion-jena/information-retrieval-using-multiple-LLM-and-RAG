To ensure the generalizability of the deep learning model, several measures were implemented during its development. Firstly, diverse datasets were utilized for both training and testing purposes. These datasets were generated through references to existing field datasets and Very High Resolution (VHR) images. Polygon areas dominated by target communities were digitized, and all pixels within them were extracted. To minimize the effects of spatial autocorrelation on model accuracies, these polygons were split into calibration and validation sets, reserving approximately 30% of pixels for each Vegetation Type (VT) for independent model validation. This approach helped maintain the diversity of the dataset while ensuring robustness against potential biases caused by spatial dependencies.

Furthermore, the Python implementation of the XGBoostClassifier was employed to develop optimized random trees where each new tree learned from the errors of those preceding it. This method allowed for continuous improvement and adaptation of the model to better handle complex patterns and relationships within the data.

As inputs to the machine learning algorithm, various features such as seasonal vegetation index composites from Sentinel-2 (S2), backscatter composites from Sentinel-1 (S1), elevation, and slope were incorporated. In total, up to 54 features were considered, contributing to the richness and variability of the dataset. By incorporating this wide range of features, the model was able to capture more nuanced aspects of the environment, thereby enhancing its ability to generalize well to unseen data.

Lastly, the use of stratified splitting techniques further ensured the representativeness of the dataset. Stratified random sampling points were generated using the QGIS ACA_TAMA plugin, increasing the number of points per class to account for bias associated with restricted inclusion probabilities resulting from the pre-defined distribution of GMEP squares. This step aimed to mitigate any imbalances or skewness in the dataset, ultimately promoting fair and accurate representation of different classes.

Overall, these measures collectively contributed to improving the generalizability of the deep learning model, enabling it to perform effectively across diverse landscapes and conditions.