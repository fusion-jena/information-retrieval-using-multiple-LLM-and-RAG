The criterion used to determine when training is complete is called early stopping. Early stopping is a form of regularization used to avoid overfitting by stopping the training process before it converges. In this case, the training data is divided into training and validation groups. The training continues until the validation error starts increasing for a specified number of epochs. This indicates that the model has started to overfit the training data and further training would not improve the model's ability to generalize to new data. Therefore, the optimal point to stop training is determined based on the minimum validation error achieved during the training process.

In summary, the criterion used to determine when training is complete is early stopping, where the training stops when the validation error starts increasing for a specified number of epochs.