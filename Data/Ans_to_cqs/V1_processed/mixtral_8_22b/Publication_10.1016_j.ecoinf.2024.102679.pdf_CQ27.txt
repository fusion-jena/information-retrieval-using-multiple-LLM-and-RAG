Unfortunately, the provided context does not explicitly mention the specific process followed to deploy the trained deep learning model, such as model serialization or platform selection. However, it does provide some relevant details about the fine-tuning process and inference settings.

During the fine-tuning process, the pre-trained model went through four iterations using the entire Southwest (SW) stratum with the Spatial Autoencoder Learning (SAL) approach. The goal was to improve the model's performance and collect samples related to each key species in the region. The training procedure involved two main steps: 1) training the architecture using positive patches for 200 epochs, and 2) incorporating hard negative patches, which contain false positives, to further train the model for 50 epochs to minimize false positives. For the final two fine-tuning iterations, only the second step of the training procedure was utilized.

Regarding inference settings, the patch size was set to 1024 x 1024 pixels to expedite the process. Additionally, the model was chosen based on its performance on the validation set during each training stage to prevent overfitting. Further information about the fine-tuning process can be found in Section 2.5.2.