Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, we do see some elements related to handling data in the process.

In section A.1.3, users have the ability to set a threshold to filter out negligible values. This could potentially help manage noise or outliers in the dataset, which might contribute to reducing bias. But this doesnâ€™t directly address class imbalance issues often handled through methods like oversampling or undersampling.

Additionally, while not explicitly mentioned in the context, the fact that LaDeco allows users to switch between different pre-trained models suggests that they may also be able to choose from various architectures designed to handle biased data better. For instance, some models might inherently perform well on imbalanced classes due to their design.

Lastly, although not discussed in detail, the reference to 'Data Filtering Module' in Section 6 implies that there might be mechanisms in place to remove irrelevant or noisy data points before feeding into the model. While this does not necessarily tackle data bias head-on, it contributes towards improving overall data quality.

However, without further information about how exactly these modules operate, it remains unclear whether they specifically target data bias reduction. Therefore, based solely on the provided context, we cannot definitively state what techniques are employed to address data bias during preprocessing of the deep learning pipeline.