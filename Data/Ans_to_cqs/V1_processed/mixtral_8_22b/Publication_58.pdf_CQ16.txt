Based on the given context, there isn't explicit information about the specific criteria used to determine when training is complete. However, we can infer some possibilities based on common practices in machine learning.

In general, training could be considered complete when certain conditions are met, such as achieving a desired level of performance or when further training does not lead to significant improvements. This is often determined by monitoring various metrics during the training process, such as validation loss or accuracy.

From the context, we know that the models were trained using stochastic gradient descent with a momentum of 0.9 and an initial learning rate of 10^-2. The learning rate was decreased every 20 epochs until it reached 10^-6. This suggests that the training might have been stopped after a certain number of epochs or when the decrease in learning rate no longer resulted in improved performance.

However, without explicit mention of the stopping criterion, we cannot definitively state what criteria were used to determine when training was complete.