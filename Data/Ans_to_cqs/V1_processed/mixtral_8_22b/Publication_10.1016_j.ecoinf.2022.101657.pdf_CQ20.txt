The provided context does not explicitly mention which specific hardware resources were used for training the deep learning models. However, there are some relevant details about implementing neural networks on hardware. In section 7.1.4, it discusses the implementation of a Multilayer Perceptron model on an Field Programmable Gate Array (FPGA), which offers improved power efficiency compared to software-based alternatives. Additionally, Intel's results show that running a Convolutional Neural Network on an FPGA can have twice the efficiency of a CPU implementation. These findings suggest that FPGAs might be one type of hardware resource used for deploying trained deep learning models more efficiently. Nevertheless, without explicit information regarding the training phase, it cannot be confirmed whether these same hardware resources were utilized during the training process itself.