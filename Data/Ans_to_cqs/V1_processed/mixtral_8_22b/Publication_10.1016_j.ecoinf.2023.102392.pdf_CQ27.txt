Based on the given information, there isn't enough detail to provide a precise answer regarding the deployment process of the trained deep learning model. However, I can infer some general steps typically involved in deploying such models.

Model Serialization: After training, the deep learning model needs to be serialized or saved so it can be used later. This usually involves saving the model architecture and its learned parameters (weights and biases). Common formats include.h5 for Keras models,.pth for PyTorch models, and.pb for TensorFlow models.

Platform Selection: Once the model is serialized, it needs to be deployed onto a platform where it can receive input data and generate predictions. Depending on the application, this could range from a simple local server to cloud platforms like AWS, Google Cloud, or Azure. For real-time applications, edge devices might also be considered.

However, without explicit details about the specific deep learning model mentioned in the papers, I cannot provide a detailed description of how exactly it was deployed.