In the provided context, there isn't explicit information about the specific criteria used to determine when training is complete. However, based on common practices in machine learning, several possible criteria can be suggested.

One commonly used criterion is reaching a validation loss plateau. During training, both the training loss and validation loss decrease. When the validation loss stops decreasing significantly or even starts to increase, it indicates that the model might be starting to overfit the training data. At this point, further training may not improve the model's performance on unseen data. Therefore, reaching a validation loss plateau could be considered as a sign that training should stop.

Another potential criterion mentioned indirectly in the context is the number of epochs. In this case, the models were trained for a fixed number of epochs, specifically 500. An epoch refers to one full pass through the entire training dataset. After each epoch, the model updates its internal parameters based on the observed errors. By setting a maximum number of epochs, the training process has a predefined endpoint.

Additionally, early stopping is another frequently used method to decide when to terminate training. Early stopping involves monitoring the validation error during training and stopping the training process if the validation error does not improve after a certain number of epochs. This helps prevent overfitting and saves computational resources.

Lastly, the use of cross-validation, as described in the context, also provides insights into the model's performance on unseen data. Cross-validation involves splitting the available data into multiple subsets and iteratively using each subset as a validation set while training on the remaining data. By averaging the performances of the models trained on different versions of the dataset, cross-validation gives a more robust estimate of the model's overall performance. While cross-validation itself doesn't directly determine when training is complete, it can help identify whether the model is overfitting or underfitting, thus influencing decisions regarding the optimal duration of training.