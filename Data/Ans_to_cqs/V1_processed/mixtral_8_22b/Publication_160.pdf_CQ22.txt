The performance of the deep learning model is evaluated using several metrics such as precision, recall, and F1-score. These metrics are calculated during training, validation, and testing phases. Precision measures the number of true positive predictions divided by the total number of positive predictions. Recall calculates the number of true positive predictions divided by the actual number of positives. The F1-score combines precision and recall into a single metric, ranging from 0 to 1, where 1 represents a perfect classifier. Additionally, these metrics can be computed at both micro and macro levels. Micro-level calculations consider all classes together, giving them weights based on their distribution in the entire dataset. On the other hand, macro-level computations assign equal importance to all classes, making class-wise performance variations significantly affect the scores. Notably, micro-recall is equivalent to the overall top-1 accuracy of the models.