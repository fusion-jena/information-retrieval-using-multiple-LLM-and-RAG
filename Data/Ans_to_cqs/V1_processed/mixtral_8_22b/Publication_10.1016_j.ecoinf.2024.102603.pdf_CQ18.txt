To monitor the model performance during training, the authors employed the leave-one-out procedure for cross-validation. This method maximizes the utilization of available data, minimizes bias in performance estimation, and is particularly beneficial for small datasets. By iteratively training the model on all but one sample and then evaluating the excluded sample, this approach provides a thorough assessment of the model's performance. Furthermore, several metrics were computed to evaluate the model's performance, including the coefficient of determination (R^2), Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Relative Root Mean Square Error (RRMSE).