To handle randomness in the deep learning pipeline, several strategies can be employed. One common approach is to use a fixed random seed value across different runs of the same experiment. This ensures that the results obtained from multiple runs are reproducible and comparable. Another strategy is to perform multiple runs with different random seeds and report the average performance metrics. This helps to reduce the impact of random initialization and improve the robustness of the model. Additionally, techniques like dropout and batch normalization can also help to mitigate the effects of randomness during training. Dropout randomly drops out neurons during training, which prevents overfitting and improves generalization. Batch normalization standardizes the inputs to each layer, reducing internal covariate shift and improving convergence speed. Overall, these strategies can help to ensure that the deep learning pipeline produces reliable and consistent results despite the inherent randomness involved.

Based on the given context, it appears that the authors have used Optuna, a hyperparameter optimization framework, to optimize the structure and hyperparameters of their Random Forest (RF), Artificial Neural Network (ANN), and Gradient Boosting Decision Tree (GBDT) models. However, there is no explicit mention of how they handled randomness in the deep learning pipeline. Nevertheless, based on common practices in the field, one could infer that they might have used a fixed random seed value or performed multiple runs with different random seeds to ensure reproducibility and reliability of their results. Furthermore, the use of Optuna itself suggests that they aimed to find the most suitable set of hyperparameters for their models, which would indirectly address some aspects of randomness in the pipeline.