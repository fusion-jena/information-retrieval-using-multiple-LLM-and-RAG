The authors took several measures to ensure the generalizability of their deep learning model. Firstly, they created a diverse dataset consisting of 35,573 images for each of the 12 channels, covering 35 different species, resulting in a total of 426,876 images. This large and varied dataset helped prevent overfitting and improved the model's ability to generalize well to unseen data. Secondly, the dataset was divided into three subsets for training, validation, and testing in the proportions 80:10:10. This stratified splitting ensured that all classes were proportionally represented in each subset, which is crucial for maintaining the balance of the dataset and preventing any bias towards certain classes during training. Thirdly, the images in the training set were further augmented through various transformations such as flipping horizontally and vertically, adjusting brightness, saturation, contrast, and hue. These image augmentation techniques increased the diversity of the training data and made the model more robust against variations in input images. Lastly, the model was trained using a batch size of 32, and the initial learning rate of 0.001 was exponentially decayed every 3 epochs with a factor of 0.94. This learning rate schedule allowed the model to converge faster and prevented it from getting stuck in local minima, thereby improving its overall performance and generalization capabilities.