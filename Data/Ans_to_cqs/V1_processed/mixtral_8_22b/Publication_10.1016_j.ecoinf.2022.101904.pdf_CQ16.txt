Unfortunately, the provided context does not explicitly mention any specific criteria used to determine when training is complete, such as a validation loss plateau or another stopping criterion. However, based on the information given, it can be inferred that the authors evaluated their proposed model with varying amounts of training data to assess its performance and understand how much data is needed to achieve an acceptable level of wetland mapping accuracy. They started with a small percentage of training data (10%) and gradually increased it to 90%, observing improvements in classification accuracy along the way. Notably, they found that the most significant increase in accuracy occurred between 10% and 30% of training data, suggesting that a relatively smaller dataset could still yield satisfactory results. While this approach does not directly address the query regarding stopping criteria during training, it demonstrates the importance of evaluating models with various amounts of training data to optimize performance and resource allocation.