The table provided does not explicitly state how the hyperparameters were optimized. However, it lists the final values used for various hyperparameters such as learning rate, minimum learning rate, optimizer, scheduler, batch size, weight decay, input size, and epochs for each of the models ResNet-50, ViT-S/16, Volo-d1, and ViP-Small/7. Without additional context or information, it cannot be determined whether techniques like grid search or random search were employed during optimization.