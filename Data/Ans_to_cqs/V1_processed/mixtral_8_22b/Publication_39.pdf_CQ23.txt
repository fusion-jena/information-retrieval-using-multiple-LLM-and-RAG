To ensure the generalizability of their deep learning model, the authors used several measures. Firstly, they utilized a diverse dataset called 'AnnotationsActions', which was randomly but fixedly split into a training set, validation set, and test set. Specifically, 20% of the video clips from each class formed the test set, while another 20% of the remaining clips in each class made up the validation set. The rest of the clips served as the training set.

Additionally, data augmentation techniques were employed for action recognition tasks. These techniques help prevent overfitting and improve the model's ability to generalize to unseen data. Although the specific data augmentation methods used are not explicitly mentioned in the given context, common techniques include random cropping, flipping, rotation, scaling, and color jittering.

Lastly, the authors used pretrained versions of various detection models such as Mask R-CNN and ResNets. Pretraining on large datasets like COCO 2017train and Kinetics-400 allows the model to learn useful features before fine-tuning on the target task. This helps reduce overfitting and improves the model's performance on new, unseen data.