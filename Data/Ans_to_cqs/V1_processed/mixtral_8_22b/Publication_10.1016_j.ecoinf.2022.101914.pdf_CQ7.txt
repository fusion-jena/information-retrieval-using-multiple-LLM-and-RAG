The text does not provide explicit information about the specific criteria used to split the data for deep learning model training, such as train, test, and validation sets. However, it mentions that the dataset was divided into five equal parts or folds for cross-validation purposes. One fold was set aside for obtaining presences and background points for external evaluation, while the remaining four folds were used for internal cross-validation during model training. This suggests that the authors may have employed a form of k-fold cross-validation, where k equals five in this case. K-fold cross-validation involves splitting the dataset into k equally sized subsamples or folds. Of these k folds, one fold is retained as the validation data for testing the model, while the remaining k-1 folds are used as training data. This process is repeated k times, with each unique fold serving as the validation data once. The results from each run can then be averaged to produce a single estimation. Nonetheless, without further details regarding the exact methodology used, it cannot be definitively stated what specific criteria were applied to split the data for deep learning model training.