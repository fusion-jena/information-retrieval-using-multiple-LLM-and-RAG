The text does not provide explicit details on the deployment process of the trained deep learning models. However, it mentions that the models are intended to be deployed on IoT edge devices such as Raspberry Pi. Additionally, it states that TensorFlow Lite was used, which is a framework designed specifically for running machine learning models on mobile and other edge devices. Therefore, we can infer that the likely steps taken to deploy the models would have included model serialization into a format compatible with TensorFlow Lite, selecting an appropriate platform (such as Raspberry Pi), installing necessary software libraries, loading the serialized model onto the device, and then integrating the model into the overall application or workflow.