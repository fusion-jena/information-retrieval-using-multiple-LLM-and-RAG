In the given context, there is no explicit mention of specific regularization methods such as dropout or L2 regularization used to prevent overfitting in the deep learning pipeline. However, it does mention the application of different normalization strategies, which could potentially include techniques like batch normalization, layer normalization, or weight normalization. These normalization techniques help in reducing internal covariate shift, improving gradient flow, and stabilizing the learning process, thereby preventing overfitting indirectly. Additionally, the text mentions the use of Convolutional Neural Networks (CNNs), which inherently have some degree of regularization due to the convolution operation and shared weights across spatial locations.