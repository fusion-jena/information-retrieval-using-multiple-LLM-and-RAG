Based on the given information, the authors use two criteria to determine when training is complete: the maximum number of iterations and the maximum number of iterations with no improvement. These criteria are part of the hyperparameter tuning process conducted through a grid search using Optuna. The goal of this process is to find the best combination of hyperparameters that result in the lowest Mean Squared Error (MSE) for the model. During this process, the authors divide their dataset into a training set (80%) and a test set (20%). They then train the Multilayer Perceptron (MLP) models on the training set while monitoring the performance on the test set. Training continues until either the maximum number of iterations has been reached or there have been no improvements in the MSE after a certain number of iterations. In other words, if the model stops improving during training, the authors stop the training process even before reaching the maximum number of iterations. However, the exact threshold for determining when there have been no improvements is not specified in the provided text.