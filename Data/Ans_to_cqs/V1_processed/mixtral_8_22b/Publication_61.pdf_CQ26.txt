The given context does not provide information about specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it mentions the use of data augmentation to improve the accuracy of the deep learning model. Data augmentation involves creating new training samples by applying random (but realistic) transformations to the existing training data, which can help reduce overfitting and improve generalization performance. In this case, the authors experimented with two types of data augmentation: no augmentation (where patches are simply resized and normalized) and vertical/horizontal flip (where patches are flipped vertically or horizontally with probability 0.5). These experiments aimed to evaluate the impact of data augmentation on the accuracy of the network.