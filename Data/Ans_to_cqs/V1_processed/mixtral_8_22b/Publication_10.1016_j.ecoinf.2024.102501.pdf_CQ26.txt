Based on the given context, several techniques are mentioned to address data bias or improve the predictive performance during the preprocessing stage of the deep learning pipeline. However, none of them directly correspond to stratified splitting, oversampling, undersampling, or diverse data collection. Instead, the context focuses on other aspects of data preprocessing.

One technique mentioned is normalization, which aims to reduce the impact of large differences in dimensions and magnitudes among various parameters. Normalization is achieved by applying formulas like those presented in equations (1) and (2).

Additionally, principal component analysis (PCA) is employed to select key factors for input data, thereby reducing data dimensionality and information redundancy. PCA helps improve the predictive performance of DO models.

Clustering algorithms are also utilized to group datasets with different periodic changes. By doing so, the grouped datasets can be modeled separately, which is another common data preprocessing method in combinatorial modeling.

Lastly, methods such as empirical mode decomposition (EMD) and wavelet transform (WT) are used for denoising and extracting features from raw time series data. These techniques help fully mine and utilize various time-frequency feature information, ultimately improving the overall performance of the deep learning pipeline.