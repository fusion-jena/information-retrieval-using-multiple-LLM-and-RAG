The study primarily focuses on species distribution models rather than deep learning models specifically. However, several metrics used to evaluate these models overlap with those used for evaluating deep learning models. The most frequently used metric in the reviewed studies was the Area Under the Receiver Operating Characteristic Curve (AUC-ROC curve), appearing in 55% of the studies. Other popular metrics included TSS, Cohen's Kappa, Sensitivity, Specificity, Accuracy, and Precision. These metrics help measure various aspects of model performance, including the ability to discriminate between occupied and unoccupied sites and the correct prediction of the conditional probability of presence. Interestingly, there seems to be less emphasis on calibration metrics like the Brier score. Half of the examined studies relied on a single metric, while others didn't specify the metric used. To achieve a comprehensive overview of model performance, it is recommended to incorporate multiple validation metrics, aligning with the suggestion by Guisan et al. (2017).