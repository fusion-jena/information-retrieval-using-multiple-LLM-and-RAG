To deploy the trained deep learning model, it was first serialized using a suitable format such as HDF5 or ONNX. This allows the model architecture and weights to be saved and loaded easily. After serializing the model, it was then deployed on a cloud-based system. A cloud resident camera was placed in the Kohora range of KNP, and the images captured by the camera were fed into the model. The cloud computing infrastructure used for deployment included a processor equivalent to Intel Core i9 7980XE @ 2.60 GHz, a Tesla T4 GPU, 1Gbps bandwidth, 100GB storage, maximum latency of 50ms, secured wireless connectivity with WPA3, and various cloud features such as scalability, resource pooling, security, and economy. The specific platform used for deployment may not have been explicitly stated in the given information, but popular platforms for deploying deep learning models include TensorFlow Serving, TorchServe, and AWS SageMaker.