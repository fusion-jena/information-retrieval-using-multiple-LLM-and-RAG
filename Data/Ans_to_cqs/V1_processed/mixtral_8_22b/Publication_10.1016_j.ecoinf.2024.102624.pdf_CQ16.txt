Based on the given context, it appears that the authors use a combination of cross-validation and hyperparameter tuning to determine the optimal point for completing their training process. Specifically, they employ a 10-fold cross-validation technique with three repetitions during the model building phase. This involves randomly splitting the training dataset into ten folds, where nine folds are used for model training and one fold is used for testing. This process continues until all folds have been used as testing data. The entire sequence is then repeated twice more with different random splits. This approach allows them to identify the best models with the largest overall accuracy (OA) while also providing insight into the distribution of potential model outcomes. Additionally, they mention using hyperparameter tuning, which suggests that they may be adjusting various parameters within their models to optimize performance further. However, the specific criteria used to determine when training is complete, such as reaching a certain threshold for validation loss or achieving a desired level of accuracy, are not explicitly stated in the provided context.