The deep learning pipeline mentioned does not use any standard image datasets such as MNIST, CIFAR, or ImageNet. Instead, it uses custom datasets generated through reference to existing field datasets and Very High Resolution (VHR) images. Specifically, areas dominated by target communities were digitized as polygons, and all pixels contained within them were extracted. These polygons were then split into calibration and validation sets, with approximately 30% of pixels for each Vegetation Type (VT) reserved for independent model validation. The input to the machine learning algorithm included seasonal vegetation index composites from Sentinel-2 (S2), backscatter composites from Sentinel-1 (S1), elevation, and slope, totaling up to 54 features. Additionally, several vector datasets were utilized, including Living Wales data products, peat depth maps, phase-1 habitat survey maps, digital elevation models, saltmarsh layers, mean high water spring tide vectors, and national forest inventory data.