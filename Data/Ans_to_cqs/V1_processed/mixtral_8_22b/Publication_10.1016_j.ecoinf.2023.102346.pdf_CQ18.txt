The authors employed two strategies to ensure the validity and reliability of their models. Firstly, they utilized 30% of each taxon's data records as testing data, while the remaining 70% served as training data. This allowed them to evaluate how well the trained models could generalize to new, unseen data. Secondly, after conducting 10 K-fold cross-validation and 10-fold bootstrapping, the authors evaluated the models based on several metrics such as Area Under the Curve (AUC), True Skill Statistics (TSS), Cohen's Kappa (KAPPA), point-biserial correlation (COR), and Receiver Operator Characteristics (ROC). These evaluations helped determine the overall performance of the models during training. Additionally, bootstrapping was used to provide unbiased predictive accuracy with a sufficiently low variance. Lastly, for the model threshold, the sensitivity-specificity sum maximization technique was employed, ensuring accurate species distribution predictions.