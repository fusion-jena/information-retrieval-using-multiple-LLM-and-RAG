The given context does not provide explicit information about the specific data annotation techniques used in their deep learning pipeline. However, based on common practices in deep learning pipelines, especially those involving image recognition tasks like plant classification, we can infer that they likely employed some form of labeling or categorization technique.

In the case of the Google Search Image dataset mentioned, the authors selected 3680 labels with more than 12 images in their training dataset. These labels could be considered as categories or classes under which the corresponding images were grouped. Each image was then assigned a label, effectively 'annotating' it with its respective category.

While the text does not explicitly mention bounding box annotation or instance segmentation, these techniques are typically used when dealing with multiple objects within an image or when precise localization of objects is required. Given that the paper focuses on plant classification, where the goal is to identify the type of plant rather than locate individual plants within an image, such detailed annotations may not have been necessary.

Therefore, while the exact data annotation techniques used in this particular study remain unclear due to lack of explicit information, it is reasonable to assume that basic labeling or categorization was employed.