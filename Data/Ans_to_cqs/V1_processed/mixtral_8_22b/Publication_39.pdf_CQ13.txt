For object detection using Mask R-CNN, the Stochastic Gradient Descent (SGD) optimizer was utilized with a learning rate of 0.0005, a momentum of 0.9, and a weight decay of 0.0005. The learning rate was reduced every 10 epochs by multiplying it with gamma (γ) equal to 0.1. Warmup iterations were employed during the first epoch with a warmup factor of 1/1000. The model was trained for 30 epochs.

For action recognition using the three ResNet variants, they were trained for 40 epochs with an initial learning rate of 0.001. The learning rate was decreased every 10 epochs by multiplying it with gamma (γ) equal to 0.1. Similarly, the Stochastic Gradient Descent (SGD) optimizer was used with a momentum of 0.9.

Lastly, for action recognition using the SlowFast architecture, it was trained for 40 epochs with an initial base learning rate of 0.1. Five warmup epochs were applied with a warmup learning rate of 0.001. The momentum was set to 0.9, and the weight decay parameter was 4 × 10^-4. The learning rate was decreased using a cosine strategy. The optimization technique used was SGD, and the loss function was the cross-entropy loss.