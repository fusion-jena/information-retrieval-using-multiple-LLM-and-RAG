The strategy implemented to monitor the model performance during training involves using control mechanisms in the form of Eqs. (6)-(8), which ensure that the model optimization does not deviate significantly from previous optimal solutions. These equations provide a way to balance long and short-term memory of losses and their respective optima, helping the model move toward global optima. Furthermore, the inclusion of an additional loss term scaling term γ(t)ℒcls in Eq. (9) improves the clustering performance of the model by keeping the contribution from ℒcls in a similar range as ℒrec and ℒreg. However, expanding Eq. (4) to include a dynamically adjusted γ(t)ℒcls term may reduce the generality of the model for other tasks. During training, the performance of the model is monitored through its ability to reconstruct data and maintain a well-generalized latent space, while avoiding collapse.