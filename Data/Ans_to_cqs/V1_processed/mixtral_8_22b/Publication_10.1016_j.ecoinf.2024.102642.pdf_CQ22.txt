The state-of-the-art metrics used to evaluate the performance of the deep learning model include Area Under Curve (AUC), Mean Average Precision (mAP), F1 Score, Recall, and Precision. These metrics are used to compare pairs of annotators, evaluate the performance of detection models, and observe the agreement between novice and expert annotations. Specifically, the F1 score is calculated based on measurements of recall and precision, while the AUC and mAP are used to determine whether the performance of the model trained with expert annotations significantly differs from those trained with non-expert annotations.