The study uses three independent fish images datasets from the Mayotte Island (Western Indian Ocean) to train and test their Convolutional Neural Network (CNN) model and post-processing method. These datasets consist of fish images extracted from 175 underwater high-definition videos lasting between 5 and 21 minutes, totaling 83 hours of footage. The videos were recorded in 1920 x 1080 pixels resolution using GoPro Hero 3+ Black and Hero 4+ Black cameras. They were captured between 2 and 30 meters deep, covering various luminosity, transparency, and benthic environment conditions on fringing and barrier reefs. Therefore, the primary data format used in this deep learning pipeline is video files containing high-definition underwater footage. From these video files, fish images are extracted to create the datasets required for training and testing the CNN model.