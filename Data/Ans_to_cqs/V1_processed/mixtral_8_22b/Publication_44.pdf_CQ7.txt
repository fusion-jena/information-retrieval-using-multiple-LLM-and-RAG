Based on the given context, it is not explicitly mentioned how the data was split for deep learning model training into train, test, and validation sets. However, it is common practice in machine learning to randomly divide the available data into three subsets: training set, validation set, and test set. Typically, around 60-80% of the data is allocated for training, 10-20% for validation, and the remaining 10-20% for testing. This division allows the model to learn patterns from the training data, tune hyperparameters using the validation data, and evaluate its generalization performance on unseen data using the test data.

In this case, we do see that the best performing model was selected based on the validation loss after training for 3000 iterations. This suggests that there was indeed a separate validation set used during the training process. However, without further information, we cannot determine the exact proportions or method used to split the data.