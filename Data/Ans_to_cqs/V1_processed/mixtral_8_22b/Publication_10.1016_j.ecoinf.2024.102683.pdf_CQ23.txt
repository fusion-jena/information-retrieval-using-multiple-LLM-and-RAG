To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the data was split into two parts - 80% for training and validation, and the remaining 20% for testing the model. This allowed for the improvement of the generalization performance of the models. Secondly, the use of diverse datasets was implied through the implementation of data augmentation techniques. These techniques helped to artificially increase and diversify the training data, thereby improving the generalization ability of the network. Specifically, a designed set of data augmentations was used instead of simple random transformations during data training. Lastly, the proposed approach mentioned the use of a Bayesian optimizer to control the output of each Convolutional Neural Network (CNN). This could potentially contribute to the generalizability of the model by optimizing its parameters. However, it is not explicitly stated how this contributes to the generalizability of the model.