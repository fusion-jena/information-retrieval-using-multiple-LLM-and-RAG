The strategy implemented to monitor the model performance during training involves maintaining the number of epochs at 500, which guarantees the stabilization of loss curves during training. Additionally, the Adam algorithm, a stochastic gradient descent method, was used as the optimizer. However, the specific metrics used to evaluate the model performance during training, such as accuracy, precision, recall, F1 score, etc., are not explicitly mentioned in the provided context.