Based on the given information, there isn't any explicit mention of how the data was split for deep learning model training (train, test, validation). However, it can be assumed that standard practices were followed such as splitting the data into three sets - training set, testing set, and validation set. Typically, the data is divided randomly where around 60-80% of the data is used for training, 20-30% for testing, and a small portion (around 10%) for validation. These percentages may vary depending upon the size of the dataset and specific requirements of the project.