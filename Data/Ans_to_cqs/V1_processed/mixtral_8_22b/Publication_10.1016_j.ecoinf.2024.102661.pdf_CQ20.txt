Unfortunately, the given context does not provide information about the specific hardware resources used for training the deep learning model, such as GPUs or TPUs. Therefore, I cannot give a definitive answer regarding this matter. However, it can be generally stated that deep learning models often require substantial computational power, making GPU usage common due to their ability to handle parallel processing tasks efficiently. In some cases, specialized hardware like Tensor Processing Units (TPUs) may also be employed for optimized performance.