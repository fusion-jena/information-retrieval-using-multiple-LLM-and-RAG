Based on the given context, there isn't any explicit mention of specific methods used for collecting raw data in the deep learning pipeline. However, some clues can be derived indirectly. For instance, the context mentions that CLIP was trained on 400 million images from the web along with their captions. This suggests that one method for gathering raw data could involve scraping or downloading images and associated metadata from publicly accessible sources like websites. Additionally, the use of Inception-V3, ResNet-50, and other models implies that existing datasets might have been employed for training purposes. These datasets may include those created via manual labeling efforts, sensor data collection, or even crowdsourced contributions. Nonetheless, without more detailed information about the exact process followed in this case, it remains speculative to pinpoint the precise methods used for collecting raw data.