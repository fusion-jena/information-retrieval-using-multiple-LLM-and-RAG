Based on the given context, it does not explicitly mention any specific preprocessing steps taken before training the deep learning model. However, it can be inferred that some level of preprocessing might have been done due to the nature of the task. Typically, preprocessing steps could include normalization, scaling, or cleaning of the dataset. Normalization involves rescaling the values to fit within a certain range, often between 0 and 1. Scaling refers to adjusting the scale of features so they fall under similar ranges, which helps prevent variables with larger scales dominating those with smaller ones. Cleaning may involve removing missing or irrelevant data points, handling outliers, or dealing with inconsistent data entries. In this case, since the authors mentioned using separate two-class models for different regions, it suggests that there might have been some regional differences in the input data requiring appropriate preprocessing. Nevertheless, without explicit information about the exact preprocessing steps applied, it remains speculative.