The text does not explicitly mention the specific criteria used to split the data for deep learning model training. However, it does provide some insights into the splitting process. For instance, it mentions that the data was divided into four non-overlapping subsites to maximize the independence between the training and testing sets. This suggests that one criterion used might be ensuring that the training and testing data come from different sources or locations to ensure the model's ability to generalize well to unseen data. Additionally, the text implies that the division should avoid overlaps between the training and testing sets to prevent the model from simply memorizing the training data instead of learning meaningful patterns. Lastly, the text hints at the importance of considering the class distribution when splitting the data, as significant variations between the training and testing sets could negatively impact the model's performance.