The paper discusses several data augmentation techniques used in their deep learning pipeline for image classification tasks. These include horizontal flipping, random cropping, and color jittering. Horizontal flipping involves creating a mirror image of the original input data by reversing its order along the horizontal axis. This technique helps improve model robustness against object orientation variations. Random cropping is another common data augmentation method where a portion of the input image is randomly selected and rescaled to match the network's input size. This process introduces variability into the training dataset, helping prevent overfitting and improving generalization performance. Color jittering modifies the brightness, contrast, saturation, or hue of images during training, which can help models become more invariant to changes in lighting conditions or color distributions. Other potential data augmentation methods mentioned but not explicitly implemented in this study include rotation, scaling, and translation transformations.