Two main metrics are used to evaluate the performance of the deep learning model: recall and precision. Recall measures the proportion of true positive predictions out of the total actual positives, calculated using the formula TP/(TP+FN). On the other hand, precision measures the proportion of true positive predictions out of the total predicted positives, calculated using the formula TP/(TP+FP). Additionally, another evaluation metric called Average Precision (AP) is employed to assess the overall performance of the model across various confidence thresholds. This metric is computed using the formula âˆ‘n (rn+1 - rn) pinterp (rn+1), where pinterp (rn+1) represents the maximum value of p(r~) such that r~ >= rn+1 and p(r~) denotes the measured precision at recall r.