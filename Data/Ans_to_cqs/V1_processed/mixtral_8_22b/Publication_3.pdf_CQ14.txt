Based on the provided context, it appears that the authors used a manual approach to determine the optimal number of training steps for their TensorFlow models. They experimented with different numbers of training steps and evaluated the performance based on two factors: correct identification rate and processing time. After testing various configurations, they found that 4000 training steps worked best for most challenges, while 8000 training steps were required for one specific challenge involving 41 species. However, there is no explicit mention of any standard optimization techniques such as grid search or random search being employed in this process. Therefore, it can be concluded that the authors did not use these common hyperparameter tuning strategies but rather relied on trial and error to arrive at the optimal configuration.