The provided context does not directly address the specific strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, it is important to note that handling randomness is crucial in ensuring reproducibility and consistency in machine learning experiments. Some common strategies include setting fixed seeds for various libraries like NumPy or TensorFlow, which ensures consistent results across different runs. Additionally, techniques like cross-validation, bootstrapping, and bagging can help manage variability due to random sampling. Lastly, employing deterministic algorithms instead of stochastic ones can also reduce the impact of randomness.