The strategy implemented to monitor the model performance during training involves partial training, successive halving, and repetition. Initially, models are partially trained on a small fraction of the data to quickly eliminate underperforming configurations. Then, the remaining configurations are grouped into sets of different sizes, and the associated models are trained further. The best-performing configurations in each set are promoted to the next stage, while the underperforming configurations are eliminated. These steps are repeated until only one configuration remains, which is then considered the best configuration found. During this process, the mean absolute error (MAE) metric and Nash-Sutcliffe efficiency (NSE) score are used to evaluate the model performance.