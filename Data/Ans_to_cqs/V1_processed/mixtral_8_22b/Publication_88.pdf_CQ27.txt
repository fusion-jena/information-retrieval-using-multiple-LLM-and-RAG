Unfortunately, there isn't enough information available to provide a detailed response regarding the deployment process of the trained deep learning model. However, based on common practices in machine learning projects, the following steps might have been taken:

1. Model Serialization: After training the EF or SN models, they could have been serialized into a format such as.h5 (HDF5) or.pt (PyTorch) to save their weights and architectures. This allows for easy loading and use of the models later during deployment.

2. Platform Selection: Depending on the requirements and constraints of the project, different platforms could have been chosen for deploying the models. Some popular options include cloud services like AWS, Google Cloud, or Azure; edge devices like NVIDIA Jetson or Raspberry Pi; or custom servers built specifically for running AI applications.

3. Deployment: Once the platform has been selected, the next step would involve setting up the necessary infrastructure to run the models. This may include installing required libraries, configuring hardware resources, and creating APIs or web interfaces for users to interact with the deployed models.

Without further details about the specific implementation of this project, these general steps serve as a possible outline for how the trained deep learning models might have been deployed.