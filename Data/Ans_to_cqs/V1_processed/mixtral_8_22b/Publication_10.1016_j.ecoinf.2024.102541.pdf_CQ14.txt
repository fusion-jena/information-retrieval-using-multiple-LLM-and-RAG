The given context does not provide explicit information on how the hyperparameters of the model were optimized, whether through methods like grid search or random search. However, it mentions several modifications made to improve the model's performance, including changes to its architecture and loss functions. These adjustments could be considered part of the process of tuning the model's hyperparameters. For instance, the replacement of certain layers with more efficient alternatives and the integration of depth-wise separable convolutions can be seen as ways to optimize the model's configuration. Similarly, changing the loss function from traditional CIoU to Focal-EIoU addresses issues related to class imbalance, another important factor when fine-tuning a deep learning model. Nevertheless, without specific details about the methodology used for selecting these modifications, we cannot definitively state that techniques like grid search or random search were employed.