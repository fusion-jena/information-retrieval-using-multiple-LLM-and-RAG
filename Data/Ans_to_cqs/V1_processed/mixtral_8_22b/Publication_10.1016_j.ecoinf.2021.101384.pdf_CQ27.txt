Unfortunately, there isn't enough information available to determine what specific process was followed to deploy the trained deep learning model. However, based on common practices, after training a deep learning model, one might serialize the model using popular libraries such as TensorFlow or PyTorch. This serialized model could then be deployed onto various platforms depending on the application requirements. For instance, this could include cloud services like AWS S3, Google Cloud Storage, or Azure Blob Storage, or edge devices for real-time predictions. Without additional details about the specific implementation, I cannot provide a more precise response.