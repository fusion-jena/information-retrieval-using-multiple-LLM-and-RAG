The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, there are some indications of methods employed to improve the quality and robustness of the dataset.

Firstly, the authors mention using data augmentation to estimate ÏƒARU by adding a number of known 'non-detections' with distance of NA to their dataset of detected or simulated calls. This technique can help mitigate potential biases caused by overrepresentation of certain types of data points in the training set. By artificially expanding the dataset with non-detection examples, they aim to create a more balanced representation of both positive and negative cases.

Secondly, the authors describe using a conservative score threshold of 0.95 or higher when classifying positive bobwhite detections. This approach helps reduce the likelihood of false positives, which could introduce bias into the dataset if left unchecked. Additionally, manual review of a random sample of CNN detections allows them to evaluate model accuracy and calculate a false positive rate, further ensuring the reliability of their results.

While these practices do not directly correspond to stratified splitting, oversampling, undersampling, or diverse data collection, they still contribute to addressing data bias within the context of this particular study.