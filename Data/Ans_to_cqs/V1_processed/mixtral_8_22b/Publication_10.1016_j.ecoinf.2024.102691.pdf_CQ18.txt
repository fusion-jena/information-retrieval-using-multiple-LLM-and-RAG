To monitor the model performance during training, several strategies were employed. Firstly, the input image size was fixed at 512 x 512 pixels. Secondly, the maximum batch size was restricted to 4 to manage computational resources effectively. Thirdly, to avoid underfitting, the authors made sure that all models followed back-propagation after accumulating the batch size 32 times. Fourthly, the models were trained using a Stochastic Gradient Descent (SGD) optimizer with an initial learning rate of 0.01 and a cyclic learning rate of 0.2. Lastly, the performance of the models was evaluated using various matrices like precision, recall, and average precision (AP) at different Intersection over Union (IoU) thresholds. These evaluations were conducted after every 300 epochs.