The deep learning models used in this study have several hyperparameters. The learning rate and dropout rate are both set to 0.001. The bias value is set to 0. The resolution of the input data is 224x224 with RGB format, and the inputs are batch normalized before training. The batch size is set to 30 during training, but images are tested one by one. An optimized rectified linear activation, Leaky ReLU, is introduced into the models after convolution or concatenate layer. In MobileNet, the width multiplier is 1.2, and the resolution multiplier is 1. The number of epochs varies depending on the depth of the neural network. Models with less than 100 layers use 60 epochs, while others use 80 epochs. A fully connected layer with softmax activation has 28 nodes, which serves as the classifier during training but is removed during inference. However, the specific optimizer used is not mentioned in the given context.