Based on the given context, it does not directly discuss the specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, I can provide some general insights based on common practices in machine learning and deep learning pipelines.

Data bias can be addressed during preprocessing using various techniques such as stratified splitting, oversampling, undersampling, and collecting diverse data.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of classes or labels in both sets. This ensures that the model learns from a representative sample of the entire dataset.

Oversampling is a technique used when dealing with imbalanced datasets. It involves duplicating examples from the minority class to balance the dataset. Synthetic Minority Over-sampling Technique (SMOTE) is one popular method used for oversampling.

Undersampling is another approach to handle imbalanced datasets. In contrast to oversampling, undersampling reduces the size of the majority class by randomly removing samples until the desired balance is achieved.

Collecting diverse data is also crucial to reduce data bias. By gathering data from different sources, demographics, or environments, the model can better capture the underlying patterns and improve its performance on new, unseen data.

In summary, addressing data bias during preprocessing of the deep learning pipeline can involve techniques like stratified splitting, oversampling, undersampling, and collecting diverse data. These methods help ensure that the model learns from a balanced and representative dataset, ultimately improving its performance and reducing potential biases.