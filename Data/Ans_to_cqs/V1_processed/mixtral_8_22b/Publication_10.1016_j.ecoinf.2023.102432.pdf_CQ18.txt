The study uses k-fold cross validation to evaluate the performance of the models during training. Specifically, it employs 5-fold cross validation, where the dataset is divided into five equal parts or 'folds'. Four folds are used for training the algorithm, while the remaining fold is used for testing. This process is repeated five times, each time with a different fold serving as the test set. The results of these iterations are then combined to produce a more robust estimate of the model's performance. The evaluation metrics used include overall accuracy, producer accuracy, and user accuracy, which are derived from a confusion matrix.