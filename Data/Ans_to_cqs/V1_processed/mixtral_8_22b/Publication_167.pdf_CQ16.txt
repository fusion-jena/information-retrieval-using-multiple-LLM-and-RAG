Based on the given information, there isn't a direct mention of specific criteria used to determine when training is complete. However, we can infer from common machine learning practices that the criteria could involve monitoring the validation loss or accuracy. Typically, training continues until the validation loss plateaus or starts increasing, indicating possible overfitting. This suggests that the model might have started memorizing the training data instead of learning general patterns. Additionally, early stopping can also be employed, where training stops if the validation metric doesn't improve for a specified number of epochs. In this case, the 10-fold cross-validation method was used, suggesting that the average performance across multiple folds may serve as another criterion for determining completion.