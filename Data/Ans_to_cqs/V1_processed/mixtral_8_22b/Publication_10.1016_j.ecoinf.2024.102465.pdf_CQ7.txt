Based on the given context, there isn't a direct mention of the specific criteria used to split the data for deep learning model training into sets such as train, test, or validation. However, it is common practice in machine learning and deep learning to use various methods to divide datasets. Some popular techniques include random splitting, stratified sampling, time series based splitting, etc.

Random splitting involves dividing the dataset randomly into different subsets like training, testing, and validation. Stratified sampling ensures that each subset maintains the same distribution of classes as the original dataset. Time series based splitting is useful when dealing with temporal data, where the order of events matters.

In this particular context, since the research focuses on utilizing deep learning models like ERNIE, LSTM-CNN, and HRNet for tasks such as sentiment analysis and semantic segmentation, it would be reasonable to assume that standard practices were followed while splitting the data. These could involve any of the mentioned techniques depending upon the nature of the dataset and the problem statement.