The provided context does not explicitly mention any specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it is common practice in machine learning and deep learning pipelines to use these techniques to mitigate issues related to class imbalance and ensure fair representation of different classes in the dataset.

Stratified splitting involves dividing the dataset into training and testing sets while maintaining the same distribution of target variables across both sets. Oversampling increases the number of instances from minority classes, while undersampling reduces the number of instances from majority classes. These methods help balance the dataset and improve the performance of the model.

Additionally, collecting diverse data can also be beneficial in addressing data bias. This involves gathering data from various sources and ensuring that the dataset represents all possible scenarios and variations. By doing so, the model will have a better chance of generalizing well to new, unseen data.

While the provided context does not directly discuss these techniques, they are commonly employed in deep learning pipelines to handle data bias and improve overall model performance.