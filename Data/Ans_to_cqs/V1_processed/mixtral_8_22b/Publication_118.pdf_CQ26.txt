Based on the given context, there isn't any specific information about what techniques are used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, it can be noted from the context that the authors have constrained the size of their audio spectrograms to 128 x 128 pixel RGB images with values repeated in each color channel to produce a grayscale image. This might suggest some form of normalization or standardization technique being applied to the input data before feeding into the network. Additionally, the use of a basic auto-encoder architecture with ReLU activation function also suggests that the authors aimed to minimize potential biases that could be introduced by more complex architectures. Nevertheless, without further details regarding the specific steps taken to handle data bias, it cannot be definitively stated what techniques were employed.