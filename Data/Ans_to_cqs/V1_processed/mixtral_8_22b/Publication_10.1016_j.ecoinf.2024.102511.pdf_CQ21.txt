The article does not provide explicit information about the specific postprocessing steps used after model training for this particular study. However, based on common practices in machine learning projects, some possible postprocessing steps could include:

1. Model evaluation metrics: Calculating various performance metrics such as accuracy, precision, recall, or F1 score to evaluate the trained model's effectiveness.

2. Confusion matrix: Creating a confusion matrix to visualize the model's performance by comparing predicted labels against actual labels. This can help identify patterns of misclassifications and areas where the model needs improvement.

3. Cross-validation: Using techniques like k-fold cross-validation to ensure the robustness and generalizability of the model across different subsets of the dataset.

4. Hyperparameter tuning: Adjusting hyperparameters, such as learning rate or regularization strength, to optimize the model's performance further.

5. Feature importance analysis: Examining feature importances to understand which input features contribute most significantly to the model's predictions.

6. Visualizations: Generating saliency maps or other visual representations to gain insights into how the model makes its decisions and what parts of the input data it focuses on during prediction.