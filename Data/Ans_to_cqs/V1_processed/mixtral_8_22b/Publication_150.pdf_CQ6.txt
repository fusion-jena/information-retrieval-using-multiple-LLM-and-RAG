The text does not provide explicit details about the specific preprocessing steps taken before training the deep learning models mentioned. However, it can be inferred from common practices in machine learning that some form of preprocessing would have been applied to prepare the input data. Typically, these steps might include normalization, scaling, and cleaning. Normalization involves adjusting values measured on different scales to a common scale, often between 0 and 1. Scaling refers to rescaling numerical attributes so they fall within a specified range, such as -1 to 1 or 0 to 1. Cleaning involves handling missing or inconsistent data points, outliers, and noise reduction. These preprocessing techniques help improve the quality of the dataset, making it easier for the model to learn patterns and relationships within the data.