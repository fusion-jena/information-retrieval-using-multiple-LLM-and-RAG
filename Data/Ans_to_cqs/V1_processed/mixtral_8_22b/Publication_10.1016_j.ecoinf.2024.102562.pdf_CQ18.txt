Based on the given context, there isn't explicit information about the specific strategy implemented to monitor the model performance during training. However, we do have some clues regarding the evaluation methods used after the training phase. Two standard metrics are mentioned for evaluating the performance of the model: mean average precision (mAP) and recall. These metrics help assess the accuracy of object detection. Additionally, the text mentions using a minimum detection confidence score of 0.7 and an IoU (Intersection over Union) threshold of 0.5. While these details provide insight into the evaluation process, they do not directly address the monitoring strategy during training. Therefore, based on the available context, I cannot provide a definitive answer to the query.