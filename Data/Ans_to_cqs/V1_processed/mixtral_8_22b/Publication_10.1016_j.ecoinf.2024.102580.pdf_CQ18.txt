A strategy implemented to monitor the model performance during training involves dividing the ground-truth dataset into training (80%), validation (10%), and test (10%) sets. This division allows for a good-sized validation and test dataset for evaluating the modelâ€™s accuracy while maximizing the training set. During the training process, each image is subset and cropped into six overlapping patches matching the output size of the network (388 x 388 pixels), resulting in a total training set size of 379 images. Additionally, data augmentation techniques such as random horizontal flips, rotations, zooms, and brightness adjustments are used to increase the diversity of the training set. The model undergoes 300 training cycles with a batch size of two, and the learning rate for the model backbone is set to 10^-5, while the transformer is set to 10^-4. To establish a confidence threshold determining the optimal model performance, Precision and Recall are plotted against the threshold on the validation set. The chosen threshold balances the two metrics, maximizing performance by detecting individuals while minimizing false detections.