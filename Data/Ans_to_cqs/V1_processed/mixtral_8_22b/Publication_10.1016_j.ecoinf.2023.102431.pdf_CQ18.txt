The text does not explicitly mention any specific strategies used to monitor the model performance during training. However, it can be inferred from the information presented that the researchers employed a combination of cross-validation techniques and stepwise variable selection methods to optimize their models.

Cross-validation involves splitting the dataset into multiple subsets, such as training, testing, and validation datasets, to evaluate how well the model generalizes to new, unseen data. This technique helps prevent overfitting and provides a reliable estimate of the model's performance. In this study, the authors have mentioned separate sample sizes for training, validation, and test groups for both species and sex discrimination tasks.

Additionally, the researchers utilized backward stepwise selection to simplify their initial complex model while maintaining high classification accuracy. Stepwise selection is a method for selecting significant variables for inclusion in a regression or classification model. By iteratively removing less influential variables, the researchers aimed to create a simpler yet still accurate model.

Although the text does not directly discuss monitoring strategies like learning curves, early stopping, or regularization techniques, the use of cross-validation and stepwise selection suggests that the researchers were mindful of model performance and sought to minimize overfitting.