The deep learning model used in this study employed the NASnet architecture with a Faster-rcnn backbone, implemented in Tensorflow2. The specific parameters of the model can be found in the TensorFlow Model Zoo under the name "faster\_rcnn\_nas". The learning rate used was 0.008 with a cosine learning rate decay. The model was trained through 200,000 iterations with a batch size of 16 images per iteration. However, the exact details about other hyperparameters such as the optimizer, weight initialization, regularization techniques, etc., are not explicitly mentioned in the given context.