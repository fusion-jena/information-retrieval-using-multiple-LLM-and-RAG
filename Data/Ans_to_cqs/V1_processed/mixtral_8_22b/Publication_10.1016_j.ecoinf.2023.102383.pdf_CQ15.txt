The given context does not explicitly mention any optimization techniques such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) used in the deep learning pipeline. These optimization techniques are typically employed to update the weights of the neural networks during training. Therefore, I cannot provide a helpful answer regarding the optimization techniques used in the deep learning pipeline based on the given context.