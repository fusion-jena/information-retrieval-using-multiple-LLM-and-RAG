The text does not provide explicit information about specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, there are some indications of strategies employed to improve the performance and generalization of the machine learning models.

One approach mentioned is the use of a balanced sampling technique for the test set. In this case, one audio sample out of every five was chosen for each type of anuran call to ensure representation from all classes in the test set. This can help mitigate potential biases by ensuring that the test set contains a fair distribution of examples from different classes.

Additionally, the authors mention using data augmentation to create a more robust training set. By generating ten additional audios for each of the 865 original audio samples, they effectively increase the diversity of the training data. This can also help reduce any potential biases in the dataset by providing a broader range of examples for the model to learn from.

While these approaches do not directly correspond to the techniques listed in the query, they demonstrate efforts to manage data imbalances and promote better model performance through improved data representation and diversity.