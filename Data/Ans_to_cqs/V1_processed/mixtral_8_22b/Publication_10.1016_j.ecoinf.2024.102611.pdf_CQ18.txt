To monitor the model performance during training, the authors have employed a level-wise training, validation, and testing strategy using a Random Forest classifier. They divided their dataset into eleven groups based on visual morphological characteristics, maintaining consistent ratios across these groups to prevent potential biases during classification. These groups consist of multiple plant species varieties, ranging from 7 to 14 plants per group, covering 100 medicinal plant species.

The data was split into three parts: training, validation, and testing, with proportions of 70%, 20%, and 10%, respectively. This division applies to both levels of the hierarchical classification model. Additionally, two new datasets, RTL80 and RTP40, were introduced to evaluate the efficiency of the proposed model. These datasets contained random collections captured in real-time.

Validation and test sets were considered separately to fine-tune the model's hyperparameters, aiming for generalizability and scalability towards unseen datasets. The Random Forest classifier was utilized in both levels of the hierarchical classification model for making group and plant-level predictions. The Gini index served as the splitting criterion for the Random Forest classifier, while the number of estimators (decision trees) was set to 100. Other parameters included setting the random state to 5 and allowing the maximum depth of each decision tree to grow until all leaf nodes contained only samples of the same class.

In summary, the strategy implemented to monitor the model performance during training involves dividing the dataset into training, validation, and testing sets, employing a Random Forest classifier, utilizing the Gini index as the splitting criterion, and adjusting relevant parameters such as the number of estimators, random state, and maximum depth of decision trees.