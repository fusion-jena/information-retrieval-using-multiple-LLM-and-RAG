The text does not provide explicit information about the method used to optimize the hyperparameters of the model. However, it mentions that the'stochastic gradient descent with momentum optimizer' was used for training the AN model in MATLAB, with the initial learning rate set to 0.001 and the maximum number of epochs set to 15 after preliminary tests. This suggests that some form of optimization or tuning was performed during the preliminary tests.

For the classical machine-learning algorithms (AB, GB, HB, and LD), which were run in Python using the scikit-learn toolbox, the hyperparameters were left at the default values, except for the learning rate of GB and HB (set to 0.15) and the tolerance threshold value for LD (set to 1 Ã— 10^-5). Again, there is no explicit mention of the specific optimization method used for these hyperparameters.

Therefore, based on the given context, it cannot be definitively determined whether grid search, random search, or another method was used to optimize the hyperparameters of the model.