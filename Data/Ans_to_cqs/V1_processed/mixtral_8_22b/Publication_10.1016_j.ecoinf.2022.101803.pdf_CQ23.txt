To ensure the generalizability of their deep learning models, the authors employed several strategies. Firstly, they utilized diverse datasets, which helped prevent overfitting and improved the robustness of the models. Secondly, they implemented a nested k-fold cross-validation scheme to optimize the iteration number and mitigate potential overfitting issues. Specifically, they divided each dataset into three subsets: a tuning set (k-2 folds), a validation set (1-fold), and a test set (1-fold). They then trained the model on the tuning set while monitoring its performance on the validation set by calculating the out-of-sample prediction accuracy and taking the median of k-1 folds. This process yielded k medians for each number of iterations, providing a comprehensive evaluation of the model's performance across various scenarios. Lastly, the authors compared their proposed Random Forest (RBF-GFR-RF) model against other methods, including the original Generalized Functional Response (GFR) model from Matthiopoulos et al. (2011). Their results demonstrated that the RBF-GFR-RF model consistently achieved high performance rankings, often placing within the top three. Furthermore, nearly all the methods proposed in this study surpassed the original GFR model, indicating significant improvements in both model design and implementation.