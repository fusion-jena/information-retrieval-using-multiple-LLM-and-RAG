In the given context, several techniques are mentioned for preprocessing the dataset during the deep learning pipeline. However, none of these techniques directly addresses data bias. Instead, they focus on standardizing and enriching the dataset.

Techniques like auto-orientation, resizing, tiling, and filtering are employed to ensure consistent orientation, uniform size, and substantial annotated data in the images. Auto-orientation ensures that all images have the same orientation, while resizing scales them to a uniform size of 640 x 640 pixels. Tiling and filtering help in improving the quality of the images and removing any irrelevant information.

Augmentation plays a significant role in diversifying the dataset by introducing random saturation adjustments to each training example. This increases the number of outputs per example to two, contributing to a more comprehensive and robust training dataset.

However, there is no mention of specific techniques to address data bias, such as stratified splitting, oversampling, undersampling, or diverse data collection. Therefore, based on the provided context, I cannot provide a helpful answer regarding the techniques used to address data bias during preprocessing of the deep learning pipeline.