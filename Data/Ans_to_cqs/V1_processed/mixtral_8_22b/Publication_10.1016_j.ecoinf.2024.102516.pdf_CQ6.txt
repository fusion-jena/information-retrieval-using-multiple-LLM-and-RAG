The given context does not provide explicit information about the specific preprocessing steps involved before training the deep learning models mentioned. However, based on common practices in machine learning and deep learning, some general preprocessing steps could include:

1. Data Cleaning: Removing irrelevant, redundant, or corrupted data points from the dataset.
2. Normalization/Scaling: Scaling the input features to a similar range to ensure that all inputs contribute equally during training. Common methods include min-max scaling, z-score normalization, or unit length normalization.
3. Data Augmentation: Applying transformations like rotation, translation, zooming, cropping, or flipping to increase the diversity of the training set and prevent overfitting. In the given context, horizontal flipping is mentioned as a form of data augmentation.
4. Splitting Datasets: Dividing the dataset into separate subsets for training, validation, and testing purposes.
5. Label Encoding: Converting categorical labels into numerical values if required by the model architecture.