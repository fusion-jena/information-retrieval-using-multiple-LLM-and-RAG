The paper mentions two preprocessing steps before training the deep learning model: resizing and normalization. The patches are first resized to 32x32 pixels, which helps reduce computational complexity while maintaining enough detail for accurate classification. Then, the patches are normalized, which scales the pixel values between 0 and 1. This step ensures that all input features have similar magnitudes, preventing any single feature from dominating the others during training. Additionally, the paper discusses data augmentation techniques such as vertical and horizontal flipping, which help increase the diversity of the training dataset and prevent overfitting. However, these techniques are applied after the initial resizing and normalization steps.