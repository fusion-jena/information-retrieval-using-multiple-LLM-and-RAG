Unfortunately, there isn't enough information available in the given context to provide a detailed explanation about the deployment process of the trained deep learning model. However, it can be assumed that after training the deep learning model using the Benthoz15 dataset, the authors would have serialized their model into a format suitable for deployment. They might have used popular libraries like TensorFlow or PyTorch for this purpose. Afterwards, they could have selected a platform for hosting their model, depending upon factors such as scalability, cost, ease of integration, etc. Some common platforms include cloud services like AWS, Google Cloud, Azure, or even custom servers. Without further details, it cannot be determined exactly how the model was deployed.