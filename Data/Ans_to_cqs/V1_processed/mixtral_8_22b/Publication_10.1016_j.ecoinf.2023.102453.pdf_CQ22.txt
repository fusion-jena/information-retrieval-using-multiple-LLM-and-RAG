In evaluating the performance of a Deep Neural Network (DNN) classification model, several metrics are typically employed. These include Accuracy, Precision, Recall, and F1-Score.

Accuracy is calculated as the ratio of correctly predicted instances to the total instances. However, it might not provide a reliable measure when dealing with imbalanced classes. It is computed using the formula:

Accuracy = (TP + TN) / (TP + FN + TN + FP)

where TP stands for True Positive, TN for True Negative, FN for False Negative, and FP for False Positive.

Precision is another metric used, which represents the proportion of correct positive predictions out of the total predicted positives. It is given by:

Precision = TP / (TP + FP)

Recall, or Sensitivity, measures the proportion of actual positives that were identified correctly. It is expressed as:

Recall = TP / (TP + FN)

Lastly, the F1-Score provides a balance between Precision and Recall, being the Harmonic Mean of these two metrics. Its calculation is as follows:

F1-Score = (2 * Precision * Recall) / (Precision + Recall)

These metrics help assess different aspects of the model's performance, providing a comprehensive evaluation of its effectiveness.