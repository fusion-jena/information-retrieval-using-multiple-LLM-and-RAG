The information provided does not explicitly state the specific hyperparameters such as learning rate or optimizer used in the deep learning model. However, it is mentioned that a three-layer feedforward back-propagation neural network with a 30-20-10 architecture was developed. The activation functions used were 'tansig', 'tansig', and 'purelin' for each layer, respectively. Additionally, 70% of the data was used for training, 15% for validation, and 15% for model testing. Unfortunately, without further details, I cannot provide more specific information about the hyperparameters used in this deep learning model.