The text does not provide explicit details regarding the specific criteria used to determine when training is completed. However, it mentions that the dataset was divided into a "training dataset" containing 60 randomly selected records and a "testing dataset" containing the remaining 29 records. This suggests that the training process might have involved some form of cross-validation, where the performance of the model on the testing dataset could serve as an indicator of its generalization ability.

In machine learning, common criteria used to determine when training should stop include observing a plateau in the validation loss, reaching a predefined number of epochs, or meeting a certain threshold for the desired metric (accuracy, precision, recall, etc.) on the validation set. Without more specific information from the given context, it can only be inferred that similar principles may apply here.