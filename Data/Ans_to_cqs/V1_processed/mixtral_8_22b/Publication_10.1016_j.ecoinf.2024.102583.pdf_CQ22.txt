To assess the performance of their deep learning models, the authors utilized several evaluation metrics. These include the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), Overall Accuracy, Kappa Score, and F1-Score. Each metric provides unique insights into the model's predictive capabilities.

The AUC-ROC measures the ability of the model to distinguish between positive and negative classes. It ranges from 0 to 1, with higher values indicating better performance.

Overall Accuracy represents the proportion of correctly classified instances out of the total number of instances. This can be calculated as (TP+TN)/(TP+TN+FP+FN), where TP is True Positive, TN is True Negative, FP is False Positive, and FN is False Negative.

The Kappa Score is a statistical measure that compares observed accuracy with expected accuracy (random chance). It ranges from -1 to 1, with 1 representing perfect agreement between the model and actual class labels.

Lastly, the F1-Score is the harmonic mean of precision and recall. It considers both false positives and false negatives, providing a more balanced view of the model's performance compared to using only accuracy or precision.