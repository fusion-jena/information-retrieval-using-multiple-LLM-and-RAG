The given context does not provide information on the specific optimization techniques used in a deep learning pipeline such as Stochastic Gradient Descent (SGD) or Adam. However, it mentions several machine learning models like Random Forest (RF), Artificial Neural Network (ANN), and others. In general, optimization techniques play a crucial role in training these models by minimizing their loss functions. For instance, ANNs can use backpropagation with gradient descent algorithms like SGD or adaptive methods like Adam for optimization during training. But without explicit mention in the provided context, we cannot confirm which optimization techniques are applied in this case.