During the training phase, the model performance was monitored through a validation set, which comprised 10% of the total preprocessed data. This approach allowed for continuous evaluation of the model's performance on unseen data while adjusting its parameters. Additionally, hyper-parameter tuning was carried out using GridSearchCV with cross-validation (cv = 10). This method systematically explores various combinations of hyperparameters to identify the best configuration for optimizing the model's performance. By employing this strategy, the researchers aimed to ensure that the final model would have strong predictive capabilities and avoid overfitting to the training data.