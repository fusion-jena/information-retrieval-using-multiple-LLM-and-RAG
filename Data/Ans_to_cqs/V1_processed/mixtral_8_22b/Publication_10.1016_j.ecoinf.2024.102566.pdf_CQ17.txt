The given context does not provide information about the regularization methods used to prevent overfitting in a deep learning pipeline. However, some common regularization techniques include Dropout, which randomly sets a fraction rate of input units to 0 during training time, helping reduce overfitting by providing a way of approximately combining exponentially many different neural network architectures efficiently; and L2 Regularization, also known as weight decay, where the weights are penalized based on their size, discouraging large weights and thus preventing overfitting. Other methods include early stopping, data augmentation, and batch normalization.

Based on the provided context, it appears that the study focused on estimating forest biomass using small footprint LiDAR data and an individual tree-based approach that incorporated training data. The authors utilized various references related to spatial distribution and validation of the results but did not mention any specific regularization methods used in their methodology.