After the model training, there are several postprocessing steps that can be performed depending on the specific requirements of the project or study. Based on the given context, two main postprocessing steps are mentioned: metrics calculation and confusion matrix generation.

Metrics calculation involves evaluating the performance of the trained model using various evaluation metrics like accuracy, precision, recall, F1 score, etc. These metrics help assess the effectiveness of the model in making accurate predictions. In the given context, the authors mention that they achieved an accuracy of 0.98 and 0.95 on the train and validation sets, respectively, using data augmentation. They also discuss the impact of imbalanced classes on the results and provide a normalized confusion matrix to better understand the distribution of errors across different classes.

Confusion matrix generation is another essential step in postprocessing. A confusion matrix is a table that summarizes the performance of a classification model by comparing actual values against predicted ones. This helps visualize the types of errors made by the model during prediction. In the given context, the authors generate a non-normalized and a normalized confusion matrix to analyze the distribution of errors between the cactus and non-cactus classes.

Although not explicitly mentioned in the provided context, saliency maps can also be generated as part of postprocessing. Saliency maps highlight the regions of input images that contribute most significantly to the final output of the model. This technique can help identify which parts of the image are crucial for correct classification and improve interpretability.

In summary, the postprocessing steps discussed in the given context include metrics calculation and generating confusion matrices. Additionally, creating saliency maps may also be considered as a valuable postprocessing step to enhance understanding and interpretation of the model's behavior.