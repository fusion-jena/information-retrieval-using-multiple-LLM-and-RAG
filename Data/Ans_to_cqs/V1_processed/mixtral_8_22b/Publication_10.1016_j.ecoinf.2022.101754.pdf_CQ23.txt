To ensure the generalizability of their deep learning model, the authors employed several strategies. Firstly, they adopted a training-and-test approach with stratification splitting. This method involves dividing the dataset into two parts - one for training the model and another for testing its performance. By employing stratification splitting, the authors ensured that both sets contained representative samples from all classes or categories present in the original dataset. Furthermore, this process was repeated 100 times with different splits to minimize bias and increase robustness. Secondly, tuning of the hyperparameters was conducted on the training set for each split. Hyperparameters are parameters whose values are set before the commencement of the learning process and remain constant throughout it. They play a crucial role in determining the overall performance of the model. Lastly, the authors also applied cross-validation during the evaluation phase. Cross-validation is a technique used to assess how well a statistical model will generalize to an independent dataset. It does so by partitioning the original sample into subsets such that the analysis is initially performed on a single subset while the other subset(s) are retained for subsequent use in confirming and validating the initial analysis. These measures collectively contribute towards enhancing the reliability and applicability of the developed deep learning model across diverse datasets.