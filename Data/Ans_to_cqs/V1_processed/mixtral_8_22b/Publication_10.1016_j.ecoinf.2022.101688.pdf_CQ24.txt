The text does not provide explicit details about handling randomness in the deep learning pipeline, such as managing random seed values. However, it mentions that the weights in the output layer of the Convolutional Neural Network (CNN) were randomly initialized. Additionally, the data splitting process involved randomly selecting entire audio files for training (60%) and testing (40%). These steps suggest that some level of randomness was introduced during model initialization and data partitioning.

To manage randomness in the deep learning pipeline, one common strategy is setting a specific seed value before initializing any part of the model or processing the data. By doing so, researchers can reproduce their results consistently across multiple runs. Another strategy involves conducting multiple trials with different seeds and reporting the aggregated performance metrics, such as mean and standard deviation, to account for variability due to randomness.

Although the given context does not explicitly discuss these strategies, they are commonly employed in deep learning research to address randomness concerns.