The deep learning model used in this research employed the ResNet50 architecture with an Adam optimizer. The model was trained from scratch for 55 epochs with a one-cycle learning rate policy. This policy had a minimum learning rate of 0.000001 and a maximum learning rate of 0.001. Different hyperparameters were explored, and those that yielded the best results for training the final model were chosen. However, the specific values or ranges of these other hyperparameters are not explicitly mentioned in the given context.