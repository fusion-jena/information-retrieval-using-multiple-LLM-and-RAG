The given context does not provide information regarding the specific optimization techniques used in the deep learning pipeline. However, common optimization techniques used in deep learning include Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), Root Mean Square Propagation (RMSProp), and others. These methods help minimize the cost function during the training process. Without explicit mention in the provided context, one cannot definitively state which optimization technique was utilized in this particular case.