The hyperparameters considered for tuning in the deep learning model include the optimizer, activation function, initial learning rate, learning rate drop period, learning rate drop factor, and the number of neurons. These hyperparameters were chosen based on their demonstrated effectiveness in previous studies. The Hybrid Hyperparameter Optimization Scheme (HHOS) was employed to find the optimal values for these hyperparameters. This scheme combines manual and random search methods sequentially. Firstly, a manual search was conducted to identify potential optimal hyperparameter values and narrow down the search space. Then, a random search method was applied to explore different combinations of hyperparameters within the reduced search space. Through this process, the Fine-tuned EfficientNetB0 model achieved the highest accuracy of 99.12%.