Based on the given context, there isn't any direct mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some relevant information regarding addressing potential issues like overfitting and autocorrelations in datasets can be found.

To prevent overfitting in XGBoost, a nested k-fold cross-validation scheme is employed. This involves splitting each dataset into three subsets: the tuning set (k-2 folds), validation set (1-fold), and test set (1-fold). By training the model on the tuning set and monitoring its performance on the validation set, the optimal number of iterations can be determined without causing overfitting.

Additionally, the context mentions the implementation of a block cross-validation approach to handle autocorrelation in dataset structures. This method is applied to a simulated dataset with a spatial structure based on various scenarios. Each scenario consists of 500 observations representing a sub-population in a different landscape. These scenarios are then utilized as dataset blocks when applying the models.

In conclusion, while the context does not directly discuss techniques for handling data bias during preprocessing, it highlights strategies for managing overfitting and autocorrelations in datasets, namely nested k-fold cross-validation and block cross-validation.