The provided context does not explicitly mention specific strategies employed to handle randomness in the deep learning pipeline, such as managing random seed values. However, it does indicate that during the training phase, the model was selected based on its performance on the validation set rather than the training set. This approach helps prevent overfitting, which could potentially mitigate some effects of randomness introduced by factors like initial weights or random seed values. Additionally, the use of a patch size of 1024 x 1024 pixels during inference suggests that the authors may have used techniques like sliding windows or tiling to manage larger input sizes, although this doesn't directly relate to handling randomness. It would be beneficial to refer to other sources or resources for more detailed information regarding strategies to handle randomness in deep learning pipelines.