Based on the given context, there isn't explicit information about specific measures taken to ensure the generalizability of the deep learning model such as diverse datasets, cross-validation, or stratified splitting. However, some aspects related to the robustness and applicability of the model can be inferred.

Firstly, the experiments were conducted on a small-sized dataset without data augmentation, demonstrating that it is feasible to use small datasets to train deep learning models effectively. This suggests that the model might still work well even when dealing with limited resources.

Secondly, two models - MG and MO - were used, and they achieved good training results and performed well in their respective validation sets. This implies that the models were tested separately, ensuring that each one had its unique validation set. Although this does not directly indicate cross-validation or stratified splitting, it shows that the models were evaluated independently, contributing to their reliability.

Lastly, the context mentions that determining if the models can achieve similar good results with complex images from different sources would require further experiments after gathering more images. This statement indicates that the researchers acknowledge the need for additional testing with varied datasets to validate the model's performance across multiple scenarios.

In conclusion, while the context does not provide direct evidence of specific techniques like diverse datasets, cross-validation, or stratified splitting being employed to ensure the generalizability of the deep learning model, it does suggest that the study considered certain factors related to the model's robustness and applicability. These include working with small datasets, evaluating separate models individually, and recognizing the necessity for future tests involving diverse image sources.