Based on the given information, it appears that the specific criteria used to determine when training is complete are not explicitly mentioned. However, we can infer some possible methods based on common practices in machine learning.

One commonly used criterion is the validation loss plateau. Training continues until the validation error stops decreasing or starts increasing, indicating that the model might be overfitting the training data. Another method could involve setting a predefined maximum number of epochs or iterations, after which training would stop regardless of the model's performance.

In this case, the text mentions that the optimal number of neurons in the hidden layer was determined by incrementally adjusting their count to find the configuration yielding the best results. This suggests that the model's performance on the validation set during training might have been monitored to decide when to stop adding more neurons.

Additionally, the use of various statistical metrics such as Mean Absolute Percentage Error (MAPE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and correlation coefficient (R) indicates that these measures likely played a role in evaluating the model's performance during training and determining its completion.