The given context does not directly discuss regularization methods used to prevent overfitting in the deep learning pipeline such as dropout or L2 regularization. However, it mentions that modeling package options allow for automated tuning for parameters through resampling and standard default values to reach the most accurate final model configuration. This could potentially include regularization techniques like dropout or L2 regularization, though it is not explicitly stated. Additionally, the text discusses using random forests, which can help reduce overfitting by creating multiple decision trees and averaging their results. But again, this is not a direct discussion of regularization methods specific to deep learning pipelines.