The text does not provide explicit information about the strategy used to monitor the model performance during training. However, it mentions that these models are trained using stochastic gradient descent, which is a common optimization technique used in machine learning. This method involves iteratively updating the model parameters to minimize the error between predicted and actual outputs. To monitor the model performance during this process, one could use various strategies like tracking metrics such as loss function values, accuracy, precision, recall, F1 score, etc., over epochs or batches. Additionally, techniques like cross-validation, early stopping, or learning rate scheduling might be employed to prevent overfitting and ensure optimal model performance. But without more specific details, I cannot definitively state the exact strategy used in this case.