The strategy implemented to monitor the model performance during training involves the use of a confusion matrix. This matrix is a parameter used to validate the performance of a machine learning model and tells us about the accomplishment of the classification problem. Essential parameters of the confusion matrix include True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN). These parameters help evaluate the model's ability to accurately predict bleached and unbleached corals.

Additionally, other metrics such as Sensitivity (TPR), Specificity (Sy), Accuracy, F1-score, and Cohen's Kappa (Îº) are derived from the confusion matrix to further assess the model's performance. For instance, Sensitivity measures the proportion of actual positives that were correctly identified, while Specificity measures the proportion of negatives that were correctly identified. Accuracy represents the overall effectiveness of the model, whereas F1-score balances both precision and recall. Lastly, Cohen's Kappa evaluates the agreement between predicted and observed values, considering the possibility of chance agreement.

In summary, the strategy employed to monitor the model performance during training revolves around utilizing a confusion matrix and various related metrics to gauge the model's efficacy in distinguishing between bleached and unbleached corals.