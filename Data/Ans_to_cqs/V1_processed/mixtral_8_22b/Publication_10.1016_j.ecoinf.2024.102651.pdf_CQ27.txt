The provided context does not contain information about the specific process followed to deploy the trained deep learning models mentioned. However, generally speaking, after training a deep learning model, it needs to be serialized into a format that can be loaded for use in applications or services. This often involves saving the model architecture and weights to disk using popular formats such as HDF5, ONNX, TensorFlow SavedModel, PyTorch TorchScript, etc. Once the model is saved, it can then be deployed onto various platforms depending on the application requirements. These could include cloud platforms like AWS, Google Cloud, Azure, edge devices, mobile devices, web browsers, etc. Each platform may require different deployment strategies and tools, but common ones include Flask, Django, FastAPI, TensorFlow Serving, TorchServe, MLflow, etc. Again, this is a general overview and the exact steps would depend on the specific details of the project.