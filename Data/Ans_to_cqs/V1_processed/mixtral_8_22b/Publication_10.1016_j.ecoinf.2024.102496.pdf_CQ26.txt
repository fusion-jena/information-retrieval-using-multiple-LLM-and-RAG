There are several techniques used to address data bias during preprocessing of the deep learning pipeline. These include stratified splitting, oversampling, undersampling, and diverse data collection.

Stratified splitting involves dividing the dataset into training and testing sets while preserving the percentage of samples for each class. This ensures that the distribution of classes remains similar between the two datasets, reducing any potential bias introduced by imbalanced classes.

Oversampling is a technique where additional copies of minority class examples are added to the dataset to balance it. This can be done randomly or through synthetic sample generation using methods like SMOTE (Synthetic Minority Over-sampling Technique). Oversampling helps prevent the model from becoming biased towards the majority class.

Undersampling is another approach to addressing data bias, where examples from the majority class are removed until both classes have equal representation. However, this method may lead to loss of important information if too many instances are discarded.

Diverse data collection aims to gather a wide range of representative samples to ensure that the trained model generalizes well across different scenarios. This includes collecting data from various sources, demographics, geographical locations, etc., depending on the specific application.

These techniques help mitigate data bias during preprocessing of the deep learning pipeline, ensuring fairer and more accurate predictions.