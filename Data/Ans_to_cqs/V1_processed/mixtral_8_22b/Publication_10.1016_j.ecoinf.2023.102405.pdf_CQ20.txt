The provided context does not explicitly mention which specific hardware resources were used for training the deep learning model. However, it can be assumed that a powerful computational resource such as Graphical Processing Units (GPUs) or Tensor Processing Units (TPUs) would have been utilized due to their ability to accelerate machine learning tasks like training neural networks. These specialized processors offer parallel processing capabilities, enabling faster computation of complex mathematical operations required during the training phase of deep learning models. Therefore, while the exact type of hardware resource isn't specified, it is likely that either GPUs or TPUs were employed for this purpose.