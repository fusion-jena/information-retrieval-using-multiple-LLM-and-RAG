The strategy implemented to monitor the model performance during training was folded cross-validation. This involved partitioning the dataset into ten equal sections or 'folds'. Each fold served as the test set once, while the remaining nine were used for training. The trained model was then evaluated on the test set, and the results were recorded. This process was repeated until each fold had been used as the test set. The average of these outcomes provided a comprehensive assessment of the model's performance. This approach helped maintain high detection accuracy and allowed for rigorous control over external factors that might influence the results, thus enhancing the precision and reliability of the tests.