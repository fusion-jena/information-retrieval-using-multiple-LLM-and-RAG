Unfortunately, based on the given context, there isn't enough information to determine what specific measures were taken to ensure the generalizability of any particular deep learning model. The context does mention various sources related to deep learning, including papers about optogenetics, clustering algorithms, and articles discussing different deep learning frameworks like TensorFlow and Theano. However, none of these directly address the specific techniques used to improve the generalizability of a deep learning model. Common approaches include using diverse datasets, employing cross-validation, or stratified splitting during training and testing phases. Without further details regarding the specific deep learning models being discussed, I cannot provide a more precise response.