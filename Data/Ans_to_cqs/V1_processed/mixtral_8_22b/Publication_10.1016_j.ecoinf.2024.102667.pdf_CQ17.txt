Based on the given context, there is no direct mention or discussion about regularization methods used to prevent overfitting in the deep learning pipeline. Regularization methods such as dropout and L2 regularization are techniques employed during model training to avoid overfitting by adding a penalty term to the loss function or randomly dropping out neurons. However, since this topic is not covered within the provided context, I cannot provide specific details regarding the usage of these methods in this case.