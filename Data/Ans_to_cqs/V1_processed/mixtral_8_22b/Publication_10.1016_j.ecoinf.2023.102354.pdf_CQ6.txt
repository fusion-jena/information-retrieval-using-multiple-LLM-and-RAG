Before training a deep learning model, several preprocessing steps are typically involved to ensure the data is suitable for training. These steps can include:

1. Data Cleaning: This involves removing any irrelevant, incorrect, or duplicate data points from the dataset. It also includes handling missing values by either filling them with appropriate values or dropping those records altogether.

2. Normalization/Standardization: Deep learning models often perform better when input features are scaled to a similar range. Normalization scales the data between 0 and 1, while standardization transforms the data to have a mean of 0 and a standard deviation of 1. Both methods help prevent features with larger magnitudes from dominating the learning process.

3. Feature Selection/Extraction: Selecting relevant features helps reduce dimensionality and improve model performance. Techniques like Principal Component Analysis (PCA) can be used for feature extraction, creating new features based on linear combinations of existing ones.

4. Encoding Categorical Variables: Since deep learning models work primarily with numerical inputs, categorical variables need to be converted into numerical form. One common method is one-hot encoding, which creates binary columns for each category.

5. Splitting Dataset: The dataset should be split into training, validation, and testing sets. Training set is used to train the model, validation set is used to tune hyperparameters, and test set is used to evaluate the final model performance.

These preprocessing steps may vary depending on the specific requirements of the problem and the nature of the available data. However, they generally contribute towards improving the overall accuracy and efficiency of the deep learning model.