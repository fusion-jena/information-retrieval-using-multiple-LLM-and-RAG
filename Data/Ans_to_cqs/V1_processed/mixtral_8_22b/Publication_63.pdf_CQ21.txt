After the model training, several postprocessing steps can be performed depending on the specific requirements of the project or analysis. However, based on the given context, there is no explicit mention of any specific postprocessing steps such as generating saliency maps, calculating metrics like confusion matrices, precision, recall, F1 score, etc. Nevertheless, some general postprocessing steps can still be identified from the context.

Firstly, it is mentioned that the Mean Absolute Error (MAE) of the validation dataset was calculated after each epoch during the training phase. This indicates that evaluating the performance of the model using appropriate metrics is part of the postprocessing step. Additionally, the context mentions that the models were trained until the validation MAE stopped improving, which suggests monitoring the model's performance over time and deciding when to stop training based on certain criteria.

Secondly, the context states that the trained model was then applied to the test dataset. Applying the trained model to new, unseen data is another common postprocessing step. It allows us to evaluate how well our model has learned to generalize from the training data and make predictions on previously unseen examples.

Lastly, although not explicitly stated in the context, visualizing the results and interpreting them is also an important aspect of postprocessing. For example, plotting the predicted vs actual values, analyzing the residuals, or creating visualizations to understand the patterns in the data could provide valuable insights about the model's performance and help identify areas for improvement.

Therefore, based on the given context, the postprocessing steps involved after the model training include evaluating the model's performance using appropriate metrics, applying the trained model to new data, and potentially visualizing and interpreting the results.