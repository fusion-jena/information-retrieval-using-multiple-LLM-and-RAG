According to the given context, the data was split into training and validation sets using a 60%-40% ratio. This means that 60% of the total samples were allocated for training the deep learning models, while the remaining 40% were reserved for validating their performance. No specific information is available regarding any separate testing dataset. However, typically, such datasets are created from the initial pool of samples before splitting them into training and validation sets. In this case, the distribution of samples can be seen in Figure 8, where there were no mis-collected samples found among the automatically gathered ones.

The data consisted of six batches with different combinations of input features derived from various sources like Sentinel-2 and Sentinel-1 satellite imagery. These included visible (RGB) bands, multispectral (MS) bands, spectral indices, spectral features, textural features, and Digital Surface Model (DSM). Each batch had its unique combination of these features, allowing the exploration of diverse inputs for the deep learning models.

As for the machine learning algorithm employed here, Support Vector Machines (SVM) was utilized due to its advantages in handling high dimensional spaces and robustness against minor changes in the feature extraction process. The SVM parameters were set based on Google Earth Engine's guidelines, specifically choosing Radial Basis Function (RBF) as the kernel type and setting the gamma (Î³) and cost parameters to 0.5 and 10, respectively.

In summary, the data was divided into training and validation sets according to a 60%-40% ratio without specifying a separate testing dataset. Six distinct batches containing varying combinations of input features were prepared for analysis. Lastly, the SVM algorithm was selected for modeling purposes, with its parameters configured based on Google Earth Engine's recommendations.