To ensure the generalizability of their deep learning model, M. Abdelgadir et al. employed several measures. They utilized diverse datasets by including eight different machine learning algorithms to generate their predictive models. These algorithms included Generalized Linear Model (GLM), Support Vector Machine (SVM), Multivariate Adaptive Regression Spline (MARS), Random Forest (RF), Flexible Discriminant Analysis (FDA), Classification and Regression Trees (CART), Generalized Boosting regression Model (GBM), and Maximum-Entropy learning (MAXENT) for habitat suitability prediction.

Cross-validation was performed through 10 K-fold cross-validation and 10-fold bootstrapping. This process helped evaluate the models based on various metrics such as Area Under the Curve (AUC), True Skill Statistics (TSS), Cohen’s KAPPA, point-biserial correlation (COR), and Receiver Operator Characteristics (ROC). Bootstrapping was specifically used to provide unbiased predictive accuracy with a sufficiently low variance.

Stratified splitting was applied by dividing the data into training and testing sets, with 70% of each taxon’s data records being used for training and the remaining 30% for testing. This ensured that both the training and testing datasets contained representative samples from each class or category, thereby improving the model’s ability to generalize well to new, unseen data.

Overall, these measures aimed to enhance the robustness and reliability of the deep learning model, ensuring it could effectively handle diverse datasets and produce accurate predictions across various scenarios.