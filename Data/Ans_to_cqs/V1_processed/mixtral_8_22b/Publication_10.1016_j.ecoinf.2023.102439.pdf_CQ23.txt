Based on the given information, it appears that the researchers took several steps to ensure the generalizability of their deep learning model. Firstly, they used a diverse dataset comprising data from two different study areas - Iznik and Alanya. This allowed the model to learn patterns and relationships from multiple sources, thereby increasing its applicability across different scenarios.

Secondly, the researchers employed a specific data partitioning strategy where they allocated 60% of the data for training and the remaining 40% for validation and testing. This approach helps prevent overfitting, which occurs when a model performs well on the training data but poorly on new, unseen data. By reserving a portion of the data solely for validation and testing, the researchers could assess how well the model would perform on previously unseen data, thus ensuring its generalizability.

Lastly, the researchers evaluated the performance of their model using several statistical metrics such as Mean Absolute Percent Error (MAPE), Mean Square Error (MSE), Root Mean Square Error (RMSE), and correlation coefficient (R). These metrics measure the deviation between the predicted and actual observed values, providing insights into the accuracy and predictive capability of the model. By using these metrics, the researchers could objectively determine whether their model was performing well not only on the training data but also on the validation and test datasets, further enhancing its generalizability.