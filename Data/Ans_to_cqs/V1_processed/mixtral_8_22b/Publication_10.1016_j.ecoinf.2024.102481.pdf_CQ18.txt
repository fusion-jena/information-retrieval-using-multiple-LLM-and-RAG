During the training process of the Random Forest (RF) classifier for determining the maturity classes of Chilean Hake, the model performance was monitored by utilizing the Out-of-Bag (OOB) error. This method involves training the models on bootstrapped data, where the excluded portion at each iteration serves as validation data for calculating generalization error. By employing this approach, it becomes possible to tune two crucial hyperparameters: the number of covariates randomly selected before growing each tree (mtry) and the total number of trees (ntree) combined for the forest. Consequently, through this procedure, the optimal values of mtry = 2 and ntree = 500 were determined (Supplementary Figs. S1 and S2).