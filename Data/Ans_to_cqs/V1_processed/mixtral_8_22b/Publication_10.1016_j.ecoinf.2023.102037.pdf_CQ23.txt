The authors took several measures to ensure the generalizability of their deep learning model. Firstly, they avoided using weak validation procedures such as random data splitting, which could lead to overestimation of model performance. Instead, they opted for a more robust approach by splitting their data on the sticky plate level. This means that all insects belonging to the same sticky plate image were kept together in the same dataset (training, validation, or testing). This method allowed them to validate their model's performance in a practical manner, simulating how the model would be used in real life - predicting a class for any given object it detects on unseen sticky plate images.

Additionally, they also considered the issue of broad insect classes, which are easier to classify due to their distinct differences. They aimed to address this limitation by focusing on datasets with more specific insect classes, making classification more challenging and improving the model's ability to generalize.

Furthermore, they employed a technique called "tiling" to find regions of interest within the sticky plate images containing the maximum number of complete bounding boxes. This process involved breaking down large images into smaller tiles, allowing the model to focus on relevant areas and improve its accuracy.

Lastly, they utilized the "YOLOv5" model along with the "Slicing Aided Hyper Inference" (SAHI) technique to apply their model to sticky plate images. These methods further contributed to enhancing the model's performance and ensuring its applicability across various scenarios.