After the model training process, several postprocessing steps can be taken depending on the specific requirements of the task or project. Here are some common postprocessing steps:

1. Model Evaluation: This involves calculating various metrics such as accuracy, precision, recall, F1 score, ROC AUC, etc., to evaluate the performance of the trained model. These metrics help us understand how well our model has learned from the data and how accurately it predicts new instances.

2. Confusion Matrix: It is a table used to describe the performance of a classification model. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class. The confusion matrix provides detailed information about true positives, false negatives, false positives, and true negatives which can further be used to calculate other evaluation metrics like precision, recall, and F1 score.

3. Saliency Maps: In case of image data, saliency maps can be generated to visualize the regions of input images that contribute most towards the final prediction made by the model. This helps in understanding what features the model focuses on during its decision making process.

4. Hyperparameter Tuning: After evaluating the initial model, hyperparameters may need to be adjusted for better results. Techniques such as Grid Search, Randomized Search, Bayesian Optimization, etc., can be employed for this purpose.

In the given context, no explicit mention of these postprocessing steps is found. However, we do see that the Support Vector Machine (SVM) algorithm was implemented in MATLAB R2016a using the libsvm package. Also, parameter values were chosen based on Root Mean Square Error Cross Validation (RMSEcv) values. Therefore, it can be assumed that similar postprocessing steps might have been followed here as well.