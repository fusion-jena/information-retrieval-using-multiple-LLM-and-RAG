To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the dataset was stratified before being split into three parts: training (60%), validation (20%), and testing (20%). This stratification helped maintain class proportions across all parts, ensuring that each subset had a representative distribution of classes. Secondly, the models were trained on an NVIDIA 3090 GPU with a 256 x 256 image input size. Parameter tuning was also conducted, resulting in setting the learning rate, batch size, and number of epochs to 0.0001, 8, and 30, respectively. These steps ensured that the model could learn from diverse data and avoid overfitting or underfitting. Lastly, the model's performance was continuously assessed using the validation set during training, and the performance of the testing set guided the final decision. This approach allowed for regular monitoring of the model's progress and adjustments if necessary, further enhancing its generalizability.