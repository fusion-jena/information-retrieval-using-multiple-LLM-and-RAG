Based on the given information, there isn't any explicit mention of the specific process followed to deploy the trained deep learning model. However, some details can be inferred about the platforms and tools used during the development and testing phases.

The experiments were conducted on a desktop computer running Windows 10 64-bit professional operating system, equipped with 128GB memory, 16 cores, 32 threads, and a 3.40 GHz frequency processor. Additionally, it had a 24GB GPU.

As for software, Anaconda3, PyCharm 2020.1, Python 3.7, TensorFlow 2.6, and MATLAB 2018b were utilized. TensorFlow 2.6 served as the deep learning platform, while MATLAB 2018b was employed for data processing purposes.

Although not explicitly stated, it could be assumed that the deployment process might involve saving the trained model weights and architecture, possibly through model serialization techniques like checkpointing or exporting the entire model as a single file. Then, these saved files would be loaded onto the desired platform for further use.

However, without more precise information regarding the deployment process, this remains speculative. It is recommended to refer back to the original source material or consult with the authors for accurate details.