The authors of the paper did not explicitly mention the specific data annotation techniques used in their deep learning pipeline. However, they mentioned that they worked with biology experts to label many videos and created a training database composed of 13,000 fish thumbnails. They also stated that each thumbnail contained only one labeled-fish. Based on these statements, it can be inferred that the authors used bounding box annotation to identify and label individual fish instances within the video frames. Additionally, they mentioned adding a class for the background, which was constituted with random thumbnails of the background and specific background thumbnails taken around the fish thumbnails. This suggests that they may have also used semantic segmentation or instance segmentation techniques to differentiate between foreground objects (i.e., fish) and background elements.