To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the dataset was divided into training and test sets, with 80% of the data allocated for training and the remaining 20% for testing. This division aimed to maximize model training while preserving enough data for robust model validation. The division was carried out through random sampling to guarantee that both subsets represented the entire dataset accurately and minimize the risk of bias. Randomization helped maintain the distribution of crucial features and target variables across both training and test sets, thereby enhancing the model's generalizability.

Secondly, the scikit-learn function GridSearchCV was employed to carefully tune the hyperparameters of each model within the training set. This step aimed to improve their predictive performance. Five-fold cross-validation was utilized, and negative mean square error served as the target measure. After completing the hyperparameter optimization process, the performance metrics outlined in Section 2.5 were thoroughly assessed using the designated test set. Based on these performance metrics, the most efficient models for each target variable were identified.

Lastly, Table 4 provides further information regarding the chosen prediction model, including its hyperparameters, parameters selected during the 5-fold cross-validation, and any adjustments made to the hyperparameters based on the selection criteria. These steps collectively contributed to ensuring the generalizability of the deep learning model.