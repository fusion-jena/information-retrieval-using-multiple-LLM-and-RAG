The provided context does not explicitly mention which optimization techniques were used in the deep learning pipeline. Therefore, it is not possible to provide a definitive answer based solely on this information. However, some commonly used optimization techniques in deep learning pipelines include Stochastic Gradient Descent (SGD), Adaptive Moment Estimation (Adam), Root Mean Square Propagation (RMSProp), and others. These methods help minimize the loss function during training by adjusting the model parameters iteratively. Without further details about the specific deep learning pipeline used in this study, it would be speculative to suggest which optimization technique was employed.