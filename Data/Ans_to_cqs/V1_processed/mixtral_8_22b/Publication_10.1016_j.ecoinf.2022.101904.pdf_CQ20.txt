The hardware resources used for training the deep learning models in this study include an Intel Core i7-10750H 2.60 GHz CPU, GeForce RTX 2070-MaxQ GPU, and 16GB RAM. These resources were used to train various models, including the Swin Transformer classifier, CoAtNet algorithm, and the proposed 3DUNetGSFormer. The Swin Transformer classifier had the least cost in terms of time, requiring approximately 1.5 hours for its required training time, while the CoAtNet algorithm required about 5 hours for its training. The proposed 3DUNetGSFormer required around 3.5 hours for its training time.