During the validation phase of the machine learning algorithms, a K-fold cross-validation technique was implemented. Specifically, a four-fold cross-validation was conducted on the training dataset. In this approach, the feature set was randomly divided into four mutually exclusive folds via stratified sampling. Each fold acted as the validation set, while the remaining three folds formed the training set for model training. To handle class imbalance issues, random under-sampling (RUS) was applied to the training set, leaving the validation set untouched. The model was then trained using the balanced three-fold training dataset for a certain number of epochs and subsequently evaluated on the validation fold to produce predictions for that particular fold. This procedure was repeated four times with different validation folds. By employing this K-fold cross-validation technique, the researchers aimed to optimize the use of both on-site and remote sensing datasets, incorporating them thoroughly into both training and validation stages.