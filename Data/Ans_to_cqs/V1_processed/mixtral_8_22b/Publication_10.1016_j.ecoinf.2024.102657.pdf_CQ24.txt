The text does not provide explicit details about handling randomness in the deep learning pipeline, such as managing random seed values. However, some implicit strategies can be inferred from the given context. For instance, the authors mention using 80% of the full dataset to train and validate the CNN spectrogram classifier and to train the k-NN location classifier, while reserving 20% of the dataset to test the system's ability to classify songs correctly. This approach suggests that the authors may have used a fixed random seed or a consistent methodology to ensure reproducibility and minimize the impact of randomness during model training and evaluation. Additionally, the use of a validation set to tune the hyperparameters of the CNN indicates that the authors aimed to optimize their models without overfitting them to specific subsets of the data. While these practices do not explicitly address randomness related to seed values, they demonstrate efforts to maintain consistency and reliability throughout the deep learning pipeline.