To ensure the generalizability of their deep learning model, the authors took several measures. Firstly, they created a diverse dataset consisting of 6570 images of insects belonging to three different genera (Triatoma, Rhodnius, and Panstrongylus). This diversity in the dataset helped prevent overfitting and improved the model's ability to generalize well to unseen data. Secondly, they split the dataset into training (80%) and testing sets (20%). By doing so, they could train the model using one set of data and evaluate its performance on another independent set, which is crucial for understanding how well the model can perform on new, unseen data. Lastly, they repeated this training-testing process ten times for each algorithm to gauge performance consistency. In each of these pseudo-replicate runs, all five algorithms used the same training and testing picture subsets. These steps ensured that the results obtained were not due to chance and that the model would likely perform similarly when applied to other datasets.