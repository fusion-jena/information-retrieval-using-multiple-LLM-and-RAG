Unfortunately, the given context does not provide information about the specific hardware resources used for training the deep learning models like ResNet or GoogLeNet. However, typically, deep learning models require significant computational power due to their complex nature and large datasets. Therefore, Graphics Processing Units (GPUs) are often used for training deep learning models because they can perform parallel operations more efficiently than Central Processing Units (CPUs). Recently, Tensor Processing Units (TPUs) designed specifically for machine learning tasks have also been introduced. But without explicit information, I cannot confirm whether GPUs, TPUs, or any other hardware resources were used for training the mentioned models.