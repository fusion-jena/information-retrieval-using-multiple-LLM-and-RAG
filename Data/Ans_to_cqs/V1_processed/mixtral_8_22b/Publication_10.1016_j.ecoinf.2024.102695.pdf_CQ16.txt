The training process uses an early stopping strategy to determine when training is complete. Early stopping is a form of regularization used to avoid overfitting by halting the training process before the model starts to fit the noise in the training data. In this case, the training process converges before the last epoch due to the implementation of early stopping, indicating that further training would not improve the model's performance significantly. Therefore, the criterion used to determine when training is complete is based on the convergence of the training process rather than a specific metric such as validation loss plateau.