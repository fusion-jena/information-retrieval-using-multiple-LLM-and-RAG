The study uses audio data for its deep learning pipeline. This is evident from the use of bird song identification software like Bird Song Id Australia and Raven Lite, which are designed to identify birds based on their unique vocalizations. Additionally, the fieldwork involved identifying species from audio recordings using observer knowledge, data from the website eBird, and two low-cost phone apps. Furthermore, the analysis was conducted using the 'R Stats Package', which can handle various data formats but is particularly suited for statistical analysis of numerical data. However, it does not explicitly mention handling other data formats like images or videos. Therefore, we can infer that the primary data format used in this study is audio.

Reference(s):
[1] Bird Song Id Australia and Raven Lite (K. Lisa Yang Center for Conservation Bioacoustics at the Cornell Lab of Ornithology, 2022)
[2] Chalmers, C., Fergus, P., Wich, S., Longmore, S. N. (2021). Modelling animal biodiversity using acoustic monitoring and deep learning. Proceedings of the 2021 International Joint Conference on Neural Networks (IJCNN), pp. 1â€“7. <https://doi.org/10.1109/IJCNN52387.2021.9534195>
[3] Field work and species identification from audio was undertaken by author S. Fischer using a combination of observer knowledge, data from the website eBird (eBird, 2021) and two low-cost phone apps: Morcombe and Stewart Guide to Birds of Australia (PDA Solutions, 2021) and Bird Song Id Australia (Sunbird Images, 2019)
[4] Data were analyzed using the 'R Stats Package', version 4.0.1 in RStudio (R version 4.0.1 (2020-06-06)) (RStudio Team, 2020)