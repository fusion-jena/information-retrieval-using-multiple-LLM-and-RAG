Based on the given context, there isn't any explicit mention of specific techniques used to address data bias during preprocessing of the deep learning pipeline such as stratified splitting, oversampling, undersampling, or diverse data collection. However, some relevant information can still be extracted.

The authors have mentioned collecting a new fish dataset in turbid waters called FishInTurbidWater and labeling it quickly and weakly to create the first weakly-supervised fish dataset in turbid waters. They also discuss developing two novel deep learning networks using this dataset - one with semi-supervised contrastive learning and another with weak supervision. These approaches aim to significantly accelerate model deployment times while maintaining high accuracy.

Although not directly addressing data bias, these methods could potentially help mitigate its effects indirectly. By creating a large, weakly-labeled dataset, they may introduce more diversity into their training data, which could help counteract potential biases present in smaller, carefully curated datasets. Additionally, employing semi-supervised and weakly-supervised learning techniques might enable the models to learn better representations from limited amounts of accurately labeled data, thus reducing the risk of overfitting due to imbalanced classes or other forms of data bias.