An Nvidia 2070 Super GPU with 8GB of memory is utilized to accelerate model training. Additionally, CUDA 11 and cuDNN 7.6.5 enable the GPU accelerated learning aspect of the pipeline. For inferencing, a custom-built server containing an Intel Xeon E5-1630v3 CPU, 64GB of RAM, and a NVidia Quadro RTX 8000 GPU is used.