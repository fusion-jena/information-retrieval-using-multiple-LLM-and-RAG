The study uses several metrics to evaluate the performance of its machine learning models. These include Area Under the Curve (AUC), True Skill Statistics (TSS), Cohen's Kappa (KAPPA), point-biserial correlation (COR), and Receiver Operator Characteristics (ROC).

AUC is a measure of the ability of a classifier to distinguish between classes and is used to compare the performance of different models. It represents the degree or measure of separability, indicating how much a model is capable of distinguishing between classes.

True Skill Statistics (TSS) is another metric used to evaluate binary classification models. It takes into account both false positives and false negatives, providing a more balanced assessment of a model's performance.

Cohen's Kappa (KAPPA) is a statistic that measures inter-rater agreement for qualitative (categorical) items. In the context of machine learning, it is often used to evaluate the performance of classification models.

Point-biserial correlation (COR) is a correlation used when one variable is dichotomous (binary); Y can either be '0' or '1', and the other variable X is continuous. This correlation coefficient is a measure of association that describes the strength and direction of the relationship between the two variables.

Receiver Operating Characteristic (ROC) curve is a plot of the true positive rate against the false positive rate for different decision thresholds of a classifier. It shows the tradeoff between sensitivity (true positive rate) and specificity (false positive rate) for every possible cut-off.

These metrics are used after 10 K-fold cross-validation and 10-fold bootstrapping to assess the models. Bootstrapping is used to provide unbiased predictive accuracy with a sufficiently low variance. For the model threshold, the sensitivity-specificity sum maximization technique is employed.