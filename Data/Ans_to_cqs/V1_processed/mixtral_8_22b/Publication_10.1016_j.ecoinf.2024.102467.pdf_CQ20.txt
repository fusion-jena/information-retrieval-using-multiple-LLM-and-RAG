In the given context, it is mentioned that the algorithm was trained on an RTX 3090 GPU for 6 hours. Additionally, the video memory usage was 12 GB. Therefore, it can be concluded that the hardware resource used for training the deep learning model in this case was a GPU, specifically an NVIDIA GeForce RTX 3090 graphics card. No mention of other types of hardware resources such as TPUs or CPUs was made in the provided context.