Based on the given context, the data is split into three parts for deep learning model training: train, test, and validation. However, the specific criteria used to split the data are not explicitly mentioned. Nevertheless, it can be inferred that the data is divided based on the number of frames available. For instance, the models are trained with increasing sizes of training sets ranging from 50 to 500 frames. Additionally, the validation set consists of the original base model validation set combined with 100 frames per class from the labeled December 3rd, 2019 training set, randomly pooled per experiment. Therefore, it appears that the data splitting criteria depend on the availability and labeling of the frames.