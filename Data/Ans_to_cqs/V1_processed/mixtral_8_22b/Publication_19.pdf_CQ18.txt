The strategy implemented to monitor the model performance during training is not explicitly mentioned in the given context. However, it is stated that a 60-20-20 train/validate/test regime was used to split the data into training, validation, and testing sets. This suggests that the model performance might have been monitored by evaluating its accuracy on the validation set after each epoch during training. Additionally, the use of grid search for hyperparameter tuning implies that cross-validation could also have been employed to ensure robustness and prevent overfitting.