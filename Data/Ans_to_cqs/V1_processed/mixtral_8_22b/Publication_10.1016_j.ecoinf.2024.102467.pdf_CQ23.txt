Based on the given context, there is no explicit mention of specific measures taken to ensure the generalizability of any particular deep learning model. However, it is common practice in machine learning and deep learning research to employ various techniques such as using diverse datasets, cross-validation, stratified splitting, or other methods to enhance the robustness and generalizability of models.

In the case of the mentioned papers, they primarily discuss different architectures for deep learning models like Xception, EfficientNetV1, and EfficientNetV2. These architectures are focused on improving aspects such as computational efficiency, reducing model complexity, increasing detection accuracy, and enhancing training speeds. While these improvements may indirectly contribute to better generalizability, the context does not provide direct evidence of specific measures employed to ensure the generalizability of these models.