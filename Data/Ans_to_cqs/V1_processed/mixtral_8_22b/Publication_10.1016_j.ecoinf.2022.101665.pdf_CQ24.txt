The text does not provide direct information about handling randomness in the deep learning pipeline. However, it discusses related concepts in machine learning, specifically addressing limited data availability and evaluation of predictive models.

In machine learning, when data is abundant, a common approach is to split the dataset into three parts: a training set, a validation set, and a test set. The training set is used for fitting the models, the validation set is used to estimate prediction errors for model selection and hyperparameter tuning, and the test set is used for assessing the accuracy of the final model.

When data availability is limited, setting aside a test set might not be feasible. In such cases, resampling methods like cross-validation or bootstrapping are used. Cross-validation involves partitioning the original sample into subsamples, using one subsample for training and another for validation, repeating the process multiple times, and averaging the results. Bootstrapping involves creating multiple datasets by drawing observations with replacement from the original dataset, then aggregating the results across these datasets.

These techniques help manage variability due to randomness in the data and improve the robustness of the model. While they do not directly address managing randomness in the deep learning pipeline, such as controlling the random seed value, they offer insights into how to deal with uncertainty and variability in machine learning tasks.