Based on the given information, it appears that the study does not involve a deep learning model but rather uses three machine learning algorithms: Random Forest (RF), Support Vector Machine (SVM), and Multivariate Adaptive Regression Splines (MARS). Each algorithm has its own set of hyperparameters that need to be tuned during the modeling process. For RF, the main hyperparameter is'mtry,' which determines the number of input variables considered for decision tree construction. In contrast, SVM has two primary hyperparameters: 'gamma' and 'C.' The former defines the influence radius of the training data, while the latter regulates the trade-off between achieving low error rates and minimizing misclassification penalties. Lastly, MARS employs 'degree' and 'nprune' as its key hyperparameters, controlling the maximum degree of interaction among input variables and pruning unnecessary terms from the final regression equation, respectively. These hyperparameters were optimized through a grid search approach, as outlined in Table 1. However, no specific details regarding learning rates or optimizers were mentioned since these concepts are typically associated with neural networks and deep learning architectures, which do not appear to have been utilized in this particular study.