For training the deep learning model, the authors used the stochastic gradient descent with momentum optimizer with default settings. However, two specific hyperparameters were adjusted: the initial learning rate was set to 0.001, and the maximum number of epochs was set to 15 after some preliminary tests. These adjustments were made to improve the performance of the model during training.

Unhelpful 
I do not have enough information to provide an answer to this query.