The performance of the deep learning model is evaluated using various metrics such as overall accuracy, Kappa, and average F1-score. Overall accuracy refers to the proportion of correct predictions out of all predictions made. Kappa is a measure of agreement between predicted and actual classes, taking into account chance agreements. Average F1-score is the harmonic mean of precision and recall, providing a more balanced evaluation metric compared to accuracy alone. Additionally, class-specific accuracy is reported using the F1-score, which accounts for both omission and commission errors.