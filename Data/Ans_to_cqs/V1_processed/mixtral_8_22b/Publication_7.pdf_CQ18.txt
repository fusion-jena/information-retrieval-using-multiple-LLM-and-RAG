The text does not provide explicit information about the strategy implemented to monitor the model performance during training. However, based on common practices in machine learning, we can infer that the authors might have used techniques like cross-validation or validation sets to monitor the model performance during training. In experiment 1, they mention training the classifier on two-thirds of the images from the year 2011 and testing it on the remaining images from the same year. This suggests that they could be using a form of holdout validation or cross-validation to assess the model's performance during training. Additionally, they report accuracy metrics for each experiment, indicating that they evaluated the model's performance after training.