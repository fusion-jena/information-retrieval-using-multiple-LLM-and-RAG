The given context does not explicitly mention any postprocessing steps involved after the model training such as saliency maps, metrics calculation, or confusion matrices. However, it does discuss some aspects related to model evaluation and interpretation.

Model complexity is discussed in terms of the number of variables included in the predictor set, with proper variable selection being essential to minimize training costs, measurement requirements, and decrease the likelihood of overfitting. Hyperparameter optimization is also mentioned, which involves tuning the parameters of the machine learning algorithm used (random forest method in this case), optimizing them using Bayesian Optimization to minimize a 5k-fold cross-validation loss during model development.

Additionally, the concept of model explainability is introduced, emphasizing the importance of understanding the value of each predictor variable towards building more parsimonious models rather than solely focusing on achieving maximum predictive performance. This suggests that while the text doesn't directly address postprocessing steps like saliency maps or confusion matrices, it highlights the significance of interpreting and explaining the trained models.