The text mentions several metrics used to evaluate the performance of the deep learning model. One of these metrics is classification accuracy, which measures the proportion of correct predictions out of the total number of instances. The text notes that high values of classification accuracy can sometimes give an overly optimistic view of the model's performance, since they may miss subtle errors on important species. Another metric mentioned is False Positive Rate (FPR), which measures the proportion of negative instances incorrectly classified as positive. The text indicates that FPR was used to evaluate the performance of the model on larger classes. However, the text does not mention any other specific metrics used to evaluate the performance of the deep learning model.