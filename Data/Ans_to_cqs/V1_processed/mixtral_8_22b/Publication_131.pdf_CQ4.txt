The text does not provide specific details about the exact data augmentation techniques applied to the audio samples. However, it mentions that for each of the 865 audio samples in the database, 10 additional audios were generated. It also states that when dealing with convolutional neural networks (CNNs) and images, data augmentation typically involves extending the set of images through transformations such as rotations, size modifications, etc. In the context of this work on sounds, the transformations must be made on the audios, which would then be reflected in the mel-spectrogram images. Therefore, while the specific techniques are not explicitly stated, we can infer that similar transformations might have been applied to the audio samples, such as pitch shifting or time stretching, before generating the mel-spectrogram images.