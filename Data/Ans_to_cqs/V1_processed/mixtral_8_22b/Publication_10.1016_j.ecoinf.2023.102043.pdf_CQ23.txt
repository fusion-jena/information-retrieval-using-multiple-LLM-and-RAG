To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the dataset used for training, validating, and testing the model was diverse, consisting of recordings from four different farms (A, B, C, and D). This diversity helped to prevent overfitting and improve the model's ability to perform well on unseen data. Secondly, the dataset was split into three parts: 70% for training, 10% for validation, and 20% for testing. This approach allowed for proper evaluation of the model's performance during training and prevented any potential bias towards specific subsets of the data. Lastly, the use of stratified splitting ensured that each subset maintained the original class distribution, further improving the model's robustness and generalizability.