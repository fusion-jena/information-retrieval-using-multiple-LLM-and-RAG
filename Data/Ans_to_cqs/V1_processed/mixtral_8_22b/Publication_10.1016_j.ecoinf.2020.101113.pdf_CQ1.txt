In the given context, there isn't explicit information about the specific methods used for collecting raw data in the deep learning pipeline. However, we can infer some details based on the available information.

Firstly, the text mentions that the CNN model used in this study requires equally sized input images. These images seem to be derived from time-frequency input windows of 2 seconds, which were chosen due to their proximity to the mean and median template duration across target call types. This suggests that the raw data might be audio recordings, possibly from field surveys or sensor deployments, which are then processed into spectrograms or similar representations suitable for the CNN model.

Secondly, the context discusses the reduction of manual effort in training data creation through template creation and validation of template-based detections in a graphical user interface. This implies that the raw data might involve human intervention for creating templates and validating detections, potentially involving experts in the respective fields.

Lastly, the text highlights the importance of having data collected from the study region rather than relying on crowd-sourced public datasets. This indicates that the raw data might not solely rely on publicly available datasets but also include data specifically gathered for the study.

Therefore, although the exact methods for collecting raw data aren't explicitly stated, we can surmise that they likely involve audio recordings from field surveys or sensor deployments, with possible involvement of human expertise for template creation and validation. Additionally, the data collection process seems to prioritize gathering data from the study region over utilizing crowd-sourced public datasets.