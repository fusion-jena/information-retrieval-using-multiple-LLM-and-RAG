The authors employ several strategies to handle randomness in their deep learning pipeline. Firstly, they use a fixed random seed value throughout their experiments to ensure reproducibility. Secondly, they perform cross-validation by shifting the validation set five times to quantify the average validation cross-entropy loss and accuracy. This helps them to evaluate the performance of their model more robustly and reduce the impact of any potential randomness. Lastly, they select the best performing model based on its cross-entropy loss across different feature sets and architectures, which further reduces the risk of overfitting due to random factors. Overall, these strategies help to mitigate the effects of randomness and improve the reliability of their results.