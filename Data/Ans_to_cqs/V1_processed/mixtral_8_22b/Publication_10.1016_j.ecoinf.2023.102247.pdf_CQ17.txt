The query asks about regularization methods used to prevent overfitting in deep learning pipelines. However, based on the given context, there isn't any direct information regarding regularization methods such as dropout or L2 regularization. Nevertheless, I can provide some general insights into these techniques.

Regularization methods are used to prevent overfitting by adding a penalty term to the loss function during the training process. This helps to reduce the complexity of the model and improve its ability to generalize well to unseen data. Two common types of regularization methods are L1 and L2 regularizations.

L1 Regularization, also known as Lasso Regression, adds an absolute value of the magnitude of coefficients as penalty term to the loss function. It tends to produce sparse output, driving some of the weights to zero which results in feature selection.

L2 Regularization, also known as Ridge Regression, adds the squared magnitude of coefficients as penalty term to the loss function. Unlike L1, it doesn't result in sparsity but reduces the values of all weights.

Dropout is another popular regularization technique used in deep learning. During training, Dropout randomly sets a fraction rate of input units to 0 at each update, which helps to avoid overfitting.

However, without specific details related to the deep learning pipeline mentioned in the context, I cannot confirm if these regularization methods were applied.