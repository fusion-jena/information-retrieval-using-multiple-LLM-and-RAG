The text does not provide explicit information on handling randomness in the deep learning pipeline, such as managing random seed values. However, it mentions the use of randomized grid search methods (Bergstra & Bengio, 2012), which help reduce computational costs and avoid overfitting by exploring only a subset of the parameter grid instead of exhaustively searching through all possible combinations of hyperparameters. In this method, various cases are generated by combining hyperparameter values extracted from a uniform distribution, and their performance is evaluated. Although this strategy doesn't directly address randomness in the deep learning pipeline, it contributes to managing the overall randomness inherent in the process by systematically exploring the parameter space.