Based on the given context, there isn't explicit information about the specific criteria used to split the data for deep learning model training into train, test, and validation sets. However, some common practices can be inferred. Typically, the dataset is divided into three subsets: training set, validation set, and testing set. The training set is used to fit the model, while the validation set is used during the training process to fine-tune the model parameters and prevent overfitting. Lastly, the testing set is used to evaluate the performance of the trained model on unseen data. In this case, the context mentions that the same independent testing data was used for evaluating different models, which suggests that the dataset might have been split into training and testing sets beforehand. Furthermore, the context also discusses hyperparameter optimization, which often involves using a separate validation set to tune the model's parameters without affecting the actual training or testing processes.