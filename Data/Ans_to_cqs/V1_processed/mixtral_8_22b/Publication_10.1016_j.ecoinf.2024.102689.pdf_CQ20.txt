The deep learning model was trained using GPU resources. Specifically, it utilized CUDA version 11.4. The programming language used was Python 3.6, and PyTorch version 1.8.0 was employed within the virtual environment function of Anaconda3. The optimization process was carried out using the Adam optimizer with a momentum of 0.9 and a batch size of 16. Images were processed at a resolution of 1024 x 1024, with an initial learning rate set at 0.001 and a minimum learning rate of 0.0001. Training spanned 300 epochs.