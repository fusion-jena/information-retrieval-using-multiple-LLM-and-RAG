The text does not provide explicit information about specific preprocessing steps such as normalization, scaling, or cleaning prior to training a deep learning model. However, it mentions that the dataset is divided into training and testing sets with an 80:20 ratio, respectively, through random sampling. This step ensures that both subsets are representative of the overall dataset and minimises the risk of bias. Additionally, the text discusses the use of GridSearchCV function from scikit-learn library to fine-tune the hyperparameters of each model within the training set, employing a five-fold cross-validation and setting negative mean square error as the target measure. After this optimization process, the performance metrics are evaluated using the designated test set to determine the best performing models for each target variable.