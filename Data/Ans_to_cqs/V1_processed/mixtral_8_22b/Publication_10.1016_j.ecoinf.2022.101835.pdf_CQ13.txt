The deep learning model used in this study is an artificial neural network (ANN). The hyperparameters used for the optimization of the ANN model include the activation function, optimizer, units in the initial layer, and units in the middle layers. The activation function used is ReLu, and the optimizer used is Adam. The number of units in the initial layer is set to 90, and there are no intermediate layers in the optimized ANN models. Therefore, the number of units in the middle layers does not apply here. Other hyperparameters mentioned in the text but not specific to the ANN model include n\_estimators (number of trees), max\_depth (maximum depth of the tree), num\_leaves (maximum tree leaves for base learners), lambda\_l1 (L1 regularization), lambda\_l2 (L2 regularization), feature\_fraction (a subset of features on each iteration/tree), bagging\_fraction (randomly select a part of data without resampling), bagging\_freq (frequency for bagging), and min\_child\_samples (minimal number of data in one leaf). However, these hyperparameters are not directly related to the deep learning model.