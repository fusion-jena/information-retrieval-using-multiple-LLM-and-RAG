The given context does not provide information on the specific machine learning or deep learning models used for this study, nor does it mention any details about the post-processing steps involved after model training. Therefore, I cannot provide a direct answer based solely on the given context. However, generally speaking, some common post-processing steps after model training include:

1. Model evaluation: This involves calculating various metrics such as accuracy, precision, recall, F1 score, ROC curves, etc., to evaluate the performance of the trained model.

2. Confusion Matrix: It is a table layout that allows visualization of the performance of an algorithm. Each row of the matrix represents the instances in an actual class, while each column represents the instances in a predicted class.

3. Saliency Maps: These are visualizations that highlight which input pixels have the most influence on the output prediction made by the model. They can be useful for understanding how the model makes its decisions.

4. Hyperparameter tuning: After evaluating the initial model, one might need to adjust hyperparameters like learning rate, number of layers, batch size, etc., to improve the model's performance further.

5. Ensemble methods: Combining multiple models to create a more robust final model is another popular post-processing step. Techniques like bagging, boosting, stacking, etc., can be employed here.