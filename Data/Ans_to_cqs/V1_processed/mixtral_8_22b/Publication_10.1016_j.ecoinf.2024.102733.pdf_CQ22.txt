The paper evaluates the performance of the deep learning models using several metrics. These include Cross-Entropy Loss, Focal Loss, F1-score, and the geometric mean of true positives and negatives (G-mean). The results show that the models trained with plain Cross-Entropy Loss achieve lower or comparable performance in every metric compared to those trained with Focal Loss or SMOTE. The models exploiting SMOTE obtain the best performance across all metrics. However, the features from (Beyan and Fisher, 2013a; Beyan and Fisher, 2013b) combined with SVM yield the lowest results across all combinations.