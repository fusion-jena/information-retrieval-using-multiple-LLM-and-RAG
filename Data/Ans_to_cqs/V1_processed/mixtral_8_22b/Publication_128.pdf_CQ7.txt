The context does not provide explicit details about how the data was split for deep learning model training (e.g., train, test, validation). However, it mentions that the inputs are batch normalized before training and that images are tested one by one. It can be inferred that there might have been separate datasets for training and testing purposes. Typically, in machine learning and deep learning applications, the data is divided into three sets: training, validation, and testing. The training set is used to fit the model, while the validation set helps tune hyperparameters and prevent overfitting. Finally, the testing set evaluates the final performance of the trained model. Without specific information regarding the splitting criteria, we cannot definitively state how the data was partitioned in this case.