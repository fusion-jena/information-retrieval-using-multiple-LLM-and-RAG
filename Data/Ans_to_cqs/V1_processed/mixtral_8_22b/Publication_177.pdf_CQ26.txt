The paper [33] discusses a novel ensemble method for classification in imbalanced datasets using a split balancing technique based on instance hardness (sBal_IH). This approach addresses data bias during preprocessing of the deep learning pipeline.

To tackle the issue of data imbalance, the authors propose a new sampling strategy called sBal_IH. This technique involves dividing the majority class into several subsets and combining them with minority classes to create balanced subsets. Each subset is then used to train a base learner, resulting in multiple base learners. These base learners are combined using various ensemble methods like voting, averaging, or stacking.

Moreover, the authors employ stratified k-fold cross-validation to ensure that the distribution of samples across folds remains consistent with the original dataset. This helps maintain the balance between classes when training and testing the models.

While the papers do not explicitly mention oversampling or undersampling techniques, they focus on addressing data bias through diverse data collection and the proposed sBal_IH technique. By creating balanced subsets and utilizing different ensemble methods, the authors aim to improve the overall performance of their deep learning models on imbalanced datasets.