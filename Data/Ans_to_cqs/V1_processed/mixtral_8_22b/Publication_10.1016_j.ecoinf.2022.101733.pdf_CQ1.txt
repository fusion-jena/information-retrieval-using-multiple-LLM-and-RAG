The study utilizes various methods for collecting raw data in its deep learning pipeline. For instance, it employs field surveys to collect samples, although this can be challenging due to time and access constraints in remote environments. In such cases, researchers resort to obtaining training and validation sample points from imagery instead of field validation. This involves interpreting images, benefiting sample selection from both fields survey and high-resolution Google Earth images. Despite the potential uncertainty in determining a training sample's class, this approach enables the rapid and efficient accumulation of a larger number of training samples.

Moreover, the study uses satellite data from Sentinel-2 and Sentinel-1 missions. From Sentinel-2, it extracts visible red, green, and blue bands, twelve multispectral bands, spectral indices, and spectral features. Additionally, it incorporates Sentinel-1 bands, textural features, and Digital Surface Model (DSM). These diverse sets of features are analyzed using McNemar's test to understand their impact on the model's performance.

Furthermore, the study visualizes the initial datasets using true color composites, false color composites, and specific band combinations of Sentinel-2 and Sentinel-1 data. It also includes AW3D30 data, likely used for topographical information or digital elevation models.

In summary, the study combines field surveys, image interpretation, and publicly available satellite data from Sentinel-2 and Sentinel-1 missions to collect raw data for its deep learning pipeline.