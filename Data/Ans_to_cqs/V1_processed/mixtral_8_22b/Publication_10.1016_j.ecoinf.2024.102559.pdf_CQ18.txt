The text does not provide explicit information about the specific strategy used to monitor the model performance during training. However, it can be inferred that the authors might have used common strategies such as cross-validation or holdout validation methods to evaluate their models. Additionally, they could have monitored various evaluation metrics like overall accuracy, producer's accuracy, user's accuracy, FP, FN, TP, and TN to assess the performance of their models. These metrics were reported in tables A.5 and A.6, which suggest that the authors evaluated their models based on these criteria. Nevertheless, without further details regarding the actual implementation process, we cannot definitively state what exact strategy was employed by the authors to monitor the model performance during training.