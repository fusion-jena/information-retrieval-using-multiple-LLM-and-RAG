The given context does not provide information about the specific data augmentation techniques applied in the deep learning pipeline. However, common data augmentation techniques include flipping, rotation, scaling, cropping, zooming, shearing, and brightness adjustment. These techniques help increase the amount of training data and improve the generalization ability of the model.

Based on the context, it appears that the authors conducted active learning experiments using various sampling strategies, including random sampling, uncertainty sampling, and diversity sampling. They evaluated these strategies on both focal and citizen-science datasets. Additionally, they explored the use of transfer learning models, specifically BirdNet-1, as an embedding model for fine-grained, sub-species sound event analysis. Different call types of the same species were found to form distinct clusters in the embedding space. Overall, the results suggest that using a transfer learning model tailored to both the target modality and domain can yield better performance as a feature embedding model. Active learning sample selection strategies can also significantly reduce the number of required annotations for achieving model convergence.