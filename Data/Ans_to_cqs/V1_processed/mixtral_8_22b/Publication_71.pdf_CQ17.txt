The text does mention one specific regularization method used to prevent overfitting in the deep learning pipeline - dropout. Dropout is a technique where randomly selected neurons are ignored during training, which helps to make the model more robust and prevents overfitting. In the given context, it is mentioned that a dropout layer was added for each convolutional layer with a dropout rate of '0.1'. However, there is no explicit mention of other regularization methods such as L2 regularization.