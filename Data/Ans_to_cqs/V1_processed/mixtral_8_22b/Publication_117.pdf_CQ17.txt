The text does not provide explicit information about the specific regularization methods used to prevent overfitting in the deep learning pipeline. However, it mentions that they used transfer learning during training, which involves freezing all layers except the last few layers of a pre-trained model. Transfer learning itself acts as a form of regularization since it leverages the knowledge gained from solving one problem to improve generalization when applied to another related problem. Additionally, the text discusses adjusting the weighting given to the no-object component of the multipart loss function, which might also help mitigate overfitting. But without further details, it cannot be confirmed if techniques like dropout or L2 regularization were explicitly utilized.