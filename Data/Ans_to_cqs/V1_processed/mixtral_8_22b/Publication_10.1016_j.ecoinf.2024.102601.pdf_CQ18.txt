The strategy implemented to monitor the model performance during training involves a systematic three-step process. First, the dNBR model was used exclusively in this study to create a comprehensive training dataset. Next, the most salient predictor was identified, revealing the variables that significantly influence the model’s inferential capacity in assessing WSM. Lastly, the SHAP (SHapley Additive exPlanation) framework was employed to interpret the output of the machine learning model.

To evaluate the model’s performance, a dataset composed of 235 predictors and 5000 data points was randomly split into 3000 for training and 2000 for validation (a 60/40 ratio). The model demonstrated a flawless training accuracy of 1.0 and a commendable accuracy of 0.924 on the validation dataset. Additionally, the hyperparameters of the RF model were optimized using two prominent models – RandomizedSearchCV and GridSearchCV – from the scikit-learn library. These tools helped refine the RF algorithm’s performance by initially exploring the hyperparameter space using RandomizedSearchCV, followed by a focused and exhaustive search using GridSearchCV to fine-tune the model.