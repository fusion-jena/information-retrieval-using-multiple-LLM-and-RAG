To monitor the model performance during training, the researchers used a strategy involving hyperparameter tuning with validation data. They allocated 70% of their sample data for training purposes and reserved 30% for testing. Within the training dataset, they further separated 10% of the data for use as validation data. This validation data was then employed to tune the key hyperparameters for each model, helping prevent overfitting due to limited processing capabilities in Google Earth Engine (GEE). The specific hyperparameters set for each machine learning technique are listed in Table 3, which includes details such as max nodes, min leaf population, number of trees, bag fraction, variables per split, shrinkage, sampling rate, loss, kernel type, SVM type, and decision procedure. By utilizing this strategy, the researchers aimed to ensure optimal model performance while avoiding potential issues related to overfitting or underfitting.