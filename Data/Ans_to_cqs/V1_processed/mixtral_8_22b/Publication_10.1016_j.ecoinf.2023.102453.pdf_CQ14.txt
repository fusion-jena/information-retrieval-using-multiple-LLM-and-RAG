In the given context, hyperparameter optimization is performed using the Keras Tuner library, which offers three main algorithms: Random Search, Hyperband, and Bayesian Optimization. For the purpose of this study, Hyperband and Bayesian Optimization were chosen due to their superiority over other search algorithms available in the Keras Tuner.

Hyperband is a multi-armed bandit algorithm designed for hyperparameter optimization. It combines elements of random search and successive halving to efficiently allocate resources across multiple configurations. This allows for faster convergence towards promising hyperparameter settings compared to traditional methods like grid or random search.

On the other hand, Bayesian Optimization is a sequential model-based approach that uses probabilistic models to guide the search for optimal hyperparameters. By iteratively updating its belief about the underlying function based on previous evaluations, Bayesian Optimization aims to find the best possible set of hyperparameters within fewer iterations than exhaustive search strategies.

In this particular case, the hyperparameter optimization focused on finding the optimal learning rate for EfficientNetV2B0 and MobileNetV2 models when applied to the Extinction dataset. Both Hyperband and Bayesian Optimization techniques were employed to determine the optimum learning rate value, resulting in a value of 0.00001 for both models. These findings demonstrate how advanced hyperparameter optimization techniques can significantly enhance model performance by identifying the most suitable hyperparameter configurations.