In this study, the authors address data bias during preprocessing of their deep learning pipeline using stratified splitting. They create two datasets - a biased dataset and an unbiased dataset. The biased dataset is created by taking 70% of the data for training and 30% for testing, approximating these percentages for each species in the dataset. However, this can result in a significant bias due to Species Sampling Proportional Bias (SSPB), where some species have more samples than others. To mitigate this, the authors create an unbiased dataset. In this case, they still attempt to achieve a 70%-30% distribution for each species, but they ensure that images from the same specimen are placed either in the training dataset or the testing dataset. This prevents any potential leakage between the training and testing sets, which could lead to overfitting and poor generalization performance. While the paper does not explicitly mention oversampling, undersampling, or diverse data collection, these techniques could also potentially help reduce data bias in deep learning pipelines. Oversampling involves duplicating examples from underrepresented classes, while undersampling removes examples from overrepresented classes. Diverse data collection aims to gather a wide range of examples representing different scenarios, conditions, and variations within each class.