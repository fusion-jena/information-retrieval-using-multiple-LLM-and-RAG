The text does not provide explicit information about specific techniques such as stratified splitting, oversampling, undersampling, or diverse data collection being employed to address data bias during preprocessing of the deep learning pipeline. However, there is mention of avoiding biases in the experiments by separating the datasets in a particular manner for training and testing.

In the case of herbarium datasets H255 and H1K, the separation was done such that sheets of the same species collected by the same collector were not allowed to be part of both the training and testing sets. Similarly, for the CR dataset, images of different leaves from each specimen were included only in either the training or the testing set, but not in both. The same approach was applied to the PlantCLEF (PC) dataset at the observation level, ensuring that no same observation was present in both training and testing subsets.

These measures led to more realistic and unbiased training/testing scenarios, although they resulted in lower accuracy rates. While these methods can help reduce bias, they do not directly correspond to the mentioned techniques like stratified splitting, oversampling, undersampling, or diverse data collection.