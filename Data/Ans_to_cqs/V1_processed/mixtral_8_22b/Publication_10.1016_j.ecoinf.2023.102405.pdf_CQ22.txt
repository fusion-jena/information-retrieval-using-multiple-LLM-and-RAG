The performance of the deep learning model is evaluated using several key metrics such as Accuracy, Precision, Recall, F-score, and Loss. Each metric provides valuable insights into different aspects of the model's performance.

Accuracy measures the proportion of correctly classified instances among all cases examined. In this case, the model achieved impressive accuracy rates of around 98.69% on a publicly available dataset and 99.89% on a real-time dataset.

Precision, also known as Positive Predictive Value, calculates the ratio of accurately identified positive observations to the total predicted positives. High precision indicates low false positive rates. The model demonstrated high precision, achieving 98.5% on the public dataset and 99.26% on the real-time dataset.

Recall, or Sensitivity, determines the proportion of actual positives that were correctly identified by the model. A higher recall value signifies fewer missed detections. The model showed strong recall rates, reaching 97.33% on the public dataset and 99.62% on the real-time dataset.

F-score combines both precision and recall into a single measure, providing a more balanced evaluation of the model's performance. The F-score ranges from 0 to 1, where 1 represents perfect precision and recall. Although specific F-scores are not mentioned, they can be calculated based on the given precision and recall values.

Lastly, Loss refers to the penalty for incorrect classifications made by the model during training. Lower loss values indicate better model performance. On the public dataset, the model achieved losses of 0.036 and 0.034, while on the real-time dataset, it attained even lower losses of 0.0104 and 0.0092.