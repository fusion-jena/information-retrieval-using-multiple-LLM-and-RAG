The text does not explicitly state the specific criterion used to determine when training is complete. However, it mentions that the training was stopped after 100 epochs. This suggests that the number of epochs or iterations through the entire dataset might be used as a stopping criterion. Additionally, the use of early stopping based on validation loss plateauing can also be inferred, given that the training process involves a cross-validation split of 80% training data and 20% validation data. Therefore, monitoring the performance on the validation set during training would allow for identifying when the model starts to overfit and stop training accordingly.