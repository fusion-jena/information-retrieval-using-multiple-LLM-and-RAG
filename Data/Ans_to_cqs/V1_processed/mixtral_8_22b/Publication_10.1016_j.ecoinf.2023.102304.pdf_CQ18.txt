The text does not provide explicit information about the specific strategy implemented to monitor the model performance during training. However, it mentions two machine learning algorithms - Random Forest and XGBoost - both known for their ability to evaluate feature importance. This implies that these models might have been used to track the significance of different features during training, thus indirectly monitoring the model's performance.

Random Forest determines feature importance by measuring the decrease in impurity (like Gini Impurity) when a particular feature is chosen for splitting data into branches. On the other hand, XGBoost calculates feature importance using 'gain,' which measures how much a feature improves prediction accuracy at its respective branch. Therefore, these methods could potentially help understand the contribution of individual features towards improving the model's predictive power during training.