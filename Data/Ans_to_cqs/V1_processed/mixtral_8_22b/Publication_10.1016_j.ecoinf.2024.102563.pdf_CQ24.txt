The provided sources do not directly address the specific strategies used to handle randomness in the deep learning pipeline, such as managing random seed values. However, some general approaches can be applied to manage this issue. One common strategy is setting a fixed random seed value before running any code involving random processes, which ensures reproducibility by generating consistent results across different runs or environments. Another approach involves using techniques like cross-validation, where multiple models are trained on different subsets of data, averaging their performance to reduce variability caused by random initialization. Additionally, ensemble methods combine predictions from various models, often reducing overall variance due to randomness. Lastly, hyperparameter tuning through grid search or Bayesian optimization can help find optimal configurations that minimize the impact of random factors.