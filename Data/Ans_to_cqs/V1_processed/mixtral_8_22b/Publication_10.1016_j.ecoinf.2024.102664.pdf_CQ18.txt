To monitor the model performance during training, a specific strategy was employed. All the collected data was divided into three distinct sets: data spanning from 2003 to 2020 was used for training purposes, while data from 2021 served as validation data, and data from 2022 was reserved for testing. To assess the efficacy of the validation data forecasts, points A, B, and C were utilized. The structure of all models, along with their respective hyperparameters like kernel size and number of nodes, was established through a controlled variable approach. This entailed maintaining constant other variables and choosing those parameters that yielded optimal validation data forecast outcomes as the model's hyperparameters. Furthermore, it was observed that employing Adam as the solver for training the network generally resulted in a lower Root Mean Square Error (RMSE) for the validation data forecasting results.