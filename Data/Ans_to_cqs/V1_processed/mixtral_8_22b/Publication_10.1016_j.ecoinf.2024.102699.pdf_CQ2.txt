The paper discusses the use of deep learning strategies for the classification of birdsong within natural soundscapes. It employs three fundamental deep neural network architectures, including vision transformers, to classify 397 different bird species. The authors incorporate up to 19 well-established data augmentation techniques commonly used in audio classification. These include integrating various noise samples and non-bird audio elements.

From these details, it can be inferred that the input data format used in the deep learning pipeline is primarily audio. However, since vision transformers are also mentioned as one of the employed architectures, it suggests that the audio data might have been converted into spectrogram images before being fed into the models. Spectrograms are visual representations of the spectrum of frequencies of a signal as they vary with time. Therefore, the data formats used in the deep learning pipeline would likely be audio and possibly spectrogram images derived from the audio files.