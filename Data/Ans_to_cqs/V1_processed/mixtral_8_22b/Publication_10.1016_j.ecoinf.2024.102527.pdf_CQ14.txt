Based on the given context, there isn't any explicit information about the specific method used for hyperparameter optimization such as grid search or random search. However, it does mention that they employed Stochastic Gradient Descent (SGD) optimizer with a momentum value of Î¼ = 0.9 to train the model. It also states that other hyper-parameter settings for model training were shown in Table S.4 of the Supporting Information. Therefore, without access to the supporting information, it cannot be determined exactly which methods were used for hyperparameter optimization.