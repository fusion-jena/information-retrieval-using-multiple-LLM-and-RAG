The deep learning model used a learning rate of 10^-5 with an exponential learning decay and a gamma of 0.95. A dropout of 50% was applied, and the Adam solver type was used as the learning parameter. These hyperparameters were chosen for their ability to facilitate fast convergence of the network without causing overfitting. The model was trained using thumbnails of whole fish, parts of fish species, and environment. The raw outputs were post-processed using two decision rules: (r1) keeping the most likely fish class if "environment" was the most likely class, and (r2) considering "part of species X" equivalent to "species X." The model was trained using a GoogLeNet architecture, which won the 2015 ImageNet competition, an identification challenge on 1000 different classes.