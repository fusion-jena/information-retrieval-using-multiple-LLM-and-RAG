According to the provided context, the hyperparameters of the model, including 'k' and the training parameters like the stopping criterion, were based on preselected values that were not fine-tuned on any dataset. This approach was adopted due to computational limitations during extensive simulations. However, when applying the method in practice on real data, it is suggested that all the hyperparameters could be fine-tuned using a validation set. This process involves selecting a subset of the reference species as the validation set, tuning the parameters using these data, and finally retraining the model with all the data using the fine-tuned parameters. It is noted that this procedure may be computationally intensive and slow, and the gains in accuracy might be minimal. Unfortunately, the context does not provide specific information about the optimization methods used, such as grid search or random search. Therefore, while it suggests that hyperparameter optimization is possible, it does not specify which optimization techniques are employed.