The authors used a dataset split ratio of 80:10:10 for training, validation, and testing sets, respectively. They chose this ratio based on previous studies showing better performance in detecting small insects and diseases using deep learning models. For the 640 x 640 pixel input resolution, they had 1543 images for training, 243 images for validation, and 247 images for testing. For the 1280 x 1280 pixel input resolution, there were 1637 images for training, 255 images for validation, and 262 images for testing. Five different versions of the YOLOv5 model family were independently trained to detect alates on sorghum leaves.

Summary:
The dataset was split into three parts - training, validation, and testing - using a ratio of 80:10:10. This decision was made based on past research indicating superior results in identifying small insects and diseases using deep learning models. Different numbers of images were allocated to each part depending on the chosen input resolution. Additionally, five distinct variations of the YOLOv5 model family were employed for training purposes.