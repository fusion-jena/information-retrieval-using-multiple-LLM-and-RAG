The given context does not provide explicit information about the specific criteria used to determine when training is completed. However, it mentions the use of spatial cross-validation techniques to enhance model performance. This technique involves separating the training and test data beforehand, which could imply that some form of validation loss or error metric might be monitored during training to decide when to stop. The text also refers to Meyer et al. (2019), who discuss how spatial cross-validation helps refine the estimation of prediction errors through iteration. This suggests that tracking the improvement in prediction accuracy over time may play a role in deciding when to conclude training. Nevertheless, without more detailed information from the authors or additional sources, it is impossible to definitively state what exact criteria they employed to establish the completion of their models' training phase.