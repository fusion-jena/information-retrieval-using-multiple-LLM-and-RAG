The paper does not provide explicit information about the specific preprocessing steps taken before training the deep learning models. However, it mentions that there are four main modules in their methodology, one of which is the preprocessing of historical images (section 2.1). This suggests that some form of preprocessing was performed on the input data before being fed into the deep learning models. Common preprocessing techniques include normalization, scaling, cleaning, augmentation, etc. Without further details, we cannot confirm exactly what preprocessing steps were applied in this study.

Based on common practices in machine learning and computer vision tasks involving deep learning, it is reasonable to assume that the authors might have employed some or all of these preprocessing techniques. Normalization helps scale pixel values between 0 and 1, while scaling could involve resizing images to fit the required dimensions of the input layer of the deep learning model. Cleaning may refer to removing noise or irrelevant features from the images, and augmentation involves applying various transformations like rotation, flipping, zooming, etc., to increase the diversity of the training dataset.

Without additional information, we cannot definitively state the exact preprocessing steps followed in this research. Nonetheless, given the prevalence of such techniques in similar studies, it is likely that some combination of them was utilized here as well.