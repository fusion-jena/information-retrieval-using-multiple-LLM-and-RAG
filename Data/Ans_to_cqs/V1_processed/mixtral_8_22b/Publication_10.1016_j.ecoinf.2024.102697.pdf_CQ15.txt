The given context does not provide information about specific optimization techniques such as Stochastic Gradient Descent (SGD) or Adaptive Moment Estimation (Adam) being applied in the deep learning pipeline. However, it mentions that hyperparameter optimization was performed using Bayesian Optimization during the model development process. This suggests that Bayesian Optimization was employed to optimize the parameters of the machine learning model, which in this case is a Random Forest model. It should be noted that while Bayesian Optimization can be used for hyperparameter tuning in various types of machine learning models, including deep learning models, the context only discusses its application within the Random Forest framework. Therefore, without additional information, we cannot definitively state whether optimization techniques like SGD or Adam were utilized in the deep learning pipeline.