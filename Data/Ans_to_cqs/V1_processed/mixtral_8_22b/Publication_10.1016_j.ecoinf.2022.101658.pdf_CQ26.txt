The text does not explicitly mention specific techniques such as stratified splitting, oversampling, or undersampling to address data bias during preprocessing of the deep learning pipeline. However, it does discuss the use of data augmentation strategies to increase the training set size fourfold. These strategies include horizontal flipping, adding Gaussian noise, and reducing contrast. While these methods do not directly target class imbalances, they help improve model robustness and generalization by increasing the diversity of the training data. Additionally, the authors acknowledge the challenge posed by high class-imbalance in their study, suggesting that diverse data collection could potentially mitigate this issue.