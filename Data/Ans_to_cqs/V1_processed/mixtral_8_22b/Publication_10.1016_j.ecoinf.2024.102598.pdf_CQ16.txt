In this study, the authors did not explicitly mention specific criteria for determining when training is complete. However, they do provide some information about how they approached model training and validation. They used a 10-fold cross-validation (CV) design, which means that the dataset was divided into 10 equal parts or folds. Nine of those folds were used for training the model, while the remaining fold was used for testing or validation. This process was repeated 10 times, such that each fold served once as the validation set.

For each run of the cross-validation procedure, 30% of the forest fire occurrence data was reserved as a validation set, with the remaining 70% of the data being used to train the model. This suggests that the authors might have used some form of early stopping based on the performance of the model on the validation set during training. Early stopping is a technique used to prevent overfitting by halting the training process before the model starts to fit the noise in the training data. It can be implemented by monitoring the performance of the model on a separate validation set and stopping the training process when the performance stops improving or even starts deteriorating.

However, without explicit mention of the use of early stopping or other specific criteria for determining when training is complete, it cannot be definitively stated what criteria were used in this particular study.