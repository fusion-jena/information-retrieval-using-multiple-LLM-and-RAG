To ensure the generalizability of their deep learning model, J. Soom et al. employed several measures. Firstly, they utilized a diverse dataset consisting of six different environmental conditions: Turbidity, Biofilm, Overexposure, Bubbles, Clear, and Low Light. This diversity in the dataset helped prevent overfitting and improved the model's ability to perform well with unseen data. Secondly, they implemented cross-validation, which involves dividing the dataset into multiple subsets or folds and training the model on one fold while validating it on another. This process is repeated for all combinations of train/validate splits, allowing the model to be trained and tested on various portions of the dataset. Cross-validation helps assess the model's performance more accurately by reducing bias and variance. Lastly, although not explicitly mentioned in the given context, stratified splitting might have been applied to maintain the same distribution of classes across the different folds during cross-validation. In summary, J. Soom et al. ensured the generalizability of their deep learning model through utilizing a diverse dataset, implementing cross-validation, and possibly employing stratified splitting.