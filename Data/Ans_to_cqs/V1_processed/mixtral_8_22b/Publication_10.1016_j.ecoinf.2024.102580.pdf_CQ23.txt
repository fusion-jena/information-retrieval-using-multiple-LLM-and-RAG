To ensure the generalizability of the deep learning model, several measures were taken. Firstly, a diverse dataset was created for both the semantic segmentation model and the DETR model. For the semantic segmentation model, a dataset consisting of various substrate types such as vegetation, bare substrate, and 'other' classes was used. Similarly, for the DETR model, a dataset containing different species of sea turtles was utilized. This diversity in datasets allowed the models to learn from a wide range of examples, thereby improving their ability to generalize well to unseen data.

Secondly, cross-validation was employed during the training process. Cross-validation is a technique used to assess how accurately a predictive model will perform in practice. In this study, k-fold cross-validation might have been used, where the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, one subsample is retained as the validation data for testing the model, while the remaining kâˆ’1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The results from the folds are averaged to produce a single estimation.

Lastly, stratified splitting could also have been applied to maintain the same distribution of target variables across the splits. This ensures that each fold is representative of the whole and prevents any bias towards certain classes or features. However, the paper does not explicitly mention the use of stratified splitting. Therefore, while we can confirm the use of diverse datasets and cross-validation, the application of stratified splitting remains uncertain based on the given information.