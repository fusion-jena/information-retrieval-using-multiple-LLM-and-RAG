To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the model was evaluated on single and multi-label classification problems, and three different sites were considered in the experiments. This allowed for the assessment of the model's performance on different datasets and its ability to generalize across different sites.

Additionally, the model was evaluated in cross-site scenarios, where the model was trained on data from one site and tested on data from a different site. This allowed for the assessment of the model's ability to generalize to new, unseen data.

Furthermore, the authors proposed a classification decision committee (CDC) constituted by an ensemble of networks, where the individual predictions are fused through a majority voting mechanism. This allowed for the combination of the predictions of multiple models, which can help to improve the generalizability of the model.

The authors also mentioned that there is room to improve the generalization capacity of the deep learning classifiers by better exploiting the training data, such as using additional data augmentation techniques or simplifying the classifiers in terms of the number of parameters to reduce the risk of overfitting.

However, it is not mentioned whether the dataset was diverse, or if cross-validation or stratified splitting were used.