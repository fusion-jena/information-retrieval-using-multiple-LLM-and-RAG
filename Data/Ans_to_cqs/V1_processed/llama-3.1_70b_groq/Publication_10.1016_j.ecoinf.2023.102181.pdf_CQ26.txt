The provided context does not specifically discuss techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention some techniques that can be used to address biased model training and validation in the context of machine learning models with clustered data.

Some of the techniques mentioned in the context include:

* Inverse probability bootstrap sampling to eliminate sample-induced bias (Nahorniak et al., 2015)
* Covariance-weighted bagging to reduce bias during model training (mentioned in the context, but not explicitly explained)
* Bootstrap aggregation (bagging) to address both sources of bias using bootstrapping

Additionally, the context mentions the importance of considering spatially correlated map errors that may result from modeling clustered sample data and proposes using residual spatial autocorrelation information in the bagging procedure to correct for the effects of clustering sampling.

It does not mention stratified splitting, oversampling, undersampling, or diverse data collection as techniques to address data bias. These techniques are commonly used in deep learning pipelines, but they are not discussed in the provided context.

Therefore, the answer to the query is that the context does not provide a comprehensive list of techniques to address data bias during preprocessing of the deep learning pipeline, but it mentions some techniques that can be used to address biased model training and validation in specific contexts.