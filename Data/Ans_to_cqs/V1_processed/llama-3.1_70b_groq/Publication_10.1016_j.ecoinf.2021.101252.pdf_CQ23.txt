The text does not explicitly mention measures taken to ensure the generalizability of the deep learning model, such as using a diverse dataset, cross-validation, or stratified splitting. However, it does mention that the data was balanced by randomly duplicating presence records and deleting absence records until a balance of ~50:50 is obtained. This was done to address the issue of strong class imbalance, which can bias models towards the prediction of majority classes.

Additionally, the text mentions that the AutoML procedure involves training candidate models on a small subset of the data (At) and then evaluating their performance on a left-out validation data set (Av). The selected candidate model is then trained on the full training data (Bt). This suggests that some form of data partitioning and validation is being used, but the specifics of the approach are not detailed.

Overall, while the text does not provide a comprehensive answer to the question, it suggests that some measures were taken to address issues related to data imbalance and model evaluation, but the generalizability of the model is not explicitly addressed.