To ensure the generalizability of the models, several measures were taken. Firstly, a 10-fold cross-validation (CV) design was used to calibrate and validate each model. This involved reserving 30% of the forest fire occurrence data as a validation set, with the remaining 70% being used to train the model. This rigorous validation methodology was adopted following the method explained by Eskandari et al. (2021).

Additionally, the performance of each model was evaluated using several metrics, such as AUC, TSS, Kappa, and phi. The outcomes of these evaluations were presented in Table 3, and Fig. 4 visually illustrated the predictive performance of each model with AUC values for both training and test datasets.

Furthermore, the difference between the AUC (train) and AUC (CV), represented as Î” AUC, was computed for each model to evaluate its sensitivity to the training data. This provided insights into the model's complexity and its ability to generalize well to unseen data.

It is worth noting that the context does not mention the use of a diverse dataset or stratified splitting as measures to ensure generalizability. However, the use of cross-validation and evaluation of model performance using multiple metrics suggest that efforts were made to ensure the models' ability to generalize well to new data.