Unfortunately, the provided context does not mention specific optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context appears to focus on the use of pre-trained models (e.g., VGG16, ResNet152V2, BirdNet), transfer learning, and active learning strategies for audio classification tasks. It does not provide information on the optimization techniques used for training or fine-tuning these models. Therefore, I do not know the answer to this question based on the provided context.