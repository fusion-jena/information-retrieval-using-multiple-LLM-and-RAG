Unfortunately, the provided context does not explicitly mention strategies for handling randomness in the deep learning pipeline, such as setting a random seed value. The context primarily focuses on the application of convolutional neural networks (CNNs) for predicting water quality and algal blooms in various lakes, discussing the architecture, methodology, and results of the studies.

However, in general, deep learning pipelines often employ techniques to handle randomness, such as:

* Setting a fixed random seed value to ensure reproducibility of results
* Using techniques like dropout, batch normalization, or data augmentation to reduce overfitting and improve model generalization
* Employing ensemble methods, such as bagging or boosting, to combine the predictions of multiple models trained on different random seeds

Unfortunately, the provided context does not provide specific information on how randomness is handled in the deep learning pipeline.