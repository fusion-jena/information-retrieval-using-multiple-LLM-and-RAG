To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the dataset used was diverse, consisting of 59,441 samples from ten of the most profitable and endangered species in the Peruvian Amazon Forestry. The dataset was collected using six different commercial cameras to ensure variability and to develop a flexible solution that can work with real-world conditions.

Additionally, the data distribution was split into training (70.12%), validation (1.69%), and testing (28.19%) sets. This splitting helps to prevent overfitting and ensures that the model is evaluated on unseen data.

Furthermore, the model was fine-tuned using pre-trained architectures (AlexNet, VGG-19, ResNet-101, and DenseNet-201) that were trained on the ImageNet dataset. This transfer learning approach allows the model to leverage features learned from a large and diverse dataset, which can improve its generalizability.

The use of mini-batches (16 elements per batch) and the ADAM optimizer with a learning rate of 1e-3 also helps to improve the model's generalizability by reducing the risk of overfitting.

However, it is not explicitly mentioned whether cross-validation or stratified splitting were used. Therefore, I do not know if these specific measures were taken to ensure the generalizability of the model.