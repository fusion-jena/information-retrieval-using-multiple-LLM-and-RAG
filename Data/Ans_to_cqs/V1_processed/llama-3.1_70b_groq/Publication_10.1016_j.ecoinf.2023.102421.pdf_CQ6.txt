Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. The context primarily focuses on the training process, hyperparameter optimization, and model evaluation. It mentions that the training dataset is in a tabulated format, but it does not provide information on any preprocessing steps such as normalization, scaling, or cleaning that may have been performed on the data.

However, it does mention that the dataset was divided into two parts, with 80% used for training/validation and 20% kept as unseen data for testing. It also mentions that 10-fold cross-validation was used during the training process, but it does not provide information on any preprocessing steps that may have been performed on the data before training.

Therefore, I do not have enough information to provide a specific answer to the query.