Unfortunately, the provided context does not mention the specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The text only discusses the model architecture, data preprocessing, and the use of a pre-trained ResNet50 model, but it does not provide information on the optimization techniques used during training.