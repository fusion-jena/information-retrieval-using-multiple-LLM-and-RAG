Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. The text primarily focuses on the architecture of the baseline model, the use of one-hot encoding, and the general concept of deep learning. It does not provide information on the specific preprocessing steps such as normalization, scaling, or cleaning that are typically involved in preparing data for training a deep learning model.

However, it does mention that the input to the baseline model is a spectrogram, which suggests that some form of preprocessing may have been applied to the data to convert it into a suitable format for the model. Nevertheless, the exact preprocessing steps are not specified in the provided context.

Therefore, I do not have enough information to provide a detailed answer to the query.