The context provided does not explicitly mention the criteria used to determine when training is complete. However, in machine learning, it is common to use various techniques to determine when training is complete, such as:

1. Validation loss plateau: This is a common technique used to determine when training is complete. The model is trained until the validation loss stops improving, indicating that the model has learned the underlying patterns in the data.

2. Early stopping: This is a technique used to prevent overfitting by stopping the training process when the model's performance on the validation set starts to degrade.

3. Monitoring metrics: The model's performance on the validation set is monitored, and training is stopped when the desired level of performance is achieved.

4. Time-based: Training is stopped after a fixed amount of time, regardless of the model's performance.

It's worth noting that the context provided is related to machine learning and classification, but it does not provide enough information to determine the specific criteria used to determine when training is complete.