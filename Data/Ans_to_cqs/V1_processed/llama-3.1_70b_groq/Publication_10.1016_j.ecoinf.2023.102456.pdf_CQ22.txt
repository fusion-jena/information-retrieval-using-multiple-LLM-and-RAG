The metrics used to evaluate the performance of the deep learning model include accuracy, F1-score, and confusion matrices, among others. Specifically, the use of confusion matrices provides detailed information regarding both correct and incorrect classifications made by the model. This valuable insight enables the identification of potential deficiencies in classifying specific classes or categories.

In addition to these metrics, the model's performance is also evaluated using false positive (FP) and false negative (FN) percentages, which measure the percentage of hits that the model achieves for each class. Other metrics used include balanced accuracy (B. Acc), F-measure Fβ, Cohen’s kappa coefficient k, and Matthew’s correlation coefficient (MCC). These metrics have proven to be adequate in similar contexts, although they have their own limitations.

These metrics are used to provide a comprehensive assessment of the model's performance and effectiveness. The results of these metrics are presented in Table 1, which shows the relationship between the model's parameters and the final results obtained in the real-world fire scenario. The use of these alternative measures gives a more complete and accurate picture of the model's performance, which is essential for proper evaluation.