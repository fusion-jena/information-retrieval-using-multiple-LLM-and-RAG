To ensure the generalizability of the deep learning model, several measures were taken. 

Firstly, a random sample of 10% of the dataset of each trait was extracted as a 'test dataset' which was not involved in the training process and was used exclusively for the independent evaluation of the trained models. This helps to prevent overfitting and ensures that the model's performance is evaluated on unseen data.

Secondly, the remaining data was split into 'training dataset' and 'validation dataset' by a ratio of 4:1. The training dataset was used to train the weights of the CNN model, while the validation dataset was used to track the training progress after each full training cycle (epoch). This helps to prevent overfitting and ensures that the model is not over-specialized to the training data.

Thirdly, a 3-fold cross-validation was used to assess the final model performance. This involves splitting the data into three different training, validation, and test splits, and evaluating the model's performance on each split. This helps to ensure that the model's performance is not dependent on a particular split of the data.

Lastly, a stratified sampling design was used to collect the data, with each species being a stratum, and up to eight images per species were collected to acquire a sufficient amount of training data while balancing the taxonomic evenness. This helps to ensure that the model is trained on a diverse dataset and can generalize well to different species.

Overall, these measures help to ensure that the deep learning model is generalizable and can perform well on unseen data.