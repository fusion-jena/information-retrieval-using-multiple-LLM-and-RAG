The provided context mentions the use of Monte Carlo Dropout (MCD) as a regularization technique to prevent overfitting in deep learning models. Specifically, it states that MCD is a convenient technique for performing Bayesian deep learning and that it corresponds to an approximate variational distribution, resulting in uncertainty estimates.

Additionally, the context mentions that other variants of dropout follow a similar interpretation and correspond to alternative approximate distributions, which would result in different uncertainty estimates. This suggests that dropout is a regularization method used to prevent overfitting in the deep learning pipeline.

However, the context does not mention L2 regularization as a regularization method used in the deep learning pipeline. It only mentions dropout and its variants as regularization techniques.

Therefore, based on the provided context, the regularization method used to prevent overfitting in the deep learning pipeline is dropout, specifically Monte Carlo Dropout.