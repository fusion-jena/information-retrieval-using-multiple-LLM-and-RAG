Unfortunately, the provided context does not explicitly mention the measures taken to ensure the generalizability of the deep learning model. The text focuses on the architecture of the Bayesian Deep Learning model, its performance, and the metrics used to evaluate it. However, it does mention that the model is designed to handle limited datasets, which suggests that the authors may have taken steps to ensure generalizability.

One possible indication of generalizability is the use of Monte Carlo Dropout (MCD) and Variational Bayes Inference (VBI) approaches, which are mentioned in the context. These approaches can help to regularize the model and prevent overfitting, which is a common issue in deep learning models. However, without further information, it is unclear whether these approaches were used specifically to ensure generalizability.

Additionally, the text mentions that the model was evaluated on a test set, which suggests that some form of splitting or cross-validation may have been used. However, the specific details of the splitting or cross-validation procedure are not provided.

Overall, while the context suggests that the authors may have taken steps to ensure generalizability, the specific measures taken are not explicitly stated.