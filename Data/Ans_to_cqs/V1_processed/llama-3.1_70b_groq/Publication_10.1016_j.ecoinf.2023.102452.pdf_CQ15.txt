Unfortunately, the provided context does not explicitly mention the optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context appears to be focused on various topics related to machine learning, signal processing, and hydroinformatics, but it does not provide specific information on optimization techniques used in deep learning.

However, it is worth noting that some of the papers mentioned in the context, such as those related to neural networks and genetic programming, may implicitly involve optimization techniques. For example, the paper by Ang et al. (2022) mentions a modified particle swarm optimization algorithm for optimizing artificial neural networks. However, this is not directly related to the deep learning pipeline.

Therefore, based on the provided context, I do not have enough information to provide a specific answer to the query.