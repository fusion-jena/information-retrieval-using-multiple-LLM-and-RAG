Unfortunately, the provided context does not explicitly mention the data augmentation techniques applied in the deep learning pipeline. The context primarily focuses on the utility of computer vision techniques, machine learning, and deep learning algorithms in ecology and evolutionary biology, as well as the use of pre-trained CNNs and their limitations.

However, it does mention that the overarching goal of training a neural network is to iteratively minimize the error between model output and expected output by optimally adjusting model weights and reaching model convergence. It also mentions the use of stochastic gradient descent with backpropagation for adjusting model weights.

While data augmentation techniques such as flipping, rotating, and scaling are commonly used in deep learning pipelines to increase the diversity of the training data and improve model generalization, they are not explicitly mentioned in the provided context. Therefore, I cannot provide a definitive answer to the query based on the given information.