Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does mention the importance of the quality and quantity of the sample dataset in training an Artificial Neural Network (ANN) model (Yang et al., 2018). It also mentions the process of trial and error in determining the optimal number of hidden layers and neurons in the ANN model.

In general, common practices in splitting data for deep learning model training include:

* Random splitting: dividing the data into training, validation, and test sets using random sampling.
* Stratified splitting: dividing the data into training, validation, and test sets while maintaining the same proportion of class labels in each set.
* K-fold cross-validation: dividing the data into k subsets and using each subset as a test set while the remaining subsets are used for training.

However, without more specific information from the provided context, it is difficult to provide a more detailed answer.