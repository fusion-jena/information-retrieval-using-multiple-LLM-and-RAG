The criteria used to split the data for deep learning model training are not explicitly stated in the provided context. However, based on the information given, it appears that the data is split into several partitions, including:

* At: a small subset of the data used to train candidate models
* Av: a left-out validation data set used to compare the performance of candidate models
* Bt: the full training data used to train the selected model
* Bv: a holdout data partition used to monitor the model's validation performance and identify the optimal number of training epochs
* T: a final test data set used to evaluate the performance of the model with the optimal number of training epochs

It is not clear what specific criteria are used to split the data into these partitions, such as the proportion of data allocated to each partition or the method used to select the data points for each partition.