The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention that the data is split into several larger blocks depending on coordinates for cross-validation purposes, and then into smaller areas of 80 Ã— 80 pixels. This suggests that some form of data partitioning is used, but it is not clear if this is done to address data bias specifically.

Additionally, the context mentions that the model is trained on a subset of the data and validated on a separate subset, which is randomly selected from all areas used in the training set. This suggests that some form of random sampling is used, but again, it is not clear if this is done to address data bias.

There is no mention of techniques such as stratified splitting, oversampling, undersampling, or diverse data collection in the provided context. Therefore, I do not know what specific techniques are used to address data bias during preprocessing of the deep learning pipeline.