The provided context does not explicitly mention the optimizer used in the deep learning model. However, it does mention the learning rate used in the hyperparameter fine-tuning results. According to Table 1, the learning rates used in the different scenarios are:

- 0.001 (Scenarios 1-7)
- 0.01 (Scenario 8)
- 0.0005 (Scenario 9)
- 0.00001 (Scenario 10)

Additionally, the context mentions the number of blocks and the number of filters used in the different scenarios. However, it does not provide information about other hyperparameters such as the optimizer, batch size, or activation functions.