The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, based on the information provided in the context, it can be inferred that the model performance is monitored through various metrics and visualizations.

The context mentions that the training summary for each of the epochs (100, 200, and 250) is shown in Tables 5, 6, and 7, respectively. Additionally, the trends of mAP values with increasing epochs are shown in Figs. 14 and 15. This suggests that the model performance is being monitored through metrics such as mAP (mean Average Precision) and visualized through plots.

Furthermore, the context mentions that the model is tuned with optimized hyperparameters to prevent overfitting and underfitting. The effort to over-train the model has been avoided, and graded MSE convergence (Figs. 7 to 11) has been adopted to fine-tune the model. This suggests that the model performance is being monitored through metrics such as MSE (Mean Squared Error) and visualized through plots.

Overall, while the exact strategy implemented to monitor the model performance during training is not explicitly stated, it can be inferred that the model performance is being monitored through various metrics and visualizations, including mAP, MSE, and plots.