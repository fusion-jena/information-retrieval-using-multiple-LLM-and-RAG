To ensure the generalizability of the deep learning model, several measures were taken. Firstly, the dataset was split into training and testing sets using an 80% and 20% ratio, respectively. This is a common practice in machine learning to prevent overfitting and ensure that the model is evaluated on unseen data.

Additionally, the study mentions the use of cross-validation, which is a technique used to evaluate the performance of a model on unseen data. However, the specific type of cross-validation used is not specified.

Furthermore, the study mentions the use of random sampling to select sample locations for training and testing, which helps to ensure that the model is trained and tested on diverse data.

It is also worth noting that the study mentions the use of various statistical measures to evaluate the performance of the model, including R2, NSE, MEF, Z, RMSE, and MAE. These measures help to ensure that the model is performing well on both the training and testing data.

Overall, the study appears to have taken several measures to ensure the generalizability of the deep learning model, including data splitting, cross-validation, and the use of statistical measures to evaluate performance.