Unfortunately, the provided context does not mention the specific data augmentation techniques applied in the deep learning pipeline, such as flipping, rotating, or scaling. The context primarily focuses on the architecture of the CNN model, specifically the AlexNet architecture, and its application in image scene classification tasks, as well as the study's findings and conclusions.

However, it does mention that the AlexNet architecture employs practical strategies like ReLU nonlinear layers and dropout regularization techniques, which are effective for handling complex problems. But it does not provide information on data augmentation techniques.

Therefore, I don't know the specific data augmentation techniques applied in the deep learning pipeline.