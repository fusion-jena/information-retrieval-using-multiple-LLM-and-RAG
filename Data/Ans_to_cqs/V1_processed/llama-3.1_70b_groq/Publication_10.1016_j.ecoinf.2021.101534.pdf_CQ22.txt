The performance metrics used to evaluate the deep learning model include:

1. Area under the ROC curve (AUC) for each sound class
2. Average precision (AP) for each sound class
3. Mean average precision (mAP) for the overall model
4. Macro-average AUC for the overall model
5. Precision, recall, and F1 score for each class, plotted as curves to examine class-specific performance and its changes with threshold scores.

These metrics are calculated using the scikit-learn package. The specific values of these metrics are reported in the text, including AP values ranging from 0.49 to 0.96 for different classes, and a mAP of 0.83 for the overall model.