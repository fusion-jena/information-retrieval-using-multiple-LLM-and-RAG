The provided context does not specifically mention the preprocessing steps involved in training a deep learning model. However, it does describe the data curation process applied to the dataset obtained from GBIF and OBIS. 

According to the text, the following preprocessing steps were applied to the dataset:

1. Taxonomic filtering: The dataset was filtered to retain only taxonomic information down to the species level.
2. Removal of records with NA values: Records with missing values in the columns labeled "scientific name", "family", "year", "longitude", and "latitude" were removed.
3. Removal of duplicate records: Duplicate records with identical latitude and longitude values were removed.
4. Data curation: The dataset was curated following the guidelines provided by Zizka et al. (2020).

It is not clear if these preprocessing steps are specific to the analysis presented in the text or if they are general preprocessing steps that can be applied to any dataset. Additionally, the text does not mention normalization or scaling, which are common preprocessing steps in deep learning. Therefore, I do not know if these steps were applied to the dataset.