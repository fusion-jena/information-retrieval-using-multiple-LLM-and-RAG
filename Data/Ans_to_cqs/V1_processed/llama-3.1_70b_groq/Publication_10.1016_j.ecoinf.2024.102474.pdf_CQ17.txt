The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that the AdamW optimizer is used, which "decouples the weight decay" (Section 2.4). This suggests that weight decay, a form of L2 regularization, is used as a regularization method in the model.