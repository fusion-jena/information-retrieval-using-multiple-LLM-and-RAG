The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does mention the use of data augmentation to extend the amount of data, which can help reduce the impact of randomness in the training data. Additionally, the context mentions the use of a fixed number of epochs (200) and a fixed batch size (16) during training, which can help reduce the randomness in the training process. However, it does not provide information on whether a random seed value was set to ensure reproducibility of the results.