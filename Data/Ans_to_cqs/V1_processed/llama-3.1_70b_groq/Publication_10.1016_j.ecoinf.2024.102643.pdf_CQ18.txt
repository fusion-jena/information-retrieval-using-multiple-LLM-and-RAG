To monitor the model performance during training, the strategy implemented was to split the collected data into training (80%) and testing (20%) datasets. Additionally, pseudo-absence points were generated three times for each model and cross-validated per model using bootstrapping. This approach helps to avoid sampling bias and evaluate the performance of the model.