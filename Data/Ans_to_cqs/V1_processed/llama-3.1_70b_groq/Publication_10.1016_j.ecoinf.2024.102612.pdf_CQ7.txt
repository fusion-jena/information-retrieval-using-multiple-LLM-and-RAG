Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context discusses the training process, evaluation metrics, and the use of a pre-trained model for inference on real MS point clouds, but it does not provide information on how the data was split for training, testing, and validation.

However, it is mentioned that the model was trained over 1000 epochs for each type of input data, and metrics such as MIoU or MA were computed after each epoch to analyze the training performance. This suggests that the model was trained using a iterative process, but the specifics of the data splitting criteria are not provided.

Therefore, I do not know the exact criteria used to split the data for deep learning model training, and I cannot provide a more detailed answer.