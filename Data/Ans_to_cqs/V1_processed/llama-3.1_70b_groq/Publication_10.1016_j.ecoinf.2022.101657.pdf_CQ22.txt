The metrics used to evaluate the performance of the deep learning model include mean average precision (mAP), specifically mAP50, which takes the mean over all considered species of their respective, species-specific average precision. The mAP metric requires that the area of the intersection of ground truth bounding box and predicted bounding box needs to be at least 50% of the area of the union of both for an otherwise true species identification to be considered correct.

Additionally, the model's performance is also evaluated using the Eα metric, which is the weighted harmonic mean between specificity (S) and recall (R) with α ∈ [0, 1] and S, R ∈ (0, 1]. This metric allows for mediation between specificity and recall, and higher values indicate better performance.

The Matthews Correlation Coefficient (MCC) is also mentioned as a possible metric, but it is not used in this case because it is a single number that does not allow for mediation between the two use cases. Instead, the Eα metric is used, which provides a more nuanced evaluation of the model's performance.