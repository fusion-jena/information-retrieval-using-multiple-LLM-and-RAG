Unfortunately, the provided context does not mention the process followed to deploy the trained deep learning model. The context only discusses the training process, including the computing platform used (Dell PowerEdge C4130 rack server with two Tesla K80 GPUs and 256 GB of memory), the deep learning environment (PyTorch 1.7.1), and the optimizer used (Stochastic Gradient Descent with a momentum value of Î¼ = 0.9). It also mentions the hyper-parameter settings for model training, which are shown in Table S.4 of the Supporting Information. However, it does not provide information on how the trained model was deployed.