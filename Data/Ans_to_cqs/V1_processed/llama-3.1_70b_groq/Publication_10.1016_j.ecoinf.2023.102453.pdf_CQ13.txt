The hyperparameters used in the deep learning model mentioned in the context are:

1. Learning rate: This is the most commonly mentioned hyperparameter in the context. It is optimized using Hyperband and Bayesian Optimization techniques. The optimal value of the learning rate is found to be 0.00001 for both the EfficientNetV2B0 and MobileNetV2 models.

2. Batch size: This is mentioned as one of the common hyperparameters for a DNN model, but it is not optimized or discussed in detail in the provided context.

3. Dropout: This is also mentioned as one of the common hyperparameters for a DNN model, but it is not optimized or discussed in detail in the provided context.

The optimizer is not explicitly mentioned in the context, but it is mentioned that the learning rate is optimized, which suggests that an optimizer is used. However, the type of optimizer is not specified.

It is also mentioned that different models have different numbers and types of hyperparameters, and trying to fully optimize each will require considerable compute resources and time.