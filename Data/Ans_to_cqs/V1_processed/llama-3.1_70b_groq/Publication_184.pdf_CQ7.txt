Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the training process, hyper-parameters, and data augmentation techniques used for the Yolo model. It does mention that the model was trained and validated, but it does not provide information on how the data was split for these purposes.

However, it does mention that for each epoch, 64 images are randomly selected and used to train the model, and that each image is used multiple times due to the limited number of samples. This suggests that the training data may have been randomly sampled, but the exact criteria for splitting the data into training, test, and validation sets is not provided.

Therefore, I do not have enough information to provide a specific answer to this question.