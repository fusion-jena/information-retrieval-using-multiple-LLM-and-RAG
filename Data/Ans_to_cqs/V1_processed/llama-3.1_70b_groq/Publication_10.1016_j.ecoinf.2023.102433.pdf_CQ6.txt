The provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. However, based on general knowledge of deep learning, common preprocessing steps typically include normalization, scaling, and cleaning of the data.

Normalization involves scaling numeric data to a common range, usually between 0 and 1, to prevent features with large ranges from dominating the model. Scaling involves transforming data to have zero mean and unit variance, which can improve the stability and speed of training. Cleaning involves handling missing values, outliers, and noisy data to ensure the quality of the data.

Additionally, the context mentions the use of PyTorch, a popular deep learning framework, but it does not provide specific details on preprocessing steps. The book "Deep Learning with Python" by Ketkar and Jojo (2021) might cover these topics, but the provided context does not provide enough information to provide a detailed answer.

Therefore, while we can make some educated guesses about common preprocessing steps, the specific steps involved in a particular deep learning project would depend on the specific requirements of the project and the characteristics of the data being used.