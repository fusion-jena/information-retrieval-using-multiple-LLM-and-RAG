The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it is mentioned that the validation set is used to estimate prediction error for model selection and hyperparameter tuning. This suggests that the model performance is monitored during training using the validation set, but the specific strategy or metrics used for this purpose are not mentioned.

It is also mentioned that cross-validation methods are used to assess the accuracy of the model, including k-fold cross-validation, random cross-validation, blocked spatial cross-validation, and weighted cross-validation. These methods involve splitting the dataset into subsets or folds and using each fold to evaluate the model's performance. However, it is not clear if these methods are used to monitor the model performance during training or only to evaluate the final model.

Therefore, while it can be inferred that the validation set and cross-validation methods are used to monitor and evaluate the model performance, the specific strategy implemented during training is not explicitly stated in the provided context.