The provided context does not explicitly mention the preprocessing steps involved before training a deep learning model, such as normalization, scaling, or cleaning. However, it does mention the use of data augmentation techniques during training, which can be considered a form of preprocessing.

According to the context, the following data augmentation techniques were applied to the training data:

* Random crop
* Mosaic
* Color distortions (brightness, contrast, saturation, hue)
* Gaussian blur
* Random scaling
* Random rotation
* Random horizontal flipping

These techniques are used to artificially increase the size of the dataset and help the model generalize better to new, unseen data. However, it is not clear if any other preprocessing steps, such as normalization or scaling, were applied to the data before training.

Therefore, the answer to the query is that the context does not provide a comprehensive list of preprocessing steps involved before training a deep learning model, but it does mention the use of data augmentation techniques during training.