The optimization technique applied in the deep learning pipeline, as mentioned in the provided context, is the Adam optimizer. Specifically, it is used to train the geographic prior with a learning rate of 0.0005 and a batch size of 32 for 10 epochs. There is no mention of other optimization techniques such as SGD being used in the pipeline.