The provided context does not explicitly mention the postprocessing steps involved after the model training, such as Saliency maps, Metrics calculation, or Confusion matrix. However, it does mention that the model's performance was evaluated using the AUC (Area Under ROC Curve) metric. 

The context states that the model's performance was validated by using 70% of the data for calibration and 30% for testing. The AUC metric was used to assess the model's performance in predicting the species probability distribution. However, it does not provide information on other postprocessing steps such as Saliency maps or Confusion matrix.