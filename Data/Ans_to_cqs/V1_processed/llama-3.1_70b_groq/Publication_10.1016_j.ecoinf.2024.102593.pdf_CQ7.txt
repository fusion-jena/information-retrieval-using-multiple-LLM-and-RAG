Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The text discusses various aspects of deep learning, such as active learning, dimensionality reduction, and model embeddings, but it does not provide information on data splitting criteria.

However, it does mention that the authors "generated embeddings using the BirdNET model on a randomly selected 40% sample of the [dataset]" (Section 4.7). This suggests that random sampling was used to select a subset of the data for a specific experiment, but it does not provide a general answer to the question of how the data was split for training, testing, and validation.

Therefore, I must conclude that the provided context does not contain enough information to answer the query.

 I don't know.