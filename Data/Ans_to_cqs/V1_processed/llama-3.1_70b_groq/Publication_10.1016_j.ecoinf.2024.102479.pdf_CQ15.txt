Unfortunately, the provided context does not mention specific optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on hyperparameter tuning using Grid Search Cross-Validation (GSCV) for various machine learning algorithms, including Random Forest, Support Vector Machine, and Artificial Neural Network. However, it does not delve into the specifics of optimization techniques used in the deep learning pipeline. Therefore, I don't know the answer to this question based on the provided context.