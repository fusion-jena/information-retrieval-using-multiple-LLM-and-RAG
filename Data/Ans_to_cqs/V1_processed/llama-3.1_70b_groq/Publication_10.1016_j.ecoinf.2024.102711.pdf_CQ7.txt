The provided context does not specifically discuss the criteria used to split the data for deep learning model training. However, it does mention the process of splitting the development dataset into training and tuning datasets for hyperparameter tuning using k-fold cross-validation.

According to the text, the development dataset is evenly divided into k groups, and during each iteration, one group is used as the tuning dataset, while the remaining groups are used as the training dataset. The performance of the model is evaluated using the tuning dataset, and the average performance of the k models represents the performance of the machine learning technique for the selected hyperparameters.

In this specific study, a value of 5 is assumed for k, meaning the data is split into 5 folds. However, the text does not provide general criteria for splitting data into training, test, and validation sets for deep learning model training.

It is worth noting that the context mentions the importance of using an independent dataset for model evaluation to avoid overfitting and to get a true representation of the model's performance.