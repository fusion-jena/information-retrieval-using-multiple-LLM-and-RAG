The provided context does not specifically mention the criteria used to split the data for deep learning model training. However, it does mention that the training dataset was divided into two parts, where 80% was used for training/validation, and the remaining 20% was kept as unseen data for testing. This suggests that the data was split into training, validation, and testing sets, but the exact criteria used for this split are not specified.

It is common in machine learning to split the data into training, validation, and testing sets to evaluate the performance of the model. The training set is used to train the model, the validation set is used to tune the hyperparameters, and the testing set is used to evaluate the final performance of the model. However, the exact proportion of the data used for each set can vary depending on the specific problem and the size of the dataset.

In this case, the context mentions that 10-fold cross-validation was used during the training process, which is a technique used to evaluate the performance of the model on unseen data. However, it does not provide further details on the criteria used to split the data.