Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The text discusses the use of KERAS and Scikit-Learn packages for building and scaling the LSTM model, but it does not provide information on how the data was split for training, testing, and validation.

However, it does mention that the prediction error was obtained by calculating the difference between the predicted value and the validation data at different starting times. This suggests that some form of validation was used to evaluate the model's performance, but the specific criteria for splitting the data are not mentioned.

Therefore, I do not know the exact criteria used to split the data for deep learning model training in this context.