I don't know.

The provided context does not mention the specific criteria used to split the data for deep learning model training. It mentions the limitations of the current methodology, the challenges of working with tweets, and the use of the twarc2 library to handle Twitter API data. However, it does not provide information on how the data is split for training, testing, and validation.