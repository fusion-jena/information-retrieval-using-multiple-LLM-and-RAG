Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. However, it does mention that the training and testing datasets were generated through reference to existing field datasets and VHR images, and that the seasonal vegetation index composites from S2, backscatter composites from S1, elevation, and slope were used as input to the ML algorithm.

It also mentions that the polygons were split into calibration and validation sets, with ~30% of pixels for each VT reserved for independent model validation. This suggests that some form of data splitting and partitioning was performed, but it does not provide information on normalization, scaling, or cleaning.

Therefore, I do not know the specific preprocessing steps involved before training the deep learning model, as this information is not provided in the context.