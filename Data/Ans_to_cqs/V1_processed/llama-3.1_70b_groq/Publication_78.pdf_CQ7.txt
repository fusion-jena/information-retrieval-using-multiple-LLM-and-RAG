Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, I can provide general information on common practices used in the field.

Typically, the data is split into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to evaluate the model's performance during training and adjust hyperparameters, and the testing set is used to evaluate the final performance of the model.

The common criteria used to split the data include:

* Random splitting: The data is randomly divided into training, validation, and testing sets.
* Stratified splitting: The data is split in a way that maintains the same proportion of classes in each set.
* K-fold cross-validation: The data is split into k folds, and each fold is used as a testing set while the remaining folds are used as training sets.

The provided context does not specify the exact criteria used to split the data for the deep learning models mentioned, such as CoralNet, AlexNet, ResNet-50, VGG-19, GoogleNet, and Inceptionv3.