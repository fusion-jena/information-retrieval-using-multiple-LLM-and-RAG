The optimization technique applied in the deep learning pipeline is ADAM (Kingma and Ba, 2017). According to Table 1, which lists the hyperparameters utilized for training the Recurrent Neural Network model, the optimizer used is ADAM with a learning rate of 0.003.