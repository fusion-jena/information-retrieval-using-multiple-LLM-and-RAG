The provided context does not explicitly mention the postprocessing steps involved after model training, such as saliency maps, metrics calculation, or confusion matrix. However, it does mention the evaluation metrics used to assess the model's performance, including:

* Area Under the Curve (AUC)
* True Skill Statistics (TSS)
* Cohen's KAPPA
* Point-biserial correlation (COR)
* Receiver Operator Characteristics (ROC)

These metrics are used to evaluate the model's performance, but they are not postprocessing steps per se. The context also mentions the use of 10-fold bootstrapping to provide unbiased predictive accuracy and the sensitivity-specificity sum maximization technique to determine the model threshold.

It is likely that the authors calculated confusion matrices and other metrics as part of the model evaluation process, but this is not explicitly stated in the provided context. Therefore, I do not have enough information to provide a complete answer to the query.