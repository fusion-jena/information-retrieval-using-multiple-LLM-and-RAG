Unfortunately, the provided context does not mention specific methods for collecting raw data in the deep learning pipeline. The context primarily focuses on various deep learning models, such as ResNet-50, Inception-V3, and CLIP, and their applications in image classification tasks. It also discusses the use of transformers in vision models and the training procedures for these models.

However, it does mention that CLIP was trained on 400 million images from the web along with their captions. This suggests that web scraping or crawling might be one method for collecting raw data, at least for image classification tasks. Nevertheless, this is not explicitly stated, and other methods for collecting raw data are not mentioned.

Therefore, based on the provided context, I can only speculate that web scraping or crawling might be one method for collecting raw data, but I do not have enough information to provide a definitive answer.