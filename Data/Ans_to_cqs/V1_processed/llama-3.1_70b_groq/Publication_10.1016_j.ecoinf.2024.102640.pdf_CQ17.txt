Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context primarily focuses on the architecture and performance of various models, such as SegFormer, FCN, HRNet, PSPNet, and DeeplabV3+, but does not provide information on the regularization techniques used.

However, it does mention the use of the Adam optimizer with a learning rate of 0.0001 in the training of the EPDNet model, which is a neural network used to learn eye-phone distance. But it does not provide information on the regularization methods used in this model or any other model mentioned in the context.

Therefore, I don't know the specific regularization methods used to prevent overfitting in the deep learning pipeline.