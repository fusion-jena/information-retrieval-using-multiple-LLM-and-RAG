The provided context does not explicitly mention the preprocessing steps involved before training a deep learning model, such as normalization, scaling, or cleaning. However, it does mention that the input images are augmented with random horizontal flipping, random ±7° rotation, and random ±40% brightness during the self-supervised contrastive learning phase. This suggests that some form of data augmentation is used to increase the diversity of the training data, but it does not provide information on other preprocessing steps. Therefore, I do not know the complete set of preprocessing steps involved in this case.