To handle randomness in the deep learning pipeline, the authors employed a strategy of repeating the random partition of the dataset ten times. This approach helps to reduce the influence of random splitting on the performance of the model, ensuring converged performance. Additionally, the authors used techniques such as batch normalization and dropout to mitigate overfitting and accelerate the learning process. However, the specific strategy for handling the random seed value is not mentioned in the provided context.