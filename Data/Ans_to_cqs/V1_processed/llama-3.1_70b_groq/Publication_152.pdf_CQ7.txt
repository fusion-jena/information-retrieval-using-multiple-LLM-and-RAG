Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, it does mention that the data was divided into train and test datasets (Section II). It also mentions the use of epochs for training and validation, but it does not provide information on how the data was split for these purposes.

In general, common practices for splitting data in deep learning include:

- Random splitting: dividing the data randomly into training, validation, and test sets.
- Stratified splitting: dividing the data into training, validation, and test sets while maintaining the same class distribution in each set.
- K-fold cross-validation: dividing the data into k subsets and using each subset as a test set while the remaining subsets are used for training.

However, without more information from the provided context, it is impossible to determine the specific criteria used in this case.