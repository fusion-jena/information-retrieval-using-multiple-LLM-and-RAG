The hyperparameters used in the deep learning model are as follows:

* Learning rate: 0.0001
* Number of training epochs: 300
* Batch size: 24
* Dropout rate: 0.05 (implemented to prevent overfitting)

Additionally, the model uses an early stopping strategy to prevent overfitting issues, which causes the training process to converge before the last epoch.

Note that the optimizer used in the model is not explicitly mentioned in the provided context.