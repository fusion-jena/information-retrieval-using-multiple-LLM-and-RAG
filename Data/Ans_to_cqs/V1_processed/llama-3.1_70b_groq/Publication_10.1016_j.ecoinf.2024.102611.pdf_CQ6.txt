According to the provided context, the preprocessing steps involved before training a deep learning model include:

1. Resize: The images are resized to a specific size before being fed into the model.
2. Segmentation: The images are segmented to extract the relevant features.
3. Augmentation: The images are augmented to increase the sample size and improve the model's robustness.

Additionally, the context mentions that the input image is subjected to a sequence of operations and length in both the X and Y axes, but it does not provide further details on what these operations entail.

It is also worth noting that the context mentions batch normalization, which is a type of normalization technique used to normalize the input data for each layer in the model. However, this is not a preprocessing step per se, but rather a technique used within the model architecture.

Other preprocessing steps such as scaling, cleaning, and normalization are not explicitly mentioned in the provided context.