Unfortunately, the provided context does not explicitly mention the postprocessing steps involved after model training, such as Saliency maps, Metrics calculation, or Confusion matrix. The context primarily focuses on the model training process, including the use of the fast.ai platform, Leave-One-Group-Out cross-validation, and transfer learning with the ResNet-34 architecture.

However, it does mention that a cumulative evaluation was performed to measure the model's performance across all transects, using the coefficient of determination (R2) between true vs predicted values for all 648 multitemporal transects predictions. This suggests that some form of metrics calculation was performed, but the specific details are not provided.

Therefore, I can only confirm that metrics calculation was involved in the postprocessing steps, but I do not have information on Saliency maps or Confusion matrix.