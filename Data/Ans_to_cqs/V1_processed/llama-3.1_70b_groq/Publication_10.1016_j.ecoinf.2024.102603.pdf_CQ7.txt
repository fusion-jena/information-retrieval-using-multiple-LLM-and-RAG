Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context primarily discusses the differences between XGBoost and deep learning models, their computational requirements, interpretability, and performance on small datasets. It also provides information on how XGBoost works, including its use of regression decision trees and the division of data into training and validation sets in an 80:20 ratio. However, it does not provide specific details on the criteria used to split data for deep learning model training.

Therefore, I do not have enough information to provide a definitive answer to this question.