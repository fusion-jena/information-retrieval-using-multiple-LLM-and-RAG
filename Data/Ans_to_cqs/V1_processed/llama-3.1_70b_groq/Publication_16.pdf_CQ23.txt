To ensure the generalizability of the deep learning model, several measures were taken. 

Firstly, the model used dropout layers with a dropout value of 50% in the first three layers. This is a regularization technique that helps prevent overfitting by randomly dropping out nodes during training, which in turn helps the model generalize better to unseen data.

Secondly, the model was trained and validated over 100 epochs, and the performance was evaluated on both the train and validation data. This helps to ensure that the model is not overfitting to the training data and is generalizing well to the validation data.

Lastly, the model's performance was also evaluated on a test set, which is a separate dataset not used during training. This provides an unbiased estimate of the model's performance on unseen data.

However, there is no mention of using a diverse dataset, cross-validation, or stratified splitting in the provided context.