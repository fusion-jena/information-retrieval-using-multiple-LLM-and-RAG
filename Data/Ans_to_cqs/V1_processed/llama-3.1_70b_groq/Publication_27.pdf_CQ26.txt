The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, based on general knowledge, some common techniques used to address data bias include:

1. Stratified splitting: This technique involves splitting the data into training and testing sets while maintaining the same proportion of classes in both sets. This helps to ensure that the model is trained and tested on a representative sample of the data.

2. Oversampling: This technique involves creating additional copies of the minority class to balance the data. However, this can lead to overfitting, as the model may become biased towards the minority class.

3. Undersampling: This technique involves reducing the number of samples in the majority class to balance the data. However, this can lead to loss of information, as some data points are discarded.

4. Diverse data collection: This technique involves collecting data from diverse sources to ensure that the data is representative of the population. This can help to reduce bias in the data.

Other techniques that are not mentioned in the query but are commonly used to address data bias include:

1. Data augmentation: This technique involves generating new data points by applying transformations to the existing data. This can help to increase the size of the minority class and reduce bias.

2. Transfer learning: This technique involves using a pre-trained model as a starting point for the deep learning pipeline. This can help to reduce bias, as the pre-trained model has been trained on a large and diverse dataset.

3. Regularization techniques: This technique involves adding a penalty term to the loss function to discourage the model from becoming biased towards the majority class.

It is worth noting that the provided context does not mention any specific techniques used to address data bias, and the above answer is based on general knowledge.