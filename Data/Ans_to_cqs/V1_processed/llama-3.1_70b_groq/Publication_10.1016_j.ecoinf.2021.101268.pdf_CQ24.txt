Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. The context primarily focuses on the application of deep learning methods in agriculture, specifically in plant classification and forestry, and discusses the use of various deep learning models, such as AlexNet, VGG-19, ResNet-101, and DenseNet-201. It also introduces the Peruvian Amazon Forestry Dataset and presents the results of experiments conducted on this dataset.

However, it is common practice in deep learning to employ strategies to handle randomness, such as:

* Setting a fixed random seed value to ensure reproducibility of results
* Using techniques like data augmentation to increase the size of the training dataset and reduce overfitting
* Employing regularization techniques, such as dropout, to prevent overfitting
* Averaging the results of multiple models trained with different random seeds to reduce variance

But, these strategies are not explicitly mentioned in the provided context. Therefore, I cannot provide a more specific answer to this query based on the given information.