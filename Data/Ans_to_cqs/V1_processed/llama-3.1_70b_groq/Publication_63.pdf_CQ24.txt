The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. However, it does mention the use of a 3-fold cross-validation approach to assess the final model performance. This suggests that the authors may have used techniques like data splitting and averaging to reduce the impact of randomness on the model's performance.

Additionally, the context mentions the use of ensemble approach, where two more state-of-the-art model architectures (Xception and MobileNetV2) were trained on the same configuration and their predictions were averaged. This ensemble approach can help to reduce the variance of the model's predictions and improve its overall performance.

However, the context does not provide explicit information on how the authors handled randomness in the deep learning pipeline, such as setting a random seed value. Therefore, I cannot provide a more detailed answer to this question based on the provided context.