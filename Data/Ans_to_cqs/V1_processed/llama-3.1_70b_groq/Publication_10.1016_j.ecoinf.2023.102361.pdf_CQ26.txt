According to the provided context, several techniques are used to address data bias during preprocessing of the deep learning pipeline. These techniques include:

1. Data augmentation: This approach is used to increase the number of training data to address the issue of class imbalance. Studies have shown that data augmentation can improve the classification accuracy of deep learning models (Chen et al., 2022; Hasan et al., 2023; Le et al., 2020; Olsen et al., 2019; Sarvini et al., 2019).
2. Image preprocessing techniques: Various image preprocessing techniques are applied to improve the performance of the models. These techniques include resizing (ChechliÂ´nski et al., 2019; Farooq et al., 2018; Partel et al., 2020), removing background (Alam et al., 2020; Bah et al., 2018; Jiang et al., 2019), image enhancement (Nkelu et al., 2018; Wang et al., 2020), and denoising (Tang et al., 2017).

However, the context does not mention the use of stratified splitting, oversampling, or undersampling to address data bias. Additionally, diverse data collection is not explicitly mentioned as a technique used in the preprocessing pipeline.

It is worth noting that the context mentions that the datasets were randomly divided into three parts for training, validation, and testing, with 60% of the data used for training, 20% for validation, and 20% for testing. However, this is not a technique used to address data bias, but rather a common practice in machine learning to evaluate the performance of models.