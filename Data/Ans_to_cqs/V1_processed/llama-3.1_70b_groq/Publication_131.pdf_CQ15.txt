Unfortunately, the provided context does not mention the specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context only discusses the structure of the CNN, the number of filters and kernel size used in each convolution layer, the number of neurons in the fully connected layer, and the accuracy results obtained for the test data. It does not provide information on the optimization techniques used to train the model.