The provided context does not explicitly state the specific criteria used to determine when training is complete, such as a validation loss plateau. However, it does mention that the authors performed cross-validation by shifting the validation set 5 times to quantify the average validation cross-entropy loss and accuracy. They then used the neural network with the lowest cross-entropy loss across a range of models with different numbers of hidden layers and subsets of features. This suggests that the training process was stopped when the model with the lowest cross-entropy loss was found, but the exact stopping criteria are not specified.