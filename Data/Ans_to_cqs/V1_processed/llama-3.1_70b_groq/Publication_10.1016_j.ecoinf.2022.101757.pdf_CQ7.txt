Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context appears to be focused on semantic segmentation, image processing, and feature extraction, but it does not provide information on data splitting criteria.

However, it is common practice in deep learning to split data into training, validation, and testing sets using techniques such as random sampling, stratified sampling, or k-fold cross-validation. The specific criteria used to split the data can depend on the problem, dataset, and model architecture.

Some common criteria used to split data include:

* Random sampling: splitting the data into random subsets
* Stratified sampling: splitting the data into subsets based on class labels or other relevant variables
* K-fold cross-validation: splitting the data into k subsets and using each subset as a validation set once

Without more information, it is difficult to provide a specific answer to this question. If you have any additional context or information, I may be able to provide a more detailed answer.