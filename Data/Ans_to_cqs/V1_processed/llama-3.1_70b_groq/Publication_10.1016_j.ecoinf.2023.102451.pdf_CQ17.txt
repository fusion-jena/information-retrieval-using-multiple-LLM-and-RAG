Unfortunately, the provided context does not mention the specific regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily focuses on the performance comparison of different deep learning models, including the proposed EMViT-Net, and the architecture of the EMViT-Net model. It does mention data augmentation and normalization as preprocessing steps to address data diversity and imbalance problems, but it does not provide information on regularization methods used to prevent overfitting.