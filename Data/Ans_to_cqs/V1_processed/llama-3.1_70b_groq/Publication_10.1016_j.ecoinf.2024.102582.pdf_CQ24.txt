The provided context does not specifically discuss strategies for handling randomness in a deep learning pipeline, such as setting a random seed value. However, it does mention the use of random sampling and random division of datasets in the context of land cover classification.

According to the text, "sample points were imported into the GEE application programming interface (API) for further analysis. The samples were then randomly divided into training and validation datasets at a 7:3 ratio." This suggests that randomness is introduced in the data splitting process, but it does not provide information on how this randomness is controlled or whether a random seed value is set.

In another part of the text, it is mentioned that "Google Earth Pro was used to randomly generate 1800 sample points in the image of the study area for each year (300 sample points for each land cover type)". This again introduces randomness in the sampling process, but does not provide information on how this randomness is handled.

Overall, the provided context does not provide a clear answer to the query on strategies for handling randomness in a deep learning pipeline.