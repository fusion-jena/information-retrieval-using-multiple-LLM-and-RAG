Unfortunately, the provided context does not explicitly mention the postprocessing steps involved after the model training. The context primarily focuses on the model training process, data augmentation, and the performance of the model on the test set. It also discusses the workflow and the benefits of using citizen science data, but it does not provide information on the specific postprocessing steps taken after model training.

However, it does mention that the model's performance was evaluated based on an independent test set of 2060 images, and the results include metrics such as training loss, training accuracy, validation loss, and validation accuracy. Additionally, it mentions that the model was selected based on minimal validation loss, which occurred at epoch 448.

But, it does not provide information on the calculation of other metrics, such as precision, recall, F1-score, or the creation of a confusion matrix. It also does not mention the use of saliency maps or other visualization techniques to interpret the model's predictions.

Therefore, based on the provided context, I do not know the specific postprocessing steps involved after the model training.