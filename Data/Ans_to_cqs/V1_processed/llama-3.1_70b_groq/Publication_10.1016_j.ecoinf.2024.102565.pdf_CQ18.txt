The strategy implemented to monitor the model performance during training is the K-fold cross-validation technique, specifically a four-fold cross-validation. This technique involves dividing the dataset into four mutually exclusive folds through stratified sampling. Each fold serves as the validation set, while the remaining three folds constitute the training set for model training. The model is trained on the balanced three-fold training dataset for a specified number of epochs and then tested on the validation fold to generate predictions for that specific fold. This process is repeated four times with distinct validation sets. This approach allows for the evaluation of the model's performance on unseen data during training, helping to prevent overfitting and ensuring a more robust model.