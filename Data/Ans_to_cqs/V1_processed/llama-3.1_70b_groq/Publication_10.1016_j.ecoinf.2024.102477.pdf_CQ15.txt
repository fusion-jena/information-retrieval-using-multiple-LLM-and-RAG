Unfortunately, the provided context does not mention specific optimization techniques applied in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on the use of Support Vector Regression (SVR) and deep learning methods like SLSTM (Stacked Long Short-Term Memory) and SGRU (Stacked Gated Recurrent Unit) for time-series prediction. It discusses the parameters and performance of these models but does not delve into the optimization techniques used during training. Therefore, I don't know the specific optimization techniques applied in the deep learning pipeline mentioned in the query.