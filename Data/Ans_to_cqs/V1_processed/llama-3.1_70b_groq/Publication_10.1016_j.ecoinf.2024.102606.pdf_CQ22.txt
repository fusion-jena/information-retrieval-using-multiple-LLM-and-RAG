The metrics used to evaluate the performance of the deep learning model are:

1. IoU (Intersection over Union): This metric quantifies the overlap between the annotation and the prediction box. An IoU of 0.5 or higher is considered a match.
2. mAP (Mean Average Precision): This metric gives a score for the whole model, averaging the precision of each species.
3. AP (Average Precision): This metric gives a score for each species, indicating how well the model predicts that specific species.
4. Precision: This metric measures the confidence of the model in predicting a species correctly. A higher precision indicates that the model is more confident in its predictions.
5. Recall: This metric is used to calculate the precision-recall curve, which represents the balance between recall and precision.

Note that accuracy is not explicitly mentioned in the provided context as a metric used to evaluate the performance of the deep learning model.