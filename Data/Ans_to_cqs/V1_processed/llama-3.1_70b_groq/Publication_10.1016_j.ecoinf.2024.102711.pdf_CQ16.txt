The provided context does not explicitly mention the specific criteria used to determine when training is complete, such as validation loss plateau. However, it does mention the use of k-fold cross-validation for hyperparameter tuning, where the average performance of the k models developed on the validation groups represents the performance of the machine learning technique for the selected hyperparameters.

Additionally, the context mentions that the model's performance is evaluated using the tuning dataset, and the maximum depth of the tree, the number of trees in the ensemble model, and the learning rate are tuned as influential hyperparameters. However, it does not provide information on the specific stopping criteria used to determine when training is complete.

Therefore, based on the provided context, I do not know the specific criteria used to determine when training is complete, such as validation loss plateau.