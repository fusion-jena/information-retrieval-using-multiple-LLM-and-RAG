The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the authors used a combination of techniques to evaluate the model performance.

In Section 4.1, the authors mention that they used a five-fold cross-validation approach to generate prediction results for the training and validation samples. This suggests that they used cross-validation as a technique to evaluate the model performance during training.

Additionally, in Section 3.3, the authors mention that they used Recursive Feature Elimination and Cross-Validation (RFECV) to select the optimal features. This approach involves recursively removing the least important features until the cross-validation accuracy reaches the highest level. This suggests that the authors used cross-validation accuracy as a metric to evaluate the model performance during the feature selection process.

However, the exact strategy implemented to monitor the model performance during training is not explicitly stated, and it is unclear what specific metrics or techniques were used to evaluate the model performance beyond cross-validation accuracy.