Unfortunately, the provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on the use of Extreme Gradient Boosting (XGBoost) and Artificial Neural Networks (ANNs), specifically Multilayer Perceptron Neural Networks (MLPNN), for prediction tasks. It discusses hyperparameter tuning, model training, and predictor variable selection, but does not delve into data preprocessing techniques for addressing bias.

However, it is worth noting that the context does mention the use of grid search method for hyperparameter tuning, which can help in identifying optimal hyperparameters that may mitigate bias to some extent. Additionally, the use of XGBoost is mentioned, which is known for its ability to minimize bias error within and between spectral predictors.

To answer the query, I would say that the context does not provide explicit information on techniques used to address data bias during preprocessing. If you're looking for information on techniques like Stratified splitting, oversampling, undersampling, or Diverse data collection, I would recommend referring to other sources that specifically focus on data preprocessing and bias mitigation in deep learning pipelines.