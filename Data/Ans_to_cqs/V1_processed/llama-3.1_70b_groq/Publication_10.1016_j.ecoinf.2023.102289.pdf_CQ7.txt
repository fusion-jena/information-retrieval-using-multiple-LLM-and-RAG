Unfortunately, the provided context does not mention the specific criteria used to split the data for deep learning model training (e.g., train, test, validation). The context primarily focuses on the LaDeco platform, its architecture, and the use of pre-trained models, such as Deeplabv3 and Resnet269. It also discusses the use of MXNet and GluonCV for AI development, but it does not provide information on data splitting criteria.

However, it is common practice in deep learning to split the data into training, testing, and validation sets using techniques such as random sampling, stratified sampling, or k-fold cross-validation. The specific criteria used to split the data may depend on the specific problem, dataset, and model architecture.

In this case, since the context does not provide specific information on data splitting criteria, I cannot provide a more detailed answer.