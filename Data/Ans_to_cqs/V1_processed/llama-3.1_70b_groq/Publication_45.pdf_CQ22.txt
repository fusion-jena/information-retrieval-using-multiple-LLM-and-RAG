The performance of the deep learning model is evaluated using several metrics, including accuracy, precision, recall, F1 Score, Conditional Kappa, and the True Skill Statistic. Accuracy is defined as the ratio of correct classifications relative to the total number of examples. However, due to the unbalanced class distribution (only 3.48% of the data points are classified as disturbed), accuracy has limited value as an evaluation metric. Therefore, additional metrics such as precision, recall, and the F1 Score are used to provide a more comprehensive evaluation of the model's performance. Conditional Kappa and the True Skill Statistic are also used, which range from -1 to +1, where +1 indicates perfect agreement with the test data, and values >0 indicate a performance better than random.