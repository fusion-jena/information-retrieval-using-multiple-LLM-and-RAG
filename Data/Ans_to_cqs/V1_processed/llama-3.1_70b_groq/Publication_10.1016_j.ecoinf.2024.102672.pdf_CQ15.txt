The optimization technique applied in the deep learning pipeline is the Adam algorithm, which is a stochastic gradient descent method. This is mentioned in the context as "As optimizer, the Adam algorithm was used, which is a stochastic gradient descent method."