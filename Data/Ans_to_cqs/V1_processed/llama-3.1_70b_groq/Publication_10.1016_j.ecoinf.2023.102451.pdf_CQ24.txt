Unfortunately, the provided context does not mention any specific strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The context primarily focuses on the performance comparison of different deep learning models, including the proposed EMViT-Net model, on a specific dataset (EMDS-6). It discusses the experimental setup, performance evaluation, and comparison of results on validation and test sets.

However, it does mention the use of batch normalization to ensure stable training and faster convergence of the proposed model. Batch normalization can help reduce the effect of internal covariate shift, which can be caused by randomness in the training process. Nevertheless, this is not a direct strategy for handling randomness in the deep learning pipeline.

Therefore, based on the provided context, I do not have enough information to provide a specific answer to the query.