Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training the deep learning model. The context only mentions that the audio data were stored as FLAC files at a sampling rate of 44.1 kHz for the solar-powered bioacoustic recorders and WAV files at a 32 kHz sampling rate for the Audiomoth recorders. However, it does not provide information on any preprocessing steps such as normalization, scaling, or cleaning that may have been applied to the data before training the model.

The context does mention that the CNN model was developed with active learning, and the training/validation dataset was used to tune hyperparameters of the final model. However, it does not provide details on the preprocessing steps involved in preparing the data for training.

Therefore, I do not have enough information to provide a specific answer to the query.