Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context only mentions that each optimization run consisted of 3000 train iterations with a batch size of 25 individuals, and validating each 300 iterations. However, it does not provide information on how the data was split for training, testing, and validation.

Therefore, I don't know the specific criteria used to split the data for deep learning model training.