The data format used in the deep learning pipeline is audio. Specifically, the audio data is converted into spectrograms, which are then used as input to the Convolutional Neural Networks (CNNs). The spectrograms are generated using a Mel-spectrogram, which is divided into harmonic and percussive components using Harmonic-percussive source separation. The audio data is initially in varying lengths, but it is either repeated from the beginning to force a fixed duration of 2 seconds or resized to a fixed size to accommodate the CNN architecture.