The provided context does not explicitly mention the criteria used to determine when training is complete, such as a validation loss plateau. However, it does mention the use of cross-validation to obtain the RTMSPE (Root Trimmed Mean Squared Prediction Error) and the calculation of RTMSPE using the training data to select the appropriate values for the tuning parameters τ and ϕ.

It can be inferred that the training process may be considered complete when the RTMSPE converges or reaches a stable value, indicating that the model has achieved a satisfactory level of performance. However, without further information, it is unclear what specific criteria are used to determine the completion of training.

It is also worth noting that the context mentions the use of a penalized loss function with an L1 penalty, which is used to simultaneously carry out shrinkage estimation and variable selection. The loss function is minimized using the gradient ascent method, but the stopping criteria for the training process are not explicitly stated.