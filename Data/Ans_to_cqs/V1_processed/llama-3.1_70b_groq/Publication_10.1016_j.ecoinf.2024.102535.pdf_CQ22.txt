The performance of the deep learning models is evaluated using the F1-score metric, which is the harmonic mean of Precision (Pc) and Recall (Rc). Specifically, for each class, the F1-score is calculated as:

F1 (cid:0) scorec = 2 × Pc × Rc / (Pc + Rc)

where Pc is the precision, calculated as the number of true positives (tp) divided by the sum of true positives and false positives (fp), and Rc is the recall, calculated as the number of true positives (tp) divided by the sum of true positives and false negatives (fn).

Pc = tp / (tp + fp)
Rc = tp / (tp + fn)

The F1-score is used to evaluate the performance of the models in terms of their ability to correctly classify images into different classes. The average F1-score is reported across the testing folds, and the results are presented in terms of the average F1-scores computed for each individual class.