Unfortunately, the provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context primarily focuses on the design constraints of machine learning systems, template matching methods, and various approaches used by different systems submitted to a public challenge. It also discusses techniques such as transductive few-shot learning, meta-learning methods, and adaptive mechanisms used in some of the systems.

However, it does mention the use of pseudo-negatives (e.g., "Pseudo-neg (SpecSim)") and pseudo-positives in some of the systems, which could be related to addressing data bias. Additionally, some systems use techniques such as data augmentation ("5 + aug") and retraining with new positive and negative examples, which could also be related to addressing data bias.

But, it does not provide explicit information on techniques such as stratified splitting, oversampling, undersampling, or diverse data collection. Therefore, I cannot provide a definitive answer to the query based on the provided context.