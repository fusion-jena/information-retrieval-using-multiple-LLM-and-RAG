Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention some techniques and concepts related to deep learning, such as Mask R-CNN, U-Net, and data augmentation.

Data augmentation is mentioned in reference [27] as a technique to improve the performance of fine-tuned CNN models. Data augmentation can help prevent overfitting by increasing the diversity of the training data.

While dropout and L2 regularization are not explicitly mentioned, they are common regularization techniques used in deep learning to prevent overfitting. However, without more specific information, it is unclear if these techniques are used in the specific deep learning pipeline being referred to.

Therefore, based on the provided context, I can only confirm that data augmentation is mentioned as a technique that can help prevent overfitting, but I do not have enough information to confirm the use of dropout, L2 regularization, or other regularization methods.