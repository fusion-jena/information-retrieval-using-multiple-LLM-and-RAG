Unfortunately, the provided context does not explicitly discuss strategies for handling randomness in the deep learning pipeline, such as random seed values. The context primarily focuses on various topics like event-stream processing, machine learning, computer vision, and optogenetics, but does not delve into the specifics of deep learning pipeline management.

However, it's worth noting that the context does mention the use of deep learning frameworks like Theano, Torch, Caffe, TensorFlow, and deeplearning4j in a comparative study (Kovalev et al., 2016). While this study might touch on aspects of deep learning pipeline management, it does not specifically address strategies for handling randomness.

In general, handling randomness in deep learning pipelines often involves techniques like setting random seeds for reproducibility, using techniques like dropout or batch normalization to reduce overfitting, and employing regularization methods to prevent model overfitting. However, these strategies are not explicitly mentioned in the provided context.

Therefore, I must conclude that the provided context does not offer a clear answer to the query about strategies for handling randomness in the deep learning pipeline.