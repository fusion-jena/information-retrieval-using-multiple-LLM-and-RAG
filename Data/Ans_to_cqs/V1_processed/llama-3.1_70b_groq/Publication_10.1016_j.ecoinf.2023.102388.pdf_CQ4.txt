Unfortunately, the provided context does not mention any specific data augmentation techniques applied in the deep learning pipeline, such as flipping, rotating, or scaling. The context primarily focuses on the architecture of VGG16, the training process, and the mitigation of overfitting challenges. It discusses the use of batch normalization, dropout, and weight decay to prevent overfitting, but it does not provide information on data augmentation techniques. Therefore, I do not know the specific data augmentation techniques applied in this pipeline.