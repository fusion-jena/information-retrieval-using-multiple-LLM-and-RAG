To address data bias during preprocessing of the deep learning pipeline, several techniques can be employed. However, based on the provided context, it appears that the specific techniques used in this case are not explicitly mentioned. Nevertheless, I can provide some general information on the techniques you've listed:

* Stratified splitting: This technique involves splitting the data into training and testing sets while maintaining the same proportion of class labels in both sets. This can help prevent bias in the model.
* Oversampling: This involves creating additional copies of the minority class to balance the class distribution. However, this technique is not mentioned in the provided context.
* Undersampling: This involves reducing the number of samples in the majority class to balance the class distribution. Again, this technique is not mentioned in the provided context.
* Diverse data collection: This involves collecting data from diverse sources to ensure that the model is trained on a representative sample of the population. While the context mentions that the data is generated by Wireless Sensor Networks (WSNs), it does not provide information on whether diverse data collection techniques are employed.

In the context provided, it is mentioned that "to avoid bias generated by random data removal, we keep the data sets with the removed data for use with all methods." This suggests that the authors are taking steps to address bias, but the specific techniques used are not specified.

Therefore, I can conclude that while some techniques are likely being used to address data bias, the specific techniques employed are not explicitly mentioned in the provided context.