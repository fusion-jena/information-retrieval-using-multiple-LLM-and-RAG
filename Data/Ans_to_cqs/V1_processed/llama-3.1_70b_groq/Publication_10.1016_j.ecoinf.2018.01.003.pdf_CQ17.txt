Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The text primarily discusses the development of neural networks, the introduction of deep learning, and some specific neural network models, but it does not delve into the details of regularization techniques.

However, it does mention that the researchers tried different neural network models, such as BPNN2-1 to BPNN7-1, and found that BPNN4-1 offered the lowest mean square error and the most stable average performance. This suggests that the researchers were experimenting with different architectures to improve performance, but it does not provide information on regularization methods.

Therefore, I do not have enough information to provide a specific answer to the query about regularization methods used to prevent overfitting in the deep learning pipeline.