The provided context does not explicitly describe the process followed to deploy the trained deep learning model. However, it mentions that the proposed inferencing pipeline is discussed along with the associated technologies. 

It is mentioned that the audio files are transmitted over 4G using SMTP, and then the audio file is segmented into 15-second windows. Each of the sample windows is passed to the feature extractor function where MFCC is used to return the extracted features for the classifier. The predicted vector is then processed and logged to the site for review.

Additionally, it is mentioned that deploying trained models on edge devices for real-time inferencing will take some consideration, but the specific process followed for deployment is not described. Therefore, the exact process of model deployment, such as model serialization and platform selection, is not provided in the given context.