The provided context does not explicitly mention a specific strategy implemented to monitor the model performance during training. However, it does mention that the model's performance was evaluated on a test dataset of 70 videos, and the results are reported in terms of true positive rate and true negative rate. 

It is mentioned that the model had a true positive rate of 89.3% and a true negative rate of 91.9% using a standard acceptance threshold of 0.5. Additionally, the model's performance was also evaluated using a more conservative acceptance threshold of 0.1, which resulted in a true positive rate of 95.7% and a true negative rate of 76.1%. 

This suggests that the model's performance was evaluated using metrics such as true positive rate and true negative rate, but the exact strategy used to monitor the model's performance during training is not specified.