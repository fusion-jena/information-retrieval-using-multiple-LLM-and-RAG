The provided context does not explicitly mention how the hyperparameters of the model are optimized. It only mentions that the learning ratio varies with group based on the cosine function's law, often in the range between 0.0 and 1.0, but it does not provide information on how other hyperparameters, such as the batch size or the number of epochs, were chosen. 

However, it does mention that the batch size was set to 32 to not exceed the memory limit and to make full use of computer resources, but it does not provide information on whether this was the result of a hyperparameter optimization process or simply a design choice. 

Therefore, I do not know how the hyperparameters of the model were optimized.