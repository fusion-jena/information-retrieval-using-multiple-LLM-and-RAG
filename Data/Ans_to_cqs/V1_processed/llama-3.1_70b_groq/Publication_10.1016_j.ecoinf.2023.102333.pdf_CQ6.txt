Unfortunately, the provided context does not mention specific preprocessing steps involved before training a deep learning model, such as normalization, scaling, or cleaning. The context primarily focuses on hyperparameter optimization, neural network architecture, and training procedures. It discusses the importance of hyperparameter tuning, different optimization algorithms, and techniques for preventing overfitting, but it does not delve into preprocessing steps.

However, it is worth noting that the context does mention the use of a dropout layer to prevent overfitting, which is a regularization technique used during training. Additionally, the study adopted an automated optimization architecture to optimize hyperparameters, but it does not provide information on preprocessing steps.

Therefore, I do not have enough information to provide a comprehensive answer to the query about preprocessing steps involved before training a deep learning model.