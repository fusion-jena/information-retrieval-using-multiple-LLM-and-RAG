The provided context does not explicitly mention the use of a random seed value to handle randomness in the deep learning pipeline. However, it does mention the use of stochastic gradient descent (SGD) as the optimizer, which inherently involves randomness in the gradient updates.

Additionally, the context mentions the use of random shuffling of images within each class (species) to split the data into training and test groups. This suggests that randomness is introduced in the data preparation step to ensure that the training and test sets are representative of the overall data distribution.

Furthermore, the context mentions the use of an image augmentation strategy that includes random rotation, crop, shear, and horizontal flip. This introduces randomness in the input data to help reduce overfitting and improve the generality of the models.

Overall, while the context does not explicitly mention the use of a random seed value, it does employ strategies that involve randomness in the data preparation and augmentation steps to improve the robustness and generalizability of the models.