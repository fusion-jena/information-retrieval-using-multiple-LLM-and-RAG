The provided context mentions two regularization methods used to prevent overfitting in the deep learning pipeline. 

Firstly, it mentions the use of weight decay to control the strength of the unit Gaussian prior. The magnitude of weight decay is set to 10^-3, which is inversely proportional to the hyperparameter Î» from Eq. (1). This is equivalent to L2 regularization, which adds a penalty term to the loss function to discourage large weights.

Secondly, the context mentions the use of a Gaussian prior over the network parameters, which corresponds to L2 regularization. However, it does not explicitly mention the use of dropout as a regularization method.

Therefore, based on the provided context, the regularization methods used to prevent overfitting in the deep learning pipeline are L2 regularization (in the form of weight decay) and a Gaussian prior over the network parameters. However, it does not mention the use of dropout.