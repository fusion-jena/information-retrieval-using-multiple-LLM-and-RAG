The optimization technique applied in the deep learning pipeline is Adam. According to the text, "The optimizer is Adam and the starting learning rate is set to 0.001." This is mentioned in the context of the MCD model implementation details, as shown in Algorithm 1.