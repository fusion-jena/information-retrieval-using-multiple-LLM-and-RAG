The hyperparameters used in the deep learning model are as follows:

- Learning rate: 10^-5
- Learning decay: Exponential decay with a Gamma of 0.95
- Dropout: 50%
- Optimizer: Adam Solver type
- Weight initialization: Random Gaussian initialization

These hyperparameters were chosen as they are considered classic parameters for fast convergence of the network without overfitting, as mentioned in the reference (Srivastava et al., 2014).