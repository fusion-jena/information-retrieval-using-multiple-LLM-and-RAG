The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does mention the use of Stochastic Gradient Descent (SGD) as the optimization method, which inherently involves randomness in the gradient updates.

Additionally, the context mentions the use of Bayesian optimization for tuning hyperparameters, which is a probabilistic approach that can help handle uncertainty and randomness in the optimization process.

It is also worth noting that the context mentions the use of a batch size of 25 individuals to pick a pair of similar and a pair of dissimilar photos, which may help reduce the impact of randomness in the training process.

However, without more information, it is unclear whether any specific strategies are employed to handle randomness in the deep learning pipeline, such as setting a random seed value.