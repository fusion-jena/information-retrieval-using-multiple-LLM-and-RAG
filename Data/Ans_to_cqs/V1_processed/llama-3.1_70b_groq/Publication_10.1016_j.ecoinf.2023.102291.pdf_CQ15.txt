Unfortunately, the provided context does not mention specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on the architecture and training of Convolutional Neural Networks (CNNs) using TensorFlow and Python 3, but it does not provide details on the optimization techniques employed. Therefore, I do not know the answer to this question based on the given context.