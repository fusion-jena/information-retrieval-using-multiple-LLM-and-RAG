The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that the patch size of 224 Ã— 224 included enough contextual noise to "regularize overfitting." This suggests that the use of contextual noise in the data may have helped to prevent overfitting, but it does not provide information on specific regularization methods used in the model.

Additionally, the context mentions that training a logistic regression (LR) on the penultimate and final layers of the ensemble network improved classification performances, and that using a CNN in combination with other machine learning algorithms can improve classification accuracy. However, it does not provide information on the specific regularization methods used in the model.

Therefore, based on the provided context, I do not know the specific regularization methods used to prevent overfitting in the deep learning pipeline.