The type of deep learning model used in the pipeline for deep noise reduction techniques includes U-net architecture, which consists of an encoder and decoder section. Additionally, transformer attention mechanisms have also been applied with great success in recent years. Specifically, models such as Multi-scale temporal frequency convolutional network with axial attention and Frcrn: Boosting Feature Representation Using Frequency Recurrence for Monaural Speech Enhancement have been used for speech enhancement. These models are often used in conjunction with raw waveform data, rather than audio spectrograms, to remove errors introduced by the Fast Fourier Transform (FFT) and reconstruction errors due to the loss of phase information.