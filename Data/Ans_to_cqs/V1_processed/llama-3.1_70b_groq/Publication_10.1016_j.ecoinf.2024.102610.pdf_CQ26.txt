The provided context does not specifically mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention feature elimination techniques used in the context of random forest models, such as Recursive Feature Elimination (RFE) and Variable Selection Using Random Forests (VSURF). These techniques are used to select the most relevant features for the model, but they do not directly address data bias.

The context also mentions the use of crowdsourcing-based nationwide tick collection to reveal the distribution of Ixodes ricinus and I. persulcatus and associated pathogens in Finland, which could be considered a form of diverse data collection. However, this is not explicitly mentioned as a technique to address data bias.

The context does not mention stratified splitting, oversampling, or undersampling as techniques used to address data bias. Therefore, I do not have enough information to provide a comprehensive answer to the query.

If you're looking for techniques to address data bias, some common methods include:

* Stratified splitting: splitting the data into subsets based on the target variable to ensure that each subset has a similar distribution of classes.
* Oversampling: creating additional instances of the minority class to balance the dataset.
* Undersampling: reducing the number of instances of the majority class to balance the dataset.
* Diverse data collection: collecting data from a variety of sources to ensure that the dataset is representative of the population.

However, these techniques are not mentioned in the provided context.