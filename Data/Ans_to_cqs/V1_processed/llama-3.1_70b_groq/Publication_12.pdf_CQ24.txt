The provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. However, it does mention the use of batch normalization (BNorm) layers to prevent overfitting in the model. This suggests that the authors are aware of the importance of managing randomness and variability in the training process.

Additionally, the context mentions that the batch size was set to 128, which may help to reduce the impact of randomness in the training process by averaging out the effects of individual data points. However, this is not a direct strategy for handling randomness in the deep learning pipeline.

It is also worth noting that the context mentions the use of a deep learning approach called BatNet, which is a neural network architecture. However, the details of how randomness is handled in this architecture are not provided.

Overall, while the context provides some information about the strategies employed to manage variability in the training process, it does not provide a clear answer to the question of how randomness is handled in the deep learning pipeline.