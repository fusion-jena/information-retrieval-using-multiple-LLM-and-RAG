The provided context does not explicitly mention the use of regularization methods such as dropout or L2 regularization to prevent overfitting in the deep learning pipeline. However, it does mention the use of weight decay with a value of 0.005, which is a form of L2 regularization. Additionally, the context mentions the use of data augmentation techniques, which can help prevent overfitting by increasing the diversity of the training data. Cross-validation is also used to evaluate the model's performance and prevent overfitting. Therefore, the regularization methods used to prevent overfitting in this pipeline are weight decay (L2 regularization) and data augmentation.