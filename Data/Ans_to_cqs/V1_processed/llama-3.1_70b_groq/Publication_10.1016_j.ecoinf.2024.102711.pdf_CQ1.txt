Unfortunately, the provided context does not explicitly mention the methods used for collecting raw data in the deep learning pipeline. The context appears to focus on the application of automated machine learning (AutoML) and generative adversarial networks (GANs) in various studies, particularly in the field of ecological informatics.

However, it can be inferred that the studies mentioned in the context likely utilized existing datasets, as they are referenced as part of the analysis. For example, the study by Babu et al. (2023) mentions the use of environmental drivers and spatial prediction of forest fires in the Western Ghats biodiversity hotspot, India, which suggests that they may have used data from environmental sensors or public datasets.

Additionally, the study by Barros-Rosa et al. (2022) mentions the use of environmental data for fire probability mapping and prediction, which could imply the use of sensors or public datasets.

However, without explicit information on the methods used for collecting raw data, it is difficult to provide a definitive answer. Therefore, I must conclude that I don't know the specific methods used for collecting raw data in the deep learning pipeline based on the provided context.