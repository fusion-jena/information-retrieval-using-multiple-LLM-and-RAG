The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it is mentioned that the authors used a common approach to split the data into evaluation and training datasets prior to training the models. They set aside the evaluation dataset and used it to evaluate individual averaged modeling approaches and the final ensemble models. This suggests that the authors used a hold-out method, where a portion of the data is held out from the training process and used to evaluate the model's performance. Additionally, the authors calculated the True Skill Statistic (TSS) and the Area Under the Receiver Operating Curve (AUC-ROC) for each model using the external evaluation datasets. This indicates that the authors used these metrics to evaluate the model's performance during training.