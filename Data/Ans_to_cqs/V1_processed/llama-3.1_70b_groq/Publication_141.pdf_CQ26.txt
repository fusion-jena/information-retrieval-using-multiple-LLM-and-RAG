The provided context does not explicitly mention techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention a few techniques used to enhance model robustness and handle the small sample size of the dataset.

Data augmentation is mentioned as a technique used to randomly deform input images in each training cycle. This can help increase the diversity of the training data and potentially reduce bias. Additionally, dropout techniques are applied to extracted features to enhance model robustness.

There is no mention of stratified splitting, oversampling, or undersampling in the provided context. It is also not clear if diverse data collection was used to collect the dataset.

It is worth noting that the context mentions that the dataset was constructed under a lab-based protocol of image acquisition with fully controlled position of the larvae (ventral point of view). This suggests that the data collection process was controlled and consistent, which may help reduce bias. However, it is not clear if this is sufficient to address data bias.

Overall, the provided context does not provide a comprehensive answer to the query, and it is not possible to determine the full range of techniques used to address data bias during preprocessing of the deep learning pipeline.