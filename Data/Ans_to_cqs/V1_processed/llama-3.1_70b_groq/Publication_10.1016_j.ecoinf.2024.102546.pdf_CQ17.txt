Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The context discusses various topics such as dataset curation, domain randomization, and image augmentations, but it does not specifically mention regularization methods like dropout or L2 regularization.

However, it does mention that the I3Net model uses "target domains with regularizations for feature consistency", but it does not provide further details on what these regularizations are. Additionally, the context mentions that the models were trained for 40 epochs with a batch size of 8, which could be related to regularization, but it is not explicitly stated.

Therefore, based on the provided context, I do not know what regularization methods are used to prevent overfitting in the deep learning pipeline.