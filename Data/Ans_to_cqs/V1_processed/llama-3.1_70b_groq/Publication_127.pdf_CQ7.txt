Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. However, I can provide some general information on common practices in the field.

In deep learning, it is common to split the available data into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to evaluate the model's performance during training and tune hyperparameters, and the testing set is used to evaluate the model's performance after training is complete.

The criteria for splitting the data can vary depending on the specific problem and dataset. Some common practices include:

* Random splitting: The data is randomly split into training, validation, and testing sets.
* Stratified splitting: The data is split in a way that preserves the class balance in each set.
* Time-based splitting: The data is split based on time, with earlier data used for training and later data used for testing.

The provided context does mention that the authors trained nine models for each stage and formed an ensemble of the trained models by averaging their predictions. However, it does not provide information on how the data was split for training, validation, and testing.

Therefore, I do not know the specific criteria used to split the data for deep learning model training in this context.