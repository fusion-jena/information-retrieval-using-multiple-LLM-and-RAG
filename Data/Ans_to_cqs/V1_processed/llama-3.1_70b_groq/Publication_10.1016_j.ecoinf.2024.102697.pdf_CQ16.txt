The provided context does not explicitly mention the criteria used to determine when training is complete, such as validation loss plateau. It only mentions that the training performance was calculated based on the inner cross-validated ensemble, and the testing performance was determined by selecting the optimal set of hyperparameters from the entire training set to predict on the holdout data. Additionally, it mentions that Bayesian Optimization was used to minimize a 5 k-fold cross-validation loss during model development, but it does not specify how this loss was used to determine the completion of training. Therefore, I don't know the exact criteria used to determine when training is complete.