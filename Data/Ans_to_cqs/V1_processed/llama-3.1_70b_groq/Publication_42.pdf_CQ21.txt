The provided context does not explicitly mention the postprocessing steps involved after the model training. However, it does mention the evaluation metrics used to assess the performance of the CNN model.

The context mentions that the chosen model had an F1-score of 92.75%, which indicates that the trained CNN was very accurate in its predictions. It also mentions that the final architecture was chosen because it achieved average precision, recall, and an F1-score of 93%, which indicated a suitable model classification.

Additionally, the context provides a table (Table 2) that ranks the CNN architectures with the highest and lowest F1 classification scores. This suggests that the authors calculated and compared the F1-scores of different models to select the best one.

However, there is no mention of saliency maps, confusion matrices, or other postprocessing steps. Therefore, I can only confirm that the authors calculated and compared the F1-scores of different models, but I do not know about other postprocessing steps that may have been involved.