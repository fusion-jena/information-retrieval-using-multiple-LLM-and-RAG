The text does not explicitly state the criteria used to determine when training is complete, such as a validation loss plateau. However, it does mention that the VAE was trained over a maximum of 100,000 batches with a hold-out split for both validation and test of 20%. This suggests that the training process was stopped after a fixed number of batches, rather than based on a specific performance metric such as validation loss. Additionally, the text mentions that the learning rate was tweaked to an optimal configuration and underwent annealing, which may have helped to prevent overfitting, but it does not provide further details on how the training process was terminated.