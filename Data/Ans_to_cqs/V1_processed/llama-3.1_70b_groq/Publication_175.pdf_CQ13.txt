The provided context does not explicitly mention the specific hyperparameters used in the deep learning model, such as the learning rate or optimizer. It only mentions that the same hyperparameters were used when training the model on different datasets (AT0 and AT1). The context does mention that hyperparameters include parameters defining the architecture (number of layers, number and size of convolutions, connections between layers) and the training process of a Deep Model (learning rate, neuron activation, back-propagation computation), but it does not provide the specific values or settings used in the model.