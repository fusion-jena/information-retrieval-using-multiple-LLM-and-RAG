The provided context does not explicitly mention specific techniques used to address data bias during preprocessing of the deep learning pipeline. However, it does mention that the dataset may be "substantially imbalanced" and references a paper titled "practices to address a substantially imbalanced dataset with deep learning" (Remote Sens. Environ. 216, 139â€“153). This suggests that techniques such as oversampling, undersampling, or other methods to address class imbalance may be relevant.

Additionally, the context mentions the importance of "carefully select[ing] and manipulat[ing] the training images to attempt to influence the network to learn particular characteristics and/or assign more importance to certain characteristics than others." This implies that diverse data collection and careful curation of the training dataset may be important for addressing data bias.

However, the context does not provide explicit information on techniques such as stratified splitting, oversampling, or undersampling. Therefore, I can only provide a partial answer based on the available information.

It is worth noting that the context highlights the challenges of working with deep learning models, including the lack of standardized approaches and the need for trial and error. This suggests that addressing data bias may require a combination of techniques and careful experimentation.