The strategy implemented to monitor the model performance during training is not explicitly stated in the provided context. However, it can be inferred that the performance of the models was evaluated using various statistical measures such as R2, NSE, MEF, Z statistics, RMSE, and MAE. These metrics were used to compare the performance of different machine learning models during both the training and testing periods.

Additionally, the context mentions that the data was split into training and testing datasets with an 80% and 20% ratio, respectively. This suggests that the model performance was evaluated on a separate testing dataset after training, which is a common strategy to monitor model performance and prevent overfitting.

However, the specific strategy or technique used to monitor model performance during training, such as cross-validation or early stopping, is not mentioned in the provided context.