To address data bias during preprocessing of the deep learning pipeline, several techniques are employed. According to the provided context, the following techniques are used:

1. **Stratified sampling**: This method is used to split the datasets into training, validation, and testing sets. The context mentions that the datasets were divided into three exclusive groups: 80% for training, 10% for validation, and 10% for testing.
2. **Data augmentation**: To enhance the datasets and attain data diversity, random mutations are applied to the data. These include:
	* **Random spectrogram mixup**: A new spectrogram is created by combining two randomly selected spectrograms with a probability of 0.5.
	* **Random tanh distortion**: This technique is applied to introduce random distortions to the data.
	* **Adding background noise**: This technique is used to address the issue of a long-tailed distribution of the data for rare and endangered bird species.
	* **Random clipping and splicing**: This technique is also used to address the issue of a long-tailed distribution of the data for rare and endangered bird species.

Additionally, the context mentions that files from "BirdsOnly" are incorporated for all bird audio recordings to enhance the datasets.

It is not explicitly mentioned in the context whether oversampling or undersampling techniques are used to address data bias. However, the use of stratified sampling and data augmentation techniques suggests that the focus is on creating a more diverse and representative dataset rather than simply oversampling or undersampling the data.