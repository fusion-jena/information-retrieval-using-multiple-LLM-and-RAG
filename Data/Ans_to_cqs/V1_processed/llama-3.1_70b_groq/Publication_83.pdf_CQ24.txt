Unfortunately, the provided context does not explicitly mention any strategies employed to handle randomness in the deep learning pipeline, such as setting a random seed value. The text primarily focuses on the architecture of the proposed model, the dataset used, and the experimental results. It does mention the use of the Adam optimizer with a learning rate of 10^-4, but it does not provide information on how randomness is handled in the pipeline.

However, it is worth noting that the batch size is set to 64 samples, and the network is trained with 200 epochs. This suggests that the training process may involve some level of randomness, such as random sampling of the training data. Nevertheless, without further information, it is unclear how randomness is specifically handled in the pipeline.

In summary, the provided context does not provide enough information to answer the query about strategies employed to handle randomness in the deep learning pipeline.