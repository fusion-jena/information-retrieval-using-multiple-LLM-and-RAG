Unfortunately, the provided context does not explicitly mention the hyperparameters used in the deep learning model, such as the learning rate or optimizer. However, it does mention a few hyperparameters that were used or experimented with, including:

* Batch size: The context mentions that different batch sizes were used, including 16, 128, and 200.
* Patch size: The context mentions that different patch sizes were used, including 128x128 and 224x224.
* Depth: The context mentions that different network depths were used, including ResNet18, ResNet50, and ResNet152.
* Weight decay: The context mentions that weight decay is a hyperparameter that can influence calibration.
* Batch normalization: The context mentions that batch normalization is a hyperparameter that can influence calibration.

However, the learning rate and optimizer used in the model are not specified in the provided context.