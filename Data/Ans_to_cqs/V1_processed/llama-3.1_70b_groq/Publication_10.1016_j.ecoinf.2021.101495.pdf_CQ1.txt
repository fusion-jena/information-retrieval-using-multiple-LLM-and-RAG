Unfortunately, the provided context does not explicitly mention the methods used for collecting raw data in the deep learning pipeline. The context appears to focus on the computing infrastructure, hyperparameters, and training of neural networks for tasks such as segmentation and classification, particularly in the context of underwater fish species classification and automated catch event detection for longline fishing.

However, it can be inferred that the data used for training the models may have come from sources such as electronic monitoring data, as mentioned in the paper by Qiao et al. (2020). Additionally, the context mentions "official sources" and "estimations" as part of the data used for validation, but it does not provide further details on the methods used for collecting the raw data.

Therefore, I cannot provide a definitive answer to the query, and I would like to say that I don't know the specific methods used for collecting raw data in the deep learning pipeline based on the provided context.