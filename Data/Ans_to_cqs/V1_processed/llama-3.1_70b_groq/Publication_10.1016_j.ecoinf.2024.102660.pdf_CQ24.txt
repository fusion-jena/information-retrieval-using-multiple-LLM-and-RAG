Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed value. The context primarily focuses on the proposed Res_AUNet network architecture, its performance evaluation, and comparison with other state-of-the-art models.

However, it can be inferred that the authors might have used techniques such as data augmentation, batch normalization, and dropout to mitigate overfitting, which can be related to handling randomness in the pipeline. Additionally, the use of residual structures and reducing the number of convolutional kernels within each block might also help in reducing the impact of randomness.

But, specifically regarding random seed value, there is no mention of how it was handled or if it was fixed for reproducibility. Therefore, I cannot provide a definitive answer to this query based on the given context.