The provided context does not explicitly mention strategies for handling randomness in the deep learning pipeline, such as setting a random seed value. However, it does mention the use of the "reparameterisation trick" in the encoder, which is a technique used in variational autoencoders to sample from a Gaussian distribution. This trick allows for the injection of randomness into the model while still allowing for backpropagation.

Additionally, the context mentions the use of batch normalization, which can help to reduce the effect of internal covariate shift, a type of randomness that can occur during training. However, this is not directly related to handling randomness in the pipeline.

It is also worth noting that the context mentions the use of a fixed dimensionality for the latent vector (d = 128), which could potentially help to reduce the effect of randomness in the model. However, this is not a direct strategy for handling randomness.

Overall, the provided context does not provide a clear answer to the question of how randomness is handled in the deep learning pipeline.