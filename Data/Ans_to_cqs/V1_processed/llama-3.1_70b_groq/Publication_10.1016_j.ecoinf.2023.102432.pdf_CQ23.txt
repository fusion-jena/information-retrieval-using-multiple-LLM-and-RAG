To ensure the generalizability of the model, the data was split into training and testing data using 5 K-fold cross-validations. This approach helps to evaluate the model's performance on unseen data and reduces the risk of overfitting. Additionally, the model was tested on 20% of the data that was not used for training the algorithm, which further helps to assess its generalizability. However, it is not mentioned whether the dataset was diverse or if stratified splitting was used.