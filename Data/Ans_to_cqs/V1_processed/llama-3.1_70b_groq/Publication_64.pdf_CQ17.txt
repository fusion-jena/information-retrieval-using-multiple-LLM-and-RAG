The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. However, it does mention that the model is trained for 100 epochs and that standard data augmentation techniques are applied during training, such as shear, translation, and mirroring. This suggests that data augmentation is used as a regularization method to prevent overfitting.

Additionally, the context mentions that the model is initialized with pre-trained weights on the ImageNet dataset, which can also help to prevent overfitting by leveraging the knowledge learned from a large dataset.

However, it does not mention the use of dropout or L2 regularization explicitly. Therefore, we cannot confirm if these methods are used in the pipeline.