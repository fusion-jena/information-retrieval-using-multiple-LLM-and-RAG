Unfortunately, the provided context does not specifically mention techniques used to address data bias during preprocessing of the deep learning pipeline. The context mentions that deep learning algorithms were considered, but the limited number of samples was not conducive to deep learning. It does not provide information on techniques such as Stratified splitting, oversampling, undersampling, or Diverse data collection.

However, the context does mention that the researchers used techniques such as gradient-based one-sided sampling and exclusive feature bundling in the LightGBM (LGBM) algorithm, which can help reduce the number of sample features and improve processing speed. Additionally, the CatBoost algorithm is mentioned to be able to handle one-hot encoding for discrete features, addressing gradient bias and prediction shifts.

But these techniques are not specifically mentioned as methods to address data bias during preprocessing of the deep learning pipeline. Therefore, I do not have enough information to provide a comprehensive answer to the query.