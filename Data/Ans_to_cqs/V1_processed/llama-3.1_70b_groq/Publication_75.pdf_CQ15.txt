The optimization techniques applied in the deep learning pipeline, as mentioned in the provided context, are Adam and Stochastic Gradient Descent with Momentum (Sgdm). According to the text, Adam turned out to be the most efficient solver for classification, while Sgdm experienced drops in performance.