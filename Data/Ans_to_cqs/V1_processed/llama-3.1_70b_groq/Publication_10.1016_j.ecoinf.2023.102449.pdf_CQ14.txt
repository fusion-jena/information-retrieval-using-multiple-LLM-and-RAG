The text does not explicitly mention how the hyperparameters of the model are optimized, such as through grid search or random search. However, it does mention that the learning rate was "tweaked to an optimal configuration of Î· = 0.0005", suggesting that some form of manual tuning or experimentation was used to find a suitable value for the learning rate. Additionally, the text mentions that the learning rate undergoes annealing by a factor of 100 using a cosine function over the duration of the training, which suggests that the learning rate is adjusted during training. However, the exact method used to optimize the hyperparameters is not specified.