The metrics used to evaluate the performance of the deep learning model are: positive predictive value, sensitivity, and F1-measure. 

Positive predictive value refers to the proportion of true positives among all predicted positive instances. In the context of the given text, it means that the model returned substantially more actual whales than false ones. 

Sensitivity, on the other hand, refers to the proportion of true positives among all actual positive instances. In this case, it means that the model returned most of the actual whales.

F1-measure provides a balance between precision and sensitivity. It is a measure of the model's accuracy on a specific task.

Note that accuracy is not explicitly mentioned in the given text as a metric used to evaluate the performance of the model. However, the text does mention that the model's performance is evaluated using a 5-fold Cross-Validation strategy on the test dataset.