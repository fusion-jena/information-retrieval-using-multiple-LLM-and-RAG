Unfortunately, the provided context does not mention the specific hardware resources used for training the deep learning model, such as GPUs or TPUs. The text only mentions that the batch size was set to 32 to "make full use of computer resources" and "not exceed the memory limit", but it does not provide further details on the type of hardware used.