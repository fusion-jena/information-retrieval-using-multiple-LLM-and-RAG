Unfortunately, the provided context does not mention specific optimization techniques used in the deep learning pipeline, such as SGD (Stochastic Gradient Descent) or Adam. The context primarily focuses on the architectures of various pre-trained CNN models (EfficientNet, ResNet-50, InceptionV3, and InceptionResNetV2) and the use of transfer learning and RNNs (Recurrent Neural Networks) in the model. It also mentions the use of GPU acceleration to expedite computations, but it does not provide information on the optimization techniques employed. Therefore, I do not know the answer to this question based on the provided context.