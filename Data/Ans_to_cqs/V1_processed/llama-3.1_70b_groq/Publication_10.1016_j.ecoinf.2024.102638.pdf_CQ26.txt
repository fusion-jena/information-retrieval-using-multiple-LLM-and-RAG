To address data bias during preprocessing of the deep learning pipeline, the techniques used are not explicitly mentioned in the provided context. However, it is mentioned that the dataset is divided into training sets and a test set by random sampling to ensure that both subsets are representative of the overall dataset and minimize the risk of bias. This suggests that random sampling is used to address data bias.

Additionally, the context mentions that the division is done to "minimise the risk of bias" and to "preserve the distribution of key features and target variables across both training and test sets", which implies that the authors are aware of the importance of addressing data bias. However, the specific techniques used to address bias, such as stratified splitting, oversampling, undersampling, or diverse data collection, are not mentioned.

Therefore, based on the provided context, the only technique that can be confirmed as being used to address data bias is random sampling.