The provided context mentions one regularization method used to prevent overfitting in the deep learning pipeline, which is Dropout. According to the text, a dropout layer with a dropout rate of 0.2 was added to the model to reduce overfitting. 

Additionally, the context mentions that even after using over-fitting prevention techniques such as Dropout, overfitting can still occur when learning too many parameters with limited training samples.

There is no mention of L2 regularization in the provided context. However, it is mentioned that overfitting of a machine learning model includes more terms and uses more complicated approaches than necessary, but no specific regularization methods other than Dropout are mentioned.

Therefore, based on the provided context, the only regularization method mentioned is Dropout.