The text does not explicitly mention how the hyperparameters of the model are optimized, such as through grid search or random search. However, it does mention that the learning rates were chosen from empirical trials over 100 epochs, suggesting that some form of trial and error or experimentation was used to determine the optimal hyperparameters. Additionally, the text mentions that the Adam optimizer algorithm was used, which is a popular optimization algorithm for deep learning models.