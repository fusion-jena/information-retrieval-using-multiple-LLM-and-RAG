Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline. The text discusses the issue of overfitting when training the YOLOv8n model on the MNIST dataset, but it does not provide information on the specific regularization methods used to address this issue.

However, it is mentioned that the model was trained solely on the provided dataset (Model 4) to prevent overfitting, which suggests that the authors may have used a different approach to prevent overfitting, such as using a smaller dataset or adjusting the model architecture.

Common regularization methods used to prevent overfitting in deep learning include dropout, L2 regularization, and early stopping, but these are not mentioned in the provided context. Therefore, I cannot provide a specific answer to this question based on the provided text.