The provided context does not explicitly mention the specific data annotation techniques used in the deep learning pipeline, such as bounding box annotation or instance segmentation. However, it does mention that select spectrogram images were manually labeled via visual inspection by two trained graduate students into a set of sound categories. This suggests that the annotation technique used is likely a form of classification or labeling, where the annotators assign a category or label to each spectrogram image. The context also mentions that the annotators could annotate around 60 images per minute, which corresponds to 8 minutes of audio data. This implies that the annotation process is focused on labeling the spectrogram images rather than annotating specific objects or regions within the images.