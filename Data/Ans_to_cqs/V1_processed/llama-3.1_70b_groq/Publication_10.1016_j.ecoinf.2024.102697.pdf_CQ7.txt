The provided context does not specifically mention deep learning models, but it does describe the methodology used for machine learning (ML) model training. According to Section 2.7, a repeated nested k-fold cross-validation approach was employed for all ML models developed. 

The data was initially divided into holdout data and data for model development using an outer 10 k-fold cross-validation. This means that the data was split into 10 folds, and 9 folds were used for training while 1 fold was used as the holdout data for testing. This process was repeated 10 times, with each fold serving as the holdout data once.

The data for model development was further divided using an inner 5 k-fold cross-validation. This means that the 9 folds used for training were further split into 5 folds, with 4 folds used for training and 1 fold used for validation. This process was repeated 5 times, with each fold serving as the validation data once.

The training performance was calculated based on the inner cross-validated ensemble, while the testing performance was determined by selecting the optimal set of hyperparameters from the entire training set to predict on the holdout data. This process was repeated 15 times for each unique model to reduce the potential bias and variance related to random sampling.

Therefore, the criteria used to split the data for ML model training are:

* Outer 10 k-fold cross-validation: 9 folds for training and 1 fold for testing (holdout data)
* Inner 5 k-fold cross-validation: 4 folds for training and 1 fold for validation

Note that the context does not specifically mention deep learning models, so this answer may not be directly applicable to deep learning models.