The provided context does not specifically mention deep learning models, but it does discuss various metrics used to evaluate the performance of models in general. According to the text, the most common metrics used are:

* Area Under the Receiver Operating Characteristic Curve (AUC-ROC)
* Accuracy
* Precision
* Sensitivity
* Specificity
* Cohen's Kappa
* Brier score (although this is mentioned as being used less frequently)

Additionally, the text mentions that some studies used metrics derived from two-way contingency tables comparing presence-absence observations to primary predictions. It also notes that about half of the studies used more than one validation metric simultaneously to assess different aspects of model performance.

It's worth noting that the context does not provide an exhaustive list of metrics used to evaluate model performance, and it does not specifically address deep learning models. However, the mentioned metrics are commonly used in various machine learning and modeling applications.