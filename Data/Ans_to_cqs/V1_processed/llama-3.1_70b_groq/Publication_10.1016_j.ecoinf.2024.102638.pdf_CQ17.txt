Unfortunately, the provided context does not specifically mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily discusses various machine learning algorithms, their strengths and weaknesses, and the process of hyperparameter tuning using GridSearchCV. It also mentions the use of techniques like cross-validation to prevent overfitting, but it does not delve into the specifics of regularization methods used in deep learning.

However, it does mention the use of L1 regularization (l1_ratio) and alpha (which could be a reference to L2 regularization) as hyperparameters in some of the machine learning algorithms, such as Elastic Net (EN) and Support Vector Regression (SVR). But it does not provide information on the use of these regularization methods in the context of deep learning.

Therefore, I do not have enough information to provide a specific answer to the query.