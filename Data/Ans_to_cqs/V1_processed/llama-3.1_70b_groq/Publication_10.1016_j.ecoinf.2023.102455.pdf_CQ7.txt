Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context appears to be a collection of experimental results and model configurations for various deep learning models, including CNN-BiGRU, RVFL, KELM, and others. However, it does not provide information on how the data was split for training, testing, and validation.

In general, common practices for splitting data in deep learning include:

* Random splitting: dividing the data into training, testing, and validation sets using random sampling.
* Stratified splitting: dividing the data into training, testing, and validation sets while maintaining the same class distribution in each set.
* K-fold cross-validation: dividing the data into k subsets and using each subset as a validation set while the remaining subsets are used for training.

Without further information, it is impossible to determine the specific criteria used to split the data in this context.