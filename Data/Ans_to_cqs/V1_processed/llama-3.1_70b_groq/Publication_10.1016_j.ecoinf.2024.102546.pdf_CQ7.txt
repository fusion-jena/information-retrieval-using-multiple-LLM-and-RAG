Unfortunately, the provided context does not explicitly mention the criteria used to split the data for deep learning model training. The context appears to be a research paper on weed detection using deep learning models, and it discusses the dataset curation, hyperparameter settings, and model performance. However, it does not provide information on how the data was split for training, testing, and validation.

The context does mention that the authors used a dataset, but it does not provide details on how the dataset was preprocessed or split. It is possible that the authors used a common approach such as splitting the data into training, validation, and testing sets using a random split or k-fold cross-validation, but without further information, it is impossible to determine the exact criteria used.

Therefore, I do not know the answer to this question based on the provided context.