The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention that a Max pooling strategy with a 3 × 3 filter size and 1 × 1 stride is employed periodically between successive convolutional layers to reduce the amount of parameters and computation in the network, and hence to also control overfitting.