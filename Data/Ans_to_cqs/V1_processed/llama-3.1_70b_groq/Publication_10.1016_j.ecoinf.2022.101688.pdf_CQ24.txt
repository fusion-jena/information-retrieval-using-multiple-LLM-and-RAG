To handle randomness in the deep learning pipeline, the authors employed a few strategies. Firstly, they split each dataset into training (60%) and testing (40%) by randomly selecting entire audio files, but ensured that the training audio files were mutually exclusive to the testing audio files. This was done to ensure a fair evaluation of the models.

Additionally, the authors used a fixed decision threshold of 0.5 for assigning the final class based on the softmax output. This threshold was not optimized, which suggests that the authors aimed to keep the resulting models as accessible and easy-to-use as possible, rather than trying to squeeze out the best possible performance.

The authors also averaged the results across 13 unique executions, which suggests that they ran the experiments multiple times with different random seeds to account for any variability in the results. This is a common strategy in deep learning to handle randomness and ensure that the results are robust.

However, it is not explicitly mentioned whether the authors used a fixed random seed value for the experiments. It is possible that they used a fixed seed, but it is not clear from the provided text.