Unfortunately, the provided context does not explicitly mention the preprocessing steps involved before training a deep learning model. It mentions the use of batch normalization, which is a technique used to normalize the input data for each layer in a neural network, but it does not provide information on other preprocessing steps such as scaling, cleaning, or data augmentation.

However, it does mention the use of data augmentation as a potential way to improve model performance, citing a paper by Hernández-García and König (2018) that discusses the advantages of data augmentation on convolutional neural networks. Additionally, it mentions the importance of prioritizing images of poorly sampled species with higher error rates, which suggests that data cleaning and preprocessing may be important steps in improving model performance.

Overall, while the context does not provide a comprehensive list of preprocessing steps, it suggests that batch normalization and data augmentation may be important techniques to consider when training a deep learning model.