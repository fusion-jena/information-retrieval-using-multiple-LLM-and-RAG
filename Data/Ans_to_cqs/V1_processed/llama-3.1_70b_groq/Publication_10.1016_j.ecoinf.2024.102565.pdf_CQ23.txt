To ensure the generalizability of the model, several measures were taken. Firstly, a K-fold cross-validation technique was employed, where the dataset was divided into four mutually exclusive folds through stratified sampling. This approach allowed for the model to be trained and validated on different subsets of the data, reducing the risk of overfitting and increasing the model's ability to generalize to new data.

Additionally, the dataset was randomly divided into four folds, and each fold served as the validation set while the remaining three folds constituted the training set. This process was iterated four times, with distinct validation sets each time. This approach helped to maximize the utilization of both on-site and RS datasets, integrating them comprehensively into both training and validation phases.

Furthermore, to address imbalances in the dataset, random under-sampling (RUS) was applied to the training set, while the validation set remained unchanged. This helped to prevent the model from being biased towards the majority class and improved its ability to generalize to new data.

Overall, the use of K-fold cross-validation, stratified sampling, and random under-sampling helped to ensure the generalizability of the model by providing a more comprehensive and balanced evaluation of its performance.