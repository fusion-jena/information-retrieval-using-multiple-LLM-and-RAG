The provided context does not specifically discuss the criteria used to split data for deep learning model training. However, it does mention a common approach used in machine learning, which is to partition the data into k different subsets, or "folds", each of which is held out in turn as test data while the model is trained using the other k-1 folds. This is known as k-fold cross-validation.

Additionally, the context mentions that the data can be split into training and test sets, where a portion of the sample data is set aside during model training to test the accuracy of model predictions. This is often referred to as a train-test split.

It also mentions bagging, which involves drawing many bootstrap samples of the data and training models on each, which are aggregated to form an ensemble predictor. However, this is more related to model training and ensemble methods rather than data splitting criteria.

It's worth noting that the context does not provide specific criteria for splitting data into train, test, and validation sets, such as the proportion of data to be used for each set. These criteria can vary depending on the specific problem, dataset, and model being used.