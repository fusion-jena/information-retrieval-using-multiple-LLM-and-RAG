Unfortunately, the provided context does not explicitly mention strategies employed to handle randomness in the deep learning pipeline, such as random seed values. The context appears to be focused on the performance of a model on a specific dataset, the use of DBSCAN and other algorithms, and the analysis of results.

However, it can be inferred that the model was trained and tested on a specific dataset with a fixed train-test split, which might have been done to reduce the impact of randomness on the results. Additionally, the context mentions the use of an "ideal train-test split" which might imply that the authors have taken steps to ensure that the model is evaluated on a representative sample of the data.

But without further information, it is not possible to provide a more detailed answer on the specific strategies employed to handle randomness in the deep learning pipeline.