To ensure the generalizability of the model, several measures were taken. Firstly, the data was split into training, validation, and test sets. For the three-part split, the validation set was used to tweak the model's parameters and evaluate its performance, while the test set was used only once to evaluate the final model's performance. This approach helps to prevent overfitting and ensures that the model is not over-optimized to the training data.

Additionally, for the RY models, a specific data splitting approach was used where individual observations were grouped according to year of capture, and years were randomly selected for inclusion in the train and test datasets. This approach ensures that the model is tested using previously unseen combinations of explanatory variables, making it a more robust test of model performance.

Furthermore, hyperparameter tuning was done manually, starting with a low learning rate and a high number of iterations. The learning rate was adjusted to determine the contribution of each tree to the model, and the maximum tree depth was kept low to reflect the degree of interaction in the model. This approach helps to prevent overfitting and ensures that the model generalizes well to new data.

It is also mentioned that randomly splitting all individual observations is generally considered optimum in machine learning, as it does not introduce any systematic differences between the test and train datasets. However, this approach was not used for the RY models due to the specific requirements of the problem.

Overall, the measures taken to ensure the generalizability of the model include data splitting, hyperparameter tuning, and a specific data splitting approach for the RY models.