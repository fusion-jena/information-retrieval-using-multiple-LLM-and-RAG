Unfortunately, the provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. The context primarily focuses on the challenges of model validation and transfer learning in remote sensing applications, as well as the hyperparameter search process used in the research.

However, it does mention that the researchers compared the training, validation, and testing performance to avoid overfitting, which suggests that they may have used some form of regularization or early stopping. Additionally, the context mentions the use of techniques such as Nearest Neighbor Distance Matching (NNDM) and Leave-One-Out Cross-Validation (LOO CV) to evaluate the model's performance, but these are not regularization methods per se.

Therefore, I cannot provide a specific answer to the query, as the context does not provide enough information on the regularization methods used in the deep learning pipeline.