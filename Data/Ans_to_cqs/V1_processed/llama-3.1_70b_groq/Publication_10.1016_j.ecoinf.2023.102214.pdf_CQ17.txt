The provided context does not explicitly mention the regularization methods used to prevent overfitting in the deep learning pipeline, such as dropout or L2 regularization. However, it does mention the use of data augmentation techniques, specifically left-right mirroring, which helped reduce the issue of overfitting and strengthened the algorithm's capacity to match individuals based on pelt patterns rather than the background.

It is also mentioned that the model was trained and tested by tuning the number of required epochs and inspecting the model outputs and error outcomes for signs of overfitting. This suggests that the researchers may have used early stopping as a regularization method, where the training process is stopped when the model's performance on the validation set starts to degrade.

However, without more information, it is not possible to determine if other regularization methods, such as dropout or L2 regularization, were used in the deep learning pipeline.