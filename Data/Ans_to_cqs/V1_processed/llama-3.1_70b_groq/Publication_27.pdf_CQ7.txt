Unfortunately, the provided context does not contain specific information about the criteria used to split data for deep learning model training. The context appears to be a collection of encoded text, possibly from a research paper or academic article, but it does not provide clear guidance on data splitting criteria.

However, I can provide general information on common practices for splitting data in deep learning. Typically, data is split into three sets: training, validation, and testing. The training set is used to train the model, the validation set is used to evaluate the model's performance during training and tune hyperparameters, and the testing set is used to evaluate the model's performance after training.

Common criteria for splitting data include:

* Random splitting: Data is randomly assigned to each set.
* Stratified splitting: Data is split in a way that maintains the same proportion of classes in each set.
* K-fold cross-validation: Data is split into k folds, and each fold is used as a validation set once.

The specific criteria used to split data can depend on the problem, dataset, and model architecture. However, without more information from the provided context, I cannot provide a more specific answer.